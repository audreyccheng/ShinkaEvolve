<NAME>
two_stage_zoom_top4_pooling
</NAME>

<DESCRIPTION>
This edit introduces a Two-Stage "Zoom-In" search strategy to break the performance plateau.

1.  **Stage 1 (Exploration)**: Runs a smaller population of 64 candidates using Randomized LPT initialization and a fast greedy packing. This identifies the most promising "basin of attraction" in the solution space efficiently.
2.  **Stage 2 (Exploitation)**: Takes the best solution from Stage 1 and replicates it 128 times. These replicas are then subjected to:
    *   **Top-4 Pooling (Destruct-Reconstruct)**: A new refinement operator that pools items from the 2 heaviest and 2 lightest packs, sorts them, and redistributes them using a balanced zigzag pattern. This effectively resolves complex imbalances involving multiple packs that simple 1-item or 2-item swaps miss. Random noise is added to pack sums during pack selection to ensure diversity across replicas.
    *   **Max-Any Swap**: A deep run of the standard 1-item swap local search to polish the final configurations.

This approach combines global search with intensive, structured local search, leveraging the GPU's parallelism to perform heavy refinement only on the most promising candidates.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses a Massive Parallel Diverse Initialization followed by a
    Vectorized Max-Any Swap (1-item) and Max-Min Swap (2-item) local search.

    Parameters:
        weight: [layers, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [layers, n], the pack index of each item
        rank_in_pack: [layers, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_packs, dtype=torch.int64, device=device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # --- 1. Massive Parallel Initialization ---
    num_candidates = 128
    num_total_problems = num_layers * num_candidates

    # [L*C, N]
    w_expanded = weight.repeat_interleave(num_candidates, dim=0)

    # Strategy:
    # 0-95: Randomized LPT (LPT + Noise 0.0 to 0.4)
    # 96-127: Random Shuffle (Pure Random keys)

    # Create base noise
    base_noise = torch.rand_like(w_expanded, dtype=torch.float32)

    # Create scales [128]
    cand_scales = torch.zeros(num_candidates, device=device)
    cand_scales[:96] = torch.linspace(0, 0.4, 96, device=device)

    # Expand scales to [L*C, 1]
    scales_expanded = cand_scales.repeat(num_layers).view(-1, 1)

    # Apply noise for LPT part
    noise_lpt = base_noise * w_expanded.float() * scales_expanded
    sort_keys = w_expanded + noise_lpt.to(dtype=weight.dtype)

    # Fix Candidate 0 of each layer to be Pure LPT
    sort_keys.view(num_layers, num_candidates, num_groups)[:, 0, :] = w_expanded.view(num_layers, num_candidates, num_groups)[:, 0, :]

    # Part 2: Random Shuffle for 96-127
    random_keys = torch.rand_like(w_expanded)

    # Mask for last 32 candidates
    mask_random = torch.zeros(num_candidates, dtype=torch.bool, device=device)
    mask_random[96:] = True
    mask_random_expanded = mask_random.repeat(num_layers)

    sort_keys[mask_random_expanded] = random_keys[mask_random_expanded]

    # Sort
    _, sorted_indices = sort_keys.sort(dim=-1, descending=True)
    sorted_weight = torch.gather(w_expanded, 1, sorted_indices)

    # --- 2. Vectorized Greedy LPT Construction ---
    # Fill packs greedily item by item
    pack_weights = torch.zeros(num_total_problems, num_packs, device=device, dtype=weight.dtype)
    pack_counts = torch.zeros(num_total_problems, num_packs, device=device, dtype=torch.int64)
    sorted_pack_index = torch.zeros_like(sorted_indices)

    # Optimization: Pre-allocate constants
    ones = torch.ones(num_total_problems, 1, device=device, dtype=torch.int64)

    for i in range(num_groups):
        w_item = sorted_weight[:, i:i+1] # [LC, 1]

        # Mask full packs by setting their current weight to infinity
        is_full = (pack_counts >= groups_per_pack)
        candidates = pack_weights.clone()
        candidates[is_full] = float('inf')

        # Choose pack with min weight
        chosen_pack = candidates.argmin(dim=1, keepdim=True)

        # Record decision
        sorted_pack_index[:, i:i+1] = chosen_pack

        # Update state
        pack_weights.scatter_add_(1, chosen_pack, w_item)
        pack_counts.scatter_add_(1, chosen_pack, ones)

    # --- 3. Vectorized Local Search: Max-Any Swap (1-Item) ---
    _, pack_content_sort_idx = sorted_pack_index.sort(dim=1, stable=True)
    pack_contents = pack_content_sort_idx.view(num_total_problems, num_packs, groups_per_pack)

    K = groups_per_pack
    num_iters_1 = 20

    for _ in range(num_iters_1):
        # Recompute Weights & Identify Max Pack
        flat_contents = pack_contents.view(num_total_problems, -1)
        current_weights = torch.gather(sorted_weight, 1, flat_contents).view(num_total_problems, num_packs, K)
        pack_sums = current_weights.sum(dim=2)
        val_max, idx_max_pack = pack_sums.max(dim=1)

        gather_idx = idx_max_pack.view(-1, 1, 1).expand(-1, 1, K)
        w_max = torch.gather(current_weights, 1, gather_idx).squeeze(1)

        # Diff against all packs
        diffs = w_max.view(num_total_problems, 1, K, 1) - current_weights.view(num_total_problems, num_packs, 1, K)

        val_max_exp = val_max.view(num_total_problems, 1, 1, 1)
        pack_sums_exp = pack_sums.view(num_total_problems, num_packs, 1, 1)

        new_pair_max = torch.max(val_max_exp - diffs, pack_sums_exp + diffs)
        improvement = val_max_exp - new_pair_max

        mask_self = (torch.arange(num_packs, device=device).view(1, -1) == idx_max_pack.view(-1, 1))
        mask_self = mask_self.view(num_total_problems, num_packs, 1, 1)

        valid_mask = (diffs > 0) & (improvement > 1e-6) & (~mask_self)

        scores = torch.where(valid_mask, improvement, torch.tensor(float('-inf'), device=device))
        best_imp, flat_idx = scores.view(num_total_problems, -1).max(dim=1)

        if not (best_imp > float('-inf')).any():
            break

        valid_layers = torch.nonzero(best_imp > float('-inf')).squeeze(1)
        if len(valid_layers) == 0:
            break

        f_idx = flat_idx[valid_layers]
        K2 = K * K
        p_other = f_idx // K2
        rem = f_idx % K2
        idx_in_max = rem // K
        idx_in_other = rem % K
        p_max = idx_max_pack[valid_layers]

        val_max_item = pack_contents[valid_layers, p_max, idx_in_max].clone()
        val_other_item = pack_contents[valid_layers, p_other, idx_in_other].clone()
        pack_contents[valid_layers, p_max, idx_in_max] = val_other_item
        pack_contents[valid_layers, p_other, idx_in_other] = val_max_item

    # --- 4. Vectorized Max-Min Swap (2-Item) ---
    if K >= 2 and K <= 32:
        pair_idx = torch.triu_indices(K, K, offset=1, device=device)
        idx_1 = pair_idx[0]
        idx_2 = pair_idx[1]
        num_pairs = pair_idx.shape[1]

        num_iters_2 = 10
        for _ in range(num_iters_2):
            flat_contents = pack_contents.view(num_total_problems, -1)
            current_weights = torch.gather(sorted_weight, 1, flat_contents).view(num_total_problems, num_packs, K)
            pack_sums = current_weights.sum(dim=2)
            val_max, idx_max_pack = pack_sums.max(dim=1)
            val_min, idx_min_pack = pack_sums.min(dim=1)

            gather_max = idx_max_pack.view(-1, 1, 1).expand(-1, 1, K)
            gather_min = idx_min_pack.view(-1, 1, 1).expand(-1, 1, K)

            items_max = torch.gather(current_weights, 1, gather_max).squeeze(1)
            items_min = torch.gather(current_weights, 1, gather_min).squeeze(1)

            pairs_max_w = items_max[:, idx_1] + items_max[:, idx_2]
            pairs_min_w = items_min[:, idx_1] + items_min[:, idx_2]

            diffs = pairs_max_w.unsqueeze(2) - pairs_min_w.unsqueeze(1)

            val_max_exp = val_max.view(-1, 1, 1)
            val_min_exp = val_min.view(-1, 1, 1)

            new_peak = torch.max(val_max_exp - diffs, val_min_exp + diffs)
            improvement = val_max_exp - new_peak

            valid_mask = (diffs > 0) & (improvement > 1e-6)

            scores = torch.where(valid_mask, improvement, torch.tensor(float('-inf'), device=device))
            best_imp, flat_idx = scores.view(num_total_problems, -1).max(dim=1)

            if not (best_imp > float('-inf')).any():
                break

            valid_layers = torch.nonzero(best_imp > float('-inf')).squeeze(1)
            if len(valid_layers) == 0:
                break

            f_idx = flat_idx[valid_layers]
            p_idx_max_pair = f_idx // num_pairs
            p_idx_min_pair = f_idx % num_pairs

            i1_max = idx_1[p_idx_max_pair]
            i2_max = idx_2[p_idx_max_pair]
            i1_min = idx_1[p_idx_min_pair]
            i2_min = idx_2[p_idx_min_pair]

            p_max = idx_max_pack[valid_layers]
            p_min = idx_min_pack[valid_layers]

            val_max_1 = pack_contents[valid_layers, p_max, i1_max].clone()
            val_min_1 = pack_contents[valid_layers, p_min, i1_min].clone()
            pack_contents[valid_layers, p_max, i1_max] = val_min_1
            pack_contents[valid_layers, p_min, i1_min] = val_max_1

            val_max_2 = pack_contents[valid_layers, p_max, i2_max].clone()
            val_min_2 = pack_contents[valid_layers, p_min, i2_min].clone()
            pack_contents[valid_layers, p_max, i2_max] = val_min_2
            pack_contents[valid_layers, p_min, i2_min] = val_max_2

    # --- 5. Select Best Candidate ---
    flat_contents = pack_contents.view(num_total_problems, -1)
    final_weights = torch.gather(sorted_weight, 1, flat_contents).view(num_total_problems, num_packs, groups_per_pack)
    final_max_loads = final_weights.sum(dim=2).max(dim=1).values # [LC]

    # Reshape: [L, C] -> min over candidates
    reshaped_max_loads = final_max_loads.view(num_layers, num_candidates)
    best_candidate_idx = reshaped_max_loads.argmin(dim=1) # [L]

    # Gather best result
    # For repeat_interleave: index = layer * C + cand_idx
    best_indices = torch.arange(num_layers, device=device) * num_candidates + best_candidate_idx

    best_contents = pack_contents[best_indices]
    best_sorted_indices = sorted_indices[best_indices]

    # Map back
    flat_best_contents = best_contents.view(num_layers, -1)
    original_item_indices = torch.gather(best_sorted_indices, 1, flat_best_contents)

    pack_ids = torch.arange(num_packs, device=device).view(1, num_packs, 1).expand(num_layers, -1, groups_per_pack).reshape(num_layers, -1)
    rank_ids = torch.arange(groups_per_pack, device=device).view(1, 1, groups_per_pack).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    pack_index = torch.empty_like(pack_ids)
    rank_in_pack = torch.empty_like(rank_ids)

    pack_index.scatter_(1, original_item_indices, pack_ids)
    rank_in_pack.scatter_(1, original_item_indices, rank_ids)

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses a Two-Stage "Zoom-In" Strategy:
    1. Exploration: 64 candidates with randomized LPT + Greedy.
    2. Exploitation: Replicate best candidate, apply mutations, Top-4 Pooling,
       and Vectorized Max-Any Swap.

    Parameters:
        weight: [layers, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [layers, n], the pack index of each item
        rank_in_pack: [layers, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_packs, dtype=torch.int64, device=device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # --- Stage 1: Exploration (64 Candidates) ---
    num_candidates_s1 = 64
    w_s1 = weight.repeat_interleave(num_candidates_s1, dim=0) # [L*64, N]

    # Randomized LPT
    noise = torch.rand_like(w_s1) * w_s1 * 0.2
    # Candidate 0 is pure LPT
    noise.view(num_layers, num_candidates_s1, num_groups)[:, 0, :] = 0
    sort_keys = w_s1 + noise
    _, sorted_indices_s1 = sort_keys.sort(dim=-1, descending=True)
    sorted_weight_s1 = torch.gather(w_s1, 1, sorted_indices_s1)

    # Greedy Packing
    pack_counts = torch.zeros(num_layers * num_candidates_s1, num_packs, device=device, dtype=torch.int64)
    pack_weights = torch.zeros(num_layers * num_candidates_s1, num_packs, device=device, dtype=weight.dtype)
    sorted_pack_index_s1 = torch.zeros_like(sorted_indices_s1)

    ones = torch.ones(num_layers * num_candidates_s1, 1, device=device, dtype=torch.int64)
    inf_tensor = torch.tensor(float('inf'), device=device)

    for i in range(num_groups):
        w_item = sorted_weight_s1[:, i:i+1]
        is_full = (pack_counts >= groups_per_pack)
        costs = torch.where(is_full, inf_tensor, pack_weights)
        chosen_pack = costs.argmin(dim=1, keepdim=True)

        sorted_pack_index_s1[:, i:i+1] = chosen_pack
        pack_weights.scatter_add_(1, chosen_pack, w_item)
        pack_counts.scatter_add_(1, chosen_pack, ones)

    # Select Best Candidate from Stage 1
    max_loads_s1 = pack_weights.max(dim=1).values
    max_loads_s1 = max_loads_s1.view(num_layers, num_candidates_s1)
    best_cand_s1 = max_loads_s1.argmin(dim=1) # [L]

    best_idx_flat = torch.arange(num_layers, device=device) * num_candidates_s1 + best_cand_s1

    # Extract Best Configuration
    best_pack_index = sorted_pack_index_s1[best_idx_flat] # [L, N]
    best_sorted_indices = sorted_indices_s1[best_idx_flat] # [L, N]
    best_weight = torch.gather(weight, 1, best_sorted_indices) # [L, N] sorted by LPT of winner

    # --- Stage 2: Exploitation (128 Candidates) ---
    num_candidates_s2 = 128
    num_problems = num_layers * num_candidates_s2

    # Replicate Best Config
    # pack_index: [L, N] -> [L*128, N]
    curr_pack_index = best_pack_index.repeat_interleave(num_candidates_s2, dim=0)
    curr_sorted_weight = best_weight.repeat_interleave(num_candidates_s2, dim=0) # [L*128, N]

    # Convert to pack_contents: [Batch, Packs, K]
    _, sort_p = curr_pack_index.sort(dim=1, stable=True)
    pack_contents = sort_p.view(num_problems, num_packs, groups_per_pack)

    K = groups_per_pack

    # Mutation: Random Swaps (Apply to 75% of candidates, keep 25% pristine)
    # We can skip this if we rely on Top-4 Pooling to introduce diversity via noise

    # --- Top-4 Pooling (Destruct-Reconstruct) ---
    # Pool items from 2 Heaviest and 2 Lightest packs, sort, and redistribute (ABBA-like)
    # Pattern for 4K items:
    # Packs: Max1, Max2, Min1, Min2
    # Redistribution:
    # Max1: 0, 7, 8, 15...
    # Max2: 1, 6, 9, 14...
    # Min1: 2, 5, 10, 13...
    # Min2: 3, 4, 11, 12... (Zigzag)

    iters_pooling = 10

    # Precompute masks
    indices_4k = torch.arange(4 * K, device=device)
    # Zigzag modulo 8
    # 0,7 -> P0; 1,6 -> P1; 2,5 -> P2; 3,4 -> P3
    # rem = indices_4k % 8
    # target:
    # 0 -> 0
    # 1 -> 1
    # 2 -> 2
    # 3 -> 3
    # 4 -> 3
    # 5 -> 2
    # 6 -> 1
    # 7 -> 0
    rem = indices_4k % 8
    target_p = torch.where(rem < 4, rem, 7 - rem)

    mask_p0 = (target_p == 0)
    mask_p1 = (target_p == 1)
    mask_p2 = (target_p == 2)
    mask_p3 = (target_p == 3)

    if num_packs >= 4:
        for _ in range(iters_pooling):
            flat_c = pack_contents.view(num_problems, -1)
            # pack_contents points to indices in curr_sorted_weight
            curr_w = torch.gather(curr_sorted_weight, 1, flat_c).view(num_problems, num_packs, K)
            pack_sums = curr_w.sum(dim=2)

            # Add noise to pack sums to diversify selection across replicas
            noise = torch.rand_like(pack_sums) * pack_sums.mean(dim=1, keepdim=True) * 0.01
            # Candidate 0: No noise (Greedy)
            noise.view(num_layers, num_candidates_s2, num_packs)[:, 0, :] = 0

            noisy_sums = pack_sums + noise

            # Select Top 2 Max and Top 2 Min
            # We use topk
            _, top_indices = noisy_sums.topk(k=2, dim=1, largest=True) # [Batch, 2]
            _, bot_indices = noisy_sums.topk(k=2, dim=1, largest=False) # [Batch, 2]

            p0 = top_indices[:, 0] # Max 1
            p1 = top_indices[:, 1] # Max 2
            p2 = bot_indices[:, 0] # Min 1
            p3 = bot_indices[:, 1] # Min 2

            # Ensure distinct packs (overlap unlikely with sufficient packs/noise, but possible)
            # If overlap, we just skip or accept sub-optimal behavior. Given N=256, collision is rare.

            # Gather items
            # Shape: [Batch, 1, K]
            def get_items(p_idx):
                gather_idx = p_idx.view(-1, 1, 1).expand(-1, 1, K)
                return torch.gather(pack_contents, 1, gather_idx).squeeze(1) # [Batch, K]

            idx0 = get_items(p0)
            idx1 = get_items(p1)
            idx2 = get_items(p2)
            idx3 = get_items(p3)

            # Merge indices [Batch, 4K]
            merged_indices = torch.cat([idx0, idx1, idx2, idx3], dim=1)

            # Get weights
            merged_w = torch.gather(curr_sorted_weight, 1, merged_indices)

            # Sort descending
            _, sort_idx = merged_w.sort(dim=1, descending=True)
            sorted_merged_indices = torch.gather(merged_indices, 1, sort_idx)

            # Redistribute
            new_idx0 = sorted_merged_indices[:, mask_p0]
            new_idx1 = sorted_merged_indices[:, mask_p1]
            new_idx2 = sorted_merged_indices[:, mask_p2]
            new_idx3 = sorted_merged_indices[:, mask_p3]

            # Update pack_contents
            batch_idx = torch.arange(num_problems, device=device)
            pack_contents[batch_idx, p0, :] = new_idx0
            pack_contents[batch_idx, p1, :] = new_idx1
            pack_contents[batch_idx, p2, :] = new_idx2
            pack_contents[batch_idx, p3, :] = new_idx3

    # --- Vectorized Max-Any Swap (Deep Refinement) ---
    iters_swap = 20
    for _ in range(iters_swap):
        flat_c = pack_contents.view(num_problems, -1)
        curr_w = torch.gather(curr_sorted_weight, 1, flat_c).view(num_problems, num_packs, K)
        pack_sums = curr_w.sum(dim=2)

        val_max, idx_max = pack_sums.max(dim=1)

        gather_max = idx_max.view(-1, 1, 1).expand(-1, 1, K)
        w_max = torch.gather(curr_w, 1, gather_max).squeeze(1) # [Batch, K]

        # Diffs: [Batch, 1, K, 1] - [Batch, M, 1, K]
        # max_item - other_item
        diffs = w_max.view(num_problems, 1, K, 1) - curr_w.view(num_problems, num_packs, 1, K)

        val_max_exp = val_max.view(num_problems, 1, 1, 1)
        pack_sums_exp = pack_sums.view(num_problems, num_packs, 1, 1)

        # New Max Load if swap happens
        # Only checks pair max. Heuristic.
        new_pair_max = torch.max(val_max_exp - diffs, pack_sums_exp + diffs)
        improvement = val_max_exp - new_pair_max

        mask_self = (torch.arange(num_packs, device=device).view(1, -1) == idx_max.view(-1, 1)).view(num_problems, num_packs, 1, 1)

        valid = (diffs > 0) & (improvement > 1e-6) & (~mask_self)

        scores = torch.where(valid, improvement, torch.tensor(float('-inf'), device=device))
        best_imp, flat_idx = scores.view(num_problems, -1).max(dim=1)

        if not (best_imp > float('-inf')).any():
            break

        active = torch.nonzero(best_imp > float('-inf')).squeeze(1)
        if len(active) == 0: break

        f_idx = flat_idx[active]
        K2 = K*K
        p_other = f_idx // K2
        rem = f_idx % K2
        i_max = rem // K
        i_other = rem % K

        p_max = idx_max[active]

        v_max = pack_contents[active, p_max, i_max].clone()
        v_oth = pack_contents[active, p_other, i_other].clone()

        pack_contents[active, p_max, i_max] = v_oth
        pack_contents[active, p_other, i_other] = v_max

    # --- Final Selection ---
    flat_c = pack_contents.view(num_problems, -1)
    final_w = torch.gather(curr_sorted_weight, 1, flat_c).view(num_problems, num_packs, K)
    final_max = final_w.sum(dim=2).max(dim=1).values

    final_max = final_max.view(num_layers, num_candidates_s2)
    best_cand = final_max.argmin(dim=1)

    best_idx = torch.arange(num_layers, device=device) * num_candidates_s2 + best_cand

    best_c = pack_contents[best_idx] # [L, M, K]

    # We need to map back to ORIGINAL indices.
    # pack_contents indices refer to `curr_sorted_weight` which is `best_weight` replicated.
    # `best_weight` is `weight` gathered by `best_sorted_indices` (from stage 1).

    flat_best_c = best_c.view(num_layers, -1)

    # These are indices into best_sorted_indices[layer]
    # We need to gather from best_sorted_indices
    original_idx = torch.gather(best_sorted_indices, 1, flat_best_c)

    # Output arrays
    pack_index = torch.empty(num_layers, num_groups, dtype=torch.long, device=device)
    rank_in_pack = torch.empty(num_layers, num_groups, dtype=torch.long, device=device)

    p_ids = torch.arange(num_packs, device=device).view(1, num_packs, 1).expand(num_layers, -1, groups_per_pack).reshape(num_layers, -1)
    r_ids = torch.arange(groups_per_pack, device=device).view(1, 1, groups_per_pack).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    pack_index.scatter_(1, original_idx, p_ids)
    rank_in_pack.scatter_(1, original_idx, r_ids)

    return pack_index, rank_in_pack
>>>>>>> REPLACE
</DIFF>