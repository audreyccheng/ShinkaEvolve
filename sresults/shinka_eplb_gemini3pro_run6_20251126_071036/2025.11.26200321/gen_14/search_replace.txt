<NAME>
hybrid_greedy_packing
</NAME>

<DESCRIPTION>
Implements a Hybrid Packing strategy that computes both "Folded Chunked Sorted Greedy" and "Global Greedy" allocations for each layer, and selects the better one based on load balance (minimized max-min load difference). This ensures the algorithm performs at least as well as the robust chunked approach while taking advantage of the global greedy approach when it produces tighter packing.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs using a Folded Chunked Sorted Greedy strategy.

    Items are processed in "double chunks" of size 2*m. In each double chunk,
    items are paired (heaviest + lightest) to form m balanced pairs, which are
    then assigned to packs greedily (heaviest pair -> lightest pack).
    This smoothing reduces load variance significantly compared to single-item greedy.

    Parameters:
        weight: [layers, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [layers, n], the pack index of each item
        rank_in_pack: [layers, n], the rank of the item in the pack
    """
    num_layers, num_items = weight.shape
    device = weight.device

    sorted_weights, sorted_indices = weight.sort(dim=-1, descending=True)

    pack_loads = torch.zeros(num_layers, num_packs, device=device, dtype=weight.dtype)
    aligned_pack_ids = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)
    aligned_ranks = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)

    # Process in chunks of 2 * num_packs to enable folding
    double_chunk_size = 2 * num_packs
    num_double_chunks = num_items // double_chunk_size

    for k in range(num_double_chunks):
        start = k * double_chunk_size
        end = start + double_chunk_size

        # Chunk weights: [Layers, 2*M]
        chunk_weights = sorted_weights[:, start:end]

        # Pair indices: 0 with 2M-1, 1 with 2M-2, ...
        idx_low = torch.arange(num_packs, device=device)
        idx_high = torch.arange(double_chunk_size - 1, num_packs - 1, -1, device=device)

        # Compute pair weights
        pair_weights = chunk_weights[:, idx_low] + chunk_weights[:, idx_high]

        # Identify assignment order: Heaviest pair -> Lightest pack
        _, sorted_bin_indices = pack_loads.sort(dim=-1) # Lightest pack at 0
        _, pairs_order = pair_weights.sort(dim=-1, descending=True) # Heaviest pair at 0

        # We assign sorted_bin_indices[i] to pairs_order[i]
        # Map: Pair j gets Pack assigned_packs[j]
        # assigned_packs[pairs_order] = sorted_bin_indices
        assigned_packs = torch.empty_like(sorted_bin_indices)
        assigned_packs.scatter_(1, pairs_order, sorted_bin_indices)

        # Assign to items
        # Low item (j) and High item (2M-1-j) get the same pack
        aligned_pack_ids[:, start + idx_low] = assigned_packs
        aligned_pack_ids[:, start + idx_high] = assigned_packs

        # Assign ranks (2 items added per pack)
        aligned_ranks[:, start + idx_low] = 2 * k
        aligned_ranks[:, start + idx_high] = 2 * k + 1

        # Update loads
        pack_loads.scatter_add_(1, assigned_packs, pair_weights)

    # Handle remainder chunk (size M, if any)
    remainder_start = num_double_chunks * double_chunk_size
    if remainder_start < num_items:
        start = remainder_start
        end = num_items # Should be start + num_packs

        chunk_weights = sorted_weights[:, start:end]
        _, sorted_bin_indices = pack_loads.sort(dim=-1)

        aligned_pack_ids[:, start:end] = sorted_bin_indices
        aligned_ranks[:, start:end] = 2 * num_double_chunks

        pack_loads.scatter_add_(1, sorted_bin_indices, chunk_weights)

    # Scatter back to original order
    pack_index = torch.empty_like(aligned_pack_ids)
    rank_in_pack = torch.empty_like(aligned_ranks)

    pack_index.scatter_(1, sorted_indices, aligned_pack_ids)
    rank_in_pack.scatter_(1, sorted_indices, aligned_ranks)

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs using a Hybrid Strategy.

    This function computes two different packing allocations:
    1. Folded Chunked Sorted Greedy: Pairs heaviest+lightest items in chunks.
    2. Global Greedy: Assigns items strictly by weight to the lightest valid pack.

    It then selects the allocation that minimizes load imbalance (max - min)
    independently for each layer.

    Parameters:
        weight: [layers, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [layers, n], the pack index of each item
        rank_in_pack: [layers, n], the rank of the item in the pack
    """
    num_layers, num_items = weight.shape
    device = weight.device

    # Shared Sort
    sorted_weights, sorted_indices = weight.sort(dim=-1, descending=True)

    # --- Strategy 1: Folded Chunked Sorted Greedy ---
    loads1 = torch.zeros(num_layers, num_packs, device=device, dtype=weight.dtype)
    ids1 = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)
    ranks1 = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)

    double_chunk_size = 2 * num_packs
    num_double_chunks = num_items // double_chunk_size

    for k in range(num_double_chunks):
        start = k * double_chunk_size
        end = start + double_chunk_size
        chunk_weights = sorted_weights[:, start:end]

        idx_low = torch.arange(num_packs, device=device)
        idx_high = torch.arange(double_chunk_size - 1, num_packs - 1, -1, device=device)
        pair_weights = chunk_weights[:, idx_low] + chunk_weights[:, idx_high]

        _, sorted_bin_indices = loads1.sort(dim=-1)
        _, pairs_order = pair_weights.sort(dim=-1, descending=True)

        assigned_packs = torch.empty_like(sorted_bin_indices)
        assigned_packs.scatter_(1, pairs_order, sorted_bin_indices)

        ids1[:, start + idx_low] = assigned_packs
        ids1[:, start + idx_high] = assigned_packs
        ranks1[:, start + idx_low] = 2 * k
        ranks1[:, start + idx_high] = 2 * k + 1
        loads1.scatter_add_(1, assigned_packs, pair_weights)

    remainder_start = num_double_chunks * double_chunk_size
    if remainder_start < num_items:
        start = remainder_start
        end = num_items
        chunk_weights = sorted_weights[:, start:end]
        _, sorted_bin_indices = loads1.sort(dim=-1)
        ids1[:, start:end] = sorted_bin_indices
        ranks1[:, start:end] = 2 * num_double_chunks
        loads1.scatter_add_(1, sorted_bin_indices, chunk_weights)

    # --- Strategy 2: Global Greedy with Cardinality Constraints ---
    # Capacity is strictly n/m
    capacity = num_items // num_packs
    loads2 = torch.zeros(num_layers, num_packs, device=device, dtype=weight.dtype)
    counts2 = torch.zeros(num_layers, num_packs, device=device, dtype=torch.int64)
    ids2 = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)
    ranks2 = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)

    layer_indices = torch.arange(num_layers, device=device)

    for i in range(num_items):
        w = sorted_weights[:, i]
        valid_mask = counts2 < capacity

        # Select pack with min load among valid packs
        masked_loads = loads2.clone()
        masked_loads[~valid_mask] = float('inf')

        chosen_packs = torch.argmin(masked_loads, dim=1)

        ids2[:, i] = chosen_packs
        ranks2[:, i] = counts2[layer_indices, chosen_packs]

        counts2[layer_indices, chosen_packs] += 1
        loads2[layer_indices, chosen_packs] += w

    # --- Selection ---
    # Metric: Max Load - Min Load (smaller is better)
    imbalance1 = loads1.max(dim=-1).values - loads1.min(dim=-1).values
    imbalance2 = loads2.max(dim=-1).values - loads2.min(dim=-1).values

    # Select Strategy 2 if it's better (strictly smaller imbalance)
    use_strategy2 = (imbalance2 < imbalance1).unsqueeze(-1) # [Layers, 1]

    final_ids_aligned = torch.where(use_strategy2, ids2, ids1)
    final_ranks_aligned = torch.where(use_strategy2, ranks2, ranks1)

    # Scatter back
    pack_index = torch.empty_like(final_ids_aligned)
    rank_in_pack = torch.empty_like(final_ranks_aligned)

    pack_index.scatter_(1, sorted_indices, final_ids_aligned)
    rank_in_pack.scatter_(1, sorted_indices, final_ranks_aligned)

    return pack_index, rank_in_pack
>>>>>>> REPLACE
</DIFF>