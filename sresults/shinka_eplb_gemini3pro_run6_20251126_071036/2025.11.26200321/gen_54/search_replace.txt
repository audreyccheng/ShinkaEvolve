<NAME>
greedy_lpt_max_any_swap
</NAME>

<DESCRIPTION>
Replaces the "ZigZag" initialization with a "Massive Parallel Greedy LPT" initialization using 128 candidates. ZigZag is a fixed pattern that doesn't adapt to specific weight distributions, while Greedy LPT (Longest Processing Time) actively balances loads during construction, usually providing a much better starting point.

Replaces the "Max-Min Swap" local search with a stronger "Max-Any Swap" local search. Instead of only checking swaps between the heaviest and lightest packs, this checks swaps between the heaviest pack and *all* other packs. This broadens the search neighborhood significantly, allowing the algorithm to find moves that reduce the max load by swapping with a "medium" pack when the lightest pack cannot accommodate the swap (e.g., due to item size constraints).

These changes aim to break the 0.31 balancedness plateau by combining a better constructive heuristic with a more comprehensive local search, leveraging the massive parallelism of the GPU to handle the increased computational work.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses a Parallel Randomized ZigZag initialization followed by a Vectorized
    Max-Min Swap local search refinement.

    Parameters:
        weight: [layers, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [layers, n], the pack index of each item
        rank_in_pack: [layers, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_packs, dtype=torch.int64, device=device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # Configuration
    # Using more candidates improves solution quality at the cost of memory/compute.
    # 64 is a good balance for GPU processing.
    num_candidates = 64
    num_iters = 20

    # 1. Expand and Randomize
    # [L*C, N]
    w_expanded = weight.repeat_interleave(num_candidates, dim=0)

    # Add noise to weights to generate diverse permutations.
    # Candidate 0 is always pure LPT (zero noise) to preserve the baseline greedy solution.
    # Use float32 for noise generation to ensure precision.
    noise = torch.rand_like(w_expanded, dtype=torch.float32) * (w_expanded.float() * 0.15)
    noise = noise.to(dtype=weight.dtype)
    noise.view(num_layers, num_candidates, num_groups)[:, 0, :] = 0

    # Sort by noisy weights to determine processing order
    # sorted_indices: [batch, N]
    sort_keys = w_expanded + noise
    _, sorted_indices = sort_keys.sort(dim=-1, descending=True)

    # Gather actual weights in the sorted order: [batch, N]
    sorted_weights = torch.gather(w_expanded, 1, sorted_indices)

    # 2. Vectorized ZigZag Assignment
    # Create pattern: 0, 1, ... M-1, M-1, ... 0
    # Length 2M.
    fwd = torch.arange(num_packs, device=device)
    bwd = torch.arange(num_packs - 1, -1, -1, device=device)
    pattern = torch.cat([fwd, bwd])

    # Tile pattern to length N (number of items)
    num_tiles = (num_groups + len(pattern) - 1) // len(pattern)
    assignments = pattern.repeat(num_tiles)[:num_groups] # [N]

    # Convert linear assignment to structured pack_contents.
    # pack_contents stores indices into the 'sorted_weights' array.
    # We first find the indices that sort 'assignments', effectively grouping items by pack.
    # A stable sort ensures that within each pack, the items remain in descending weight order.
    _, pattern_sort_idx = assignments.sort(stable=True)

    # pattern_sort_idx is [N].
    # Reshape to [M, K] to get the structure: rows are packs, cols are items in pack.
    pack_content_indices = pattern_sort_idx.view(num_packs, groups_per_pack) # [M, K]

    # Expand to full batch: [batch, M, K]
    pack_contents = pack_content_indices.unsqueeze(0).expand(num_layers * num_candidates, -1, -1).clone()

    # 3. Vectorized Local Search (Max-Min Swap)
    batch_size = num_layers * num_candidates
    batch_range = torch.arange(batch_size, device=device)

    for _ in range(num_iters):
        # Calculate pack sums
        # Flatten contents to gather weights: [batch, M*K] -> gather -> [batch, M, K]
        flat_contents = pack_contents.view(batch_size, -1)
        p_weights = torch.gather(sorted_weights, 1, flat_contents).view(batch_size, num_packs, groups_per_pack)

        # Sum items in each pack: [batch, M]
        p_sums = p_weights.sum(dim=2)

        # Identify Max and Min packs for each candidate
        max_val, max_id = p_sums.max(dim=1) # [batch]
        min_val, min_id = p_sums.min(dim=1) # [batch]

        # Retrieve item weights in Max and Min packs for possible swap
        # p_weights is [batch, M, K]. We select the rows corresponding to max_id/min_id.
        w_max_items = p_weights[batch_range, max_id, :] # [batch, K]
        w_min_items = p_weights[batch_range, min_id, :] # [batch, K]

        # Calculate diff matrix: [batch, K, K]
        # diff[b, i, j] = weight of item i in max pack - weight of item j in min pack
        diffs = w_max_items.unsqueeze(2) - w_min_items.unsqueeze(1)

        # Optimization Goal: Minimize max(SumMax - diff, SumMin + diff)
        # We define Improvement = CurrentMax - NewPairMax

        s_max = max_val.view(-1, 1, 1)
        s_min = min_val.view(-1, 1, 1)

        # Estimate new loads after swap
        new_max_load = s_max - diffs
        new_min_load = s_min + diffs

        # The new max of the pair (since other packs don't change, we only care if this pair reduces below current max)
        pair_max = torch.max(new_max_load, new_min_load)

        improvement = s_max - pair_max

        # Validity mask:
        # 1. diff > 0: Must strictly move weight from Max to Min pack
        # 2. improvement > epsilon: Must actually improve the objective
        valid = (diffs > 0)

        score = torch.where(valid, improvement, torch.tensor(float('-inf'), device=device))

        # Find best swap per candidate
        # Flatten KxK -> K^2
        flat_score = score.view(batch_size, -1)
        best_imp, best_idx = flat_score.max(dim=1)

        # Threshold check
        do_swap = best_imp > 1e-6
        if not do_swap.any():
            break

        # Execute swaps for applicable batches
        active = torch.nonzero(do_swap).squeeze(1)

        if len(active) == 0:
            break

        # Decode indices
        sel_idx = best_idx[active]
        idx_max = sel_idx // groups_per_pack
        idx_min = sel_idx % groups_per_pack

        sel_batch = batch_range[active]
        sel_p_max = max_id[active]
        sel_p_min = min_id[active]

        # Perform swap in pack_contents
        # Get the item indices (in sorted_weights) being swapped
        val_max_ptr = pack_contents[sel_batch, sel_p_max, idx_max].clone()
        val_min_ptr = pack_contents[sel_batch, sel_p_min, idx_min].clone()

        pack_contents[sel_batch, sel_p_max, idx_max] = val_min_ptr
        pack_contents[sel_batch, sel_p_min, idx_min] = val_max_ptr

    # 4. Select Best Candidate
    # Recompute sums to ensure accuracy
    flat_contents = pack_contents.view(batch_size, -1)
    final_weights = torch.gather(sorted_weights, 1, flat_contents).view(batch_size, num_packs, groups_per_pack)
    final_max_load = final_weights.sum(dim=2).max(dim=1).values # [batch]

    # Reshape [Layers, Candidates] to find best per layer
    final_max_load = final_max_load.view(num_layers, num_candidates)
    best_cand = final_max_load.argmin(dim=1) # [L]

    # Gather best solution indices
    # Index in batch = layer * C + best_cand
    batch_indices = torch.arange(num_layers, device=device) * num_candidates + best_cand

    best_contents = pack_contents[batch_indices] # [L, M, K]
    best_sorted_idx = sorted_indices[batch_indices] # [L, N]

    # Map back to original indices
    # best_contents has indices into best_sorted_idx
    flat_best_contents = best_contents.view(num_layers, -1)
    original_indices = torch.gather(best_sorted_idx, 1, flat_best_contents)

    # Create outputs
    # pack_ids: [0, 0... 1, 1... M-1, M-1...]
    pack_ids = torch.arange(num_packs, device=device).view(1, num_packs, 1).expand(num_layers, -1, groups_per_pack).reshape(num_layers, -1)
    # rank_ids: [0, 1... K-1, 0, 1... K-1...]
    rank_ids = torch.arange(groups_per_pack, device=device).view(1, 1, groups_per_pack).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    pack_index = torch.empty_like(pack_ids)
    rank_in_pack = torch.empty_like(rank_ids)

    # Scatter results to original positions
    pack_index.scatter_(1, original_indices, pack_ids)
    rank_in_pack.scatter_(1, original_indices, rank_ids)

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses a Massive Parallel Greedy LPT initialization followed by a
    Vectorized Max-Any Swap local search refinement.

    Parameters:
        weight: [layers, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [layers, n], the pack index of each item
        rank_in_pack: [layers, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_packs, dtype=torch.int64, device=device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # --- 1. Massive Parallel Initialization ---
    # Increased candidates for better exploration
    num_candidates = 128
    num_total_problems = num_layers * num_candidates

    # [L*C, N]
    w_expanded = weight.repeat_interleave(num_candidates, dim=0)

    # Noise Spectrum: 0.0 to 0.4
    # Candidate 0 of each layer group is pure LPT (0 noise)
    scales = torch.linspace(0, 0.4, num_candidates, device=device)
    noise_scale = scales.repeat(num_layers).view(-1, 1)

    # Add noise
    noise = torch.rand_like(w_expanded, dtype=torch.float32) * (w_expanded.float() * noise_scale)
    noise = noise.to(dtype=weight.dtype)
    noise.view(num_layers, num_candidates, num_groups)[:, 0, :] = 0

    sort_keys = w_expanded + noise
    _, sorted_indices = sort_keys.sort(dim=-1, descending=True)
    sorted_weight = torch.gather(w_expanded, 1, sorted_indices)

    # --- 2. Vectorized Greedy LPT Construction ---
    # Fill packs greedily item by item
    pack_weights = torch.zeros(num_total_problems, num_packs, device=device, dtype=weight.dtype)
    pack_counts = torch.zeros(num_total_problems, num_packs, device=device, dtype=torch.int64)
    sorted_pack_index = torch.zeros_like(sorted_indices)

    # Optimization: Pre-allocate constants
    ones = torch.ones(num_total_problems, 1, device=device, dtype=torch.int64)

    for i in range(num_groups):
        w_item = sorted_weight[:, i:i+1] # [LC, 1]

        # Mask full packs by setting their current weight to infinity
        is_full = (pack_counts >= groups_per_pack)
        candidates = pack_weights.clone()
        candidates[is_full] = float('inf')

        # Choose pack with min weight
        chosen_pack = candidates.argmin(dim=1, keepdim=True)

        # Record decision
        sorted_pack_index[:, i:i+1] = chosen_pack

        # Update state
        pack_weights.scatter_add_(1, chosen_pack, w_item)
        pack_counts.scatter_add_(1, chosen_pack, ones)

    # --- 3. Vectorized Local Search: Max-Any Swap ---
    # Convert linear assignment to structured [Batch, Pack, Group]
    # We sort the 'sorted_pack_index' to group items by pack
    _, pack_content_sort_idx = sorted_pack_index.sort(dim=1, stable=True)

    # pack_contents contains indices (0..N-1) referring to sorted_weight
    pack_contents = pack_content_sort_idx.view(num_total_problems, num_packs, groups_per_pack)

    K = groups_per_pack
    num_iters = 20

    for _ in range(num_iters):
        # 1. Recompute Weights & Identify Max Pack
        flat_contents = pack_contents.view(num_total_problems, -1)
        current_weights = torch.gather(sorted_weight, 1, flat_contents).view(num_total_problems, num_packs, K)

        pack_sums = current_weights.sum(dim=2) # [LC, M]
        val_max, idx_max_pack = pack_sums.max(dim=1) # [LC]

        # 2. Gather items
        # Max Pack Items: [LC, 1, K]
        gather_idx = idx_max_pack.view(-1, 1, 1).expand(-1, 1, K)
        w_max = torch.gather(current_weights, 1, gather_idx).squeeze(1) # [LC, K]

        # 3. Compute Swap Diffs against ALL packs
        # w_max: [LC, 1, K, 1]
        # current_weights: [LC, M, 1, K]
        # diffs: [LC, M, K, K] -> diff[b, m, i, j] = w_max[i] - w_pack_m[j]
        diffs = w_max.view(num_total_problems, 1, K, 1) - current_weights.view(num_total_problems, num_packs, 1, K)

        # 4. Compute Improvement
        # New Max Pack Load = val_max - diff
        # New Other Pack Load = pack_sums[other] + diff
        # Objective = max(New Max Pack Load, New Other Pack Load)

        val_max_exp = val_max.view(num_total_problems, 1, 1, 1)
        pack_sums_exp = pack_sums.view(num_total_problems, num_packs, 1, 1)

        new_pair_max = torch.max(val_max_exp - diffs, pack_sums_exp + diffs)
        improvement = val_max_exp - new_pair_max

        # 5. Masking
        # Mask self-swaps (swapping with same pack)
        mask_self = (torch.arange(num_packs, device=device).view(1, -1) == idx_max_pack.view(-1, 1))
        mask_self = mask_self.view(num_total_problems, num_packs, 1, 1)

        # Validity: Must reduce weight of max pack (diff > 0) AND reduce global max (improvement > 0)
        valid_mask = (diffs > 0) & (improvement > 1e-6) & (~mask_self)

        scores = torch.where(valid_mask, improvement, torch.tensor(float('-inf'), device=device))

        # 6. Select Best Swap
        flat_scores = scores.view(num_total_problems, -1)
        best_imp, flat_idx = flat_scores.max(dim=1)

        if not (best_imp > float('-inf')).any():
            break

        # 7. Execute Swaps
        valid_layers = torch.nonzero(best_imp > float('-inf')).squeeze(1)

        if len(valid_layers) == 0:
            break

        f_idx = flat_idx[valid_layers]

        # Decode flattened index: M * K * K
        K2 = K * K
        p_other = f_idx // K2
        rem = f_idx % K2
        idx_in_max = rem // K
        idx_in_other = rem % K

        p_max = idx_max_pack[valid_layers]

        # Swap indices in pack_contents
        val_max_item = pack_contents[valid_layers, p_max, idx_in_max].clone()
        val_other_item = pack_contents[valid_layers, p_other, idx_in_other].clone()

        pack_contents[valid_layers, p_max, idx_in_max] = val_other_item
        pack_contents[valid_layers, p_other, idx_in_other] = val_max_item

    # --- 4. Select Best Candidate ---
    flat_contents = pack_contents.view(num_total_problems, -1)
    final_weights = torch.gather(sorted_weight, 1, flat_contents).view(num_total_problems, num_packs, groups_per_pack)
    final_max_loads = final_weights.sum(dim=2).max(dim=1).values # [LC]

    # Reshape: [L, C] -> min over candidates
    reshaped_max_loads = final_max_loads.view(num_layers, num_candidates)
    best_candidate_idx = reshaped_max_loads.argmin(dim=1) # [L]

    # Gather best result
    # For repeat_interleave: index = layer * C + cand_idx
    best_indices = torch.arange(num_layers, device=device) * num_candidates + best_candidate_idx

    best_contents = pack_contents[best_indices]
    best_sorted_indices = sorted_indices[best_indices]

    # Map back
    flat_best_contents = best_contents.view(num_layers, -1)
    original_item_indices = torch.gather(best_sorted_indices, 1, flat_best_contents)

    pack_ids = torch.arange(num_packs, device=device).view(1, num_packs, 1).expand(num_layers, -1, groups_per_pack).reshape(num_layers, -1)
    rank_ids = torch.arange(groups_per_pack, device=device).view(1, 1, groups_per_pack).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    pack_index = torch.empty_like(pack_ids)
    rank_in_pack = torch.empty_like(rank_ids)

    pack_index.scatter_(1, original_item_indices, pack_ids)
    rank_in_pack.scatter_(1, original_item_indices, rank_ids)

    return pack_index, rank_in_pack
>>>>>>> REPLACE
</DIFF>