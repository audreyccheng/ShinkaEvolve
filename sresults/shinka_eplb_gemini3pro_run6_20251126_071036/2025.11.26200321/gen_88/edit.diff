--- a/original.py
+++ b/original.py
@@ -1,501 +1,527 @@
 # EVOLVE-BLOCK-START
 """
 Expert parallelism load balancer (EPLB) for vLLM.
 
 This module implements the core rearrangement algorithm using a 
-Massive Parallel Ensemble strategy with Targeted Max-Reduction Refinement.
+Two-Stage Evolutionary Strategy with Massive Parallelism and Targeted Refinement.
 """
 
 import torch
 
 
 def _refine_packing_max_reduction(weights: torch.Tensor,
                                   pack_ids: torch.Tensor,
                                   pack_loads: torch.Tensor,
                                   ranks: torch.Tensor,
                                   num_packs: int,
                                   num_iters: int = 20) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
-    Refines packing by attempting to move items from the heaviest pack to ANY
-    other pack to strictly reduce the maximum load.
-    
-    This overcomes the limitation of only swapping with the lightest pack.
+    Refines packing by attempting pairwise swaps between the heaviest pack and 
+    any other pack to strictly reduce the maximum load.
+    Vectorized over batches.
     """
     batch_size, num_items = weights.shape
     device = weights.device
     
     # Precompute pairwise weight differences: [B, N, N]
     # w_diff[b, i, j] = w[b, i] - w[b, j]
-    # This takes ~128MB for B=512, N=256, which fits easily on GPU.
     w_diff = weights.unsqueeze(2) - weights.unsqueeze(1)
     
     batch_range = torch.arange(batch_size, device=device)
 
     for _ in range(num_iters):
         # Identify Max Pack
         max_vals, max_indices = pack_loads.max(dim=1) # [B]
         
-        # Track best swap per batch
+        # State to track best swap
         # best_gain stores the reduction in Max Load
-        best_gain = torch.zeros_like(max_vals) - 1.0
-        
-        # Store: [flat_idx_of_swap, target_pack_index]
+        best_gain = torch.full((batch_size,), -1.0, device=device, dtype=weights.dtype)
         best_flat_idx = torch.zeros(batch_size, dtype=torch.long, device=device)
-        best_target_p = torch.zeros(batch_size, dtype=torch.long, device=device)
-        
-        # Mask for items currently in the Max Pack [B, N]
+        best_target_p = torch.full((batch_size,), -1, dtype=torch.long, device=device)
+        
+        # Mask for items in Max Pack [B, N]
         mask_max = (pack_ids == max_indices.unsqueeze(1))
         
-        # Iterate over all possible target packs
-        # Since M (num_packs) is typically small (4-16), this loop is fast.
+        # Try all target packs
         for p in range(num_packs):
+            # Optim: Filter batches where max_pack == p (cannot swap with self)
+            
             # Mask Target Pack [B, N]
             mask_target = (pack_ids == p)
             
-            # Filter batches where Target == Max (cannot swap with self)
             # valid_batch [B]
-            valid_batch_mask = (max_indices != p)
-            
-            # If no batch can swap to p, skip
-            if not valid_batch_mask.any():
+            valid_batch = (max_indices != p)
+            if not valid_batch.any():
                 continue
-                
-            # Current Load of target pack [B]
+            
             target_vals = pack_loads[:, p]
             
-            # Calculate Gain
-            # We want to swap i (Max) with j (Target)
-            # New Max = Max - (w_i - w_j)
-            # New Target = Target + (w_i - w_j)
-            # Condition 1: New Max < Old Max  =>  w_i - w_j > 0
-            # Condition 2: New Target < Old Max => Target + (w_i - w_j) < Max
-            # Improvement = Old Max - max(New Max, New Target)
-            #             = Old Max - max(Max - delta, Target + delta)
-            #             = min(delta, (Max - Target) - delta)
-            
+            # Load Diff: Max - Target
             load_diff = max_vals - target_vals
             
-            # Diff tensor [B, N, N] using precomputed w_diff
+            # We want to swap i (Max) <-> j (Target)
+            # Delta = w_i - w_j
+            # Gain = min(Delta, LoadDiff - Delta)
+            
+            # Use precomputed w_diff
             delta = w_diff
             
-            # Validity Mask: i in Max, j in Target
+            # Valid Swap: i in Max, j in Target
             # [B, N, N]
             valid_swap = mask_max.unsqueeze(2) & mask_target.unsqueeze(1)
-            
-            # Combine with batch validity
-            valid_swap = valid_swap & valid_batch_mask.view(-1, 1, 1)
-            
-            # Calculate potential gain
-            # improvement = min(delta, load_diff - delta)
-            # We use broadcasting for load_diff
+            valid_swap = valid_swap & valid_batch.view(-1, 1, 1)
+            
+            # Gain calculation
             gap = load_diff.view(-1, 1, 1)
             gain = torch.min(delta, gap - delta)
             
-            # Filter invalid gains
-            # We require positive improvement
+            # Threshold: Must reduce max load by at least epsilon
+            # Also implies Delta > 0 (since gain <= delta)
             valid_swap = valid_swap & (gain > 1e-5)
             
-            # Mask invalid entries with -1
+            # Mask invalid entries
             gain = torch.where(valid_swap, gain, torch.tensor(-1.0, device=device, dtype=weights.dtype))
             
-            # Find best swap for this target pack p across all batches
-            # Flatten N*N dims -> [B, N*N]
+            # Max gain for this target pack p
             flat_gain = gain.view(batch_size, -1)
             p_max_gain, p_max_idx = flat_gain.max(dim=1)
             
-            # Update global best if this pack offers a better swap
-            improve_mask = p_max_gain > best_gain
-            
-            if improve_mask.any():
-                best_gain = torch.where(improve_mask, p_max_gain, best_gain)
-                best_flat_idx = torch.where(improve_mask, p_max_idx, best_flat_idx)
-                best_target_p = torch.where(improve_mask, torch.tensor(p, device=device), best_target_p)
+            # Update best found so far
+            improve = (p_max_gain > best_gain)
+            
+            if improve.any():
+                best_gain = torch.where(improve, p_max_gain, best_gain)
+                best_flat_idx = torch.where(improve, p_max_idx, best_flat_idx)
+                best_target_p = torch.where(improve, torch.tensor(p, device=device), best_target_p)
                 
-        # Apply the best swap found across all packs
+        # Apply best swaps found
         active = best_gain > 1e-5
         if not active.any():
             break
             
-        # Gather indices
         active_batch = batch_range[active]
         active_flat = best_flat_idx[active]
+        
         p_target = best_target_p[active]
         p_max = max_indices[active]
         
         i_idx = active_flat // num_items
         j_idx = active_flat % num_items
         
-        # Execute Swap
         w_i = weights[active_batch, i_idx]
         w_j = weights[active_batch, j_idx]
         delta_val = w_i - w_j
         
-        # Update Loads
+        # Update loads
         pack_loads[active_batch, p_max] -= delta_val
         pack_loads[active_batch, p_target] += delta_val
         
         # Update IDs
         pack_ids[active_batch, i_idx] = p_target
         pack_ids[active_batch, j_idx] = p_max
         
-        # Update Ranks (swap to maintain set validity)
+        # Update Ranks
         r_i = ranks[active_batch, i_idx]
         r_j = ranks[active_batch, j_idx]
         ranks[active_batch, i_idx] = r_j
         ranks[active_batch, j_idx] = r_i
         
     return pack_ids, ranks, pack_loads
 
 
 def balanced_packing(weight: torch.Tensor,
                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
     """
-    Pack n weighted objects to m packs using a Massive Parallel Ensemble strategy.
-    
-    Generates 256 candidates, selects the top 16 based on imbalance, and
-    refines them using targeted max-load reduction.
+    Pack n weighted objects to m packs using a Two-Stage Evolutionary Strategy.
     """
     num_layers, num_items = weight.shape
     device = weight.device
     
-    # 1. Configuration
-    num_candidates = 256
-    num_refine = 16 # Top-K to refine
+    # --- PHASE 1: Diverse Candidates ---
+    num_candidates = 128
+    num_refine_k = 8
     capacity = num_items // num_packs
     
-    # 2. Candidate Generation
     # A. LPT
     lpt_val, lpt_idx = weight.sort(dim=-1, descending=True)
     c_lpt = lpt_idx.unsqueeze(1)
     
     # B. ZigZag
     zigzag_perm = torch.empty(num_items, device=device, dtype=torch.long)
     half = (num_items + 1) // 2
     arange = torch.arange(num_items, device=device)
     zigzag_perm[0::2] = arange[:half]
     zigzag_perm[1::2] = arange[half:].flip(0)
     c_zigzag = lpt_idx.gather(1, zigzag_perm.unsqueeze(0).expand(num_layers, -1)).unsqueeze(1)
     
-    # C. Random Shuffles (128 candidates)
-    # Using random permutations to explore un-greedy basins
-    num_random = 128
+    # C. Random Shuffles
+    num_random = 32
     rand_perm = torch.rand(num_layers, num_random, num_items, device=device).argsort(dim=-1)
     
-    # D. Noisy LPT (Remaining 126 candidates)
+    # D. Noisy LPT
     num_noisy = num_candidates - 2 - num_random
-    # Vary noise levels for diversity: Half low noise, half high noise
-    noise_low = torch.rand(num_layers, num_noisy // 2, num_items, device=device) * 0.2 + 0.9
-    noise_high = torch.rand(num_layers, num_noisy - (num_noisy // 2), num_items, device=device) * 0.6 + 0.7
-    noise = torch.cat([noise_low, noise_high], dim=1)
-    
+    noise = torch.rand(num_layers, num_noisy, num_items, device=device) * 0.4 + 0.8
     noisy_w = weight.unsqueeze(1) * noise
     _, c_noisy = noisy_w.sort(dim=-1, descending=True)
     
     # Combine
     all_indices = torch.cat([c_lpt, c_zigzag, rand_perm, c_noisy], dim=1)
     
     # Gather weights
+    # [L, C, N]
     expanded_weight = weight.unsqueeze(1).expand(-1, num_candidates, -1)
     ordered_weights = expanded_weight.gather(2, all_indices)
     
-    # Flatten for vectorized kernel
+    # Flatten
     batch_size = num_layers * num_candidates
     flat_weights = ordered_weights.view(batch_size, num_items)
     
-    # 3. Vectorized Greedy Packing
+    # Greedy Packing
+    # Inline basic greedy to save function call overhead and memory allocs
     pack_loads = torch.zeros(batch_size, num_packs, device=device, dtype=weight.dtype)
     pack_counts = torch.zeros(batch_size, num_packs, device=device, dtype=torch.int64)
     flat_ids = torch.empty(batch_size, num_items, device=device, dtype=torch.int64)
     flat_ranks = torch.empty(batch_size, num_items, device=device, dtype=torch.int64)
     
     batch_range = torch.arange(batch_size, device=device)
     inf = torch.tensor(float('inf'), device=device, dtype=weight.dtype)
     
     for i in range(num_items):
         w = flat_weights[:, i]
-        # Mask full packs
         valid_mask = pack_counts < capacity
         temp_loads = torch.where(valid_mask, pack_loads, inf)
         chosen_packs = temp_loads.argmin(dim=1)
         
         flat_ids[:, i] = chosen_packs
         flat_ranks[:, i] = pack_counts[batch_range, chosen_packs]
         
         pack_loads[batch_range, chosen_packs] += w
         pack_counts[batch_range, chosen_packs] += 1
         
-    # 4. Top-K Selection
+    # Top-K Selection
     loads = pack_loads.view(num_layers, num_candidates, num_packs)
     imbalance = loads.max(dim=-1).values - loads.min(dim=-1).values
     
-    # Select Top-K smallest imbalance
-    _, best_k_indices = imbalance.topk(num_refine, dim=1, largest=False) # [L, K]
-    
-    # Extract data for Top-K
+    _, best_k_indices = imbalance.topk(num_refine_k, dim=1, largest=False)
+    
+    # Extract Top-K
     layer_offsets = (torch.arange(num_layers, device=device) * num_candidates).unsqueeze(1)
     flat_selected_indices = (layer_offsets + best_k_indices).flatten()
     
     refined_weights = flat_weights[flat_selected_indices]
     refined_ids = flat_ids[flat_selected_indices]
     refined_ranks = flat_ranks[flat_selected_indices]
     refined_loads = pack_loads[flat_selected_indices]
     
-    # 5. Targeted Max-Reduction Refinement
+    # Refine Top-K
     refined_ids, refined_ranks, refined_loads = _refine_packing_max_reduction(
-        refined_weights, refined_ids, refined_loads, refined_ranks, num_packs, num_iters=20
+        refined_weights, refined_ids, refined_loads, refined_ranks, num_packs, num_iters=10
     )
     
-    # 6. Final Selection
-    loads_final = refined_loads.view(num_layers, num_refine, num_packs)
-    imbalance_final = loads_final.max(dim=-1).values - loads_final.min(dim=-1).values
-    best_in_k = imbalance_final.argmin(dim=1) # [L]
-    
-    # 7. Scatter Back
-    # Get the original permutation index
-    # best_k_indices [L, K] -> select best [L]
-    winner_cand_idx = best_k_indices.gather(1, best_in_k.unsqueeze(1)).squeeze(1) # [L]
-    
-    # Get the final IDs/Ranks
-    # refined_ids [L*K, N] -> select best
-    # Index in refined_ids = layer * K + best_in_k
-    winner_flat_idx = (torch.arange(num_layers, device=device) * num_refine) + best_in_k
-    final_aligned_ids = refined_ids[winner_flat_idx] # [L, N]
-    final_aligned_ranks = refined_ranks[winner_flat_idx]
-    
-    # Get the sorted indices corresponding to the winner candidate
-    idx_view = winner_cand_idx.view(num_layers, 1, 1).expand(-1, 1, num_items)
-    final_sorted_idx = all_indices.gather(1, idx_view).squeeze(1)
+    # Select Phase 1 Winner
+    loads_p1 = refined_loads.view(num_layers, num_refine_k, num_packs)
+    imbalance_p1 = loads_p1.max(dim=-1).values - loads_p1.min(dim=-1).values
+    best_p1_idx = imbalance_p1.argmin(dim=1) # [L]
+    
+    # --- PHASE 2: Evolutionary Mutation ---
+    # Extract winner data
+    winner_flat_idx = (torch.arange(num_layers, device=device) * num_refine_k) + best_p1_idx
+    
+    # [L, N]
+    winner_weights = refined_weights[winner_flat_idx]
+    winner_ids = refined_ids[winner_flat_idx]
+    winner_ranks = refined_ranks[winner_flat_idx]
+    winner_loads = refined_loads[winner_flat_idx]
+    
+    # Clones
+    num_mutants = 32
+    # [L*num_mutants, N]
+    mutant_weights = winner_weights.repeat_interleave(num_mutants, dim=0)
+    mutant_ids = winner_ids.repeat_interleave(num_mutants, dim=0)
+    mutant_ranks = winner_ranks.repeat_interleave(num_mutants, dim=0)
+    # Load needs recalculation after swap, or just copy and update?
+    # Update is hard with random swaps, easier to recalc or just update. 
+    # But since we swap, loads change.
+    
+    # Apply Mutation: Random Swaps
+    # Swap 2 random pairs per mutant
+    m_batch_size = num_layers * num_mutants
+    num_swaps = 2
+    
+    for _ in range(num_swaps):
+        idx1 = torch.randint(0, num_items, (m_batch_size,), device=device)
+        idx2 = torch.randint(0, num_items, (m_batch_size,), device=device)
+        
+        # Swapping items means swapping their pack assignment and rank
+        p1 = mutant_ids.gather(1, idx1.unsqueeze(1))
+        p2 = mutant_ids.gather(1, idx2.unsqueeze(1))
+        r1 = mutant_ranks.gather(1, idx1.unsqueeze(1))
+        r2 = mutant_ranks.gather(1, idx2.unsqueeze(1))
+        
+        mutant_ids.scatter_(1, idx1.unsqueeze(1), p2)
+        mutant_ids.scatter_(1, idx2.unsqueeze(1), p1)
+        mutant_ranks.scatter_(1, idx1.unsqueeze(1), r2)
+        mutant_ranks.scatter_(1, idx2.unsqueeze(1), r1)
+        
+    # Recalculate loads for mutants
+    mutant_loads = torch.zeros(m_batch_size, num_packs, device=device, dtype=weight.dtype)
+    mutant_loads.scatter_add_(1, mutant_ids, mutant_weights)
+    
+    # Refine Mutants
+    # Run refinement for more iters as this is the final polishing
+    mutant_ids, mutant_ranks, mutant_loads = _refine_packing_max_reduction(
+        mutant_weights, mutant_ids, mutant_loads, mutant_ranks, num_packs, num_iters=15
+    )
+    
+    # Final Selection
+    loads_p2 = mutant_loads.view(num_layers, num_mutants, num_packs)
+    imbalance_p2 = loads_p2.max(dim=-1).values - loads_p2.min(dim=-1).values
+    
+    best_p2_idx = imbalance_p2.argmin(dim=1) # [L]
+    
+    # Gather Final Result
+    final_flat_idx = (torch.arange(num_layers, device=device) * num_mutants) + best_p2_idx
+    
+    final_ids = mutant_ids[final_flat_idx]
+    final_ranks = mutant_ranks[final_flat_idx]
+    
+    # Scatter Back
+    # We need the original sorted indices for the Phase 1 winner.
+    winner_cand_orig_idx = best_k_indices.gather(1, best_p1_idx.unsqueeze(1)).squeeze(1) # [L]
+    idx_view = winner_cand_orig_idx.view(num_layers, 1, 1).expand(-1, 1, num_items)
+    final_perm = all_indices.gather(1, idx_view).squeeze(1)
     
     pack_index = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)
     rank_in_pack = torch.empty(num_layers, num_items, device=device, dtype=torch.int64)
     
-    pack_index.scatter_(1, final_sorted_idx, final_aligned_ids)
-    rank_in_pack.scatter_(1, final_sorted_idx, final_aligned_ranks)
+    pack_index.scatter_(1, final_perm, final_ids)
+    rank_in_pack.scatter_(1, final_perm, final_ranks)
     
     return pack_index, rank_in_pack
 
 
 def replicate_experts(
         weight: torch.Tensor,
         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
     Replicate experts using Binary Search on Max Load followed by Greedy Refinement.
     """
     num_layers, num_log = weight.shape
     device = weight.device
 
     if num_phy == num_log:
         phy2log = torch.arange(num_log, device=device).expand(num_layers, -1)
         rank = torch.zeros(num_layers, num_phy, dtype=torch.int64, device=device)
         logcnt = torch.ones(num_layers, num_log, dtype=torch.int64, device=device)
         return phy2log, rank, logcnt
 
     # Binary Search
     low = weight.sum(dim=-1, keepdim=True) / num_phy
     high = weight.max(dim=-1, keepdim=True).values
     low = torch.max(low, torch.tensor(1e-6, device=device))
 
     for _ in range(15):
         mid = (low + high) * 0.5
         counts = torch.ceil(weight / mid)
         total = counts.sum(dim=-1, keepdim=True)
         mask = total <= num_phy
         high = torch.where(mask, mid, high)
         low = torch.where(mask, low, mid)
 
     logcnt = torch.ceil(weight / high).long().clamp(min=1)
 
     # Correct sum
     current_sum = logcnt.sum(dim=-1)
     diff = num_phy - current_sum
 
     # Under-allocation
     max_diff = int(diff.max().item())
     if max_diff > 0:
         rows = torch.arange(num_layers, device=device)
         for _ in range(max_diff):
             active = current_sum < num_phy
             if not active.any(): break
             
             density = weight / logcnt.float()
             density[~active] = -1.0
             target_idx = density.argmax(dim=-1)
             
             active_rows = rows[active]
             active_targets = target_idx[active]
             
             logcnt.index_put_((active_rows, active_targets), 
                               torch.tensor(1, device=device, dtype=torch.int64), 
                               accumulate=True)
             current_sum[active] += 1
 
     # Over-allocation
     min_diff = int(diff.min().item())
     if min_diff < 0:
         rows = torch.arange(num_layers, device=device)
         for _ in range(abs(min_diff)):
             active = current_sum > num_phy
             if not active.any(): break
             
             valid = logcnt > 1
             cost = weight / (logcnt - 1).float()
             cost[~valid] = float('inf')
             cost[~active] = float('inf')
             
             target_idx = cost.argmin(dim=-1)
             
             active_rows = rows[active]
             active_targets = target_idx[active]
             
             logcnt.index_put_((active_rows, active_targets), 
                               torch.tensor(-1, device=device, dtype=torch.int64), 
                               accumulate=True)
             current_sum[active] -= 1
 
     # Construct maps
     flat_log_ids = torch.arange(num_log, device=device).repeat(num_layers)
     flat_counts = logcnt.flatten()
     flat_phy2log = torch.repeat_interleave(flat_log_ids, flat_counts)
     
     target_size = num_layers * num_phy
     if flat_phy2log.numel() != target_size:
         if flat_phy2log.numel() < target_size:
             flat_phy2log = torch.cat([flat_phy2log, torch.zeros(target_size - flat_phy2log.numel(), device=device, dtype=torch.long)])
         else:
             flat_phy2log = flat_phy2log[:target_size]
             
     phy2log = flat_phy2log.view(num_layers, num_phy)
     
     offsets = torch.zeros_like(logcnt)
     offsets[:, 1:] = logcnt[:, :-1].cumsum(dim=1)
     mapped_offsets = offsets.gather(1, phy2log)
     phy_indices = torch.arange(num_phy, device=device).expand(num_layers, -1)
     rank = phy_indices - mapped_offsets
 
     return phy2log, rank, logcnt
 
 
 def rebalance_experts_hierarchical(
     weight: torch.Tensor,
     num_physical_experts: int,
     num_groups: int,
     num_nodes: int,
     num_gpus: int,
 ):
     """
     Hierarchical rebalancing.
     """
     num_layers, num_logical_experts = weight.shape
     group_size = num_logical_experts // num_groups
     groups_per_node = num_groups // num_nodes
     phy_experts_per_gpu = num_physical_experts // num_gpus
 
     def inverse(perm: torch.Tensor) -> torch.Tensor:
         inv = torch.empty_like(perm)
         inv.scatter_(
             1,
             perm,
             torch.arange(perm.size(1), dtype=torch.int64,
                          device=perm.device).expand(perm.shape),
         )
         return inv
 
     # 1. Groups -> Nodes
     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)
     group_pack_index, group_rank_in_pack = balanced_packing(
         tokens_per_group, num_nodes)
         
     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *
                  group_size).unsqueeze(-1) +
                 torch.arange(group_size,
                              dtype=torch.int64,
                              device=group_pack_index.device)).flatten(-2)
     mlog2log = inverse(log2mlog)
 
     # 2. Replicate within nodes
     tokens_per_mlog = weight.gather(-1, mlog2log).view(
         -1, num_logical_experts // num_nodes)
     phy2mlog, phyrank, mlogcnt = replicate_experts(
         tokens_per_mlog, num_physical_experts // num_nodes)
 
     # 3. Physical -> GPUs
     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)
     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,
                                                 num_gpus // num_nodes)
     
     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack
     pphy2phy = inverse(phy2pphy)
 
     pphy2mlog = phy2mlog.gather(-1, pphy2phy)
     
     node_offsets = torch.arange(
         0,
         num_logical_experts,
         num_logical_experts // num_nodes,
         device=weight.device,
     ).view(1, -1, 1)
     
     pphy2mlog_restored = (pphy2mlog.view(num_layers, num_nodes, -1) + node_offsets).flatten(-2)
     
     pphy2log = mlog2log.gather(-1, pphy2mlog_restored)
     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)
     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)
     
     return pphy2log, pphyrank, logcnt
 
 
 def rebalance_experts(
     weight: torch.Tensor,
     num_replicas: int,
     num_groups: int,
     num_nodes: int,
     num_gpus: int,
 ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
     Entry point.
     """
     num_layers, num_logical_experts = weight.shape
     weight = weight.float().cpu()
     
     if num_groups % num_nodes == 0:
         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
             weight, num_replicas, num_groups, num_nodes, num_gpus)
     else:
         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
             weight, num_replicas, 1, 1, num_gpus)
             
     max_replicas = int(logcnt.max().item())
     
     log2phy = torch.full(
         (num_layers, num_logical_experts, max_replicas),
         -1,
         dtype=torch.int64,
         device=logcnt.device,
     )
     
     flat_layer_idx = torch.arange(num_layers, device=logcnt.device).unsqueeze(-1).expand(-1, num_replicas).flatten()
     flat_log_idx = phy2log.flatten()
     flat_rank_idx = phyrank.flatten()
     flat_phy_ids = torch.arange(num_replicas, dtype=torch.int64, device=logcnt.device).expand(num_layers, -1).flatten()
     
     indices = (flat_layer_idx * num_logical_experts * max_replicas) + \
               (flat_log_idx * max_replicas) + \
               flat_rank_idx
               
     log2phy.view(-1).scatter_(0, indices, flat_phy_ids)
     
     return phy2log, log2phy, logcnt
+
 # EVOLVE-BLOCK-END
 
 
 # This part remains fixed (not evolved)
 def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,
              num_nodes: int, num_gpus: int):
     """Run the expert parallelism load balancer"""
     phy2log, log2phy, logcnt = rebalance_experts(
         weight, num_replicas, num_groups, num_nodes, num_gpus
     )
     return phy2log, log2phy, logcnt
 
 
 __all__ = ["rebalance_experts", "run_eplb"]