<NAME>
randomized_restarts_packing
</NAME>

<DESCRIPTION>
Introduces a randomized greedy strategy with multiple restarts to `balanced_packing`. The standard LPT packing is susceptible to local optima. By running the packing algorithm multiple times with perturbed weights (Randomized LPT) and keeping the configuration that minimizes the maximum load, we can achieve better load balancing. The refinement phase (local search) is preserved and applied to each restart candidate.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)

    # Use CPU weights for faster scalar access
    weight_cpu = weight.cpu()

    for i in range(num_layers):
        pack_weights = [0.0] * num_packs
        pack_contents = [[] for _ in range(num_packs)]

        # Initial Greedy Packing (Modified LPT)
        for group in indices[i]:
            # Find valid packs (not full)
            valid_packs = (p for p in range(num_packs)
                           if len(pack_contents[p]) < groups_per_pack)
            # Select pack with minimum weight
            pack = min(valid_packs, key=pack_weights.__getitem__)

            g_idx = group.item()
            w = weight_cpu[i, g_idx].item()

            pack_index[i, g_idx] = pack
            pack_weights[pack] += w
            pack_contents[pack].append(g_idx)

        # Refinement: Local Search (Swap)
        # Try to swap items between heaviest pack and any other pack to reduce variance
        for _ in range(20):
            max_pack = max(range(num_packs), key=pack_weights.__getitem__)
            max_w = pack_weights[max_pack]

            best_swap = None
            best_gain = 0.0

            u_indices = pack_contents[max_pack]
            w_u = weight_cpu[i, u_indices]

            for p in range(num_packs):
                if p == max_pack:
                    continue

                diff = max_w - pack_weights[p]
                if diff < 1e-6:
                    continue

                v_indices = pack_contents[p]
                w_v = weight_cpu[i, v_indices]

                # Matrix of potential deltas: shape [len(u), len(v)]
                # delta = w_u - w_v. We want 0 < delta < diff to reduce max_pack and increase p without overshooting
                deltas = w_u.unsqueeze(1) - w_v.unsqueeze(0)

                # gain = delta * (diff - delta) is maximized when delta is close to diff/2
                # This corresponds to minimizing the sum of squares of the two packs
                mask = (deltas > 1e-6) & (deltas < diff)

                if not mask.any():
                    continue

                gains = deltas * (diff - deltas)
                gains = torch.where(mask, gains, torch.tensor(-1.0, device=gains.device))

                max_gain, max_idx = gains.flatten().max(0)

                if max_gain > best_gain:
                    best_gain = max_gain.item()
                    flat_idx = max_idx.item()
                    idx_u = flat_idx // len(v_indices)
                    idx_v = flat_idx % len(v_indices)
                    best_swap = (max_pack, p, u_indices[idx_u], v_indices[idx_v], deltas.flatten()[flat_idx].item())

            if best_swap:
                p_src, p_dst, u, v, delta = best_swap

                pack_contents[p_src].remove(u)
                pack_contents[p_src].append(v)
                pack_contents[p_dst].remove(v)
                pack_contents[p_dst].append(u)

                pack_weights[p_src] -= delta
                pack_weights[p_dst] += delta
                pack_index[i, u] = p_dst
                pack_index[i, v] = p_src
            else:
                break

        # Assign ranks
        for p in range(num_packs):
            for rank, g_idx in enumerate(pack_contents[p]):
                rank_in_pack[i, g_idx] = rank

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    device = weight.device
    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Use CPU weights
    weight_cpu = weight.cpu()

    # Outputs on CPU to avoid device synchronization during fill
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)

    # Number of restarts for the randomized heuristic
    NUM_RESTARTS = 10

    for i in range(num_layers):
        layer_w = weight_cpu[i]

        best_max_load = float('inf')
        best_assignment = None

        for attempt in range(NUM_RESTARTS):
            # 1. Candidate Generation
            if attempt == 0:
                # Deterministic LPT
                indices = layer_w.argsort(descending=True).tolist()
            else:
                # Randomized LPT (Perturbed weights)
                noise = torch.rand(num_groups) * 0.2 + 0.9 # 0.9 to 1.1
                indices = (layer_w * noise).argsort(descending=True).tolist()

            # 2. Greedy Construction
            packs = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs

            for g_idx in indices:
                w = layer_w[g_idx].item()
                # Best fit among non-full packs (min current load)
                best_p = -1
                min_w = float('inf')
                for p in range(num_packs):
                    if len(packs[p]) < groups_per_pack:
                        if pack_weights[p] < min_w:
                            min_w = pack_weights[p]
                            best_p = p

                packs[best_p].append(g_idx)
                pack_weights[best_p] += w

            # 3. Refinement (Local Search)
            for _ in range(20):
                # Identify max load pack
                max_p = -1
                max_w = -1.0
                for p in range(num_packs):
                    if pack_weights[p] > max_w:
                        max_w = pack_weights[p]
                        max_p = p

                best_swap = None
                best_gain = 0.0

                # Tensorize items in max pack for fast vectorized comp
                u_nodes = packs[max_p]
                w_u = layer_w[u_nodes]

                for p in range(num_packs):
                    if p == max_p:
                        continue

                    diff = max_w - pack_weights[p]
                    if diff < 1e-6:
                        continue

                    v_nodes = packs[p]
                    w_v = layer_w[v_nodes]

                    # Deltas matrix: w_u[i] - w_v[j]
                    deltas = w_u.unsqueeze(1) - w_v.unsqueeze(0)

                    # Valid swaps: 0 < delta < diff
                    mask = (deltas > 1e-6) & (deltas < diff)
                    if not mask.any():
                        continue

                    # Gain metric: maximize delta * (diff - delta)
                    gains = deltas * (diff - deltas)
                    gains = torch.where(mask, gains, -1.0)

                    curr_max_gain, curr_idx = gains.flatten().max(0)
                    curr_max_gain = curr_max_gain.item()

                    if curr_max_gain > best_gain:
                        best_gain = curr_max_gain
                        idx = curr_idx.item()
                        u_idx = idx // len(v_nodes)
                        v_idx = idx % len(v_nodes)
                        best_swap = (max_p, p, u_idx, v_idx, deltas.flatten()[idx].item())

                if best_swap:
                    p1, p2, u_i, v_i, delta = best_swap
                    # Execute swap
                    val_u = packs[p1][u_i]
                    val_v = packs[p2][v_i]
                    packs[p1][u_i] = val_v
                    packs[p2][v_i] = val_u

                    pack_weights[p1] -= delta
                    pack_weights[p2] += delta
                else:
                    break

            # 4. Evaluation
            current_max = max(pack_weights)
            if current_max < best_max_load - 1e-6:
                best_max_load = current_max
                best_assignment = [list(p) for p in packs]

        # 5. Final assignment for this layer
        for p, nodes in enumerate(best_assignment):
            for r, g_idx in enumerate(nodes):
                pack_index[i, g_idx] = p
                rank_in_pack[i, g_idx] = r

    return pack_index.to(device), rank_in_pack.to(device)
>>>>>>> REPLACE
</DIFF>