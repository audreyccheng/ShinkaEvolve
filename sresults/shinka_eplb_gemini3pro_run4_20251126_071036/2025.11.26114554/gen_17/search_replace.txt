<NAME>
randomized_greedy_with_restarts
</NAME>

<DESCRIPTION>
Replaces the deterministic greedy packing algorithm with a randomized greedy approach using multiple restarts.
For each layer, the algorithm runs 20 iterations (restarts). In the first iteration, it uses the standard LPT (Longest Processing Time) sorting. In subsequent iterations, it perturbs the weights with random noise before sorting to explore different packing configurations.
A fast local search refinement step (swapping items between the heaviest pack and others) is applied to each candidate solution.
The algorithm returns the packing configuration that yields the minimum maximum load across all packs, improving load balancing capabilities at the cost of slightly increased compute (which is acceptable given the high speed score).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)

    # Use CPU weights for faster scalar access
    weight_cpu = weight.cpu()

    for i in range(num_layers):
        pack_weights = [0.0] * num_packs
        pack_contents = [[] for _ in range(num_packs)]

        # Initial Greedy Packing (Modified LPT)
        for group in indices[i]:
            # Find valid packs (not full)
            valid_packs = (p for p in range(num_packs)
                           if len(pack_contents[p]) < groups_per_pack)
            # Select pack with minimum weight
            pack = min(valid_packs, key=pack_weights.__getitem__)

            g_idx = group.item()
            w = weight_cpu[i, g_idx].item()

            pack_index[i, g_idx] = pack
            pack_weights[pack] += w
            pack_contents[pack].append(g_idx)

        # Refinement: Local Search (Swap)
        # Try to swap items between heaviest pack and any other pack to reduce variance
        for _ in range(20):
            max_pack = max(range(num_packs), key=pack_weights.__getitem__)
            max_w = pack_weights[max_pack]

            best_swap = None
            best_gain = 0.0

            u_indices = pack_contents[max_pack]
            w_u = weight_cpu[i, u_indices]

            for p in range(num_packs):
                if p == max_pack:
                    continue

                diff = max_w - pack_weights[p]
                if diff < 1e-6:
                    continue

                v_indices = pack_contents[p]
                w_v = weight_cpu[i, v_indices]

                # Matrix of potential deltas: shape [len(u), len(v)]
                # delta = w_u - w_v. We want 0 < delta < diff to reduce max_pack and increase p without overshooting
                deltas = w_u.unsqueeze(1) - w_v.unsqueeze(0)

                # gain = delta * (diff - delta) is maximized when delta is close to diff/2
                # This corresponds to minimizing the sum of squares of the two packs
                mask = (deltas > 1e-6) & (deltas < diff)

                if not mask.any():
                    continue

                gains = deltas * (diff - deltas)
                gains = torch.where(mask, gains, torch.tensor(-1.0, device=gains.device))

                max_gain, max_idx = gains.flatten().max(0)

                if max_gain > best_gain:
                    best_gain = max_gain.item()
                    flat_idx = max_idx.item()
                    idx_u = flat_idx // len(v_indices)
                    idx_v = flat_idx % len(v_indices)
                    best_swap = (max_pack, p, u_indices[idx_u], v_indices[idx_v], deltas.flatten()[flat_idx].item())

            if best_swap:
                p_src, p_dst, u, v, delta = best_swap

                pack_contents[p_src].remove(u)
                pack_contents[p_src].append(v)
                pack_contents[p_dst].remove(v)
                pack_contents[p_dst].append(u)

                pack_weights[p_src] -= delta
                pack_weights[p_dst] += delta
                pack_index[i, u] = p_dst
                pack_index[i, v] = p_src
            else:
                break

        # Assign ranks
        for p in range(num_packs):
            for rank, g_idx in enumerate(pack_contents[p]):
                rank_in_pack[i, g_idx] = rank

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs
    device = weight.device

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Operations on CPU are generally faster for this sequential/iterative logic
    weight_cpu = weight.cpu()

    # Pre-allocate output tensors
    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)
    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)

    # Number of restarts for randomized greedy
    NUM_RESTARTS = 20

    for i in range(num_layers):
        layer_weights = weight_cpu[i]

        # Base sort indices (LPT)
        base_indices = layer_weights.argsort(descending=True).tolist()

        best_assignment = None
        best_max_load = float('inf')

        for attempt in range(NUM_RESTARTS):
            # 1. Randomized Candidate Generation
            if attempt == 0:
                indices = base_indices
            else:
                # Add noise to weights to perturb sort order
                # 5% noise is usually sufficient to swap similar items
                noise = torch.rand(num_groups) * 0.05
                indices = (layer_weights * (1 + noise)).argsort(descending=True).tolist()

            # 2. Greedy Construction (LPT / Best Fit)
            # pack_contents: list of lists storing item indices
            pack_contents = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs
            pack_sizes = [0] * num_packs # optimization to avoid len()

            for idx in indices:
                w = layer_weights[idx].item()

                # Find lightest valid pack
                best_p = -1
                min_w = float('inf')

                for p in range(num_packs):
                    if pack_sizes[p] < groups_per_pack:
                        if pack_weights[p] < min_w:
                            min_w = pack_weights[p]
                            best_p = p

                pack_contents[best_p].append(idx)
                pack_weights[best_p] += w
                pack_sizes[best_p] += 1

            # 3. Refinement: Local Search (Swaps)
            # Iteratively improve the max load pack

            has_improvement = True
            step = 0
            while has_improvement and step < 20:
                has_improvement = False
                step += 1

                # Identify max pack
                max_p = -1
                max_w = -1.0
                for p in range(num_packs):
                    if pack_weights[p] > max_w:
                        max_w = pack_weights[p]
                        max_p = p

                # Find best swap involving max_pack
                best_swap = None
                best_reduction = 0.0

                u_nodes = pack_contents[max_p]

                for p in range(num_packs):
                    if p == max_p: continue

                    diff = max_w - pack_weights[p]
                    if diff < 1e-6: continue # p is heavier or equal (shouldn't happen if max is unique max)

                    v_nodes = pack_contents[p]

                    # Try swapping u (from max_p) and v (from p)
                    # We need w_u - w_v > 0 and w_u - w_v < diff
                    # Maximize min(delta, diff - delta)

                    for u_idx, u in enumerate(u_nodes):
                        w_u = layer_weights[u].item()
                        for v_idx, v in enumerate(v_nodes):
                            w_v = layer_weights[v].item()

                            delta = w_u - w_v
                            if 1e-6 < delta < diff:
                                reduction = min(delta, diff - delta)
                                if reduction > best_reduction:
                                    best_reduction = reduction
                                    best_swap = (p, u_idx, v_idx, delta)

                if best_swap:
                    target_p, u_idx, v_idx, delta = best_swap

                    # Execute swap
                    u = pack_contents[max_p][u_idx]
                    v = pack_contents[target_p][v_idx]

                    pack_contents[max_p][u_idx] = v
                    pack_contents[target_p][v_idx] = u

                    pack_weights[max_p] -= delta
                    pack_weights[target_p] += delta

                    has_improvement = True

            # 4. Check global best
            current_max = max(pack_weights)
            if current_max < best_max_load - 1e-6:
                best_max_load = current_max
                # Deep copy current packing
                best_assignment = [list(p) for p in pack_contents]

        # 5. Write best assignment to output tensors
        # Flatten for scatter
        flat_indices = []
        flat_packs = []
        flat_ranks = []

        for p, items in enumerate(best_assignment):
            for r, idx in enumerate(items):
                flat_indices.append(idx)
                flat_packs.append(p)
                flat_ranks.append(r)

        idx_tensor = torch.tensor(flat_indices, dtype=torch.int64, device=device)
        pack_tensor = torch.tensor(flat_packs, dtype=torch.int64, device=device)
        rank_tensor = torch.tensor(flat_ranks, dtype=torch.int64, device=device)

        pack_index[i].scatter_(0, idx_tensor, pack_tensor)
        rank_in_pack[i].scatter_(0, idx_tensor, rank_tensor)

    return pack_index, rank_in_pack
>>>>>>> REPLACE
</DIFF>