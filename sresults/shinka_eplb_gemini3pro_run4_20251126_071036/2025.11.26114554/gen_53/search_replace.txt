<NAME>
randomized_restarts_and_reshuffle
</NAME>

<DESCRIPTION>
Implements a more advanced balanced packing algorithm using:
1. Multiple restarts with randomized greedy initialization (LPT with noise) to explore different starting points.
2. An enhanced refinement phase that uses a "Reshuffle" heuristic: for a pair of packs, it pools all items and greedily re-partitions them. This can escape local optima that single-item swaps cannot.
3. Fallback to single-item swaps if reshuffle fails.
4. "Random walk" strategy in refinement: besides the heaviest/lightest pair, it tries to improve the heaviest/lightest packs by pairing them with random packs, facilitating multi-step weight transfers.
This aims to significantly improve load balancing (balancedness score) while maintaining high speed due to efficient CPU-based list operations.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
import torch


def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Optimization: Move weights to CPU and convert to list for faster access
    weight_cpu = weight.to("cpu", dtype=torch.float32)
    indices = weight_cpu.sort(-1, descending=True).indices.tolist()
    weight_list = weight_cpu.tolist()

    pack_index = torch.empty_like(weight, dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty_like(weight, dtype=torch.int64, device="cpu")

    for i in range(num_layers):
        row_weight = weight_list[i]
        current_packs = [[] for _ in range(num_packs)]
        pack_weights = [0.0] * num_packs

        # 1. Greedy packing
        for group in indices[i]:
            w = row_weight[group]
            best_pack = -1
            min_val = float('inf')
            for p in range(num_packs):
                if len(current_packs[p]) < groups_per_pack:
                    if pack_weights[p] < min_val:
                        min_val = pack_weights[p]
                        best_pack = p
            current_packs[best_pack].append(group)
            pack_weights[best_pack] += w

        # 2. Refinement: Pairwise swapping
        for _ in range(20):
            found_improvement = False
            # Sort packs by weight descending
            sorted_packs = sorted(range(num_packs),
                                  key=pack_weights.__getitem__,
                                  reverse=True)

            for i1 in range(num_packs):
                p1 = sorted_packs[i1]
                # Check against lighter packs
                for i2 in range(num_packs - 1, i1, -1):
                    p2 = sorted_packs[i2]

                    diff = pack_weights[p1] - pack_weights[p2]
                    if diff < 1e-6: break

                    target = diff / 2.0
                    best_swap = None
                    best_gap = diff

                    # Try to swap item u from heavier pack with item v from lighter pack
                    for idx_u, u in enumerate(current_packs[p1]):
                        w_u = row_weight[u]
                        for idx_v, v in enumerate(current_packs[p2]):
                            w_v = row_weight[v]
                            delta = w_u - w_v
                            if 0 < delta < diff:
                                gap = abs(delta - target)
                                if gap < best_gap:
                                    best_gap = gap
                                    best_swap = (idx_u, idx_v, delta)
                                    if gap < 1e-5: break
                        if best_swap and best_gap < 1e-5: break

                    if best_swap:
                        idx_u, idx_v, delta = best_swap
                        u = current_packs[p1][idx_u]
                        v = current_packs[p2][idx_v]
                        current_packs[p1][idx_u] = v
                        current_packs[p2][idx_v] = u
                        pack_weights[p1] -= delta
                        pack_weights[p2] += delta
                        found_improvement = True
                        break
                if found_improvement: break

            if not found_improvement:
                break

        # 3. Fill result tensors
        for p in range(num_packs):
            for r, g in enumerate(current_packs[p]):
                pack_index[i, g] = p
                rank_in_pack[i, g] = r

    return pack_index, rank_in_pack
=======
import torch
import random


def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Optimization: Move weights to CPU and use Python lists
    weight_cpu = weight.to("cpu", dtype=torch.float32)
    weight_list = weight_cpu.tolist()

    pack_index = torch.empty(weight.shape, dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device="cpu")

    # Use randomized restarts to explore solution space
    rng = random.Random(42)
    num_restarts = 4

    for i in range(num_layers):
        row_weight = weight_list[i]

        best_spread = float('inf')
        best_packing = None

        # Base LPT indices
        base_indices = sorted(range(num_groups), key=lambda x: row_weight[x], reverse=True)

        for attempt in range(num_restarts):
            # 1. Initialization: Randomized Greedy
            if attempt == 0:
                indices = base_indices
            else:
                # Add noise to weights for sorting order (multiplicative noise 0.9 ~ 1.1)
                indices = sorted(range(num_groups),
                                 key=lambda x: row_weight[x] * (0.9 + rng.random() * 0.2),
                                 reverse=True)

            current_packs = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs

            # Greedy filling
            for group_idx in indices:
                w = row_weight[group_idx]
                # Find best pack (min weight among valid)
                best_p = -1
                min_val = float('inf')
                for p in range(num_packs):
                    if len(current_packs[p]) < groups_per_pack:
                        if pack_weights[p] < min_val:
                            min_val = pack_weights[p]
                            best_p = p
                current_packs[best_p].append(group_idx)
                pack_weights[best_p] += w

            # 2. Refinement: Pairwise Reshuffling
            # We focus on the heaviest and lightest packs to reduce the max spread.
            # "Reshuffling" means pooling items from two packs and re-distributing greedily.

            stagnant_steps = 0
            max_steps = 40

            for _ in range(max_steps):
                # Find min/max packs
                min_p = 0
                max_p = 0
                min_val = pack_weights[0]
                max_val = pack_weights[0]

                for p in range(1, num_packs):
                    val = pack_weights[p]
                    if val < min_val:
                        min_val = val
                        min_p = p
                    elif val > max_val:
                        max_val = val
                        max_p = p

                spread = max_val - min_val
                if spread < 1e-6:
                    break

                # Heuristic: Try to reshuffle (max_p, min_p).
                # If that fails to improve, try (max_p, random) or (random, min_p) to escape local optimum.
                pairs_to_try = [(max_p, min_p)]
                if stagnant_steps >= 2:
                    r = rng.randint(0, num_packs - 1)
                    if r != max_p: pairs_to_try.append((max_p, r))
                    if r != min_p: pairs_to_try.append((r, min_p))

                improved = False
                for p1, p2 in pairs_to_try:
                    if p1 == p2: continue

                    # Pool items
                    items = current_packs[p1] + current_packs[p2]
                    # Sort items descending
                    items.sort(key=lambda x: row_weight[x], reverse=True)

                    w_total = pack_weights[p1] + pack_weights[p2]

                    # Greedy Partition into two bins
                    new_p1 = []
                    new_w1 = 0.0
                    new_p2 = []
                    new_w2 = 0.0

                    for item in items:
                        w = row_weight[item]
                        c1 = len(new_p1) < groups_per_pack
                        c2 = len(new_p2) < groups_per_pack

                        if c1 and c2:
                            # Put in lighter bin
                            if new_w1 < new_w2:
                                new_p1.append(item)
                                new_w1 += w
                            else:
                                new_p2.append(item)
                                new_w2 += w
                        elif c1:
                            new_p1.append(item)
                            new_w1 += w
                        else:
                            new_p2.append(item)
                            new_w2 += w

                    # Check if this reshuffle improved the local pair balance
                    old_diff = abs(pack_weights[p1] - pack_weights[p2])
                    new_diff = abs(new_w1 - new_w2)

                    if new_diff < old_diff - 1e-5:
                        current_packs[p1] = new_p1
                        pack_weights[p1] = new_w1
                        current_packs[p2] = new_p2
                        pack_weights[p2] = new_w2
                        improved = True
                        break # Restart loop to re-evaluate max/min

                if improved:
                    stagnant_steps = 0
                else:
                    stagnant_steps += 1
                    if stagnant_steps > 5:
                        break

            # Check global best
            final_spread = max(pack_weights) - min(pack_weights)
            if final_spread < best_spread:
                best_spread = final_spread
                best_packing = [p[:] for p in current_packs]
                if best_spread < 1e-6:
                    break

        # Write result
        for p in range(num_packs):
            for r, g in enumerate(best_packing[p]):
                pack_index[i, g] = p
                rank_in_pack[i, g] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)
>>>>>>> REPLACE
</DIFF>