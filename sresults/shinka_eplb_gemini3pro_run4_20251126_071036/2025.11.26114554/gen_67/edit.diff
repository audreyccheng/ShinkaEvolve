--- a/original.py
+++ b/original.py
@@ -1,418 +1,451 @@
 # EVOLVE-BLOCK-START
 """
 Expert parallelism load balancer (EPLB) for vLLM.
 
 This module implements the core rearrangement algorithm.
 
 The rearrangement algorithm is adapted from
 [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).
 
 Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example
 on how the EPLB algorithm works.
 """
 
 import torch
 import random
 
 
 def balanced_packing(weight: torch.Tensor,
                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
     """
     Pack n weighted objects to m packs, such that each bin contains exactly
     n/m objects and the weights of all packs are as balanced as possible.
 
     Parameters:
         weight: [X, n], the weight of each item
         num_packs: number of packs
 
     Returns:
         pack_index: [X, n], the pack index of each item
         rank_in_pack: [X, n], the rank of the item in the pack
     """
     num_layers, num_groups = weight.shape
     assert num_groups % num_packs == 0
     groups_per_pack = num_groups // num_packs
 
     # Handle trivial case
     if groups_per_pack == 1:
         pack_index = torch.arange(num_groups,
                                   dtype=torch.int64,
                                   device=weight.device).expand(num_layers, -1)
         rank_in_pack = torch.zeros_like(pack_index)
         return pack_index, rank_in_pack
 
     # Optimization: perform sequential packing logic on CPU to avoid GPU overhead
     weight_cpu = weight.to("cpu", dtype=torch.float32)
     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
 
     # Configuration for restarts
     # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off
     num_restarts = 3
 
     for i in range(num_layers):
         row_weight = weight_cpu[i]
         row_weight_list = row_weight.tolist()
 
         best_diff = float('inf')
         best_packs = None
 
         # Base indices for deterministic LPT (sorted descending)
         base_indices = torch.argsort(row_weight, descending=True).tolist()
 
         for attempt in range(num_restarts):
             # 1. Initialization Strategy
             if attempt == 0:
                 # Deterministic LPT
                 indices = base_indices
             else:
                 # Randomized LPT
                 noise = torch.rand(num_groups, device="cpu") * 0.2 + 0.9
                 indices = torch.argsort(row_weight * noise, descending=True).tolist()
 
             # 2. Greedy Packing
             current_packs = [[] for _ in range(num_packs)]
             pack_weights = [0.0] * num_packs
 
             for group_idx in indices:
                 w = row_weight_list[group_idx]
 
                 # Find best pack (min weight with capacity)
                 best_p = -1
                 min_val = float('inf')
                 for p in range(num_packs):
                     if len(current_packs[p]) < groups_per_pack:
                         if pack_weights[p] < min_val:
                             min_val = pack_weights[p]
                             best_p = p
 
                 current_packs[best_p].append(group_idx)
                 pack_weights[best_p] += w
 
             # 3. Refinement Phase (Local Search)
             # Iteratively swap items between heavy and light packs
             for _ in range(20): # Iteration limit
                 # Sort packs by weight
                 sorted_pack_indices = sorted(range(num_packs),
                                              key=pack_weights.__getitem__,
                                              reverse=True)
 
                 max_p = sorted_pack_indices[0]
                 min_p = sorted_pack_indices[-1]
                 diff = pack_weights[max_p] - pack_weights[min_p]
 
                 if diff < 1e-6:
                     break
 
-                # Strategy A: Merge and Repack (Best Fit Decreasing for 2 bins)
-                # This breaks local optima that single swaps cannot fix by completely
-                # redistributing items between the heaviest and lightest packs.
+                # Strategy A: Randomized Merge and Repack
+                # Try to repack the heaviest pack with lighter packs to offload weight.
+                # We try multiple packs and randomized orders to escape local optima.
                 improved_via_repack = False
                 if groups_per_pack > 1:
-                    p1, p2 = max_p, min_p
-
-                    # Gather all items from both packs
-                    combined_items = current_packs[p1] + current_packs[p2]
-                    combined_weights = [row_weight_list[idx] for idx in combined_items]
-
-                    # Sort descending
-                    combined = sorted(zip(combined_items, combined_weights), key=lambda x: x[1], reverse=True)
-
-                    # Re-distribute using constrained LPT
-                    new_p1, new_p2 = [], []
-                    w_p1, w_p2 = 0.0, 0.0
-
-                    for item, w in combined:
-                        # Try to add to the lighter bin if it has space
-                        can_1 = len(new_p1) < groups_per_pack
-                        can_2 = len(new_p2) < groups_per_pack
-
-                        if can_1 and can_2:
-                            if w_p1 <= w_p2:
-                                new_p1.append(item)
-                                w_p1 += w
+                    # Try repacking max_p with other packs, preferring lighter ones.
+                    # We check all lighter packs to maximize chance of finding a good partner.
+                    candidates = sorted_pack_indices[1:]
+
+                    for partner_p in candidates:
+                        p1, p2 = max_p, partner_p
+
+                        # Gather items
+                        combined_items = current_packs[p1] + current_packs[p2]
+                        combined_weights = [row_weight_list[idx] for idx in combined_items]
+                        items_with_weights = list(zip(combined_items, combined_weights))
+
+                        current_pair_max = max(pack_weights[p1], pack_weights[p2])
+                        current_pair_diff = abs(pack_weights[p1] - pack_weights[p2])
+
+                        best_repack = None
+                        best_repack_max = current_pair_max
+                        best_repack_diff = current_pair_diff
+
+                        # Try Deterministic LPT + Randomized variants
+                        # 1 Deterministic + 5 Randomized
+                        seeds = [None] + [random.random() for _ in range(5)]
+
+                        for seed in seeds:
+                            if seed is None:
+                                # Deterministic LPT
+                                combined = sorted(items_with_weights, key=lambda x: x[1], reverse=True)
                             else:
-                                new_p2.append(item)
-                                w_p2 += w
-                        elif can_1:
-                            new_p1.append(item)
-                            w_p1 += w
-                        else:
-                            new_p2.append(item)
-                            w_p2 += w
-
-                    new_diff = abs(w_p1 - w_p2)
-                    current_pair_diff = pack_weights[p1] - pack_weights[p2]
-
-                    # If we improved the local balance significantly, apply it
-                    if new_diff < current_pair_diff - 1e-5:
-                        current_packs[p1] = new_p1
-                        pack_weights[p1] = w_p1
-                        current_packs[p2] = new_p2
-                        pack_weights[p2] = w_p2
-                        improved_via_repack = True
+                                # Randomized LPT with multiplicative noise
+                                combined = sorted(items_with_weights, key=lambda x: x[1] * (0.8 + 0.4 * random.random()), reverse=True)
+
+                            # Greedy construct (Constrained LPT)
+                            t_p1, t_p2 = [], []
+                            t_w1, t_w2 = 0.0, 0.0
+
+                            for item, w in combined:
+                                can_1 = len(t_p1) < groups_per_pack
+                                can_2 = len(t_p2) < groups_per_pack
+
+                                if can_1 and can_2:
+                                    if t_w1 <= t_w2:
+                                        t_p1.append(item)
+                                        t_w1 += w
+                                    else:
+                                        t_p2.append(item)
+                                        t_w2 += w
+                                elif can_1:
+                                    t_p1.append(item)
+                                    t_w1 += w
+                                else:
+                                    t_p2.append(item)
+                                    t_w2 += w
+
+                            t_max = max(t_w1, t_w2)
+                            t_diff = abs(t_w1 - t_w2)
+
+                            # Acceptance criteria:
+                            # Strictly reduce the local peak load OR (maintain peak and reduce diff)
+                            if t_max < best_repack_max - 1e-6:
+                                best_repack_max = t_max
+                                best_repack_diff = t_diff
+                                best_repack = (t_p1, t_w1, t_p2, t_w2)
+                            elif abs(t_max - best_repack_max) < 1e-6 and t_diff < best_repack_diff - 1e-6:
+                                best_repack_diff = t_diff
+                                best_repack = (t_p1, t_w1, t_p2, t_w2)
+
+                        if best_repack:
+                            # Apply the best found repack
+                            new_p1, new_w1, new_p2, new_w2 = best_repack
+                            current_packs[p1] = new_p1
+                            pack_weights[p1] = new_w1
+                            current_packs[p2] = new_p2
+                            pack_weights[p2] = new_w2
+                            improved_via_repack = True
+                            break # Restart the outer refinement loop to re-evaluate global max/min
 
                 if improved_via_repack:
                     continue
 
                 # Strategy B: Single Swap Descent
                 found_swap = False
                 for i1 in range(num_packs):
                     p1 = sorted_pack_indices[i1]
                     for i2 in range(num_packs - 1, i1, -1):
                         p2 = sorted_pack_indices[i2]
 
                         diff_pair = pack_weights[p1] - pack_weights[p2]
                         if diff_pair < 1e-6: break
 
                         target = diff_pair / 2.0
                         best_swap = None
                         best_gap = diff_pair
 
                         # Find swap (u, v)
                         for idx_u, u in enumerate(current_packs[p1]):
                             w_u = row_weight_list[u]
                             for idx_v, v in enumerate(current_packs[p2]):
                                 w_v = row_weight_list[v]
 
                                 delta = w_u - w_v
                                 if 0 < delta < diff_pair:
                                     gap = abs(delta - target)
                                     if gap < best_gap:
                                         best_gap = gap
                                         best_swap = (idx_u, idx_v, delta)
                                         if gap < 1e-5: break
                             if best_swap and best_gap < 1e-5: break
 
                         if best_swap:
                             idx_u, idx_v, delta = best_swap
                             u = current_packs[p1][idx_u]
                             v = current_packs[p2][idx_v]
 
                             current_packs[p1][idx_u] = v
                             current_packs[p2][idx_v] = u
                             pack_weights[p1] -= delta
                             pack_weights[p2] += delta
                             found_swap = True
                             break
                     if found_swap: break
 
                 if not found_swap:
                     break
 
             # 4. Check if this is the best solution so far
             current_diff = max(pack_weights) - min(pack_weights)
             if current_diff < best_diff:
                 best_diff = current_diff
                 best_packs = [list(p) for p in current_packs]
                 if best_diff < 1e-6:
                     break
 
         # Fill result tensors
         for p in range(num_packs):
             for r, g in enumerate(best_packs[p]):
                 pack_index[i, g] = p
                 rank_in_pack[i, g] = r
 
     return pack_index.to(weight.device), rank_in_pack.to(weight.device)
 
 
 def replicate_experts(
         weight: torch.Tensor,
         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
     Replicate `num_log` experts to `num_phy` replicas, such that the maximum
     load of all replicas is minimized.
 
     Parameters:
         weight: [X, num_log]
         num_phy: total number of experts after replication
 
     Returns:
         phy2log: [X, num_phy], logical expert id of each physical expert
         rank: [X, num_phy], the replica rank
         logcnt: [X, num_log], number of replicas for each logical expert
     """
     n, num_log = weight.shape
     num_redundant = num_phy - num_log
     assert num_redundant >= 0
     device = weight.device
 
     phy2log = torch.arange(num_phy, dtype=torch.int64,
                            device=device).repeat(n, 1)
     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)
     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)
     arangen = torch.arange(n, dtype=torch.int64, device=device)
 
     # Current score tracks weight / logcnt.
     # Initialized as weight / 1.0
     current_scores = weight.clone() # Float copy
 
     for i in range(num_log, num_phy):
         # Find expert with max current average load
         redundant_indices = current_scores.max(dim=-1).indices
 
         phy2log[:, i] = redundant_indices
         rank[:, i] = logcnt[arangen, redundant_indices]
 
         # Update counts
         logcnt[arangen, redundant_indices] += 1
 
         # Update scores incrementally: new_score = weight / new_count
         # Only update the experts that got a new replica
         selected_weights = weight[arangen, redundant_indices]
         selected_counts = logcnt[arangen, redundant_indices].float()
         current_scores[arangen, redundant_indices] = selected_weights / selected_counts
 
     return phy2log, rank, logcnt
 
 
 def rebalance_experts_hierarchical(
     weight: torch.Tensor,
     num_physical_experts: int,
     num_groups: int,
     num_nodes: int,
     num_gpus: int,
 ):
     """
     Parameters:
         weight: [num_moe_layers, num_logical_experts]
         num_physical_experts: number of physical experts after replication
         num_groups: number of expert groups
         num_nodes: number of server nodes, where the intra-node network
         (e.g, NVLink) is faster
         num_gpus: number of GPUs, must be a multiple of `num_nodes`
 
     Returns:
         physical_to_logical_map: [num_moe_layers, num_physical_experts]
         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]
         logical_count: [num_moe_layers, num_logical_experts]
     """
     num_layers, num_logical_experts = weight.shape
     assert num_logical_experts % num_groups == 0
     group_size = num_logical_experts // num_groups
     assert num_groups % num_nodes == 0
     groups_per_node = num_groups // num_nodes
     assert num_gpus % num_nodes == 0
     assert num_physical_experts % num_gpus == 0
     phy_experts_per_gpu = num_physical_experts // num_gpus
 
     def inverse(perm: torch.Tensor) -> torch.Tensor:
         inv = torch.empty_like(perm)
         inv.scatter_(
             1,
             perm,
             torch.arange(perm.size(1), dtype=torch.int64,
                          device=perm.device).expand(perm.shape),
         )
         return inv
 
     # Step 1: pack groups to nodes
     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)
     group_pack_index, group_rank_in_pack = balanced_packing(
         tokens_per_group, num_nodes)
     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *
                  group_size).unsqueeze(-1) +
                 torch.arange(group_size,
                              dtype=torch.int64,
                              device=group_pack_index.device)).flatten(-2)
     mlog2log = inverse(log2mlog)
 
     # Step 2: construct redundant experts within nodes
     # [num_layers * num_nodes, num_logical_experts // num_nodes]
     tokens_per_mlog = weight.gather(-1, mlog2log).view(
         -1, num_logical_experts // num_nodes)
     phy2mlog, phyrank, mlogcnt = replicate_experts(
         tokens_per_mlog, num_physical_experts // num_nodes)
 
     # Step 3: pack physical_experts to GPUs
     # [num_layers * num_nodes, num_physical_experts // num_nodes]
     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)
     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,
                                                 num_gpus // num_nodes)
     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack
     pphy2phy = inverse(phy2pphy)
 
     pphy2mlog = phy2mlog.gather(
         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]
     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(
         0,
         num_logical_experts,
         num_logical_experts // num_nodes,
         device=group_pack_index.device,
     ).view(1, -1, 1)).flatten(-2)
     pphy2log = mlog2log.gather(-1, pphy2mlog)
     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)
     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)
     return pphy2log, pphyrank, logcnt
 
 
 def rebalance_experts(
     weight: torch.Tensor,
     num_replicas: int,
     num_groups: int,
     num_nodes: int,
     num_gpus: int,
 ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
     Entry point for expert-parallelism load balancer.
 
     Parameters:
         weight: [layers, num_logical_experts], the load statistics for all
             logical experts
         num_replicas: number of physical experts, must be a multiple of
             `num_gpus`
         num_groups: number of expert groups
         num_nodes: number of server nodes, where the intra-node network
             (e.g, NVLink) is faster
         num_gpus: number of GPUs, must be a multiple of `num_nodes`
 
     Returns:
         physical_to_logical_map: [layers, num_replicas], the expert index of
             each replica
         logical_to_physical_map: [layers, num_logical_experts, X], the replica
             indices for each expert
         expert_count: [layers, num_logical_experts], number of physical
             replicas for each logical expert
     """
     num_layers, num_logical_experts = weight.shape
     weight = weight.float().cpu()
     if num_groups % num_nodes == 0:
         # use hierarchical load-balance policy
         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
             weight, num_replicas, num_groups, num_nodes, num_gpus)
     else:
         # use global load-balance policy
         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
             weight, num_replicas, 1, 1, num_gpus)
     num_redundant_experts = num_replicas - num_logical_experts
     maxlogcnt = num_redundant_experts + 1
     log2phy: torch.Tensor = torch.full(
         (num_layers, num_logical_experts, maxlogcnt),
         -1,
         dtype=torch.int64,
         device=logcnt.device,
     )
     log2phy.view(num_layers, -1).scatter_(
         -1,
         phy2log * maxlogcnt + phyrank,
         torch.arange(num_replicas, dtype=torch.int64,
                      device=log2phy.device).expand(num_layers, -1),
     )
     return phy2log, log2phy, logcnt
 
 
 # EVOLVE-BLOCK-END
 
 
 # This part remains fixed (not evolved)
 def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,
              num_nodes: int, num_gpus: int):
     """Run the expert parallelism load balancer"""
     phy2log, log2phy, logcnt = rebalance_experts(
         weight, num_replicas, num_groups, num_nodes, num_gpus
     )
     return phy2log, log2phy, logcnt
 
 
 __all__ = ["rebalance_experts", "run_eplb"]