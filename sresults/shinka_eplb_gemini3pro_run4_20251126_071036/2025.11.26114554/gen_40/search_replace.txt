<NAME>
ils_balanced_packing
</NAME>

<DESCRIPTION>
Replacing the complex multi-heuristic strategy with an Iterated Local Search (ILS) algorithm.
1. **Greedy Initialization**: Starts with a standard Longest Processing Time (LPT) greedy packing to get a good initial solution.
2. **Local Search**: Uses a descent method that attempts to swap items between the heaviest pack and the lightest (or other) packs to reduce the maximum load.
3. **Perturbation (Restarts)**: Instead of starting from scratch, subsequent iterations perturb the best known solution by performing random swaps, then re-running the local search. This allows the algorithm to escape local optima without losing all structure.
This approach is generally robust for partitioning problems like this (Multi-Way Number Partitioning with cardinality constraints).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Handle trivial case where each pack gets exactly one item
    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # Optimization: Process on CPU using standard Python lists for flexibility and speed in scalar logic
    weight_cpu = weight.to("cpu", dtype=torch.float32)

    # Pre-allocate output tensors
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")

    for i in range(num_layers):
        row_w = weight_cpu[i]
        total_weight = row_w.sum().item()
        target_avg = total_weight / num_packs

        # Prepare items: list of (original_index, weight)
        items = []
        for idx in range(num_groups):
            items.append((idx, row_w[idx].item()))

        # Sort items descending by weight (common for all heuristics)
        items_desc = sorted(items, key=lambda x: x[1], reverse=True)

        candidates = []

        # --- Strategy 1: ZigZag (Snake) Packing ---
        # Distribute items 0..M-1, then M-1..0, etc.
        # This naturally pairs large with small items.
        packs_zz = [[] for _ in range(num_packs)]
        loads_zz = [0.0] * num_packs
        for k, (idx, w) in enumerate(items_desc):
            row = k // num_packs
            col = k % num_packs
            # Zig-zag mapping
            bin_idx = col if (row % 2 == 0) else (num_packs - 1 - col)
            packs_zz[bin_idx].append((idx, w))
            loads_zz[bin_idx] += w
        candidates.append((packs_zz, loads_zz))

        # --- Strategy 2: Projected Best-Fit LPT ---
        # Greedy allocation that accounts for remaining empty slots.
        # We try to keep the "Projected Load" of all bins close to Target.
        packs_plpt = [[] for _ in range(num_packs)]
        loads_plpt = [0.0] * num_packs
        caps_plpt = [groups_per_pack] * num_packs

        current_rem_weight = total_weight
        current_rem_count = num_groups

        for idx, w in items_desc:
            # Update remaining stats (excluding current item)
            current_rem_weight -= w
            current_rem_count -= 1
            avg_rem = current_rem_weight / current_rem_count if current_rem_count > 0 else 0.0

            best_p = -1
            min_score = float('inf')

            for p in range(num_packs):
                if caps_plpt[p] > 0:
                    # Score is deviation of (current + new + future_fill) from Target
                    # Future fill assumption: remaining slots filled with average remaining weight
                    proj_load = loads_plpt[p] + w + (caps_plpt[p] - 1) * avg_rem
                    score = abs(proj_load - target_avg)
                    if score < min_score:
                        min_score = score
                        best_p = p

            packs_plpt[best_p].append((idx, w))
            loads_plpt[best_p] += w
            caps_plpt[best_p] -= 1

        candidates.append((packs_plpt, loads_plpt))

        # --- Strategy 3: Randomized LPT Restarts ---
        # Generate a few variations to escape initial deterministic local optima.
        for _ in range(5):
            # Perturb weights slightly to change sort order
            noise = torch.rand(num_groups, device="cpu") * 0.05 + 0.975 # +/- 2.5%
            noisy_items = []
            for k in range(num_groups):
                orig_idx, orig_w = items[k]
                noisy_items.append((orig_idx, orig_w, orig_w * noise[k].item()))

            # Sort by noisy weight
            noisy_items.sort(key=lambda x: x[2], reverse=True)

            packs_rnd = [[] for _ in range(num_packs)]
            loads_rnd = [0.0] * num_packs

            # Simple LPT with noisy order
            for idx, w, _ in noisy_items:
                # Assign to least loaded pack with space
                best_p = -1
                min_load = float('inf')
                for p in range(num_packs):
                    if len(packs_rnd[p]) < groups_per_pack:
                        if loads_rnd[p] < min_load:
                            min_load = loads_rnd[p]
                            best_p = p
                packs_rnd[best_p].append((idx, w))
                loads_rnd[best_p] += w
            candidates.append((packs_rnd, loads_rnd))

        # --- Evaluation and Refinement ---
        best_diff_global = float('inf')
        best_packing_global = None

        for packs_init, loads_init in candidates:
            # Create a working copy
            current_packs = [list(p) for p in packs_init]
            current_loads = list(loads_init)

            # Iterative Improvement
            max_iter = 50
            for _ in range(max_iter):
                # Identify Min and Max packs
                min_p = 0
                max_p = 0
                min_v = current_loads[0]
                max_v = current_loads[0]

                for p in range(1, num_packs):
                    v = current_loads[p]
                    if v < min_v:
                        min_v = v
                        min_p = p
                    if v > max_v:
                        max_v = v
                        max_p = p

                diff = max_v - min_v
                if diff < 1e-6:
                    break

                # --- 1. Pairwise Swap Refinement ---
                best_swap = None

                # A. Swap with Min Pack (Target reduction)
                target_delta = diff / 2.0
                best_gap_sq = diff * diff

                p1 = max_p
                p2 = min_p

                for i1, (u, w_u) in enumerate(current_packs[p1]):
                    for i2, (v, w_v) in enumerate(current_packs[p2]):
                        delta = w_u - w_v
                        # We need w_u > w_v to reduce max
                        if 0 < delta < diff:
                            gap = abs(delta - target_delta)
                            if gap * gap < best_gap_sq:
                                best_gap_sq = gap * gap
                                best_swap = (p1, p2, i1, i2, delta, u, w_u, v, w_v)
                                if gap < 1e-6: break
                    if best_swap and best_gap_sq < 1e-12: break

                # B. Swap with Any Pack (Greedy reduction)
                if best_swap is None:
                    other_packs = sorted([p for p in range(num_packs) if p != max_p],
                                         key=lambda k: current_loads[k])
                    for p_other in other_packs:
                        limit = max_v - current_loads[p_other]
                        if limit < 1e-6: continue

                        local_max_delta = -1.0
                        local_best = None

                        for i1, (u, w_u) in enumerate(current_packs[max_p]):
                            for i2, (v, w_v) in enumerate(current_packs[p_other]):
                                delta = w_u - w_v
                                if 0 < delta < limit:
                                    if delta > local_max_delta:
                                        local_max_delta = delta
                                        local_best = (max_p, p_other, i1, i2, delta, u, w_u, v, w_v)
                        if local_best:
                            best_swap = local_best
                            break

                if best_swap:
                    p_from, p_to, i_from, i_to, delta, u_idx, u_w, v_idx, v_w = best_swap
                    current_packs[p_from][i_from] = (v_idx, v_w)
                    current_packs[p_to][i_to] = (u_idx, u_w)
                    current_loads[p_from] -= delta
                    current_loads[p_to] += delta
                    continue

                # --- 2. 3-Way Cyclic Swap Refinement ---
                # Try Max -> Mid -> Min -> Max
                found_3way = False
                mid_candidates = sorted([p for p in range(num_packs) if p != max_p and p != min_p],
                                      key=lambda k: current_loads[k])

                limit_min = max_v - current_loads[min_p]

                for p_mid in mid_candidates:
                    limit_mid = max_v - current_loads[p_mid]

                    for i_u, (u, w_u) in enumerate(current_packs[max_p]):
                        for i_w, (w, w_w) in enumerate(current_packs[min_p]):
                            if w_u <= w_w: continue

                            min_v = w_u - limit_mid
                            for i_v, (v, w_v) in enumerate(current_packs[p_mid]):
                                if w_v > min_v:
                                    if w_v - w_w >= limit_min: continue

                                    current_packs[max_p][i_u] = (w, w_w)
                                    current_loads[max_p] -= (w_u - w_w)
                                    current_packs[min_p][i_w] = (v, w_v)
                                    current_loads[min_p] += (w_v - w_w)
                                    current_packs[p_mid][i_v] = (u, w_u)
                                    current_loads[p_mid] += (w_u - w_v)
                                    found_3way = True
                                    break
                            if found_3way: break
                        if found_3way: break
                    if found_3way: break

                if not found_3way:
                    break

            # Check final score for this candidate
            final_max = max(current_loads)
            final_min = min(current_loads)
            final_diff = final_max - final_min

            if final_diff < best_diff_global:
                best_diff_global = final_diff
                best_packing_global = current_packs
                if best_diff_global < 1e-6:
                    break # Optimal

        # Write results
        for p in range(num_packs):
            for r, (idx, _) in enumerate(best_packing_global[p]):
                pack_index[i, idx] = p
                rank_in_pack[i, idx] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses Iterated Local Search (ILS) with a greedy LPT initialization.
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Handle trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups, dtype=torch.int64, device=weight.device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # CPU processing for complex logic
    weight_cpu = weight.to("cpu", dtype=torch.float32)
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")

    import random

    for i in range(num_layers):
        row_w = weight_cpu[i]
        items = sorted([(idx, row_w[idx].item()) for idx in range(num_groups)],
                       key=lambda x: x[1], reverse=True)

        # --- 1. Greedy Initialization (LPT) ---
        # Assign to the lightest pack that has space
        current_packs = [[] for _ in range(num_packs)]
        current_loads = [0.0] * num_packs

        for idx, w in items:
            best_p = -1
            min_load = float('inf')
            for p in range(num_packs):
                if len(current_packs[p]) < groups_per_pack:
                    if current_loads[p] < min_load:
                        min_load = current_loads[p]
                        best_p = p
            current_packs[best_p].append((idx, w))
            current_loads[best_p] += w

        # Track global best
        best_packs = [list(p) for p in current_packs]
        best_loads = list(current_loads)
        best_diff = max(best_loads) - min(best_loads)

        if best_diff < 1e-6:
            # Already optimal
            pass
        else:
            # --- 2. Iterated Local Search ---
            # Try to improve packing via local search and restarts
            num_restarts = 4
            iter_per_restart = 50

            for attempt in range(num_restarts):
                # Perturbation (except first run, which uses greedy)
                if attempt > 0:
                    # Restore best known as base for perturbation
                    current_packs = [list(p) for p in best_packs]
                    current_loads = list(best_loads)

                    # Randomly swap items between k random pairs of packs
                    k_swaps = 2
                    for _ in range(k_swaps):
                        p1 = random.randint(0, num_packs - 1)
                        p2 = random.randint(0, num_packs - 1)
                        if p1 == p2: continue
                        if not current_packs[p1] or not current_packs[p2]: continue

                        i1 = random.randint(0, len(current_packs[p1]) - 1)
                        i2 = random.randint(0, len(current_packs[p2]) - 1)

                        u, w_u = current_packs[p1][i1]
                        v, w_v = current_packs[p2][i2]

                        current_packs[p1][i1] = (v, w_v)
                        current_packs[p2][i2] = (u, w_u)
                        current_loads[p1] = current_loads[p1] - w_u + w_v
                        current_loads[p2] = current_loads[p2] - w_v + w_u

                # Local Search (Descent)
                for _ in range(iter_per_restart):
                    # Sort packs by load
                    sorted_packs = sorted(range(num_packs), key=lambda k: current_loads[k])
                    min_p = sorted_packs[0]
                    max_p = sorted_packs[-1]

                    diff = current_loads[max_p] - current_loads[min_p]
                    if diff < 1e-6: break

                    target = diff / 2.0
                    best_move = None
                    best_gap = diff

                    # Try to swap between max_p and min_p
                    p1 = max_p
                    p2 = min_p
                    found_swap = False

                    for i1, (u, w_u) in enumerate(current_packs[p1]):
                        for i2, (v, w_v) in enumerate(current_packs[p2]):
                            delta = w_u - w_v
                            if 0 < delta < diff:
                                gap = abs(delta - target)
                                if gap < best_gap:
                                    best_gap = gap
                                    best_move = (p1, p2, i1, i2, delta, u, w_u, v, w_v)
                                    if gap < 1e-6:
                                        found_swap = True
                                        break
                        if found_swap: break

                    # If no good swap between extremes, try swapping max_p with random others
                    if not best_move:
                        for _ in range(2):
                            rand_p = random.choice(sorted_packs[1:-1]) if len(sorted_packs) > 2 else min_p
                            if rand_p == max_p: continue

                            limit = current_loads[max_p] - current_loads[rand_p]
                            if limit < 1e-6: continue

                            for i1, (u, w_u) in enumerate(current_packs[max_p]):
                                for i2, (v, w_v) in enumerate(current_packs[rand_p]):
                                    delta = w_u - w_v
                                    if 0 < delta < limit:
                                        best_move = (max_p, rand_p, i1, i2, delta, u, w_u, v, w_v)
                                        found_swap = True
                                        break
                                if found_swap: break
                            if found_swap: break

                    if best_move:
                        p_from, p_to, i_from, i_to, delta, u_idx, u_w, v_idx, v_w = best_move
                        current_packs[p_from][i_from] = (v_idx, v_w)
                        current_packs[p_to][i_to] = (u_idx, u_w)
                        current_loads[p_from] -= delta
                        current_loads[p_to] += delta
                    else:
                        break # Local optimum reached

                # Check against global best
                curr_diff = max(current_loads) - min(current_loads)
                if curr_diff < best_diff:
                    best_diff = curr_diff
                    best_packs = [list(p) for p in current_packs]
                    best_loads = list(current_loads)
                    if best_diff < 1e-6: break

        # Fill output tensors
        for p in range(num_packs):
            for r, (idx, _) in enumerate(best_packs[p]):
                pack_index[i, idx] = p
                rank_in_pack[i, idx] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)
>>>>>>> REPLACE
</DIFF>