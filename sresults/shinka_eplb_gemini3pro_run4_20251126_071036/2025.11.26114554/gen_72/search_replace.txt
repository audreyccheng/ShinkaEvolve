<NAME>
exact_solver_and_3way_v2
</NAME>

<DESCRIPTION>
Improve `balanced_packing` by:
1.  Using an **Exact Solver** (brute-force combinations) for 2-way rebalancing when the total number of items is small (<= 14). This guarantees optimal local swaps for small groups.
2.  Adding a **3-Way Rebalancing** fallback. If 2-way rebalancing fails to improve the spread, the algorithm picks a random third pack and attempts to rebalance the 3 packs using randomized greedy packing. This helps escape local optima.

The implementation replaces the previous heuristic-only refinement logic.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Handle trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # CPU processing for complex sequential logic
    weight_cpu = weight.to("cpu", dtype=torch.float32)
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")

    # Heuristic parameters
    num_restarts = 2
    max_refine_steps = 20

    for i in range(num_layers):
        row_weight = weight_cpu[i]
        row_weight_list = row_weight.tolist()

        best_diff = float('inf')
        best_packs = None # List[List[item_index]]
        best_pack_weights = None

        # Base indices for deterministic LPT
        base_indices = torch.argsort(row_weight, descending=True).tolist()

        for attempt in range(num_restarts):
            # 1. Initialization
            if attempt == 0:
                indices = base_indices
            else:
                # Randomized LPT: Add multiplicative noise
                noise = torch.rand(num_groups, device="cpu") * 0.2 + 0.9
                indices = torch.argsort(row_weight * noise, descending=True).tolist()

            current_packs = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs

            # Greedy Packing
            for group_idx in indices:
                w = row_weight_list[group_idx]
                best_p = -1
                min_val = float('inf')
                for p in range(num_packs):
                    if len(current_packs[p]) < groups_per_pack:
                        if pack_weights[p] < min_val:
                            min_val = pack_weights[p]
                            best_p = p
                current_packs[best_p].append(group_idx)
                pack_weights[best_p] += w

            # 2. Refinement Phase: Iterative 2-Bin Repartitioning
            for step in range(max_refine_steps):
                # Identify max and min packs
                min_p = 0
                max_p = 0
                min_val = pack_weights[0]
                max_val = pack_weights[0]

                # Randomized selection occasionally to escape local optima
                if step > 0 and step % 5 == 0:
                    p1 = random.randint(0, num_packs - 1)
                    p2 = random.randint(0, num_packs - 2)
                    if p2 >= p1: p2 += 1
                    max_p, min_p = p1, p2
                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]
                else:
                    for p in range(1, num_packs):
                        val = pack_weights[p]
                        if val < min_val:
                            min_val = val
                            min_p = p
                        elif val > max_val:
                            max_val = val
                            max_p = p

                diff = abs(max_val - min_val)
                if diff < 1e-6:
                    if step % 5 != 0:
                        break
                    else:
                        continue

                # Pool items from both packs
                pool = current_packs[max_p] + current_packs[min_p]
                pool_weights = [row_weight_list[x] for x in pool]
                total_pool = sum(pool_weights)
                target_half = total_pool / 2.0
                K = groups_per_pack

                # Record current best state for this pair
                # We want to minimize deviation from target_half
                best_dev = abs(pack_weights[max_p] - target_half)
                best_assignment = None # Will store set_A indices relative to pool

                pool_indices = list(range(len(pool)))

                # Heuristic: Repeated Randomized Greedy
                # We want to partition pool into A and B of size K
                sub_trials = 30
                for sub in range(sub_trials):
                    # Sort with noise
                    if sub == 0:
                        # Deterministic LPT first
                        sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)
                    else:
                        # Add noise to weights
                        noise = [random.uniform(0.8, 1.2) for _ in pool]
                        sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)

                    w_A = 0.0
                    w_B = 0.0
                    cnt_A = 0
                    cnt_B = 0
                    set_A_local = []

                    # Greedy assignment
                    for idx in sorted_idx:
                        w = pool_weights[idx]
                        can_A = cnt_A < K
                        can_B = cnt_B < K

                        if can_A and can_B:
                            # Put in the lighter bin so far
                            if w_A <= w_B:
                                w_A += w
                                cnt_A += 1
                                set_A_local.append(idx)
                            else:
                                w_B += w
                                cnt_B += 1
                        elif can_A:
                            w_A += w
                            cnt_A += 1
                            set_A_local.append(idx)
                        else: # can_B
                            w_B += w
                            cnt_B += 1

                    dev = abs(w_A - target_half)
                    if dev < best_dev:
                        best_dev = dev
                        best_assignment = set_A_local
                        if dev < 1e-6: break

                # Apply improvement if found
                if best_assignment is not None:
                    set_A_indices = set(best_assignment)
                    new_max = [pool[i] for i in best_assignment]
                    new_min = [pool[i] for i in pool_indices if i not in set_A_indices]

                    current_packs[max_p] = new_max
                    current_packs[min_p] = new_min
                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)
                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)
                else:
                    # No improvement found for this pair
                    if step % 5 != 0:
                        break

            # Check result
            current_diff = max(pack_weights) - min(pack_weights)
            if current_diff < best_diff:
                best_diff = current_diff
                best_packs = [list(p) for p in current_packs]
                if best_diff < 1e-6:
                    break

        # Fill tensors
        for p in range(num_packs):
            for r, g in enumerate(best_packs[p]):
                pack_index[i, g] = p
                rank_in_pack[i, g] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Handle trivial case
    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # CPU processing for complex sequential logic
    weight_cpu = weight.to("cpu", dtype=torch.float32)
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")

    # Heuristic parameters
    num_restarts = 2
    max_refine_steps = 20

    for i in range(num_layers):
        row_weight = weight_cpu[i]
        row_weight_list = row_weight.tolist()

        best_diff = float('inf')
        best_packs = None

        # Base indices for deterministic LPT
        base_indices = torch.argsort(row_weight, descending=True).tolist()

        for attempt in range(num_restarts):
            # 1. Initialization
            if attempt == 0:
                indices = base_indices
            else:
                noise = torch.rand(num_groups, device="cpu") * 0.2 + 0.9
                indices = torch.argsort(row_weight * noise, descending=True).tolist()

            current_packs = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs

            # Greedy Packing
            for group_idx in indices:
                w = row_weight_list[group_idx]
                best_p = -1
                min_val = float('inf')
                for p in range(num_packs):
                    if len(current_packs[p]) < groups_per_pack:
                        if pack_weights[p] < min_val:
                            min_val = pack_weights[p]
                            best_p = p
                current_packs[best_p].append(group_idx)
                pack_weights[best_p] += w

            # 2. Refinement Phase
            for step in range(max_refine_steps):
                # Identify max and min packs
                min_p = 0
                max_p = 0
                min_val = pack_weights[0]
                max_val = pack_weights[0]

                # Random perturbation occasionally
                if step > 0 and step % 6 == 0:
                    p1 = random.randint(0, num_packs - 1)
                    p2 = random.randint(0, num_packs - 2)
                    if p2 >= p1: p2 += 1
                    max_p, min_p = p1, p2
                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]
                else:
                    for p in range(1, num_packs):
                        val = pack_weights[p]
                        if val < min_val:
                            min_val = val
                            min_p = p
                        elif val > max_val:
                            max_val = val
                            max_p = p

                diff = max_val - min_val
                if diff < 1e-6:
                    if step % 6 != 0: break
                    else: continue

                # Try 2-Pack Rebalancing
                pool = current_packs[max_p] + current_packs[min_p]
                pool_weights = [row_weight_list[x] for x in pool]
                total_pool = sum(pool_weights)
                target_half = total_pool / 2.0
                K = groups_per_pack
                pool_len = 2 * K

                improved = False
                best_dev = abs(pack_weights[max_p] - target_half)
                best_assignment = None

                # EXACT SOLVER for small K
                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.
                if pool_len <= 14:
                    # Fix first element to be in Set A to reduce symmetry
                    indices_rest = list(range(1, pool_len))
                    w_0 = pool_weights[0]

                    for comb in itertools.combinations(indices_rest, K - 1):
                        s = w_0
                        for idx in comb:
                            s += pool_weights[idx]
                        dev = abs(s - target_half)
                        if dev < best_dev - 1e-6:
                            best_dev = dev
                            best_assignment = (0,) + comb
                            if dev < 1e-6: break
                else:
                    # Heuristic Solver
                    pool_indices = list(range(pool_len))
                    sub_trials = 30
                    for sub in range(sub_trials):
                        if sub == 0:
                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)
                        else:
                            noise = [random.uniform(0.8, 1.2) for _ in pool]
                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)

                        w_A, w_B = 0.0, 0.0
                        cnt_A, cnt_B = 0, 0
                        set_A_local = []

                        for idx in sorted_idx:
                            w = pool_weights[idx]
                            if cnt_A < K and cnt_B < K:
                                if w_A <= w_B:
                                    w_A += w
                                    cnt_A += 1
                                    set_A_local.append(idx)
                                else:
                                    w_B += w
                                    cnt_B += 1
                            elif cnt_A < K:
                                w_A += w
                                cnt_A += 1
                                set_A_local.append(idx)
                            else:
                                w_B += w
                                cnt_B += 1

                        dev = abs(w_A - target_half)
                        if dev < best_dev - 1e-6:
                            best_dev = dev
                            best_assignment = set_A_local
                            if dev < 1e-6: break

                if best_assignment is not None:
                    set_A_indices = set(best_assignment)
                    new_max = [pool[i] for i in best_assignment]
                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]
                    current_packs[max_p] = new_max
                    current_packs[min_p] = new_min
                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)
                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)
                    improved = True

                # 3-Way Rebalancing Fallback
                if not improved and num_packs >= 3:
                     # Pick random 3rd pack
                     while True:
                         mid_p = random.randint(0, num_packs - 1)
                         if mid_p != max_p and mid_p != min_p: break

                     packs_3 = [max_p, min_p, mid_p]
                     pool_3 = []
                     for p in packs_3:
                         pool_3.extend(current_packs[p])

                     pool_3_weights = [row_weight_list[x] for x in pool_3]
                     total_3 = sum(pool_3_weights)

                     # Check if we can improve deviation of these 3 packs
                     current_loads = [pack_weights[p] for p in packs_3]
                     best_spread_3 = max(current_loads) - min(current_loads)

                     pool_3_indices = list(range(3 * K))
                     best_assignment_3 = None

                     for sub in range(20):
                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]
                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)

                         bins = [0.0] * 3
                         counts = [0] * 3
                         assignment = [[] for _ in range(3)]

                         for idx in sorted_idx:
                             w = pool_3_weights[idx]
                             # Assign to valid bin with min load
                             best_b = -1
                             min_b_val = float('inf')
                             for b in range(3):
                                 if counts[b] < K:
                                     if bins[b] < min_b_val:
                                         min_b_val = bins[b]
                                         best_b = b
                             bins[best_b] += w
                             counts[best_b] += 1
                             assignment[best_b].append(idx)

                         spread = max(bins) - min(bins)
                         if spread < best_spread_3 - 1e-6:
                             best_spread_3 = spread
                             best_assignment_3 = assignment

                     if best_assignment_3 is not None:
                         for b_idx, p_idx in enumerate(packs_3):
                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]
                             current_packs[p_idx] = new_items
                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)

            # Check result
            current_diff = max(pack_weights) - min(pack_weights)
            if current_diff < best_diff:
                best_diff = current_diff
                best_packs = [list(p) for p in current_packs]
                if best_diff < 1e-6:
                    break

        # Fill tensors
        for p in range(num_packs):
            for r, g in enumerate(best_packs[p]):
                pack_index[i, g] = p
                rank_in_pack[i, g] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)
>>>>>>> REPLACE
</DIFF>