--- a/original.py
+++ b/original.py
@@ -1,426 +1,476 @@
 # EVOLVE-BLOCK-START
 """
 Expert parallelism load balancer (EPLB) for vLLM.
 
 This module implements the core rearrangement algorithm.
 
 The rearrangement algorithm is adapted from
 [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).
 
 Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example
 on how the EPLB algorithm works.
 """
 
 import torch
+import random
+import itertools
 
 
 def balanced_packing(weight: torch.Tensor,
                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
     """
     Pack n weighted objects to m packs, such that each bin contains exactly
     n/m objects and the weights of all packs are as balanced as possible.
 
     Parameters:
         weight: [X, n], the weight of each item
         num_packs: number of packs
 
     Returns:
         pack_index: [X, n], the pack index of each item
         rank_in_pack: [X, n], the rank of the item in the pack
     """
     num_layers, num_groups = weight.shape
     assert num_groups % num_packs == 0
     groups_per_pack = num_groups // num_packs
     device = weight.device
 
+    # Trivial case
     if groups_per_pack == 1:
-        pack_index = torch.arange(weight.size(-1),
-                                  dtype=torch.int64,
-                                  device=device).expand(weight.shape)
+        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(weight.shape)
         rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
         return pack_index, rank_in_pack
 
-    # Operations on CPU are generally faster for this sequential/iterative logic
+    # Work on CPU for scalar efficiency
     weight_cpu = weight.cpu()
 
-    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)
-    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)
-
-    # Pre-allocate helper tensors for scatter
-    flat_packs = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)
-    flat_ranks = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)
+    # Pre-allocate output tensors
+    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)
+    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)
+
+    # Helper for 2-Partition solving
+    # Defined inside to access scope if needed, but clean as static
+    def solve_2_partition(items_a, items_b, all_weights, k):
+        """
+        Redistribute items from two sets A and B (size k each) to minimize
+        abs(sum(new_A) - sum(new_B)).
+        Returns (best_A_indices, best_B_indices, best_diff, improved)
+        """
+        pool = items_a + items_b
+        n = len(pool)
+        pool_weights = [all_weights[i] for i in pool]
+        total_w = sum(pool_weights)
+        target_w = total_w / 2.0
+        
+        current_w_a = sum(all_weights[i] for i in items_a)
+        current_w_b = total_w - current_w_a
+        current_diff = abs(current_w_a - current_w_b)
+        
+        best_diff = current_diff
+        best_A = None
+        best_B = None
+        found_improvement = False
+
+        # Strategy 1: Exact Solver for small inputs (n <= 14 means binom(13, k-1) checks)
+        # 2*k <= 14 => k <= 7. 
+        if n <= 14:
+            # Fix first element to set A to break symmetry
+            fixed = 0
+            # Choose k-1 from the remaining n-1 items
+            others = range(1, n)
+            
+            # We want sum(subset) close to target_w
+            # Optimization: Pre-calculate weights and target
+            
+            for combo in itertools.combinations(others, k - 1):
+                # Combo contains indices relative to pool
+                # Construct sum directly
+                w_subset = pool_weights[fixed]
+                for idx in combo:
+                    w_subset += pool_weights[idx]
+                
+                diff = abs(w_subset - (total_w - w_subset))
+                
+                if diff < best_diff - 1e-6:
+                    best_diff = diff
+                    found_improvement = True
+                    # Reconstruct
+                    indices_A = [fixed] + list(combo)
+                    # Use set for fast lookup
+                    set_A = set(indices_A)
+                    best_A = [pool[i] for i in indices_A]
+                    best_B = [pool[i] for i in range(n) if i not in set_A]
+                    
+                    if best_diff < 1e-6:
+                        return best_A, best_B, best_diff, True
+
+        # Strategy 2: Randomized Perturbed Greedy
+        # Used if exact solver didn't run or didn't find perfect 0.0 diff (though exact finds global opt)
+        # If n > 14, we rely on this.
+        if not found_improvement and n > 14:
+            # Number of restarts depends on size
+            num_restarts = 50 if n < 40 else 30
+            
+            # We also include a deterministic LPT pass
+            attempts = 1 + num_restarts
+            
+            indices_rel = list(range(n))
+            
+            for attempt in range(attempts):
+                if attempt == 0:
+                    # Deterministic LPT
+                    sorted_idx = sorted(indices_rel, key=lambda i: pool_weights[i], reverse=True)
+                else:
+                    # Perturbed LPT
+                    # Random noise +/- 10%
+                    sorted_idx = sorted(indices_rel, key=lambda i: pool_weights[i] * random.uniform(0.9, 1.1), reverse=True)
+                
+                w_A, w_B = 0.0, 0.0
+                c_A, c_B = 0, 0
+                idx_A, idx_B = [], []
+                
+                for i in sorted_idx:
+                    w = pool_weights[i]
+                    # Fill logic: maintain partition constraint
+                    if c_A < k and (c_B == k or w_A < w_B):
+                        w_A += w
+                        c_A += 1
+                        idx_A.append(i)
+                    else:
+                        w_B += w
+                        c_B += 1
+                        idx_B.append(i)
+                
+                diff = abs(w_A - w_B)
+                if diff < best_diff - 1e-6:
+                    best_diff = diff
+                    found_improvement = True
+                    best_A = [pool[i] for i in idx_A]
+                    best_B = [pool[i] for i in idx_B]
+                    if best_diff < 1e-6:
+                        break
+
+        if found_improvement:
+            return best_A, best_B, best_diff, True
+        return items_a, items_b, current_diff, False
+
 
     for i in range(num_layers):
-        # Extract weights for this layer as a list for fast Python iteration
-        layer_weights_t = weight_cpu[i]
-        layer_weights = layer_weights_t.tolist()
-
-        # Candidate generation:
-        # We try:
-        # 1. Deterministic LPT (sort descending)
-        # 2. Perturbed LPT (add noise to break ties/local optima) if useful
-
+        layer_w = weight_cpu[i]
+        layer_w_list = layer_w.tolist()
+
+        # --- Phase 1: Initialization ---
+        # Generate candidates using Randomized Best Fit Decreasing
+        # LPT usually works best for MakeSpan.
+        
         candidates = []
-
         # 1. Deterministic
-        indices_det = layer_weights_t.sort(descending=True).indices.tolist()
-        candidates.append(indices_det)
-
-        # 2. Perturbed (only if we have enough groups for it to matter)
-        if groups_per_pack > 1:
-            # Add small random noise to explore different greedy decisions
-            # Generate multiple candidates to improve diversity
-            for _ in range(4):
-                noise = torch.rand(num_groups) * 0.1 + 0.95 # +/- 5% noise
-                indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()
-                candidates.append(indices_rand)
+        candidates.append(sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True))
+        # 2. Random Noise
+        for _ in range(4):
+             noise = torch.rand(num_groups) * 0.15 + 0.925 # +/- 7.5%
+             candidates.append((layer_w * noise).sort(descending=True).indices.tolist())
 
         best_assignment = None
         best_pack_weights = None
         min_max_load = float('inf')
 
-        # Evaluate candidates with fast Python Greedy
         for indices in candidates:
-            # Re-init packs using lists for speed
-            current_pack_contents = [[] for _ in range(num_packs)]
-            current_pack_weights = [0.0] * num_packs
-            current_pack_cnt = [0] * num_packs
-
-            # Pack
+            packs = [[] for _ in range(num_packs)]
+            p_weights = [0.0] * num_packs
+            p_counts = [0] * num_packs
+            
             for idx in indices:
-                w = layer_weights[idx]
-
-                # Find best pack: valid (not full) and min weight
+                w = layer_w_list[idx]
+                # Best Fit: Min weight among valid packs
                 best_p = -1
                 min_w = float('inf')
-
                 for p in range(num_packs):
-                    if current_pack_cnt[p] < groups_per_pack:
-                        pw = current_pack_weights[p]
-                        if pw < min_w:
-                            min_w = pw
+                    if p_counts[p] < groups_per_pack:
+                        if p_weights[p] < min_w:
+                            min_w = p_weights[p]
                             best_p = p
-
-                # Assign
-                current_pack_contents[best_p].append(idx)
-                current_pack_weights[best_p] += w
-                current_pack_cnt[best_p] += 1
-
-            # Metric: minimize max load
-            max_load = max(current_pack_weights)
-            if max_load < min_max_load:
-                min_max_load = max_load
-                best_assignment = current_pack_contents
-                best_pack_weights = current_pack_weights
-
-        # Convert best assignment to tensor for vectorized refinement
-        # [num_packs, groups_per_pack]
-        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)
-        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)
-
-        # Iterative Refinement: Mix of Vectorized Swaps and LNS
-        for outer_loop in range(3):
-            # Phase 1: Vectorized Local Search (Steepest Descent 1-Swap)
-            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously
-            improved_swap = False
-            for _ in range(20):
-                max_pack = torch.argmax(pack_weights).item()
-                max_w = pack_weights[max_pack].item()
-
-                # Items in max pack: [G]
-                u_indices = pack_assignment[max_pack]
-                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1) # [1, G, 1]
-
-                # Items in all packs: [M, G]
-                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack) # [M, 1, G]
-
-                # Compute deltas: w_u - w_v
-                deltas = w_u - w_v # [M, G, G]
-
-                # Diff with max pack
-                diffs = (max_w - pack_weights).view(num_packs, 1, 1) # [M, 1, 1]
-
-                # We want to swap such that max_load is reduced.
-                mask = (deltas > 1e-6) & (deltas < diffs)
-
-                if not mask.any():
-                    break
-
-                gains = deltas * (diffs - deltas)
-                gains = torch.where(mask, gains, -1.0)
-
-                best_flat = torch.argmax(gains).item()
-                max_gain = gains.view(-1)[best_flat].item()
-
-                if max_gain < 0:
-                    break
-
-                # Perform Swap
-                best_p = best_flat // (groups_per_pack * groups_per_pack)
-                rem = best_flat % (groups_per_pack * groups_per_pack)
-                best_u_idx = rem // groups_per_pack
-                best_v_idx = rem % groups_per_pack
-
-                u_val = pack_assignment[max_pack, best_u_idx].item()
-                v_val = pack_assignment[best_p, best_v_idx].item()
-
-                pack_assignment[max_pack, best_u_idx] = v_val
-                pack_assignment[best_p, best_v_idx] = u_val
-
-                d_val = deltas[best_p, best_u_idx, best_v_idx].item()
-                pack_weights[max_pack] -= d_val
-                pack_weights[best_p] += d_val
-                improved_swap = True
-
-            # Phase 2: LNS (3-Pack Repacking)
-            # Pick heaviest, lightest, and one random pack to reshuffle
-            # This helps break out of local optima where 1-swaps fail
-            max_p = torch.argmax(pack_weights).item()
-            min_p = torch.argmin(pack_weights).item()
-
-            possible_others = [p for p in range(num_packs) if p != max_p and p != min_p]
-            if possible_others:
-                # Deterministic rotation based on loop index to cover different combos
-                other_p = possible_others[outer_loop % len(possible_others)]
-                lns_packs = [max_p, min_p, other_p]
-            elif max_p != min_p:
-                lns_packs = [max_p, min_p]
-            else:
+                
+                packs[best_p].append(idx)
+                p_weights[best_p] += w
+                p_counts[best_p] += 1
+            
+            max_l = max(p_weights)
+            if max_l < min_max_load:
+                min_max_load = max_l
+                best_assignment = packs
+                best_pack_weights = p_weights
+
+        # Set current best
+        current_packs = best_assignment
+        current_weights = best_pack_weights
+
+        # --- Phase 2: Pairwise Repartitioning Refinement ---
+        # Iteratively target the Max Load pack and try to offload to lighter packs
+        
+        MAX_ROUNDS = 20
+        for _ in range(MAX_ROUNDS):
+            # Sort packs by weight
+            sorted_packs = sorted(range(num_packs), key=lambda x: current_weights[x])
+            
+            max_p = sorted_packs[-1]
+            min_p = sorted_packs[0]
+            
+            # Global stop condition
+            if current_weights[max_p] - current_weights[min_p] < 1e-6:
                 break
-
-            # Extract items
-            items_flat = pack_assignment[lns_packs].view(-1).tolist()
-            weights_flat = [layer_weights[idx] for idx in items_flat]
-
-            # Sort for LPT
-            item_pairs = sorted(zip(weights_flat, items_flat), key=lambda x: x[0], reverse=True)
-
-            # Greedy repack
-            new_bins = [[] for _ in lns_packs]
-            new_bin_weights = [0.0] * len(lns_packs)
-
-            for w, idx in item_pairs:
-                # Find best bin (min weight and not full)
-                best_b = -1
-                min_bw = float('inf')
-                for b in range(len(lns_packs)):
-                    if len(new_bins[b]) < groups_per_pack:
-                        if new_bin_weights[b] < min_bw:
-                            min_bw = new_bin_weights[b]
-                            best_b = b
-                new_bins[best_b].append(idx)
-                new_bin_weights[best_b] += w
-
-            # Check for improvement (minimized max load within this subset)
-            old_local_max = max(pack_weights[p].item() for p in lns_packs)
-            new_local_max = max(new_bin_weights)
-
-            # Accept if max load reduced, or same max load but better variance (sum of squares)
-            if new_local_max < old_local_max - 1e-6:
-                accept = True
-            elif abs(new_local_max - old_local_max) < 1e-6:
-                old_ss = sum(pack_weights[p].item()**2 for p in lns_packs)
-                new_ss = sum(w**2 for w in new_bin_weights)
-                accept = new_ss < old_ss - 1e-6
-            else:
-                accept = False
-
-            if accept:
-                for b_i, p_idx in enumerate(lns_packs):
-                    pack_assignment[p_idx] = torch.tensor(new_bins[b_i], dtype=torch.int64)
-                    pack_weights[p_idx] = new_bin_weights[b_i]
-
-            if not improved_swap and not accept:
+                
+            improved_round = False
+            
+            # Try to pair Max Pack with Lighter Packs
+            # We check the 3 lightest packs to increase chances of finding a good swap
+            # while keeping complexity low.
+            candidate_partners = sorted_packs[:3]
+            if min_p not in candidate_partners: # Should be there, but just in case
+                candidate_partners.insert(0, min_p)
+
+            for partner_p in candidate_partners:
+                if partner_p == max_p: continue
+                
+                # Run Pairwise Solver
+                items_a = current_packs[max_p]
+                items_b = current_packs[partner_p]
+                
+                new_a, new_b, diff, improved = solve_2_partition(
+                    items_a, items_b, layer_w_list, groups_per_pack
+                )
+                
+                if improved:
+                    # Calculate new weights
+                    wa = sum(layer_w_list[x] for x in new_a)
+                    wb = sum(layer_w_list[x] for x in new_b)
+                    
+                    # Accept only if it reduces Max Load or reduces variance significantly
+                    # Since we are pairing Max with a small pack, reducing diff usually reduces Max.
+                    # Explicit check:
+                    old_max_pair = current_weights[max_p] # The heavier one
+                    new_max_pair = max(wa, wb)
+                    
+                    if new_max_pair < old_max_pair - 1e-6:
+                        current_packs[max_p] = new_a
+                        current_packs[partner_p] = new_b
+                        current_weights[max_p] = wa
+                        current_weights[partner_p] = wb
+                        improved_round = True
+                        break # Restart outer loop to re-evaluate who is max
+            
+            if not improved_round:
+                # If we couldn't improve Max Load by pairing with lightest, try Second Heaviest?
+                # This might help unblock.
+                if num_packs > 2:
+                     # Try Max vs Random
+                     rand_p = random.choice(sorted_packs[:-1])
+                     items_a = current_packs[max_p]
+                     items_b = current_packs[rand_p]
+                     new_a, new_b, diff, improved = solve_2_partition(
+                        items_a, items_b, layer_w_list, groups_per_pack
+                     )
+                     if improved:
+                         wa = sum(layer_w_list[x] for x in new_a)
+                         wb = sum(layer_w_list[x] for x in new_b)
+                         if max(wa, wb) < current_weights[max_p] - 1e-6:
+                             current_packs[max_p] = new_a
+                             current_packs[rand_p] = new_b
+                             current_weights[max_p] = wa
+                             current_weights[rand_p] = wb
+                             improved_round = True
+
+            if not improved_round:
                 break
 
-        # Final write to output tensors
-        # pack_assignment contains expert indices in packed order
-        flat_experts = pack_assignment.view(-1).to(device)
-        pack_index[i].scatter_(0, flat_experts, flat_packs)
-        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks)
-
-    return pack_index, rank_in_pack
+        # Fill output
+        for p in range(num_packs):
+            for r, item_idx in enumerate(current_packs[p]):
+                pack_index[i, item_idx] = p
+                rank_in_pack[i, item_idx] = r
+
+    return pack_index.to(device), rank_in_pack.to(device)
 
 
 def replicate_experts(
         weight: torch.Tensor,
         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
     Replicate `num_log` experts to `num_phy` replicas, such that the maximum
     load of all replicas is minimized.
 
     Parameters:
         weight: [X, num_log]
         num_phy: total number of experts after replication
 
     Returns:
         phy2log: [X, num_phy], logical expert id of each physical expert
         rank: [X, num_phy], the replica rank
         logcnt: [X, num_log], number of replicas for each logical expert
     """
     n, num_log = weight.shape
     num_redundant = num_phy - num_log
     assert num_redundant >= 0
     device = weight.device
     phy2log = torch.arange(num_phy, dtype=torch.int64,
                            device=device).repeat(n, 1)
     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)
     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)
     arangen = torch.arange(n, dtype=torch.int64, device=device)
     for i in range(num_log, num_phy):
         redundant_indices = (weight / logcnt).max(dim=-1).indices
         phy2log[:, i] = redundant_indices
         rank[:, i] = logcnt[arangen, redundant_indices]
         logcnt[arangen, redundant_indices] += 1
     return phy2log, rank, logcnt
 
 
 def rebalance_experts_hierarchical(
     weight: torch.Tensor,
     num_physical_experts: int,
     num_groups: int,
     num_nodes: int,
     num_gpus: int,
 ):
     """
     Parameters:
         weight: [num_moe_layers, num_logical_experts]
         num_physical_experts: number of physical experts after replication
         num_groups: number of expert groups
         num_nodes: number of server nodes, where the intra-node network
         (e.g, NVLink) is faster
         num_gpus: number of GPUs, must be a multiple of `num_nodes`
 
     Returns:
         physical_to_logical_map: [num_moe_layers, num_physical_experts]
         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]
         logical_count: [num_moe_layers, num_logical_experts]
     """
     num_layers, num_logical_experts = weight.shape
     assert num_logical_experts % num_groups == 0
     group_size = num_logical_experts // num_groups
     assert num_groups % num_nodes == 0
     groups_per_node = num_groups // num_nodes
     assert num_gpus % num_nodes == 0
     assert num_physical_experts % num_gpus == 0
     phy_experts_per_gpu = num_physical_experts // num_gpus
 
     def inverse(perm: torch.Tensor) -> torch.Tensor:
         inv = torch.empty_like(perm)
         inv.scatter_(
             1,
             perm,
             torch.arange(perm.size(1), dtype=torch.int64,
                          device=perm.device).expand(perm.shape),
         )
         return inv
 
     # Step 1: pack groups to nodes
     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)
     group_pack_index, group_rank_in_pack = balanced_packing(
         tokens_per_group, num_nodes)
     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *
                  group_size).unsqueeze(-1) +
                 torch.arange(group_size,
                              dtype=torch.int64,
                              device=group_pack_index.device)).flatten(-2)
     mlog2log = inverse(log2mlog)
 
     # Step 2: construct redundant experts within nodes
     # [num_layers * num_nodes, num_logical_experts // num_nodes]
     tokens_per_mlog = weight.gather(-1, mlog2log).view(
         -1, num_logical_experts // num_nodes)
     phy2mlog, phyrank, mlogcnt = replicate_experts(
         tokens_per_mlog, num_physical_experts // num_nodes)
 
     # Step 3: pack physical_experts to GPUs
     # [num_layers * num_nodes, num_physical_experts // num_nodes]
     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)
     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,
                                                 num_gpus // num_nodes)
     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack
     pphy2phy = inverse(phy2pphy)
 
     pphy2mlog = phy2mlog.gather(
         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]
     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(
         0,
         num_logical_experts,
         num_logical_experts // num_nodes,
         device=group_pack_index.device,
     ).view(1, -1, 1)).flatten(-2)
     pphy2log = mlog2log.gather(-1, pphy2mlog)
     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)
     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)
     return pphy2log, pphyrank, logcnt
 
 
 def rebalance_experts(
     weight: torch.Tensor,
     num_replicas: int,
     num_groups: int,
     num_nodes: int,
     num_gpus: int,
 ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
     """
     Entry point for expert-parallelism load balancer.
 
     Parameters:
         weight: [layers, num_logical_experts], the load statistics for all
             logical experts
         num_replicas: number of physical experts, must be a multiple of
             `num_gpus`
         num_groups: number of expert groups
         num_nodes: number of server nodes, where the intra-node network
             (e.g, NVLink) is faster
         num_gpus: number of GPUs, must be a multiple of `num_nodes`
 
     Returns:
         physical_to_logical_map: [layers, num_replicas], the expert index of
             each replica
         logical_to_physical_map: [layers, num_logical_experts, X], the replica
             indices for each expert
         expert_count: [layers, num_logical_experts], number of physical
             replicas for each logical expert
     """
     num_layers, num_logical_experts = weight.shape
     weight = weight.float().cpu()
     if num_groups % num_nodes == 0:
         # use hierarchical load-balance policy
         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
             weight, num_replicas, num_groups, num_nodes, num_gpus)
     else:
         # use global load-balance policy
         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
             weight, num_replicas, 1, 1, num_gpus)
     num_redundant_experts = num_replicas - num_logical_experts
     maxlogcnt = num_redundant_experts + 1
     log2phy: torch.Tensor = torch.full(
         (num_layers, num_logical_experts, maxlogcnt),
         -1,
         dtype=torch.int64,
         device=logcnt.device,
     )
     log2phy.view(num_layers, -1).scatter_(
         -1,
         phy2log * maxlogcnt + phyrank,
         torch.arange(num_replicas, dtype=torch.int64,
                      device=log2phy.device).expand(num_layers, -1),
     )
     return phy2log, log2phy, logcnt
 
 
 # EVOLVE-BLOCK-END
 
 
 # This part remains fixed (not evolved)
 def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,
              num_nodes: int, num_gpus: int):
     """Run the expert parallelism load balancer"""
     phy2log, log2phy, logcnt = rebalance_experts(
         weight, num_replicas, num_groups, num_nodes, num_gpus
     )
     return phy2log, log2phy, logcnt
 
 
 __all__ = ["rebalance_experts", "run_eplb"]