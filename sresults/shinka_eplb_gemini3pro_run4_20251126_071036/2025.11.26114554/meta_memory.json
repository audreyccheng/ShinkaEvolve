{
  "unprocessed_programs": [
    {
      "id": "e65b7f45-1dfb-45da-94c0-43b00087cd96",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport heapq\nimport random\nimport bisect\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    # Increased to 10 since speed is high and we want better balance\n    num_restarts = 10\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Hybrid (Pool-and-Split + Swap)\n            for _ in range(50):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n\n                improvement_found = False\n\n                # --- Strategy A: Pool-and-Split ---\n                p1, p2 = max_p, min_p\n\n                # Pool items from Max and Min packs\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending for LPT\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n                possible = True\n\n                for idx, w in pooled_items:\n                    # Best Fit (Greedy)\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if possible:\n                    old_local_max = max(pack_weights[p1], pack_weights[p2])\n                    new_local_max = max(t_weights[0], t_weights[1])\n                    old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                    new_spread = abs(t_weights[0] - t_weights[1])\n\n                    # Strict improvement in local max or spread\n                    if new_local_max < old_local_max - 1e-6 or \\\n                       (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                        current_packs[p1] = t_packs[0]\n                        pack_weights[p1] = t_weights[0]\n                        current_packs[p2] = t_packs[1]\n                        pack_weights[p2] = t_weights[1]\n                        improvement_found = True\n\n                # --- Strategy B: Single Item Swap ---\n                # If Pool-and-Split failed to improve (e.g. LPT is stuck), try a precise single swap.\n                if not improvement_found:\n                    # We want to swap u in Max, v in Min such that w_u > w_v\n                    # Target delta: (max_val - min_val) / 2\n                    target = diff / 2.0\n\n                    # Prepare items in Min pack for binary search: (weight, index_in_pack)\n                    # We need to sort min pack items by weight\n                    min_items = []\n                    for i_v, idx_v in enumerate(current_packs[min_p]):\n                        min_items.append((row_w[idx_v], i_v))\n                    min_items.sort(key=lambda x: x[0])\n                    min_weights = [x[0] for x in min_items]\n\n                    best_swap = None\n                    best_gap = diff # Gap from target\n\n                    # Iterate items in Max pack\n                    for i_u, idx_u in enumerate(current_packs[max_p]):\n                        w_u = row_w[idx_u]\n                        # We want w_u - w_v approx target  =>  w_v approx w_u - target\n                        target_v = w_u - target\n\n                        # Find insertion point\n                        pos = bisect.bisect_left(min_weights, target_v)\n\n                        # Check neighbors\n                        candidates = []\n                        if pos < len(min_weights): candidates.append(pos)\n                        if pos > 0: candidates.append(pos - 1)\n\n                        for c in candidates:\n                            w_v = min_weights[c]\n                            delta = w_u - w_v\n\n                            # Must reduce max (delta > 0) and not flip order too much (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (i_u, min_items[c][1], delta) # (idx_in_max, idx_in_min, delta)\n                                    if gap < 1e-6: break\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        i_u, i_v, delta = best_swap\n\n                        # Perform Swap\n                        u = current_packs[max_p][i_u]\n                        v = current_packs[min_p][i_v]\n\n                        current_packs[max_p][i_u] = v\n                        current_packs[min_p][i_v] = u\n                        pack_weights[max_p] -= delta\n                        pack_weights[min_p] += delta\n                        improvement_found = True\n\n                if not improvement_found:\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n\n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Move to CPU for efficient priority queue operations\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n\n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n\n        # Priority queue stores (-score, expert_idx, current_count)\n        # Score = weight / count\n        # Python heapq is a min-heap, so we store negative score to simulate max-heap\n        pq = []\n        for i in range(num_log):\n            heapq.heappush(pq, (-w_row[i], i, 1))\n\n        # Assign replicas one by one\n        for r_idx in range(num_log, num_phy):\n            score_neg, expert_idx, count = heapq.heappop(pq)\n\n            # Assign the new replica\n            phy2log_cpu[layer_idx, r_idx] = expert_idx\n            rank_cpu[layer_idx, r_idx] = count\n\n            # Update count and push back with new score\n            new_count = count + 1\n            logcnt_cpu[layer_idx, expert_idx] = new_count\n            new_score_neg = -w_row[expert_idx] / new_count\n            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "f4f85777-ce14-4dd4-8832-17472b54e6bb",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "da819c1e-f45a-4d44-bd1d-891b9efb616b"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 90,
      "timestamp": 1764180155.4818194,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,394 +1,453 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n import heapq\n import random\n+import bisect\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n \n     Parameters:\n         weight: [X, n], the weight of each item\n         num_packs: number of packs\n \n     Returns:\n         pack_index: [X, n], the pack index of each item\n         rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     # Optimization: handle trivial case efficiently\n     if groups_per_pack == 1:\n         pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n                                   device=weight.device).expand(num_layers, -1)\n         rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n     # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n \n     # Pre-allocate result tensors on CPU\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n \n     # Number of random restarts to escape local optima\n-    num_restarts = 4\n+    # Increased to 10 since speed is high and we want better balance\n+    num_restarts = 10\n \n     for i in range(num_layers):\n         row_w = weight_cpu[i].tolist()\n \n         # Original items (index, weight)\n         original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n \n         best_diff = float('inf')\n         best_packs = None\n \n         for attempt in range(num_restarts):\n             # 1. Initialization Strategy\n             current_packs = [[] for _ in range(num_packs)]\n             pack_weights = [0.0] * num_packs\n \n             if attempt == 0:\n                 # Deterministic LPT\n                 items = original_items\n             else:\n                 # Randomized LPT\n                 noise = torch.rand(num_groups).tolist()\n                 noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                                for k, (idx, w) in enumerate(original_items)]\n                 noisy_items.sort(key=lambda x: x[2], reverse=True)\n                 items = [(idx, w) for idx, w, _ in noisy_items]\n \n             # Greedy Phase\n             for idx, w in items:\n                 # Assign to the lightest pack that has space\n                 best_p = -1\n                 min_w = float('inf')\n                 for p in range(num_packs):\n                     if len(current_packs[p]) < groups_per_pack:\n                         if pack_weights[p] < min_w:\n                             min_w = pack_weights[p]\n                             best_p = p\n                 current_packs[best_p].append(idx)\n                 pack_weights[best_p] += w\n \n-            # 2. Refinement Phase: Pool-and-Split\n-            # Instead of single swaps, pick two packs (Max and Min), pool items, and re-distribute.\n-            for _ in range(30):\n+            # 2. Refinement Phase: Hybrid (Pool-and-Split + Swap)\n+            for _ in range(50):\n                 # Identify Max and Min packs\n                 min_p = 0\n                 max_p = 0\n                 min_val = pack_weights[0]\n                 max_val = pack_weights[0]\n \n                 for p in range(1, num_packs):\n                     val = pack_weights[p]\n                     if val < min_val:\n                         min_val = val\n                         min_p = p\n                     elif val > max_val:\n                         max_val = val\n                         max_p = p\n \n-                if max_val - min_val < 1e-6:\n+                diff = max_val - min_val\n+                if diff < 1e-6:\n                     break\n \n-                # Try to improve by pairing Max Pack with Min Pack\n-                # Only trying Max-Min pair is usually sufficient and fast.\n+                improvement_found = False\n+\n+                # --- Strategy A: Pool-and-Split ---\n                 p1, p2 = max_p, min_p\n \n-                # Pool items\n+                # Pool items from Max and Min packs\n                 pooled_items = []\n                 for idx in current_packs[p1]:\n                     pooled_items.append((idx, row_w[idx]))\n                 for idx in current_packs[p2]:\n                     pooled_items.append((idx, row_w[idx]))\n \n-                # Sort Descending\n+                # Sort Descending for LPT\n                 pooled_items.sort(key=lambda x: x[1], reverse=True)\n \n-                # Re-distribute using constrained greedy into two temp packs\n+                # Re-distribute using constrained greedy\n                 t_packs = [[], []]\n                 t_weights = [0.0, 0.0]\n-\n                 possible = True\n+\n                 for idx, w in pooled_items:\n-                    # Put in valid bin with min weight\n+                    # Best Fit (Greedy)\n                     b_best = -1\n                     b_min = float('inf')\n                     for b in range(2):\n                         if len(t_packs[b]) < groups_per_pack:\n                             if t_weights[b] < b_min:\n                                 b_min = t_weights[b]\n                                 b_best = b\n                     if b_best != -1:\n                         t_packs[b_best].append(idx)\n                         t_weights[b_best] += w\n                     else:\n                         possible = False\n                         break\n \n-                if not possible: break\n-\n-                # Check criteria\n-                old_local_max = max(pack_weights[p1], pack_weights[p2])\n-                new_local_max = max(t_weights[0], t_weights[1])\n-                old_spread = abs(pack_weights[p1] - pack_weights[p2])\n-                new_spread = abs(t_weights[0] - t_weights[1])\n-\n-                # Accept if max load reduced, or if max load unchanged but spread reduced\n-                if new_local_max < old_local_max - 1e-6 or \\\n-                   (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n-                    current_packs[p1] = t_packs[0]\n-                    pack_weights[p1] = t_weights[0]\n-                    current_packs[p2] = t_packs[1]\n-                    pack_weights[p2] = t_weights[1]\n-                else:\n-                    # If Pool-and-Split on Max/Min didn't help, we are likely in a local optimum\n-                    # reachable by this move.\n+                if possible:\n+                    old_local_max = max(pack_weights[p1], pack_weights[p2])\n+                    new_local_max = max(t_weights[0], t_weights[1])\n+                    old_spread = abs(pack_weights[p1] - pack_weights[p2])\n+                    new_spread = abs(t_weights[0] - t_weights[1])\n+\n+                    # Strict improvement in local max or spread\n+                    if new_local_max < old_local_max - 1e-6 or \\\n+                       (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n+                        current_packs[p1] = t_packs[0]\n+                        pack_weights[p1] = t_weights[0]\n+                        current_packs[p2] = t_packs[1]\n+                        pack_weights[p2] = t_weights[1]\n+                        improvement_found = True\n+\n+                # --- Strategy B: Single Item Swap ---\n+                # If Pool-and-Split failed to improve (e.g. LPT is stuck), try a precise single swap.\n+                if not improvement_found:\n+                    # We want to swap u in Max, v in Min such that w_u > w_v\n+                    # Target delta: (max_val - min_val) / 2\n+                    target = diff / 2.0\n+\n+                    # Prepare items in Min pack for binary search: (weight, index_in_pack)\n+                    # We need to sort min pack items by weight\n+                    min_items = []\n+                    for i_v, idx_v in enumerate(current_packs[min_p]):\n+                        min_items.append((row_w[idx_v], i_v))\n+                    min_items.sort(key=lambda x: x[0])\n+                    min_weights = [x[0] for x in min_items]\n+\n+                    best_swap = None\n+                    best_gap = diff # Gap from target\n+\n+                    # Iterate items in Max pack\n+                    for i_u, idx_u in enumerate(current_packs[max_p]):\n+                        w_u = row_w[idx_u]\n+                        # We want w_u - w_v approx target  =>  w_v approx w_u - target\n+                        target_v = w_u - target\n+\n+                        # Find insertion point\n+                        pos = bisect.bisect_left(min_weights, target_v)\n+\n+                        # Check neighbors\n+                        candidates = []\n+                        if pos < len(min_weights): candidates.append(pos)\n+                        if pos > 0: candidates.append(pos - 1)\n+\n+                        for c in candidates:\n+                            w_v = min_weights[c]\n+                            delta = w_u - w_v\n+\n+                            # Must reduce max (delta > 0) and not flip order too much (delta < diff)\n+                            if 0 < delta < diff:\n+                                gap = abs(delta - target)\n+                                if gap < best_gap:\n+                                    best_gap = gap\n+                                    best_swap = (i_u, min_items[c][1], delta) # (idx_in_max, idx_in_min, delta)\n+                                    if gap < 1e-6: break\n+                        if best_swap and best_gap < 1e-6: break\n+\n+                    if best_swap:\n+                        i_u, i_v, delta = best_swap\n+\n+                        # Perform Swap\n+                        u = current_packs[max_p][i_u]\n+                        v = current_packs[min_p][i_v]\n+\n+                        current_packs[max_p][i_u] = v\n+                        current_packs[min_p][i_v] = u\n+                        pack_weights[max_p] -= delta\n+                        pack_weights[min_p] += delta\n+                        improvement_found = True\n+\n+                if not improvement_found:\n                     break\n \n             # Check global result\n             curr_diff = max(pack_weights) - min(pack_weights)\n             if curr_diff < best_diff:\n                 best_diff = curr_diff\n                 best_packs = [list(p) for p in current_packs]\n                 if best_diff < 1e-6: break\n \n         # Fill result tensors\n         for p in range(num_packs):\n             for r, idx in enumerate(best_packs[p]):\n                 pack_index[i, idx] = p\n                 rank_in_pack[i, idx] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n \n     Parameters:\n         weight: [X, num_log]\n         num_phy: total number of experts after replication\n \n     Returns:\n         phy2log: [X, num_phy], logical expert id of each physical expert\n         rank: [X, num_phy], the replica rank\n         logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n \n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n \n     if num_redundant == 0:\n         return phy2log, rank, logcnt\n \n     # Move to CPU for efficient priority queue operations\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     phy2log_cpu = phy2log.to(\"cpu\")\n     rank_cpu = rank.to(\"cpu\")\n     logcnt_cpu = logcnt.to(\"cpu\")\n \n     for layer_idx in range(n):\n         w_row = weight_cpu[layer_idx].tolist()\n \n         # Priority queue stores (-score, expert_idx, current_count)\n         # Score = weight / count\n         # Python heapq is a min-heap, so we store negative score to simulate max-heap\n         pq = []\n         for i in range(num_log):\n             heapq.heappush(pq, (-w_row[i], i, 1))\n \n         # Assign replicas one by one\n         for r_idx in range(num_log, num_phy):\n             score_neg, expert_idx, count = heapq.heappop(pq)\n \n             # Assign the new replica\n             phy2log_cpu[layer_idx, r_idx] = expert_idx\n             rank_cpu[layer_idx, r_idx] = count\n \n             # Update count and push back with new score\n             new_count = count + 1\n             logcnt_cpu[layer_idx, expert_idx] = new_count\n             new_score_neg = -w_row[expert_idx] / new_count\n             heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n \n     return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Parameters:\n         weight: [num_moe_layers, num_logical_experts]\n         num_physical_experts: number of physical experts after replication\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n         (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [num_moe_layers, num_physical_experts]\n         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n         logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n \n     Parameters:\n         weight: [layers, num_logical_experts], the load statistics for all\n             logical experts\n         num_replicas: number of physical experts, must be a multiple of\n             `num_gpus`\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n             (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [layers, num_replicas], the expert index of\n             each replica\n         logical_to_physical_map: [layers, num_logical_experts, X], the replica\n             indices for each expert\n         expert_count: [layers, num_logical_experts], number of physical\n             replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n \n \n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385886499905,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.3110771772999811,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.055061325,
        0.022026828,
        0.013972156,
        -0.039641395,
        -0.026174812,
        0.016695347,
        -0.0086349305,
        -0.008290223,
        -0.02569222,
        0.028105175,
        0.030701974,
        0.022670282,
        -0.011254709,
        -0.023738876,
        0.016994094,
        0.016948134,
        -0.01035847,
        0.015132672,
        -0.0058341795,
        0.052809235,
        0.007859338,
        -0.00883601,
        0.02695615,
        -0.041893486,
        -0.0024905137,
        0.010191861,
        0.06186356,
        -0.04375491,
        0.030035539,
        -0.047201987,
        0.07799588,
        -0.010295273,
        0.01586805,
        0.0025853084,
        -0.016086364,
        0.03228763,
        -0.0065264674,
        0.011823477,
        0.016511504,
        0.061725676,
        0.026473558,
        -0.02344013,
        -0.04469711,
        0.038929,
        -0.03720546,
        0.031667154,
        0.006331133,
        -0.006767763,
        0.077766076,
        0.005182107,
        0.037228443,
        0.01591401,
        -0.0017723725,
        0.06250701,
        0.027208935,
        0.043203376,
        0.021153567,
        0.021590197,
        0.018740613,
        -0.04467413,
        0.053820375,
        -0.015373968,
        0.07013655,
        0.04026187,
        -0.031575233,
        0.0045271623,
        -0.036010474,
        0.027162975,
        0.023129893,
        -0.012397991,
        -0.039595436,
        0.046696417,
        -0.022497928,
        -0.027071051,
        0.0014750621,
        0.0064058197,
        -0.019533442,
        0.043640006,
        -0.028909493,
        -0.042766746,
        -0.029461026,
        -0.006980333,
        0.050695024,
        0.021050155,
        0.013489565,
        -0.07436496,
        -0.02168212,
        -0.03718248,
        -0.03451674,
        -0.024635118,
        0.034838468,
        -0.04681132,
        -0.00018061252,
        0.03311493,
        0.04203137,
        -0.03329877,
        0.059979156,
        0.014523689,
        0.031965904,
        0.05699169,
        -0.013845763,
        0.016729819,
        -0.055383053,
        -0.0003590706,
        0.028633727,
        0.008732597,
        0.00519647,
        -0.0027432996,
        0.011559201,
        -0.016614916,
        -0.03971034,
        0.019246185,
        0.03001256,
        0.009450738,
        0.014891377,
        0.006336878,
        -0.042353097,
        -0.023129893,
        0.010703177,
        -0.025577318,
        -0.027783448,
        -0.03709056,
        0.024910884,
        -0.026841247,
        0.008227026,
        -0.03725142,
        0.011294926,
        -0.03235657,
        0.010525078,
        0.001291936,
        0.041295994,
        0.02431339,
        0.008272987,
        -0.022164712,
        -0.024658097,
        0.004754095,
        -0.022888597,
        0.007732945,
        -0.0059002484,
        -0.020670976,
        -0.024635118,
        0.030219384,
        -0.012168185,
        -0.009134756,
        -0.048856586,
        0.053130962,
        -0.0014779347,
        0.013972156,
        -0.037297383,
        0.031529274,
        0.015936991,
        -0.036516044,
        -0.011576436,
        -0.011553456,
        0.00025440153,
        -0.010680197,
        0.0067390376,
        0.020084973,
        0.082546026,
        -0.034723565,
        -0.02789835,
        0.02746172,
        -0.025370494,
        0.021992357,
        0.034838468,
        0.028817572,
        -0.05207386,
        0.0045530153,
        -0.057681102,
        -0.0609903,
        -0.003564853,
        -0.021130588,
        -0.005230941,
        -0.01412153,
        0.004119258,
        0.015661225,
        -0.023807818,
        -0.03713652,
        -0.026680384,
        -0.039457552,
        -0.023302246,
        -0.011392592,
        -0.01587954,
        -0.00686543,
        -0.04775352,
        0.027990272,
        -0.029461026,
        -0.01147877,
        -0.009364562,
        -0.0050528417,
        0.0123635195,
        0.04563931,
        -0.03669989,
        0.034240972,
        -0.0020452663,
        -0.018878497,
        0.05437191,
        0.017407743,
        0.0033781363,
        -0.0066586053,
        -0.03984822,
        -0.012949523,
        0.039227746,
        -0.040032066,
        0.046052963,
        0.033689443,
        -0.011461535,
        0.012110733,
        0.013857253,
        -0.0050930576,
        0.032448493,
        -0.023761857,
        0.037665073,
        -0.0036481575,
        -0.026772305,
        -0.029392084,
        -0.04995965,
        0.017637549,
        0.00094291946,
        0.07004462,
        -0.01862571,
        0.018212061,
        -0.025577318,
        0.005592884,
        -0.041387916,
        0.020004543,
        0.048902545,
        -0.018441867,
        0.004455348,
        0.007078,
        -0.029461026,
        -0.000960873,
        -0.010301018,
        -0.028702669,
        0.032931086,
        -0.030747935,
        -0.033942226,
        0.017982256,
        -0.015098201,
        -0.03587259,
        0.019533442,
        0.04281271,
        0.010094193,
        -0.045869116,
        0.0093186,
        0.01815461,
        -0.042169254,
        -0.015063731,
        0.0053400984,
        -0.022980519,
        0.020877803,
        -0.045892097,
        0.022842636,
        -0.060346846,
        -0.01638511,
        0.03228763,
        -0.022451967,
        -0.05437191,
        -0.018062688,
        -0.02966785,
        0.015936991,
        -0.0163966,
        -0.0029012905,
        -0.022831146,
        -0.021176549,
        -0.0019691433,
        -0.0040187184,
        0.034355875,
        -0.048718702,
        -0.018395906,
        0.03191994,
        0.016258718,
        -0.013317211,
        0.03534404,
        -0.042353097,
        -0.0194645,
        0.0034442053,
        -0.01587954,
        -0.030656014,
        -0.043042514,
        -0.025508376,
        0.00054542825,
        0.039825242,
        -0.001210068,
        0.013317211,
        -0.0039670123,
        -0.00441226,
        0.027668545,
        0.0092036985,
        -0.02162467,
        0.0038061487,
        -0.020556075,
        0.0371595,
        0.013029954,
        -0.0092036985,
        -0.01855677,
        -0.05758918,
        -0.015626753,
        -0.0004642783,
        -0.0057537477,
        0.011093846,
        -0.0050040083,
        -0.007790396,
        0.0071584317,
        -0.0070090583,
        -0.02426743,
        -0.016580446,
        0.017269861,
        -0.01674131,
        -0.022808166,
        -0.013317211,
        0.0125473635,
        -0.01945301,
        -0.0008423797,
        -0.028679688,
        0.004449603,
        0.03097774,
        0.0028768738,
        -0.0147534935,
        -0.05230366,
        -0.05395826,
        -0.040767442,
        0.042261176,
        0.025278572,
        0.00049587653,
        0.022693263,
        -0.044375382,
        0.017798413,
        -0.0075605907,
        -0.01643107,
        0.006377094,
        0.042468,
        0.030839857,
        0.02431339,
        0.011903909,
        -0.040445715,
        0.03322983,
        -0.002628397,
        0.044834994,
        0.020602036,
        -0.056945726,
        0.023348209,
        -0.012949523,
        -0.022451967,
        -0.046259787,
        0.021463806,
        0.05965743,
        0.02780643,
        0.026565481,
        0.07555995,
        -0.03745825,
        -0.018821046,
        -0.01412153,
        0.016925152,
        0.011076611,
        -0.023715897,
        0.0017781177,
        0.0043289554,
        -0.04515672,
        0.0058140713,
        -0.027484702,
        -0.0070148036,
        0.027967293,
        -0.0047713304,
        -0.010065467,
        0.06466718,
        0.031046681,
        0.015534831,
        0.009077305,
        0.008060417,
        0.039963122,
        -0.0022736352,
        -0.024106566,
        0.007164177,
        -0.010559549,
        -0.013937685,
        0.023497581,
        0.053636532,
        -0.029116318,
        0.004231288,
        0.024175506,
        0.020464152,
        -0.022635812,
        0.011731555,
        0.019636855,
        0.03587259,
        -0.01193838,
        0.017051546,
        -0.07321593,
        0.008531518,
        0.052027896,
        -0.01412153,
        -0.020107955,
        -0.04419154,
        0.037228443,
        -0.012915052,
        -0.0363322,
        -0.024841942,
        0.046144884,
        0.009151991,
        -0.010743393,
        0.0052596666,
        -0.038239583,
        -0.018671673,
        -0.025531357,
        0.011869438,
        0.04697218,
        0.017614568,
        -0.0034872938,
        0.04377789,
        0.02833498,
        -0.033068966,
        0.01128918,
        0.0058657774,
        0.013018465,
        -0.036975656,
        0.0046650455,
        0.040399753,
        0.00473686,
        -0.008795794,
        -0.007439943,
        -0.008887716,
        0.018395906,
        -0.00432321,
        -0.017063037,
        0.015167143,
        0.016235737,
        -0.015419928,
        0.012915052,
        -0.062461052,
        -0.013133367,
        0.0033781363,
        0.06434546,
        -0.029323142,
        0.0221762,
        0.038653232,
        -0.007078,
        0.02833498,
        -0.000109965375,
        -0.0020064865,
        0.008140849,
        -0.014224942,
        -0.014224942,
        -0.01988964,
        0.022474948,
        -0.013638939,
        0.0059634447,
        -0.051568285,
        0.052441545,
        -0.006762018,
        0.015672714,
        -0.015684204,
        0.05432595,
        0.005127528,
        -0.021613179,
        -0.051844053,
        0.0724346,
        0.032563396,
        0.05087887,
        -0.023509072,
        0.042513963,
        0.016408091,
        0.0026154704,
        -0.027048072,
        0.052717313,
        0.018821046,
        0.0071929027,
        -0.0043031024,
        0.00838789,
        0.024658097,
        0.061220106,
        -0.049224272,
        -0.0006553039,
        0.038101703,
        -0.028105175,
        0.012593324,
        -0.014270903,
        0.065632366,
        0.029966598,
        -0.048810624,
        0.02787537,
        -0.046995163,
        -0.032471474,
        -0.0406985,
        0.027139993,
        0.027668545,
        0.034470778,
        0.0015238957,
        0.0005755902,
        0.027714506,
        0.028656708,
        -0.01373086,
        0.008968147,
        -0.00994482,
        -0.0017651912,
        -0.007428453,
        -0.016419582,
        -0.024290409,
        0.003823384,
        0.04853486,
        0.007934025,
        -0.084936,
        -0.060346846,
        -0.022256633,
        0.018441867,
        -0.033597518,
        -0.030816877,
        0.0009098849,
        -0.0053544613,
        0.03789488,
        -0.01945301,
        -0.0090026185,
        0.027048072,
        0.030426208,
        -0.0069171363,
        0.038377468,
        -0.0059059937,
        0.010496352,
        0.0065322127,
        0.031713117,
        -0.028955454,
        -0.021854473,
        -0.05087887,
        0.023164364,
        0.029989578,
        -0.034378856,
        -0.016660877,
        -0.05529113,
        0.016120834,
        -0.0066413702,
        -0.016879192,
        -0.013133367,
        -0.052993078,
        0.03001256,
        -0.019142773,
        0.029805733,
        -0.0026097253,
        -0.040422734,
        -0.03001256,
        -0.040123988,
        0.006141544,
        0.015075221,
        0.020659488,
        0.022854127,
        0.011128317,
        -0.039158806,
        0.06839003,
        0.029024396,
        0.0273698,
        0.026450578,
        0.008290223,
        -0.043961734,
        0.0014226378,
        -0.0023282138,
        -0.029254202,
        -0.018326964,
        -0.012535874,
        -0.047569677,
        0.028403923,
        0.048902545,
        0.021532746,
        -0.0044869464,
        0.0099678,
        -0.0003474008,
        0.0002786388,
        0.009783956,
        0.021211019,
        -0.041456856,
        0.017235389,
        0.0035907063,
        -0.0108927665,
        0.012018812,
        0.009962055,
        -0.06498891,
        0.024106566,
        -0.0042169252,
        0.018935949,
        -0.025025785,
        -0.0056934236,
        -0.009376052,
        -0.028518824,
        -0.022049809,
        -0.015971461,
        -0.027990272,
        -0.055934586,
        -0.0076410226,
        -0.03182802,
        -0.011536221,
        -0.0048373993,
        -0.027254896,
        -0.005248176,
        -0.000762666,
        0.03709056,
        -0.015822088,
        0.015247575,
        -0.0064977417,
        -0.039641395,
        0.012317559,
        0.026266733,
        0.009393287,
        -0.018683162,
        0.06241509,
        0.0027361182,
        0.020188386,
        -0.028312,
        0.0022362918,
        0.008140849,
        0.0060438765,
        0.0031942923,
        -0.031644177,
        -0.009077305,
        -0.018028218,
        -0.030150441,
        -0.009048579,
        -0.008336184,
        0.00407617,
        0.0547396,
        0.005256794,
        0.013248269,
        -0.02071694,
        -0.009134756,
        0.043594044,
        0.013409133,
        -0.016902173,
        -0.0014836797,
        -0.010846805,
        -0.011668359,
        -0.003984248,
        -0.026772305,
        0.015684204,
        -0.037848916,
        -0.017384764,
        -0.022486439,
        0.027139993,
        9.0620444e-05,
        0.067241,
        0.023853779,
        0.03493039,
        0.009106031,
        -0.012731208,
        0.027921332,
        -0.0066126445,
        0.012110733,
        -0.040606577,
        0.0121796755,
        0.022153221,
        -0.0034413328,
        -0.006543703,
        0.008520028,
        -0.011720065,
        -0.0051878523,
        -0.018097159,
        0.03534404,
        0.03702162,
        0.029805733,
        -0.01637362,
        -0.013202309,
        -0.035504904,
        -0.029920636,
        -0.00023375497,
        -0.035137214,
        -0.009898859,
        -0.010984688,
        -0.02165914,
        0.014512198,
        0.027323838,
        0.020981215,
        0.002700211,
        0.00641731,
        0.048810624,
        -0.0058226893,
        0.029093338,
        0.024956845,
        -0.044903934,
        -0.03840045,
        -0.017982256,
        -0.027714506,
        0.014293883,
        0.0011353813,
        0.020303288,
        0.010680197,
        -0.02126847,
        -0.031942923,
        -0.008215535,
        -0.0106572155,
        0.027484702,
        0.021256981,
        -0.0032402533,
        0.0363322,
        -0.01898191,
        0.016752798,
        -0.011346632,
        -0.037756994,
        -0.015259065,
        0.015707185,
        0.041847527,
        0.008313203,
        0.009646073,
        -0.01901638,
        -0.04375491,
        -0.011984341,
        -6.261294e-05,
        -0.025416454,
        -0.011674104,
        -0.039319668,
        -0.018338455,
        -0.045823157,
        0.0476616,
        0.021946397,
        -0.0011813423,
        -0.04099725,
        0.0028294765,
        -0.02077439,
        -0.018223552,
        -0.06857387,
        0.0054176576,
        -0.0015540576,
        0.012225636,
        0.024359351,
        -0.040928304,
        -0.006894156,
        0.0033206851,
        -0.03667691,
        0.00029677188,
        0.04904043,
        0.015971461,
        0.011628143,
        0.0031770568,
        0.006308153,
        -0.002231983,
        0.011271945,
        -0.014385805,
        0.01988964,
        -0.034309916,
        0.039825242,
        -0.0073652565,
        -0.00057523116,
        -0.034470778,
        -0.024060603,
        0.010519333,
        -0.008543008,
        -0.023968682,
        0.013547016,
        -0.0056015016,
        0.010082703,
        0.0040302086,
        -0.005334353,
        0.03401117,
        -0.015936991,
        0.021613179,
        -0.0326783,
        0.006451781,
        -0.026864227,
        -0.0017192301,
        0.043548085,
        0.032011863,
        0.01681025,
        -0.0076237875,
        -0.0037084813,
        0.00799722,
        -0.019510461,
        -0.017832883,
        -0.023118403,
        0.016488522,
        0.0118119875,
        0.004297357,
        -0.049316194,
        -0.003972757,
        0.012788659,
        -0.04249098,
        -0.023646954,
        -0.009881623,
        0.049178313,
        0.05000561,
        0.026841247,
        -0.037940837,
        0.0151211815,
        -0.05078695,
        0.008502793,
        -0.022406006,
        -0.015534831,
        -0.0220613,
        -0.0317361,
        0.00064955873,
        0.00342697,
        0.005888758,
        -0.05800283,
        -0.022854127,
        -0.010387195,
        -0.010611255,
        -0.061587792,
        -0.016568955,
        0.0014298192,
        -0.023267776,
        -0.01196136,
        0.01906234,
        -0.036791813,
        -0.051844053,
        0.008881971,
        0.017637549,
        -0.0044409856,
        0.002506313,
        0.021406354,
        -0.0010197605,
        -0.012581835,
        -0.012926542,
        -0.05666996,
        0.005216578,
        -0.039388612,
        0.017476685,
        0.018499319,
        -0.00015969666,
        -0.0344478,
        0.0059864256,
        0.065172754,
        -0.023761857,
        -0.044857975,
        -0.044030674,
        0.02962189,
        -0.010174625,
        -0.027071051,
        -0.04821313,
        0.044834994,
        0.0099563105,
        -0.048029285,
        -0.014397295,
        -0.013638939,
        0.0014671625,
        0.011019159,
        -0.015454399,
        0.00040251817,
        -0.023555033,
        0.007652513,
        0.012696737,
        0.0071986476,
        0.011984341,
        0.0054234024,
        -0.0077559254,
        -0.005452128,
        0.025508376,
        0.031253505,
        0.009439249,
        0.00020736328,
        -0.026795287,
        0.017740961,
        0.010036742,
        0.040032066,
        0.036975656,
        -0.026933169,
        -0.016235737,
        -0.016477032,
        0.012949523,
        0.025324533,
        -0.012397991,
        -0.0058226893,
        0.019154264,
        0.018499319,
        -0.006934372,
        0.01459263,
        -0.006670096,
        -0.016074874,
        -0.041847527,
        0.012811639,
        -0.028656708,
        0.00773869,
        -0.024543194,
        0.026289715,
        0.033873286,
        -0.0028208587,
        9.12937e-05,
        0.011461535,
        -0.029920636,
        0.01992411,
        0.0194645,
        -0.01018037,
        -0.016258718,
        -0.014983299,
        0.017740961,
        -0.04111215,
        -0.014868396,
        -0.0012596197,
        -0.016419582,
        -0.013719371,
        0.008301713,
        -0.0045645055,
        0.019567912,
        0.006239211,
        -0.0039497768,
        0.034723565,
        0.02438233,
        -0.0018513681,
        0.0076697483,
        0.015982952,
        0.019912621,
        0.027507681,
        0.028403923,
        -0.007692729,
        -0.00281655,
        0.028266039,
        -0.0038463646,
        -0.010318253,
        0.0027088288,
        -0.01594848,
        0.04653555,
        -0.017131977,
        -0.012938033,
        -0.007686984,
        0.010967453,
        0.027277878,
        -0.05230366,
        0.07261844,
        -0.009192208,
        -0.033023007,
        -0.010094193,
        0.006899901,
        -0.024083585,
        0.013960666,
        0.02566924,
        0.011685594,
        -0.002333959,
        0.026312694,
        -0.021578709,
        0.005374569,
        0.011007668,
        0.008686637,
        -0.002583872,
        0.009255405,
        -0.03674585,
        0.05317692,
        -0.014454747,
        0.013305721,
        -0.02295754,
        0.023807818,
        -0.0020524478,
        0.0031282231,
        -0.010036742,
        -0.012903562,
        -0.007991476,
        -0.014879886,
        0.0037400795,
        -0.051430404,
        -0.008996873,
        -0.0017695,
        0.016637895,
        -0.033068966,
        -0.031138605,
        -0.0027748977,
        -0.012214147,
        -0.014351334,
        -0.017143467,
        0.03274724,
        -0.050097533,
        0.055107284,
        0.0041566016,
        -0.033344734,
        0.035573844,
        0.008474067,
        -0.0023138511,
        0.0038722176,
        0.022383027,
        0.039986104,
        -0.0023856652,
        -0.023382679,
        0.0042255432,
        0.013213798,
        0.011019159,
        0.0061070733,
        -0.0059577,
        -0.045708254,
        0.012696737,
        0.03414905,
        -0.021797022,
        0.022222163,
        -0.005770983,
        0.012214147,
        -0.04462817,
        0.008422361,
        -0.014247922,
        0.05611843,
        -0.015328007,
        0.016591934,
        0.0048575075,
        -0.04168666,
        0.029484006,
        0.054188065,
        -0.005546923,
        0.045202684,
        0.0038607272,
        0.0074973945,
        -0.025554338,
        0.0557967,
        0.02872565,
        0.008893461,
        -0.005374569,
        0.010542314,
        0.0106744515,
        -0.012099244,
        -0.017970767,
        -0.023164364,
        -0.006279427,
        -0.036493067,
        0.006980333,
        0.02835796,
        -0.003228763,
        0.0103239985,
        0.0040187184,
        0.017752452,
        -0.01768351,
        0.0045989766,
        0.004791438,
        0.027921332,
        -0.0362173,
        -0.019315127,
        0.015396948,
        -0.04028485,
        -0.010433156,
        -0.031529274,
        0.012168185,
        -0.029139299,
        -0.008020202,
        -0.0055095796,
        -0.044375382,
        0.0020739918,
        -0.013041445,
        -0.014374315,
        0.01147877,
        0.024635118,
        -0.045294605,
        0.020602036,
        -0.020061994,
        0.028197097,
        -0.0068481946,
        -0.030770916,
        0.019625364,
        -0.013409133,
        -0.040790424,
        -0.00407617,
        0.026680384,
        0.023302246,
        0.0011375357,
        -0.025117708,
        0.032011863,
        -0.024727039,
        0.016798759,
        0.028105175,
        -0.0059864256,
        -0.0062219757,
        0.013478075,
        -0.014087059,
        -0.010301018,
        -0.0593357,
        -0.0045731235,
        -0.01127769,
        0.029369105,
        0.026358657,
        0.021302942,
        -0.0013515418,
        0.0024344989,
        -0.0027188826,
        -0.008663656,
        0.021831494,
        0.0043174652,
        -0.043456163,
        -0.018005237,
        0.011668359,
        0.011398338,
        -0.026772305,
        -0.02122251,
        -0.00018887114,
        0.001901638,
        -5.861828e-05,
        0.0070090583,
        -0.013029954,
        0.022049809,
        0.009249659,
        -0.0043921517,
        0.0033896267,
        0.019544931,
        -0.009870133,
        -0.047477752,
        -0.0065264674,
        0.003941159,
        0.0018212062,
        -0.0049551744,
        -0.014994789,
        0.041732624,
        0.03812468,
        0.0015167143,
        0.01594848,
        -0.024129545,
        -0.003406862,
        0.023313737,
        0.027507681,
        -0.008514282,
        0.014385805,
        -0.024520215,
        0.01903936,
        0.01729284,
        -0.022601342,
        0.0121452045,
        0.0024890776,
        0.003381009,
        -0.0040704245,
        -0.010864041,
        -0.028610747,
        -0.044857975,
        -0.012765679,
        -0.01039294,
        0.027783448,
        -0.0101056835,
        0.029277181,
        -0.015385458,
        0.022406006,
        0.028541805,
        -0.0046506827,
        -0.022704754,
        0.0024057731,
        -0.0046535553,
        0.021234,
        0.019659834,
        -0.021394864,
        0.0021587326,
        -0.027484702,
        0.035941534,
        -0.030724954,
        -0.00409915,
        0.008525773,
        0.023555033,
        0.018246533,
        -0.0027677163,
        0.027300857,
        -0.059473585,
        0.033413675,
        0.020946743,
        -0.009157737,
        -0.019211715,
        -0.031575233,
        0.0097207595,
        -0.006503487,
        0.035114232,
        -0.00055907294,
        -0.020211367,
        0.04203137,
        0.015672714,
        -0.001997869,
        -0.0020883547,
        0.0055210697,
        0.07123961,
        0.0042140526,
        -0.0043002297,
        0.010306763,
        0.011662614,
        0.027645566,
        -0.020188386,
        -0.00519647,
        0.019200224,
        -0.04255992,
        -0.02966785,
        0.030839857,
        -0.004179582,
        -0.021429334,
        -0.0037056087,
        0.01855677,
        -0.043019533,
        0.01681025,
        -0.018775085,
        0.014236432,
        -0.0073537664,
        -0.00062621915,
        -0.004828782,
        -0.02078588,
        0.0010894203,
        -0.03231061,
        0.0027231916,
        -0.022187691,
        -0.016051892,
        0.02075141,
        -0.023578012,
        -0.02603693,
        0.008238516,
        0.006583919,
        -0.0151211815,
        0.014879886,
        0.02033776,
        0.006377094,
        -0.00075620273,
        0.00908305,
        -0.016235737,
        -0.005455001,
        -0.033413675,
        -0.01586805,
        -0.018878497,
        -0.00796275,
        -0.0199356,
        0.017993746,
        0.0069228816,
        0.004515672,
        0.009255405,
        -0.014201961,
        0.0042686313,
        -0.024129545,
        -0.024106566,
        0.003929669,
        0.033459637,
        0.061312027,
        -0.0406985,
        0.011490259,
        -0.0065379576,
        -0.0036309222,
        -0.0064460356,
        0.028105175,
        0.017557116,
        -0.014133019,
        -0.014925848,
        -0.02431339,
        -0.01550036,
        0.029759772,
        -0.029575929,
        -0.001489425,
        -0.0060783476,
        -0.02126847,
        0.029024396,
        -0.003929669,
        -0.013213798,
        0.024359351,
        0.019234695,
        -0.035987493,
        -0.012156695,
        0.009324346,
        -0.0018743486,
        0.012168185,
        -0.03010448,
        -0.027392779,
        0.03316089,
        0.022245143,
        -0.027094033,
        0.0025364747,
        -0.006187505,
        0.021567218,
        0.027254896,
        0.03890602,
        -0.019694306,
        -0.011507495,
        -0.00752612,
        -0.007928279,
        -0.011846458,
        0.023692915,
        -0.013409133,
        0.012570344,
        0.012719718,
        0.019671325,
        -0.023555033,
        0.03771103,
        -0.0033838814,
        -0.006325388,
        -0.04237608,
        -0.04995965,
        0.03725142,
        -0.0032890867,
        0.027599605,
        -0.040330812,
        -0.03897496,
        0.038653232,
        0.04023889,
        0.03683777,
        -0.014707533,
        -0.016591934,
        0.021567218,
        -0.011536221,
        0.0073939823,
        0.0065092323,
        -0.034263954,
        0.027783448,
        0.00399861,
        0.035757687,
        -0.020245837,
        0.011358121,
        0.004673663,
        -0.0138342725,
        0.02789835,
        -0.0145696495,
        0.034838468,
        0.00035117107,
        0.0037228442,
        -0.03711354,
        -0.017798413,
        0.039112844,
        -0.039066885,
        0.0114270635,
        0.009399032,
        0.031575233,
        -0.039526492,
        0.001210068,
        0.021923415,
        -0.015063731,
        0.036516044,
        -0.022015337,
        0.024152527,
        -0.026680384,
        -0.020291798,
        -0.042215213,
        0.017557116,
        -0.014696042,
        -0.0036510301,
        0.010875531,
        0.009347326,
        -0.000833762,
        -0.016419582,
        -0.023945702,
        -0.016626406,
        0.018855516,
        0.016948134,
        0.01329423,
        -0.022854127,
        0.007078,
        0.028886514,
        0.01815461,
        0.012754188,
        0.007606552,
        0.01903936,
        -0.021957885,
        -0.010117174,
        -0.0049609197,
        0.007658258,
        -0.007847847,
        0.003757315,
        0.019602383,
        -0.022233652,
        0.022589851,
        0.024864921,
        -0.0011152733,
        0.030035539,
        -0.057175532,
        -0.0001606841,
        0.0041422388,
        0.028403923,
        0.0074456884,
        0.03543596,
        -0.0008222717,
        0.023026481,
        -0.0134665845,
        0.041640703,
        0.03175908,
        -0.01682174,
        0.005466491,
        -0.009680544,
        0.020625016,
        0.03148331,
        0.015661225,
        -0.012283088,
        -0.029713811,
        -0.012041792,
        0.024152527,
        -1.9995745e-05,
        0.01729284,
        0.019878149,
        -0.055566896,
        0.00260398,
        -0.008577479,
        0.0007590753,
        0.02610587,
        0.015891029,
        0.0014018117,
        -0.016879192,
        0.0020653743,
        0.009169227,
        -0.00994482,
        0.009835662,
        0.019602383,
        0.025531357,
        -0.016132325,
        0.017097507,
        -0.011438553,
        -0.011720065,
        -0.008370655,
        -0.022153221,
        0.018361434,
        0.03260936,
        -0.004349063,
        0.03005852,
        -0.00841087,
        0.009950565,
        0.010036742,
        -0.0038205113,
        0.003401117,
        0.043226358,
        -0.023060951,
        -0.00231816,
        0.025416454,
        0.027208935,
        -0.0040962775,
        -0.03897496,
        -0.008554499,
        -0.005400422,
        0.0072216284,
        -0.017511155,
        -0.0036826283,
        -0.01412153,
        0.017626058,
        -0.012581835,
        -0.0040560616,
        -0.013052935,
        0.014810945,
        0.027553642,
        -0.024933863,
        0.014925848,
        0.014006627,
        0.0265425,
        0.029782753,
        -0.025738182,
        -0.0059921704,
        0.018740613,
        0.025761163,
        -0.010513588,
        0.01815461,
        -0.0026456323,
        -0.034815487,
        -0.004495564,
        0.011777516,
        0.029828714,
        0.00927264,
        -0.008554499,
        0.008135104,
        -0.030426208,
        -0.0016747054,
        0.017120486,
        -0.039894182,
        0.018499319,
        0.0011317906,
        -0.0070952354,
        0.013535526,
        0.0064460356,
        0.01041592,
        -0.014362825,
        0.018028218,
        0.009726505,
        -0.009042835,
        0.044766054,
        -0.025048766,
        0.009864388,
        -0.024152527,
        -0.00796275,
        -0.04154878,
        -0.017603079,
        -0.02475002,
        0.011455789,
        0.00685394,
        -0.014856906,
        -0.006061112,
        0.01329423,
        -0.021429334,
        0.009870133,
        -0.007876573,
        0.008962403,
        0.029277181,
        0.0016273081,
        0.0011095282,
        -0.0044352403,
        -0.029346123,
        -0.01546589,
        -0.019257676,
        0.01820057,
        -0.0004326801,
        0.016178286,
        -0.023141382,
        -0.012949523,
        0.0033005772,
        0.008146594,
        -0.019384068,
        0.0065609384,
        0.012915052,
        0.0031799295,
        0.015132672,
        0.009513935,
        0.009324346,
        0.008945167,
        -0.023945702,
        -0.0074112173,
        -0.01949897,
        0.021348903,
        0.0074112173,
        -0.0099563105,
        0.007744435,
        0.020682467,
        0.022302594,
        0.030793896,
        -0.0074054725,
        -0.0068769203,
        0.012260107,
        -0.037665073,
        -0.029277181,
        -0.016764289,
        -0.016086364,
        0.026266733,
        -0.000696597,
        0.015845068,
        0.031782057,
        0.0256003,
        0.046328727,
        -0.038607273,
        -0.012099244,
        0.04419154,
        -0.0007267589,
        -0.02658846,
        -0.005466491,
        -0.013133367,
        0.011972851,
        -0.021107607,
        0.03141437,
        0.028013254,
        -0.013776821,
        0.0018944566,
        -0.03329877,
        -0.009548406,
        -0.018074179,
        0.008077652,
        -0.017097507,
        0.019728776,
        0.002726064,
        0.0057192766,
        0.033436656,
        0.0075605907,
        0.004751222,
        -0.0053831865,
        -0.0031196056,
        -0.0066643506,
        0.0037400795,
        -0.0059921704,
        -0.00508444,
        -0.008675146,
        -0.029920636,
        0.029828714,
        0.007060765,
        0.00039174606,
        -0.004291612,
        0.016706837
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 307.525563955307,
        "patch_type": "diff",
        "api_costs": 0.23914799999999997,
        "num_applied": 2,
        "patch_name": "optimize_packing_imports",
        "patch_description": "Add bisect module for efficient binary search in the optimization algorithm.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 1,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "To improve the performance of the expert rearrangement algorithm, I propose the following changes:\n\n1.  **Add `bisect` import**: The optimization algorithm will use binary search to find optimal swap candidates, so the `bisect` module is required.\n2.  **Hybrid Refinement Strategy**: The existing `balanced_packing` function uses a \"Pool-and-Split\" strategy (merging two packs and redistributing greedily). While robust, it lacks the precision of single-item swaps for fine-tuning. I propose a hybrid approach:\n    *   First, attempt **Pool-and-Split** on the heaviest and lightest packs. This acts as a \"large neighborhood\" search to escape local optima.\n    *   If Pool-and-Split fails to improve the balance, fallback to a **Pairwise Swap** search. Using binary search (`bisect`), we efficiently find the single item pair $(u, v)$ (where $u$ is from the heaviest pack and $v$ from the lightest) that minimizes the load difference.\n    *   I also increase the number of restarts from 4 to 10. Since the current speed score is perfect (1.0), we can afford more computation to search for a better balance.\n\n<NAME>\noptimize_packing_imports\n</NAME>\n\n<DESCRIPTION>\nAdd bisect module for efficient binary search in the optimization algorithm.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\nimport torch\nimport heapq\nimport random\n=======\nimport torch\nimport heapq\nimport random\nimport bisect\n>>>>>>> REPLACE\n</DIFF>\n\n<NAME>\nhybrid_refinement_strategy\n</NAME>\n\n<DESCRIPTION>\nImprove `balanced_packing` by combining \"Pool-and-Split\" with a fine-grained \"Pairwise Swap\" refinement.\nThe \"Pool-and-Split\" strategy (LPT on union of Max/Min packs) is effective for large moves but can miss optimal fine-tuning.\nThe \"Pairwise Swap\" uses binary search to efficiently find the best single item exchange between Max and Min packs to further reduce the load difference.\nWe also increase the number of restarts to 10 to utilize the available CPU budget for better exploration.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Pool-and-Split\n            # Instead of single swaps, pick two packs (Max and Min), pool items, and re-distribute.\n            for _ in range(30):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                if max_val - min_val < 1e-6:\n                    break\n\n                # Try to improve by pairing Max Pack with Min Pack\n                # Only trying Max-Min pair is usually sufficient and fast.\n                p1, p2 = max_p, min_p\n\n                # Pool items\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy into two temp packs\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n\n                possible = True\n                for idx, w in pooled_items:\n                    # Put in valid bin with min weight\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if not possible: break\n\n                # Check criteria\n                old_local_max = max(pack_weights[p1], pack_weights[p2])\n                new_local_max = max(t_weights[0], t_weights[1])\n                old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                new_spread = abs(t_weights[0] - t_weights[1])\n\n                # Accept if max load reduced, or if max load unchanged but spread reduced\n                if new_local_max < old_local_max - 1e-6 or \\\n                   (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                    current_packs[p1] = t_packs[0]\n                    pack_weights[p1] = t_weights[0]\n                    current_packs[p2] = t_packs[1]\n                    pack_weights[p2] = t_weights[1]\n                else:\n                    # If Pool-and-Split on Max/Min didn't help, we are likely in a local optimum\n                    # reachable by this move.\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n=======\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    # Increased to 10 since speed is high and we want better balance\n    num_restarts = 10\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Hybrid (Pool-and-Split + Swap)\n            for _ in range(50):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n\n                improvement_found = False\n                \n                # --- Strategy A: Pool-and-Split ---\n                p1, p2 = max_p, min_p\n                \n                # Pool items from Max and Min packs\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending for LPT\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n                possible = True\n                \n                for idx, w in pooled_items:\n                    # Best Fit (Greedy)\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if possible:\n                    old_local_max = max(pack_weights[p1], pack_weights[p2])\n                    new_local_max = max(t_weights[0], t_weights[1])\n                    old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                    new_spread = abs(t_weights[0] - t_weights[1])\n\n                    # Strict improvement in local max or spread\n                    if new_local_max < old_local_max - 1e-6 or \\\n                       (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                        current_packs[p1] = t_packs[0]\n                        pack_weights[p1] = t_weights[0]\n                        current_packs[p2] = t_packs[1]\n                        pack_weights[p2] = t_weights[1]\n                        improvement_found = True\n\n                # --- Strategy B: Single Item Swap ---\n                # If Pool-and-Split failed to improve (e.g. LPT is stuck), try a precise single swap.\n                if not improvement_found:\n                    # We want to swap u in Max, v in Min such that w_u > w_v\n                    # Target delta: (max_val - min_val) / 2\n                    target = diff / 2.0\n                    \n                    # Prepare items in Min pack for binary search: (weight, index_in_pack)\n                    # We need to sort min pack items by weight\n                    min_items = []\n                    for i_v, idx_v in enumerate(current_packs[min_p]):\n                        min_items.append((row_w[idx_v], i_v))\n                    min_items.sort(key=lambda x: x[0])\n                    min_weights = [x[0] for x in min_items]\n                    \n                    best_swap = None\n                    best_gap = diff # Gap from target\n                    \n                    # Iterate items in Max pack\n                    for i_u, idx_u in enumerate(current_packs[max_p]):\n                        w_u = row_w[idx_u]\n                        # We want w_u - w_v approx target  =>  w_v approx w_u - target\n                        target_v = w_u - target\n                        \n                        # Find insertion point\n                        pos = bisect.bisect_left(min_weights, target_v)\n                        \n                        # Check neighbors\n                        candidates = []\n                        if pos < len(min_weights): candidates.append(pos)\n                        if pos > 0: candidates.append(pos - 1)\n                        \n                        for c in candidates:\n                            w_v = min_weights[c]\n                            delta = w_u - w_v\n                            \n                            # Must reduce max (delta > 0) and not flip order too much (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (i_u, min_items[c][1], delta) # (idx_in_max, idx_in_min, delta)\n                                    if gap < 1e-6: break\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        i_u, i_v, delta = best_swap\n                        \n                        # Perform Swap\n                        u = current_packs[max_p][i_u]\n                        v = current_packs[min_p][i_v]\n                        \n                        current_packs[max_p][i_u] = v\n                        current_packs[min_p][i_v] = u\n                        pack_weights[max_p] -= delta\n                        pack_weights[min_p] += delta\n                        improvement_found = True\n\n                if not improvement_found:\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n>>>>>>> REPLACE\n</DIFF>",
          "msg": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport bisect\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # CPU-based solver\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    \n    # Use a fixed seed for deterministic behavior across runs if needed, \n    # but local randomness helps exploration.\n    rng = random.Random(42)\n\n    for i in range(num_layers):\n        row_weights = weight_cpu[i].tolist()\n        \n        # --- Internal Solver Logic ---\n        num_items = len(row_weights)\n        \n        # 1. Initial Greedy LPT\n        # Sort items by weight descending\n        sorted_indices = sorted(range(num_items), key=lambda k: row_weights[k], reverse=True)\n        \n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n        \n        for idx in sorted_indices:\n            w = row_weights[idx]\n            # Find pack with min weight that has space\n            best_p = -1\n            min_val = float('inf')\n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_p = p\n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n            \n        # Helper: Optimized Pairwise Swap\n        def refine_swaps(curr_packs, curr_weights, max_iter=20):\n            for _ in range(max_iter):\n                # Identify min and max packs\n                min_p, max_p = 0, 0\n                min_val, max_val = curr_weights[0], curr_weights[0]\n                \n                # Simple scan is fast for small num_packs\n                for p in range(1, num_packs):\n                    w = curr_weights[p]\n                    if w < min_val:\n                        min_val = w\n                        min_p = p\n                    elif w > max_val:\n                        max_val = w\n                        max_p = p\n                \n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n                    \n                target_delta = diff / 2.0\n                best_swap = None\n                best_gap = diff\n                \n                # Prepare light pack items for binary search: (weight, index_in_pack)\n                # This makes finding the best swap O(C log C) instead of O(C^2)\n                min_items = []\n                for idx_in_pack, global_idx in enumerate(curr_packs[min_p]):\n                    min_items.append((row_weights[global_idx], idx_in_pack))\n                min_items.sort(key=lambda x: x[0])\n                min_ws = [x[0] for x in min_items]\n                \n                found_swap = False\n                \n                # Iterate heavy pack items\n                for idx_u, u in enumerate(curr_packs[max_p]):\n                    w_u = row_weights[u]\n                    # We look for v such that w_u - w_v approx target_delta\n                    # w_v approx w_u - target_delta\n                    target_v = w_u - target_delta\n                    \n                    # Binary search\n                    pos = bisect.bisect_left(min_ws, target_v)\n                    \n                    # Check candidates around pos\n                    candidates = []\n                    if pos < len(min_ws): candidates.append(pos)\n                    if pos > 0: candidates.append(pos - 1)\n                    \n                    for c_idx in candidates:\n                        w_v = min_ws[c_idx]\n                        delta = w_u - w_v\n                        \n                        if 0 < delta < diff: # Valid reduction\n                            gap = abs(delta - target_delta)\n                            if gap < best_gap:\n                                best_gap = gap\n                                idx_v = min_items[c_idx][1]\n                                best_swap = (idx_u, idx_v, delta)\n                                if gap < 1e-6:\n                                    found_swap = True\n                                    break\n                    if found_swap: break\n                \n                if best_swap:\n                    idx_u, idx_v, delta = best_swap\n                    u = curr_packs[max_p][idx_u]\n                    v = curr_packs[min_p][idx_v]\n                    \n                    curr_packs[max_p][idx_u] = v\n                    curr_packs[min_p][idx_v] = u\n                    curr_weights[max_p] -= delta\n                    curr_weights[min_p] += delta\n                else:\n                    break\n\n        # Initial Refinement\n        refine_swaps(packs, pack_weights, max_iter=20)\n        \n        # 2. Large Neighborhood Search (LNS) / Ruin & Recreate\n        # Iteratively destroy and repair the solution to escape local optima\n        best_diff = max(pack_weights) - min(pack_weights)\n        best_packs = [p[:] for p in packs] # Deep copy\n        \n        lns_iters = 50\n        \n        for _ in range(lns_iters):\n            if best_diff < 1e-6: break\n            \n            # Select K packs to ruin\n            # Ideally: Heaviest, Lightest, and some Randoms\n            # Sort packs by weight\n            sorted_pack_indices = sorted(range(num_packs), key=pack_weights.__getitem__)\n            \n            candidates = set()\n            candidates.add(sorted_pack_indices[0]) # Lightest\n            candidates.add(sorted_pack_indices[-1]) # Heaviest\n            \n            # Add random packs until we have up to 4 (or num_packs)\n            while len(candidates) < min(4, num_packs):\n                candidates.add(rng.randint(0, num_packs - 1))\n            \n            candidate_list = list(candidates)\n            \n            # Remove items\n            removed_items = []\n            for p in candidate_list:\n                removed_items.extend(packs[p])\n                # Subtract weights\n                pack_weights[p] -= sum(row_weights[x] for x in packs[p])\n                packs[p] = []\n                \n            # Perturbed LPT Re-insertion\n            # Sort items by weight with multiplicative noise to vary the greedy choice\n            # Noise between 0.9 and 1.1\n            removed_items.sort(key=lambda x: row_weights[x] * (0.9 + rng.random() * 0.2), \n                               reverse=True)\n            \n            # Re-pack greedily into the selected candidates\n            # We track local weights of candidates\n            cand_weights = [pack_weights[p] for p in candidate_list]\n            \n            for item_idx in removed_items:\n                w = row_weights[item_idx]\n                \n                # Find best candidate pack (min weight)\n                best_c = -1\n                min_w = float('inf')\n                for c_i, p_idx in enumerate(candidate_list):\n                    if len(packs[p_idx]) < groups_per_pack:\n                        if cand_weights[c_i] < min_w:\n                            min_w = cand_weights[c_i]\n                            best_c = c_i\n                \n                p_real = candidate_list[best_c]\n                packs[p_real].append(item_idx)\n                cand_weights[best_c] += w\n                pack_weights[p_real] += w\n            \n            # Polish with swaps\n            refine_swaps(packs, pack_weights, max_iter=10)\n            \n            # Check acceptance\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [p[:] for p in packs]\n            else:\n                # Revert\n                packs = [p[:] for p in best_packs]\n                # Recompute weights (safer than tracking deltas)\n                for p in range(num_packs):\n                    pack_weights[p] = sum(row_weights[x] for x in packs[p])\n\n        # Fill output tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain current average load to avoid recomputing division fully\n    # score = weight / count\n    current_scores = weight.clone()\n    \n    for i in range(num_log, num_phy):\n        # Find index with max score\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment count\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores efficiently using gather/scatter logic (or indexing)\n        # We only need to update the scores for the experts that got a replica\n        # new_score = weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a modification to it below):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport heapq\nimport random\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Pool-and-Split\n            # Instead of single swaps, pick two packs (Max and Min), pool items, and re-distribute.\n            for _ in range(30):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                if max_val - min_val < 1e-6:\n                    break\n\n                # Try to improve by pairing Max Pack with Min Pack\n                # Only trying Max-Min pair is usually sufficient and fast.\n                p1, p2 = max_p, min_p\n\n                # Pool items\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy into two temp packs\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n\n                possible = True\n                for idx, w in pooled_items:\n                    # Put in valid bin with min weight\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if not possible: break\n\n                # Check criteria\n                old_local_max = max(pack_weights[p1], pack_weights[p2])\n                new_local_max = max(t_weights[0], t_weights[1])\n                old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                new_spread = abs(t_weights[0] - t_weights[1])\n\n                # Accept if max load reduced, or if max load unchanged but spread reduced\n                if new_local_max < old_local_max - 1e-6 or \\\n                   (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                    current_packs[p1] = t_packs[0]\n                    pack_weights[p1] = t_weights[0]\n                    current_packs[p2] = t_packs[1]\n                    pack_weights[p2] = t_weights[1]\n                else:\n                    # If Pool-and-Split on Max/Min didn't help, we are likely in a local optimum\n                    # reachable by this move.\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n\n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Move to CPU for efficient priority queue operations\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n\n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n\n        # Priority queue stores (-score, expert_idx, current_count)\n        # Score = weight / count\n        # Python heapq is a min-heap, so we store negative score to simulate max-heap\n        pq = []\n        for i in range(num_log):\n            heapq.heappush(pq, (-w_row[i], i, 1))\n\n        # Assign replicas one by one\n        for r_idx in range(num_log, num_phy):\n            score_neg, expert_idx, count = heapq.heappop(pq)\n\n            # Assign the new replica\n            phy2log_cpu[layer_idx, r_idx] = expert_idx\n            rank_cpu[layer_idx, r_idx] = count\n\n            # Update count and push back with new score\n            new_count = count + 1\n            logcnt_cpu[layer_idx, expert_idx] = new_count\n            new_score_neg = -w_row[expert_idx] / new_count\n            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Instructions\n\nMake sure that the changes you propose are consistent with each other. For example, if you refer to a new config variable somewhere, you should also propose a change to add that variable.\n\nNote that the changes you propose will be applied sequentially, so you should assume that the previous changes have already been applied when writing the SEARCH block.\n\n# Task\n\nSuggest a new idea to improve the performance of the code that is inspired by your expert knowledge of the considered subject.\nYour goal is to maximize the `combined_score` of the program.\nDescribe each change with a SEARCH/REPLACE block.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nYou MUST repond using a edit name, description and the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<NAME>\nA shortened name summarizing the edit you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the edit you are proposing.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly including indentation)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\n</DIFF>\n\n\nExample of a valid diff format:\n<DIFF>\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\n</DIFF>\n\n* You may only modify text that lies below a line containing \"EVOLVE-BLOCK-START\" and above the next \"EVOLVE-BLOCK-END\". Everything outside those markers is read-only.\n* Do not repeat the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the SEARCH/REPLACE blocks.  \n* Every block\u2019s SEARCH section must be copied **verbatim** from the current file.  Including indentation.\n* You can propose multiple independent edits. SEARCH/REPLACE blocks follow one after another. DO NOT ADD ANY OTHER TEXT BETWEEN THESE BLOCKS.\n* Make sure the file still runs after your changes.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program and the consistent balancedness plateau (0.31) alongside the perfect speed score (1.0), here are 5 actionable recommendations for future program mutations. These recommendations leverage the available CPU time budget to introduce smarter, scalar-based optimizations that maintain the efficiency of the current solution while attempting to break the local optima.\n\n1.  **Small-Scale Branch-and-Bound Solver**: The hierarchical nature of the problem means the top-level distribution (groups to nodes) involves small item counts ($N \\le 20$) but dictates the global balance ceiling. Modify `balanced_packing` to check if `num_groups < 18`. If true, bypass the greedy heuristic and employ a recursive **Branch-and-Bound** or **Depth-First Search** solver to find the mathematically optimal partition. This utilizes the idle CPU budget to guarantee optimal structural foundations that heuristics often miss.\n\n2.  **Pool-and-Split Refinement Strategy**: Instead of searching for single pairwise swaps between the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, implement a **full re-partitioning** of these two packs. Combine all items from $P_{max}$ and $P_{min}$ into a temporary pool, sort them descending, and redistribute them into two new packs using a \"Best Fit\" or \"Zig-Zag\" greedy logic. This implicitly performs multi-item exchanges (e.g., swapping two small items for one large item) in a single $O(k \\log k)$ step, escaping local optima that block single-item swaps.\n\n3.  **Variance-Based Greedy Initialization**: The current \"Least Loaded\" greedy construction minimizes the immediate peak but ignores the target mean, often leading to fragmentation. Change the initialization loop to assign items to the pack where the assignment minimizes the **L2 distance from the ideal mean weight** (`(current_weight + item_weight - target_avg)**2`). This ensures packs grow uniformly towards the target size, leaving \"holes\" of appropriate sizes for the final smaller items.\n\n4.  **Three-Way Cyclic Exchange**: Extend the refinement phase to handle situations where no direct $P_{max} \\leftrightarrow P_{min}$ swap is valid. When the 2-way swap search fails, trigger a scan for a **3-way cycle**: move item $u$ from $P_{max}$ to a random pack $P_{rand}$, and item $v$ from $P_{rand}$ to $P_{min}$, such that the variance decreases. This utilizes the intermediate buffer to flow weight from max to min even when their item granularities are incompatible for a direct trade.\n\n5.  **Multi-Start Randomized Greedy**: Since the current solution is extremely fast (Speed Score 1.0), exploit the time budget by running the packing algorithm multiple times with **randomized sort perturbations**. In the initialization phase, add small random noise to item weights during sorting (or shuffle equal-weight items). Run the full construction and refinement loop 5-10 times and return the solution with the lowest final imbalance. This is a robust way to escape bad initial configurations caused by specific item orderings.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport bisect\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # CPU-based solver\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    \n    # Use a fixed seed for deterministic behavior across runs if needed, \n    # but local randomness helps exploration.\n    rng = random.Random(42)\n\n    for i in range(num_layers):\n        row_weights = weight_cpu[i].tolist()\n        \n        # --- Internal Solver Logic ---\n        num_items = len(row_weights)\n        \n        # 1. Initial Greedy LPT\n        # Sort items by weight descending\n        sorted_indices = sorted(range(num_items), key=lambda k: row_weights[k], reverse=True)\n        \n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n        \n        for idx in sorted_indices:\n            w = row_weights[idx]\n            # Find pack with min weight that has space\n            best_p = -1\n            min_val = float('inf')\n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_p = p\n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n            \n        # Helper: Optimized Pairwise Swap\n        def refine_swaps(curr_packs, curr_weights, max_iter=20):\n            for _ in range(max_iter):\n                # Identify min and max packs\n                min_p, max_p = 0, 0\n                min_val, max_val = curr_weights[0], curr_weights[0]\n                \n                # Simple scan is fast for small num_packs\n                for p in range(1, num_packs):\n                    w = curr_weights[p]\n                    if w < min_val:\n                        min_val = w\n                        min_p = p\n                    elif w > max_val:\n                        max_val = w\n                        max_p = p\n                \n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n                    \n                target_delta = diff / 2.0\n                best_swap = None\n                best_gap = diff\n                \n                # Prepare light pack items for binary search: (weight, index_in_pack)\n                # This makes finding the best swap O(C log C) instead of O(C^2)\n                min_items = []\n                for idx_in_pack, global_idx in enumerate(curr_packs[min_p]):\n                    min_items.append((row_weights[global_idx], idx_in_pack))\n                min_items.sort(key=lambda x: x[0])\n                min_ws = [x[0] for x in min_items]\n                \n                found_swap = False\n                \n                # Iterate heavy pack items\n                for idx_u, u in enumerate(curr_packs[max_p]):\n                    w_u = row_weights[u]\n                    # We look for v such that w_u - w_v approx target_delta\n                    # w_v approx w_u - target_delta\n                    target_v = w_u - target_delta\n                    \n                    # Binary search\n                    pos = bisect.bisect_left(min_ws, target_v)\n                    \n                    # Check candidates around pos\n                    candidates = []\n                    if pos < len(min_ws): candidates.append(pos)\n                    if pos > 0: candidates.append(pos - 1)\n                    \n                    for c_idx in candidates:\n                        w_v = min_ws[c_idx]\n                        delta = w_u - w_v\n                        \n                        if 0 < delta < diff: # Valid reduction\n                            gap = abs(delta - target_delta)\n                            if gap < best_gap:\n                                best_gap = gap\n                                idx_v = min_items[c_idx][1]\n                                best_swap = (idx_u, idx_v, delta)\n                                if gap < 1e-6:\n                                    found_swap = True\n                                    break\n                    if found_swap: break\n                \n                if best_swap:\n                    idx_u, idx_v, delta = best_swap\n                    u = curr_packs[max_p][idx_u]\n                    v = curr_packs[min_p][idx_v]\n                    \n                    curr_packs[max_p][idx_u] = v\n                    curr_packs[min_p][idx_v] = u\n                    curr_weights[max_p] -= delta\n                    curr_weights[min_p] += delta\n                else:\n                    break\n\n        # Initial Refinement\n        refine_swaps(packs, pack_weights, max_iter=20)\n        \n        # 2. Large Neighborhood Search (LNS) / Ruin & Recreate\n        # Iteratively destroy and repair the solution to escape local optima\n        best_diff = max(pack_weights) - min(pack_weights)\n        best_packs = [p[:] for p in packs] # Deep copy\n        \n        lns_iters = 50\n        \n        for _ in range(lns_iters):\n            if best_diff < 1e-6: break\n            \n            # Select K packs to ruin\n            # Ideally: Heaviest, Lightest, and some Randoms\n            # Sort packs by weight\n            sorted_pack_indices = sorted(range(num_packs), key=pack_weights.__getitem__)\n            \n            candidates = set()\n            candidates.add(sorted_pack_indices[0]) # Lightest\n            candidates.add(sorted_pack_indices[-1]) # Heaviest\n            \n            # Add random packs until we have up to 4 (or num_packs)\n            while len(candidates) < min(4, num_packs):\n                candidates.add(rng.randint(0, num_packs - 1))\n            \n            candidate_list = list(candidates)\n            \n            # Remove items\n            removed_items = []\n            for p in candidate_list:\n                removed_items.extend(packs[p])\n                # Subtract weights\n                pack_weights[p] -= sum(row_weights[x] for x in packs[p])\n                packs[p] = []\n                \n            # Perturbed LPT Re-insertion\n            # Sort items by weight with multiplicative noise to vary the greedy choice\n            # Noise between 0.9 and 1.1\n            removed_items.sort(key=lambda x: row_weights[x] * (0.9 + rng.random() * 0.2), \n                               reverse=True)\n            \n            # Re-pack greedily into the selected candidates\n            # We track local weights of candidates\n            cand_weights = [pack_weights[p] for p in candidate_list]\n            \n            for item_idx in removed_items:\n                w = row_weights[item_idx]\n                \n                # Find best candidate pack (min weight)\n                best_c = -1\n                min_w = float('inf')\n                for c_i, p_idx in enumerate(candidate_list):\n                    if len(packs[p_idx]) < groups_per_pack:\n                        if cand_weights[c_i] < min_w:\n                            min_w = cand_weights[c_i]\n                            best_c = c_i\n                \n                p_real = candidate_list[best_c]\n                packs[p_real].append(item_idx)\n                cand_weights[best_c] += w\n                pack_weights[p_real] += w\n            \n            # Polish with swaps\n            refine_swaps(packs, pack_weights, max_iter=10)\n            \n            # Check acceptance\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [p[:] for p in packs]\n            else:\n                # Revert\n                packs = [p[:] for p in best_packs]\n                # Recompute weights (safer than tracking deltas)\n                for p in range(num_packs):\n                    pack_weights[p] = sum(row_weights[x] for x in packs[p])\n\n        # Fill output tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain current average load to avoid recomputing division fully\n    # score = weight / count\n    current_scores = weight.clone()\n    \n    for i in range(num_log, num_phy):\n        # Find index with max score\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment count\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores efficiently using gather/scatter logic (or indexing)\n        # We only need to update the scores for the experts that got a replica\n        # new_score = weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a modification to it below):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport heapq\nimport random\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Pool-and-Split\n            # Instead of single swaps, pick two packs (Max and Min), pool items, and re-distribute.\n            for _ in range(30):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                if max_val - min_val < 1e-6:\n                    break\n\n                # Try to improve by pairing Max Pack with Min Pack\n                # Only trying Max-Min pair is usually sufficient and fast.\n                p1, p2 = max_p, min_p\n\n                # Pool items\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy into two temp packs\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n\n                possible = True\n                for idx, w in pooled_items:\n                    # Put in valid bin with min weight\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if not possible: break\n\n                # Check criteria\n                old_local_max = max(pack_weights[p1], pack_weights[p2])\n                new_local_max = max(t_weights[0], t_weights[1])\n                old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                new_spread = abs(t_weights[0] - t_weights[1])\n\n                # Accept if max load reduced, or if max load unchanged but spread reduced\n                if new_local_max < old_local_max - 1e-6 or \\\n                   (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                    current_packs[p1] = t_packs[0]\n                    pack_weights[p1] = t_weights[0]\n                    current_packs[p2] = t_packs[1]\n                    pack_weights[p2] = t_weights[1]\n                else:\n                    # If Pool-and-Split on Max/Min didn't help, we are likely in a local optimum\n                    # reachable by this move.\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n\n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Move to CPU for efficient priority queue operations\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n\n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n\n        # Priority queue stores (-score, expert_idx, current_count)\n        # Score = weight / count\n        # Python heapq is a min-heap, so we store negative score to simulate max-heap\n        pq = []\n        for i in range(num_log):\n            heapq.heappush(pq, (-w_row[i], i, 1))\n\n        # Assign replicas one by one\n        for r_idx in range(num_log, num_phy):\n            score_neg, expert_idx, count = heapq.heappop(pq)\n\n            # Assign the new replica\n            phy2log_cpu[layer_idx, r_idx] = expert_idx\n            rank_cpu[layer_idx, r_idx] = count\n\n            # Update count and push back with new score\n            new_count = count + 1\n            logcnt_cpu[layer_idx, expert_idx] = new_count\n            new_score_neg = -w_row[expert_idx] / new_count\n            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Instructions\n\nMake sure that the changes you propose are consistent with each other. For example, if you refer to a new config variable somewhere, you should also propose a change to add that variable.\n\nNote that the changes you propose will be applied sequentially, so you should assume that the previous changes have already been applied when writing the SEARCH block.\n\n# Task\n\nSuggest a new idea to improve the performance of the code that is inspired by your expert knowledge of the considered subject.\nYour goal is to maximize the `combined_score` of the program.\nDescribe each change with a SEARCH/REPLACE block.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n"
            },
            {
              "role": "assistant",
              "content": "To improve the performance of the expert rearrangement algorithm, I propose the following changes:\n\n1.  **Add `bisect` import**: The optimization algorithm will use binary search to find optimal swap candidates, so the `bisect` module is required.\n2.  **Hybrid Refinement Strategy**: The existing `balanced_packing` function uses a \"Pool-and-Split\" strategy (merging two packs and redistributing greedily). While robust, it lacks the precision of single-item swaps for fine-tuning. I propose a hybrid approach:\n    *   First, attempt **Pool-and-Split** on the heaviest and lightest packs. This acts as a \"large neighborhood\" search to escape local optima.\n    *   If Pool-and-Split fails to improve the balance, fallback to a **Pairwise Swap** search. Using binary search (`bisect`), we efficiently find the single item pair $(u, v)$ (where $u$ is from the heaviest pack and $v$ from the lightest) that minimizes the load difference.\n    *   I also increase the number of restarts from 4 to 10. Since the current speed score is perfect (1.0), we can afford more computation to search for a better balance.\n\n<NAME>\noptimize_packing_imports\n</NAME>\n\n<DESCRIPTION>\nAdd bisect module for efficient binary search in the optimization algorithm.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\nimport torch\nimport heapq\nimport random\n=======\nimport torch\nimport heapq\nimport random\nimport bisect\n>>>>>>> REPLACE\n</DIFF>\n\n<NAME>\nhybrid_refinement_strategy\n</NAME>\n\n<DESCRIPTION>\nImprove `balanced_packing` by combining \"Pool-and-Split\" with a fine-grained \"Pairwise Swap\" refinement.\nThe \"Pool-and-Split\" strategy (LPT on union of Max/Min packs) is effective for large moves but can miss optimal fine-tuning.\nThe \"Pairwise Swap\" uses binary search to efficiently find the best single item exchange between Max and Min packs to further reduce the load difference.\nWe also increase the number of restarts to 10 to utilize the available CPU budget for better exploration.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Pool-and-Split\n            # Instead of single swaps, pick two packs (Max and Min), pool items, and re-distribute.\n            for _ in range(30):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                if max_val - min_val < 1e-6:\n                    break\n\n                # Try to improve by pairing Max Pack with Min Pack\n                # Only trying Max-Min pair is usually sufficient and fast.\n                p1, p2 = max_p, min_p\n\n                # Pool items\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy into two temp packs\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n\n                possible = True\n                for idx, w in pooled_items:\n                    # Put in valid bin with min weight\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if not possible: break\n\n                # Check criteria\n                old_local_max = max(pack_weights[p1], pack_weights[p2])\n                new_local_max = max(t_weights[0], t_weights[1])\n                old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                new_spread = abs(t_weights[0] - t_weights[1])\n\n                # Accept if max load reduced, or if max load unchanged but spread reduced\n                if new_local_max < old_local_max - 1e-6 or \\\n                   (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                    current_packs[p1] = t_packs[0]\n                    pack_weights[p1] = t_weights[0]\n                    current_packs[p2] = t_packs[1]\n                    pack_weights[p2] = t_weights[1]\n                else:\n                    # If Pool-and-Split on Max/Min didn't help, we are likely in a local optimum\n                    # reachable by this move.\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n=======\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Number of random restarts to escape local optima\n    # Increased to 10 since speed is high and we want better balance\n    num_restarts = 10\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i].tolist()\n\n        # Original items (index, weight)\n        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)\n\n        best_diff = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            if attempt == 0:\n                # Deterministic LPT\n                items = original_items\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups).tolist()\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))\n                               for k, (idx, w) in enumerate(original_items)]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                items = [(idx, w) for idx, w, _ in noisy_items]\n\n            # Greedy Phase\n            for idx, w in items:\n                # Assign to the lightest pack that has space\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase: Hybrid (Pool-and-Split + Swap)\n            for _ in range(50):\n                # Identify Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                    elif val > max_val:\n                        max_val = val\n                        max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n\n                improvement_found = False\n                \n                # --- Strategy A: Pool-and-Split ---\n                p1, p2 = max_p, min_p\n                \n                # Pool items from Max and Min packs\n                pooled_items = []\n                for idx in current_packs[p1]:\n                    pooled_items.append((idx, row_w[idx]))\n                for idx in current_packs[p2]:\n                    pooled_items.append((idx, row_w[idx]))\n\n                # Sort Descending for LPT\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n\n                # Re-distribute using constrained greedy\n                t_packs = [[], []]\n                t_weights = [0.0, 0.0]\n                possible = True\n                \n                for idx, w in pooled_items:\n                    # Best Fit (Greedy)\n                    b_best = -1\n                    b_min = float('inf')\n                    for b in range(2):\n                        if len(t_packs[b]) < groups_per_pack:\n                            if t_weights[b] < b_min:\n                                b_min = t_weights[b]\n                                b_best = b\n                    if b_best != -1:\n                        t_packs[b_best].append(idx)\n                        t_weights[b_best] += w\n                    else:\n                        possible = False\n                        break\n\n                if possible:\n                    old_local_max = max(pack_weights[p1], pack_weights[p2])\n                    new_local_max = max(t_weights[0], t_weights[1])\n                    old_spread = abs(pack_weights[p1] - pack_weights[p2])\n                    new_spread = abs(t_weights[0] - t_weights[1])\n\n                    # Strict improvement in local max or spread\n                    if new_local_max < old_local_max - 1e-6 or \\\n                       (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):\n                        current_packs[p1] = t_packs[0]\n                        pack_weights[p1] = t_weights[0]\n                        current_packs[p2] = t_packs[1]\n                        pack_weights[p2] = t_weights[1]\n                        improvement_found = True\n\n                # --- Strategy B: Single Item Swap ---\n                # If Pool-and-Split failed to improve (e.g. LPT is stuck), try a precise single swap.\n                if not improvement_found:\n                    # We want to swap u in Max, v in Min such that w_u > w_v\n                    # Target delta: (max_val - min_val) / 2\n                    target = diff / 2.0\n                    \n                    # Prepare items in Min pack for binary search: (weight, index_in_pack)\n                    # We need to sort min pack items by weight\n                    min_items = []\n                    for i_v, idx_v in enumerate(current_packs[min_p]):\n                        min_items.append((row_w[idx_v], i_v))\n                    min_items.sort(key=lambda x: x[0])\n                    min_weights = [x[0] for x in min_items]\n                    \n                    best_swap = None\n                    best_gap = diff # Gap from target\n                    \n                    # Iterate items in Max pack\n                    for i_u, idx_u in enumerate(current_packs[max_p]):\n                        w_u = row_w[idx_u]\n                        # We want w_u - w_v approx target  =>  w_v approx w_u - target\n                        target_v = w_u - target\n                        \n                        # Find insertion point\n                        pos = bisect.bisect_left(min_weights, target_v)\n                        \n                        # Check neighbors\n                        candidates = []\n                        if pos < len(min_weights): candidates.append(pos)\n                        if pos > 0: candidates.append(pos - 1)\n                        \n                        for c in candidates:\n                            w_v = min_weights[c]\n                            delta = w_u - w_v\n                            \n                            # Must reduce max (delta > 0) and not flip order too much (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (i_u, min_items[c][1], delta) # (idx_in_max, idx_in_min, delta)\n                                    if gap < 1e-6: break\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        i_u, i_v, delta = best_swap\n                        \n                        # Perform Swap\n                        u = current_packs[max_p][i_u]\n                        v = current_packs[min_p][i_v]\n                        \n                        current_packs[max_p][i_u] = v\n                        current_packs[min_p][i_v] = u\n                        pack_weights[max_p] -= delta\n                        pack_weights[min_p] += delta\n                        improvement_found = True\n\n                if not improvement_found:\n                    break\n\n            # Check global result\n            curr_diff = max(pack_weights) - min(pack_weights)\n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n>>>>>>> REPLACE\n</DIFF>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 31074,
          "output_tokens": 14750,
          "cost": 0.23914799999999997,
          "input_cost": 0.062147999999999995,
          "output_cost": 0.177,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 59,
          "deleted": 0,
          "modified": 30
        },
        "meta_recommendations": "Based on the analysis of the current best program and the consistent balancedness plateau (0.31) alongside the perfect speed score (1.0), here are 5 actionable recommendations for future program mutations. These recommendations leverage the available CPU time budget to introduce smarter, scalar-based optimizations that maintain the efficiency of the current solution while attempting to break the local optima.\n\n1.  **Small-Scale Branch-and-Bound Solver**: The hierarchical nature of the problem means the top-level distribution (groups to nodes) involves small item counts ($N \\le 20$) but dictates the global balance ceiling. Modify `balanced_packing` to check if `num_groups < 18`. If true, bypass the greedy heuristic and employ a recursive **Branch-and-Bound** or **Depth-First Search** solver to find the mathematically optimal partition. This utilizes the idle CPU budget to guarantee optimal structural foundations that heuristics often miss.\n\n2.  **Pool-and-Split Refinement Strategy**: Instead of searching for single pairwise swaps between the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, implement a **full re-partitioning** of these two packs. Combine all items from $P_{max}$ and $P_{min}$ into a temporary pool, sort them descending, and redistribute them into two new packs using a \"Best Fit\" or \"Zig-Zag\" greedy logic. This implicitly performs multi-item exchanges (e.g., swapping two small items for one large item) in a single $O(k \\log k)$ step, escaping local optima that block single-item swaps.\n\n3.  **Variance-Based Greedy Initialization**: The current \"Least Loaded\" greedy construction minimizes the immediate peak but ignores the target mean, often leading to fragmentation. Change the initialization loop to assign items to the pack where the assignment minimizes the **L2 distance from the ideal mean weight** (`(current_weight + item_weight - target_avg)**2`). This ensures packs grow uniformly towards the target size, leaving \"holes\" of appropriate sizes for the final smaller items.\n\n4.  **Three-Way Cyclic Exchange**: Extend the refinement phase to handle situations where no direct $P_{max} \\leftrightarrow P_{min}$ swap is valid. When the 2-way swap search fails, trigger a scan for a **3-way cycle**: move item $u$ from $P_{max}$ to a random pack $P_{rand}$, and item $v$ from $P_{rand}$ to $P_{min}$, such that the variance decreases. This utilizes the intermediate buffer to flow weight from max to min even when their item granularities are incompatible for a direct trade.\n\n5.  **Multi-Start Randomized Greedy**: Since the current solution is extremely fast (Speed Score 1.0), exploit the time budget by running the packing algorithm multiple times with **randomized sort perturbations**. In the initialization phase, add small random noise to item weights during sorting (or shuffle equal-weight items). Run the full construction and refinement loop 5-10 times and return the solution with the lowest final imbalance. This is a robust way to escape bad initial configurations caused by specific item orderings.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Swap Refinement**: The most effective and robust pattern, exemplified by the **Current Best Program** and **Generation 73**, explicitly offloads packing logic to the CPU (`weight.to(\"cpu\")`). By employing a Greedy Longest Processing Time (LPT) initialization followed by targeted pairwise swaps, these solutions achieve a **Speed Score of 1.0** while matching the maximum observed balancedness (0.31).\n- **Targeted Min-Max Pruning**: The **Current Best Program** optimizes the refinement phase by exclusively targeting the single heaviest (`max_p`) and lightest (`min_p`) packs. By restricting the search space to swaps where `0 < w_u - w_v < diff`, the algorithm avoids checking valid but non-improving moves. This strategy proved as effective as the more complex Beam Search in **Generation 79** and Hybrid Exact Solvers in **Generation 72**, but with significantly lower implementation complexity.\n- **Incremental Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 78** manage packing state using native Python lists (`current_packs`) and scalar variables (`pack_weights`) rather than PyTorch tensors. This avoids the overhead of kernel launches and synchronization for frequent small updates, ensuring the refinement loop completes within the tight latency budget.\n\n## Ineffective Approaches\n- **Advanced Heuristic Search (LNS & Beam Search)**: Sophisticated search meta-heuristics, including Beam Search (**Generation 79**), Large Neighborhood Search (**Generation 70**, **Generation 71**), and Hybrid Exact Solvers (**Generation 72**), failed to surpass the **0.31 balancedness score** achieved by simple greedy methods. These approaches introduced significant algorithmic complexity without successfully navigating the structural constraints (likely large indivisible experts) that limit load balancing.\n- **Vectorized Packing Logic**: Attempts to vectorize the sequential packing or refinement logic (**Generation 70**, **Generation 75**) offered no performance advantage over the scalar CPU implementation of the **Current Best Program**. The overhead of setting up vectorized operations for serially dependent updates proved unnecessary given that scalar Python loops already achieve a perfect speed score.\n- **Aggressive Tensor Device Casting**: **Generation 77** failed validation (Score: 0.0) due to errors likely stemming from aggressive casting of tensors between CPU and GPU without proper device restoration or mapping reconstruction. This contrasts with the **Current Best Program**, which carefully isolates CPU operations to the `balanced_packing` function while maintaining clean device boundaries.\n\n## Implementation Insights\n- **Native Python List Efficiency**: The **Current Best Program** demonstrates that for this specific problem size (iterative packing of expert groups), standard Python `list` operations are superior to tensor manipulations. The implementation `current_packs = [[] for _ in range(num_packs)]` allows for O(1) appends and efficient iteration during the swap phase, avoiding the overhead of resizing or masking PyTorch tensors.\n- **Search Space Reduction via Inequality Constraints**: A key technique in the **Current Best Program** is the strict inequality check `if 0 < delta < diff:` inside the swap loop. This condition ensures that any swap performed strictly reduces the load difference between the max and min packs, guaranteeing convergence and preventing cycles, which is critical for the `while` or `for` loop refinement stability.\n- **Explicit Type and Device decoupling**: The pattern `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)` used in the **Current Best Program** ensures that all comparison and arithmetic operations during packing are performed in system memory using fast scalar FP32 units, completely decoupling the control flow from GPU latency.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: A striking trend across all successful programs (**Generations 70-76, 78-79**) is the convergence to an identical **Balancedness Score of 0.31**. Whether using Beam Search, Exact Solvers, or Randomized Greedy, no method could improve upon this baseline. This strongly implies that the residual imbalance is inherent to the workload distribution (e.g., a single expert group being larger than the target average), and further algorithmic tuning on packing heuristics is unlikely to yield gains.\n- **Speed Score Robustness**: The consistent **Speed Score of 1.0** across almost all valid submissions confirms that CPU offloading effectively eliminates the runtime bottleneck. The variance in algorithmic complexity (from simple Greedy in **Gen 73** to Beam Search in **Gen 79**) did not degrade the speed score, suggesting the time budget is permissive enough to support even moderately complex CPU-based heuristics, provided they avoid GPU synchronization.\n- **Complexity vs. Reward**: Comparison between **Generation 79** (Beam Search) and the **Current Best Program** (Greedy Swap) highlights a diminishing return on complexity. Both achieved identical scores (0.66), but the Beam Search implementation required significantly more logic to manage states, whereas the Current Best Program achieved the same result with a straightforward double loop.",
        "embed_cost": 7.978e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_90/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_90/results\nRun 1/5 completed in 0.40 seconds\nRun 2/5 completed in 0.62 seconds\nRun 3/5 completed in 0.62 seconds\nRun 4/5 completed in 0.62 seconds\nRun 5/5 completed in 0.61 seconds\nbalancedness: 0.2107368506889166\nbalancedness: 0.3397761404567239\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_90/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_90/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385886499905\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.3110771772999811, 'speed_score': 1.0}\n  execution_time_mean: 0.5738721265995992\n  execution_time_std: 0.08893975479711314\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 62,
          "average_cyclomatic_complexity": 12.4,
          "halstead_volume": 2103.594090718422,
          "halstead_difficulty": 12.790178571428571,
          "halstead_effort": 26905.344062090535,
          "lines_of_code": 453,
          "logical_lines_of_code": 229,
          "comments": 53,
          "maintainability_index": -43.599480584886834,
          "max_nesting_depth": 10,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "b28bb50e-1795-441e-9cb7-6dd2c830c7d3",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport heapq\nimport random\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: move sequential packing logic to CPU\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 2\n    max_refine_iters = 30\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Initial preparation: list of (index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending for construction heuristics\n        items_desc = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_spread = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            # 1. Construction Strategy\n            if attempt == 0:\n                # Deterministic ZigZag (Snake) Packing\n                # Distributes large items 0, 1, .. M-1, M-1, .. 0\n                for k, (idx, w) in enumerate(items_desc):\n                    cycle = k // num_packs\n                    rem = k % num_packs\n                    if cycle % 2 == 0:\n                        p = rem\n                    else:\n                        p = num_packs - 1 - rem\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Perturb weights slightly to generate different greedy orderings\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * random.random())) for (idx, w) in items]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Fill the lightest valid pack (Best Fit)\n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            for _ in range(max_refine_iters):\n                # Identify Extremes\n                min_p = 0\n                max_p = 0\n                min_w = pack_weights[0]\n                max_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                \n                curr_spread = max_w - min_w\n                if curr_spread < 1e-6:\n                    break\n                \n                improvement_found = False\n                \n                # A. Try 1-Swap (Max <-> Min)\n                # Swap u from Max, v from Min. Target delta = (Max - Min) / 2\n                target = curr_spread / 2.0\n                best_swap = None\n                best_gap = float('inf')\n                \n                # We need w_u - w_v > 0 to reduce max_p\n                # We iterate to find best swap\n                for i_u, (idx_u, w_u) in enumerate(current_packs[max_p]):\n                    for i_v, (idx_v, w_v) in enumerate(current_packs[min_p]):\n                        delta = w_u - w_v\n                        # Valid swap must reduce Max and not increase Min beyond old Max\n                        if 0 < delta < curr_spread:\n                            gap = abs(delta - target)\n                            if gap < best_gap:\n                                best_gap = gap\n                                best_swap = (i_u, i_v, delta)\n                                if gap < 1e-5: break\n                    if best_swap and best_gap < 1e-5: break\n\n                if best_swap and best_gap < curr_spread * 0.4: # Heuristic acceptance threshold\n                    i_u, i_v, delta = best_swap\n                    u_item = current_packs[max_p][i_u]\n                    v_item = current_packs[min_p][i_v]\n                    \n                    current_packs[max_p][i_u] = v_item\n                    current_packs[min_p][i_v] = u_item\n                    pack_weights[max_p] -= delta\n                    pack_weights[min_p] += delta\n                    improvement_found = True\n                \n                # B. Try 3-Cycle Refinement (Max -> Mid -> Min -> Max)\n                # If 1-swap failed (local optimum), try to bridge via a 3rd pack\n                # Flow: u (Max->Mid), v (Mid->Min), w (Min->Max)\n                if not improvement_found and num_packs > 2:\n                    best_cycle = None\n                    best_cycle_score = curr_spread\n                    \n                    # Candidates for intermediate pack. \n                    candidate_mids = [p for p in range(num_packs) if p != max_p and p != min_p]\n                    \n                    for p_mid in candidate_mids:\n                        w_mid = pack_weights[p_mid]\n                        \n                        p_max_items = current_packs[max_p]\n                        p_min_items = current_packs[min_p]\n                        p_mid_items = current_packs[p_mid]\n                        \n                        # Iterate items. Small N per pack makes this feasible (O(N^3)).\n                        for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                            for i_v, (idx_v, w_v) in enumerate(p_mid_items):\n                                delta_mid = w_u - w_v\n                                new_mid_w = w_mid + delta_mid\n                                \n                                # Pruning: Mid must stay within bounds (approx)\n                                if new_mid_w > max_w - 1e-4 or new_mid_w < min_w + 1e-4:\n                                    continue\n                                    \n                                for i_w, (idx_w, w_w) in enumerate(p_min_items):\n                                    delta_max = w_w - w_u # decreases Max\n                                    delta_min = w_v - w_w # increases Min\n                                    \n                                    new_max_w = max_w + delta_max\n                                    new_min_w = min_w + delta_min\n                                    \n                                    # Check strict improvement on bounds\n                                    if new_max_w < max_w and new_min_w > min_w:\n                                        # Calculate new local spread among these 3\n                                        local_max = max(new_max_w, new_min_w, new_mid_w)\n                                        local_min = min(new_max_w, new_min_w, new_mid_w)\n                                        score = local_max - local_min\n                                        \n                                        if score < best_cycle_score - 1e-5:\n                                            best_cycle_score = score\n                                            best_cycle = (p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w)\n                        \n                        if best_cycle and best_cycle_score < curr_spread * 0.9: \n                            break \n                            \n                    if best_cycle:\n                        p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w = best_cycle\n                        \n                        # Apply Cycle Swap\n                        # Note: Update inplace carefully\n                        current_packs[max_p][i_u] = (idx_w, w_w)\n                        current_packs[p_mid][i_v] = (idx_u, w_u)\n                        current_packs[min_p][i_w] = (idx_v, w_v)\n                        \n                        pack_weights[max_p] += (w_w - w_u)\n                        pack_weights[p_mid] += (w_u - w_v)\n                        pack_weights[min_p] += (w_v - w_w)\n                        \n                        improvement_found = True\n\n                if not improvement_found:\n                    break\n\n            # Save best result across restarts\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            spread = curr_max - curr_min\n            \n            if spread < best_spread:\n                best_spread = spread\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_spread < 1e-6: break\n\n        # Fill Result Tensor\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    # Pre-allocate output\n    phy2log = torch.arange(num_phy, dtype=torch.int64, device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Move to CPU for priority queue operations (faster for sequential insertions)\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n\n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n        \n        # Priority Queue: Stores (-score, expert_index, current_replica_count)\n        # Score = weight / count. We want max score. Heap is min-heap.\n        pq = []\n        for i in range(num_log):\n            score = w_row[i]\n            heapq.heappush(pq, (-score, i, 1))\n            \n        # Assign replicas greedy\n        for r in range(num_log, num_phy):\n            # Pick expert with highest average load\n            neg_score, idx, count = heapq.heappop(pq)\n            \n            # Assign new replica\n            phy2log_cpu[layer_idx, r] = idx\n            rank_cpu[layer_idx, r] = count\n            \n            # Update\n            new_count = count + 1\n            logcnt_cpu[layer_idx, idx] = new_count\n            \n            new_score = w_row[idx] / new_count\n            heapq.heappush(pq, (-new_score, idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "5a4bc1df-b1a0-4aac-af8e-2f3d752bf523",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "f4c9bdd0-7ef6-4b27-bd77-e2ae2c1aeef3"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 91,
      "timestamp": 1764180494.5688467,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,452 +1,453 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n+import heapq\n import random\n-import heapq\n-import math\n-\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n \n     Parameters:\n         weight: [X, n], the weight of each item\n         num_packs: number of packs\n \n     Returns:\n         pack_index: [X, n], the pack index of each item\n         rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     # Handle trivial case\n     if groups_per_pack == 1:\n         pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n                                   device=weight.device).expand(num_layers, -1)\n         rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n-    # Move to CPU for sequential processing\n+    # Optimization: move sequential packing logic to CPU\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n \n-    # Algorithm Parameters\n+    # Hyperparameters\n     num_restarts = 2\n-    lns_iterations = 50\n-    swap_iterations = 20\n+    max_refine_iters = 30\n \n     for i in range(num_layers):\n         row_weight = weight_cpu[i]\n-        row_weight_list = row_weight.tolist()\n-\n-        best_diff = float('inf')\n+        \n+        # Initial preparation: list of (index, weight)\n+        items = []\n+        for idx in range(num_groups):\n+            items.append((idx, row_weight[idx].item()))\n+        \n+        # Sort descending for construction heuristics\n+        items_desc = sorted(items, key=lambda x: x[1], reverse=True)\n+        \n+        best_spread = float('inf')\n         best_packs = None\n-        \n-        # Base sort indices (LPT)\n-        base_indices = torch.argsort(row_weight, descending=True).tolist()\n \n         for attempt in range(num_restarts):\n-            # 1. Randomized Greedy Initialization\n-            if attempt == 0:\n-                indices = base_indices\n-            else:\n-                # Add noise to weights to get different greedy orderings\n-                noise = torch.rand(num_groups, device=\"cpu\") * 0.1 + 0.95\n-                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n-\n             current_packs = [[] for _ in range(num_packs)]\n             pack_weights = [0.0] * num_packs\n             \n-            # Greedy LPT\n-            for group_idx in indices:\n-                w = row_weight_list[group_idx]\n-                # Assign to lightest pack with space\n-                best_p = -1\n-                min_val = float('inf')\n-                for p in range(num_packs):\n-                    if len(current_packs[p]) < groups_per_pack:\n-                        if pack_weights[p] < min_val:\n-                            min_val = pack_weights[p]\n-                            best_p = p\n-                current_packs[best_p].append(group_idx)\n-                pack_weights[best_p] += w\n-\n-            # 2. Large Neighborhood Search (LNS) Refinement\n-            # Pick subset of packs, pool items, and greedy-repack them\n-            for _ in range(lns_iterations):\n-                # Find Max and Min packs\n+            # 1. Construction Strategy\n+            if attempt == 0:\n+                # Deterministic ZigZag (Snake) Packing\n+                # Distributes large items 0, 1, .. M-1, M-1, .. 0\n+                for k, (idx, w) in enumerate(items_desc):\n+                    cycle = k // num_packs\n+                    rem = k % num_packs\n+                    if cycle % 2 == 0:\n+                        p = rem\n+                    else:\n+                        p = num_packs - 1 - rem\n+                    current_packs[p].append((idx, w))\n+                    pack_weights[p] += w\n+            else:\n+                # Randomized Greedy\n+                # Perturb weights slightly to generate different greedy orderings\n+                noisy_items = [(idx, w, w * (0.9 + 0.2 * random.random())) for (idx, w) in items]\n+                noisy_items.sort(key=lambda x: x[2], reverse=True)\n+                \n+                # Fill the lightest valid pack (Best Fit)\n+                for idx, w, _ in noisy_items:\n+                    best_p = -1\n+                    min_load = float('inf')\n+                    for p in range(num_packs):\n+                        if len(current_packs[p]) < groups_per_pack:\n+                            if pack_weights[p] < min_load:\n+                                min_load = pack_weights[p]\n+                                best_p = p\n+                    current_packs[best_p].append((idx, w))\n+                    pack_weights[best_p] += w\n+\n+            # 2. Refinement Loop\n+            for _ in range(max_refine_iters):\n+                # Identify Extremes\n                 min_p = 0\n                 max_p = 0\n                 min_w = pack_weights[0]\n                 max_w = pack_weights[0]\n                 \n                 for p in range(1, num_packs):\n-                    pw = pack_weights[p]\n-                    if pw < min_w:\n-                        min_w = pw\n+                    w = pack_weights[p]\n+                    if w < min_w:\n+                        min_w = w\n                         min_p = p\n-                    elif pw > max_w:\n-                        max_w = pw\n+                    if w > max_w:\n+                        max_w = w\n                         max_p = p\n                 \n-                if max_w - min_w < 1e-6:\n+                curr_spread = max_w - min_w\n+                if curr_spread < 1e-6:\n                     break\n                 \n-                # Select packs to reshuffle: Max, Min, and a Random one\n-                # Adding a random pack facilitates indirect transfers\n-                target_packs = [max_p, min_p]\n-                \n-                # Pick a random 3rd pack different from max_p and min_p\n-                if num_packs > 2:\n-                    while True:\n-                        r = random.randint(0, num_packs - 1)\n-                        if r != max_p and r != min_p:\n-                            target_packs.append(r)\n-                            break\n-                \n-                # Collect items\n-                pooled_items = [] # List of (index, weight)\n-                for p in target_packs:\n-                    for idx in current_packs[p]:\n-                        pooled_items.append((idx, row_weight_list[idx]))\n-                \n-                # Sort items descending for LPT\n-                pooled_items.sort(key=lambda x: x[1], reverse=True)\n-                \n-                # Try to repack\n-                # We do a simple greedy fill on these 3 packs\n-                temp_weights = [0.0] * len(target_packs)\n-                temp_packs = [[] for _ in target_packs]\n-                \n-                for idx, w in pooled_items:\n-                    # Find min loaded in temp subset\n-                    b_sub = 0\n-                    min_sub_w = float('inf')\n-                    for k in range(len(target_packs)):\n-                        if len(temp_packs[k]) < groups_per_pack:\n-                            if temp_weights[k] < min_sub_w:\n-                                min_sub_w = temp_weights[k]\n-                                b_sub = k\n-                    temp_packs[b_sub].append(idx)\n-                    temp_weights[b_sub] += w\n-                \n-                # Evaluate Improvement\n-                # We check if the spread of these specific packs decreased\n-                old_spread = max_w - min_w # Approximate (local view)\n-                \n-                # Calculate new spread contribution\n-                # We need to see if we reduced the max or increased the min of the GLOBAL set?\n-                # Actually, just checking if range(temp_weights) < range(old_weights of these packs) is a good proxy\n-                \n-                current_subset_weights = [pack_weights[p] for p in target_packs]\n-                new_subset_spread = max(temp_weights) - min(temp_weights)\n-                old_subset_spread = max(current_subset_weights) - min(current_subset_weights)\n-                \n-                if new_subset_spread < old_subset_spread - 1e-6:\n-                    # Apply change\n-                    for k, p in enumerate(target_packs):\n-                        current_packs[p] = temp_packs[k]\n-                        pack_weights[p] = temp_weights[k]\n-\n-            # 3. Fine-grained Pairwise Swaps\n-            for _ in range(swap_iterations):\n-                # Sort packs to identify Heavy -> Light directions\n-                sorted_packs = sorted(range(num_packs), \n-                                      key=pack_weights.__getitem__, \n-                                      reverse=True)\n-                \n-                found_swap = False\n-                for i1 in range(num_packs):\n-                    p1 = sorted_packs[i1]\n-                    # Only look at significantly lighter packs\n-                    for i2 in range(num_packs - 1, i1, -1):\n-                        p2 = sorted_packs[i2]\n-                        \n-                        diff = pack_weights[p1] - pack_weights[p2]\n-                        if diff < 1e-5: break # Optimization: stop if packs are balanced\n-                        \n-                        target = diff / 2.0\n-                        best_swap = None\n-                        best_gap = diff\n-                        \n-                        # Look for u in p1, v in p2 such that w_u > w_v\n-                        # and w_u - w_v approx target\n-                        for idx_u, u in enumerate(current_packs[p1]):\n-                            w_u = row_weight_list[u]\n-                            for idx_v, v in enumerate(current_packs[p2]):\n-                                w_v = row_weight_list[v]\n+                improvement_found = False\n+                \n+                # A. Try 1-Swap (Max <-> Min)\n+                # Swap u from Max, v from Min. Target delta = (Max - Min) / 2\n+                target = curr_spread / 2.0\n+                best_swap = None\n+                best_gap = float('inf')\n+                \n+                # We need w_u - w_v > 0 to reduce max_p\n+                # We iterate to find best swap\n+                for i_u, (idx_u, w_u) in enumerate(current_packs[max_p]):\n+                    for i_v, (idx_v, w_v) in enumerate(current_packs[min_p]):\n+                        delta = w_u - w_v\n+                        # Valid swap must reduce Max and not increase Min beyond old Max\n+                        if 0 < delta < curr_spread:\n+                            gap = abs(delta - target)\n+                            if gap < best_gap:\n+                                best_gap = gap\n+                                best_swap = (i_u, i_v, delta)\n+                                if gap < 1e-5: break\n+                    if best_swap and best_gap < 1e-5: break\n+\n+                if best_swap and best_gap < curr_spread * 0.4: # Heuristic acceptance threshold\n+                    i_u, i_v, delta = best_swap\n+                    u_item = current_packs[max_p][i_u]\n+                    v_item = current_packs[min_p][i_v]\n+                    \n+                    current_packs[max_p][i_u] = v_item\n+                    current_packs[min_p][i_v] = u_item\n+                    pack_weights[max_p] -= delta\n+                    pack_weights[min_p] += delta\n+                    improvement_found = True\n+                \n+                # B. Try 3-Cycle Refinement (Max -> Mid -> Min -> Max)\n+                # If 1-swap failed (local optimum), try to bridge via a 3rd pack\n+                # Flow: u (Max->Mid), v (Mid->Min), w (Min->Max)\n+                if not improvement_found and num_packs > 2:\n+                    best_cycle = None\n+                    best_cycle_score = curr_spread\n+                    \n+                    # Candidates for intermediate pack. \n+                    candidate_mids = [p for p in range(num_packs) if p != max_p and p != min_p]\n+                    \n+                    for p_mid in candidate_mids:\n+                        w_mid = pack_weights[p_mid]\n+                        \n+                        p_max_items = current_packs[max_p]\n+                        p_min_items = current_packs[min_p]\n+                        p_mid_items = current_packs[p_mid]\n+                        \n+                        # Iterate items. Small N per pack makes this feasible (O(N^3)).\n+                        for i_u, (idx_u, w_u) in enumerate(p_max_items):\n+                            for i_v, (idx_v, w_v) in enumerate(p_mid_items):\n+                                delta_mid = w_u - w_v\n+                                new_mid_w = w_mid + delta_mid\n                                 \n-                                delta = w_u - w_v\n-                                if 0 < delta < diff:\n-                                    gap = abs(delta - target)\n-                                    if gap < best_gap:\n-                                        best_gap = gap\n-                                        best_swap = (idx_u, idx_v, delta)\n-                                        if gap < 1e-6: break\n-                            if best_swap and best_gap < 1e-6: break\n-                        \n-                        if best_swap:\n-                            idx_u, idx_v, delta = best_swap\n-                            u = current_packs[p1][idx_u]\n-                            v = current_packs[p2][idx_v]\n+                                # Pruning: Mid must stay within bounds (approx)\n+                                if new_mid_w > max_w - 1e-4 or new_mid_w < min_w + 1e-4:\n+                                    continue\n+                                    \n+                                for i_w, (idx_w, w_w) in enumerate(p_min_items):\n+                                    delta_max = w_w - w_u # decreases Max\n+                                    delta_min = w_v - w_w # increases Min\n+                                    \n+                                    new_max_w = max_w + delta_max\n+                                    new_min_w = min_w + delta_min\n+                                    \n+                                    # Check strict improvement on bounds\n+                                    if new_max_w < max_w and new_min_w > min_w:\n+                                        # Calculate new local spread among these 3\n+                                        local_max = max(new_max_w, new_min_w, new_mid_w)\n+                                        local_min = min(new_max_w, new_min_w, new_mid_w)\n+                                        score = local_max - local_min\n+                                        \n+                                        if score < best_cycle_score - 1e-5:\n+                                            best_cycle_score = score\n+                                            best_cycle = (p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w)\n+                        \n+                        if best_cycle and best_cycle_score < curr_spread * 0.9: \n+                            break \n                             \n-                            current_packs[p1][idx_u] = v\n-                            current_packs[p2][idx_v] = u\n-                            pack_weights[p1] -= delta\n-                            pack_weights[p2] += delta\n-                            found_swap = True\n-                            break\n-                    if found_swap: break\n-                if not found_swap: break\n-\n-            # 4. Update Best Global Solution\n+                    if best_cycle:\n+                        p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w = best_cycle\n+                        \n+                        # Apply Cycle Swap\n+                        # Note: Update inplace carefully\n+                        current_packs[max_p][i_u] = (idx_w, w_w)\n+                        current_packs[p_mid][i_v] = (idx_u, w_u)\n+                        current_packs[min_p][i_w] = (idx_v, w_v)\n+                        \n+                        pack_weights[max_p] += (w_w - w_u)\n+                        pack_weights[p_mid] += (w_u - w_v)\n+                        pack_weights[min_p] += (w_v - w_w)\n+                        \n+                        improvement_found = True\n+\n+                if not improvement_found:\n+                    break\n+\n+            # Save best result across restarts\n             curr_max = max(pack_weights)\n             curr_min = min(pack_weights)\n-            curr_diff = curr_max - curr_min\n-            \n-            if curr_diff < best_diff:\n-                best_diff = curr_diff\n-                best_packs = [list(p) for p in current_packs]\n-                if best_diff < 1e-6: break\n-\n-        # Fill output\n+            spread = curr_max - curr_min\n+            \n+            if spread < best_spread:\n+                best_spread = spread\n+                best_packs = [list(p) for p in current_packs] # Deep copy\n+                if best_spread < 1e-6: break\n+\n+        # Fill Result Tensor\n         for p in range(num_packs):\n-            for r, g in enumerate(best_packs[p]):\n-                pack_index[i, g] = p\n-                rank_in_pack[i, g] = r\n+            for r, (idx, _) in enumerate(best_packs[p]):\n+                pack_index[i, idx] = p\n+                rank_in_pack[i, idx] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n \n     Parameters:\n         weight: [X, num_log]\n         num_phy: total number of experts after replication\n \n     Returns:\n         phy2log: [X, num_phy], logical expert id of each physical expert\n         rank: [X, num_phy], the replica rank\n         logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n     \n-    # Pre-allocate output tensors\n-    phy2log = torch.arange(num_phy, dtype=torch.int64,\n-                           device=device).repeat(n, 1)\n+    # Pre-allocate output\n+    phy2log = torch.arange(num_phy, dtype=torch.int64, device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     \n-    # If no replication needed, return immediately\n     if num_redundant == 0:\n         return phy2log, rank, logcnt\n \n-    # Processing on CPU using heapq is often faster for sparse/sequential updates\n-    # than repeated GPU kernels (max/argmax) when num_redundant is large.\n+    # Move to CPU for priority queue operations (faster for sequential insertions)\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     phy2log_cpu = phy2log.to(\"cpu\")\n     rank_cpu = rank.to(\"cpu\")\n     logcnt_cpu = logcnt.to(\"cpu\")\n-    \n+\n     for layer_idx in range(n):\n         w_row = weight_cpu[layer_idx].tolist()\n         \n-        # Priority queue stores (-score, expert_idx, current_count)\n-        # We use negative score because heapq is a min-heap\n+        # Priority Queue: Stores (-score, expert_index, current_replica_count)\n+        # Score = weight / count. We want max score. Heap is min-heap.\n         pq = []\n         for i in range(num_log):\n-            # Initial score is weight / 1\n-            heapq.heappush(pq, (-w_row[i], i, 1))\n-        \n-        # Assign replicas one by one\n-        for r_idx in range(num_log, num_phy):\n-            score_neg, expert_idx, count = heapq.heappop(pq)\n-            \n-            # Assign the new replica\n-            phy2log_cpu[layer_idx, r_idx] = expert_idx\n-            rank_cpu[layer_idx, r_idx] = count\n-            \n-            # Update count and push back with new score\n+            score = w_row[i]\n+            heapq.heappush(pq, (-score, i, 1))\n+            \n+        # Assign replicas greedy\n+        for r in range(num_log, num_phy):\n+            # Pick expert with highest average load\n+            neg_score, idx, count = heapq.heappop(pq)\n+            \n+            # Assign new replica\n+            phy2log_cpu[layer_idx, r] = idx\n+            rank_cpu[layer_idx, r] = count\n+            \n+            # Update\n             new_count = count + 1\n-            logcnt_cpu[layer_idx, expert_idx] = new_count\n-            new_score_neg = -w_row[expert_idx] / new_count\n-            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n+            logcnt_cpu[layer_idx, idx] = new_count\n+            \n+            new_score = w_row[idx] / new_count\n+            heapq.heappush(pq, (-new_score, idx, new_count))\n \n     return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Parameters:\n         weight: [num_moe_layers, num_logical_experts]\n         num_physical_experts: number of physical experts after replication\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n         (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [num_moe_layers, num_physical_experts]\n         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n         logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n \n     Parameters:\n         weight: [layers, num_logical_experts], the load statistics for all\n             logical experts\n         num_replicas: number of physical experts, must be a multiple of\n             `num_gpus`\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n             (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [layers, num_replicas], the expert index of\n             each replica\n         logical_to_physical_map: [layers, num_logical_experts, X], the replica\n             indices for each expert\n         expert_count: [layers, num_logical_experts], number of physical\n             replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n \n \n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385873149429,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.3110771746298858,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.05443374,
        0.021463431,
        0.014630503,
        -0.037598327,
        -0.024391828,
        0.015560701,
        -0.009979519,
        -0.009411066,
        -0.025264606,
        0.028503068,
        0.03238463,
        0.021612722,
        -0.011828429,
        -0.023036726,
        0.015273603,
        0.01541141,
        -0.012574883,
        0.014274502,
        -0.004561984,
        0.052136958,
        0.006884605,
        -0.009112484,
        0.026780482,
        -0.042283762,
        -0.0015948282,
        0.011254233,
        0.061002538,
        -0.042812023,
        0.030524237,
        -0.048278365,
        0.07703408,
        -0.010708747,
        0.014676439,
        0.0023068308,
        -0.016800962,
        0.032958828,
        -0.006758282,
        0.012333721,
        0.016513865,
        0.06233467,
        0.025999576,
        -0.024047311,
        -0.044373833,
        0.04028556,
        -0.038884524,
        0.03344115,
        0.0065745395,
        -0.0070626056,
        0.07712595,
        0.0039217556,
        0.035898708,
        0.014412309,
        -0.0020441362,
        0.06499894,
        0.028020745,
        0.042972796,
        0.020797364,
        0.019292971,
        0.018374259,
        -0.04621126,
        0.05222883,
        -0.015905218,
        0.07170554,
        0.04200815,
        -0.030891722,
        0.0040854015,
        -0.03546232,
        0.02880165,
        0.021612722,
        -0.012149978,
        -0.03842517,
        0.046372034,
        -0.02216395,
        -0.025976608,
        0.0003814812,
        0.005029953,
        -0.01931594,
        0.044258997,
        -0.029444749,
        -0.044488672,
        -0.030317526,
        -0.0069535086,
        0.05190728,
        0.021566786,
        0.012540432,
        -0.0748751,
        -0.019396327,
        -0.039504655,
        -0.034061283,
        -0.022772597,
        0.034566574,
        -0.047543395,
        -0.0012768675,
        0.031511854,
        0.040882725,
        -0.03261431,
        0.06270216,
        0.014515664,
        0.030845787,
        0.057235815,
        -0.012287785,
        0.01588225,
        -0.05677646,
        0.0030977852,
        0.029444749,
        0.008630159,
        0.005084502,
        -0.0018101516,
        0.011759525,
        -0.017708192,
        -0.039297946,
        0.018282387,
        0.033510055,
        0.00962926,
        0.016180832,
        0.007039638,
        -0.044787254,
        -0.022715177,
        0.00960055,
        -0.025976608,
        -0.027262807,
        -0.0390453,
        0.024828216,
        -0.02565506,
        0.008210997,
        -0.03757536,
        0.010278101,
        -0.0337627,
        0.008710547,
        0.0012811739,
        0.04198518,
        0.023496084,
        0.007923899,
        -0.020774396,
        -0.023174534,
        0.005308438,
        -0.023381244,
        0.0074071228,
        -0.005896989,
        -0.01835129,
        -0.025723962,
        0.030294558,
        -0.011943268,
        -0.0072061545,
        -0.0489674,
        0.05443374,
        -0.002101556,
        0.014308954,
        -0.038149554,
        0.030776883,
        0.01761632,
        -0.0351178,
        -0.013344306,
        -0.012701206,
        0.00095531787,
        -0.010519263,
        0.008331578,
        0.019786779,
        0.08227074,
        -0.035508256,
        -0.030317526,
        0.02880165,
        -0.025563188,
        0.021360075,
        0.033923473,
        0.027814034,
        -0.051126376,
        0.005213696,
        -0.056914266,
        -0.05948666,
        -0.0049093724,
        -0.019775296,
        -0.008767966,
        -0.014423793,
        0.0039131427,
        0.015847798,
        -0.023725761,
        -0.035990577,
        -0.028526036,
        -0.04017072,
        -0.022095045,
        -0.010967135,
        -0.015216183,
        -0.0074760267,
        -0.048094623,
        0.028020745,
        -0.031190304,
        -0.012368172,
        -0.008446417,
        -0.005360116,
        0.014584567,
        0.045131773,
        -0.03546232,
        0.034566574,
        -0.0020154265,
        -0.019292971,
        0.054525614,
        0.016364574,
        0.0033044955,
        -0.0065745395,
        -0.03789691,
        -0.013459144,
        0.03927498,
        -0.04019369,
        0.046050485,
        0.03438283,
        -0.010645586,
        0.011047523,
        0.011989203,
        -0.0055151484,
        0.032200888,
        -0.024644474,
        0.037621293,
        -0.0045993067,
        -0.02639003,
        -0.032545406,
        -0.051677603,
        0.016169347,
        0.0025465575,
        0.06692824,
        -0.02037246,
        0.018500581,
        -0.026091447,
        0.005561084,
        -0.04317951,
        0.022244336,
        0.04726778,
        -0.017053608,
        0.006212796,
        0.0060807313,
        -0.028319325,
        -0.0014031904,
        -0.011615977,
        -0.029628491,
        0.03185637,
        -0.03229276,
        -0.032522436,
        0.020498782,
        -0.016100444,
        -0.036128387,
        0.017570384,
        0.041433953,
        0.012035139,
        -0.046992168,
        0.00833732,
        0.016536832,
        -0.041227244,
        -0.014756827,
        0.0055409875,
        -0.024254022,
        0.019717876,
        -0.04609642,
        0.02531054,
        -0.05907324,
        -0.015916701,
        0.03135108,
        -0.0228415,
        -0.05443374,
        -0.018500581,
        -0.030983593,
        0.01588225,
        -0.01735219,
        -0.003135108,
        -0.024116214,
        -0.0202002,
        -0.0028236068,
        -0.0044586286,
        0.036105417,
        -0.049426757,
        -0.019442262,
        0.03272915,
        0.018477613,
        -0.013849597,
        0.034520637,
        -0.044281963,
        -0.017512966,
        0.0031379787,
        -0.017983805,
        -0.030868754,
        -0.043638863,
        -0.024644474,
        0.0012352383,
        0.040974595,
        -0.0015474571,
        0.01197772,
        -0.0038212715,
        -0.0025824446,
        0.027630292,
        0.00954313,
        -0.022439564,
        0.0038729492,
        -0.020062394,
        0.036404,
        0.014159663,
        -0.011725074,
        -0.01931594,
        -0.056271166,
        -0.017156964,
        -0.000938092,
        -0.0074645425,
        0.008630159,
        -0.00519647,
        -0.008228223,
        0.007648285,
        -0.00751622,
        -0.024736345,
        -0.019281488,
        0.018477613,
        -0.0151128275,
        -0.023978407,
        -0.014366373,
        0.012012172,
        -0.018397227,
        0.0016249735,
        -0.029904107,
        0.0015704249,
        0.030662043,
        0.001825942,
        -0.014515664,
        -0.05204509,
        -0.05581181,
        -0.04294983,
        0.041273177,
        0.024391828,
        0.0009488582,
        0.021061493,
        -0.043776672,
        0.01846613,
        -0.008492352,
        -0.014906118,
        0.008658869,
        0.042237826,
        0.031190304,
        0.024070278,
        0.009991003,
        -0.04147989,
        0.03091469,
        -0.0025680896,
        0.044925064,
        0.019304456,
        -0.059165113,
        0.022336207,
        -0.01344766,
        -0.023909504,
        -0.048599914,
        0.020406911,
        0.060543183,
        0.028089648,
        0.025517251,
        0.076482855,
        -0.03642697,
        -0.01576741,
        -0.014308954,
        0.016364574,
        0.011782493,
        -0.02295634,
        0.0015230537,
        0.0045505,
        -0.045499258,
        0.0052739866,
        -0.02733171,
        -0.007108541,
        0.028250422,
        -0.0040968857,
        -0.008538288,
        0.06486113,
        0.02985817,
        0.016973222,
        0.0074300906,
        0.008245449,
        0.04019369,
        -0.0032097532,
        -0.025448348,
        0.008710547,
        -0.00839474,
        -0.014791278,
        0.022508467,
        0.056454908,
        -0.029261006,
        0.0038327554,
        0.024276989,
        0.019855684,
        -0.0218424,
        0.010180487,
        0.018454647,
        0.03587574,
        -0.010984361,
        0.017019156,
        -0.07354297,
        0.008400481,
        0.048508044,
        -0.014205598,
        -0.020762913,
        -0.045499258,
        0.03732271,
        -0.013195015,
        -0.03713897,
        -0.02542538,
        0.044856157,
        0.009841712,
        -0.010054165,
        0.005853924,
        -0.039527625,
        -0.016433477,
        -0.025586154,
        0.01271269,
        0.04749746,
        0.017421095,
        -0.006471184,
        0.044258997,
        0.028778682,
        -0.032775085,
        0.010611135,
        0.00598886,
        0.012494496,
        -0.037506454,
        0.0016924415,
        0.039412785,
        0.0034135927,
        -0.00839474,
        -0.008228223,
        -0.008084673,
        0.018891035,
        -0.004820372,
        -0.016536832,
        0.01603154,
        0.016927285,
        -0.016869865,
        0.013068692,
        -0.06261028,
        -0.013252434,
        0.003918885,
        0.06398836,
        -0.03017972,
        0.020671042,
        0.039619494,
        -0.003987788,
        0.026458932,
        -0.0019537006,
        -0.003120753,
        0.008233964,
        -0.016376058,
        -0.013252434,
        -0.020659557,
        0.023771698,
        -0.012839013,
        0.0068903468,
        -0.05278006,
        0.05085076,
        -0.0066893785,
        0.014320438,
        -0.01403334,
        0.05328535,
        0.006103699,
        -0.02157827,
        -0.053101607,
        0.07184335,
        0.034107216,
        0.051218245,
        -0.021520851,
        0.042031117,
        0.016238252,
        0.002639864,
        -0.027147967,
        0.053101607,
        0.018029742,
        0.008107642,
        -0.003654755,
        0.00825119,
        0.02636706,
        0.06022163,
        -0.048462108,
        -0.00143836,
        0.03796581,
        -0.028411197,
        0.011380556,
        -0.013309853,
        0.06729572,
        0.030570172,
        -0.0470381,
        0.027997777,
        -0.048691787,
        -0.031718563,
        -0.041824404,
        0.028411197,
        0.02565506,
        0.03408425,
        0.0003547452,
        1.1242794e-05,
        0.028112616,
        0.03217792,
        -0.013011272,
        0.00883687,
        -0.009904874,
        -0.00079813186,
        -0.006385055,
        -0.014687923,
        -0.02554022,
        0.00452179,
        0.048324298,
        0.0073784133,
        -0.0854403,
        -0.059440725,
        -0.022451047,
        0.015503281,
        -0.033923473,
        -0.029904107,
        -0.0007486075,
        -0.006241506,
        0.038494073,
        -0.017972322,
        -0.00886558,
        0.026206287,
        0.030202687,
        -0.008004286,
        0.03817252,
        -0.0058855047,
        0.009566098,
        0.0074817683,
        0.03153482,
        -0.030156752,
        -0.021348592,
        -0.049197078,
        0.023932472,
        0.030317526,
        -0.034428768,
        -0.014527149,
        -0.052871928,
        0.014596052,
        -0.0061611184,
        -0.01523915,
        -0.014056308,
        -0.05181541,
        0.031626694,
        -0.018270904,
        0.029077264,
        -0.0021833787,
        -0.04113537,
        -0.029582556,
        -0.038471103,
        0.0051677604,
        0.014550116,
        0.01999349,
        0.02316305,
        0.011541331,
        -0.038126588,
        0.06917908,
        0.027607324,
        0.027997777,
        0.025172735,
        0.007941125,
        -0.044052284,
        0.0027417839,
        -0.0026298158,
        -0.02932991,
        -0.018454647,
        -0.010553715,
        -0.047221843,
        0.028526036,
        0.048599914,
        0.021865368,
        -0.004958179,
        0.0101230685,
        -0.00053220754,
        -0.00023631737,
        0.011173846,
        0.021922788,
        -0.041388016,
        0.01688135,
        0.0028824618,
        -0.009738357,
        0.01324095,
        0.010312553,
        -0.062931836,
        0.023002274,
        -0.0036892067,
        0.021497883,
        -0.024070278,
        -0.0046194033,
        -0.0072061545,
        -0.02795184,
        -0.022611821,
        -0.014274502,
        -0.02733171,
        -0.056225233,
        -0.008842612,
        -0.030547205,
        -0.011771009,
        -0.0051763733,
        -0.028962426,
        -0.0046050483,
        0.000971826,
        0.038333297,
        -0.015537732,
        0.015445861,
        -0.0065975073,
        -0.03874672,
        0.011667654,
        0.028227454,
        0.009261775,
        -0.017719675,
        0.06283996,
        0.0032183663,
        0.019832715,
        -0.02636706,
        0.0030863013,
        0.008055964,
        0.0059027304,
        0.0038442395,
        -0.031902306,
        -0.008842612,
        -0.017444061,
        -0.031121401,
        -0.009491453,
        -0.007395639,
        0.004553371,
        0.055122774,
        0.0063104094,
        0.012299269,
        -0.021015558,
        -0.010582425,
        0.042375635,
        0.014389341,
        -0.017111028,
        -0.0013866823,
        -0.01068578,
        -0.01144946,
        -0.002747526,
        -0.028709779,
        0.016548317,
        -0.039068267,
        -0.016548317,
        -0.024024343,
        0.027147967,
        -0.0018603937,
        0.06651481,
        0.023392728,
        0.034888122,
        0.0074588004,
        -0.013516564,
        0.02604551,
        -0.0077401563,
        0.0145616,
        -0.03978027,
        0.01244856,
        0.021417495,
        -0.003766723,
        -0.0070798313,
        0.009405323,
        -0.011087717,
        -0.0036978195,
        -0.017777095,
        0.034061283,
        0.03619729,
        0.029582556,
        -0.016800962,
        -0.012035139,
        -0.035898708,
        -0.030041913,
        0.0012338028,
        -0.034957025,
        -0.010984361,
        -0.010169004,
        -0.020073878,
        0.013413209,
        0.027653258,
        0.022014659,
        0.0036317871,
        0.005681665,
        0.048599914,
        -0.005609891,
        0.028227454,
        0.024713378,
        -0.044465706,
        -0.038103618,
        -0.020062394,
        -0.026665643,
        0.013998888,
        0.0029255266,
        0.018420193,
        0.011013071,
        -0.020590654,
        -0.031672627,
        -0.009353646,
        -0.00957184,
        0.027239839,
        0.021038527,
        -0.0008555514,
        0.035646062,
        -0.01925852,
        0.016180832,
        -0.011323137,
        -0.03766723,
        -0.014354889,
        0.016697608,
        0.04313357,
        0.010645586,
        0.009502937,
        -0.019063294,
        -0.043317314,
        -0.012816045,
        -0.0007521962,
        -0.02574693,
        -0.010622618,
        -0.03808065,
        -0.018397227,
        -0.044787254,
        0.047129974,
        0.022474015,
        -0.0023843471,
        -0.040882725,
        0.0039648204,
        -0.021497883,
        -0.018374259,
        -0.06711198,
        0.0052854703,
        -0.000120042765,
        0.012930884,
        0.02531054,
        -0.040767886,
        -0.007832028,
        0.003491109,
        -0.03628916,
        0.001109633,
        0.04988611,
        0.016421994,
        0.012310754,
        0.0030748174,
        0.007165961,
        -0.0024374602,
        0.009703905,
        -0.0154803125,
        0.01899439,
        -0.034911092,
        0.03936685,
        -0.007969835,
        -0.0007557849,
        -0.034176122,
        -0.024506668,
        0.011145136,
        -0.00783777,
        -0.023381244,
        0.013723275,
        -0.0057907626,
        0.008802419,
        0.0038155296,
        -0.004929469,
        0.034865156,
        -0.01535399,
        0.022462532,
        -0.033418182,
        0.0064080227,
        -0.027928872,
        -0.0039332397,
        0.04460351,
        0.032958828,
        0.015181731,
        -0.007648285,
        -0.0042519183,
        0.0075793816,
        -0.01873026,
        -0.015687022,
        -0.02304821,
        0.01714548,
        0.012333721,
        0.0057419557,
        -0.049197078,
        -0.0036978195,
        0.011489654,
        -0.040561177,
        -0.024874153,
        -0.010507779,
        0.047405586,
        0.04979424,
        0.026642675,
        -0.03831033,
        0.01397592,
        -0.051861346,
        0.008010028,
        -0.021911303,
        -0.016755028,
        -0.022715177,
        -0.032522436,
        0.0028365261,
        0.0022896049,
        0.004834727,
        -0.057419557,
        -0.024047311,
        -0.009680937,
        -0.011524105,
        -0.06086473,
        -0.014435276,
        0.0017800063,
        -0.022852983,
        -0.012930884,
        0.015928185,
        -0.037184905,
        -0.05108044,
        0.008388997,
        0.01908626,
        -0.0045820805,
        0.0023039598,
        0.02178498,
        -0.001752732,
        -0.012276301,
        -0.012287785,
        -0.056225233,
        0.006413765,
        -0.040147755,
        0.01644496,
        0.018489098,
        0.0004496669,
        -0.033510055,
        0.0046222745,
        0.064631455,
        -0.023151565,
        -0.04460351,
        -0.045774873,
        0.029306943,
        -0.010771909,
        -0.027262807,
        -0.04749746,
        0.044281963,
        0.010174746,
        -0.048278365,
        -0.01397592,
        -0.011719332,
        0.0012560529,
        0.010461844,
        -0.015790379,
        0.00242167,
        -0.023771698,
        0.0074415747,
        0.011805461,
        0.0059142145,
        0.01150688,
        0.0053916965,
        -0.007504736,
        -0.006362087,
        0.027170936,
        0.03144295,
        0.010105842,
        0.0015187473,
        -0.026298158,
        0.016456446,
        0.010817844,
        0.03989511,
        0.037368648,
        -0.025333509,
        -0.014894634,
        -0.016904319,
        0.010789135,
        0.025792865,
        -0.011954752,
        -0.005618504,
        0.020395426,
        0.015985604,
        -0.006867379,
        0.015618119,
        -0.007843511,
        -0.014285986,
        -0.041388016,
        0.012299269,
        -0.028411197,
        0.006390797,
        -0.0244837,
        0.026091447,
        0.033487085,
        -0.003634658,
        -0.00030970675,
        0.011093458,
        -0.030570172,
        0.019212585,
        0.02005091,
        -0.012104043,
        -0.017926386,
        -0.014366373,
        0.017271804,
        -0.04017072,
        -0.016594252,
        -0.0022250079,
        -0.01629567,
        -0.01350508,
        0.008084673,
        -0.0043236925,
        0.018558001,
        0.005429019,
        -0.00253938,
        0.032935858,
        0.02457557,
        -0.0016766511,
        0.0061783446,
        0.01508986,
        0.017811546,
        0.029421782,
        0.03038643,
        -0.0081650615,
        -0.0026728804,
        0.027079064,
        -0.0027303,
        -0.010783393,
        0.0034681412,
        -0.015135796,
        0.04676249,
        -0.01682393,
        -0.012356689,
        -0.0060577635,
        0.011426492,
        0.027997777,
        -0.051723536,
        0.07308362,
        -0.010502038,
        -0.03334928,
        -0.010829329,
        0.007504736,
        -0.024552602,
        0.013539532,
        0.025471317,
        0.009152678,
        -0.00076439785,
        0.02595364,
        -0.021233752,
        0.007131509,
        0.01282753,
        0.010335521,
        -0.0033131086,
        0.010398682,
        -0.038540006,
        0.05255038,
        -0.013424693,
        0.013803662,
        -0.021383043,
        0.023679826,
        -0.0033332054,
        0.004125595,
        -0.010438875,
        -0.013665855,
        -0.007900931,
        -0.015147279,
        0.0034882382,
        -0.05273412,
        -0.009824486,
        -0.0029341395,
        0.018133096,
        -0.032752115,
        -0.032200888,
        -0.0041227243,
        -0.011943268,
        -0.015308054,
        -0.016927285,
        0.03270618,
        -0.049426757,
        0.056225233,
        0.0025709607,
        -0.03226979,
        0.034176122,
        0.0078090597,
        -0.003361915,
        0.0021187817,
        0.020659557,
        0.03948169,
        -0.0020068137,
        -0.023140082,
        0.00428637,
        0.01461902,
        0.009830228,
        0.0057362136,
        -0.0063104094,
        -0.046050485,
        0.012023656,
        0.035163738,
        -0.020452846,
        0.022875952,
        -0.0065630553,
        0.012333721,
        -0.04529255,
        0.008934483,
        -0.013884049,
        0.05677646,
        -0.015583668,
        0.017111028,
        0.006115183,
        -0.04244454,
        0.027791066,
        0.054479677,
        -0.006132409,
        0.04545332,
        0.0023125727,
        0.0074645425,
        -0.026435964,
        0.057052072,
        0.029215071,
        0.008538288,
        -0.0059027304,
        0.009663711,
        0.010961394,
        -0.014607536,
        -0.017926386,
        -0.023151565,
        -0.00698796,
        -0.036151353,
        0.00502134,
        0.028755715,
        -0.004783049,
        0.011374814,
        0.004533274,
        0.018247936,
        -0.017891934,
        0.005437632,
        0.005848182,
        0.028893521,
        -0.036771484,
        -0.017375158,
        0.01593967,
        -0.04019369,
        -0.01068578,
        -0.03135108,
        0.009623518,
        -0.02838823,
        -0.00880816,
        -0.0059371823,
        -0.044856157,
        0.0022738145,
        -0.012437076,
        -0.015170247,
        0.010639844,
        0.023863569,
        -0.043960415,
        0.020648073,
        -0.019591553,
        0.028020745,
        -0.005805117,
        -0.029720362,
        0.019097745,
        -0.013493596,
        -0.040469304,
        -0.0034652704,
        0.026435964,
        0.023817632,
        0.0031006562,
        -0.026458932,
        0.031603724,
        -0.026527835,
        0.017168447,
        0.028250422,
        -0.005380213,
        -0.0050902436,
        0.013011272,
        -0.013551015,
        -0.009520163,
        -0.05939479,
        -0.0057620527,
        -0.011351846,
        0.030156752,
        0.025264606,
        0.019511165,
        -0.0007080549,
        0.0030288817,
        -0.0006951355,
        -0.009238807,
        0.022186916,
        0.0047600814,
        -0.043707766,
        -0.018810647,
        0.011386299,
        0.012299269,
        -0.026849385,
        -0.020349491,
        0.00038291668,
        0.0013830937,
        0.0001446255,
        0.006901831,
        -0.012930884,
        0.019786779,
        0.010237907,
        -0.005357245,
        0.0038901751,
        0.019270003,
        -0.010823587,
        -0.046280164,
        -0.006230022,
        0.0033590442,
        0.0019048938,
        -0.0038212715,
        -0.015801862,
        0.041824404,
        0.03955059,
        0.002078588,
        0.015755927,
        -0.025700994,
        -0.0046366295,
        0.02122227,
        0.029398814,
        -0.008239707,
        0.01482573,
        -0.02310563,
        0.019155165,
        0.016307155,
        -0.022887437,
        0.012253334,
        0.0021417495,
        0.003628916,
        -0.004435661,
        -0.01012881,
        -0.028617907,
        -0.04262828,
        -0.011443718,
        -0.009434033,
        0.025700994,
        -0.009899132,
        0.031741533,
        -0.015158763,
        0.022680726,
        0.02868681,
        -0.004125595,
        -0.02316305,
        0.0025939285,
        -0.0062759575,
        0.021038527,
        0.021830916,
        -0.021601237,
        0.0019967651,
        -0.029215071,
        0.03546232,
        -0.03070798,
        -0.004188757,
        0.008176545,
        0.024116214,
        0.0175589,
        -0.0028293487,
        0.027928872,
        -0.06091067,
        0.032775085,
        0.02237066,
        -0.009215839,
        -0.019694908,
        -0.033487085,
        0.008475127,
        -0.0053830836,
        0.03399238,
        0.00017809034,
        -0.017891934,
        0.041204274,
        0.015468829,
        -0.0010723103,
        -0.0037868198,
        0.0056615686,
        0.07271613,
        0.005624246,
        -0.0038155296,
        0.010191971,
        0.011041781,
        0.02753842,
        -0.019281488,
        -0.005170631,
        0.018500581,
        -0.04313357,
        -0.029835202,
        0.030891722,
        -0.004808888,
        -0.021383043,
        -0.00622428,
        0.018328322,
        -0.043409187,
        0.01693877,
        -0.020602137,
        0.015009472,
        -0.008010028,
        -0.0006474055,
        -0.0056500845,
        -0.020671042,
        0.0019249907,
        -0.031695597,
        0.0046194033,
        -0.023587955,
        -0.016123412,
        0.021210784,
        -0.024529636,
        -0.027308742,
        0.008951709,
        0.007395639,
        -0.015066892,
        0.016261218,
        0.019821232,
        0.00413995,
        -0.0025695253,
        0.010909716,
        -0.016169347,
        -0.005207954,
        -0.031511854,
        -0.015549216,
        -0.01946523,
        -0.0073209936,
        -0.019178132,
        0.01729477,
        0.0066549266,
        0.0049868887,
        0.008521062,
        -0.01541141,
        0.0043208217,
        -0.023610922,
        -0.023381244,
        0.002915478,
        0.034107216,
        0.062288735,
        -0.04063008,
        0.010748941,
        -0.006850153,
        -0.004059563,
        -0.0055151484,
        0.027630292,
        0.01529657,
        -0.015893733,
        -0.014791278,
        -0.024139183,
        -0.013723275,
        0.02900836,
        -0.025976608,
        -0.002606848,
        -0.006097957,
        -0.022014659,
        0.02891649,
        -0.0048031462,
        -0.012391141,
        0.023725761,
        0.017823031,
        -0.036449935,
        -0.012563399,
        0.009301968,
        -0.0012517463,
        0.011369073,
        -0.030018944,
        -0.027584355,
        0.032637276,
        0.021750528,
        -0.028365262,
        0.0035313028,
        -0.0064080227,
        0.020969622,
        0.02659674,
        0.04051524,
        -0.019419294,
        -0.012218882,
        -0.005466342,
        -0.008612934,
        -0.011196814,
        0.025195703,
        -0.012172947,
        0.013907017,
        0.012781594,
        0.018914003,
        -0.02336976,
        0.03828736,
        -0.004326564,
        -0.007654027,
        -0.04244454,
        -0.050023917,
        0.03766723,
        -0.0030633335,
        0.027837,
        -0.038976397,
        -0.038976397,
        0.03902233,
        0.04189331,
        0.036679614,
        -0.013608435,
        -0.0153310215,
        0.020487297,
        -0.010720232,
        0.0070798313,
        0.005825214,
        -0.033326313,
        0.027768098,
        0.004165789,
        0.03672555,
        -0.021486398,
        0.011828429,
        0.005509407,
        -0.013344306,
        0.028755715,
        -0.014929085,
        0.033395216,
        -0.00064453454,
        0.0034824961,
        -0.036794454,
        -0.016927285,
        0.039389815,
        -0.03927498,
        0.011300169,
        0.009721131,
        0.030018944,
        -0.039229043,
        0.00038973524,
        0.021612722,
        -0.015250634,
        0.037621293,
        -0.023381244,
        0.023266405,
        -0.02531054,
        -0.018707292,
        -0.04170957,
        0.015560701,
        -0.017214384,
        -0.003393496,
        0.011805461,
        0.009296226,
        -0.00042992894,
        -0.01846613,
        -0.022347692,
        -0.015549216,
        0.018397227,
        0.01599709,
        0.011466686,
        -0.02216395,
        0.007361187,
        0.02838823,
        0.018454647,
        0.013022755,
        0.009416807,
        0.01858097,
        -0.022278788,
        -0.010105842,
        -0.0053629866,
        0.008457901,
        -0.0075564138,
        0.001623538,
        0.021187818,
        -0.022290273,
        0.021095946,
        0.02604551,
        -2.920323e-05,
        0.028296359,
        -0.057052072,
        -0.0009474227,
        0.0051218243,
        0.027974809,
        0.008084673,
        0.034428768,
        -0.0008892854,
        0.02172756,
        -0.013642887,
        0.04221486,
        0.03314257,
        -0.01752445,
        0.005638601,
        -0.010289585,
        0.021704594,
        0.029628491,
        0.016525349,
        -0.012379657,
        -0.030501269,
        -0.012781594,
        0.02480525,
        0.00040121915,
        0.016869865,
        0.020590654,
        -0.05677646,
        0.0018661356,
        -0.0068214433,
        0.0005088808,
        0.0264819,
        0.015445861,
        0.0017943612,
        -0.015618119,
        0.00299443,
        0.009376613,
        -0.00912971,
        0.008457901,
        0.019109229,
        0.025264606,
        -0.016203798,
        0.015755927,
        -0.012850497,
        -0.012310754,
        -0.007510478,
        -0.021945756,
        0.020016458,
        0.03284399,
        -0.003626045,
        0.029444749,
        -0.008090416,
        0.010398682,
        0.01083507,
        -0.003244205,
        0.0024489441,
        0.044580545,
        -0.02351905,
        -0.00087708374,
        0.024736345,
        0.027515452,
        -0.0030949141,
        -0.0384022,
        -0.008945967,
        -0.005713246,
        0.005868279,
        -0.017076576,
        -0.002325492,
        -0.012310754,
        0.018879551,
        -0.01297682,
        -0.0039045298,
        -0.012861981,
        0.014791278,
        0.028594939,
        -0.025172735,
        0.014217082,
        0.01508986,
        0.02616035,
        0.02891649,
        -0.02542538,
        -0.008900031,
        0.019545617,
        0.025700994,
        -0.010375714,
        0.018075677,
        -0.003996401,
        -0.03484219,
        -0.0044299187,
        0.012046623,
        0.028571973,
        0.008503837,
        -0.0065515717,
        0.00596015,
        -0.030041913,
        -0.0012503109,
        0.017329223,
        -0.03936685,
        0.018075677,
        0.0005867561,
        -0.0051620184,
        0.013838113,
        0.008704805,
        0.009439776,
        -0.014515664,
        0.017271804,
        0.008239707,
        -0.007832028,
        0.043432154,
        -0.026068479,
        0.010019713,
        -0.024070278,
        -0.007384155,
        -0.040974595,
        -0.017283287,
        -0.025976608,
        0.011874365,
        0.007946867,
        -0.01297682,
        -0.0064539583,
        0.012689723,
        -0.022324724,
        0.009479969,
        -0.008297126,
        0.0084234495,
        0.029031329,
        0.0011512621,
        0.00042705797,
        -0.0054261484,
        -0.03008785,
        -0.014837214,
        -0.019844199,
        0.018891035,
        -0.00017477079,
        0.018075677,
        -0.023679826,
        -0.010272359,
        0.0030662045,
        0.008722031,
        -0.017030641,
        0.0065573137,
        0.014584567,
        0.004398338,
        0.01588225,
        0.00936513,
        0.010209197,
        0.008722031,
        -0.024552602,
        -0.0070970575,
        -0.020154266,
        0.020694008,
        0.008928741,
        -0.009227323,
        0.0056357295,
        0.020556202,
        0.022439564,
        0.030340495,
        -0.007125767,
        -0.0062816995,
        0.013195015,
        -0.038448136,
        -0.028640876,
        -0.016065992,
        -0.017260319,
        0.026619706,
        -0.0013881178,
        0.015514765,
        0.030891722,
        0.026298158,
        0.04600455,
        -0.036909293,
        -0.012195914,
        0.045085836,
        -0.0019637488,
        -0.026941257,
        -0.0063391193,
        -0.01297682,
        0.011547073,
        -0.01999349,
        0.030685011,
        0.027928872,
        -0.013149079,
        0.0011562863,
        -0.033808637,
        -0.008429191,
        -0.017363675,
        0.007774608,
        -0.016467929,
        0.02008536,
        0.0022364918,
        0.00437537,
        0.032338694,
        0.006356345,
        0.004935211,
        -0.004280628,
        -0.002809252,
        -0.008256933,
        0.0027676227,
        -0.0060635055,
        -0.0042174663,
        -0.010002487,
        -0.029766299,
        0.02965146,
        0.007384155,
        0.00068831694,
        -0.0032298502,
        0.018098645
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 341.089026927948,
        "patch_type": "full",
        "api_costs": 0.25530200000000003,
        "num_applied": 1,
        "patch_name": "cyclic_eplb",
        "patch_description": "Implements a hybrid construction and refinement strategy for the balanced packing problem.\n1. Construction uses a ZigZag (Snake) filling strategy on sorted weights to create a high-quality initial baseline, combined with randomized restarts.\n2. Refinement uses a multi-stage approach:\n   - First, efficient 1-vs-1 swaps between the heaviest and lightest packs.\n   - Second, a novel 3-way cyclic exchange (Max -> Mid -> Min -> Max) that overcomes local optima where direct swaps are blocked by item granularity. This allows \"bridging\" weight transfers through intermediate packs.\n3. The replication step uses a CPU-based priority queue for optimal O(N log N) greedy assignment, which is faster than iterative GPU reductions for sparse updates.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 1,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\ncyclic_eplb\n</NAME>\n\n<DESCRIPTION>\nImplements a hybrid construction and refinement strategy for the balanced packing problem.\n1. Construction uses a ZigZag (Snake) filling strategy on sorted weights to create a high-quality initial baseline, combined with randomized restarts.\n2. Refinement uses a multi-stage approach:\n   - First, efficient 1-vs-1 swaps between the heaviest and lightest packs.\n   - Second, a novel 3-way cyclic exchange (Max -> Mid -> Min -> Max) that overcomes local optima where direct swaps are blocked by item granularity. This allows \"bridging\" weight transfers through intermediate packs.\n3. The replication step uses a CPU-based priority queue for optimal O(N log N) greedy assignment, which is faster than iterative GPU reductions for sparse updates.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport heapq\nimport random\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: move sequential packing logic to CPU\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 2\n    max_refine_iters = 30\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Initial preparation: list of (index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending for construction heuristics\n        items_desc = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_spread = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            # 1. Construction Strategy\n            if attempt == 0:\n                # Deterministic ZigZag (Snake) Packing\n                # Distributes large items 0, 1, .. M-1, M-1, .. 0\n                for k, (idx, w) in enumerate(items_desc):\n                    cycle = k // num_packs\n                    rem = k % num_packs\n                    if cycle % 2 == 0:\n                        p = rem\n                    else:\n                        p = num_packs - 1 - rem\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Perturb weights slightly to generate different greedy orderings\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * random.random())) for (idx, w) in items]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Fill the lightest valid pack (Best Fit)\n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            for _ in range(max_refine_iters):\n                # Identify Extremes\n                min_p = 0\n                max_p = 0\n                min_w = pack_weights[0]\n                max_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                \n                curr_spread = max_w - min_w\n                if curr_spread < 1e-6:\n                    break\n                \n                improvement_found = False\n                \n                # A. Try 1-Swap (Max <-> Min)\n                # Swap u from Max, v from Min. Target delta = (Max - Min) / 2\n                target = curr_spread / 2.0\n                best_swap = None\n                best_gap = float('inf')\n                \n                # We need w_u - w_v > 0 to reduce max_p\n                # We iterate to find best swap\n                for i_u, (idx_u, w_u) in enumerate(current_packs[max_p]):\n                    for i_v, (idx_v, w_v) in enumerate(current_packs[min_p]):\n                        delta = w_u - w_v\n                        # Valid swap must reduce Max and not increase Min beyond old Max\n                        if 0 < delta < curr_spread:\n                            gap = abs(delta - target)\n                            if gap < best_gap:\n                                best_gap = gap\n                                best_swap = (i_u, i_v, delta)\n                                if gap < 1e-5: break\n                    if best_swap and best_gap < 1e-5: break\n\n                if best_swap and best_gap < curr_spread * 0.4: # Heuristic acceptance threshold\n                    i_u, i_v, delta = best_swap\n                    u_item = current_packs[max_p][i_u]\n                    v_item = current_packs[min_p][i_v]\n                    \n                    current_packs[max_p][i_u] = v_item\n                    current_packs[min_p][i_v] = u_item\n                    pack_weights[max_p] -= delta\n                    pack_weights[min_p] += delta\n                    improvement_found = True\n                \n                # B. Try 3-Cycle Refinement (Max -> Mid -> Min -> Max)\n                # If 1-swap failed (local optimum), try to bridge via a 3rd pack\n                # Flow: u (Max->Mid), v (Mid->Min), w (Min->Max)\n                if not improvement_found and num_packs > 2:\n                    best_cycle = None\n                    best_cycle_score = curr_spread\n                    \n                    # Candidates for intermediate pack. \n                    candidate_mids = [p for p in range(num_packs) if p != max_p and p != min_p]\n                    \n                    for p_mid in candidate_mids:\n                        w_mid = pack_weights[p_mid]\n                        \n                        p_max_items = current_packs[max_p]\n                        p_min_items = current_packs[min_p]\n                        p_mid_items = current_packs[p_mid]\n                        \n                        # Iterate items. Small N per pack makes this feasible (O(N^3)).\n                        for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                            for i_v, (idx_v, w_v) in enumerate(p_mid_items):\n                                delta_mid = w_u - w_v\n                                new_mid_w = w_mid + delta_mid\n                                \n                                # Pruning: Mid must stay within bounds (approx)\n                                if new_mid_w > max_w - 1e-4 or new_mid_w < min_w + 1e-4:\n                                    continue\n                                    \n                                for i_w, (idx_w, w_w) in enumerate(p_min_items):\n                                    delta_max = w_w - w_u # decreases Max\n                                    delta_min = w_v - w_w # increases Min\n                                    \n                                    new_max_w = max_w + delta_max\n                                    new_min_w = min_w + delta_min\n                                    \n                                    # Check strict improvement on bounds\n                                    if new_max_w < max_w and new_min_w > min_w:\n                                        # Calculate new local spread among these 3\n                                        local_max = max(new_max_w, new_min_w, new_mid_w)\n                                        local_min = min(new_max_w, new_min_w, new_mid_w)\n                                        score = local_max - local_min\n                                        \n                                        if score < best_cycle_score - 1e-5:\n                                            best_cycle_score = score\n                                            best_cycle = (p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w)\n                        \n                        if best_cycle and best_cycle_score < curr_spread * 0.9: \n                            break \n                            \n                    if best_cycle:\n                        p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w = best_cycle\n                        \n                        # Apply Cycle Swap\n                        # Note: Update inplace carefully\n                        current_packs[max_p][i_u] = (idx_w, w_w)\n                        current_packs[p_mid][i_v] = (idx_u, w_u)\n                        current_packs[min_p][i_w] = (idx_v, w_v)\n                        \n                        pack_weights[max_p] += (w_w - w_u)\n                        pack_weights[p_mid] += (w_u - w_v)\n                        pack_weights[min_p] += (w_v - w_w)\n                        \n                        improvement_found = True\n\n                if not improvement_found:\n                    break\n\n            # Save best result across restarts\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            spread = curr_max - curr_min\n            \n            if spread < best_spread:\n                best_spread = spread\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_spread < 1e-6: break\n\n        # Fill Result Tensor\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    # Pre-allocate output\n    phy2log = torch.arange(num_phy, dtype=torch.int64, device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Move to CPU for priority queue operations (faster for sequential insertions)\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n\n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n        \n        # Priority Queue: Stores (-score, expert_index, current_replica_count)\n        # Score = weight / count. We want max score. Heap is min-heap.\n        pq = []\n        for i in range(num_log):\n            score = w_row[i]\n            heapq.heappush(pq, (-score, i, 1))\n            \n        # Assign replicas greedy\n        for r in range(num_log, num_phy):\n            # Pick expert with highest average load\n            neg_score, idx, count = heapq.heappop(pq)\n            \n            # Assign new replica\n            phy2log_cpu[layer_idx, r] = idx\n            rank_cpu[layer_idx, r] = count\n            \n            # Update\n            new_count = count + 1\n            logcnt_cpu[layer_idx, idx] = new_count\n            \n            new_score = w_row[idx] / new_count\n            heapq.heappush(pq, (-new_score, idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>",
          "msg": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: move to CPU and convert to list once\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.full(weight.shape,\n                            -1,\n                            dtype=torch.int64,\n                            device=\"cpu\")\n    rank_in_pack = torch.full(weight.shape,\n                              -1,\n                              dtype=torch.int64,\n                              device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n\n        # 1. Greedy packing\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Iterative Pairwise Swapping\n        # We iterate to constantly reduce the load of the heaviest packs.\n        # We restart the search after every swap to ensure we are always\n        # addressing the largest imbalances (Greedy Hill Climbing).\n        for _ in range(100):\n            found_improvement = False\n            # Sort packs by weight descending\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n\n            # Try to offload from heaviest packs to lighter packs\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n\n                # Compare p1 against all lighter packs, starting from the lightest\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6:\n                        # If difference is negligible, no swap can help (and subsequent packs are closer)\n                        break\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Find best swap (u in p1, v in p2) to close the gap\n                    # We want w_u - w_v approx target\n                    for idx_u, u in enumerate(current_packs[p1]):\n                        w_u = row_weight[u]\n                        for idx_v, v in enumerate(current_packs[p2]):\n                            w_v = row_weight[v]\n                            delta = w_u - w_v\n\n                            # Only consider swaps that strictly reduce the gap\n                            # (w_u > w_v) and don't overshoot excessively (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (idx_u, idx_v, delta)\n                                    if gap < 1e-6: break # Perfect swap\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta = best_swap\n                        u = current_packs[p1][idx_u]\n                        v = current_packs[p2][idx_v]\n\n                        current_packs[p1][idx_u] = v\n                        current_packs[p2][idx_v] = u\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n\n                if found_improvement:\n                    break # Restart outer loop (resort packs)\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move to CPU for sequential processing\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Algorithm Parameters\n    num_restarts = 2\n    lns_iterations = 50\n    swap_iterations = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base sort indices (LPT)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Randomized Greedy Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to get different greedy orderings\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.1 + 0.95\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            # Greedy LPT\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Assign to lightest pack with space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Large Neighborhood Search (LNS) Refinement\n            # Pick subset of packs, pool items, and greedy-repack them\n            for _ in range(lns_iterations):\n                # Find Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_w = pack_weights[0]\n                max_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    pw = pack_weights[p]\n                    if pw < min_w:\n                        min_w = pw\n                        min_p = p\n                    elif pw > max_w:\n                        max_w = pw\n                        max_p = p\n                \n                if max_w - min_w < 1e-6:\n                    break\n                \n                # Select packs to reshuffle: Max, Min, and a Random one\n                # Adding a random pack facilitates indirect transfers\n                target_packs = [max_p, min_p]\n                \n                # Pick a random 3rd pack different from max_p and min_p\n                if num_packs > 2:\n                    while True:\n                        r = random.randint(0, num_packs - 1)\n                        if r != max_p and r != min_p:\n                            target_packs.append(r)\n                            break\n                \n                # Collect items\n                pooled_items = [] # List of (index, weight)\n                for p in target_packs:\n                    for idx in current_packs[p]:\n                        pooled_items.append((idx, row_weight_list[idx]))\n                \n                # Sort items descending for LPT\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n                \n                # Try to repack\n                # We do a simple greedy fill on these 3 packs\n                temp_weights = [0.0] * len(target_packs)\n                temp_packs = [[] for _ in target_packs]\n                \n                for idx, w in pooled_items:\n                    # Find min loaded in temp subset\n                    b_sub = 0\n                    min_sub_w = float('inf')\n                    for k in range(len(target_packs)):\n                        if len(temp_packs[k]) < groups_per_pack:\n                            if temp_weights[k] < min_sub_w:\n                                min_sub_w = temp_weights[k]\n                                b_sub = k\n                    temp_packs[b_sub].append(idx)\n                    temp_weights[b_sub] += w\n                \n                # Evaluate Improvement\n                # We check if the spread of these specific packs decreased\n                old_spread = max_w - min_w # Approximate (local view)\n                \n                # Calculate new spread contribution\n                # We need to see if we reduced the max or increased the min of the GLOBAL set?\n                # Actually, just checking if range(temp_weights) < range(old_weights of these packs) is a good proxy\n                \n                current_subset_weights = [pack_weights[p] for p in target_packs]\n                new_subset_spread = max(temp_weights) - min(temp_weights)\n                old_subset_spread = max(current_subset_weights) - min(current_subset_weights)\n                \n                if new_subset_spread < old_subset_spread - 1e-6:\n                    # Apply change\n                    for k, p in enumerate(target_packs):\n                        current_packs[p] = temp_packs[k]\n                        pack_weights[p] = temp_weights[k]\n\n            # 3. Fine-grained Pairwise Swaps\n            for _ in range(swap_iterations):\n                # Sort packs to identify Heavy -> Light directions\n                sorted_packs = sorted(range(num_packs), \n                                      key=pack_weights.__getitem__, \n                                      reverse=True)\n                \n                found_swap = False\n                for i1 in range(num_packs):\n                    p1 = sorted_packs[i1]\n                    # Only look at significantly lighter packs\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_packs[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-5: break # Optimization: stop if packs are balanced\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Look for u in p1, v in p2 such that w_u > w_v\n                        # and w_u - w_v approx target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-6: break\n                            if best_swap and best_gap < 1e-6: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break\n                    if found_swap: break\n                if not found_swap: break\n\n            # 4. Update Best Global Solution\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill output\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    # Pre-allocate output tensors\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    # If no replication needed, return immediately\n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Processing on CPU using heapq is often faster for sparse/sequential updates\n    # than repeated GPU kernels (max/argmax) when num_redundant is large.\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n    \n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n        \n        # Priority queue stores (-score, expert_idx, current_count)\n        # We use negative score because heapq is a min-heap\n        pq = []\n        for i in range(num_log):\n            # Initial score is weight / 1\n            heapq.heappush(pq, (-w_row[i], i, 1))\n        \n        # Assign replicas one by one\n        for r_idx in range(num_log, num_phy):\n            score_neg, expert_idx, count = heapq.heappop(pq)\n            \n            # Assign the new replica\n            phy2log_cpu[layer_idx, r_idx] = expert_idx\n            rank_cpu[layer_idx, r_idx] = count\n            \n            # Update count and push back with new score\n            new_count = count + 1\n            logcnt_cpu[layer_idx, expert_idx] = new_count\n            new_score_neg = -w_row[expert_idx] / new_count\n            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nCreate a novel algorithm that draws inspiration from the provided context programs but implements a fundamentally different approach.\nStudy the patterns and techniques from the examples, then design something new.\nYou MUST respond using a short summary name, description and the full code:\n\n<NAME>\nA shortened name summarizing the code you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nExplain how you drew inspiration from the context programs and what novel approach you are implementing. Detail the key insights that led to this design.\n</DESCRIPTION>\n\n<CODE>\n```{language}\n# The inspired but novel algorithm implementation here.\n```\n</CODE>\n\n* Keep the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the code.\n* Learn from the context programs but don't copy their approaches directly.\n* Combine ideas in novel ways or apply insights to different algorithmic paradigms.\n* Maintain the same inputs and outputs as the original program.\n* Use the <NAME>, <DESCRIPTION>, and <CODE> delimiters to structure your response. It will be parsed afterwards.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: move to CPU and convert to list once\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.full(weight.shape,\n                            -1,\n                            dtype=torch.int64,\n                            device=\"cpu\")\n    rank_in_pack = torch.full(weight.shape,\n                              -1,\n                              dtype=torch.int64,\n                              device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n\n        # 1. Greedy packing\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Iterative Pairwise Swapping\n        # We iterate to constantly reduce the load of the heaviest packs.\n        # We restart the search after every swap to ensure we are always\n        # addressing the largest imbalances (Greedy Hill Climbing).\n        for _ in range(100):\n            found_improvement = False\n            # Sort packs by weight descending\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n\n            # Try to offload from heaviest packs to lighter packs\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n\n                # Compare p1 against all lighter packs, starting from the lightest\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6:\n                        # If difference is negligible, no swap can help (and subsequent packs are closer)\n                        break\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Find best swap (u in p1, v in p2) to close the gap\n                    # We want w_u - w_v approx target\n                    for idx_u, u in enumerate(current_packs[p1]):\n                        w_u = row_weight[u]\n                        for idx_v, v in enumerate(current_packs[p2]):\n                            w_v = row_weight[v]\n                            delta = w_u - w_v\n\n                            # Only consider swaps that strictly reduce the gap\n                            # (w_u > w_v) and don't overshoot excessively (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (idx_u, idx_v, delta)\n                                    if gap < 1e-6: break # Perfect swap\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta = best_swap\n                        u = current_packs[p1][idx_u]\n                        v = current_packs[p2][idx_v]\n\n                        current_packs[p1][idx_u] = v\n                        current_packs[p2][idx_v] = u\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n\n                if found_improvement:\n                    break # Restart outer loop (resort packs)\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move to CPU for sequential processing\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Algorithm Parameters\n    num_restarts = 2\n    lns_iterations = 50\n    swap_iterations = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base sort indices (LPT)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Randomized Greedy Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to get different greedy orderings\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.1 + 0.95\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            # Greedy LPT\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Assign to lightest pack with space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Large Neighborhood Search (LNS) Refinement\n            # Pick subset of packs, pool items, and greedy-repack them\n            for _ in range(lns_iterations):\n                # Find Max and Min packs\n                min_p = 0\n                max_p = 0\n                min_w = pack_weights[0]\n                max_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    pw = pack_weights[p]\n                    if pw < min_w:\n                        min_w = pw\n                        min_p = p\n                    elif pw > max_w:\n                        max_w = pw\n                        max_p = p\n                \n                if max_w - min_w < 1e-6:\n                    break\n                \n                # Select packs to reshuffle: Max, Min, and a Random one\n                # Adding a random pack facilitates indirect transfers\n                target_packs = [max_p, min_p]\n                \n                # Pick a random 3rd pack different from max_p and min_p\n                if num_packs > 2:\n                    while True:\n                        r = random.randint(0, num_packs - 1)\n                        if r != max_p and r != min_p:\n                            target_packs.append(r)\n                            break\n                \n                # Collect items\n                pooled_items = [] # List of (index, weight)\n                for p in target_packs:\n                    for idx in current_packs[p]:\n                        pooled_items.append((idx, row_weight_list[idx]))\n                \n                # Sort items descending for LPT\n                pooled_items.sort(key=lambda x: x[1], reverse=True)\n                \n                # Try to repack\n                # We do a simple greedy fill on these 3 packs\n                temp_weights = [0.0] * len(target_packs)\n                temp_packs = [[] for _ in target_packs]\n                \n                for idx, w in pooled_items:\n                    # Find min loaded in temp subset\n                    b_sub = 0\n                    min_sub_w = float('inf')\n                    for k in range(len(target_packs)):\n                        if len(temp_packs[k]) < groups_per_pack:\n                            if temp_weights[k] < min_sub_w:\n                                min_sub_w = temp_weights[k]\n                                b_sub = k\n                    temp_packs[b_sub].append(idx)\n                    temp_weights[b_sub] += w\n                \n                # Evaluate Improvement\n                # We check if the spread of these specific packs decreased\n                old_spread = max_w - min_w # Approximate (local view)\n                \n                # Calculate new spread contribution\n                # We need to see if we reduced the max or increased the min of the GLOBAL set?\n                # Actually, just checking if range(temp_weights) < range(old_weights of these packs) is a good proxy\n                \n                current_subset_weights = [pack_weights[p] for p in target_packs]\n                new_subset_spread = max(temp_weights) - min(temp_weights)\n                old_subset_spread = max(current_subset_weights) - min(current_subset_weights)\n                \n                if new_subset_spread < old_subset_spread - 1e-6:\n                    # Apply change\n                    for k, p in enumerate(target_packs):\n                        current_packs[p] = temp_packs[k]\n                        pack_weights[p] = temp_weights[k]\n\n            # 3. Fine-grained Pairwise Swaps\n            for _ in range(swap_iterations):\n                # Sort packs to identify Heavy -> Light directions\n                sorted_packs = sorted(range(num_packs), \n                                      key=pack_weights.__getitem__, \n                                      reverse=True)\n                \n                found_swap = False\n                for i1 in range(num_packs):\n                    p1 = sorted_packs[i1]\n                    # Only look at significantly lighter packs\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_packs[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-5: break # Optimization: stop if packs are balanced\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Look for u in p1, v in p2 such that w_u > w_v\n                        # and w_u - w_v approx target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-6: break\n                            if best_swap and best_gap < 1e-6: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break\n                    if found_swap: break\n                if not found_swap: break\n\n            # 4. Update Best Global Solution\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6: break\n\n        # Fill output\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    # Pre-allocate output tensors\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    # If no replication needed, return immediately\n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Processing on CPU using heapq is often faster for sparse/sequential updates\n    # than repeated GPU kernels (max/argmax) when num_redundant is large.\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n    \n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n        \n        # Priority queue stores (-score, expert_idx, current_count)\n        # We use negative score because heapq is a min-heap\n        pq = []\n        for i in range(num_log):\n            # Initial score is weight / 1\n            heapq.heappush(pq, (-w_row[i], i, 1))\n        \n        # Assign replicas one by one\n        for r_idx in range(num_log, num_phy):\n            score_neg, expert_idx, count = heapq.heappop(pq)\n            \n            # Assign the new replica\n            phy2log_cpu[layer_idx, r_idx] = expert_idx\n            rank_cpu[layer_idx, r_idx] = count\n            \n            # Update count and push back with new score\n            new_count = count + 1\n            logcnt_cpu[layer_idx, expert_idx] = new_count\n            new_score_neg = -w_row[expert_idx] / new_count\n            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\ncyclic_eplb\n</NAME>\n\n<DESCRIPTION>\nImplements a hybrid construction and refinement strategy for the balanced packing problem.\n1. Construction uses a ZigZag (Snake) filling strategy on sorted weights to create a high-quality initial baseline, combined with randomized restarts.\n2. Refinement uses a multi-stage approach:\n   - First, efficient 1-vs-1 swaps between the heaviest and lightest packs.\n   - Second, a novel 3-way cyclic exchange (Max -> Mid -> Min -> Max) that overcomes local optima where direct swaps are blocked by item granularity. This allows \"bridging\" weight transfers through intermediate packs.\n3. The replication step uses a CPU-based priority queue for optimal O(N log N) greedy assignment, which is faster than iterative GPU reductions for sparse updates.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport heapq\nimport random\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: move sequential packing logic to CPU\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 2\n    max_refine_iters = 30\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Initial preparation: list of (index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending for construction heuristics\n        items_desc = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_spread = float('inf')\n        best_packs = None\n\n        for attempt in range(num_restarts):\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            # 1. Construction Strategy\n            if attempt == 0:\n                # Deterministic ZigZag (Snake) Packing\n                # Distributes large items 0, 1, .. M-1, M-1, .. 0\n                for k, (idx, w) in enumerate(items_desc):\n                    cycle = k // num_packs\n                    rem = k % num_packs\n                    if cycle % 2 == 0:\n                        p = rem\n                    else:\n                        p = num_packs - 1 - rem\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Perturb weights slightly to generate different greedy orderings\n                noisy_items = [(idx, w, w * (0.9 + 0.2 * random.random())) for (idx, w) in items]\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Fill the lightest valid pack (Best Fit)\n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            for _ in range(max_refine_iters):\n                # Identify Extremes\n                min_p = 0\n                max_p = 0\n                min_w = pack_weights[0]\n                max_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                \n                curr_spread = max_w - min_w\n                if curr_spread < 1e-6:\n                    break\n                \n                improvement_found = False\n                \n                # A. Try 1-Swap (Max <-> Min)\n                # Swap u from Max, v from Min. Target delta = (Max - Min) / 2\n                target = curr_spread / 2.0\n                best_swap = None\n                best_gap = float('inf')\n                \n                # We need w_u - w_v > 0 to reduce max_p\n                # We iterate to find best swap\n                for i_u, (idx_u, w_u) in enumerate(current_packs[max_p]):\n                    for i_v, (idx_v, w_v) in enumerate(current_packs[min_p]):\n                        delta = w_u - w_v\n                        # Valid swap must reduce Max and not increase Min beyond old Max\n                        if 0 < delta < curr_spread:\n                            gap = abs(delta - target)\n                            if gap < best_gap:\n                                best_gap = gap\n                                best_swap = (i_u, i_v, delta)\n                                if gap < 1e-5: break\n                    if best_swap and best_gap < 1e-5: break\n\n                if best_swap and best_gap < curr_spread * 0.4: # Heuristic acceptance threshold\n                    i_u, i_v, delta = best_swap\n                    u_item = current_packs[max_p][i_u]\n                    v_item = current_packs[min_p][i_v]\n                    \n                    current_packs[max_p][i_u] = v_item\n                    current_packs[min_p][i_v] = u_item\n                    pack_weights[max_p] -= delta\n                    pack_weights[min_p] += delta\n                    improvement_found = True\n                \n                # B. Try 3-Cycle Refinement (Max -> Mid -> Min -> Max)\n                # If 1-swap failed (local optimum), try to bridge via a 3rd pack\n                # Flow: u (Max->Mid), v (Mid->Min), w (Min->Max)\n                if not improvement_found and num_packs > 2:\n                    best_cycle = None\n                    best_cycle_score = curr_spread\n                    \n                    # Candidates for intermediate pack. \n                    candidate_mids = [p for p in range(num_packs) if p != max_p and p != min_p]\n                    \n                    for p_mid in candidate_mids:\n                        w_mid = pack_weights[p_mid]\n                        \n                        p_max_items = current_packs[max_p]\n                        p_min_items = current_packs[min_p]\n                        p_mid_items = current_packs[p_mid]\n                        \n                        # Iterate items. Small N per pack makes this feasible (O(N^3)).\n                        for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                            for i_v, (idx_v, w_v) in enumerate(p_mid_items):\n                                delta_mid = w_u - w_v\n                                new_mid_w = w_mid + delta_mid\n                                \n                                # Pruning: Mid must stay within bounds (approx)\n                                if new_mid_w > max_w - 1e-4 or new_mid_w < min_w + 1e-4:\n                                    continue\n                                    \n                                for i_w, (idx_w, w_w) in enumerate(p_min_items):\n                                    delta_max = w_w - w_u # decreases Max\n                                    delta_min = w_v - w_w # increases Min\n                                    \n                                    new_max_w = max_w + delta_max\n                                    new_min_w = min_w + delta_min\n                                    \n                                    # Check strict improvement on bounds\n                                    if new_max_w < max_w and new_min_w > min_w:\n                                        # Calculate new local spread among these 3\n                                        local_max = max(new_max_w, new_min_w, new_mid_w)\n                                        local_min = min(new_max_w, new_min_w, new_mid_w)\n                                        score = local_max - local_min\n                                        \n                                        if score < best_cycle_score - 1e-5:\n                                            best_cycle_score = score\n                                            best_cycle = (p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w)\n                        \n                        if best_cycle and best_cycle_score < curr_spread * 0.9: \n                            break \n                            \n                    if best_cycle:\n                        p_mid, i_u, i_v, i_w, idx_u, w_u, idx_v, w_v, idx_w, w_w = best_cycle\n                        \n                        # Apply Cycle Swap\n                        # Note: Update inplace carefully\n                        current_packs[max_p][i_u] = (idx_w, w_w)\n                        current_packs[p_mid][i_v] = (idx_u, w_u)\n                        current_packs[min_p][i_w] = (idx_v, w_v)\n                        \n                        pack_weights[max_p] += (w_w - w_u)\n                        pack_weights[p_mid] += (w_u - w_v)\n                        pack_weights[min_p] += (w_v - w_w)\n                        \n                        improvement_found = True\n\n                if not improvement_found:\n                    break\n\n            # Save best result across restarts\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            spread = curr_max - curr_min\n            \n            if spread < best_spread:\n                best_spread = spread\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_spread < 1e-6: break\n\n        # Fill Result Tensor\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    # Pre-allocate output\n    phy2log = torch.arange(num_phy, dtype=torch.int64, device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    if num_redundant == 0:\n        return phy2log, rank, logcnt\n\n    # Move to CPU for priority queue operations (faster for sequential insertions)\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    phy2log_cpu = phy2log.to(\"cpu\")\n    rank_cpu = rank.to(\"cpu\")\n    logcnt_cpu = logcnt.to(\"cpu\")\n\n    for layer_idx in range(n):\n        w_row = weight_cpu[layer_idx].tolist()\n        \n        # Priority Queue: Stores (-score, expert_index, current_replica_count)\n        # Score = weight / count. We want max score. Heap is min-heap.\n        pq = []\n        for i in range(num_log):\n            score = w_row[i]\n            heapq.heappush(pq, (-score, i, 1))\n            \n        # Assign replicas greedy\n        for r in range(num_log, num_phy):\n            # Pick expert with highest average load\n            neg_score, idx, count = heapq.heappop(pq)\n            \n            # Assign new replica\n            phy2log_cpu[layer_idx, r] = idx\n            rank_cpu[layer_idx, r] = count\n            \n            # Update\n            new_count = count + 1\n            logcnt_cpu[layer_idx, idx] = new_count\n            \n            new_score = w_row[idx] / new_count\n            heapq.heappush(pq, (-new_score, idx, new_count))\n\n    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 30163,
          "output_tokens": 16248,
          "cost": 0.25530200000000003,
          "input_cost": 0.060326,
          "output_cost": 0.194976,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 1,
          "deleted": 0,
          "modified": 186
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 8.278e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_91/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_91/results\nRun 1/5 completed in 0.62 seconds\nRun 2/5 completed in 0.31 seconds\nRun 3/5 completed in 0.31 seconds\nRun 4/5 completed in 0.31 seconds\nRun 5/5 completed in 0.31 seconds\nbalancedness: 0.21073683733844054\nbalancedness: 0.3397761404567239\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_91/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_91/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385873149429\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.3110771746298858, 'speed_score': 1.0}\n  execution_time_mean: 0.37072757339919915\n  execution_time_std: 0.12249494202643044\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 66,
          "average_cyclomatic_complexity": 13.2,
          "halstead_volume": 2642.2156784891513,
          "halstead_difficulty": 13.152985074626866,
          "halstead_effort": 34753.0233831129,
          "lines_of_code": 453,
          "logical_lines_of_code": 227,
          "comments": 53,
          "maintainability_index": -46.2297183938136,
          "max_nesting_depth": 11,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "abca98b8-b91b-4e4b-92e0-dfa046c1c426",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Algorithm: Randomized Greedy Initialization + Local Beam Search Refinement\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case: 1 group per pack (1-to-1 mapping)\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(num_layers, num_groups)\n        rank_in_pack = torch.zeros((num_layers, num_groups), dtype=torch.int64, device=device)\n        return pack_index, rank_in_pack\n\n    # Work on CPU for efficiency with scalar logic\n    weight_cpu = weight.cpu()\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Helper: Beam Search Solver for a subset of items/packs\n    def solve_subset_beam(items, w_map, capacity, k_packs, width=32):\n        \"\"\"\n        Optimally pack 'items' into 'k_packs' each with 'capacity' using Beam Search.\n        \"\"\"\n        # Sort items Descending (LPT)\n        items_sorted = sorted(items, key=lambda x: w_map[x], reverse=True)\n        \n        # Beam State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n        # We start with empty packs.\n        start_node = (0.0, 0.0, tuple([0.0]*k_packs), tuple([0]*k_packs), ())\n        beam = [start_node]\n        \n        for item_idx in items_sorted:\n            w = w_map[item_idx]\n            next_beam = []\n            \n            for b_max, b_ss, loads, counts, assign in beam:\n                # Symmetry breaking: Bins with same (load, count) are equivalent.\n                # Only try to put item in one of the equivalent bins.\n                seen_signatures = set()\n                \n                for p in range(k_packs):\n                    if counts[p] < capacity:\n                        # Signature for symmetry breaking\n                        sig = (round(loads[p], 5), counts[p])\n                        if sig in seen_signatures:\n                            continue\n                        seen_signatures.add(sig)\n                        \n                        # Create new state\n                        nl = list(loads)\n                        nl[p] += w\n                        nc = list(counts)\n                        nc[p] += 1\n                        \n                        # Update metrics\n                        # Delta Sum Squares = (L+w)^2 - L^2 = 2Lw + w^2\n                        delta_ss = 2 * loads[p] * w + w * w\n                        new_ss = b_ss + delta_ss\n                        new_max = b_max if b_max > nl[p] else nl[p]\n                        \n                        next_beam.append((new_max, new_ss, tuple(nl), tuple(nc), assign + (p,)))\n            \n            # Prune beam\n            if len(next_beam) > width:\n                # Primary key: Max Load, Secondary: Sum Squares\n                beam = heapq.nsmallest(width, next_beam, key=lambda x: (x[0], x[1]))\n            else:\n                beam = next_beam\n        \n        # Best solution found\n        best = beam[0]\n        assign_indices = best[4]\n        final_weights = best[2]\n        \n        # Reconstruct packs\n        res_packs = [[] for _ in range(k_packs)]\n        for i, p in enumerate(assign_indices):\n            res_packs[p].append(items_sorted[i])\n            \n        return res_packs, list(final_weights)\n\n    # Main Loop over Layers\n    for i in range(num_layers):\n        layer_w_tensor = weight_cpu[i]\n        layer_w_list = layer_w_tensor.tolist()\n        \n        # --- 1. Initialization: Randomized Greedy ---\n        best_assignment = None\n        best_pack_weights = None\n        best_global_max = float('inf')\n        best_global_ss = float('inf')\n        \n        # Number of restarts\n        NUM_RESTARTS = 10\n        base_indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n        \n        for attempt in range(NUM_RESTARTS):\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to change sort order (Perturbed LPT)\n                # Noise range [0.9, 1.1]\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x] * noise[x], reverse=True)\n            \n            curr_packs = [[] for _ in range(num_packs)]\n            curr_weights = [0.0] * num_packs\n            curr_counts = [0] * num_packs\n            \n            # Greedy Fill (Best Fit)\n            for idx in indices:\n                w = layer_w_list[idx]\n                best_p = -1\n                min_load = float('inf')\n                \n                for p in range(num_packs):\n                    if curr_counts[p] < groups_per_pack:\n                        if curr_weights[p] < min_load:\n                            min_load = curr_weights[p]\n                            best_p = p\n                \n                curr_packs[best_p].append(idx)\n                curr_weights[best_p] += w\n                curr_counts[best_p] += 1\n            \n            # Check Metrics\n            c_max = max(curr_weights)\n            c_ss = sum(x*x for x in curr_weights)\n            \n            if c_max < best_global_max - 1e-6:\n                best_global_max = c_max\n                best_global_ss = c_ss\n                best_assignment = curr_packs\n                best_pack_weights = curr_weights\n            elif abs(c_max - best_global_max) < 1e-6 and c_ss < best_global_ss - 1e-6:\n                best_global_ss = c_ss\n                best_assignment = curr_packs\n                best_pack_weights = curr_weights\n        \n        packs = best_assignment\n        pack_weights = best_pack_weights\n        \n        # --- 2. Refinement: LNS with Beam Search ---\n        # Focus on Max and Min packs to reduce spread\n        MAX_LNS_STEPS = 50\n        consecutive_fail = 0\n        limit_fail = 8\n        \n        for step in range(MAX_LNS_STEPS):\n            # Identify extremes\n            max_p = -1; max_val = -1.0\n            min_p = -1; min_val = float('inf')\n            \n            for p in range(num_packs):\n                val = pack_weights[p]\n                if val > max_val: max_val = val; max_p = p\n                if val < min_val: min_val = val; min_p = p\n            \n            if max_val - min_val < 1e-6:\n                break\n                \n            # Select subset of packs to optimize\n            candidates = [max_p, min_p]\n            if num_packs > 2:\n                # Add a random third pack to allow 3-way exchanges\n                # Avoid max_p and min_p\n                r = random.randint(0, num_packs - 1)\n                while r == max_p or r == min_p:\n                    r = random.randint(0, num_packs - 1)\n                candidates.append(r)\n            \n            # Collect items from candidates\n            sub_items = []\n            for p in candidates:\n                sub_items.extend(packs[p])\n            \n            # Solve subset optimally(ish) with Beam Search\n            # Beam width 32 is sufficient for small subset (2 or 3 packs)\n            new_sub_packs, new_sub_weights = solve_subset_beam(\n                sub_items, layer_w_list, groups_per_pack, len(candidates), width=32\n            )\n            \n            # Check for improvement\n            old_sub_max = max(pack_weights[p] for p in candidates)\n            old_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n            \n            new_sub_max = max(new_sub_weights)\n            new_sub_ss = sum(x*x for x in new_sub_weights)\n            \n            improved = False\n            # Accept if Max load reduces OR Max load stays same but Variance (Sum Sq) reduces\n            if new_sub_max < old_sub_max - 1e-6:\n                improved = True\n            elif abs(new_sub_max - old_sub_max) < 1e-6 and new_sub_ss < old_sub_ss - 1e-6:\n                improved = True\n            \n            if improved:\n                for local_idx, p in enumerate(candidates):\n                    packs[p] = new_sub_packs[local_idx]\n                    pack_weights[p] = new_sub_weights[local_idx]\n                consecutive_fail = 0\n            else:\n                consecutive_fail += 1\n                if consecutive_fail >= limit_fail:\n                    break\n\n        # --- 3. Output ---\n        for p in range(num_packs):\n            for r, g_idx in enumerate(packs[p]):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "cc8f2e85-1171-49ad-ac5e-f66b7212d45a",
      "archive_inspiration_ids": [
        "f3d4c6f1-1fb7-4675-a072-fc3c129f5443",
        "ef7501ac-df60-411c-be63-a49df8d97be2",
        "dd30d137-c763-4348-a74f-d1a81a7bd607",
        "23d340ca-72ac-4815-b84c-116d9e13b8b2"
      ],
      "top_k_inspiration_ids": [
        "781c17c9-b7aa-42f9-9de8-a69d941eff7a",
        "468d35e1-4d5b-4d9e-bd19-f9b65af22cd6"
      ],
      "island_idx": 0,
      "generation": 93,
      "timestamp": 1764180932.6248372,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,378 +1,428 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n-\n+import random\n+import heapq\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n+\n+    Algorithm: Randomized Greedy Initialization + Local Beam Search Refinement\n \n     Parameters:\n         weight: [X, n], the weight of each item\n         num_packs: number of packs\n \n     Returns:\n         pack_index: [X, n], the pack index of each item\n         rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n-\n     device = weight.device\n+\n+    # Trivial case: 1 group per pack (1-to-1 mapping)\n     if groups_per_pack == 1:\n-        pack_index = torch.arange(weight.size(-1),\n-                                  dtype=torch.int64,\n-                                  device=device).expand(weight.shape)\n-        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n+        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(num_layers, num_groups)\n+        rank_in_pack = torch.zeros((num_layers, num_groups), dtype=torch.int64, device=device)\n         return pack_index, rank_in_pack\n \n-    # Use CPU weights for fast scalar access\n+    # Work on CPU for efficiency with scalar logic\n     weight_cpu = weight.cpu()\n-\n-    # Outputs on CPU\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n \n-    import random\n-    import heapq\n-\n-    def solve_beam(items_to_pack, w_map, pack_limit, num_bins, beam_width):\n+    # Helper: Beam Search Solver for a subset of items/packs\n+    def solve_subset_beam(items, w_map, capacity, k_packs, width=32):\n         \"\"\"\n-        Solve balanced packing for a subset of items using Beam Search.\n-        items_to_pack: list of item indices\n-        w_map: list of all weights (w_map[idx] is weight)\n-        pack_limit: max items per bin\n-        num_bins: number of bins\n+        Optimally pack 'items' into 'k_packs' each with 'capacity' using Beam Search.\n         \"\"\"\n-        # Sort LPT\n-        items_sorted = sorted(items_to_pack, key=lambda x: w_map[x], reverse=True)\n-\n-        # State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n-        # assignment_tuple: sequence of bin indices for items in items_sorted\n-        initial_state = (0.0, 0.0, tuple([0.0]*num_bins), tuple([0]*num_bins), ())\n-        beam = [initial_state]\n-\n+        # Sort items Descending (LPT)\n+        items_sorted = sorted(items, key=lambda x: w_map[x], reverse=True)\n+        \n+        # Beam State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n+        # We start with empty packs.\n+        start_node = (0.0, 0.0, tuple([0.0]*k_packs), tuple([0]*k_packs), ())\n+        beam = [start_node]\n+        \n         for item_idx in items_sorted:\n             w = w_map[item_idx]\n             next_beam = []\n-\n+            \n             for b_max, b_ss, loads, counts, assign in beam:\n-                # Symmetry breaking:\n-                # Identify bins by (load, count). Only try one bin for each unique (load, count) pair.\n+                # Symmetry breaking: Bins with same (load, count) are equivalent.\n+                # Only try to put item in one of the equivalent bins.\n                 seen_signatures = set()\n-\n-                for p in range(num_bins):\n-                    if counts[p] < pack_limit:\n-                        # Round to avoid float precision issues in signature\n+                \n+                for p in range(k_packs):\n+                    if counts[p] < capacity:\n+                        # Signature for symmetry breaking\n                         sig = (round(loads[p], 5), counts[p])\n                         if sig in seen_signatures:\n                             continue\n                         seen_signatures.add(sig)\n-\n+                        \n                         # Create new state\n-                        new_loads = list(loads)\n-                        new_loads[p] += w\n-                        new_counts = list(counts)\n-                        new_counts[p] += 1\n-\n-                        new_max = max(b_max, new_loads[p])\n-                        # Incremental SS: old_ss - old_L^2 + new_L^2\n-                        # new_L = old_L + w\n-                        # delta = 2*old_L*w + w^2\n+                        nl = list(loads)\n+                        nl[p] += w\n+                        nc = list(counts)\n+                        nc[p] += 1\n+                        \n+                        # Update metrics\n+                        # Delta Sum Squares = (L+w)^2 - L^2 = 2Lw + w^2\n                         delta_ss = 2 * loads[p] * w + w * w\n                         new_ss = b_ss + delta_ss\n-\n-                        next_beam.append((new_max, new_ss, tuple(new_loads), tuple(new_counts), assign + (p,)))\n-\n-            # Select top K\n-            # Primary sort: max_load, Secondary: sum_sq\n-            if len(next_beam) > beam_width:\n-                # partial sort using heapq.nsmallest is efficient\n-                beam = heapq.nsmallest(beam_width, next_beam, key=lambda x: (x[0], x[1]))\n+                        new_max = b_max if b_max > nl[p] else nl[p]\n+                        \n+                        next_beam.append((new_max, new_ss, tuple(nl), tuple(nc), assign + (p,)))\n+            \n+            # Prune beam\n+            if len(next_beam) > width:\n+                # Primary key: Max Load, Secondary: Sum Squares\n+                beam = heapq.nsmallest(width, next_beam, key=lambda x: (x[0], x[1]))\n             else:\n                 beam = next_beam\n-\n-        # Best state\n-        best_state = beam[0]\n-        # reconstruct\n-        final_assign = best_state[4]\n-        final_loads = best_state[2]\n-\n-        res_packs = [[] for _ in range(num_bins)]\n-        for i, p in enumerate(final_assign):\n+        \n+        # Best solution found\n+        best = beam[0]\n+        assign_indices = best[4]\n+        final_weights = best[2]\n+        \n+        # Reconstruct packs\n+        res_packs = [[] for _ in range(k_packs)]\n+        for i, p in enumerate(assign_indices):\n             res_packs[p].append(items_sorted[i])\n-\n-        return res_packs, list(final_loads)\n-\n+            \n+        return res_packs, list(final_weights)\n+\n+    # Main Loop over Layers\n     for i in range(num_layers):\n-        layer_w = weight_cpu[i]\n-        layer_w_list = layer_w.tolist()\n-\n-        # 1. Global Initialization with Beam Search\n-        # If num_packs is very large, reduce width to keep it fast.\n-        # But typically num_packs is small (<=8) in hierarchical steps.\n-        # Even for 64, width=2 is better than greedy.\n-        global_width = 4\n-        all_items = list(range(num_groups))\n-\n-        packs, pack_weights = solve_beam(all_items, layer_w_list, groups_per_pack, num_packs, global_width)\n-\n-        # 2. Refinement: Ruin & Recreate (LNS)\n-        # Use Beam Search on small subsets (2-3 packs)\n-        LNS_STEPS = 20 if num_packs > 1 else 0\n-\n-        for step in range(LNS_STEPS):\n-            # Identify max and min packs\n-            max_p = -1\n-            min_p = -1\n-            max_w = -1.0\n-            min_w = float('inf')\n-\n-            for p_idx, pw in enumerate(pack_weights):\n-                if pw > max_w:\n-                    max_w = pw\n-                    max_p = p_idx\n-                if pw < min_w:\n-                    min_w = pw\n-                    min_p = p_idx\n-\n-            if max_p == min_p or (max_w - min_w < 1e-6):\n+        layer_w_tensor = weight_cpu[i]\n+        layer_w_list = layer_w_tensor.tolist()\n+        \n+        # --- 1. Initialization: Randomized Greedy ---\n+        best_assignment = None\n+        best_pack_weights = None\n+        best_global_max = float('inf')\n+        best_global_ss = float('inf')\n+        \n+        # Number of restarts\n+        NUM_RESTARTS = 10\n+        base_indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n+        \n+        for attempt in range(NUM_RESTARTS):\n+            if attempt == 0:\n+                indices = base_indices\n+            else:\n+                # Add noise to weights to change sort order (Perturbed LPT)\n+                # Noise range [0.9, 1.1]\n+                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n+                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x] * noise[x], reverse=True)\n+            \n+            curr_packs = [[] for _ in range(num_packs)]\n+            curr_weights = [0.0] * num_packs\n+            curr_counts = [0] * num_packs\n+            \n+            # Greedy Fill (Best Fit)\n+            for idx in indices:\n+                w = layer_w_list[idx]\n+                best_p = -1\n+                min_load = float('inf')\n+                \n+                for p in range(num_packs):\n+                    if curr_counts[p] < groups_per_pack:\n+                        if curr_weights[p] < min_load:\n+                            min_load = curr_weights[p]\n+                            best_p = p\n+                \n+                curr_packs[best_p].append(idx)\n+                curr_weights[best_p] += w\n+                curr_counts[best_p] += 1\n+            \n+            # Check Metrics\n+            c_max = max(curr_weights)\n+            c_ss = sum(x*x for x in curr_weights)\n+            \n+            if c_max < best_global_max - 1e-6:\n+                best_global_max = c_max\n+                best_global_ss = c_ss\n+                best_assignment = curr_packs\n+                best_pack_weights = curr_weights\n+            elif abs(c_max - best_global_max) < 1e-6 and c_ss < best_global_ss - 1e-6:\n+                best_global_ss = c_ss\n+                best_assignment = curr_packs\n+                best_pack_weights = curr_weights\n+        \n+        packs = best_assignment\n+        pack_weights = best_pack_weights\n+        \n+        # --- 2. Refinement: LNS with Beam Search ---\n+        # Focus on Max and Min packs to reduce spread\n+        MAX_LNS_STEPS = 50\n+        consecutive_fail = 0\n+        limit_fail = 8\n+        \n+        for step in range(MAX_LNS_STEPS):\n+            # Identify extremes\n+            max_p = -1; max_val = -1.0\n+            min_p = -1; min_val = float('inf')\n+            \n+            for p in range(num_packs):\n+                val = pack_weights[p]\n+                if val > max_val: max_val = val; max_p = p\n+                if val < min_val: min_val = val; min_p = p\n+            \n+            if max_val - min_val < 1e-6:\n                 break\n-\n-            # Candidates: Max, Min, and maybe random\n+                \n+            # Select subset of packs to optimize\n             candidates = [max_p, min_p]\n             if num_packs > 2:\n-                # Add 1 random pack\n-                rand_p = random.randint(0, num_packs - 1)\n-                while rand_p in candidates:\n-                    rand_p = random.randint(0, num_packs - 1)\n-                candidates.append(rand_p)\n-\n-            # Pool items\n+                # Add a random third pack to allow 3-way exchanges\n+                # Avoid max_p and min_p\n+                r = random.randint(0, num_packs - 1)\n+                while r == max_p or r == min_p:\n+                    r = random.randint(0, num_packs - 1)\n+                candidates.append(r)\n+            \n+            # Collect items from candidates\n             sub_items = []\n             for p in candidates:\n                 sub_items.extend(packs[p])\n-\n-            # Solve sub-problem with Higher Width Beam Search\n-            # K=2 or 3 is small, so we can afford width=8 or more\n-            sub_packs, sub_weights = solve_beam(sub_items, layer_w_list, groups_per_pack, len(candidates), beam_width=12)\n-\n-            # Check improvement\n-            current_sub_max = max(pack_weights[p] for p in candidates)\n-            current_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n-\n-            new_sub_max = max(sub_weights)\n-            new_sub_ss = sum(w**2 for w in sub_weights)\n-\n-            if new_sub_max < current_sub_max - 1e-6 or \\\n-               (abs(new_sub_max - current_sub_max) < 1e-6 and new_sub_ss < current_sub_ss - 1e-6):\n-                # Apply update\n+            \n+            # Solve subset optimally(ish) with Beam Search\n+            # Beam width 32 is sufficient for small subset (2 or 3 packs)\n+            new_sub_packs, new_sub_weights = solve_subset_beam(\n+                sub_items, layer_w_list, groups_per_pack, len(candidates), width=32\n+            )\n+            \n+            # Check for improvement\n+            old_sub_max = max(pack_weights[p] for p in candidates)\n+            old_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n+            \n+            new_sub_max = max(new_sub_weights)\n+            new_sub_ss = sum(x*x for x in new_sub_weights)\n+            \n+            improved = False\n+            # Accept if Max load reduces OR Max load stays same but Variance (Sum Sq) reduces\n+            if new_sub_max < old_sub_max - 1e-6:\n+                improved = True\n+            elif abs(new_sub_max - old_sub_max) < 1e-6 and new_sub_ss < old_sub_ss - 1e-6:\n+                improved = True\n+            \n+            if improved:\n                 for local_idx, p in enumerate(candidates):\n-                    packs[p] = sub_packs[local_idx]\n-                    pack_weights[p] = sub_weights[local_idx]\n-\n-        # 5. Final assignment for this layer\n-        for p, nodes in enumerate(packs):\n-            for r, g_idx in enumerate(nodes):\n+                    packs[p] = new_sub_packs[local_idx]\n+                    pack_weights[p] = new_sub_weights[local_idx]\n+                consecutive_fail = 0\n+            else:\n+                consecutive_fail += 1\n+                if consecutive_fail >= limit_fail:\n+                    break\n+\n+        # --- 3. Output ---\n+        for p in range(num_packs):\n+            for r, g_idx in enumerate(packs[p]):\n                 pack_index[i, g_idx] = p\n                 rank_in_pack[i, g_idx] = r\n \n     return pack_index.to(device), rank_in_pack.to(device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n \n     Parameters:\n         weight: [X, num_log]\n         num_phy: total number of experts after replication\n \n     Returns:\n         phy2log: [X, num_phy], logical expert id of each physical expert\n         rank: [X, num_phy], the replica rank\n         logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n     for i in range(num_log, num_phy):\n         redundant_indices = (weight / logcnt).max(dim=-1).indices\n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n         logcnt[arangen, redundant_indices] += 1\n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Parameters:\n         weight: [num_moe_layers, num_logical_experts]\n         num_physical_experts: number of physical experts after replication\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n         (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [num_moe_layers, num_physical_experts]\n         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n         logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n \n     Parameters:\n         weight: [layers, num_logical_experts], the load statistics for all\n             logical experts\n         num_replicas: number of physical experts, must be a multiple of\n             `num_gpus`\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n             (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [layers, num_replicas], the expert index of\n             each replica\n         logical_to_physical_map: [layers, num_logical_experts, X], the replica\n             indices for each expert\n         expert_count: [layers, num_logical_experts], number of physical\n             replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n \n \n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385886499905,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.3110771772999811,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.05486497,
        0.022542953,
        0.0139717525,
        -0.039116263,
        -0.024854157,
        0.012357394,
        -0.010330735,
        -0.006654875,
        -0.022728778,
        0.029476566,
        0.032194264,
        0.0223339,
        -0.010731421,
        -0.022937832,
        0.017316611,
        0.0180483,
        -0.011195985,
        0.012136726,
        -0.0057983357,
        0.053517736,
        0.008687341,
        -0.008948658,
        0.026271077,
        -0.042275295,
        -0.0025855873,
        0.011172757,
        0.060579102,
        -0.043576073,
        0.031056082,
        -0.048918556,
        0.07851126,
        -0.012647746,
        0.014982179,
        0.0016404905,
        -0.016898504,
        0.03200844,
        -0.008257619,
        0.013135538,
        0.014471158,
        0.059510607,
        0.025667144,
        -0.029081687,
        -0.04515559,
        0.039162718,
        -0.034563538,
        0.02750217,
        0.00407945,
        -0.00969196,
        0.077303395,
        0.0032403318,
        0.04044027,
        0.019000655,
        -0.0024331522,
        0.066711344,
        0.028477754,
        0.042995367,
        0.019941395,
        0.018756758,
        0.018640617,
        -0.045527242,
        0.0514272,
        -0.017107558,
        0.07242548,
        0.04436583,
        -0.031892296,
        0.0032519458,
        -0.03672376,
        0.027525399,
        0.023146885,
        -0.0085712,
        -0.0383265,
        0.044040635,
        -0.022380356,
        -0.027014378,
        -0.0015896788,
        0.0092390105,
        -0.020115606,
        0.04771069,
        -0.030196639,
        -0.042786315,
        -0.028454525,
        -0.009430643,
        0.052588608,
        0.017235313,
        0.011950901,
        -0.07409791,
        -0.02250811,
        -0.040115073,
        -0.03533007,
        -0.026201392,
        0.030545061,
        -0.04592212,
        -0.0028294832,
        0.03312339,
        0.04018476,
        -0.031660017,
        0.06327357,
        0.013890454,
        0.034354486,
        0.05695551,
        -0.010081032,
        0.018176055,
        -0.055933468,
        0.00015624583,
        0.027200203,
        0.009157712,
        0.0033361479,
        -0.002642206,
        0.013007783,
        -0.01600422,
        -0.0384891,
        0.019314235,
        0.030150183,
        0.010963703,
        0.014087894,
        0.006457435,
        -0.04260049,
        -0.018907743,
        0.010185558,
        -0.022113232,
        -0.029987585,
        -0.037885167,
        0.023367554,
        -0.02685178,
        0.008269234,
        -0.03723478,
        0.012380622,
        -0.035748176,
        0.008617656,
        0.0020615014,
        0.044598114,
        0.023681134,
        0.01091144,
        -0.025922654,
        -0.022914603,
        0.005574764,
        -0.022740392,
        0.0047588744,
        -0.008757025,
        -0.016224887,
        -0.022299057,
        0.029104915,
        -0.014366631,
        -0.009546784,
        -0.049057923,
        0.054307494,
        -0.00211812,
        0.014993792,
        -0.039395,
        0.028802948,
        0.0171424,
        -0.03769934,
        -0.01387884,
        -0.011561829,
        0.0017566314,
        -0.014087894,
        0.009703574,
        0.019848483,
        0.08106636,
        -0.03200844,
        -0.02852421,
        0.027966734,
        -0.025039982,
        0.024900613,
        0.03186907,
        0.030196639,
        -0.048035886,
        0.0042333365,
        -0.057373613,
        -0.062576726,
        -0.001923584,
        -0.021729967,
        -0.006289031,
        -0.013472347,
        0.002762702,
        0.015005407,
        -0.026247848,
        -0.03567849,
        -0.030428922,
        -0.041090656,
        -0.02176481,
        -0.01433179,
        -0.014540844,
        -0.0068871565,
        -0.05077681,
        0.028175788,
        -0.026921466,
        -0.014111122,
        -0.01091144,
        -0.006945227,
        0.012798729,
        0.044714253,
        -0.037467062,
        0.03272851,
        -0.0038645891,
        -0.020313047,
        0.05230987,
        0.016852047,
        0.0043262495,
        -0.0063819434,
        -0.03981311,
        -0.015284145,
        0.038582012,
        -0.040858377,
        0.046247315,
        0.03365764,
        -0.0111204935,
        0.015934534,
        0.011561829,
        -0.0065155057,
        0.03542298,
        -0.023948258,
        0.034842275,
        -0.0058389846,
        -0.02659627,
        -0.0300805,
        -0.048314624,
        0.016991416,
        0.0026262365,
        0.070009746,
        -0.019639429,
        0.021067962,
        -0.02469156,
        0.007433019,
        -0.041113887,
        0.022659093,
        0.04938312,
        -0.020615013,
        0.008600235,
        0.006265803,
        -0.0291746,
        -0.0003839909,
        -0.011457302,
        -0.027478943,
        0.031125767,
        -0.03258914,
        -0.03326276,
        0.019941395,
        -0.01566741,
        -0.038094223,
        0.015876465,
        0.041346166,
        0.00888478,
        -0.046502825,
        0.0045294957,
        0.016131975,
        -0.042275295,
        -0.013588488,
        0.00581866,
        -0.023994714,
        0.020301433,
        -0.047106758,
        0.02517935,
        -0.05807046,
        -0.014204035,
        0.034098975,
        -0.017699877,
        -0.05230987,
        -0.017212084,
        -0.031032855,
        0.01765342,
        -0.014575685,
        -0.004067836,
        -0.023321098,
        -0.02182288,
        -0.0008246005,
        -0.004657251,
        0.034098975,
        -0.04845399,
        -0.02001108,
        0.029012002,
        0.014296947,
        -0.015934534,
        0.037025724,
        -0.04322765,
        -0.01790893,
        0.005624124,
        -0.018977426,
        -0.033076935,
        -0.046526052,
        -0.027014378,
        0.00014671865,
        0.042321753,
        -0.002154414,
        0.01311231,
        -0.0058622127,
        -0.0052002096,
        0.030196639,
        0.011846374,
        -0.023112044,
        0.0041549415,
        -0.024017943,
        0.040835146,
        0.011759268,
        -0.008698955,
        -0.020464031,
        -0.05997517,
        -0.017502436,
        -0.0055892817,
        -0.009209975,
        0.009744223,
        -0.0022545855,
        -0.010110067,
        0.00607417,
        -0.008809289,
        -0.02429668,
        -0.01574871,
        0.020638242,
        -0.016770748,
        -0.022786848,
        -0.011857988,
        0.012647746,
        -0.020731155,
        7.89849e-05,
        -0.028175788,
        0.002587039,
        0.03258914,
        0.004834366,
        -0.014471158,
        -0.05375002,
        -0.05333191,
        -0.041857187,
        0.041555222,
        0.021462843,
        -0.0016462975,
        0.022891376,
        -0.045968577,
        0.017316611,
        -0.005946415,
        -0.017862473,
        0.0041317134,
        0.04246112,
        0.03093994,
        0.02429668,
        0.011503758,
        -0.045225274,
        0.031427734,
        -0.0017000127,
        0.04568984,
        0.015539655,
        -0.057884634,
        0.025156124,
        -0.014552457,
        -0.023053972,
        -0.04629377,
        0.016793977,
        0.059417695,
        0.029824989,
        0.027827365,
        0.07874355,
        -0.03656116,
        -0.020080766,
        -0.014831196,
        0.014924108,
        0.013983367,
        -0.023623062,
        0.005319254,
        0.0016259729,
        -0.042902455,
        0.003942984,
        -0.028617123,
        -0.00444239,
        0.029662391,
        -0.0069568413,
        -0.0054063597,
        0.0634594,
        0.0315671,
        0.015017021,
        0.009105449,
        0.006666489,
        0.038465872,
        -0.00048307364,
        -0.022171302,
        0.0070032976,
        -0.013960139,
        -0.014912494,
        0.022229372,
        0.054818515,
        -0.027060835,
        0.007078789,
        0.022473268,
        0.017525665,
        -0.019604588,
        0.0096048545,
        0.020103993,
        0.03618951,
        -0.0127174305,
        0.018629003,
        -0.07507349,
        0.007920811,
        0.04757132,
        -0.015028635,
        -0.017490823,
        -0.046967387,
        0.034377713,
        -0.014958951,
        -0.03723478,
        -0.022531338,
        0.046200857,
        0.010179752,
        -0.011259862,
        0.00658519,
        -0.03749029,
        -0.018942583,
        -0.025132895,
        0.01163732,
        0.045596924,
        0.020754382,
        -0.0047791987,
        0.042623717,
        0.031404506,
        -0.031543873,
        0.011852181,
        0.0053599034,
        0.010319121,
        -0.032449774,
        0.005836081,
        0.039046578,
        0.000882671,
        -0.0082460055,
        -0.00403009,
        -0.0062832236,
        0.01773472,
        -0.0050550336,
        -0.018896127,
        0.01566741,
        0.017107558,
        -0.01560934,
        0.013286522,
        -0.06201925,
        -0.010963703,
        0.0058041424,
        0.06657197,
        -0.028710036,
        0.022182915,
        0.03723478,
        -0.0072065443,
        0.027711224,
        -0.003475517,
        -0.0030661202,
        0.007456247,
        -0.01668945,
        -0.013251679,
        -0.016619766,
        0.022995902,
        -0.014517615,
        0.0013312653,
        -0.050730355,
        0.050590985,
        -0.008698955,
        0.015446742,
        -0.018524477,
        0.05412167,
        0.005069551,
        -0.019894939,
        -0.055933468,
        0.07363334,
        0.030661203,
        0.050683897,
        -0.021184104,
        0.042670175,
        0.013251679,
        0.00067579496,
        -0.02877972,
        0.0514272,
        0.017281769,
        0.0074910894,
        -0.003954598,
        0.008861552,
        0.025643915,
        0.06192634,
        -0.049150836,
        -0.0037339306,
        0.037652887,
        -0.027827365,
        0.010394612,
        -0.015946148,
        0.06666489,
        0.029824989,
        -0.045341413,
        0.028222244,
        -0.044226464,
        -0.032194264,
        -0.040997744,
        0.027455714,
        0.028199015,
        0.03595723,
        0.004918568,
        0.0066490676,
        0.027316345,
        0.027084062,
        -0.014041437,
        0.00927966,
        -0.010348156,
        -0.0014336145,
        -0.006927806,
        -0.017107558,
        -0.02378566,
        0.0027743161,
        0.048779186,
        0.0066258395,
        -0.087152146,
        -0.059510607,
        -0.021788036,
        0.018176055,
        -0.034842275,
        -0.03107931,
        0.0012528702,
        -0.0045672418,
        0.038907208,
        -0.019813642,
        -0.0076362654,
        0.027409257,
        0.031520646,
        -0.008065987,
        0.035121012,
        -0.005296026,
        0.012380622,
        0.0049969633,
        0.03212458,
        -0.02852421,
        -0.01828058,
        -0.0488721,
        0.026549814,
        0.029708847,
        -0.03825682,
        -0.017049488,
        -0.05779172,
        0.014819581,
        -0.00398073,
        -0.016619766,
        -0.015191233,
        -0.051705938,
        0.029824989,
        -0.020313047,
        0.026967922,
        -0.001424178,
        -0.039952476,
        -0.027130518,
        -0.039325316,
        0.0050376123,
        0.017061101,
        0.016190045,
        0.021637054,
        0.013077468,
        -0.040765464,
        0.07316878,
        0.031241907,
        0.029708847,
        0.025690371,
        0.00892543,
        -0.044296145,
        0.0023213667,
        -0.0035539123,
        -0.028059646,
        -0.015539655,
        -0.013123924,
        -0.046618965,
        0.027989961,
        0.047501635,
        0.02205516,
        -0.0039778263,
        0.010708193,
        0.00030777344,
        -0.0012274643,
        0.009070606,
        0.021288631,
        -0.040742233,
        0.015504813,
        0.0043117316,
        -0.012322552,
        0.010981124,
        0.009041571,
        -0.060579102,
        0.023402395,
        -0.0022763622,
        0.022693936,
        -0.024273451,
        -0.0054760445,
        -0.0063645225,
        -0.029104915,
        -0.022484882,
        -0.01592292,
        -0.027200203,
        -0.055468902,
        -0.010313313,
        -0.03226395,
        -0.009122869,
        -0.0034929381,
        -0.026178163,
        -0.0038645891,
        -0.0006416786,
        0.037676115,
        -0.017421138,
        0.013228451,
        -0.0056328345,
        -0.03930209,
        0.01010426,
        0.027897049,
        0.006834893,
        -0.01663138,
        0.062576726,
        0.0028904572,
        0.02148607,
        -0.025760056,
        0.001637587,
        0.0075259316,
        0.007856933,
        0.0013726405,
        -0.031102538,
        -0.010499139,
        -0.017026259,
        -0.03149742,
        -0.010975317,
        -0.0064864703,
        0.0025536485,
        0.057373613,
        0.0034987452,
        0.015017021,
        -0.018001843,
        -0.010806913,
        0.04229852,
        0.013251679,
        -0.014924108,
        -0.0016869468,
        -0.008791868,
        -0.012798729,
        -0.0059986785,
        -0.028152559,
        0.014784739,
        -0.037769027,
        -0.017235313,
        -0.022891376,
        0.027269889,
        -0.0015679024,
        0.068012126,
        0.022972673,
        0.036491476,
        0.006457435,
        -0.012996169,
        0.02864035,
        -0.0065213125,
        0.017723104,
        -0.04116034,
        0.013669786,
        0.024505734,
        -0.0023895993,
        -0.004918568,
        0.009755838,
        -0.01163732,
        -0.0035510086,
        -0.019058725,
        0.03465645,
        0.03618951,
        0.030521834,
        -0.016968189,
        -0.011538601,
        -0.034006063,
        -0.028431298,
        -0.0015185425,
        -0.036282424,
        -0.012752273,
        -0.011387617,
        -0.02341401,
        0.013820769,
        0.027223432,
        0.02250811,
        0.0018916453,
        0.004213012,
        0.048546903,
        -0.0059202835,
        0.030800572,
        0.024761245,
        -0.045225274,
        -0.037559975,
        -0.019976238,
        -0.029732076,
        0.013542031,
        0.00016749698,
        0.01747921,
        0.010470104,
        -0.021985477,
        -0.032914337,
        -0.009935856,
        -0.007909196,
        0.025806513,
        0.024180539,
        -0.0018858382,
        0.036143053,
        -0.018733531,
        0.014145964,
        -0.010812719,
        -0.037583202,
        -0.012252867,
        0.017223699,
        0.04248435,
        0.008460866,
        0.010348156,
        -0.019883325,
        -0.046409912,
        -0.013228451,
        0.0010111519,
        -0.027525399,
        -0.011857988,
        -0.04032413,
        -0.017630192,
        -0.046479598,
        0.048546903,
        0.023541765,
        -0.0027031798,
        -0.039185945,
        0.0009784873,
        -0.022275828,
        -0.019047111,
        -0.06977747,
        0.0030545061,
        -9.9173456e-05,
        0.011143722,
        0.026154935,
        -0.03800131,
        -0.009204168,
        0.0041288096,
        -0.039720196,
        0.0030109533,
        0.049336664,
        0.014238877,
        0.0152260745,
        0.004215915,
        0.0035190699,
        -0.0013690111,
        0.012729045,
        -0.015249303,
        0.0188729,
        -0.03238009,
        0.037002496,
        -0.0076536867,
        -0.0019569746,
        -0.033936378,
        -0.023564992,
        0.011004352,
        -0.007345913,
        -0.023599835,
        0.016747521,
        -0.005923187,
        0.0077291783,
        0.0046311193,
        -0.0013051336,
        0.034586765,
        -0.017165627,
        0.022287443,
        -0.03465645,
        0.0067710155,
        -0.02903523,
        -0.002421538,
        0.045527242,
        0.03542298,
        0.018129598,
        -0.007793056,
        -0.004035897,
        0.010435262,
        -0.017026259,
        -0.017235313,
        -0.024598647,
        0.019813642,
        0.015318987,
        0.001704368,
        -0.04896501,
        -0.0048140413,
        0.015086706,
        -0.04002216,
        -0.022217758,
        -0.008129864,
        0.0481288,
        0.049801227,
        0.026967922,
        -0.038465872,
        0.013588488,
        -0.0539823,
        0.0056589665,
        -0.02262425,
        -0.0151215475,
        -0.021079578,
        -0.031265136,
        0.004163652,
        0.0028933606,
        0.0052205343,
        -0.057141334,
        -0.021613825,
        -0.011927673,
        -0.011108879,
        -0.060439736,
        -0.015307373,
        0.0011476175,
        -0.022473268,
        -0.012775501,
        0.019674271,
        -0.03479582,
        -0.054911427,
        0.010110067,
        0.018245738,
        -0.0042565647,
        0.0029819182,
        0.023460466,
        0.00056872756,
        -0.011265669,
        -0.007711757,
        -0.053424824,
        0.00463983,
        -0.03851233,
        0.01853609,
        0.019140024,
        0.0013436052,
        -0.034377713,
        0.005981257,
        0.065224744,
        -0.02429668,
        -0.046386685,
        -0.045480784,
        0.028849404,
        -0.011335353,
        -0.025690371,
        -0.046107944,
        0.042879228,
        0.0091344835,
        -0.048546903,
        -0.0127174305,
        -0.013460733,
        0.0034493853,
        0.012763887,
        -0.0154351285,
        0.0018161536,
        -0.02287976,
        0.007671108,
        0.011503758,
        0.0036061755,
        0.013669786,
        0.005981257,
        -0.008455059,
        -0.006858121,
        0.023681134,
        0.031938754,
        0.006167083,
        0.001673881,
        -0.02775768,
        0.01773472,
        0.012647746,
        0.039371774,
        0.037815485,
        -0.0266195,
        -0.015853235,
        -0.016840434,
        0.0118289525,
        0.023774046,
        -0.010632701,
        -0.005638642,
        0.017688261,
        0.018059913,
        -0.0073807556,
        0.013669786,
        -0.009163518,
        -0.015946148,
        -0.042414665,
        0.011387617,
        -0.027548626,
        0.0063412944,
        -0.023541765,
        0.024389593,
        0.03186907,
        -0.00505213,
        -0.0023779853,
        0.011312125,
        -0.02864035,
        0.016852047,
        0.019732343,
        -0.010696579,
        -0.018803215,
        -0.015795166,
        0.016596537,
        -0.039278857,
        -0.013565259,
        -0.00058288226,
        -0.012891642,
        -0.012787116,
        0.008391182,
        -0.0014815226,
        0.016538467,
        0.0053163506,
        -0.002617526,
        0.03210135,
        0.023994714,
        -0.00020977954,
        0.005807046,
        0.012589675,
        0.01598099,
        0.028129332,
        0.027827365,
        -0.0042826966,
        -0.00085508754,
        0.029708847,
        -0.0027176975,
        -0.010684964,
        0.003002243,
        -0.0154351285,
        0.044389058,
        -0.017095944,
        -0.01183476,
        -0.006695524,
        0.010679157,
        0.028733263,
        -0.050590985,
        0.07210028,
        -0.011602478,
        -0.032310404,
        -0.010975317,
        0.0071252454,
        -0.022868147,
        0.012554834,
        0.025295492,
        0.009947469,
        -0.0006068363,
        0.02517935,
        -0.021648668,
        0.0045440136,
        0.012218025,
        0.0092390105,
        -0.004291407,
        0.0113818105,
        -0.034168657,
        0.053889386,
        -0.013658172,
        0.01606229,
        -0.021207333,
        0.022717165,
        -0.0035277805,
        0.005310544,
        -0.011085651,
        -0.013994981,
        -0.009146097,
        -0.01747921,
        0.0047559706,
        -0.05184531,
        -0.009041571,
        -0.005272798,
        0.014935723,
        -0.03093994,
        -0.031172223,
        -0.002659627,
        -0.013960139,
        -0.016352642,
        -0.018768372,
        0.03149742,
        -0.053006716,
        0.054446865,
        0.0030835415,
        -0.031125767,
        0.033030476,
        0.008803482,
        0.00032973132,
        0.0038994313,
        0.020382732,
        0.04116034,
        -0.003852975,
        -0.024389593,
        0.005162464,
        0.011045001,
        0.0103888055,
        0.0076362654,
        -0.0060335207,
        -0.04808234,
        0.011939286,
        0.034424167,
        -0.020115606,
        0.021126034,
        -0.006811665,
        0.009587433,
        -0.04427292,
        0.008989307,
        -0.01143988,
        0.057141334,
        -0.013472347,
        0.018779987,
        0.0061496617,
        -0.040091846,
        0.026038794,
        0.0539823,
        -0.0026146225,
        0.046502825,
        0.0010786589,
        0.008013723,
        -0.025063211,
        0.056583855,
        0.027873822,
        0.010173945,
        -0.0073575275,
        0.010917246,
        0.011916058,
        -0.013507189,
        -0.015272531,
        -0.021044735,
        -0.004869208,
        -0.03744383,
        0.008263427,
        0.026758868,
        -0.0054382985,
        0.011050808,
        0.0049969633,
        0.018059913,
        -0.019662658,
        0.003841361,
        0.0060799774,
        0.02775768,
        -0.036282424,
        -0.01572548,
        0.016515238,
        -0.039116263,
        -0.01444793,
        -0.032147806,
        0.008832517,
        -0.02903523,
        -0.009877785,
        -0.0055892817,
        -0.043668985,
        0.0017682455,
        -0.012868414,
        -0.012729045,
        0.008129864,
        0.024343137,
        -0.044481974,
        0.02071954,
        -0.019860098,
        0.02866358,
        -0.005528308,
        -0.028291928,
        0.016747521,
        -0.011306318,
        -0.039696965,
        -0.0030632168,
        0.024203768,
        0.024273451,
        0.0015983895,
        -0.025388405,
        0.030475378,
        -0.02610848,
        0.015017021,
        0.026665956,
        -0.0049534105,
        -0.0054382985,
        0.011521179,
        -0.015086706,
        -0.007485282,
        -0.056305118,
        -0.005290219,
        -0.008722183,
        0.029499793,
        0.027827365,
        0.020336276,
        -1.3496845e-05,
        0.001472812,
        -0.0028207726,
        -0.010719807,
        0.019767184,
        0.0064748563,
        -0.04503945,
        -0.018385109,
        0.009058991,
        0.010156523,
        -0.026898237,
        -0.023146885,
        -0.00028817466,
        -0.0019366499,
        0.0014655532,
        0.00693942,
        -0.010284279,
        0.02182288,
        0.008931236,
        -0.003974923,
        0.0020963436,
        0.015771937,
        -0.008803482,
        -0.048361078,
        -0.007345913,
        0.0017522761,
        -0.00070011197,
        -0.0053395787,
        -0.01586485,
        0.042112697,
        0.039348543,
        0.00015887716,
        0.0162365,
        -0.024970299,
        -0.0024462182,
        0.023065588,
        0.027200203,
        -0.009302888,
        0.015109934,
        -0.022194529,
        0.016143588,
        0.013402662,
        -0.023042358,
        0.011091458,
        0.0017334032,
        0.0026697894,
        -0.002501385,
        -0.011416652,
        -0.028338384,
        -0.04476071,
        -0.011794111,
        -0.008745411,
        0.02929074,
        -0.009517749,
        0.028454525,
        -0.015888078,
        0.018315423,
        0.028199015,
        -0.004979542,
        -0.023100428,
        0.0010866434,
        -0.0060161,
        0.019035498,
        0.017955387,
        -0.023228183,
        0.0020498873,
        -0.029128144,
        0.034261573,
        -0.03184584,
        -0.005496369,
        0.007072982,
        0.02750217,
        0.016143588,
        -0.0017784078,
        0.029499793,
        -0.060207453,
        0.03479582,
        0.019976238,
        -0.010226208,
        -0.018942583,
        -0.03221749,
        0.008484094,
        -0.005902862,
        0.035655264,
        0.0007255178,
        -0.0205221,
        0.041926872,
        0.015562884,
        -0.0016535564,
        -0.000639138,
        0.0074678613,
        0.07242548,
        0.0056444486,
        -0.0035132628,
        0.007578195,
        0.011114686,
        0.027618311,
        -0.021265402,
        -0.0058418885,
        0.020464031,
        -0.04462134,
        -0.029104915,
        0.030034043,
        -0.0030545061,
        -0.021729967,
        -0.0054092635,
        0.017990228,
        -0.04208947,
        0.017119171,
        -0.021253789,
        0.015760323,
        -0.00658519,
        -0.00047145956,
        -0.0031212873,
        -0.02327464,
        0.0010699482,
        -0.03221749,
        0.0043465737,
        -0.01853609,
        -0.016166816,
        0.02154414,
        -0.021973861,
        -0.029894672,
        0.008187935,
        0.007601423,
        -0.014738283,
        0.013576874,
        0.017374681,
        0.006312259,
        -0.0012594031,
        0.010725614,
        -0.015957762,
        -0.003719413,
        -0.03310016,
        -0.01592292,
        -0.019488446,
        -0.007554967,
        -0.017293382,
        0.01598099,
        0.00770595,
        0.00346971,
        0.008466673,
        -0.0153306015,
        0.003037085,
        -0.02429668,
        -0.024505734,
        0.0007276955,
        0.03454031,
        0.06415624,
        -0.039580826,
        0.009250624,
        -0.0065329266,
        -0.006596804,
        -0.0076130372,
        0.028849404,
        0.01776956,
        -0.01586485,
        -0.012798729,
        -0.026131706,
        -0.01143988,
        0.029848216,
        -0.026921466,
        -0.0013922392,
        -0.0057605896,
        -0.021602212,
        0.027711224,
        -0.004215915,
        -0.015133162,
        0.024738016,
        0.019709114,
        -0.031404506,
        -0.01234578,
        0.007584002,
        -0.0027481846,
        0.012334166,
        -0.028106103,
        -0.026456902,
        0.034331255,
        0.023309482,
        -0.028710036,
        0.0023881476,
        -0.007316878,
        0.02182288,
        0.02622462,
        0.039743423,
        -0.021137647,
        -0.012194796,
        -0.004930182,
        -0.0076653007,
        -0.012322552,
        0.024017943,
        -0.010597859,
        0.012961327,
        0.014540844,
        0.020731155,
        -0.024226995,
        0.036143053,
        -0.0053599034,
        -0.006451628,
        -0.042623717,
        -0.050079964,
        0.03681667,
        -0.002453477,
        0.027804136,
        -0.03737415,
        -0.038605243,
        0.03902335,
        0.040115073,
        0.037002496,
        -0.015168004,
        -0.0188729,
        0.022728778,
        -0.010272664,
        0.0065793833,
        0.006858121,
        -0.034888733,
        0.028199015,
        0.0059144762,
        0.034424167,
        -0.021718351,
        0.010545596,
        0.0062367674,
        -0.0128219575,
        0.030359237,
        -0.015586112,
        0.036073368,
        0.00024988444,
        0.0037048953,
        -0.037304465,
        -0.017967,
        0.038140677,
        -0.038187135,
        0.009906821,
        0.009982312,
        0.030405693,
        -0.03990602,
        0.0028323866,
        0.018629003,
        -0.016422326,
        0.03697927,
        -0.022717165,
        0.023251412,
        -0.024203768,
        -0.021184104,
        -0.041880418,
        0.016492011,
        -0.017026259,
        -0.004157845,
        0.011486337,
        0.009465485,
        0.0005015836,
        -0.017897315,
        -0.0222526,
        -0.015202846,
        0.018698689,
        0.018327037,
        0.009389994,
        -0.022438426,
        0.0059522223,
        0.02866358,
        0.016747521,
        0.010220401,
        0.009111255,
        0.01938392,
        -0.02032466,
        -0.011091458,
        -0.006916192,
        0.009854557,
        -0.006561962,
        0.0028381937,
        0.02028982,
        -0.019906554,
        0.02003431,
        0.025481317,
        -0.0014263557,
        0.029987585,
        -0.05695551,
        0.000742576,
        0.0055486322,
        0.028547438,
        0.007572388,
        0.03363441,
        -0.0013421535,
        0.024250224,
        -0.0144943865,
        0.044226464,
        0.03005727,
        -0.016991416,
        0.0069336127,
        -0.0111263,
        0.022484882,
        0.029662391,
        0.01859416,
        -0.011683777,
        -0.02636399,
        -0.010069418,
        0.023739204,
        0.00037600624,
        0.017258542,
        0.019256165,
        -0.055050798,
        0.0005770752,
        -0.008106636,
        0.0023053973,
        0.026805324,
        0.01603906,
        0.0013682853,
        -0.016747521,
        0.0040736427,
        0.009645503,
        -0.011091458,
        0.009093834,
        0.0206034,
        0.023251412,
        -0.015318987,
        0.017270155,
        -0.013774313,
        -0.0127174305,
        -0.007949846,
        -0.019848483,
        0.01893097,
        0.032542687,
        -0.0028323866,
        0.030126955,
        -0.010237822,
        0.008995114,
        0.011881216,
        -0.002848356,
        0.0019047111,
        0.042135924,
        -0.025016755,
        0.0007091855,
        0.024621876,
        0.026665956,
        -0.002787382,
        -0.038860753,
        -0.0075027035,
        -0.0035742368,
        0.005568957,
        -0.017386295,
        -0.0007371319,
        -0.014285333,
        0.016898504,
        -0.010714,
        -0.005778011,
        -0.0126129035,
        0.013181995,
        0.027316345,
        -0.024528962,
        0.012810344,
        0.015144776,
        0.025852969,
        0.028733263,
        -0.025620688,
        -0.008971886,
        0.017188856,
        0.024993526,
        -0.009988119,
        0.019372305,
        -0.0014807967,
        -0.03340213,
        -0.0073517202,
        0.010545596,
        0.02636399,
        0.008095022,
        -0.007856933,
        0.0049156644,
        -0.03221749,
        -0.00031140284,
        0.017037872,
        -0.03800131,
        0.017003031,
        0.00011405401,
        -0.0073865624,
        0.011521179,
        0.0071020173,
        0.011108879,
        -0.013379434,
        0.016666222,
        0.008333111,
        -0.009308695,
        0.042577263,
        -0.024389593,
        0.008536357,
        -0.023263026,
        -0.00843183,
        -0.040928062,
        -0.017095944,
        -0.025225807,
        0.010783684,
        0.008774446,
        -0.012531606,
        -0.0074910894,
        0.010022962,
        -0.024343137,
        0.0077582137,
        -0.008542164,
        0.010098453,
        0.03135805,
        0.0044772327,
        0.00059558515,
        -0.0020760188,
        -0.02980176,
        -0.015946148,
        -0.019116795,
        0.019813642,
        0.000596674,
        0.019476833,
        -0.025063211,
        -0.011648934,
        0.004163652,
        0.0075491597,
        -0.01916325,
        0.00668391,
        0.012229639,
        0.0025551002,
        0.014738283,
        0.010319121,
        0.00693942,
        0.010650123,
        -0.023042358,
        -0.0061380477,
        -0.0188729,
        0.019894939,
        0.0069568413,
        -0.011561829,
        0.0067594014,
        0.021706738,
        0.022217758,
        0.029871445,
        -0.007520125,
        -0.0038123257,
        0.011927673,
        -0.037885167,
        -0.02915137,
        -0.014552457,
        -0.015260917,
        0.026549814,
        -0.0030225674,
        0.015632568,
        0.030800572,
        0.026387217,
        0.047803603,
        -0.040347356,
        -0.012136726,
        0.045596924,
        -0.002873036,
        -0.026480129,
        -0.0039662123,
        -0.011683777,
        0.010853369,
        -0.023855345,
        0.030034043,
        0.029639162,
        -0.012276095,
        0.0016898504,
        -0.03377378,
        -0.0072413865,
        -0.019151637,
        0.009128677,
        -0.014575685,
        0.020905366,
        0.003986537,
        0.006434207,
        0.0317297,
        0.002573973,
        0.0066142255,
        -0.00831569,
        -0.0017508244,
        -0.0074794753,
        0.0033129198,
        -0.0070032976,
        -0.005856406,
        -0.008269234,
        -0.028245471,
        0.03175293,
        0.004680479,
        0.00025877648,
        -0.004660154,
        0.01836188
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 256.82048988342285,
        "patch_type": "full",
        "api_costs": 0.261206,
        "num_applied": 1,
        "patch_name": "greedy_lns_beam",
        "patch_description": "This algorithm combines a Multi-Start Randomized Greedy initialization with a Large Neighborhood Search (LNS) refinement step powered by Beam Search.\n1. Initialization: Runs Randomized LPT (Longest Processing Time) greedy multiple times with weight perturbations to find a good initial load distribution.\n2. Refinement: Iteratively selects the heaviest, lightest, and a random pack (3-way) to re-optimize.\n3. Sub-problem Solver: Uses a localized Beam Search with symmetry breaking to optimally redistribute items within the selected subset of packs, effectively performing complex multi-item swaps (generalized 3-way exchanges) to minimize max load and variance.\nThis approach leverages the speed of greedy for global structure and the precision of beam search for local refinement, overcoming local optima that block simple swap heuristics.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 1,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\ngreedy_lns_beam\n</NAME>\n\n<DESCRIPTION>\nThis algorithm combines a Multi-Start Randomized Greedy initialization with a Large Neighborhood Search (LNS) refinement step powered by Beam Search.\n1. Initialization: Runs Randomized LPT (Longest Processing Time) greedy multiple times with weight perturbations to find a good initial load distribution.\n2. Refinement: Iteratively selects the heaviest, lightest, and a random pack (3-way) to re-optimize.\n3. Sub-problem Solver: Uses a localized Beam Search with symmetry breaking to optimally redistribute items within the selected subset of packs, effectively performing complex multi-item swaps (generalized 3-way exchanges) to minimize max load and variance.\nThis approach leverages the speed of greedy for global structure and the precision of beam search for local refinement, overcoming local optima that block simple swap heuristics.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Algorithm: Randomized Greedy Initialization + Local Beam Search Refinement\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case: 1 group per pack (1-to-1 mapping)\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(num_layers, num_groups)\n        rank_in_pack = torch.zeros((num_layers, num_groups), dtype=torch.int64, device=device)\n        return pack_index, rank_in_pack\n\n    # Work on CPU for efficiency with scalar logic\n    weight_cpu = weight.cpu()\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Helper: Beam Search Solver for a subset of items/packs\n    def solve_subset_beam(items, w_map, capacity, k_packs, width=32):\n        \"\"\"\n        Optimally pack 'items' into 'k_packs' each with 'capacity' using Beam Search.\n        \"\"\"\n        # Sort items Descending (LPT)\n        items_sorted = sorted(items, key=lambda x: w_map[x], reverse=True)\n        \n        # Beam State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n        # We start with empty packs.\n        start_node = (0.0, 0.0, tuple([0.0]*k_packs), tuple([0]*k_packs), ())\n        beam = [start_node]\n        \n        for item_idx in items_sorted:\n            w = w_map[item_idx]\n            next_beam = []\n            \n            for b_max, b_ss, loads, counts, assign in beam:\n                # Symmetry breaking: Bins with same (load, count) are equivalent.\n                # Only try to put item in one of the equivalent bins.\n                seen_signatures = set()\n                \n                for p in range(k_packs):\n                    if counts[p] < capacity:\n                        # Signature for symmetry breaking\n                        sig = (round(loads[p], 5), counts[p])\n                        if sig in seen_signatures:\n                            continue\n                        seen_signatures.add(sig)\n                        \n                        # Create new state\n                        nl = list(loads)\n                        nl[p] += w\n                        nc = list(counts)\n                        nc[p] += 1\n                        \n                        # Update metrics\n                        # Delta Sum Squares = (L+w)^2 - L^2 = 2Lw + w^2\n                        delta_ss = 2 * loads[p] * w + w * w\n                        new_ss = b_ss + delta_ss\n                        new_max = b_max if b_max > nl[p] else nl[p]\n                        \n                        next_beam.append((new_max, new_ss, tuple(nl), tuple(nc), assign + (p,)))\n            \n            # Prune beam\n            if len(next_beam) > width:\n                # Primary key: Max Load, Secondary: Sum Squares\n                beam = heapq.nsmallest(width, next_beam, key=lambda x: (x[0], x[1]))\n            else:\n                beam = next_beam\n        \n        # Best solution found\n        best = beam[0]\n        assign_indices = best[4]\n        final_weights = best[2]\n        \n        # Reconstruct packs\n        res_packs = [[] for _ in range(k_packs)]\n        for i, p in enumerate(assign_indices):\n            res_packs[p].append(items_sorted[i])\n            \n        return res_packs, list(final_weights)\n\n    # Main Loop over Layers\n    for i in range(num_layers):\n        layer_w_tensor = weight_cpu[i]\n        layer_w_list = layer_w_tensor.tolist()\n        \n        # --- 1. Initialization: Randomized Greedy ---\n        best_assignment = None\n        best_pack_weights = None\n        best_global_max = float('inf')\n        best_global_ss = float('inf')\n        \n        # Number of restarts\n        NUM_RESTARTS = 10\n        base_indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n        \n        for attempt in range(NUM_RESTARTS):\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to change sort order (Perturbed LPT)\n                # Noise range [0.9, 1.1]\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x] * noise[x], reverse=True)\n            \n            curr_packs = [[] for _ in range(num_packs)]\n            curr_weights = [0.0] * num_packs\n            curr_counts = [0] * num_packs\n            \n            # Greedy Fill (Best Fit)\n            for idx in indices:\n                w = layer_w_list[idx]\n                best_p = -1\n                min_load = float('inf')\n                \n                for p in range(num_packs):\n                    if curr_counts[p] < groups_per_pack:\n                        if curr_weights[p] < min_load:\n                            min_load = curr_weights[p]\n                            best_p = p\n                \n                curr_packs[best_p].append(idx)\n                curr_weights[best_p] += w\n                curr_counts[best_p] += 1\n            \n            # Check Metrics\n            c_max = max(curr_weights)\n            c_ss = sum(x*x for x in curr_weights)\n            \n            if c_max < best_global_max - 1e-6:\n                best_global_max = c_max\n                best_global_ss = c_ss\n                best_assignment = curr_packs\n                best_pack_weights = curr_weights\n            elif abs(c_max - best_global_max) < 1e-6 and c_ss < best_global_ss - 1e-6:\n                best_global_ss = c_ss\n                best_assignment = curr_packs\n                best_pack_weights = curr_weights\n        \n        packs = best_assignment\n        pack_weights = best_pack_weights\n        \n        # --- 2. Refinement: LNS with Beam Search ---\n        # Focus on Max and Min packs to reduce spread\n        MAX_LNS_STEPS = 50\n        consecutive_fail = 0\n        limit_fail = 8\n        \n        for step in range(MAX_LNS_STEPS):\n            # Identify extremes\n            max_p = -1; max_val = -1.0\n            min_p = -1; min_val = float('inf')\n            \n            for p in range(num_packs):\n                val = pack_weights[p]\n                if val > max_val: max_val = val; max_p = p\n                if val < min_val: min_val = val; min_p = p\n            \n            if max_val - min_val < 1e-6:\n                break\n                \n            # Select subset of packs to optimize\n            candidates = [max_p, min_p]\n            if num_packs > 2:\n                # Add a random third pack to allow 3-way exchanges\n                # Avoid max_p and min_p\n                r = random.randint(0, num_packs - 1)\n                while r == max_p or r == min_p:\n                    r = random.randint(0, num_packs - 1)\n                candidates.append(r)\n            \n            # Collect items from candidates\n            sub_items = []\n            for p in candidates:\n                sub_items.extend(packs[p])\n            \n            # Solve subset optimally(ish) with Beam Search\n            # Beam width 32 is sufficient for small subset (2 or 3 packs)\n            new_sub_packs, new_sub_weights = solve_subset_beam(\n                sub_items, layer_w_list, groups_per_pack, len(candidates), width=32\n            )\n            \n            # Check for improvement\n            old_sub_max = max(pack_weights[p] for p in candidates)\n            old_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n            \n            new_sub_max = max(new_sub_weights)\n            new_sub_ss = sum(x*x for x in new_sub_weights)\n            \n            improved = False\n            # Accept if Max load reduces OR Max load stays same but Variance (Sum Sq) reduces\n            if new_sub_max < old_sub_max - 1e-6:\n                improved = True\n            elif abs(new_sub_max - old_sub_max) < 1e-6 and new_sub_ss < old_sub_ss - 1e-6:\n                improved = True\n            \n            if improved:\n                for local_idx, p in enumerate(candidates):\n                    packs[p] = new_sub_packs[local_idx]\n                    pack_weights[p] = new_sub_weights[local_idx]\n                consecutive_fail = 0\n            else:\n                consecutive_fail += 1\n                if consecutive_fail >= limit_fail:\n                    break\n\n        # --- 3. Output ---\n        for p in range(num_packs):\n            for r, g_idx in enumerate(packs[p]):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>",
          "msg": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output tensors\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Number of restarts for randomized greedy\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_weights = weight_cpu[i]\n\n        # Base sort indices (LPT)\n        base_indices = layer_weights.argsort(descending=True).tolist()\n\n        best_assignment = None\n        best_max_load = float('inf')\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Randomized Candidate Generation\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to perturb sort order\n                # 5% noise is usually sufficient to swap similar items\n                noise = torch.rand(num_groups) * 0.05\n                indices = (layer_weights * (1 + noise)).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT / Best Fit)\n            # pack_contents: list of lists storing item indices\n            pack_contents = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_sizes = [0] * num_packs\n\n            for idx in indices:\n                w = layer_weights[idx].item()\n\n                # Find lightest valid pack\n                best_p = -1\n                min_w = float('inf')\n\n                # Simple linear scan is fast for small num_packs\n                for p in range(num_packs):\n                    if pack_sizes[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                pack_contents[best_p].append(idx)\n                pack_weights[best_p] += w\n                pack_sizes[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            # Iteratively improve by repacking subsets of bins\n\n            MAX_LNS_STEPS = 50\n            consecutive_no_improve = 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Sort packs by weight\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                max_p = sorted_packs[0]\n                min_p = sorted_packs[-1]\n\n                # If balanced enough, stop\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                    break\n\n                # Select candidates for LNS: Heaviest, Lightest, and potentially a random one\n                candidates = [max_p, min_p]\n                if num_packs > 2:\n                    # Pick a random pack that is not max or min to facilitate 3-way/4-way cyclic shifts\n                    # Use a simple pseudo-random approach based on step\n                    candidates.append(sorted_packs[(step + 1) % (num_packs - 1) + 1])\n\n                # Collect items from candidates\n                items_to_repack = []\n                for p in candidates:\n                    items_to_repack.extend(pack_contents[p])\n\n                # Sort descending (LPT)\n                items_to_repack.sort(key=lambda x: layer_weights[x].item(), reverse=True)\n\n                # Repack into these bins using Bounded Best Fit\n                new_loads = {p: 0.0 for p in candidates}\n                new_contents = {p: [] for p in candidates}\n                possible = True\n\n                for item_idx in items_to_repack:\n                    w = layer_weights[item_idx].item()\n                    # Assign to candidate bin with min current load that has space\n                    best_local_p = -1\n                    min_local_w = float('inf')\n                    for p in candidates:\n                        if len(new_contents[p]) < groups_per_pack:\n                            if new_loads[p] < min_local_w:\n                                min_local_w = new_loads[p]\n                                best_local_p = p\n\n                    if best_local_p == -1:\n                        possible = False\n                        break\n\n                    new_contents[best_local_p].append(item_idx)\n                    new_loads[best_local_p] += w\n\n                if possible:\n                    # Check improvement criteria\n                    old_local_max = max(pack_weights[p] for p in candidates)\n                    new_local_max = max(new_loads.values())\n\n                    # Accept if max load decreases OR max load is same but variance decreases (better balance)\n                    # Sum of squares is a good proxy for variance\n                    old_ss = sum(pack_weights[p]**2 for p in candidates)\n                    new_ss = sum(val**2 for val in new_loads.values())\n\n                    if new_local_max < old_local_max - 1e-6 or (abs(new_local_max - old_local_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                        # Apply Update\n                        for p in candidates:\n                            pack_contents[p] = new_contents[p]\n                            pack_weights[p] = new_loads[p]\n                            pack_sizes[p] = groups_per_pack # Should be full\n                        consecutive_no_improve = 0\n                    else:\n                        consecutive_no_improve += 1\n                else:\n                    consecutive_no_improve += 1\n\n                if consecutive_no_improve >= 5:\n                    break\n\n            # 4. Check global best\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in pack_contents]\n\n        # 5. Write best assignment to output tensors\n        # Flatten for scatter\n        flat_indices = []\n        flat_packs = []\n        flat_ranks = []\n\n        for p, items in enumerate(best_assignment):\n            for r, idx in enumerate(items):\n                flat_indices.append(idx)\n                flat_packs.append(p)\n                flat_ranks.append(r)\n\n        idx_tensor = torch.tensor(flat_indices, dtype=torch.int64, device=device)\n        pack_tensor = torch.tensor(flat_packs, dtype=torch.int64, device=device)\n        rank_tensor = torch.tensor(flat_ranks, dtype=torch.int64, device=device)\n\n        pack_index[i].scatter_(0, idx_tensor, pack_tensor)\n        rank_in_pack[i].scatter_(0, idx_tensor, rank_tensor)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        # Extract weights for this layer as a list for fast Python iteration\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # Candidate generation:\n        # We try:\n        # 1. Deterministic LPT (sort descending)\n        # 2. Randomized LPT (multiple attempts)\n\n        candidates = []\n\n        # 1. Deterministic\n        indices_det = layer_weights_t.sort(descending=True).indices.tolist()\n        candidates.append(indices_det)\n\n        # 2. Perturbed (only if we have enough groups for it to matter)\n        if groups_per_pack > 1:\n            for attempt in range(4):\n                # Add small random noise to explore different greedy decisions\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # +/- 5%\n                indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n                candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            # Re-init packs using lists for speed\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n\n                # Find best pack: valid (not full) and min weight\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        pw = current_pack_weights[p]\n                        if pw < min_w:\n                            min_w = pw\n                            best_p = p\n\n                # Assign\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            # Metric: minimize max load\n            max_load = max(current_pack_weights)\n            if max_load < min_max_load:\n                min_max_load = max_load\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # Global Refinement Loop\n        # Alternates between Vectorized Pairwise Swaps and Large Neighborhood Search (LNS)\n\n        NUM_GLOBAL_ITER = 3\n\n        for global_iter in range(NUM_GLOBAL_ITER):\n\n            # Phase 1: Vectorized Local Search (Pairwise Swaps)\n            # Efficiently checks swaps between max pack and others\n\n            improved_swap = False\n            for _ in range(20): # Limit iterations per phase\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1) # [1, G, 1]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack) # [M, 1, G]\n\n                # Compute deltas: w_u - w_v\n                deltas = w_u - w_v # [M, G, G]\n\n                # Diff with max pack\n                diffs = (max_w - pack_weights).view(num_packs, 1, 1) # [M, 1, 1]\n\n                # Gain metric: delta * (diff - delta)\n                # We want 0 < delta < diff\n\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_flat = torch.argmax(gains).item()\n                max_gain = gains.view(-1)[best_flat].item()\n\n                if max_gain < 0:\n                    break\n\n                # Perform Swap\n                best_p = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                best_u_idx = rem // groups_per_pack\n                best_v_idx = rem % groups_per_pack\n\n                u_val = pack_assignment[max_pack, best_u_idx].item()\n                v_val = pack_assignment[best_p, best_v_idx].item()\n\n                pack_assignment[max_pack, best_u_idx] = v_val\n                pack_assignment[best_p, best_v_idx] = u_val\n\n                d_val = deltas[best_p, best_u_idx, best_v_idx].item()\n                pack_weights[max_pack] -= d_val\n                pack_weights[best_p] += d_val\n                improved_swap = True\n\n            # Phase 2: Large Neighborhood Search (LNS)\n            # Ruin and Recreate 3 packs (Max, Min, Random)\n            # This helps to perform 3-way exchanges or more complex reshuffling\n\n            improved_lns = False\n            if num_packs >= 3:\n                # Number of LNS attempts\n                for _ in range(15):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n\n                    if max_p == min_p:\n                        break\n\n                    # Pick 3rd pack random\n                    rand_p = torch.randint(0, num_packs, (1,)).item()\n                    while rand_p == max_p or rand_p == min_p:\n                        rand_p = torch.randint(0, num_packs, (1,)).item()\n\n                    indices_list = [max_p, min_p, rand_p]\n\n                    # Collect items\n                    items = []\n                    for p in indices_list:\n                         items.extend(pack_assignment[p].tolist())\n\n                    # Sort items LPT\n                    items.sort(key=lambda x: layer_weights[x], reverse=True)\n\n                    # Repack Greedy into these 3\n                    temp_packs = {p: [] for p in indices_list}\n                    temp_weights = {p: 0.0 for p in indices_list}\n                    temp_counts = {p: 0 for p in indices_list}\n\n                    possible = True\n                    for item_idx in items:\n                        w = layer_weights[item_idx]\n                        best_local_p = -1\n                        min_local_w = float('inf')\n                        found = False\n\n                        # Greedy Best Fit on subset\n                        for p in indices_list:\n                             if temp_counts[p] < groups_per_pack:\n                                 if temp_weights[p] < min_local_w:\n                                     min_local_w = temp_weights[p]\n                                     best_local_p = p\n                                     found = True\n\n                        if not found:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        old_max = max(pack_weights[p].item() for p in indices_list)\n                        new_max = max(temp_weights.values())\n\n                        old_ss = sum(pack_weights[p].item()**2 for p in indices_list)\n                        new_ss = sum(w**2 for w in temp_weights.values())\n\n                        # Accept if improves max load or variance\n                        if new_max < old_max - 1e-6 or (abs(new_max - old_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                            for p in indices_list:\n                                pack_assignment[p] = torch.tensor(temp_packs[p], dtype=torch.int64)\n                                pack_weights[p] = temp_weights[p]\n                            improved_lns = True\n\n            if not improved_swap and not improved_lns:\n                break\n\n        # Final write to output tensors\n        # pack_assignment contains expert indices in packed order\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n\n        best_max_load = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                # Deterministic LPT\n                indices = layer_w.argsort(descending=True).tolist()\n            else:\n                # Randomized LPT (Perturbed weights)\n                noise = torch.rand(num_groups) * 0.4 + 0.8  # 0.8 to 1.2\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_cnt = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w[g_idx].item()\n                # Best fit among non-full packs (min current load)\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_cnt[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_cnt[best_p] += 1\n\n            # 3. Refinement Phase 1: Vectorized 2-Opt (Swap)\n            for _ in range(10):\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                improved = False\n                for p_idx in range(min(3, num_packs)):\n                    max_p = sorted_packs[p_idx]\n                    max_w = pack_weights[max_p]\n                    best_swap = None\n                    best_gain = 0.0\n\n                    u_nodes = packs[max_p]\n                    w_u = layer_w[u_nodes]\n\n                    for p in range(num_packs):\n                        if p == max_p: continue\n                        if pack_weights[p] >= max_w: continue\n\n                        diff = max_w - pack_weights[p]\n                        if diff < 1e-6: continue\n\n                        v_nodes = packs[p]\n                        w_v = layer_w[v_nodes]\n\n                        deltas = w_u.unsqueeze(1) - w_v.unsqueeze(0)\n                        mask = (deltas > 1e-6) & (deltas < diff)\n                        if not mask.any(): continue\n\n                        gains = deltas * (diff - deltas)\n                        gains = torch.where(mask, gains, -1.0)\n                        curr_max_gain, curr_idx = gains.flatten().max(0)\n\n                        if curr_max_gain.item() > best_gain:\n                            best_gain = curr_max_gain.item()\n                            idx = curr_idx.item()\n                            u_idx = idx // len(v_nodes)\n                            v_idx = idx % len(v_nodes)\n                            best_swap = (max_p, p, u_idx, v_idx, deltas.flatten()[idx].item())\n\n                    if best_swap:\n                        p1, p2, u_i, v_i, delta = best_swap\n                        packs[p1][u_i], packs[p2][v_i] = packs[p2][v_i], packs[p1][u_i]\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        improved = True\n                        break\n                if not improved: break\n\n            # 4. Refinement Phase 2: Pairwise Rebalancing (Ruin & Recreate)\n            # Focus on reducing the gap between heaviest and lightest packs\n            for _ in range(15):\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n                if max_p == min_p: break\n\n                diff = pack_weights[max_p] - pack_weights[min_p]\n                if diff < 1e-6: break\n\n                items_pair = packs[max_p] + packs[min_p]\n                # Optimization: Extract weights once\n                w_pair = [(layer_w[idx].item(), idx) for idx in items_pair]\n                w_pair.sort(key=lambda x: x[0], reverse=True)\n\n                best_pair_res = None\n                best_pair_diff = diff\n\n                # Try Deterministic and Randomized Greedy on this pair\n                # 1 Deterministic + 5 Randomized\n                for attempt_pair in range(6):\n                    if attempt_pair > 0:\n                        # Perturb weights for randomization\n                        current_w_pair = [(w * (1.0 + torch.rand(1).item() * 0.1), w, idx) for w, idx in w_pair]\n                        current_w_pair.sort(key=lambda x: x[0], reverse=True)\n                        iter_items = [(w_real, idx) for _, w_real, idx in current_w_pair]\n                    else:\n                        iter_items = w_pair\n\n                    p1_new, p2_new = [], []\n                    w1_new, w2_new = 0.0, 0.0\n\n                    for w_val, idx in iter_items:\n                        if len(p1_new) < groups_per_pack and len(p2_new) < groups_per_pack:\n                            if w1_new < w2_new:\n                                p1_new.append(idx); w1_new += w_val\n                            else:\n                                p2_new.append(idx); w2_new += w_val\n                        elif len(p1_new) < groups_per_pack:\n                            p1_new.append(idx); w1_new += w_val\n                        else:\n                            p2_new.append(idx); w2_new += w_val\n\n                    curr_diff = abs(w1_new - w2_new)\n                    if curr_diff < best_pair_diff - 1e-6:\n                        best_pair_diff = curr_diff\n                        best_pair_res = (p1_new, p2_new, w1_new, w2_new)\n\n                if best_pair_res:\n                    p1_idx, p2_idx, w1_v, w2_v = best_pair_res\n                    packs[max_p] = p1_idx\n                    pack_weights[max_p] = w1_v\n                    packs[min_p] = p2_idx\n                    pack_weights[min_p] = w2_v\n                else:\n                    break\n\n            # 5. Evaluation\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Algorithm: Beam Search Initialization + Perturbed LPT Refinement + Ring Swaps\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # CPU for scalar logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    for i in range(num_layers):\n        w_tensor = weight_cpu[i]\n        w_list = w_tensor.tolist()\n\n        sorted_indices = sorted(range(num_groups), key=lambda x: w_list[x], reverse=True)\n\n        # --- Phase 1: Beam Search Initialization ---\n        BEAM_WIDTH = 4\n        BEAM_DEPTH = min(num_groups, 30)\n\n        # State: (score, loads_tuple, counts_tuple, path_tuple)\n        beam = [(0.0, tuple([0.0]*num_packs), tuple([0]*num_packs), ())]\n\n        for k in range(BEAM_DEPTH):\n            item_idx = sorted_indices[k]\n            w = w_list[item_idx]\n            new_beam = []\n\n            for score, loads, counts, path in beam:\n                seen_states = set()\n\n                for p in range(num_packs):\n                    if counts[p] < groups_per_pack:\n                        state_sig = (round(loads[p], 5), counts[p])\n                        if state_sig in seen_states: continue\n                        seen_states.add(state_sig)\n\n                        nl = list(loads)\n                        nl[p] += w\n                        nc = list(counts)\n                        nc[p] += 1\n\n                        # Incremental Score Update: min sum(load^2)\n                        delta_score = 2 * loads[p] * w + w * w\n\n                        new_beam.append((score + delta_score, tuple(nl), tuple(nc), path + (p,)))\n\n            if len(new_beam) > BEAM_WIDTH:\n                beam = heapq.nsmallest(BEAM_WIDTH, new_beam, key=lambda x: x[0])\n            else:\n                beam = new_beam\n\n        best_node = beam[0]\n        _, current_loads, current_counts, path = best_node\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = list(current_loads)\n        pack_counts = list(current_counts)\n        for k in range(BEAM_DEPTH):\n            packs[path[k]].append(sorted_indices[k])\n\n        # --- Phase 2: Greedy Finish ---\n        for k in range(BEAM_DEPTH, num_groups):\n            idx = sorted_indices[k]\n            w = w_list[idx]\n            best_p = -1\n            min_load = float('inf')\n            for p in range(num_packs):\n                if pack_counts[p] < groups_per_pack:\n                    if pack_weights[p] < min_load:\n                        min_load = pack_weights[p]\n                        best_p = p\n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n            pack_counts[best_p] += 1\n\n        # --- Phase 3: Iterative Refinement ---\n        MAX_REFINE_ITER = 20\n\n        for iter_ in range(MAX_REFINE_ITER):\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n            if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                break\n\n            improved = False\n\n            # Strategy A: Pairwise Optimization (Max-Min and Max-Random)\n            pairs = [(max_p, min_p)]\n            if num_packs > 2:\n                candidates = [p for p in range(num_packs) if p != max_p and p != min_p]\n                if candidates:\n                    pairs.append((max_p, random.choice(candidates)))\n\n            for p1, p2 in pairs:\n                items = packs[p1] + packs[p2]\n                best_sub_diff = abs(pack_weights[p1] - pack_weights[p2])\n                best_sub_assign = None\n\n                # 8 attempts: 1 deterministic LPT, 7 Perturbed LPT\n                # Perturbed LPT is superior to random shuffle for packing\n                for attempt in range(8):\n                    if attempt == 0:\n                        order = sorted(items, key=lambda x: w_list[x], reverse=True)\n                    else:\n                        # Perturb weights for sorting only\n                        noise = [random.uniform(0.9, 1.1) for _ in items]\n                        order = sorted(items, key=lambda x: w_list[x] * noise[items.index(x)], reverse=True)\n\n                    l1, l2 = 0.0, 0.0\n                    c1, c2 = 0, 0\n                    ass1, ass2 = [], []\n\n                    for item in order:\n                        w = w_list[item]\n                        # Greedy balance sums: put in lighter bin unless full\n                        if c1 < groups_per_pack and (c2 == groups_per_pack or l1 < l2):\n                            ass1.append(item)\n                            l1 += w\n                            c1 += 1\n                        else:\n                            ass2.append(item)\n                            l2 += w\n                            c2 += 1\n\n                    diff = abs(l1 - l2)\n                    if diff < best_sub_diff - 1e-6:\n                        best_sub_diff = diff\n                        best_sub_assign = (ass1, ass2, l1, l2)\n\n                if best_sub_assign:\n                    ass1, ass2, l1, l2 = best_sub_assign\n                    packs[p1] = ass1\n                    packs[p2] = ass2\n                    pack_weights[p1] = l1\n                    pack_weights[p2] = l2\n                    improved = True\n\n            if improved:\n                continue\n\n            # Strategy B: 3-Way Ring Swap (Max -> Mid -> Min -> Max)\n            if num_packs < 3: continue\n\n            mids = [p for p in range(num_packs) if p != max_p and p != min_p]\n            mids.sort(key=pack_weights.__getitem__) # Try lightest mids first\n\n            found_ring = False\n            for mid_p in mids[:2]: # Limit to 2 best candidates\n                # Filter candidates for speed\n                u_cands = sorted(packs[max_p], key=lambda x: w_list[x], reverse=True)\n                w_cands = sorted(packs[min_p], key=lambda x: w_list[x]) # Smallest w out of min? No, we want Min to gain.\n                # Actually, Min loses w, gains v. We want v > w.\n                # So we want w to be small, to easily find v > w.\n                v_cands = sorted(packs[mid_p], key=lambda x: w_list[x], reverse=True) # Big v to help Min most\n\n                limit_chk = 0\n                for u in u_cands:\n                    wu = w_list[u]\n                    for w in w_cands:\n                        ww = w_list[w]\n                        if wu <= ww: continue # Max must decrease\n\n                        gain_max = wu - ww\n\n                        # Need v in Mid s.t. Mid doesn't explode\n                        # Mid new = Mid + wu - wv < Max_old - gain_max (ideally)\n                        # wv > Mid + wu - (Max_old - gain_max)\n                        min_wv_req = pack_weights[mid_p] + wu - pack_weights[max_p] + 1e-6\n\n                        for v in v_cands:\n                            wv = w_list[v]\n                            if wv <= ww: break # Min must increase (v > w) - optional but efficient\n\n                            # Check system constraint\n                            # New loads\n                            n_max = pack_weights[max_p] - wu + ww\n                            n_mid = pack_weights[mid_p] + wu - wv\n                            n_min = pack_weights[min_p] + wv - ww\n\n                            sys_max = max(n_max, n_mid, n_min)\n\n                            if sys_max < pack_weights[max_p] - 1e-6:\n                                packs[max_p].remove(u); packs[max_p].append(w)\n                                packs[mid_p].remove(v); packs[mid_p].append(u)\n                                packs[min_p].remove(w); packs[min_p].append(v)\n                                pack_weights[max_p] = n_max\n                                pack_weights[mid_p] = n_mid\n                                pack_weights[min_p] = n_min\n                                found_ring = True\n                                break\n\n                        if found_ring: break\n                        limit_chk += 1\n                        if limit_chk > 40: break\n                    if found_ring: break\n                if found_ring: break\n\n        # Fill output tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # --- 1. Initialization (Randomized Greedy) ---\n        candidates = []\n        # Deterministic LPT\n        candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n\n        # Randomized LPT (Perturbed weights)\n        # Generate multiple candidates to improve diversity\n        for _ in range(4):\n            noise = torch.rand(num_groups) * 0.1 + 0.95  # +/- 5% noise\n            indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n            candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n                # Best fit among non-full packs\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        if current_pack_weights[p] < min_w:\n                            min_w = current_pack_weights[p]\n                            best_p = p\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            max_load = max(current_pack_weights)\n            ss = sum(x*x for x in current_pack_weights)\n\n            if max_load < min_max_load - 1e-6:\n                min_max_load = max_load\n                min_ss = ss\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n            elif abs(max_load - min_max_load) < 1e-6:\n                if ss < min_ss - 1e-6:\n                    min_ss = ss\n                    best_assignment = current_pack_contents\n                    best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # --- 2. Refinement Loop ---\n        MAX_OUTER_LOOPS = 5\n        \n        for _ in range(MAX_OUTER_LOOPS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            for _ in range(10):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment]\n\n                # Deltas: w_u - w_v. Shape [M, G, G] (via broadcasting)\n                # Gain function aims to balance the pair (max_pack, p)\n                diffs = (max_w - pack_weights).view(-1, 1, 1) # [M, 1, 1]\n                deltas = w_u.view(1, groups_per_pack, 1) - w_v.view(num_packs, 1, groups_per_pack) # [M, G, G]\n\n                # Mask: valid positive delta strictly less than diff (to avoid overshooting too much)\n                # Actually, strictly less than diff ensures w_p < old_max after swap.\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Repack max, min, and a random pack using multiple randomized attempts\n            for _ in range(5):\n                max_p = torch.argmax(pack_weights).item()\n                min_p = torch.argmin(pack_weights).item()\n\n                if max_p == min_p:\n                    break\n\n                lns_packs = [max_p, min_p]\n                if num_packs > 2:\n                    p3 = random.randint(0, num_packs - 1)\n                    while p3 in lns_packs:\n                        p3 = random.randint(0, num_packs - 1)\n                    lns_packs.append(p3)\n\n                # Collect items\n                items_flat = []\n                for p in lns_packs:\n                    items_flat.extend(pack_assignment[p].tolist())\n                \n                # Base sort LPT\n                sub_weights = [(layer_weights[x], x) for x in items_flat]\n                sub_weights.sort(key=lambda x: x[0], reverse=True)\n\n                current_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                current_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                best_sub_assign = None\n                best_sub_weights = None\n                found_lns_improvement = False\n\n                # 4 attempts: 1 deterministic, 3 randomized\n                for attempt in range(4):\n                    if attempt == 0:\n                        order = sub_weights\n                    else:\n                        # Perturb weights for sorting\n                        order = sorted([(w * random.uniform(0.9, 1.1), w, idx) for w, idx in sub_weights], key=lambda x: x[0], reverse=True)\n                        order = [(w, idx) for _, w, idx in order]\n\n                    temp_bins = [[] for _ in lns_packs]\n                    temp_ws = [0.0] * len(lns_packs)\n                    temp_cts = [0] * len(lns_packs)\n                    \n                    possible = True\n                    for w_val, idx in order:\n                        # Greedy Best Fit\n                        best_b = -1\n                        min_local_w = float('inf')\n                        for b in range(len(lns_packs)):\n                            if temp_cts[b] < groups_per_pack:\n                                if temp_ws[b] < min_local_w:\n                                    min_local_w = temp_ws[b]\n                                    best_b = b\n                        if best_b == -1:\n                            possible = False\n                            break\n                        temp_bins[best_b].append(idx)\n                        temp_ws[best_b] += w_val\n                        temp_cts[best_b] += 1\n                    \n                    if possible:\n                        new_max = max(temp_ws)\n                        new_ss = sum(x*x for x in temp_ws)\n\n                        if new_max < current_sub_max - 1e-6:\n                            current_sub_max = new_max\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n                        elif abs(new_max - current_sub_max) < 1e-6 and new_ss < current_sub_ss - 1e-6:\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n\n                if found_lns_improvement:\n                    for i_idx, p_idx in enumerate(lns_packs):\n                        pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                        pack_weights[p_idx] = best_sub_weights[i_idx]\n                    improved_any = True\n\n            if not improved_any:\n                break\n\n        # Final write to output tensors\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_sum_sq = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups) * 0.15 + 0.925\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT/Best Fit)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_counts = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                # Best Fit: Assign to valid pack with min load\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_counts[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_counts[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Identify heavy and light packs\n                # Optimization: Track max/min indices dynamically or just scan\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n                if max_p == min_p:\n                    break\n\n                # If balanced enough, try to optimize variance by picking random packs\n                # Otherwise, target max load reduction\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                     # Already balanced max-min, but maybe high variance?\n                     pass\n\n                candidates = {max_p, min_p}\n                # Add random packs for k-way swaps\n                if num_packs > 2:\n                    k_random = min(2, num_packs - 2)\n                    for _ in range(k_random):\n                        candidates.add(torch.randint(0, num_packs, (1,)).item())\n\n                cand_list = list(candidates)\n\n                # Ruin\n                items = []\n                for p in cand_list:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                best_sub_weights = [pack_weights[p] for p in cand_list]\n                best_sub_packs = [list(packs[p]) for p in cand_list]\n                best_sub_max = max(best_sub_weights)\n                best_sub_ss = sum(w*w for w in best_sub_weights)\n\n                improved_sub = False\n\n                # 0. Deterministic LPT attempt\n                # 1..N. Randomized LPT attempts\n\n                # Prepare LPT sort once\n                items_sorted = sorted(items, key=lambda x: layer_w_list[x], reverse=True)\n\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        # We use a list of tuples (perturbed_weight, index)\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n\n                if improved_sub:\n                    for idx, p in enumerate(cand_list):\n                        packs[p] = best_sub_packs[idx]\n                        pack_weights[p] = best_sub_weights[idx]\n                        pack_counts[p] = groups_per_pack # Should remain full\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w*w for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6 and current_ss < best_sum_sq - 1e-6:\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights for fast scalar access\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    import random\n    import heapq\n\n    def solve_beam(items_to_pack, w_map, pack_limit, num_bins, beam_width):\n        \"\"\"\n        Solve balanced packing for a subset of items using Beam Search.\n        items_to_pack: list of item indices\n        w_map: list of all weights (w_map[idx] is weight)\n        pack_limit: max items per bin\n        num_bins: number of bins\n        \"\"\"\n        # Sort LPT\n        items_sorted = sorted(items_to_pack, key=lambda x: w_map[x], reverse=True)\n\n        # State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n        # assignment_tuple: sequence of bin indices for items in items_sorted\n        initial_state = (0.0, 0.0, tuple([0.0]*num_bins), tuple([0]*num_bins), ())\n        beam = [initial_state]\n\n        for item_idx in items_sorted:\n            w = w_map[item_idx]\n            next_beam = []\n\n            for b_max, b_ss, loads, counts, assign in beam:\n                # Symmetry breaking:\n                # Identify bins by (load, count). Only try one bin for each unique (load, count) pair.\n                seen_signatures = set()\n\n                for p in range(num_bins):\n                    if counts[p] < pack_limit:\n                        # Round to avoid float precision issues in signature\n                        sig = (round(loads[p], 5), counts[p])\n                        if sig in seen_signatures:\n                            continue\n                        seen_signatures.add(sig)\n\n                        # Create new state\n                        new_loads = list(loads)\n                        new_loads[p] += w\n                        new_counts = list(counts)\n                        new_counts[p] += 1\n\n                        new_max = max(b_max, new_loads[p])\n                        # Incremental SS: old_ss - old_L^2 + new_L^2\n                        # new_L = old_L + w\n                        # delta = 2*old_L*w + w^2\n                        delta_ss = 2 * loads[p] * w + w * w\n                        new_ss = b_ss + delta_ss\n\n                        next_beam.append((new_max, new_ss, tuple(new_loads), tuple(new_counts), assign + (p,)))\n\n            # Select top K\n            # Primary sort: max_load, Secondary: sum_sq\n            if len(next_beam) > beam_width:\n                # partial sort using heapq.nsmallest is efficient\n                beam = heapq.nsmallest(beam_width, next_beam, key=lambda x: (x[0], x[1]))\n            else:\n                beam = next_beam\n\n        # Best state\n        best_state = beam[0]\n        # reconstruct\n        final_assign = best_state[4]\n        final_loads = best_state[2]\n\n        res_packs = [[] for _ in range(num_bins)]\n        for i, p in enumerate(final_assign):\n            res_packs[p].append(items_sorted[i])\n\n        return res_packs, list(final_loads)\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        # 1. Global Initialization with Beam Search\n        # If num_packs is very large, reduce width to keep it fast.\n        # But typically num_packs is small (<=8) in hierarchical steps.\n        # Even for 64, width=2 is better than greedy.\n        global_width = 4\n        all_items = list(range(num_groups))\n\n        packs, pack_weights = solve_beam(all_items, layer_w_list, groups_per_pack, num_packs, global_width)\n\n        # 2. Refinement: Ruin & Recreate (LNS)\n        # Use Beam Search on small subsets (2-3 packs)\n        LNS_STEPS = 20 if num_packs > 1 else 0\n\n        for step in range(LNS_STEPS):\n            # Identify max and min packs\n            max_p = -1\n            min_p = -1\n            max_w = -1.0\n            min_w = float('inf')\n\n            for p_idx, pw in enumerate(pack_weights):\n                if pw > max_w:\n                    max_w = pw\n                    max_p = p_idx\n                if pw < min_w:\n                    min_w = pw\n                    min_p = p_idx\n\n            if max_p == min_p or (max_w - min_w < 1e-6):\n                break\n\n            # Candidates: Max, Min, and maybe random\n            candidates = [max_p, min_p]\n            if num_packs > 2:\n                # Add 1 random pack\n                rand_p = random.randint(0, num_packs - 1)\n                while rand_p in candidates:\n                    rand_p = random.randint(0, num_packs - 1)\n                candidates.append(rand_p)\n\n            # Pool items\n            sub_items = []\n            for p in candidates:\n                sub_items.extend(packs[p])\n\n            # Solve sub-problem with Higher Width Beam Search\n            # K=2 or 3 is small, so we can afford width=8 or more\n            sub_packs, sub_weights = solve_beam(sub_items, layer_w_list, groups_per_pack, len(candidates), beam_width=12)\n\n            # Check improvement\n            current_sub_max = max(pack_weights[p] for p in candidates)\n            current_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n\n            new_sub_max = max(sub_weights)\n            new_sub_ss = sum(w**2 for w in sub_weights)\n\n            if new_sub_max < current_sub_max - 1e-6 or \\\n               (abs(new_sub_max - current_sub_max) < 1e-6 and new_sub_ss < current_sub_ss - 1e-6):\n                # Apply update\n                for local_idx, p in enumerate(candidates):\n                    packs[p] = sub_packs[local_idx]\n                    pack_weights[p] = sub_weights[local_idx]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(packs):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nDesign a completely different algorithm approach to solve the same problem.\nIgnore the current implementation and think of alternative algorithmic strategies that could achieve better performance.\nYou MUST respond using a short summary name, description and the full code:\n\n<NAME>\nA shortened name summarizing the code you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nExplain the completely different algorithmic approach you are taking and why it should perform better than the current implementation.\n</DESCRIPTION>\n\n<CODE>\n```{language}\n# The completely new algorithm implementation here.\n```\n</CODE>\n\n* Keep the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the code.\n* Your algorithm should solve the same problem but use a fundamentally different approach.\n* Ensure the same inputs and outputs are maintained.\n* Think outside the box - consider different data structures, algorithms, or paradigms.\n* Use the <NAME>, <DESCRIPTION>, and <CODE> delimiters to structure your response. It will be parsed afterwards.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output tensors\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Number of restarts for randomized greedy\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_weights = weight_cpu[i]\n\n        # Base sort indices (LPT)\n        base_indices = layer_weights.argsort(descending=True).tolist()\n\n        best_assignment = None\n        best_max_load = float('inf')\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Randomized Candidate Generation\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to perturb sort order\n                # 5% noise is usually sufficient to swap similar items\n                noise = torch.rand(num_groups) * 0.05\n                indices = (layer_weights * (1 + noise)).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT / Best Fit)\n            # pack_contents: list of lists storing item indices\n            pack_contents = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_sizes = [0] * num_packs\n\n            for idx in indices:\n                w = layer_weights[idx].item()\n\n                # Find lightest valid pack\n                best_p = -1\n                min_w = float('inf')\n\n                # Simple linear scan is fast for small num_packs\n                for p in range(num_packs):\n                    if pack_sizes[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                pack_contents[best_p].append(idx)\n                pack_weights[best_p] += w\n                pack_sizes[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            # Iteratively improve by repacking subsets of bins\n\n            MAX_LNS_STEPS = 50\n            consecutive_no_improve = 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Sort packs by weight\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                max_p = sorted_packs[0]\n                min_p = sorted_packs[-1]\n\n                # If balanced enough, stop\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                    break\n\n                # Select candidates for LNS: Heaviest, Lightest, and potentially a random one\n                candidates = [max_p, min_p]\n                if num_packs > 2:\n                    # Pick a random pack that is not max or min to facilitate 3-way/4-way cyclic shifts\n                    # Use a simple pseudo-random approach based on step\n                    candidates.append(sorted_packs[(step + 1) % (num_packs - 1) + 1])\n\n                # Collect items from candidates\n                items_to_repack = []\n                for p in candidates:\n                    items_to_repack.extend(pack_contents[p])\n\n                # Sort descending (LPT)\n                items_to_repack.sort(key=lambda x: layer_weights[x].item(), reverse=True)\n\n                # Repack into these bins using Bounded Best Fit\n                new_loads = {p: 0.0 for p in candidates}\n                new_contents = {p: [] for p in candidates}\n                possible = True\n\n                for item_idx in items_to_repack:\n                    w = layer_weights[item_idx].item()\n                    # Assign to candidate bin with min current load that has space\n                    best_local_p = -1\n                    min_local_w = float('inf')\n                    for p in candidates:\n                        if len(new_contents[p]) < groups_per_pack:\n                            if new_loads[p] < min_local_w:\n                                min_local_w = new_loads[p]\n                                best_local_p = p\n\n                    if best_local_p == -1:\n                        possible = False\n                        break\n\n                    new_contents[best_local_p].append(item_idx)\n                    new_loads[best_local_p] += w\n\n                if possible:\n                    # Check improvement criteria\n                    old_local_max = max(pack_weights[p] for p in candidates)\n                    new_local_max = max(new_loads.values())\n\n                    # Accept if max load decreases OR max load is same but variance decreases (better balance)\n                    # Sum of squares is a good proxy for variance\n                    old_ss = sum(pack_weights[p]**2 for p in candidates)\n                    new_ss = sum(val**2 for val in new_loads.values())\n\n                    if new_local_max < old_local_max - 1e-6 or (abs(new_local_max - old_local_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                        # Apply Update\n                        for p in candidates:\n                            pack_contents[p] = new_contents[p]\n                            pack_weights[p] = new_loads[p]\n                            pack_sizes[p] = groups_per_pack # Should be full\n                        consecutive_no_improve = 0\n                    else:\n                        consecutive_no_improve += 1\n                else:\n                    consecutive_no_improve += 1\n\n                if consecutive_no_improve >= 5:\n                    break\n\n            # 4. Check global best\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in pack_contents]\n\n        # 5. Write best assignment to output tensors\n        # Flatten for scatter\n        flat_indices = []\n        flat_packs = []\n        flat_ranks = []\n\n        for p, items in enumerate(best_assignment):\n            for r, idx in enumerate(items):\n                flat_indices.append(idx)\n                flat_packs.append(p)\n                flat_ranks.append(r)\n\n        idx_tensor = torch.tensor(flat_indices, dtype=torch.int64, device=device)\n        pack_tensor = torch.tensor(flat_packs, dtype=torch.int64, device=device)\n        rank_tensor = torch.tensor(flat_ranks, dtype=torch.int64, device=device)\n\n        pack_index[i].scatter_(0, idx_tensor, pack_tensor)\n        rank_in_pack[i].scatter_(0, idx_tensor, rank_tensor)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        # Extract weights for this layer as a list for fast Python iteration\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # Candidate generation:\n        # We try:\n        # 1. Deterministic LPT (sort descending)\n        # 2. Randomized LPT (multiple attempts)\n\n        candidates = []\n\n        # 1. Deterministic\n        indices_det = layer_weights_t.sort(descending=True).indices.tolist()\n        candidates.append(indices_det)\n\n        # 2. Perturbed (only if we have enough groups for it to matter)\n        if groups_per_pack > 1:\n            for attempt in range(4):\n                # Add small random noise to explore different greedy decisions\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # +/- 5%\n                indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n                candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            # Re-init packs using lists for speed\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n\n                # Find best pack: valid (not full) and min weight\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        pw = current_pack_weights[p]\n                        if pw < min_w:\n                            min_w = pw\n                            best_p = p\n\n                # Assign\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            # Metric: minimize max load\n            max_load = max(current_pack_weights)\n            if max_load < min_max_load:\n                min_max_load = max_load\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # Global Refinement Loop\n        # Alternates between Vectorized Pairwise Swaps and Large Neighborhood Search (LNS)\n\n        NUM_GLOBAL_ITER = 3\n\n        for global_iter in range(NUM_GLOBAL_ITER):\n\n            # Phase 1: Vectorized Local Search (Pairwise Swaps)\n            # Efficiently checks swaps between max pack and others\n\n            improved_swap = False\n            for _ in range(20): # Limit iterations per phase\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1) # [1, G, 1]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack) # [M, 1, G]\n\n                # Compute deltas: w_u - w_v\n                deltas = w_u - w_v # [M, G, G]\n\n                # Diff with max pack\n                diffs = (max_w - pack_weights).view(num_packs, 1, 1) # [M, 1, 1]\n\n                # Gain metric: delta * (diff - delta)\n                # We want 0 < delta < diff\n\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_flat = torch.argmax(gains).item()\n                max_gain = gains.view(-1)[best_flat].item()\n\n                if max_gain < 0:\n                    break\n\n                # Perform Swap\n                best_p = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                best_u_idx = rem // groups_per_pack\n                best_v_idx = rem % groups_per_pack\n\n                u_val = pack_assignment[max_pack, best_u_idx].item()\n                v_val = pack_assignment[best_p, best_v_idx].item()\n\n                pack_assignment[max_pack, best_u_idx] = v_val\n                pack_assignment[best_p, best_v_idx] = u_val\n\n                d_val = deltas[best_p, best_u_idx, best_v_idx].item()\n                pack_weights[max_pack] -= d_val\n                pack_weights[best_p] += d_val\n                improved_swap = True\n\n            # Phase 2: Large Neighborhood Search (LNS)\n            # Ruin and Recreate 3 packs (Max, Min, Random)\n            # This helps to perform 3-way exchanges or more complex reshuffling\n\n            improved_lns = False\n            if num_packs >= 3:\n                # Number of LNS attempts\n                for _ in range(15):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n\n                    if max_p == min_p:\n                        break\n\n                    # Pick 3rd pack random\n                    rand_p = torch.randint(0, num_packs, (1,)).item()\n                    while rand_p == max_p or rand_p == min_p:\n                        rand_p = torch.randint(0, num_packs, (1,)).item()\n\n                    indices_list = [max_p, min_p, rand_p]\n\n                    # Collect items\n                    items = []\n                    for p in indices_list:\n                         items.extend(pack_assignment[p].tolist())\n\n                    # Sort items LPT\n                    items.sort(key=lambda x: layer_weights[x], reverse=True)\n\n                    # Repack Greedy into these 3\n                    temp_packs = {p: [] for p in indices_list}\n                    temp_weights = {p: 0.0 for p in indices_list}\n                    temp_counts = {p: 0 for p in indices_list}\n\n                    possible = True\n                    for item_idx in items:\n                        w = layer_weights[item_idx]\n                        best_local_p = -1\n                        min_local_w = float('inf')\n                        found = False\n\n                        # Greedy Best Fit on subset\n                        for p in indices_list:\n                             if temp_counts[p] < groups_per_pack:\n                                 if temp_weights[p] < min_local_w:\n                                     min_local_w = temp_weights[p]\n                                     best_local_p = p\n                                     found = True\n\n                        if not found:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        old_max = max(pack_weights[p].item() for p in indices_list)\n                        new_max = max(temp_weights.values())\n\n                        old_ss = sum(pack_weights[p].item()**2 for p in indices_list)\n                        new_ss = sum(w**2 for w in temp_weights.values())\n\n                        # Accept if improves max load or variance\n                        if new_max < old_max - 1e-6 or (abs(new_max - old_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                            for p in indices_list:\n                                pack_assignment[p] = torch.tensor(temp_packs[p], dtype=torch.int64)\n                                pack_weights[p] = temp_weights[p]\n                            improved_lns = True\n\n            if not improved_swap and not improved_lns:\n                break\n\n        # Final write to output tensors\n        # pack_assignment contains expert indices in packed order\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n\n        best_max_load = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                # Deterministic LPT\n                indices = layer_w.argsort(descending=True).tolist()\n            else:\n                # Randomized LPT (Perturbed weights)\n                noise = torch.rand(num_groups) * 0.4 + 0.8  # 0.8 to 1.2\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_cnt = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w[g_idx].item()\n                # Best fit among non-full packs (min current load)\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_cnt[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_cnt[best_p] += 1\n\n            # 3. Refinement Phase 1: Vectorized 2-Opt (Swap)\n            for _ in range(10):\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                improved = False\n                for p_idx in range(min(3, num_packs)):\n                    max_p = sorted_packs[p_idx]\n                    max_w = pack_weights[max_p]\n                    best_swap = None\n                    best_gain = 0.0\n\n                    u_nodes = packs[max_p]\n                    w_u = layer_w[u_nodes]\n\n                    for p in range(num_packs):\n                        if p == max_p: continue\n                        if pack_weights[p] >= max_w: continue\n\n                        diff = max_w - pack_weights[p]\n                        if diff < 1e-6: continue\n\n                        v_nodes = packs[p]\n                        w_v = layer_w[v_nodes]\n\n                        deltas = w_u.unsqueeze(1) - w_v.unsqueeze(0)\n                        mask = (deltas > 1e-6) & (deltas < diff)\n                        if not mask.any(): continue\n\n                        gains = deltas * (diff - deltas)\n                        gains = torch.where(mask, gains, -1.0)\n                        curr_max_gain, curr_idx = gains.flatten().max(0)\n\n                        if curr_max_gain.item() > best_gain:\n                            best_gain = curr_max_gain.item()\n                            idx = curr_idx.item()\n                            u_idx = idx // len(v_nodes)\n                            v_idx = idx % len(v_nodes)\n                            best_swap = (max_p, p, u_idx, v_idx, deltas.flatten()[idx].item())\n\n                    if best_swap:\n                        p1, p2, u_i, v_i, delta = best_swap\n                        packs[p1][u_i], packs[p2][v_i] = packs[p2][v_i], packs[p1][u_i]\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        improved = True\n                        break\n                if not improved: break\n\n            # 4. Refinement Phase 2: Pairwise Rebalancing (Ruin & Recreate)\n            # Focus on reducing the gap between heaviest and lightest packs\n            for _ in range(15):\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n                if max_p == min_p: break\n\n                diff = pack_weights[max_p] - pack_weights[min_p]\n                if diff < 1e-6: break\n\n                items_pair = packs[max_p] + packs[min_p]\n                # Optimization: Extract weights once\n                w_pair = [(layer_w[idx].item(), idx) for idx in items_pair]\n                w_pair.sort(key=lambda x: x[0], reverse=True)\n\n                best_pair_res = None\n                best_pair_diff = diff\n\n                # Try Deterministic and Randomized Greedy on this pair\n                # 1 Deterministic + 5 Randomized\n                for attempt_pair in range(6):\n                    if attempt_pair > 0:\n                        # Perturb weights for randomization\n                        current_w_pair = [(w * (1.0 + torch.rand(1).item() * 0.1), w, idx) for w, idx in w_pair]\n                        current_w_pair.sort(key=lambda x: x[0], reverse=True)\n                        iter_items = [(w_real, idx) for _, w_real, idx in current_w_pair]\n                    else:\n                        iter_items = w_pair\n\n                    p1_new, p2_new = [], []\n                    w1_new, w2_new = 0.0, 0.0\n\n                    for w_val, idx in iter_items:\n                        if len(p1_new) < groups_per_pack and len(p2_new) < groups_per_pack:\n                            if w1_new < w2_new:\n                                p1_new.append(idx); w1_new += w_val\n                            else:\n                                p2_new.append(idx); w2_new += w_val\n                        elif len(p1_new) < groups_per_pack:\n                            p1_new.append(idx); w1_new += w_val\n                        else:\n                            p2_new.append(idx); w2_new += w_val\n\n                    curr_diff = abs(w1_new - w2_new)\n                    if curr_diff < best_pair_diff - 1e-6:\n                        best_pair_diff = curr_diff\n                        best_pair_res = (p1_new, p2_new, w1_new, w2_new)\n\n                if best_pair_res:\n                    p1_idx, p2_idx, w1_v, w2_v = best_pair_res\n                    packs[max_p] = p1_idx\n                    pack_weights[max_p] = w1_v\n                    packs[min_p] = p2_idx\n                    pack_weights[min_p] = w2_v\n                else:\n                    break\n\n            # 5. Evaluation\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Algorithm: Beam Search Initialization + Perturbed LPT Refinement + Ring Swaps\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # CPU for scalar logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    for i in range(num_layers):\n        w_tensor = weight_cpu[i]\n        w_list = w_tensor.tolist()\n\n        sorted_indices = sorted(range(num_groups), key=lambda x: w_list[x], reverse=True)\n\n        # --- Phase 1: Beam Search Initialization ---\n        BEAM_WIDTH = 4\n        BEAM_DEPTH = min(num_groups, 30)\n\n        # State: (score, loads_tuple, counts_tuple, path_tuple)\n        beam = [(0.0, tuple([0.0]*num_packs), tuple([0]*num_packs), ())]\n\n        for k in range(BEAM_DEPTH):\n            item_idx = sorted_indices[k]\n            w = w_list[item_idx]\n            new_beam = []\n\n            for score, loads, counts, path in beam:\n                seen_states = set()\n\n                for p in range(num_packs):\n                    if counts[p] < groups_per_pack:\n                        state_sig = (round(loads[p], 5), counts[p])\n                        if state_sig in seen_states: continue\n                        seen_states.add(state_sig)\n\n                        nl = list(loads)\n                        nl[p] += w\n                        nc = list(counts)\n                        nc[p] += 1\n\n                        # Incremental Score Update: min sum(load^2)\n                        delta_score = 2 * loads[p] * w + w * w\n\n                        new_beam.append((score + delta_score, tuple(nl), tuple(nc), path + (p,)))\n\n            if len(new_beam) > BEAM_WIDTH:\n                beam = heapq.nsmallest(BEAM_WIDTH, new_beam, key=lambda x: x[0])\n            else:\n                beam = new_beam\n\n        best_node = beam[0]\n        _, current_loads, current_counts, path = best_node\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = list(current_loads)\n        pack_counts = list(current_counts)\n        for k in range(BEAM_DEPTH):\n            packs[path[k]].append(sorted_indices[k])\n\n        # --- Phase 2: Greedy Finish ---\n        for k in range(BEAM_DEPTH, num_groups):\n            idx = sorted_indices[k]\n            w = w_list[idx]\n            best_p = -1\n            min_load = float('inf')\n            for p in range(num_packs):\n                if pack_counts[p] < groups_per_pack:\n                    if pack_weights[p] < min_load:\n                        min_load = pack_weights[p]\n                        best_p = p\n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n            pack_counts[best_p] += 1\n\n        # --- Phase 3: Iterative Refinement ---\n        MAX_REFINE_ITER = 20\n\n        for iter_ in range(MAX_REFINE_ITER):\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n            if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                break\n\n            improved = False\n\n            # Strategy A: Pairwise Optimization (Max-Min and Max-Random)\n            pairs = [(max_p, min_p)]\n            if num_packs > 2:\n                candidates = [p for p in range(num_packs) if p != max_p and p != min_p]\n                if candidates:\n                    pairs.append((max_p, random.choice(candidates)))\n\n            for p1, p2 in pairs:\n                items = packs[p1] + packs[p2]\n                best_sub_diff = abs(pack_weights[p1] - pack_weights[p2])\n                best_sub_assign = None\n\n                # 8 attempts: 1 deterministic LPT, 7 Perturbed LPT\n                # Perturbed LPT is superior to random shuffle for packing\n                for attempt in range(8):\n                    if attempt == 0:\n                        order = sorted(items, key=lambda x: w_list[x], reverse=True)\n                    else:\n                        # Perturb weights for sorting only\n                        noise = [random.uniform(0.9, 1.1) for _ in items]\n                        order = sorted(items, key=lambda x: w_list[x] * noise[items.index(x)], reverse=True)\n\n                    l1, l2 = 0.0, 0.0\n                    c1, c2 = 0, 0\n                    ass1, ass2 = [], []\n\n                    for item in order:\n                        w = w_list[item]\n                        # Greedy balance sums: put in lighter bin unless full\n                        if c1 < groups_per_pack and (c2 == groups_per_pack or l1 < l2):\n                            ass1.append(item)\n                            l1 += w\n                            c1 += 1\n                        else:\n                            ass2.append(item)\n                            l2 += w\n                            c2 += 1\n\n                    diff = abs(l1 - l2)\n                    if diff < best_sub_diff - 1e-6:\n                        best_sub_diff = diff\n                        best_sub_assign = (ass1, ass2, l1, l2)\n\n                if best_sub_assign:\n                    ass1, ass2, l1, l2 = best_sub_assign\n                    packs[p1] = ass1\n                    packs[p2] = ass2\n                    pack_weights[p1] = l1\n                    pack_weights[p2] = l2\n                    improved = True\n\n            if improved:\n                continue\n\n            # Strategy B: 3-Way Ring Swap (Max -> Mid -> Min -> Max)\n            if num_packs < 3: continue\n\n            mids = [p for p in range(num_packs) if p != max_p and p != min_p]\n            mids.sort(key=pack_weights.__getitem__) # Try lightest mids first\n\n            found_ring = False\n            for mid_p in mids[:2]: # Limit to 2 best candidates\n                # Filter candidates for speed\n                u_cands = sorted(packs[max_p], key=lambda x: w_list[x], reverse=True)\n                w_cands = sorted(packs[min_p], key=lambda x: w_list[x]) # Smallest w out of min? No, we want Min to gain.\n                # Actually, Min loses w, gains v. We want v > w.\n                # So we want w to be small, to easily find v > w.\n                v_cands = sorted(packs[mid_p], key=lambda x: w_list[x], reverse=True) # Big v to help Min most\n\n                limit_chk = 0\n                for u in u_cands:\n                    wu = w_list[u]\n                    for w in w_cands:\n                        ww = w_list[w]\n                        if wu <= ww: continue # Max must decrease\n\n                        gain_max = wu - ww\n\n                        # Need v in Mid s.t. Mid doesn't explode\n                        # Mid new = Mid + wu - wv < Max_old - gain_max (ideally)\n                        # wv > Mid + wu - (Max_old - gain_max)\n                        min_wv_req = pack_weights[mid_p] + wu - pack_weights[max_p] + 1e-6\n\n                        for v in v_cands:\n                            wv = w_list[v]\n                            if wv <= ww: break # Min must increase (v > w) - optional but efficient\n\n                            # Check system constraint\n                            # New loads\n                            n_max = pack_weights[max_p] - wu + ww\n                            n_mid = pack_weights[mid_p] + wu - wv\n                            n_min = pack_weights[min_p] + wv - ww\n\n                            sys_max = max(n_max, n_mid, n_min)\n\n                            if sys_max < pack_weights[max_p] - 1e-6:\n                                packs[max_p].remove(u); packs[max_p].append(w)\n                                packs[mid_p].remove(v); packs[mid_p].append(u)\n                                packs[min_p].remove(w); packs[min_p].append(v)\n                                pack_weights[max_p] = n_max\n                                pack_weights[mid_p] = n_mid\n                                pack_weights[min_p] = n_min\n                                found_ring = True\n                                break\n\n                        if found_ring: break\n                        limit_chk += 1\n                        if limit_chk > 40: break\n                    if found_ring: break\n                if found_ring: break\n\n        # Fill output tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # --- 1. Initialization (Randomized Greedy) ---\n        candidates = []\n        # Deterministic LPT\n        candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n\n        # Randomized LPT (Perturbed weights)\n        # Generate multiple candidates to improve diversity\n        for _ in range(4):\n            noise = torch.rand(num_groups) * 0.1 + 0.95  # +/- 5% noise\n            indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n            candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n                # Best fit among non-full packs\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        if current_pack_weights[p] < min_w:\n                            min_w = current_pack_weights[p]\n                            best_p = p\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            max_load = max(current_pack_weights)\n            ss = sum(x*x for x in current_pack_weights)\n\n            if max_load < min_max_load - 1e-6:\n                min_max_load = max_load\n                min_ss = ss\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n            elif abs(max_load - min_max_load) < 1e-6:\n                if ss < min_ss - 1e-6:\n                    min_ss = ss\n                    best_assignment = current_pack_contents\n                    best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # --- 2. Refinement Loop ---\n        MAX_OUTER_LOOPS = 5\n        \n        for _ in range(MAX_OUTER_LOOPS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            for _ in range(10):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment]\n\n                # Deltas: w_u - w_v. Shape [M, G, G] (via broadcasting)\n                # Gain function aims to balance the pair (max_pack, p)\n                diffs = (max_w - pack_weights).view(-1, 1, 1) # [M, 1, 1]\n                deltas = w_u.view(1, groups_per_pack, 1) - w_v.view(num_packs, 1, groups_per_pack) # [M, G, G]\n\n                # Mask: valid positive delta strictly less than diff (to avoid overshooting too much)\n                # Actually, strictly less than diff ensures w_p < old_max after swap.\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Repack max, min, and a random pack using multiple randomized attempts\n            for _ in range(5):\n                max_p = torch.argmax(pack_weights).item()\n                min_p = torch.argmin(pack_weights).item()\n\n                if max_p == min_p:\n                    break\n\n                lns_packs = [max_p, min_p]\n                if num_packs > 2:\n                    p3 = random.randint(0, num_packs - 1)\n                    while p3 in lns_packs:\n                        p3 = random.randint(0, num_packs - 1)\n                    lns_packs.append(p3)\n\n                # Collect items\n                items_flat = []\n                for p in lns_packs:\n                    items_flat.extend(pack_assignment[p].tolist())\n                \n                # Base sort LPT\n                sub_weights = [(layer_weights[x], x) for x in items_flat]\n                sub_weights.sort(key=lambda x: x[0], reverse=True)\n\n                current_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                current_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                best_sub_assign = None\n                best_sub_weights = None\n                found_lns_improvement = False\n\n                # 4 attempts: 1 deterministic, 3 randomized\n                for attempt in range(4):\n                    if attempt == 0:\n                        order = sub_weights\n                    else:\n                        # Perturb weights for sorting\n                        order = sorted([(w * random.uniform(0.9, 1.1), w, idx) for w, idx in sub_weights], key=lambda x: x[0], reverse=True)\n                        order = [(w, idx) for _, w, idx in order]\n\n                    temp_bins = [[] for _ in lns_packs]\n                    temp_ws = [0.0] * len(lns_packs)\n                    temp_cts = [0] * len(lns_packs)\n                    \n                    possible = True\n                    for w_val, idx in order:\n                        # Greedy Best Fit\n                        best_b = -1\n                        min_local_w = float('inf')\n                        for b in range(len(lns_packs)):\n                            if temp_cts[b] < groups_per_pack:\n                                if temp_ws[b] < min_local_w:\n                                    min_local_w = temp_ws[b]\n                                    best_b = b\n                        if best_b == -1:\n                            possible = False\n                            break\n                        temp_bins[best_b].append(idx)\n                        temp_ws[best_b] += w_val\n                        temp_cts[best_b] += 1\n                    \n                    if possible:\n                        new_max = max(temp_ws)\n                        new_ss = sum(x*x for x in temp_ws)\n\n                        if new_max < current_sub_max - 1e-6:\n                            current_sub_max = new_max\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n                        elif abs(new_max - current_sub_max) < 1e-6 and new_ss < current_sub_ss - 1e-6:\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n\n                if found_lns_improvement:\n                    for i_idx, p_idx in enumerate(lns_packs):\n                        pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                        pack_weights[p_idx] = best_sub_weights[i_idx]\n                    improved_any = True\n\n            if not improved_any:\n                break\n\n        # Final write to output tensors\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_sum_sq = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups) * 0.15 + 0.925\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT/Best Fit)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_counts = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                # Best Fit: Assign to valid pack with min load\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_counts[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_counts[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Identify heavy and light packs\n                # Optimization: Track max/min indices dynamically or just scan\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n                if max_p == min_p:\n                    break\n\n                # If balanced enough, try to optimize variance by picking random packs\n                # Otherwise, target max load reduction\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                     # Already balanced max-min, but maybe high variance?\n                     pass\n\n                candidates = {max_p, min_p}\n                # Add random packs for k-way swaps\n                if num_packs > 2:\n                    k_random = min(2, num_packs - 2)\n                    for _ in range(k_random):\n                        candidates.add(torch.randint(0, num_packs, (1,)).item())\n\n                cand_list = list(candidates)\n\n                # Ruin\n                items = []\n                for p in cand_list:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                best_sub_weights = [pack_weights[p] for p in cand_list]\n                best_sub_packs = [list(packs[p]) for p in cand_list]\n                best_sub_max = max(best_sub_weights)\n                best_sub_ss = sum(w*w for w in best_sub_weights)\n\n                improved_sub = False\n\n                # 0. Deterministic LPT attempt\n                # 1..N. Randomized LPT attempts\n\n                # Prepare LPT sort once\n                items_sorted = sorted(items, key=lambda x: layer_w_list[x], reverse=True)\n\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        # We use a list of tuples (perturbed_weight, index)\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n\n                if improved_sub:\n                    for idx, p in enumerate(cand_list):\n                        packs[p] = best_sub_packs[idx]\n                        pack_weights[p] = best_sub_weights[idx]\n                        pack_counts[p] = groups_per_pack # Should remain full\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w*w for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6 and current_ss < best_sum_sq - 1e-6:\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights for fast scalar access\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    import random\n    import heapq\n\n    def solve_beam(items_to_pack, w_map, pack_limit, num_bins, beam_width):\n        \"\"\"\n        Solve balanced packing for a subset of items using Beam Search.\n        items_to_pack: list of item indices\n        w_map: list of all weights (w_map[idx] is weight)\n        pack_limit: max items per bin\n        num_bins: number of bins\n        \"\"\"\n        # Sort LPT\n        items_sorted = sorted(items_to_pack, key=lambda x: w_map[x], reverse=True)\n\n        # State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n        # assignment_tuple: sequence of bin indices for items in items_sorted\n        initial_state = (0.0, 0.0, tuple([0.0]*num_bins), tuple([0]*num_bins), ())\n        beam = [initial_state]\n\n        for item_idx in items_sorted:\n            w = w_map[item_idx]\n            next_beam = []\n\n            for b_max, b_ss, loads, counts, assign in beam:\n                # Symmetry breaking:\n                # Identify bins by (load, count). Only try one bin for each unique (load, count) pair.\n                seen_signatures = set()\n\n                for p in range(num_bins):\n                    if counts[p] < pack_limit:\n                        # Round to avoid float precision issues in signature\n                        sig = (round(loads[p], 5), counts[p])\n                        if sig in seen_signatures:\n                            continue\n                        seen_signatures.add(sig)\n\n                        # Create new state\n                        new_loads = list(loads)\n                        new_loads[p] += w\n                        new_counts = list(counts)\n                        new_counts[p] += 1\n\n                        new_max = max(b_max, new_loads[p])\n                        # Incremental SS: old_ss - old_L^2 + new_L^2\n                        # new_L = old_L + w\n                        # delta = 2*old_L*w + w^2\n                        delta_ss = 2 * loads[p] * w + w * w\n                        new_ss = b_ss + delta_ss\n\n                        next_beam.append((new_max, new_ss, tuple(new_loads), tuple(new_counts), assign + (p,)))\n\n            # Select top K\n            # Primary sort: max_load, Secondary: sum_sq\n            if len(next_beam) > beam_width:\n                # partial sort using heapq.nsmallest is efficient\n                beam = heapq.nsmallest(beam_width, next_beam, key=lambda x: (x[0], x[1]))\n            else:\n                beam = next_beam\n\n        # Best state\n        best_state = beam[0]\n        # reconstruct\n        final_assign = best_state[4]\n        final_loads = best_state[2]\n\n        res_packs = [[] for _ in range(num_bins)]\n        for i, p in enumerate(final_assign):\n            res_packs[p].append(items_sorted[i])\n\n        return res_packs, list(final_loads)\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        # 1. Global Initialization with Beam Search\n        # If num_packs is very large, reduce width to keep it fast.\n        # But typically num_packs is small (<=8) in hierarchical steps.\n        # Even for 64, width=2 is better than greedy.\n        global_width = 4\n        all_items = list(range(num_groups))\n\n        packs, pack_weights = solve_beam(all_items, layer_w_list, groups_per_pack, num_packs, global_width)\n\n        # 2. Refinement: Ruin & Recreate (LNS)\n        # Use Beam Search on small subsets (2-3 packs)\n        LNS_STEPS = 20 if num_packs > 1 else 0\n\n        for step in range(LNS_STEPS):\n            # Identify max and min packs\n            max_p = -1\n            min_p = -1\n            max_w = -1.0\n            min_w = float('inf')\n\n            for p_idx, pw in enumerate(pack_weights):\n                if pw > max_w:\n                    max_w = pw\n                    max_p = p_idx\n                if pw < min_w:\n                    min_w = pw\n                    min_p = p_idx\n\n            if max_p == min_p or (max_w - min_w < 1e-6):\n                break\n\n            # Candidates: Max, Min, and maybe random\n            candidates = [max_p, min_p]\n            if num_packs > 2:\n                # Add 1 random pack\n                rand_p = random.randint(0, num_packs - 1)\n                while rand_p in candidates:\n                    rand_p = random.randint(0, num_packs - 1)\n                candidates.append(rand_p)\n\n            # Pool items\n            sub_items = []\n            for p in candidates:\n                sub_items.extend(packs[p])\n\n            # Solve sub-problem with Higher Width Beam Search\n            # K=2 or 3 is small, so we can afford width=8 or more\n            sub_packs, sub_weights = solve_beam(sub_items, layer_w_list, groups_per_pack, len(candidates), beam_width=12)\n\n            # Check improvement\n            current_sub_max = max(pack_weights[p] for p in candidates)\n            current_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n\n            new_sub_max = max(sub_weights)\n            new_sub_ss = sum(w**2 for w in sub_weights)\n\n            if new_sub_max < current_sub_max - 1e-6 or \\\n               (abs(new_sub_max - current_sub_max) < 1e-6 and new_sub_ss < current_sub_ss - 1e-6):\n                # Apply update\n                for local_idx, p in enumerate(candidates):\n                    packs[p] = sub_packs[local_idx]\n                    pack_weights[p] = sub_weights[local_idx]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(packs):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\ngreedy_lns_beam\n</NAME>\n\n<DESCRIPTION>\nThis algorithm combines a Multi-Start Randomized Greedy initialization with a Large Neighborhood Search (LNS) refinement step powered by Beam Search.\n1. Initialization: Runs Randomized LPT (Longest Processing Time) greedy multiple times with weight perturbations to find a good initial load distribution.\n2. Refinement: Iteratively selects the heaviest, lightest, and a random pack (3-way) to re-optimize.\n3. Sub-problem Solver: Uses a localized Beam Search with symmetry breaking to optimally redistribute items within the selected subset of packs, effectively performing complex multi-item swaps (generalized 3-way exchanges) to minimize max load and variance.\nThis approach leverages the speed of greedy for global structure and the precision of beam search for local refinement, overcoming local optima that block simple swap heuristics.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Algorithm: Randomized Greedy Initialization + Local Beam Search Refinement\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case: 1 group per pack (1-to-1 mapping)\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(num_layers, num_groups)\n        rank_in_pack = torch.zeros((num_layers, num_groups), dtype=torch.int64, device=device)\n        return pack_index, rank_in_pack\n\n    # Work on CPU for efficiency with scalar logic\n    weight_cpu = weight.cpu()\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Helper: Beam Search Solver for a subset of items/packs\n    def solve_subset_beam(items, w_map, capacity, k_packs, width=32):\n        \"\"\"\n        Optimally pack 'items' into 'k_packs' each with 'capacity' using Beam Search.\n        \"\"\"\n        # Sort items Descending (LPT)\n        items_sorted = sorted(items, key=lambda x: w_map[x], reverse=True)\n        \n        # Beam State: (max_load, sum_sq, loads_tuple, counts_tuple, assignment_tuple)\n        # We start with empty packs.\n        start_node = (0.0, 0.0, tuple([0.0]*k_packs), tuple([0]*k_packs), ())\n        beam = [start_node]\n        \n        for item_idx in items_sorted:\n            w = w_map[item_idx]\n            next_beam = []\n            \n            for b_max, b_ss, loads, counts, assign in beam:\n                # Symmetry breaking: Bins with same (load, count) are equivalent.\n                # Only try to put item in one of the equivalent bins.\n                seen_signatures = set()\n                \n                for p in range(k_packs):\n                    if counts[p] < capacity:\n                        # Signature for symmetry breaking\n                        sig = (round(loads[p], 5), counts[p])\n                        if sig in seen_signatures:\n                            continue\n                        seen_signatures.add(sig)\n                        \n                        # Create new state\n                        nl = list(loads)\n                        nl[p] += w\n                        nc = list(counts)\n                        nc[p] += 1\n                        \n                        # Update metrics\n                        # Delta Sum Squares = (L+w)^2 - L^2 = 2Lw + w^2\n                        delta_ss = 2 * loads[p] * w + w * w\n                        new_ss = b_ss + delta_ss\n                        new_max = b_max if b_max > nl[p] else nl[p]\n                        \n                        next_beam.append((new_max, new_ss, tuple(nl), tuple(nc), assign + (p,)))\n            \n            # Prune beam\n            if len(next_beam) > width:\n                # Primary key: Max Load, Secondary: Sum Squares\n                beam = heapq.nsmallest(width, next_beam, key=lambda x: (x[0], x[1]))\n            else:\n                beam = next_beam\n        \n        # Best solution found\n        best = beam[0]\n        assign_indices = best[4]\n        final_weights = best[2]\n        \n        # Reconstruct packs\n        res_packs = [[] for _ in range(k_packs)]\n        for i, p in enumerate(assign_indices):\n            res_packs[p].append(items_sorted[i])\n            \n        return res_packs, list(final_weights)\n\n    # Main Loop over Layers\n    for i in range(num_layers):\n        layer_w_tensor = weight_cpu[i]\n        layer_w_list = layer_w_tensor.tolist()\n        \n        # --- 1. Initialization: Randomized Greedy ---\n        best_assignment = None\n        best_pack_weights = None\n        best_global_max = float('inf')\n        best_global_ss = float('inf')\n        \n        # Number of restarts\n        NUM_RESTARTS = 10\n        base_indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n        \n        for attempt in range(NUM_RESTARTS):\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to change sort order (Perturbed LPT)\n                # Noise range [0.9, 1.1]\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x] * noise[x], reverse=True)\n            \n            curr_packs = [[] for _ in range(num_packs)]\n            curr_weights = [0.0] * num_packs\n            curr_counts = [0] * num_packs\n            \n            # Greedy Fill (Best Fit)\n            for idx in indices:\n                w = layer_w_list[idx]\n                best_p = -1\n                min_load = float('inf')\n                \n                for p in range(num_packs):\n                    if curr_counts[p] < groups_per_pack:\n                        if curr_weights[p] < min_load:\n                            min_load = curr_weights[p]\n                            best_p = p\n                \n                curr_packs[best_p].append(idx)\n                curr_weights[best_p] += w\n                curr_counts[best_p] += 1\n            \n            # Check Metrics\n            c_max = max(curr_weights)\n            c_ss = sum(x*x for x in curr_weights)\n            \n            if c_max < best_global_max - 1e-6:\n                best_global_max = c_max\n                best_global_ss = c_ss\n                best_assignment = curr_packs\n                best_pack_weights = curr_weights\n            elif abs(c_max - best_global_max) < 1e-6 and c_ss < best_global_ss - 1e-6:\n                best_global_ss = c_ss\n                best_assignment = curr_packs\n                best_pack_weights = curr_weights\n        \n        packs = best_assignment\n        pack_weights = best_pack_weights\n        \n        # --- 2. Refinement: LNS with Beam Search ---\n        # Focus on Max and Min packs to reduce spread\n        MAX_LNS_STEPS = 50\n        consecutive_fail = 0\n        limit_fail = 8\n        \n        for step in range(MAX_LNS_STEPS):\n            # Identify extremes\n            max_p = -1; max_val = -1.0\n            min_p = -1; min_val = float('inf')\n            \n            for p in range(num_packs):\n                val = pack_weights[p]\n                if val > max_val: max_val = val; max_p = p\n                if val < min_val: min_val = val; min_p = p\n            \n            if max_val - min_val < 1e-6:\n                break\n                \n            # Select subset of packs to optimize\n            candidates = [max_p, min_p]\n            if num_packs > 2:\n                # Add a random third pack to allow 3-way exchanges\n                # Avoid max_p and min_p\n                r = random.randint(0, num_packs - 1)\n                while r == max_p or r == min_p:\n                    r = random.randint(0, num_packs - 1)\n                candidates.append(r)\n            \n            # Collect items from candidates\n            sub_items = []\n            for p in candidates:\n                sub_items.extend(packs[p])\n            \n            # Solve subset optimally(ish) with Beam Search\n            # Beam width 32 is sufficient for small subset (2 or 3 packs)\n            new_sub_packs, new_sub_weights = solve_subset_beam(\n                sub_items, layer_w_list, groups_per_pack, len(candidates), width=32\n            )\n            \n            # Check for improvement\n            old_sub_max = max(pack_weights[p] for p in candidates)\n            old_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n            \n            new_sub_max = max(new_sub_weights)\n            new_sub_ss = sum(x*x for x in new_sub_weights)\n            \n            improved = False\n            # Accept if Max load reduces OR Max load stays same but Variance (Sum Sq) reduces\n            if new_sub_max < old_sub_max - 1e-6:\n                improved = True\n            elif abs(new_sub_max - old_sub_max) < 1e-6 and new_sub_ss < old_sub_ss - 1e-6:\n                improved = True\n            \n            if improved:\n                for local_idx, p in enumerate(candidates):\n                    packs[p] = new_sub_packs[local_idx]\n                    pack_weights[p] = new_sub_weights[local_idx]\n                consecutive_fail = 0\n            else:\n                consecutive_fail += 1\n                if consecutive_fail >= limit_fail:\n                    break\n\n        # --- 3. Output ---\n        for p in range(num_packs):\n            for r, g_idx in enumerate(packs[p]):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 34255,
          "output_tokens": 16058,
          "cost": 0.261206,
          "input_cost": 0.06851,
          "output_cost": 0.192696,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 50,
          "deleted": 0,
          "modified": 125
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 7.72e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_93/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_93/results\nRun 1/5 completed in 5.42 seconds\nRun 2/5 completed in 11.31 seconds\nRun 3/5 completed in 12.32 seconds\nRun 4/5 completed in 11.89 seconds\nRun 5/5 completed in 12.00 seconds\nbalancedness: 0.2107368506889166\nbalancedness: 0.3397761404567239\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_93/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_93/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385886499905\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.3110771772999811, 'speed_score': 1.0}\n  execution_time_mean: 10.588297158600472\n  execution_time_std: 2.6038603004384404\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 47,
          "average_cyclomatic_complexity": 9.4,
          "halstead_volume": 2228.7820740496054,
          "halstead_difficulty": 12.35655737704918,
          "halstead_effort": 27540.073578932625,
          "lines_of_code": 428,
          "logical_lines_of_code": 217,
          "comments": 46,
          "maintainability_index": -39.256372369837266,
          "max_nesting_depth": 7,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "9294c033-5700-4ded-9ee0-128d1051be42",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 3\n    max_refine_steps = 25\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max pack\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                max_val = pack_weights[max_p]\n\n                min_val = min(pack_weights)\n                if max_val - min_val < 1e-6:\n                    break\n\n                best_move = None\n                best_move_improvement = -1.0\n\n                candidate_packs = [p for p in range(num_packs) if p != max_p]\n                # Sort candidates by weight: testing lightest first often helps move most weight\n                candidate_packs.sort(key=pack_weights.__getitem__)\n\n                for other_p in candidate_packs:\n                    other_val = pack_weights[other_p]\n\n                    # Target is average of the pair\n                    avg = (max_val + other_val) / 2.0\n                    potential_reduction = max_val - avg\n\n                    if potential_reduction < best_move_improvement + 1e-6:\n                        continue\n\n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n\n                    K = groups_per_pack\n                    pool_len = 2 * K\n\n                    best_local_set_A = None\n                    best_local_max = float('inf')\n\n                    # EXACT SOLVER for small K\n                    if pool_len <= 14:\n                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n                         indices_rest = list(range(1, pool_len))\n                         w_0 = pool_weights[0]\n\n                         for comb in itertools.combinations(indices_rest, K - 1):\n                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n                             other_w = (max_val + other_val) - current_w\n                             local_max = max(current_w, other_w)\n\n                             if local_max < best_local_max:\n                                 best_local_max = local_max\n                                 best_local_set_A = [0] + list(comb)\n                                 if abs(local_max - avg) < 1e-5:\n                                     break\n                    else:\n                        # Heuristic Solver\n                        pool_indices = list(range(pool_len))\n                        sub_trials = 10\n                        for sub in range(sub_trials):\n                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n\n                            w1, w2 = 0.0, 0.0\n                            c1, c2 = 0, 0\n                            s1, s2 = [], []\n\n                            for idx in sorted_idx:\n                                w = pool_weights[idx]\n                                if c1 < K and c2 < K:\n                                    if w1 <= w2:\n                                        w1 += w; c1 += 1; s1.append(idx)\n                                    else:\n                                        w2 += w; c2 += 1; s2.append(idx)\n                                elif c1 < K:\n                                    w1 += w; c1 += 1; s1.append(idx)\n                                else:\n                                    w2 += w; c2 += 1; s2.append(idx)\n\n                            # Swap Local Search\n                            while True:\n                                improved_swap = False\n                                current_max = max(w1, w2)\n                                for i1, idx1 in enumerate(s1):\n                                    for i2, idx2 in enumerate(s2):\n                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n                                        nmax = max(nw1, nw2)\n                                        if nmax < current_max - 1e-6:\n                                            w1, w2 = nw1, nw2\n                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n                                            current_max = nmax\n                                            improved_swap = True\n                                            break\n                                    if improved_swap: break\n                                if not improved_swap: break\n\n                            if max(w1, w2) < best_local_max:\n                                best_local_max = max(w1, w2)\n                                best_local_set_A = list(s1)\n\n                    # Check improvement\n                    improvement = max_val - best_local_max\n                    if improvement > best_move_improvement + 1e-6:\n                        best_move_improvement = improvement\n                        set_A_indices = best_local_set_A\n                        set_A_set = set(set_A_indices)\n                        new_items_A = [pool[x] for x in set_A_indices]\n                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n                        # Calculate exact new weights to avoid drift\n                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n\n                        if abs(best_local_max - avg) < 1e-5:\n                             break\n\n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    break\n\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "b96cb298-f1bc-4791-bc63-23f021d2c874",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "40ddb5c3-bbab-4055-9f26-032434ba5de4"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 94,
      "timestamp": 1764181075.4222312,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,460 +1,370 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n import random\n import itertools\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     # Handle trivial case\n     if groups_per_pack == 1:\n         pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n                                   device=weight.device).expand(num_layers, -1)\n         rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n     # CPU processing for complex sequential logic\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n \n     # Heuristic parameters\n-    num_restarts = 2\n-    max_refine_steps = 20\n+    num_restarts = 3\n+    max_refine_steps = 25\n \n     for i in range(num_layers):\n         row_weight = weight_cpu[i]\n         row_weight_list = row_weight.tolist()\n \n         best_diff = float('inf')\n         best_packs = None\n \n         # Base indices for deterministic LPT\n         base_indices = torch.argsort(row_weight, descending=True).tolist()\n \n         for attempt in range(num_restarts):\n             # 1. Initialization\n             if attempt == 0:\n                 indices = base_indices\n             else:\n-                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n+                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                 indices = torch.argsort(row_weight * noise, descending=True).tolist()\n \n             current_packs = [[] for _ in range(num_packs)]\n             pack_weights = [0.0] * num_packs\n \n             # Greedy Packing\n             for group_idx in indices:\n                 w = row_weight_list[group_idx]\n                 best_p = -1\n                 min_val = float('inf')\n                 for p in range(num_packs):\n                     if len(current_packs[p]) < groups_per_pack:\n                         if pack_weights[p] < min_val:\n                             min_val = pack_weights[p]\n                             best_p = p\n                 current_packs[best_p].append(group_idx)\n                 pack_weights[best_p] += w\n \n             # 2. Refinement Phase\n             for step in range(max_refine_steps):\n-                # Identify max and min packs\n-                min_p = 0\n-                max_p = 0\n-                min_val = pack_weights[0]\n-                max_val = pack_weights[0]\n-\n-                # Random perturbation occasionally\n-                if step > 0 and step % 6 == 0:\n-                    p1 = random.randint(0, num_packs - 1)\n-                    p2 = random.randint(0, num_packs - 2)\n-                    if p2 >= p1: p2 += 1\n-                    max_p, min_p = p1, p2\n-                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n+                # Identify max pack\n+                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n+                max_val = pack_weights[max_p]\n+\n+                min_val = min(pack_weights)\n+                if max_val - min_val < 1e-6:\n+                    break\n+\n+                best_move = None\n+                best_move_improvement = -1.0\n+\n+                candidate_packs = [p for p in range(num_packs) if p != max_p]\n+                # Sort candidates by weight: testing lightest first often helps move most weight\n+                candidate_packs.sort(key=pack_weights.__getitem__)\n+\n+                for other_p in candidate_packs:\n+                    other_val = pack_weights[other_p]\n+\n+                    # Target is average of the pair\n+                    avg = (max_val + other_val) / 2.0\n+                    potential_reduction = max_val - avg\n+\n+                    if potential_reduction < best_move_improvement + 1e-6:\n+                        continue\n+\n+                    pool = current_packs[max_p] + current_packs[other_p]\n+                    pool_weights = [row_weight_list[x] for x in pool]\n+\n+                    K = groups_per_pack\n+                    pool_len = 2 * K\n+\n+                    best_local_set_A = None\n+                    best_local_max = float('inf')\n+\n+                    # EXACT SOLVER for small K\n+                    if pool_len <= 14:\n+                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n+                         indices_rest = list(range(1, pool_len))\n+                         w_0 = pool_weights[0]\n+\n+                         for comb in itertools.combinations(indices_rest, K - 1):\n+                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n+                             other_w = (max_val + other_val) - current_w\n+                             local_max = max(current_w, other_w)\n+\n+                             if local_max < best_local_max:\n+                                 best_local_max = local_max\n+                                 best_local_set_A = [0] + list(comb)\n+                                 if abs(local_max - avg) < 1e-5:\n+                                     break\n+                    else:\n+                        # Heuristic Solver\n+                        pool_indices = list(range(pool_len))\n+                        sub_trials = 10\n+                        for sub in range(sub_trials):\n+                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n+                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n+\n+                            w1, w2 = 0.0, 0.0\n+                            c1, c2 = 0, 0\n+                            s1, s2 = [], []\n+\n+                            for idx in sorted_idx:\n+                                w = pool_weights[idx]\n+                                if c1 < K and c2 < K:\n+                                    if w1 <= w2:\n+                                        w1 += w; c1 += 1; s1.append(idx)\n+                                    else:\n+                                        w2 += w; c2 += 1; s2.append(idx)\n+                                elif c1 < K:\n+                                    w1 += w; c1 += 1; s1.append(idx)\n+                                else:\n+                                    w2 += w; c2 += 1; s2.append(idx)\n+\n+                            # Swap Local Search\n+                            while True:\n+                                improved_swap = False\n+                                current_max = max(w1, w2)\n+                                for i1, idx1 in enumerate(s1):\n+                                    for i2, idx2 in enumerate(s2):\n+                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n+                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n+                                        nmax = max(nw1, nw2)\n+                                        if nmax < current_max - 1e-6:\n+                                            w1, w2 = nw1, nw2\n+                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n+                                            current_max = nmax\n+                                            improved_swap = True\n+                                            break\n+                                    if improved_swap: break\n+                                if not improved_swap: break\n+\n+                            if max(w1, w2) < best_local_max:\n+                                best_local_max = max(w1, w2)\n+                                best_local_set_A = list(s1)\n+\n+                    # Check improvement\n+                    improvement = max_val - best_local_max\n+                    if improvement > best_move_improvement + 1e-6:\n+                        best_move_improvement = improvement\n+                        set_A_indices = best_local_set_A\n+                        set_A_set = set(set_A_indices)\n+                        new_items_A = [pool[x] for x in set_A_indices]\n+                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n+                        # Calculate exact new weights to avoid drift\n+                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n+                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n+                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n+\n+                        if abs(best_local_max - avg) < 1e-5:\n+                             break\n+\n+                if best_move:\n+                    other_p, items_A, items_B, w_A, w_B = best_move\n+                    current_packs[max_p] = items_A\n+                    current_packs[other_p] = items_B\n+                    pack_weights[max_p] = w_A\n+                    pack_weights[other_p] = w_B\n                 else:\n-                    for p in range(1, num_packs):\n-                        val = pack_weights[p]\n-                        if val < min_val:\n-                            min_val = val\n-                            min_p = p\n-                        elif val > max_val:\n-                            max_val = val\n-                            max_p = p\n-\n-                diff = max_val - min_val\n-                if diff < 1e-6:\n-                    if step % 6 != 0: break\n-                    else: continue\n-\n-                # Try 2-Pack Rebalancing\n-                pool = current_packs[max_p] + current_packs[min_p]\n-                pool_weights = [row_weight_list[x] for x in pool]\n-                total_pool = sum(pool_weights)\n-                target_half = total_pool / 2.0\n-                K = groups_per_pack\n-                pool_len = 2 * K\n-\n-                improved = False\n-                best_dev = abs(pack_weights[max_p] - target_half)\n-                best_assignment = None\n-\n-                # EXACT SOLVER for small K\n-                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n-                if pool_len <= 14:\n-                    # Fix first element to be in Set A to reduce symmetry\n-                    indices_rest = list(range(1, pool_len))\n-                    w_0 = pool_weights[0]\n-\n-                    for comb in itertools.combinations(indices_rest, K - 1):\n-                        s = w_0\n-                        for idx in comb:\n-                            s += pool_weights[idx]\n-                        dev = abs(s - target_half)\n-                        if dev < best_dev - 1e-6:\n-                            best_dev = dev\n-                            best_assignment = (0,) + comb\n-                            if dev < 1e-6: break\n-                else:\n-                    # Heuristic Solver with Local Search\n-                    pool_indices = list(range(pool_len))\n-                    sub_trials = 15\n-                    for sub in range(sub_trials):\n-                        # 1. Randomized Greedy Construction\n-                        if sub == 0:\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n-                        else:\n-                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n-\n-                        w_A, w_B = 0.0, 0.0\n-                        cnt_A, cnt_B = 0, 0\n-                        set_A_local = []\n-                        set_B_local = []\n-\n-                        for idx in sorted_idx:\n-                            w = pool_weights[idx]\n-                            if cnt_A < K and cnt_B < K:\n-                                if w_A <= w_B:\n-                                    w_A += w\n-                                    cnt_A += 1\n-                                    set_A_local.append(idx)\n-                                else:\n-                                    w_B += w\n-                                    cnt_B += 1\n-                                    set_B_local.append(idx)\n-                            elif cnt_A < K:\n-                                w_A += w\n-                                cnt_A += 1\n-                                set_A_local.append(idx)\n-                            else:\n-                                w_B += w\n-                                cnt_B += 1\n-                                set_B_local.append(idx)\n-\n-                        # 2. Local Search (Swap)\n-                        # Iteratively improve the partition by swapping pairs\n-                        curr_diff = w_A - w_B\n-\n-                        while True:\n-                            # We want to reduce |curr_diff|.\n-                            # Swap a (from A) and b (from B).\n-                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n-                            #          = w_A - w_B - 2*wa + 2*wb\n-                            #          = curr_diff - 2*(wa - wb)\n-\n-                            if abs(curr_diff) < 1e-6: break\n-\n-                            best_swap_gain = 0.0\n-                            best_pair = None\n-\n-                            # O(K^2) scan\n-                            for i_a, idx_a in enumerate(set_A_local):\n-                                wa = pool_weights[idx_a]\n-                                for i_b, idx_b in enumerate(set_B_local):\n-                                    wb = pool_weights[idx_b]\n-\n-                                    change = 2.0 * (wa - wb)\n-                                    new_diff = curr_diff - change\n-\n-                                    # gain = reduction in absolute difference\n-                                    gain = abs(curr_diff) - abs(new_diff)\n-\n-                                    if gain > best_swap_gain + 1e-6:\n-                                        best_swap_gain = gain\n-                                        best_pair = (i_a, i_b, change, new_diff)\n-\n-                            if best_pair:\n-                                i_a, i_b, change, new_diff = best_pair\n-                                # Apply swap\n-                                val_a = set_A_local[i_a]\n-                                val_b = set_B_local[i_b]\n-                                set_A_local[i_a] = val_b\n-                                set_B_local[i_b] = val_a\n-\n-                                curr_diff = new_diff\n-                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n-                            else:\n-                                break\n-\n-                        dev = abs(w_A - target_half)\n-                        if dev < best_dev - 1e-6:\n-                            best_dev = dev\n-                            best_assignment = list(set_A_local)\n-                            if dev < 1e-6: break\n-\n-                if best_assignment is not None:\n-                    set_A_indices = set(best_assignment)\n-                    new_max = [pool[i] for i in best_assignment]\n-                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n-                    current_packs[max_p] = new_max\n-                    current_packs[min_p] = new_min\n-                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n-                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n-                    improved = True\n-\n-                # 3-Way Rebalancing Fallback\n-                if not improved and num_packs >= 3:\n-                     # Pick random 3rd pack\n-                     while True:\n-                         mid_p = random.randint(0, num_packs - 1)\n-                         if mid_p != max_p and mid_p != min_p: break\n-\n-                     packs_3 = [max_p, min_p, mid_p]\n-                     pool_3 = []\n-                     for p in packs_3:\n-                         pool_3.extend(current_packs[p])\n-\n-                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n-                     total_3 = sum(pool_3_weights)\n-\n-                     # Check if we can improve deviation of these 3 packs\n-                     current_loads = [pack_weights[p] for p in packs_3]\n-                     best_spread_3 = max(current_loads) - min(current_loads)\n-\n-                     pool_3_indices = list(range(3 * K))\n-                     best_assignment_3 = None\n-\n-                     for sub in range(20):\n-                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n-                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n-\n-                         bins = [0.0] * 3\n-                         counts = [0] * 3\n-                         assignment = [[] for _ in range(3)]\n-\n-                         for idx in sorted_idx:\n-                             w = pool_3_weights[idx]\n-                             # Assign to valid bin with min load\n-                             best_b = -1\n-                             min_b_val = float('inf')\n-                             for b in range(3):\n-                                 if counts[b] < K:\n-                                     if bins[b] < min_b_val:\n-                                         min_b_val = bins[b]\n-                                         best_b = b\n-                             bins[best_b] += w\n-                             counts[best_b] += 1\n-                             assignment[best_b].append(idx)\n-\n-                         spread = max(bins) - min(bins)\n-                         if spread < best_spread_3 - 1e-6:\n-                             best_spread_3 = spread\n-                             best_assignment_3 = assignment\n-\n-                     if best_assignment_3 is not None:\n-                         for b_idx, p_idx in enumerate(packs_3):\n-                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n-                             current_packs[p_idx] = new_items\n-                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n-\n-            # Check result\n+                    break\n+\n             current_diff = max(pack_weights) - min(pack_weights)\n             if current_diff < best_diff:\n                 best_diff = current_diff\n                 best_packs = [list(p) for p in current_packs]\n                 if best_diff < 1e-6:\n                     break\n \n-        # Fill tensors\n         for p in range(num_packs):\n             for r, g in enumerate(best_packs[p]):\n                 pack_index[i, g] = p\n                 rank_in_pack[i, g] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n \n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n \n     # Efficient incremental update of scores\n     current_scores = weight.clone() # weight / 1\n \n     for i in range(num_log, num_phy):\n         # Pick expert with max current load\n         redundant_indices = current_scores.max(dim=-1).indices\n \n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n \n         logcnt[arangen, redundant_indices] += 1\n \n         # Update score: weight / new_count\n         selected_weights = weight[arangen, redundant_indices]\n         selected_counts = logcnt[arangen, redundant_indices].float()\n         current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n \n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Hierarchical rebalancing strategy.\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.655538593116922,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.31107718623384406,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.05996707,
        0.000977724,
        0.030078346,
        -0.04434719,
        -0.025408972,
        0.01520509,
        -0.024247555,
        0.0049389875,
        -0.014908809,
        0.039464496,
        0.024034234,
        0.015714692,
        -0.009664654,
        -0.01994557,
        0.01659168,
        0.013948862,
        -0.006885547,
        0.015572477,
        -0.024769008,
        0.049917255,
        -0.0077566104,
        -0.0032679683,
        0.03408405,
        -0.026902225,
        -0.0040086685,
        -0.002844288,
        0.053188186,
        -0.029011738,
        0.016899811,
        -0.0582605,
        0.08746186,
        -0.0087758135,
        -0.000192582,
        0.0075906934,
        -0.023619441,
        0.033135954,
        -0.0071462737,
        0.02519565,
        0.021995828,
        0.055274,
        0.033444088,
        -0.033823326,
        -0.05489476,
        0.042427298,
        -0.042474702,
        0.013297047,
        0.0031287167,
        -0.011471962,
        0.06745703,
        0.0087758135,
        0.049822446,
        0.011471962,
        -0.0072055296,
        0.058023475,
        0.017243495,
        0.03436848,
        0.023619441,
        0.021106988,
        0.023572037,
        -0.021355862,
        0.037757922,
        -0.012822999,
        0.06527641,
        0.0384927,
        -0.041929547,
        -0.00039516346,
        -0.024342366,
        0.01917524,
        0.013048171,
        -0.019625587,
        -0.06314319,
        0.032614503,
        -0.0066248206,
        -0.042498402,
        0.0018695268,
        0.0017510148,
        -0.006565565,
        0.03960671,
        -0.020194445,
        -0.026973331,
        -0.027044438,
        -0.021509929,
        0.056222092,
        0.019815207,
        0.008621748,
        -0.07684318,
        -0.031192359,
        -0.029983535,
        -0.024484579,
        -0.042901345,
        0.02815845,
        -0.03643059,
        0.0004540491,
        0.044726428,
        0.04434719,
        -0.04228508,
        0.05266673,
        0.013913309,
        0.052998565,
        0.058118284,
        -0.017397562,
        0.007300339,
        -0.03695204,
        0.010192032,
        0.024223853,
        0.0008081037,
        -0.007270711,
        0.0068381424,
        0.009972785,
        -0.01283485,
        -0.046053763,
        0.02775551,
        0.02212619,
        -0.0043582786,
        0.022623941,
        -0.0059226374,
        -0.018404914,
        -0.0012784482,
        -0.005321189,
        -0.026594093,
        -0.031026442,
        -0.03199824,
        0.016662788,
        -0.04088664,
        -0.0019065618,
        -0.038066056,
        0.014814,
        -0.040531103,
        -0.017148687,
        -0.0017539776,
        0.042688023,
        0.027897725,
        -0.010547568,
        -0.02526676,
        -0.016970918,
        0.005424887,
        -0.042024355,
        0.001755459,
        -0.012597825,
        -0.025432676,
        -0.031192359,
        0.028561393,
        -0.025503783,
        -0.027115546,
        -0.045105666,
        0.04624338,
        0.0070929434,
        0.008971359,
        -0.03486623,
        0.03446329,
        0.009160978,
        -0.035387684,
        -0.021687696,
        -0.012668933,
        0.009919454,
        -0.014920661,
        -0.021355862,
        0.008378798,
        0.062526934,
        -0.030979037,
        -7.898871e-07,
        0.014873256,
        -0.008562492,
        0.0073299673,
        0.046670027,
        0.01650872,
        -0.042024355,
        0.012325248,
        -0.06300098,
        -0.05598507,
        0.007448479,
        -0.022458024,
        -0.0025287499,
        -0.0111164255,
        0.019981124,
        0.008805442,
        -0.030789418,
        -0.048826944,
        -0.022078786,
        -0.045698225,
        -0.025290461,
        -0.014920661,
        -0.009018763,
        -0.011442333,
        -0.06636672,
        0.03417886,
        -0.0335863,
        -0.017930865,
        -0.025006032,
        0.0034635132,
        0.009700207,
        0.04008076,
        -0.038066056,
        0.036857232,
        0.0066248206,
        -0.0043316134,
        0.045010857,
        0.032140456,
        -0.008704706,
        -0.009083944,
        -0.037426088,
        -0.0076677264,
        0.043778334,
        -0.030504989,
        0.036999445,
        0.038824532,
        -0.017871609,
        0.015039173,
        0.016247995,
        -0.015181387,
        0.036288373,
        -0.03140568,
        0.04659892,
        -0.0035316576,
        -0.032069348,
        -0.01451772,
        -0.03408405,
        0.016899811,
        -0.008449906,
        0.07523142,
        -0.012420057,
        0.015193239,
        -0.028395476,
        0.011495664,
        -0.011317896,
        0.013297047,
        0.040839236,
        -0.023560185,
        0.0094454065,
        0.006772961,
        -0.029959833,
        -0.018902663,
        -0.0034724015,
        -0.02045517,
        0.036288373,
        -0.041052558,
        -0.047760338,
        0.015856905,
        0.008135849,
        -0.04197695,
        0.035292875,
        0.040365186,
        0.012894106,
        -0.062574334,
        0.016959067,
        0.011762316,
        -0.03645429,
        -0.005261933,
        -0.0017510148,
        -0.010097222,
        0.008361022,
        -0.044963453,
        0.009166903,
        -0.045081966,
        -0.020467022,
        0.02300318,
        -0.0023302422,
        -0.05266673,
        -0.021901017,
        -0.043114666,
        0.005587841,
        -0.025006032,
        -0.0052174907,
        -0.0074721817,
        -0.014885107,
        -0.004177548,
        -0.0015051024,
        0.0074188514,
        -0.041905843,
        -0.0036057276,
        0.019293753,
        0.0063937223,
        -0.0067611095,
        0.01323779,
        -0.022375066,
        -0.02102403,
        0.01896192,
        -0.016413912,
        -0.036122456,
        -0.044299785,
        -0.021545481,
        -0.00029090993,
        0.029817618,
        -0.0047138147,
        0.022943923,
        -0.0096053975,
        -0.001429551,
        0.014067374,
        0.010565345,
        -0.0066485233,
        -0.01659168,
        -0.029272463,
        0.032353777,
        -0.0059315255,
        0.013605177,
        -0.013415558,
        -0.052097876,
        -0.010986063,
        0.008769888,
        -0.008195105,
        0.014778446,
        0.01022166,
        -0.033538897,
        -0.0032264893,
        0.019198945,
        -0.043493904,
        -0.025006032,
        0.01016833,
        -0.009522439,
        -0.020395916,
        -0.008289915,
        0.020301105,
        -0.02438977,
        -0.0006762591,
        -0.01719609,
        -0.006417425,
        0.040246677,
        -0.008260286,
        -0.009747612,
        -0.061863266,
        -0.046267085,
        -0.044702727,
        0.048969157,
        0.035126958,
        0.002029518,
        0.018167889,
        -0.024769008,
        0.0008206956,
        -0.015773946,
        -0.0073536695,
        -0.0063759456,
        0.032424882,
        0.020407766,
        0.023880169,
        0.013451112,
        -0.03041018,
        0.038563807,
        -0.0024117192,
        0.04733369,
        0.021972125,
        -0.064138696,
        0.016153187,
        -0.014849554,
        -0.020277403,
        -0.039654117,
        0.028798416,
        0.052903756,
        0.02607264,
        0.026001533,
        0.07343004,
        -0.04266432,
        -0.035458792,
        -0.023572037,
        0.01757533,
        0.008876549,
        -0.032638203,
        -0.0009755019,
        0.013913309,
        -0.045081966,
        -0.015039173,
        -0.027637,
        -0.008165477,
        0.020064082,
        -0.0060500377,
        0.013320749,
        0.06849994,
        0.03140568,
        -0.010476461,
        0.027660701,
        0.01303632,
        0.033989243,
        0.00013378894,
        -0.014837703,
        0.0018250848,
        -0.031737514,
        -0.019898165,
        0.042142868,
        0.040744424,
        -0.0096053975,
        0.00992538,
        0.021415118,
        0.011993415,
        -0.030789418,
        0.0019524852,
        0.023524633,
        0.043612417,
        0.0042842086,
        0.012117852,
        -0.050912756,
        0.013380005,
        0.06214769,
        -0.021462522,
        -0.013166683,
        -0.024413472,
        0.04977504,
        -0.008580268,
        -0.03022056,
        -0.018227145,
        0.052003067,
        0.005987819,
        -0.010328321,
        0.021379564,
        -0.031856027,
        -0.024674198,
        -0.038303077,
        0.021095136,
        0.03415516,
        0.03337298,
        0.00799956,
        0.011389003,
        0.04306726,
        -0.035292875,
        0.022149893,
        0.0019154502,
        0.015845055,
        -0.0325671,
        -0.0030116863,
        0.035482492,
        0.0197441,
        0.020976624,
        0.0049863923,
        -0.006755184,
        -0.0011843793,
        -0.0012999285,
        -0.012117852,
        -0.00017304604,
        0.022197297,
        -0.017990122,
        0.023477226,
        -0.048921753,
        -0.0015880608,
        0.016532425,
        0.05214528,
        -0.022683198,
        0.014920661,
        0.031144954,
        0.0068381424,
        0.041218475,
        0.023394268,
        0.015856905,
        0.0045508607,
        0.0025450452,
        -0.02092922,
        -0.007318116,
        0.008586194,
        -0.017468669,
        -0.0049893553,
        -0.0454375,
        0.043636117,
        0.017350158,
        0.020289255,
        -0.035766922,
        0.0711072,
        -0.002785032,
        -0.008118072,
        -0.046954453,
        0.07580028,
        0.041811034,
        0.043280583,
        0.0074188514,
        0.046077468,
        -0.00019147096,
        0.0068973983,
        -0.0375446,
        0.042095464,
        0.022778006,
        -0.0030027977,
        -0.0070159105,
        -0.011791944,
        0.022730602,
        0.067125194,
        -0.05266673,
        -0.0038723797,
        0.036193565,
        -0.01945967,
        0.007750685,
        -0.0039079334,
        0.046172276,
        0.014411059,
        -0.044442,
        0.0256697,
        -0.046385597,
        -0.026641497,
        -0.0325908,
        0.021889167,
        0.016722044,
        0.03150049,
        0.0029865024,
        -0.009759463,
        0.02694963,
        0.038563807,
        0.0069270264,
        0.008123998,
        -0.011181607,
        -0.0058722696,
        -0.027874023,
        -0.025314163,
        -0.0012154886,
        -0.009498737,
        0.044726428,
        0.01550137,
        -0.082105115,
        -0.06622451,
        -0.0021539556,
        0.02044332,
        -0.045840442,
        -0.037189066,
        0.0061270706,
        0.0028902113,
        0.034012944,
        -0.03505585,
        0.004817513,
        0.011993415,
        0.03439218,
        -0.005211565,
        0.027471082,
        -0.014268844,
        0.0010614231,
        0.007158125,
        0.039251175,
        -0.029153952,
        -0.026522987,
        -0.06494457,
        0.016413912,
        0.037876435,
        -0.03486623,
        -0.020514427,
        -0.071486436,
        0.011643804,
        -0.011602324,
        -0.029580595,
        -0.023844615,
        -0.060772955,
        0.015394709,
        -0.01244376,
        0.025408972,
        -0.009635026,
        -0.026641497,
        -0.03446329,
        -0.04906397,
        0.010529791,
        0.0074307024,
        0.0355773,
        0.020028528,
        0.008799516,
        -0.029793916,
        0.06347503,
        0.03643059,
        0.020952921,
        0.038682315,
        0.011774167,
        -0.055084378,
        -0.0064114993,
        0.003952375,
        -0.025930425,
        -0.010411279,
        -0.010920881,
        -0.037354983,
        0.02024185,
        0.05551102,
        0.019222647,
        -0.014079225,
        0.0021939534,
        -0.009048391,
        -0.011560845,
        0.004384944,
        0.011833423,
        -0.045318987,
        0.001503621,
        0.014636232,
        -0.0047375173,
        0.021296607,
        0.0016191702,
        -0.046859644,
        0.021699548,
        0.010292768,
        0.004204213,
        -0.011981564,
        0.0020428507,
        -0.016674638,
        -0.028703606,
        -0.016840555,
        -0.024650495,
        -0.021166243,
        -0.045176774,
        -0.010808295,
        -0.04197695,
        0.010808295,
        -0.005599692,
        -0.017836057,
        0.008698781,
        0.00046182645,
        0.03929858,
        -0.01737386,
        0.0035375832,
        -0.006873696,
        -0.050723135,
        0.007958081,
        0.020917367,
        0.010879402,
        -0.019044878,
        0.053709637,
        -0.004817513,
        0.018203443,
        -0.037971243,
        -0.015596179,
        0.0099431565,
        0.015477668,
        0.0054693287,
        -0.045105666,
        0.0031464936,
        -0.026712606,
        -0.024934925,
        0.0009103203,
        -0.0016206516,
        -0.01071941,
        0.03586173,
        0.009712058,
        0.025029734,
        -0.021261053,
        -0.003970152,
        0.035411384,
        0.0036057276,
        -0.013605177,
        -0.02588302,
        -0.018274551,
        -0.018191593,
        0.0026561501,
        -0.0058456045,
        0.019222647,
        -0.029580595,
        -0.009919454,
        -0.013830351,
        0.013972565,
        0.019388564,
        0.062100288,
        0.045318987,
        0.016911663,
        0.0069803568,
        -0.0066129696,
        0.035814326,
        -0.009676505,
        0.009249861,
        -0.02548008,
        0.016129483,
        0.024863817,
        -0.010150553,
        -0.0033153733,
        0.013107427,
        -0.010855699,
        -0.020573683,
        -0.015928013,
        0.050817944,
        0.027281463,
        0.02844288,
        0.0012006747,
        -0.0081121465,
        -0.04977504,
        -0.02588302,
        -0.0030087235,
        -0.029604297,
        -0.0059789303,
        -0.016650936,
        -0.013901457,
        0.02834807,
        0.010304619,
        0.020419618,
        0.017219793,
        0.012088224,
        0.05124459,
        -0.0007903269,
        0.024911223,
        0.028111046,
        -0.032922633,
        -0.035316575,
        -0.01975595,
        -0.021367714,
        -0.009125424,
        -0.009860198,
        0.023240203,
        -0.002288763,
        -0.01343926,
        -0.030339072,
        -0.0028931743,
        -0.010061669,
        0.027684404,
        0.006684077,
        0.00048626956,
        0.052192684,
        -0.009717984,
        0.03417886,
        -0.010002413,
        -0.036549103,
        -0.02063294,
        0.02626226,
        0.04178733,
        0.0025939315,
        0.016058376,
        -0.02931987,
        -0.049917255,
        -0.012894106,
        0.0066781514,
        -0.018428616,
        -0.030955335,
        -0.04847141,
        -0.017314604,
        -0.029983535,
        0.04958542,
        0.022398768,
        -0.0061566983,
        -0.046835944,
        -0.00060033734,
        -0.029201357,
        -0.03446329,
        -0.06873696,
        0.0048115873,
        0.008704706,
        0.0066603743,
        0.023903871,
        -0.034913637,
        -0.01986261,
        0.00599967,
        -0.03534028,
        -0.0031613077,
        0.04600636,
        0.01876045,
        0.020490725,
        0.012277843,
        0.0060678143,
        0.010417205,
        0.018345658,
        -0.021592887,
        0.024484579,
        -0.029983535,
        0.03199824,
        -0.012159332,
        0.0053389654,
        -0.04384944,
        -0.015039173,
        0.011791944,
        0.0004996022,
        -0.02607264,
        0.013071873,
        -2.437366e-05,
        0.01598727,
        0.0056352457,
        0.00883507,
        0.044276085,
        -0.015762096,
        0.030504989,
        -0.032306373,
        0.0071462737,
        -0.02607264,
        0.010796444,
        0.046622623,
        0.020182593,
        0.021106988,
        -0.0053922962,
        -0.0026057826,
        0.018582681,
        -0.016745746,
        -0.020621087,
        -0.023311311,
        0.019033028,
        0.003567211,
        -0.0030635353,
        -0.037805326,
        -0.0013984416,
        0.018547129,
        -0.034321073,
        -0.01313113,
        0.002270986,
        0.060488526,
        0.04323318,
        0.0217351,
        -0.029343572,
        0.022066934,
        -0.03415516,
        0.002315428,
        -0.0325908,
        0.0018710082,
        -0.00414792,
        -0.026831117,
        -0.009291341,
        -0.001288818,
        0.0016399098,
        -0.049917255,
        -0.004491605,
        -0.0025198613,
        -0.007436628,
        -0.056838356,
        -0.01866564,
        -0.004621968,
        -0.0066663,
        0.0038575656,
        0.020514427,
        -0.03564841,
        -0.05579545,
        0.0077684615,
        0.0061092936,
        -0.0071521993,
        0.0034635132,
        0.028561393,
        0.00599967,
        0.0038249749,
        -0.025408972,
        -0.045864142,
        -0.008337319,
        -0.025788212,
        0.027968831,
        0.009712058,
        0.0063877967,
        -0.039345983,
        0.0065359366,
        0.053472616,
        -0.02706814,
        -0.044513106,
        -0.040625915,
        0.019222647,
        -0.008497311,
        -0.036098756,
        -0.049111374,
        0.027399974,
        0.012082298,
        -0.037165362,
        -0.012870403,
        -0.019281903,
        -0.003199824,
        0.018689342,
        -0.023678698,
        -0.0056174686,
        -0.029746512,
        0.036075052,
        0.009155052,
        0.012325248,
        0.0041390317,
        0.0099431565,
        -0.027305165,
        -0.0101090735,
        0.028679904,
        0.017101282,
        -0.003973115,
        -0.00987205,
        -0.010043892,
        0.024366068,
        0.0015021396,
        0.038587507,
        0.03327817,
        -0.036572803,
        -0.030386478,
        -0.024650495,
        0.0035138808,
        0.020123338,
        -0.0154539645,
        -0.0010199439,
        0.016947215,
        0.013652583,
        -0.0046101166,
        0.0023213539,
        0.0056974646,
        -0.023287607,
        -0.036383186,
        0.009078019,
        -0.03100274,
        0.015631733,
        -0.032898933,
        0.026001533,
        0.032638203,
        0.01313113,
        0.003451662,
        0.01865379,
        -0.027423676,
        0.027257761,
        0.021201797,
        -0.0035227693,
        -0.005584878,
        -0.008894325,
        0.023358716,
        -0.033112254,
        -0.015714692,
        0.009303192,
        -0.016176889,
        -0.016935365,
        -0.0029420604,
        -0.0076084705,
        0.010529791,
        0.018061228,
        -0.010150553,
        0.034510694,
        0.025314163,
        -0.0020872925,
        0.015264345,
        0.028703606,
        0.0187723,
        0.019838909,
        0.021663994,
        0.002429496,
        0.0031435308,
        0.023643143,
        -0.002710962,
        0.0036472068,
        -0.0047049266,
        -0.013154832,
        0.03870602,
        -0.016899811,
        -0.020064082,
        -0.01442291,
        0.012680784,
        0.025764508,
        -0.04475013,
        0.065229006,
        0.009563918,
        -0.02033666,
        -0.007300339,
        0.020775154,
        -0.014174035,
        0.011134203,
        0.03346779,
        0.02045517,
        0.00032498213,
        0.027328867,
        -0.020976624,
        -0.0015821352,
        0.0014725116,
        0.018713044,
        -0.0055167335,
        0.002214693,
        -0.016556127,
        0.04008076,
        -0.020123338,
        -0.0054604406,
        -0.027281463,
        0.013368154,
        0.0024028309,
        -0.014138482,
        0.002577636,
        -0.0076795775,
        -0.0055433987,
        -0.009848347,
        -0.010061669,
        -0.05916119,
        -0.0011917863,
        -0.0063107642,
        0.005910786,
        -0.030362774,
        -0.021201797,
        0.0064233504,
        -0.003896082,
        -0.012799296,
        -0.014031821,
        0.03389443,
        -0.048376597,
        0.058023475,
        0.01353407,
        -0.033989243,
        0.03287523,
        0.0058100508,
        0.012384504,
        0.012609676,
        0.0082780635,
        0.023963127,
        -0.0031494563,
        -0.025361568,
        0.014185887,
        -0.00039738556,
        0.020668494,
        0.0004184955,
        -0.011430482,
        -0.05807088,
        0.008864698,
        -0.0008036595,
        -0.013060022,
        0.0038546028,
        -0.0111105,
        -9.990191e-05,
        -0.042403594,
        0.02015889,
        -0.0182627,
        0.050296493,
        -0.01570284,
        0.019424116,
        0.013249641,
        -0.031571597,
        0.01657983,
        0.045366395,
        -0.0032235265,
        0.04095775,
        0.024460876,
        0.017421264,
        -0.032733016,
        0.053188186,
        0.024140894,
        0.010903104,
        -0.00040405185,
        0.020478874,
        0.012917808,
        -0.012491165,
        -0.014268844,
        -0.01511028,
        0.00019906313,
        -0.026712606,
        0.0127874445,
        0.0256697,
        -0.006458904,
        -0.0073418184,
        0.001681389,
        -0.00054700696,
        -0.01866564,
        -0.004995281,
        0.0012991878,
        0.024318663,
        -0.024437174,
        -0.03022056,
        0.01748052,
        -0.044110168,
        -0.028703606,
        -0.02785032,
        0.009717984,
        -0.029746512,
        0.011590473,
        -0.0078099407,
        -0.026925927,
        -0.0014265882,
        -0.019981124,
        0.0011177163,
        0.026854819,
        0.016153187,
        -0.04228508,
        0.033610005,
        -0.012064521,
        0.021581035,
        -0.015821353,
        -0.038729724,
        0.021118838,
        -0.010417205,
        -0.039061554,
        -0.0131192785,
        0.03683353,
        0.026309663,
        -0.0084321285,
        -0.011234937,
        0.034012944,
        -0.014494018,
        0.02004038,
        0.020123338,
        -0.016247995,
        -0.013380005,
        0.009723909,
        -0.019992974,
        0.0053093378,
        -0.050912756,
        0.01205267,
        -0.027399974,
        0.016378358,
        0.028111046,
        0.021972125,
        -0.0070573897,
        -0.015311751,
        -0.009623175,
        0.0022828374,
        0.019590033,
        -0.00030239078,
        -0.042403594,
        -0.017658288,
        0.0121237775,
        -0.0009755019,
        -0.03586173,
        -0.017456818,
        -0.0065003834,
        -0.008556566,
        0.0073951487,
        0.0007895862,
        -0.008449906,
        0.03339668,
        -0.0008673597,
        -0.008064741,
        0.0076558753,
        0.032851525,
        -0.010855699,
        -0.062526934,
        -0.0007732908,
        0.009700207,
        -0.0003873861,
        -0.013225939,
        -0.0121237775,
        0.043090962,
        0.035032146,
        -0.0011303083,
        0.01560803,
        -0.020964773,
        0.014885107,
        0.030007238,
        0.018250847,
        -0.010055743,
        0.02015889,
        -0.02607264,
        0.021806208,
        0.025717104,
        -0.028490284,
        0.003822012,
        -0.014174035,
        0.0007103313,
        0.0016458353,
        -0.013142981,
        -0.030030942,
        -0.05607988,
        -0.012716338,
        -0.020917367,
        0.035103254,
        -0.023429822,
        0.02241062,
        0.0023198724,
        0.0068025887,
        0.022197297,
        0.0008784702,
        -0.027044438,
        0.018582681,
        -0.008497311,
        0.03327817,
        0.007495884,
        -0.016947215,
        0.001133271,
        -0.025006032,
        0.039748926,
        -0.032638203,
        -0.0111164255,
        0.008639525,
        0.014304399,
        0.014861405,
        0.013083725,
        0.02694963,
        -0.059256,
        0.029959833,
        0.008491385,
        -0.011738613,
        -0.0045004934,
        -0.014268844,
        0.020514427,
        -0.011471962,
        0.032353777,
        -0.0069151754,
        -0.028537689,
        0.039464496,
        0.027779212,
        -0.017338306,
        0.012977064,
        0.009824645,
        0.07347744,
        -0.0019302642,
        -0.013285195,
        0.011140128,
        0.027542189,
        0.011874902,
        -0.03389443,
        -0.00690925,
        0.017136835,
        -0.03901415,
        -0.016437614,
        0.02756589,
        -0.0017880498,
        -0.00883507,
        0.0057833856,
        0.0023495003,
        -0.027589593,
        0.004236804,
        -0.0048915828,
        0.009261712,
        0.0060974425,
        0.01135345,
        0.006885547,
        -0.029059142,
        0.011418631,
        -0.034036648,
        -0.0026028198,
        -0.016082078,
        -0.00908987,
        0.032330073,
        -0.012396355,
        -0.016923513,
        0.00013165943,
        0.009800943,
        -0.011857126,
        0.01797827,
        0.014778446,
        -0.001622133,
        0.015181387,
        0.01599912,
        -0.01955448,
        0.0037746073,
        -0.036383186,
        -0.004781959,
        -0.025006032,
        -0.009350597,
        -0.03365741,
        0.022114338,
        0.004533084,
        0.013735541,
        0.0107786665,
        0.0015525072,
        -0.002799846,
        -0.027423676,
        -0.021806208,
        0.0035968393,
        0.037354983,
        0.053946663,
        -0.037189066,
        0.025100842,
        -0.013699987,
        -0.008787665,
        -0.0028161414,
        0.039962247,
        0.030599799,
        -0.009848347,
        -0.003066498,
        -0.015560626,
        -0.01451772,
        0.043209475,
        -0.037994947,
        0.009498737,
        -0.012420057,
        -0.024816412,
        0.033538897,
        0.0055167335,
        -0.004633819,
        0.025574889,
        0.02815845,
        -0.034652907,
        -0.014920661,
        0.027281463,
        0.007626247,
        0.0075018094,
        -0.038658615,
        -0.015359155,
        0.028798416,
        0.021841763,
        -0.03327817,
        0.010938657,
        -0.01125864,
        0.032353777,
        0.036335777,
        0.035198063,
        -0.028608797,
        -0.01160825,
        -0.009012838,
        -0.004180511,
        -0.0013969602,
        0.021995828,
        -0.007495884,
        0.0089476565,
        0.0020724786,
        0.021462522,
        -0.04285394,
        0.037757922,
        -0.0009710577,
        0.0006118182,
        -0.04709667,
        -0.039772626,
        0.04313837,
        -0.012218587,
        0.021640291,
        -0.038540103,
        -0.029865025,
        0.042332485,
        0.040222973,
        0.049253587,
        -0.010920881,
        -0.011691209,
        0.029580595,
        -0.0042723576,
        0.015039173,
        0.012716338,
        -0.03704685,
        0.02063294,
        -0.0004570119,
        0.03863491,
        -0.021154393,
        0.008402501,
        0.003836826,
        -0.009889826,
        0.04119477,
        -0.005990782,
        0.043304283,
        0.009427629,
        0.009042466,
        -0.041218475,
        -0.012479314,
        0.030599799,
        -0.035601005,
        -0.0072055296,
        0.0182627,
        0.033230767,
        -0.048258085,
        -0.0017954569,
        0.024840115,
        -0.008390649,
        0.03723647,
        -0.008977284,
        0.02548008,
        -0.026546689,
        -0.027826618,
        -0.049727634,
        0.020218147,
        -0.01372369,
        -0.011193458,
        0.0072055296,
        0.022683198,
        0.0001222155,
        -0.022671346,
        -0.031026442,
        -0.016141335,
        0.023465376,
        0.025171949,
        0.0047197402,
        -0.029770214,
        0.0010436462,
        0.028371774,
        0.01190453,
        0.013214088,
        -0.010523866,
        0.02083441,
        -0.024911223,
        -0.011513441,
        0.0052263793,
        0.0106127495,
        -0.0041864365,
        0.009018763,
        0.010672006,
        -0.024152746,
        0.025337866,
        0.021095136,
        -0.004002743,
        0.03424997,
        -0.043209475,
        0.0035612856,
        -0.0001636947,
        0.02182991,
        -0.0010021671,
        0.025574889,
        -0.008532864,
        0.030884227,
        -0.019779652,
        0.041645117,
        0.02132031,
        -0.009160978,
        0.010144628,
        -0.0060974425,
        0.021308457,
        0.042213976,
        0.009575769,
        -0.011193458,
        -0.022197297,
        -0.025977831,
        0.017290901,
        -0.007952156,
        0.013842202,
        0.013403707,
        -0.04185844,
        0.014363655,
        -0.006707779,
        -0.006577416,
        0.035103254,
        0.020170743,
        0.002133216,
        -0.017646438,
        0.0053656306,
        0.008722483,
        -0.0154539645,
        0.018203443,
        0.016710192,
        0.025100842,
        -0.0071047945,
        0.013735541,
        -0.008663227,
        0.0043168,
        -0.009475035,
        -0.014529571,
        0.012384504,
        0.031263467,
        -0.0032413031,
        0.020751452,
        -0.0045538237,
        0.0073418184,
        0.004651596,
        0.0025376382,
        0.002491715,
        0.035198063,
        -0.02775551,
        -0.017527925,
        0.026499283,
        0.027874023,
        -0.00996686,
        -0.025622295,
        0.00071996043,
        0.004678261,
        0.023963127,
        -0.006417425,
        -0.0014228848,
        -0.016330954,
        0.017030174,
        -0.006755184,
        -0.008965433,
        -0.012372653,
        0.001162899,
        0.020704046,
        -0.03467661,
        0.027376272,
        0.023666846,
        0.014328101,
        0.026688902,
        -0.030860525,
        -0.006618895,
        0.012206736,
        0.03199824,
        -0.019732248,
        0.03318336,
        0.0057063526,
        -0.031239763,
        -8.4162035e-05,
        0.023062436,
        0.014494018,
        0.0017243496,
        -0.020941071,
        0.011193458,
        -0.040341485,
        -0.0019095246,
        0.017504223,
        -0.04650411,
        0.036762424,
        0.022268405,
        -0.014648084,
        0.014778446,
        0.007964007,
        0.0058693066,
        -0.015347304,
        0.02420015,
        0.0058337534,
        -0.0024280145,
        0.039085258,
        -0.020502577,
        0.008704706,
        -0.02694963,
        -0.01244376,
        -0.028703606,
        -0.009700207,
        -0.021983976,
        -0.0013251123,
        -0.011424556,
        -0.027542189,
        -0.016271697,
        0.010393502,
        -0.027897725,
        0.013474815,
        -0.022221,
        0.023963127,
        0.02844288,
        -0.010938657,
        0.0059256,
        0.0056945016,
        -0.02312169,
        -0.018144187,
        -0.01007352,
        0.020976624,
        0.009060242,
        0.013889606,
        -0.031737514,
        -0.026546689,
        0.0036027648,
        0.013451112,
        -0.019590033,
        0.014328101,
        0.013451112,
        0.0044975304,
        0.0038457145,
        0.012100075,
        -0.004903434,
        0.005196751,
        -0.023489079,
        -0.0016650936,
        -0.016485019,
        0.040744424,
        0.012645231,
        -0.0036857233,
        0.025811914,
        0.03178492,
        0.007993635,
        0.021794356,
        -0.008852846,
        0.0008488422,
        -0.0032383404,
        -0.04017557,
        -0.020787004,
        -0.014031821,
        -0.013937011,
        0.011993415,
        0.0054278495,
        0.022268405,
        0.041502904,
        0.022375066,
        0.046575215,
        -0.032424882,
        -0.012763742,
        0.036501694,
        0.0071936785,
        -0.019305605,
        -0.0027213318,
        -0.021770654,
        0.0031287167,
        -0.024531985,
        0.033135954,
        0.026143746,
        -0.009255787,
        -0.007347744,
        -0.022932071,
        -0.022730602,
        -0.016176889,
        0.008230658,
        -0.028751012,
        0.01748052,
        0.0029731698,
        0.010186106,
        0.03804235,
        0.003881268,
        0.007335893,
        -0.0031731587,
        0.004930099,
        0.013699987,
        0.015904311,
        -0.0053063747,
        0.00503676,
        0.0008110665,
        -0.036572803,
        0.021047732,
        0.009291341,
        -0.0055908035,
        -0.012811148,
        0.013901457
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 144.7986602783203,
        "patch_type": "diff",
        "api_costs": 0.509434,
        "num_applied": 1,
        "patch_name": "iterative_refinement_max_vs_all",
        "patch_description": "Improved the `balanced_packing` function by enhancing the refinement strategy.\n1.  **Objective**: Minimize the maximum load (Makespan).\n2.  **Strategy**: In each refinement step, identify the heaviest pack (`max_p`). Instead of only trying to balance it with the lightest pack (`min_p`), evaluate potential pairings with **all other packs**. Choose the partner that results in the greatest reduction of the `max_p` load (specifically, minimizing the new maximum of the pair).\n3.  **Solver**: Uses an exact solver (combinatorial) for small problem sizes (<= 14 items in pair) and a robust randomized greedy+swap heuristic for larger sizes.\n4.  **Init**: Uses multi-start randomized LPT (Longest Processing Time) greedy initialization.\n5.  **Efficiency**: Optimization logic uses CPU scalar operations (lists) to avoid GPU overheads.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 2,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\niterative_refinement_max_vs_all\n</NAME>\n\n<DESCRIPTION>\nImproved the `balanced_packing` function by enhancing the refinement strategy.\n1.  **Objective**: Minimize the maximum load (Makespan).\n2.  **Strategy**: In each refinement step, identify the heaviest pack (`max_p`). Instead of only trying to balance it with the lightest pack (`min_p`), evaluate potential pairings with **all other packs**. Choose the partner that results in the greatest reduction of the `max_p` load (specifically, minimizing the new maximum of the pair).\n3.  **Solver**: Uses an exact solver (combinatorial) for small problem sizes (<= 14 items in pair) and a robust randomized greedy+swap heuristic for larger sizes.\n4.  **Init**: Uses multi-start randomized LPT (Longest Processing Time) greedy initialization.\n5.  **Efficiency**: Optimization logic uses CPU scalar operations (lists) to avoid GPU overheads.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n=======\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 3\n    max_refine_steps = 25\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max pack\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                max_val = pack_weights[max_p]\n\n                min_val = min(pack_weights)\n                if max_val - min_val < 1e-6:\n                    break\n\n                best_move = None\n                best_move_improvement = -1.0 \n\n                candidate_packs = [p for p in range(num_packs) if p != max_p]\n                # Sort candidates by weight: testing lightest first often helps move most weight\n                candidate_packs.sort(key=pack_weights.__getitem__)\n\n                for other_p in candidate_packs:\n                    other_val = pack_weights[other_p]\n                    \n                    # Target is average of the pair\n                    avg = (max_val + other_val) / 2.0\n                    potential_reduction = max_val - avg\n                    \n                    if potential_reduction < best_move_improvement + 1e-6:\n                        continue\n                        \n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    \n                    K = groups_per_pack\n                    pool_len = 2 * K\n                    \n                    best_local_set_A = None\n                    best_local_max = float('inf')\n                    \n                    # EXACT SOLVER for small K\n                    if pool_len <= 14:\n                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n                         indices_rest = list(range(1, pool_len))\n                         w_0 = pool_weights[0]\n                         \n                         for comb in itertools.combinations(indices_rest, K - 1):\n                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n                             other_w = (max_val + other_val) - current_w\n                             local_max = max(current_w, other_w)\n                             \n                             if local_max < best_local_max:\n                                 best_local_max = local_max\n                                 best_local_set_A = [0] + list(comb)\n                                 if abs(local_max - avg) < 1e-5:\n                                     break\n                    else:\n                        # Heuristic Solver\n                        pool_indices = list(range(pool_len))\n                        sub_trials = 10\n                        for sub in range(sub_trials):\n                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n                            \n                            w1, w2 = 0.0, 0.0\n                            c1, c2 = 0, 0\n                            s1, s2 = [], []\n                            \n                            for idx in sorted_idx:\n                                w = pool_weights[idx]\n                                if c1 < K and c2 < K:\n                                    if w1 <= w2: \n                                        w1 += w; c1 += 1; s1.append(idx)\n                                    else:\n                                        w2 += w; c2 += 1; s2.append(idx)\n                                elif c1 < K:\n                                    w1 += w; c1 += 1; s1.append(idx)\n                                else:\n                                    w2 += w; c2 += 1; s2.append(idx)\n                            \n                            # Swap Local Search\n                            while True:\n                                improved_swap = False\n                                current_max = max(w1, w2)\n                                for i1, idx1 in enumerate(s1):\n                                    for i2, idx2 in enumerate(s2):\n                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n                                        nmax = max(nw1, nw2)\n                                        if nmax < current_max - 1e-6:\n                                            w1, w2 = nw1, nw2\n                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n                                            current_max = nmax\n                                            improved_swap = True\n                                            break\n                                    if improved_swap: break\n                                if not improved_swap: break\n                            \n                            if max(w1, w2) < best_local_max:\n                                best_local_max = max(w1, w2)\n                                best_local_set_A = list(s1)\n\n                    # Check improvement\n                    improvement = max_val - best_local_max\n                    if improvement > best_move_improvement + 1e-6:\n                        best_move_improvement = improvement\n                        set_A_indices = best_local_set_A\n                        set_A_set = set(set_A_indices)\n                        new_items_A = [pool[x] for x in set_A_indices]\n                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n                        # Calculate exact new weights to avoid drift\n                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n                        \n                        if abs(best_local_max - avg) < 1e-5:\n                             break\n\n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    break\n\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n>>>>>>> REPLACE\n</DIFF>",
          "msg": "The previous edit was not successful. This was the error message: \n\nNo changes applied.\n\n Try again.",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nYou MUST repond using a edit name, description and the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<NAME>\nA shortened name summarizing the edit you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the edit you are proposing.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly including indentation)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\n</DIFF>\n\n\nExample of a valid diff format:\n<DIFF>\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\n</DIFF>\n\n* You may only modify text that lies below a line containing \"EVOLVE-BLOCK-START\" and above the next \"EVOLVE-BLOCK-END\". Everything outside those markers is read-only.\n* Do not repeat the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the SEARCH/REPLACE blocks.  \n* Every block\u2019s SEARCH section must be copied **verbatim** from the current file.  Including indentation.\n* You can propose multiple independent edits. SEARCH/REPLACE blocks follow one after another. DO NOT ADD ANY OTHER TEXT BETWEEN THESE BLOCKS.\n* Make sure the file still runs after your changes.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move weights to CPU and use Python lists for the sequential greedy/swap logic.\n    # This avoids high kernel launch overheads for sequential scalar operations on GPU.\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        # current_packs stores tuples of (expert_index, weight)\n        current_packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy packing (LPT: Longest Processing Time first)\n        # Assign heaviest items first to the least loaded pack that has space.\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n\n            # Find the least loaded pack with capacity\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n\n            current_packs[best_pack].append((group, w))\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Pairwise balancing (Swap or Repartition)\n        # Try to improve balance between heaviest and lighter packs.\n        # We consider both single-item swaps and full greedy re-partitioning of the two packs.\n        for _ in range(20):\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n            found_improvement = False\n\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n                # Compare against lighter packs (starting from lightest)\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    current_diff = pack_weights[p1] - pack_weights[p2]\n                    if current_diff < 1e-6:\n                        break\n\n                    # Strategy A: Greedy Repartitioning\n                    # Combine items, sort, and fill two bins greedily.\n                    # This handles multi-item moves implicitly.\n                    p1_items = current_packs[p1]\n                    p2_items = current_packs[p2]\n\n                    combined_items = p1_items + p2_items\n                    # Sort by weight descending\n                    combined_items.sort(key=lambda x: x[1], reverse=True)\n\n                    # Simulation of Greedy Packing\n                    sim_w1 = 0.0\n                    sim_w2 = 0.0\n                    sim_p1 = []\n                    sim_p2 = []\n                    cap = groups_per_pack\n\n                    possible_repartition = True\n                    for item in combined_items:\n                        # Try to add to lighter simulated pack\n                        if len(sim_p1) < cap and len(sim_p2) < cap:\n                            if sim_w1 <= sim_w2:\n                                sim_p1.append(item)\n                                sim_w1 += item[1]\n                            else:\n                                sim_p2.append(item)\n                                sim_w2 += item[1]\n                        elif len(sim_p1) < cap:\n                            sim_p1.append(item)\n                            sim_w1 += item[1]\n                        elif len(sim_p2) < cap:\n                            sim_p2.append(item)\n                            sim_w2 += item[1]\n                        else:\n                            # Should not happen if sizes match\n                            possible_repartition = False\n                            break\n\n                    best_diff = current_diff\n                    best_action = None # ('repartition', p1_list, p2_list, w1, w2) or ('swap', ...)\n\n                    if possible_repartition:\n                        new_diff_repart = abs(sim_w1 - sim_w2)\n                        if new_diff_repart < best_diff - 1e-6:\n                            best_diff = new_diff_repart\n                            best_action = ('repartition', sim_p1, sim_p2, sim_w1, sim_w2)\n\n                    # Strategy B: Single Item Swap (Original Logic)\n                    # Sometimes better than greedy if greedy gets stuck.\n                    target = current_diff / 2.0\n\n                    found_better_swap = False\n                    best_swap_tuple = None\n\n                    for idx_u, (u, w_u) in enumerate(p1_items):\n                        for idx_v, (v, w_v) in enumerate(p2_items):\n                            delta = w_u - w_v\n                            if 0 < delta < current_diff:\n                                gap = abs(delta - target)\n                                # Check if this swap results in a diff smaller than best_diff\n                                # New diff would be |(W1 - delta) - (W2 + delta)| = 2 * gap\n                                if 2 * gap < best_diff - 1e-6:\n                                    best_diff = 2 * gap\n                                    best_swap_tuple = (idx_u, idx_v, delta, v, w_v, u, w_u)\n                                    found_better_swap = True\n                                    if gap < 1e-5: break\n                        if found_better_swap and best_diff < 1e-5: break\n\n                    # Execute Best Action\n                    if found_better_swap:\n                        idx_u, idx_v, delta, val_v, weight_v, val_u, weight_u = best_swap_tuple\n                        current_packs[p1][idx_u] = (val_v, weight_v)\n                        current_packs[p2][idx_v] = (val_u, weight_u)\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n                    elif best_action and best_action[0] == 'repartition':\n                        _, new_p1, new_p2, new_w1, new_w2 = best_action\n                        current_packs[p1] = new_p1\n                        current_packs[p2] = new_p2\n                        pack_weights[p1] = new_w1\n                        pack_weights[p2] = new_w2\n                        found_improvement = True\n                        break\n\n                if found_improvement: break\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, (g, _) in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Optimization: Track current scores (load/count) to avoid full matrix recalculation\n    current_scores = weight.clone()\n\n    for i in range(num_log, num_phy):\n        # Pick the expert with the max current load per replica\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        # Increment count\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update scores only for the experts that got a new replica\n        # score = weight / count\n        # We use advanced indexing to update only the modified positions\n        updated_weights = weight[arangen, redundant_indices]\n        updated_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = updated_weights / updated_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a modification to it below):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Instructions\n\nMake sure that the changes you propose are consistent with each other. For example, if you refer to a new config variable somewhere, you should also propose a change to add that variable.\n\nNote that the changes you propose will be applied sequentially, so you should assume that the previous changes have already been applied when writing the SEARCH block.\n\n# Task\n\nSuggest a new idea to improve the performance of the code that is inspired by your expert knowledge of the considered subject.\nYour goal is to maximize the `combined_score` of the program.\nDescribe each change with a SEARCH/REPLACE block.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n"
            },
            {
              "role": "assistant",
              "content": "The current algorithm implements a load balancer for expert parallelism. The core problem is partitioning weighted items (expert groups) into packs (Nodes or GPUs) with a cardinality constraint (equal items per pack) to minimize the maximum load (Makespan) or load variance.\n\nThe existing solution uses a greedy LPT initialization followed by a refinement phase that strictly pairs the heaviest pack (`max_p`) with the lightest pack (`min_p`). While this is a standard heuristic, it often gets stuck in local optima when the `min_p` pack does not contain suitable items to swap with `max_p` to reduce the max load.\n\nThe proposed improvement modifies the refinement strategy in `balanced_packing`. Instead of only considering the `(max_p, min_p)` pair, the new algorithm iterates through **all other packs** as potential partners for `max_p`. For each candidate pair `(max_p, other_p)`, it attempts to rebalance them optimally (using an exact solver for small subset sizes or a robust heuristic for larger ones) to minimize the maximum load of the pair. If a rebalancing is found that strictly reduces the load of `max_p` (without making `other_p` heavier than `max_p` was), it is applied immediately. This strictly descends the global objective function (minimize peak load).\n\nAdditionally, the number of restarts for the randomized greedy initialization is increased to 3, and the exact solver threshold is kept at a safe but effective level (subset size <= 14) to handle typical vLLM configurations (e.g., 8 experts per GPU) efficiently.\n\n<NAME>\niterative_refinement_max_vs_all\n</NAME>\n\n<DESCRIPTION>\nImproved the `balanced_packing` function by enhancing the refinement strategy.\n1.  **Objective**: Minimize the maximum load (Makespan).\n2.  **Strategy**: In each refinement step, identify the heaviest pack (`max_p`). Instead of only trying to balance it with the lightest pack (`min_p`), evaluate potential pairings with **all other packs**. Choose the partner that results in the greatest reduction of the `max_p` load (specifically, minimizing the new maximum of the pair).\n3.  **Solver**: Uses an exact solver (combinatorial) for small problem sizes (<= 14 items in pair) and a robust randomized greedy+swap heuristic for larger sizes.\n4.  **Init**: Uses multi-start randomized LPT (Longest Processing Time) greedy initialization.\n5.  **Efficiency**: Optimization logic uses CPU scalar operations (lists) to avoid GPU overheads, as the problem size (N groups) is typically small enough for CPU but sequential logic is complex.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if wA <= wB:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n=======\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Parameters\n    num_restarts = 3\n    max_refine_steps = 25\n    \n    # Pre-calculate combinations support for small exact solver\n    # We rely on itertools which is efficient enough for small N\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization (Randomized Greedy LPT)\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights"
            },
            {
              "role": "user",
              "content": "The previous edit was not successful. This was the error message: \n\nNo changes applied.\n\n Try again."
            },
            {
              "role": "assistant",
              "content": "<NAME>\niterative_refinement_max_vs_all\n</NAME>\n\n<DESCRIPTION>\nImproved the `balanced_packing` function by enhancing the refinement strategy.\n1.  **Objective**: Minimize the maximum load (Makespan).\n2.  **Strategy**: In each refinement step, identify the heaviest pack (`max_p`). Instead of only trying to balance it with the lightest pack (`min_p`), evaluate potential pairings with **all other packs**. Choose the partner that results in the greatest reduction of the `max_p` load (specifically, minimizing the new maximum of the pair).\n3.  **Solver**: Uses an exact solver (combinatorial) for small problem sizes (<= 14 items in pair) and a robust randomized greedy+swap heuristic for larger sizes.\n4.  **Init**: Uses multi-start randomized LPT (Longest Processing Time) greedy initialization.\n5.  **Efficiency**: Optimization logic uses CPU scalar operations (lists) to avoid GPU overheads.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n=======\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 3\n    max_refine_steps = 25\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max pack\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                max_val = pack_weights[max_p]\n\n                min_val = min(pack_weights)\n                if max_val - min_val < 1e-6:\n                    break\n\n                best_move = None\n                best_move_improvement = -1.0 \n\n                candidate_packs = [p for p in range(num_packs) if p != max_p]\n                # Sort candidates by weight: testing lightest first often helps move most weight\n                candidate_packs.sort(key=pack_weights.__getitem__)\n\n                for other_p in candidate_packs:\n                    other_val = pack_weights[other_p]\n                    \n                    # Target is average of the pair\n                    avg = (max_val + other_val) / 2.0\n                    potential_reduction = max_val - avg\n                    \n                    if potential_reduction < best_move_improvement + 1e-6:\n                        continue\n                        \n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    \n                    K = groups_per_pack\n                    pool_len = 2 * K\n                    \n                    best_local_set_A = None\n                    best_local_max = float('inf')\n                    \n                    # EXACT SOLVER for small K\n                    if pool_len <= 14:\n                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n                         indices_rest = list(range(1, pool_len))\n                         w_0 = pool_weights[0]\n                         \n                         for comb in itertools.combinations(indices_rest, K - 1):\n                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n                             other_w = (max_val + other_val) - current_w\n                             local_max = max(current_w, other_w)\n                             \n                             if local_max < best_local_max:\n                                 best_local_max = local_max\n                                 best_local_set_A = [0] + list(comb)\n                                 if abs(local_max - avg) < 1e-5:\n                                     break\n                    else:\n                        # Heuristic Solver\n                        pool_indices = list(range(pool_len))\n                        sub_trials = 10\n                        for sub in range(sub_trials):\n                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n                            \n                            w1, w2 = 0.0, 0.0\n                            c1, c2 = 0, 0\n                            s1, s2 = [], []\n                            \n                            for idx in sorted_idx:\n                                w = pool_weights[idx]\n                                if c1 < K and c2 < K:\n                                    if w1 <= w2: \n                                        w1 += w; c1 += 1; s1.append(idx)\n                                    else:\n                                        w2 += w; c2 += 1; s2.append(idx)\n                                elif c1 < K:\n                                    w1 += w; c1 += 1; s1.append(idx)\n                                else:\n                                    w2 += w; c2 += 1; s2.append(idx)\n                            \n                            # Swap Local Search\n                            while True:\n                                improved_swap = False\n                                current_max = max(w1, w2)\n                                for i1, idx1 in enumerate(s1):\n                                    for i2, idx2 in enumerate(s2):\n                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n                                        nmax = max(nw1, nw2)\n                                        if nmax < current_max - 1e-6:\n                                            w1, w2 = nw1, nw2\n                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n                                            current_max = nmax\n                                            improved_swap = True\n                                            break\n                                    if improved_swap: break\n                                if not improved_swap: break\n                            \n                            if max(w1, w2) < best_local_max:\n                                best_local_max = max(w1, w2)\n                                best_local_set_A = list(s1)\n\n                    # Check improvement\n                    improvement = max_val - best_local_max\n                    if improvement > best_move_improvement + 1e-6:\n                        best_move_improvement = improvement\n                        set_A_indices = best_local_set_A\n                        set_A_set = set(set_A_indices)\n                        new_items_A = [pool[x] for x in set_A_indices]\n                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n                        # Calculate exact new weights to avoid drift\n                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n                        \n                        if abs(best_local_max - avg) < 1e-5:\n                             break\n\n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    break\n\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n>>>>>>> REPLACE\n</DIFF>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 35642,
          "output_tokens": 14923,
          "cost": 0.25036,
          "input_cost": 0.071284,
          "output_cost": 0.179076,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 0,
          "deleted": 90,
          "modified": 123
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 6.512e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_94/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_94/results\nRun 1/5 completed in 21.93 seconds\nRun 2/5 completed in 21.42 seconds\nRun 3/5 completed in 17.08 seconds\nRun 4/5 completed in 16.85 seconds\nRun 5/5 completed in 17.02 seconds\nbalancedness: 0.21073686403939265\nbalancedness: 0.3397761717755627\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_94/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_94/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.655538593116922\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.31107718623384406, 'speed_score': 1.0}\n  execution_time_mean: 18.860156769599417\n  execution_time_std: 2.306070117454986\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 61,
          "average_cyclomatic_complexity": 12.2,
          "halstead_volume": 2328.2723314297236,
          "halstead_difficulty": 14.184873949579831,
          "halstead_effort": 33026.24954162499,
          "lines_of_code": 370,
          "logical_lines_of_code": 229,
          "comments": 28,
          "maintainability_index": -39.40060898419512,
          "max_nesting_depth": 11,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "6870a182-c7e1-41a9-804b-edad3aa2afeb",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\nimport math\n\n\ndef solve_2_partition_restricted(weights: list[float], K: int, max_iter: int = 5) -> list[int] | None:\n    \"\"\"\n    Partition items into two sets of size K to minimize weight difference.\n    Returns indices of items in the first set (subset of range(2*K)).\n    \"\"\"\n    n = len(weights)\n    # Target is half the total weight\n    \n    # Exact solver for small problems\n    if n <= 14:\n        total_weight = sum(weights)\n        target = total_weight / 2.0\n        best_diff = float('inf')\n        best_comb = None\n        # Fix first item in first set to break symmetry and reduce search space by half\n        indices = list(range(1, n))\n        w0 = weights[0]\n        for comb in itertools.combinations(indices, K - 1):\n            s = w0 + sum(weights[i] for i in comb)\n            diff = abs(s - target)\n            if diff < best_diff:\n                best_diff = diff\n                best_comb = (0,) + comb\n                if best_diff < 1e-6: break\n        return list(best_comb) if best_comb else None\n\n    # Heuristic solver for larger problems using Randomized Greedy + Local Descent\n    indices = list(range(n))\n    best_diff = float('inf')\n    best_set_A = None\n\n    for attempt in range(max_iter):\n        # Randomized Greedy Construction\n        if attempt == 0:\n            sorted_idx = sorted(indices, key=lambda i: weights[i], reverse=True)\n        else:\n            # Multiplicative noise 0.9 ~ 1.1\n            noise = [random.uniform(0.9, 1.1) for _ in range(n)]\n            sorted_idx = sorted(indices, key=lambda i: weights[i] * noise[i], reverse=True)\n        \n        wA, wB = 0.0, 0.0\n        cntA, cntB = 0, 0\n        setA = []\n        setB = []\n        \n        for idx in sorted_idx:\n            w = weights[idx]\n            # Assign to the lighter bin if capacity allows\n            if cntA < K and cntB < K:\n                if wA <= wB:\n                    wA += w\n                    cntA += 1\n                    setA.append(idx)\n                else:\n                    wB += w\n                    cntB += 1\n                    setB.append(idx)\n            elif cntA < K:\n                wA += w\n                cntA += 1\n                setA.append(idx)\n            else:\n                wB += w\n                cntB += 1\n                setB.append(idx)\n        \n        # Local Descent (Swap heuristic)\n        # We want to minimize |wA - wB|\n        curr_diff_signed = wA - wB\n        improved = True\n        \n        while improved:\n            improved = False\n            best_reduction = 0.0\n            swap_pair = None\n            \n            # O(K^2) search for the best single swap\n            # For K ~ 8-16 this is very fast\n            for i_a, idx_a in enumerate(setA):\n                wa = weights[idx_a]\n                for i_b, idx_b in enumerate(setB):\n                    wb = weights[idx_b]\n                    \n                    # New difference if we swap a and b:\n                    # diff_new = (wA - wa + wb) - (wB - wb + wa) \n                    #          = (wA - wB) - 2*(wa - wb)\n                    change = 2.0 * (wa - wb)\n                    new_val = curr_diff_signed - change\n                    \n                    # Reduction in absolute difference\n                    reduction = abs(curr_diff_signed) - abs(new_val)\n                    \n                    if reduction > best_reduction + 1e-9:\n                        best_reduction = reduction\n                        swap_pair = (i_a, i_b, new_val)\n            \n            if swap_pair:\n                i_a, i_b, new_val = swap_pair\n                # Apply swap\n                tmp = setA[i_a]\n                setA[i_a] = setB[i_b]\n                setB[i_b] = tmp\n                curr_diff_signed = new_val\n                improved = True\n\n        final_diff = abs(curr_diff_signed)\n        if final_diff < best_diff:\n            best_diff = final_diff\n            best_set_A = list(setA)\n            if best_diff < 1e-6: break\n            \n    return best_set_A\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: processing on CPU for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    num_restarts = 3\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n            \n            # Greedy Phase\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Best Fit: Assign to the lightest pack that has space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n                \n            # 2. Refinement Phase\n            for _ in range(20):\n                # Sort packs by weight (heaviest to lightest)\n                sorted_packs = sorted(range(num_packs), key=lambda p: pack_weights[p], reverse=True)\n                max_p = sorted_packs[0]\n                max_w = pack_weights[max_p]\n                \n                improved = False\n                \n                # Strategy A: Reduce the Max Load\n                # Try to rebalance the heaviest pack with *any* other pack that is lighter.\n                # We iterate from lightest to heaviest (excluding max_p) to maximize probability of success.\n                for p_other in reversed(sorted_packs[1:]):\n                    w_other = pack_weights[p_other]\n                    \n                    # If packs are already balanced within epsilon, no need to pair\n                    if max_w - w_other < 1e-6:\n                        continue\n                    \n                    # Combine items and try to re-partition optimally\n                    pool = current_packs[max_p] + current_packs[p_other]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    \n                    # Solve 2-partition\n                    set_A_indices = solve_2_partition_restricted(pool_weights, groups_per_pack, max_iter=5)\n                    \n                    if set_A_indices is not None:\n                        # Reconstruct the new packs\n                        new_max_items = [pool[k] for k in set_A_indices]\n                        set_A_set = set(set_A_indices)\n                        new_other_items = [pool[k] for k in range(len(pool)) if k not in set_A_set]\n                        \n                        w_new_max = sum(row_weight_list[x] for x in new_max_items)\n                        w_new_other = sum(row_weight_list[x] for x in new_other_items)\n                        \n                        # We accept the change if it strictly reduces the maximum load of the pair.\n                        # Original max was max_w. New max is max(w_new_max, w_new_other).\n                        if max(w_new_max, w_new_other) < max_w - 1e-6:\n                            current_packs[max_p] = new_max_items\n                            current_packs[p_other] = new_other_items\n                            pack_weights[max_p] = w_new_max\n                            pack_weights[p_other] = w_new_other\n                            improved = True\n                            break\n                \n                if improved:\n                    continue\n\n                # Strategy B: 3-Way Rebalancing Fallback\n                # If 2-way rebalancing is stuck, try mixing 3 packs.\n                if num_packs >= 3:\n                    min_p = sorted_packs[-1]\n                    if max_p != min_p:\n                        # Pick a random third pack to disrupt local optima\n                        candidates = [p for p in range(num_packs) if p != max_p and p != min_p]\n                        if candidates:\n                            mid_p = random.choice(candidates)\n                            \n                            packs_3 = [max_p, min_p, mid_p]\n                            pool_3 = []\n                            for p in packs_3: pool_3.extend(current_packs[p])\n                            pool_3_weights = [row_weight_list[x] for x in pool_3]\n                            \n                            current_max_3 = max(pack_weights[p] for p in packs_3)\n                            best_ass_3 = None\n                            \n                            # Try randomized greedy re-packing\n                            for _sub in range(10):\n                                 noise_3 = [random.uniform(0.9, 1.1) for _ in pool_3]\n                                 sorted_3 = sorted(range(len(pool_3)), key=lambda i: pool_3_weights[i] * noise_3[i], reverse=True)\n                                 \n                                 bins = [0.0] * 3\n                                 cnts = [0] * 3\n                                 ass = [[] for _ in range(3)]\n                                 \n                                 for idx in sorted_3:\n                                     w = pool_3_weights[idx]\n                                     # Best fit\n                                     best_b = -1\n                                     min_b = float('inf')\n                                     for b in range(3):\n                                         if cnts[b] < groups_per_pack:\n                                             if bins[b] < min_b:\n                                                 min_b = bins[b]\n                                                 best_b = b\n                                     ass[best_b].append(idx)\n                                     bins[best_b] += w\n                                     cnts[best_b] += 1\n                                     \n                                 # Check if improved max load among these 3\n                                 if max(bins) < current_max_3 - 1e-6:\n                                     current_max_3 = max(bins)\n                                     best_ass_3 = ass\n                            \n                            if best_ass_3:\n                                for b_idx, p_idx in enumerate(packs_3):\n                                    new_items = [pool_3[x] for x in best_ass_3[b_idx]]\n                                    current_packs[p_idx] = new_items\n                                    pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n                                improved = True\n                \n                if not improved:\n                    break\n            \n            # Check global improvement\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Efficient incremental score tracking\n    # Score = weight / count. We pick the expert with max score to replicate.\n    current_scores = weight.clone() # Initial score is weight / 1.0\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "b96cb298-f1bc-4791-bc63-23f021d2c874",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "94d4b7e6-c563-44e1-a27d-a77047c8f7af"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 95,
      "timestamp": 1764181363.2440221,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,460 +1,521 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n import random\n import itertools\n+import math\n+\n+\n+def solve_2_partition_restricted(weights: list[float], K: int, max_iter: int = 5) -> list[int] | None:\n+    \"\"\"\n+    Partition items into two sets of size K to minimize weight difference.\n+    Returns indices of items in the first set (subset of range(2*K)).\n+    \"\"\"\n+    n = len(weights)\n+    # Target is half the total weight\n+    \n+    # Exact solver for small problems\n+    if n <= 14:\n+        total_weight = sum(weights)\n+        target = total_weight / 2.0\n+        best_diff = float('inf')\n+        best_comb = None\n+        # Fix first item in first set to break symmetry and reduce search space by half\n+        indices = list(range(1, n))\n+        w0 = weights[0]\n+        for comb in itertools.combinations(indices, K - 1):\n+            s = w0 + sum(weights[i] for i in comb)\n+            diff = abs(s - target)\n+            if diff < best_diff:\n+                best_diff = diff\n+                best_comb = (0,) + comb\n+                if best_diff < 1e-6: break\n+        return list(best_comb) if best_comb else None\n+\n+    # Heuristic solver for larger problems using Randomized Greedy + Local Descent\n+    indices = list(range(n))\n+    best_diff = float('inf')\n+    best_set_A = None\n+\n+    for attempt in range(max_iter):\n+        # Randomized Greedy Construction\n+        if attempt == 0:\n+            sorted_idx = sorted(indices, key=lambda i: weights[i], reverse=True)\n+        else:\n+            # Multiplicative noise 0.9 ~ 1.1\n+            noise = [random.uniform(0.9, 1.1) for _ in range(n)]\n+            sorted_idx = sorted(indices, key=lambda i: weights[i] * noise[i], reverse=True)\n+        \n+        wA, wB = 0.0, 0.0\n+        cntA, cntB = 0, 0\n+        setA = []\n+        setB = []\n+        \n+        for idx in sorted_idx:\n+            w = weights[idx]\n+            # Assign to the lighter bin if capacity allows\n+            if cntA < K and cntB < K:\n+                if wA <= wB:\n+                    wA += w\n+                    cntA += 1\n+                    setA.append(idx)\n+                else:\n+                    wB += w\n+                    cntB += 1\n+                    setB.append(idx)\n+            elif cntA < K:\n+                wA += w\n+                cntA += 1\n+                setA.append(idx)\n+            else:\n+                wB += w\n+                cntB += 1\n+                setB.append(idx)\n+        \n+        # Local Descent (Swap heuristic)\n+        # We want to minimize |wA - wB|\n+        curr_diff_signed = wA - wB\n+        improved = True\n+        \n+        while improved:\n+            improved = False\n+            best_reduction = 0.0\n+            swap_pair = None\n+            \n+            # O(K^2) search for the best single swap\n+            # For K ~ 8-16 this is very fast\n+            for i_a, idx_a in enumerate(setA):\n+                wa = weights[idx_a]\n+                for i_b, idx_b in enumerate(setB):\n+                    wb = weights[idx_b]\n+                    \n+                    # New difference if we swap a and b:\n+                    # diff_new = (wA - wa + wb) - (wB - wb + wa) \n+                    #          = (wA - wB) - 2*(wa - wb)\n+                    change = 2.0 * (wa - wb)\n+                    new_val = curr_diff_signed - change\n+                    \n+                    # Reduction in absolute difference\n+                    reduction = abs(curr_diff_signed) - abs(new_val)\n+                    \n+                    if reduction > best_reduction + 1e-9:\n+                        best_reduction = reduction\n+                        swap_pair = (i_a, i_b, new_val)\n+            \n+            if swap_pair:\n+                i_a, i_b, new_val = swap_pair\n+                # Apply swap\n+                tmp = setA[i_a]\n+                setA[i_a] = setB[i_b]\n+                setB[i_b] = tmp\n+                curr_diff_signed = new_val\n+                improved = True\n+\n+        final_diff = abs(curr_diff_signed)\n+        if final_diff < best_diff:\n+            best_diff = final_diff\n+            best_set_A = list(setA)\n+            if best_diff < 1e-6: break\n+            \n+    return best_set_A\n+\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n+\n+    Parameters:\n+        weight: [X, n], the weight of each item\n+        num_packs: number of packs\n+\n+    Returns:\n+        pack_index: [X, n], the pack index of each item\n+        rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     # Handle trivial case\n     if groups_per_pack == 1:\n         pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n                                   device=weight.device).expand(num_layers, -1)\n         rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n-    # CPU processing for complex sequential logic\n+    # Optimization: processing on CPU for scalar efficiency\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n \n-    # Heuristic parameters\n-    num_restarts = 2\n-    max_refine_steps = 20\n-\n+    num_restarts = 3\n+    \n     for i in range(num_layers):\n         row_weight = weight_cpu[i]\n         row_weight_list = row_weight.tolist()\n-\n+        \n         best_diff = float('inf')\n         best_packs = None\n-\n+        \n         # Base indices for deterministic LPT\n         base_indices = torch.argsort(row_weight, descending=True).tolist()\n-\n+        \n         for attempt in range(num_restarts):\n             # 1. Initialization\n+            current_packs = [[] for _ in range(num_packs)]\n+            pack_weights = [0.0] * num_packs\n+            \n             if attempt == 0:\n                 indices = base_indices\n             else:\n+                # Randomized LPT\n                 noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                 indices = torch.argsort(row_weight * noise, descending=True).tolist()\n-\n-            current_packs = [[] for _ in range(num_packs)]\n-            pack_weights = [0.0] * num_packs\n-\n-            # Greedy Packing\n+            \n+            # Greedy Phase\n             for group_idx in indices:\n                 w = row_weight_list[group_idx]\n+                # Best Fit: Assign to the lightest pack that has space\n                 best_p = -1\n                 min_val = float('inf')\n                 for p in range(num_packs):\n                     if len(current_packs[p]) < groups_per_pack:\n                         if pack_weights[p] < min_val:\n                             min_val = pack_weights[p]\n                             best_p = p\n                 current_packs[best_p].append(group_idx)\n                 pack_weights[best_p] += w\n-\n+                \n             # 2. Refinement Phase\n-            for step in range(max_refine_steps):\n-                # Identify max and min packs\n-                min_p = 0\n-                max_p = 0\n-                min_val = pack_weights[0]\n-                max_val = pack_weights[0]\n-\n-                # Random perturbation occasionally\n-                if step > 0 and step % 6 == 0:\n-                    p1 = random.randint(0, num_packs - 1)\n-                    p2 = random.randint(0, num_packs - 2)\n-                    if p2 >= p1: p2 += 1\n-                    max_p, min_p = p1, p2\n-                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n-                else:\n-                    for p in range(1, num_packs):\n-                        val = pack_weights[p]\n-                        if val < min_val:\n-                            min_val = val\n-                            min_p = p\n-                        elif val > max_val:\n-                            max_val = val\n-                            max_p = p\n-\n-                diff = max_val - min_val\n-                if diff < 1e-6:\n-                    if step % 6 != 0: break\n-                    else: continue\n-\n-                # Try 2-Pack Rebalancing\n-                pool = current_packs[max_p] + current_packs[min_p]\n-                pool_weights = [row_weight_list[x] for x in pool]\n-                total_pool = sum(pool_weights)\n-                target_half = total_pool / 2.0\n-                K = groups_per_pack\n-                pool_len = 2 * K\n-\n+            for _ in range(20):\n+                # Sort packs by weight (heaviest to lightest)\n+                sorted_packs = sorted(range(num_packs), key=lambda p: pack_weights[p], reverse=True)\n+                max_p = sorted_packs[0]\n+                max_w = pack_weights[max_p]\n+                \n                 improved = False\n-                best_dev = abs(pack_weights[max_p] - target_half)\n-                best_assignment = None\n-\n-                # EXACT SOLVER for small K\n-                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n-                if pool_len <= 14:\n-                    # Fix first element to be in Set A to reduce symmetry\n-                    indices_rest = list(range(1, pool_len))\n-                    w_0 = pool_weights[0]\n-\n-                    for comb in itertools.combinations(indices_rest, K - 1):\n-                        s = w_0\n-                        for idx in comb:\n-                            s += pool_weights[idx]\n-                        dev = abs(s - target_half)\n-                        if dev < best_dev - 1e-6:\n-                            best_dev = dev\n-                            best_assignment = (0,) + comb\n-                            if dev < 1e-6: break\n-                else:\n-                    # Heuristic Solver with Local Search\n-                    pool_indices = list(range(pool_len))\n-                    sub_trials = 15\n-                    for sub in range(sub_trials):\n-                        # 1. Randomized Greedy Construction\n-                        if sub == 0:\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n-                        else:\n-                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n-\n-                        w_A, w_B = 0.0, 0.0\n-                        cnt_A, cnt_B = 0, 0\n-                        set_A_local = []\n-                        set_B_local = []\n-\n-                        for idx in sorted_idx:\n-                            w = pool_weights[idx]\n-                            if cnt_A < K and cnt_B < K:\n-                                if w_A <= w_B:\n-                                    w_A += w\n-                                    cnt_A += 1\n-                                    set_A_local.append(idx)\n-                                else:\n-                                    w_B += w\n-                                    cnt_B += 1\n-                                    set_B_local.append(idx)\n-                            elif cnt_A < K:\n-                                w_A += w\n-                                cnt_A += 1\n-                                set_A_local.append(idx)\n-                            else:\n-                                w_B += w\n-                                cnt_B += 1\n-                                set_B_local.append(idx)\n-\n-                        # 2. Local Search (Swap)\n-                        # Iteratively improve the partition by swapping pairs\n-                        curr_diff = w_A - w_B\n-\n-                        while True:\n-                            # We want to reduce |curr_diff|.\n-                            # Swap a (from A) and b (from B).\n-                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n-                            #          = w_A - w_B - 2*wa + 2*wb\n-                            #          = curr_diff - 2*(wa - wb)\n-\n-                            if abs(curr_diff) < 1e-6: break\n-\n-                            best_swap_gain = 0.0\n-                            best_pair = None\n-\n-                            # O(K^2) scan\n-                            for i_a, idx_a in enumerate(set_A_local):\n-                                wa = pool_weights[idx_a]\n-                                for i_b, idx_b in enumerate(set_B_local):\n-                                    wb = pool_weights[idx_b]\n-\n-                                    change = 2.0 * (wa - wb)\n-                                    new_diff = curr_diff - change\n-\n-                                    # gain = reduction in absolute difference\n-                                    gain = abs(curr_diff) - abs(new_diff)\n-\n-                                    if gain > best_swap_gain + 1e-6:\n-                                        best_swap_gain = gain\n-                                        best_pair = (i_a, i_b, change, new_diff)\n-\n-                            if best_pair:\n-                                i_a, i_b, change, new_diff = best_pair\n-                                # Apply swap\n-                                val_a = set_A_local[i_a]\n-                                val_b = set_B_local[i_b]\n-                                set_A_local[i_a] = val_b\n-                                set_B_local[i_b] = val_a\n-\n-                                curr_diff = new_diff\n-                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n-                            else:\n-                                break\n-\n-                        dev = abs(w_A - target_half)\n-                        if dev < best_dev - 1e-6:\n-                            best_dev = dev\n-                            best_assignment = list(set_A_local)\n-                            if dev < 1e-6: break\n-\n-                if best_assignment is not None:\n-                    set_A_indices = set(best_assignment)\n-                    new_max = [pool[i] for i in best_assignment]\n-                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n-                    current_packs[max_p] = new_max\n-                    current_packs[min_p] = new_min\n-                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n-                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n-                    improved = True\n-\n-                # 3-Way Rebalancing Fallback\n-                if not improved and num_packs >= 3:\n-                     # Pick random 3rd pack\n-                     while True:\n-                         mid_p = random.randint(0, num_packs - 1)\n-                         if mid_p != max_p and mid_p != min_p: break\n-\n-                     packs_3 = [max_p, min_p, mid_p]\n-                     pool_3 = []\n-                     for p in packs_3:\n-                         pool_3.extend(current_packs[p])\n-\n-                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n-                     total_3 = sum(pool_3_weights)\n-\n-                     # Check if we can improve deviation of these 3 packs\n-                     current_loads = [pack_weights[p] for p in packs_3]\n-                     best_spread_3 = max(current_loads) - min(current_loads)\n-\n-                     pool_3_indices = list(range(3 * K))\n-                     best_assignment_3 = None\n-\n-                     for sub in range(20):\n-                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n-                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n-\n-                         bins = [0.0] * 3\n-                         counts = [0] * 3\n-                         assignment = [[] for _ in range(3)]\n-\n-                         for idx in sorted_idx:\n-                             w = pool_3_weights[idx]\n-                             # Assign to valid bin with min load\n-                             best_b = -1\n-                             min_b_val = float('inf')\n-                             for b in range(3):\n-                                 if counts[b] < K:\n-                                     if bins[b] < min_b_val:\n-                                         min_b_val = bins[b]\n-                                         best_b = b\n-                             bins[best_b] += w\n-                             counts[best_b] += 1\n-                             assignment[best_b].append(idx)\n-\n-                         spread = max(bins) - min(bins)\n-                         if spread < best_spread_3 - 1e-6:\n-                             best_spread_3 = spread\n-                             best_assignment_3 = assignment\n-\n-                     if best_assignment_3 is not None:\n-                         for b_idx, p_idx in enumerate(packs_3):\n-                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n-                             current_packs[p_idx] = new_items\n-                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n-\n-            # Check result\n+                \n+                # Strategy A: Reduce the Max Load\n+                # Try to rebalance the heaviest pack with *any* other pack that is lighter.\n+                # We iterate from lightest to heaviest (excluding max_p) to maximize probability of success.\n+                for p_other in reversed(sorted_packs[1:]):\n+                    w_other = pack_weights[p_other]\n+                    \n+                    # If packs are already balanced within epsilon, no need to pair\n+                    if max_w - w_other < 1e-6:\n+                        continue\n+                    \n+                    # Combine items and try to re-partition optimally\n+                    pool = current_packs[max_p] + current_packs[p_other]\n+                    pool_weights = [row_weight_list[x] for x in pool]\n+                    \n+                    # Solve 2-partition\n+                    set_A_indices = solve_2_partition_restricted(pool_weights, groups_per_pack, max_iter=5)\n+                    \n+                    if set_A_indices is not None:\n+                        # Reconstruct the new packs\n+                        new_max_items = [pool[k] for k in set_A_indices]\n+                        set_A_set = set(set_A_indices)\n+                        new_other_items = [pool[k] for k in range(len(pool)) if k not in set_A_set]\n+                        \n+                        w_new_max = sum(row_weight_list[x] for x in new_max_items)\n+                        w_new_other = sum(row_weight_list[x] for x in new_other_items)\n+                        \n+                        # We accept the change if it strictly reduces the maximum load of the pair.\n+                        # Original max was max_w. New max is max(w_new_max, w_new_other).\n+                        if max(w_new_max, w_new_other) < max_w - 1e-6:\n+                            current_packs[max_p] = new_max_items\n+                            current_packs[p_other] = new_other_items\n+                            pack_weights[max_p] = w_new_max\n+                            pack_weights[p_other] = w_new_other\n+                            improved = True\n+                            break\n+                \n+                if improved:\n+                    continue\n+\n+                # Strategy B: 3-Way Rebalancing Fallback\n+                # If 2-way rebalancing is stuck, try mixing 3 packs.\n+                if num_packs >= 3:\n+                    min_p = sorted_packs[-1]\n+                    if max_p != min_p:\n+                        # Pick a random third pack to disrupt local optima\n+                        candidates = [p for p in range(num_packs) if p != max_p and p != min_p]\n+                        if candidates:\n+                            mid_p = random.choice(candidates)\n+                            \n+                            packs_3 = [max_p, min_p, mid_p]\n+                            pool_3 = []\n+                            for p in packs_3: pool_3.extend(current_packs[p])\n+                            pool_3_weights = [row_weight_list[x] for x in pool_3]\n+                            \n+                            current_max_3 = max(pack_weights[p] for p in packs_3)\n+                            best_ass_3 = None\n+                            \n+                            # Try randomized greedy re-packing\n+                            for _sub in range(10):\n+                                 noise_3 = [random.uniform(0.9, 1.1) for _ in pool_3]\n+                                 sorted_3 = sorted(range(len(pool_3)), key=lambda i: pool_3_weights[i] * noise_3[i], reverse=True)\n+                                 \n+                                 bins = [0.0] * 3\n+                                 cnts = [0] * 3\n+                                 ass = [[] for _ in range(3)]\n+                                 \n+                                 for idx in sorted_3:\n+                                     w = pool_3_weights[idx]\n+                                     # Best fit\n+                                     best_b = -1\n+                                     min_b = float('inf')\n+                                     for b in range(3):\n+                                         if cnts[b] < groups_per_pack:\n+                                             if bins[b] < min_b:\n+                                                 min_b = bins[b]\n+                                                 best_b = b\n+                                     ass[best_b].append(idx)\n+                                     bins[best_b] += w\n+                                     cnts[best_b] += 1\n+                                     \n+                                 # Check if improved max load among these 3\n+                                 if max(bins) < current_max_3 - 1e-6:\n+                                     current_max_3 = max(bins)\n+                                     best_ass_3 = ass\n+                            \n+                            if best_ass_3:\n+                                for b_idx, p_idx in enumerate(packs_3):\n+                                    new_items = [pool_3[x] for x in best_ass_3[b_idx]]\n+                                    current_packs[p_idx] = new_items\n+                                    pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n+                                improved = True\n+                \n+                if not improved:\n+                    break\n+            \n+            # Check global improvement\n             current_diff = max(pack_weights) - min(pack_weights)\n             if current_diff < best_diff:\n                 best_diff = current_diff\n                 best_packs = [list(p) for p in current_packs]\n                 if best_diff < 1e-6:\n                     break\n-\n-        # Fill tensors\n+        \n+        # Fill result tensors\n         for p in range(num_packs):\n             for r, g in enumerate(best_packs[p]):\n                 pack_index[i, g] = p\n                 rank_in_pack[i, g] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n+\n+    Parameters:\n+        weight: [X, num_log]\n+        num_phy: total number of experts after replication\n+\n+    Returns:\n+        phy2log: [X, num_phy], logical expert id of each physical expert\n+        rank: [X, num_phy], the replica rank\n+        logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n-\n+    \n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n-\n-    # Efficient incremental update of scores\n-    current_scores = weight.clone() # weight / 1\n-\n+    \n+    # Efficient incremental score tracking\n+    # Score = weight / count. We pick the expert with max score to replicate.\n+    current_scores = weight.clone() # Initial score is weight / 1.0\n+    \n     for i in range(num_log, num_phy):\n-        # Pick expert with max current load\n+        # Find expert with max current average load\n         redundant_indices = current_scores.max(dim=-1).indices\n-\n+        \n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n-\n+        \n+        # Update counts\n         logcnt[arangen, redundant_indices] += 1\n-\n-        # Update score: weight / new_count\n+        \n+        # Update scores only for changed experts\n         selected_weights = weight[arangen, redundant_indices]\n         selected_counts = logcnt[arangen, redundant_indices].float()\n         current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n-\n+        \n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n-    Hierarchical rebalancing strategy.\n+    Parameters:\n+        weight: [num_moe_layers, num_logical_experts]\n+        num_physical_experts: number of physical experts after replication\n+        num_groups: number of expert groups\n+        num_nodes: number of server nodes, where the intra-node network\n+        (e.g, NVLink) is faster\n+        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n+\n+    Returns:\n+        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n+        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n+        logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n+    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n+    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n-        -1, pphy2phy)\n+        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n+\n+    Parameters:\n+        weight: [layers, num_logical_experts], the load statistics for all\n+            logical experts\n+        num_replicas: number of physical experts, must be a multiple of\n+            `num_gpus`\n+        num_groups: number of expert groups\n+        num_nodes: number of server nodes, where the intra-node network\n+            (e.g, NVLink) is faster\n+        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n+\n+    Returns:\n+        physical_to_logical_map: [layers, num_replicas], the expert index of\n+            each replica\n+        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n+            indices for each expert\n+        expert_count: [layers, num_logical_experts], number of physical\n+            replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n+\n+\n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385904468268,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.31107718089365366,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.05267054,
        0.023268994,
        0.014683417,
        -0.037049882,
        -0.027492356,
        0.012646946,
        -0.009285613,
        -0.009441819,
        -0.025409602,
        0.031565297,
        0.031287596,
        0.024645925,
        -0.0074227047,
        -0.020087007,
        0.015435523,
        0.016650463,
        -0.0042870026,
        0.018119961,
        -0.004848189,
        0.05438303,
        0.0071218624,
        -0.011802274,
        0.02404424,
        -0.041539375,
        -0.0012749638,
        0.012982502,
        0.05822455,
        -0.043529563,
        0.033115793,
        -0.047903348,
        0.08048688,
        -0.0092624705,
        0.012554379,
        -0.00020700986,
        -0.014579279,
        0.036980458,
        -0.0075152717,
        0.010726185,
        0.013931312,
        0.061742093,
        0.028649442,
        -0.02689067,
        -0.05063407,
        0.041631944,
        -0.036401916,
        0.028533733,
        0.0080648875,
        -0.0075962674,
        0.07659907,
        0.0036997814,
        0.0364482,
        0.016361192,
        -0.0015895464,
        0.06493565,
        0.025085617,
        0.046514843,
        0.016581038,
        0.02107053,
        0.01471813,
        -0.047347944,
        0.053040806,
        -0.018872067,
        0.07002682,
        0.045959443,
        -0.03228269,
        0.0034249737,
        -0.03684161,
        0.027770055,
        0.021521794,
        -0.008967414,
        -0.037906125,
        0.044223815,
        -0.021811064,
        -0.031958707,
        -0.0012749638,
        0.009193046,
        -0.024553359,
        0.042372476,
        -0.024067381,
        -0.041932784,
        -0.03202813,
        -0.006763166,
        0.050078668,
        0.020815972,
        0.011217945,
        -0.07747845,
        -0.02185735,
        -0.038276393,
        -0.03337035,
        -0.028302316,
        0.029760243,
        -0.049153,
        -0.002332974,
        0.030847903,
        0.044246957,
        -0.032352116,
        0.06382485,
        0.011096451,
        0.029899094,
        0.05762287,
        -0.009528601,
        0.018964635,
        -0.055030994,
        0.0002901754,
        0.027098946,
        0.0064333966,
        0.008018604,
        0.0004006409,
        0.014498283,
        -0.021591218,
        -0.03376376,
        0.017402569,
        0.03200499,
        0.014359433,
        0.016777743,
        0.0017819119,
        -0.044339523,
        -0.020191146,
        0.011808059,
        -0.025918718,
        -0.024599642,
        -0.040729415,
        0.02686753,
        -0.025039334,
        0.0076251947,
        -0.03466629,
        0.0064276108,
        -0.03552253,
        0.013318056,
        -0.0008656447,
        0.04332129,
        0.025062475,
        0.009343467,
        -0.021938344,
        -0.019496894,
        0.002539803,
        -0.02026057,
        0.0055337623,
        -0.008383086,
        -0.017645556,
        -0.02756178,
        0.028510591,
        -0.013931312,
        -0.005357307,
        -0.049060434,
        0.0497084,
        -0.0011809506,
        0.014914835,
        -0.047185954,
        0.033277784,
        0.017842261,
        -0.040590566,
        -0.00945339,
        -0.009326111,
        0.00011597976,
        -0.013132922,
        0.008012818,
        0.020827543,
        0.07891324,
        -0.03443487,
        -0.03186614,
        0.029065993,
        -0.027168373,
        0.025941862,
        0.03401832,
        0.027469214,
        -0.047093388,
        0.0075962674,
        -0.06049244,
        -0.06336201,
        -0.005423839,
        -0.025363319,
        -0.008215308,
        -0.011929553,
        0.0011520234,
        0.015018973,
        -0.023859106,
        -0.03119503,
        -0.027862623,
        -0.040474858,
        -0.020815972,
        -0.014428859,
        -0.018409234,
        -0.0061556958,
        -0.048458748,
        0.0291817,
        -0.030084228,
        -0.014949547,
        -0.013514761,
        -0.007335923,
        0.01903406,
        0.04512634,
        -0.036795326,
        0.033138935,
        -0.0030894189,
        -0.014440429,
        0.053642493,
        0.01984402,
        0.00030644692,
        -0.0023705794,
        -0.041030258,
        -0.017171152,
        0.036124215,
        -0.042465046,
        0.043275006,
        0.03390261,
        -0.0104600545,
        0.016824026,
        0.009725305,
        -0.003621678,
        0.033995178,
        -0.025895577,
        0.03309265,
        0.00061759446,
        -0.017529849,
        -0.02797833,
        -0.04808848,
        0.017483564,
        0.004107654,
        0.07155418,
        -0.022123478,
        0.023581406,
        -0.02658983,
        0.0061556958,
        -0.043205578,
        0.020168003,
        0.04725538,
        -0.02013329,
        0.0064854654,
        0.00702351,
        -0.030014802,
        0.0006624315,
        -0.013028785,
        -0.025432743,
        0.034365445,
        -0.03010737,
        -0.040590566,
        0.020908538,
        -0.018814214,
        -0.03887808,
        0.013966024,
        0.03943348,
        0.007839255,
        -0.044825498,
        0.006236692,
        0.014301579,
        -0.039803747,
        -0.01608349,
        0.0039022714,
        -0.028325457,
        0.022354895,
        -0.04686197,
        0.022702022,
        -0.05766915,
        -0.015643798,
        0.031889282,
        -0.017263718,
        -0.052022573,
        -0.016465329,
        -0.026173279,
        0.008307875,
        -0.015817361,
        -0.0024038455,
        -0.026705537,
        -0.021799494,
        0.0015331386,
        -0.0038299535,
        0.038322676,
        -0.04632971,
        -0.021660645,
        0.02901971,
        0.016835596,
        -0.016407475,
        0.032629818,
        -0.04376098,
        -0.017714981,
        0.0014000736,
        -0.012184112,
        -0.03987317,
        -0.046237145,
        -0.02307229,
        -0.0010399307,
        0.041932784,
        -0.00065266865,
        0.01459085,
        -0.002949122,
        -0.0033584412,
        0.0323984,
        0.010107144,
        -0.01971674,
        0.007237571,
        -0.020850684,
        0.04128482,
        0.012484955,
        -0.009245114,
        -0.022505317,
        -0.05817827,
        -0.019288618,
        8.6736225e-05,
        -0.012994072,
        0.012508096,
        -0.0047729784,
        -0.007821899,
        0.012878364,
        -0.0048713307,
        -0.02538646,
        -0.015007401,
        0.022783017,
        -0.019381186,
        -0.025965003,
        -0.013989165,
        0.009302969,
        -0.020156432,
        0.0009278381,
        -0.03144959,
        -0.0022056946,
        0.033532344,
        -0.0024660388,
        -0.012091545,
        -0.05155974,
        -0.056280646,
        -0.04781078,
        0.03499027,
        0.021996198,
        0.0023835965,
        0.020040724,
        -0.04674626,
        0.01851337,
        -0.007521057,
        -0.018339807,
        0.0058779954,
        0.043136153,
        0.033509202,
        0.024761634,
        0.0065143923,
        -0.041655086,
        0.03105618,
        -0.0037373868,
        0.04494121,
        0.019867161,
        -0.05998332,
        0.023812823,
        -0.016754601,
        -0.022621024,
        -0.045404043,
        0.01714801,
        0.06007589,
        0.033347208,
        0.024831058,
        0.076876774,
        -0.03630935,
        -0.01566694,
        -0.015875215,
        0.016384333,
        0.012704801,
        -0.018999347,
        0.0047122315,
        0.0073069963,
        -0.043946113,
        0.002494966,
        -0.02580301,
        -0.002506537,
        0.032074414,
        -0.008701284,
        -0.0076194094,
        0.06317688,
        0.025941862,
        0.017333144,
        0.00702351,
        0.009372394,
        0.04241876,
        -0.0065143923,
        -0.02215819,
        0.002312725,
        -0.014116446,
        -0.014810697,
        0.021128384,
        0.05604923,
        -0.025548453,
        0.0037634212,
        0.021764781,
        0.016581038,
        -0.018247241,
        0.012936218,
        0.02107053,
        0.033115793,
        -0.012739513,
        0.019925015,
        -0.07238728,
        0.008192167,
        0.049754683,
        -0.011501431,
        -0.013283344,
        -0.044108108,
        0.035684522,
        -0.016141346,
        -0.035545673,
        -0.02243589,
        0.045959443,
        0.0122651085,
        -0.01006086,
        0.0050593573,
        -0.043575846,
        -0.01876793,
        -0.024622783,
        0.014000737,
        0.048782732,
        0.016974447,
        -0.0057622865,
        0.04292788,
        0.034064602,
        -0.032537248,
        0.012959359,
        0.004920507,
        0.0124502415,
        -0.035059698,
        0.00580857,
        0.03670276,
        -0.00026504495,
        -0.011472505,
        -0.009684807,
        -0.008880633,
        0.015724795,
        -0.010610476,
        -0.015065256,
        0.01755299,
        0.020422563,
        -0.013665182,
        0.011090666,
        -0.061371826,
        -0.011975837,
        0.0059474204,
        0.063454576,
        -0.029551968,
        0.020827543,
        0.039618615,
        -0.0036303564,
        0.027237797,
        -0.0039543402,
        -0.0026396017,
        0.0032745525,
        -0.01689345,
        -0.008660787,
        -0.016986018,
        0.02336156,
        -0.01006086,
        0.0089732,
        -0.051050622,
        0.05604923,
        -0.009279828,
        0.018154675,
        -0.019624174,
        0.05378134,
        0.0024616998,
        -0.020006012,
        -0.056141797,
        0.07294268,
        0.027932048,
        0.048412465,
        -0.022111908,
        0.04267332,
        0.018478658,
        -0.0013675307,
        -0.027075805,
        0.054105327,
        0.01836295,
        0.012496525,
        -0.0058693173,
        0.009326111,
        0.025687302,
        0.061510675,
        -0.05091177,
        -0.0066821696,
        0.0370036,
        -0.028325457,
        0.008695499,
        -0.012959359,
        0.069749124,
        0.027608065,
        -0.044663507,
        0.032537248,
        -0.04818105,
        -0.033948895,
        -0.04251133,
        0.029413117,
        0.023130143,
        0.033578627,
        0.0032600889,
        0.00303735,
        0.02876515,
        0.024275657,
        -0.015412381,
        0.009696378,
        -0.010199711,
        0.002652619,
        -0.0030691698,
        -0.013260202,
        -0.030616486,
        0.004917614,
        0.04535776,
        0.00081863813,
        -0.08312503,
        -0.057993133,
        -0.025224468,
        0.017761266,
        -0.03524483,
        -0.029065993,
        0.0003234416,
        -0.003309265,
        0.040752556,
        -0.020410992,
        -0.008273163,
        0.026427837,
        0.03038507,
        -0.008950057,
        0.040821984,
        -0.0035377895,
        0.008371515,
        0.008342587,
        0.032884374,
        -0.030593345,
        -0.022459034,
        -0.05174487,
        0.02608071,
        0.0291817,
        -0.034342304,
        -0.015863644,
        -0.052577972,
        0.015852073,
        -0.0061383396,
        -0.014336292,
        -0.011952695,
        -0.05049522,
        0.028001474,
        -0.018883638,
        0.027608065,
        -0.0002560052,
        -0.040197156,
        -0.026682395,
        -0.034226593,
        0.006346615,
        0.014660276,
        0.015088397,
        0.022366466,
        0.01404702,
        -0.039202064,
        0.07076736,
        0.026913812,
        0.026636112,
        0.02658983,
        0.0062829754,
        -0.043298148,
        0.0059532057,
        -0.003401832,
        -0.033532344,
        -0.019358043,
        -0.008007033,
        -0.04373784,
        0.025039334,
        0.048273616,
        0.021001104,
        -0.0013508975,
        0.010234423,
        -0.0008468421,
        -0.00023738336,
        0.008203737,
        0.024923626,
        -0.041423667,
        0.013838745,
        0.0061672665,
        -0.011952695,
        0.014174299,
        0.013572615,
        -0.06289918,
        0.024807917,
        -0.0040845126,
        0.02350041,
        -0.028603159,
        -0.0039254134,
        -0.007723547,
        -0.029667677,
        -0.022528458,
        -0.015817361,
        -0.02982967,
        -0.055308696,
        -0.010350131,
        -0.028348599,
        -0.013422194,
        -0.0037084597,
        -0.030199936,
        -0.0057854285,
        8.637464e-05,
        0.03887808,
        -0.018166246,
        0.014671846,
        -0.008718641,
        -0.035175405,
        0.013676752,
        0.02714523,
        0.0070292954,
        -0.016650463,
        0.06609274,
        0.0040729414,
        0.019508464,
        -0.028996566,
        0.0038212754,
        0.012033691,
        0.007278069,
        0.0017775729,
        -0.029806526,
        -0.010026148,
        -0.019091913,
        -0.02820975,
        -0.0065201777,
        -0.012461813,
        -0.00041944356,
        0.05470701,
        0.00425229,
        0.010396414,
        -0.020110149,
        -0.009522815,
        0.04209478,
        0.006930943,
        -0.014891692,
        0.000976291,
        -0.007850827,
        -0.009684807,
        -0.0062424773,
        -0.02795519,
        0.014266866,
        -0.038692944,
        -0.015285102,
        -0.02619642,
        0.028742008,
        -0.004243612,
        0.06433396,
        0.024229374,
        0.0410534,
        0.007573126,
        -0.010587334,
        0.027631206,
        -0.007075579,
        0.016187629,
        -0.04362213,
        0.013063497,
        0.02336156,
        -0.0020928788,
        -0.002701795,
        0.0065375343,
        -0.011796488,
        -0.0014637134,
        -0.020098578,
        0.033277784,
        0.036934175,
        0.031171888,
        -0.013838745,
        -0.011530358,
        -0.03381004,
        -0.033578627,
        0.00088878645,
        -0.033925753,
        -0.007810328,
        -0.012369246,
        -0.023141714,
        0.016696746,
        0.023951674,
        0.023743398,
        0.0037431722,
        0.0045010634,
        0.048829015,
        -0.0022331753,
        0.028256033,
        0.029274268,
        -0.046237145,
        -0.03862352,
        -0.018073678,
        -0.02390539,
        0.011032812,
        0.00055106205,
        0.021035818,
        0.01107331,
        -0.018999347,
        -0.031079322,
        -0.0062077646,
        -0.010240208,
        0.025525311,
        0.024599642,
        -0.0029274267,
        0.0337869,
        -0.024090525,
        0.013653611,
        -0.014984259,
        -0.037373867,
        -0.015111539,
        0.013549473,
        0.046399135,
        0.0108013945,
        0.011316298,
        -0.018247241,
        -0.04568174,
        -0.014232154,
        0.00016750624,
        -0.024877341,
        -0.0097137345,
        -0.038415246,
        -0.012045262,
        -0.046514843,
        0.04873645,
        0.026774963,
        -0.005172173,
        -0.03809126,
        0.0026844388,
        -0.020364707,
        -0.018698504,
        -0.0675738,
        0.004836618,
        0.0025687302,
        0.013086639,
        0.026427837,
        -0.03901693,
        -0.009968293,
        -0.001968492,
        -0.03887808,
        0.0034047246,
        0.04727852,
        0.014509855,
        0.014405717,
        0.0047816564,
        0.006271404,
        -0.0006233799,
        0.015227248,
        -0.015354527,
        0.014937976,
        -0.03459686,
        0.038114402,
        -0.009418678,
        -0.002726383,
        -0.029806526,
        -0.02337313,
        0.013399052,
        -0.009470746,
        -0.022447463,
        0.014891692,
        -0.0050593573,
        0.007972321,
        0.00067544874,
        -0.0018976205,
        0.031079322,
        -0.018872067,
        0.024113666,
        -0.033254642,
        0.00661853,
        -0.02739979,
        -0.0005384064,
        0.039919455,
        0.035453103,
        0.015018973,
        -0.0053081308,
        -0.0036882106,
        0.0054643373,
        -0.017043872,
        -0.016847167,
        -0.02175321,
        0.014509855,
        0.014035449,
        0.004370891,
        -0.050726637,
        -0.005721789,
        0.008105385,
        -0.0378367,
        -0.02012172,
        -0.008261592,
        0.04484864,
        0.051004335,
        0.024113666,
        -0.037998695,
        0.014486712,
        -0.05498471,
        0.007359065,
        -0.019832449,
        -0.017344715,
        -0.022609454,
        -0.031495873,
        0.0056234365,
        0.002899946,
        -0.0009712288,
        -0.05535498,
        -0.022401178,
        -0.009476531,
        -0.011738635,
        -0.063130595,
        -0.016453758,
        0.0013725929,
        -0.02201934,
        -0.01579422,
        0.013491619,
        -0.04010459,
        -0.056234363,
        0.009349252,
        0.017113296,
        -0.0037113524,
        0.003127024,
        0.024530217,
        -0.0041279034,
        -0.010795609,
        -0.01188327,
        -0.053503644,
        0.0039340914,
        -0.040775698,
        0.018212529,
        0.019115055,
        0.0022129263,
        -0.028117182,
        0.007185502,
        0.0645191,
        -0.021591218,
        -0.049523268,
        -0.04332129,
        0.027723772,
        -0.009690593,
        -0.024645925,
        -0.045427185,
        0.041955926,
        0.010251779,
        -0.04901415,
        -0.014128016,
        -0.010436913,
        0.004341964,
        0.009545957,
        -0.018791072,
        0.002762542,
        -0.026103852,
        0.007723547,
        0.012866793,
        0.0062598335,
        0.016233912,
        0.00796075,
        -0.00408162,
        -0.007764045,
        0.022644166,
        0.032328974,
        0.0071507897,
        0.0024327727,
        -0.027307222,
        0.0164769,
        0.009181475,
        0.04068313,
        0.03501341,
        -0.0248542,
        -0.015250389,
        -0.020688692,
        0.014301579,
        0.024900483,
        -0.009783159,
        -0.010361702,
        0.01607192,
        0.01769184,
        -0.008487224,
        0.019149767,
        -0.004784549,
        -0.017529849,
        -0.042488188,
        0.010633618,
        -0.030292504,
        0.0034799352,
        -0.021313518,
        0.026265845,
        0.031935565,
        -0.0090136975,
        -0.0026019965,
        0.013746178,
        -0.031009896,
        0.019057201,
        0.020792829,
        -0.012774226,
        -0.019115055,
        -0.016766172,
        0.017587703,
        -0.037096165,
        -0.010003006,
        -0.0020914325,
        -0.013468477,
        -0.011692351,
        0.006508607,
        0.0012648393,
        0.018085249,
        0.007335923,
        -0.003685318,
        0.035291113,
        0.02336156,
        -0.002240407,
        0.0044258526,
        0.016962877,
        0.019462181,
        0.030269362,
        0.027168373,
        -0.003714245,
        0.0020596124,
        0.02878829,
        -0.0010876606,
        -0.011298941,
        0.002442897,
        -0.015493377,
        0.046352852,
        -0.021579647,
        -0.0108187515,
        -0.009227758,
        0.00864343,
        0.028695725,
        -0.050680354,
        0.072988965,
        -0.013885028,
        -0.032375257,
        -0.007995462,
        0.0044923853,
        -0.026705537,
        0.013942882,
        0.025317036,
        0.010795609,
        -0.0025369104,
        0.02499305,
        -0.022250758,
        0.006792093,
        0.013572615,
        0.014394145,
        -0.0009126513,
        0.0133064855,
        -0.033948895,
        0.053920195,
        -0.011582428,
        0.017090155,
        -0.016002495,
        0.022378037,
        -0.0018310881,
        0.0055395477,
        -0.014278437,
        -0.014139587,
        -0.009071552,
        -0.016685175,
        0.00320802,
        -0.049245566,
        -0.0099162245,
        -0.003381583,
        0.016858738,
        -0.03348606,
        -0.033740617,
        -0.0038849153,
        -0.012843651,
        -0.01540081,
        -0.019277047,
        0.029089134,
        -0.052022573,
        0.056141797,
        0.0031385948,
        -0.028996566,
        0.031843,
        0.0056407927,
        -0.0048134765,
        0.0031125604,
        0.01795797,
        0.038970646,
        0.0002055635,
        -0.017182723,
        0.0019265476,
        0.010147641,
        0.012565951,
        0.0073995627,
        -0.0042378264,
        -0.04892158,
        0.009274041,
        0.03404146,
        -0.016812455,
        0.024761634,
        -0.005759394,
        0.0073648505,
        -0.045866877,
        0.011501431,
        -0.014162729,
        0.05336479,
        -0.016361192,
        0.017483564,
        0.0069078016,
        -0.040752556,
        0.029598251,
        0.05498471,
        -0.003916735,
        0.04447837,
        0.0028305207,
        0.007185502,
        -0.025756728,
        0.057021182,
        0.026728678,
        0.0060804854,
        -0.006699526,
        0.009245114,
        0.01309821,
        -0.012172542,
        -0.02295658,
        -0.020237429,
        -0.0032861233,
        -0.03806812,
        0.0062019792,
        0.026566688,
        -0.004318822,
        0.013318056,
        0.0047324803,
        0.020561412,
        -0.019057201,
        0.0097137345,
        0.0059474204,
        0.026821246,
        -0.034550577,
        -0.015285102,
        0.014926406,
        -0.037373867,
        -0.015099968,
        -0.03304637,
        0.007810328,
        -0.029389976,
        -0.0064333966,
        -0.00661853,
        -0.044663507,
        0.0022577634,
        -0.009407107,
        -0.014625563,
        0.00951703,
        0.026103852,
        -0.045982584,
        0.021544935,
        -0.022111908,
        0.024738492,
        -0.006913587,
        -0.029135417,
        0.018825784,
        -0.010483196,
        -0.041655086,
        -0.0052589546,
        0.028279174,
        0.021301948,
        0.002722044,
        -0.025016192,
        0.030824762,
        -0.028510591,
        0.01823567,
        0.029389976,
        -0.006838376,
        -0.006387113,
        0.010841893,
        -0.015134681,
        -0.0070524374,
        -0.055678964,
        -0.0043998184,
        -0.005849068,
        0.029945377,
        0.029505685,
        0.021973057,
        -0.0024530217,
        0.0028044863,
        -0.003835739,
        -0.0092509,
        0.016581038,
        0.003219591,
        -0.043251865,
        -0.018860497,
        0.011449363,
        0.009326111,
        -0.02809404,
        -0.024229374,
        0.0005029707,
        -0.0016792206,
        -0.0013328181,
        0.007764045,
        -0.016419046,
        0.019010918,
        0.012126258,
        0.00028493235,
        0.0018036073,
        0.015690083,
        -0.0069367285,
        -0.043946113,
        -0.0016112418,
        0.0044923853,
        -0.0037402795,
        -0.0035291114,
        -0.014984259,
        0.040613707,
        0.0358928,
        -0.00024551913,
        0.013954453,
        -0.025872435,
        -0.0067226677,
        0.021718498,
        0.02739979,
        -0.008435154,
        0.012959359,
        -0.02186892,
        0.016361192,
        0.013283344,
        -0.024321942,
        0.010552621,
        0.0029881739,
        0.0050738207,
        -0.0027914692,
        -0.010026148,
        -0.024391366,
        -0.041817077,
        -0.010882391,
        -0.007370636,
        0.025016192,
        -0.0069772266,
        0.031843,
        -0.016870309,
        0.023812823,
        0.030223077,
        -0.0034162954,
        -0.025293892,
        0.0013067836,
        -0.005646578,
        0.022123478,
        0.018374521,
        -0.02756178,
        0.002463146,
        -0.02957511,
        0.03300008,
        -0.032352116,
        -0.004819262,
        0.005406483,
        0.028927142,
        0.0142090125,
        -0.0009343467,
        0.026728678,
        -0.06063129,
        0.037211876,
        0.021093672,
        -0.005496157,
        -0.021290377,
        -0.03418031,
        0.0077987574,
        -0.0050940695,
        0.031634722,
        0.00092639175,
        -0.018663792,
        0.037975553,
        0.016245482,
        0.0016763279,
        -0.0037836703,
        0.008446725,
        0.07377578,
        0.0061499104,
        -0.0044866,
        0.0075673405,
        0.010170783,
        0.027908906,
        -0.020110149,
        -0.0053688777,
        0.019763023,
        -0.039502904,
        -0.026774963,
        0.032467823,
        -0.005718896,
        -0.020549841,
        -0.0039514476,
        0.02161436,
        -0.04200221,
        0.016257053,
        -0.019786166,
        0.017101726,
        -0.008990556,
        -0.00076295336,
        -0.0050159665,
        -0.025409602,
        0.0006779799,
        -0.03265296,
        0.0036968887,
        -0.019161338,
        -0.01688188,
        0.020341566,
        -0.023835965,
        -0.02957511,
        0.007954964,
        0.0049147215,
        -0.013213919,
        0.016048778,
        0.018825784,
        0.0013198009,
        -0.0012019228,
        0.008921131,
        -0.01350319,
        -0.0013697002,
        -0.03198185,
        -0.016430616,
        -0.019277047,
        -0.005293667,
        -0.014926406,
        0.016523184,
        0.012045262,
        0.0023705794,
        0.006456538,
        -0.01459085,
        0.007046652,
        -0.021301948,
        -0.025201326,
        -0.0006371203,
        0.033694334,
        0.063686,
        -0.03987317,
        0.008932701,
        -0.008342587,
        -0.005577153,
        -0.006497036,
        0.027538639,
        0.018166246,
        -0.022297041,
        -0.017171152,
        -0.026936954,
        -0.013815603,
        0.028441167,
        -0.027538639,
        -0.0008193613,
        -0.005883781,
        -0.02284087,
        0.029505685,
        -0.006728453,
        -0.010859249,
        0.025525311,
        0.019693598,
        -0.03482828,
        -0.0121494,
        0.0036882106,
        -0.0039196275,
        0.012195683,
        -0.030431353,
        -0.025733586,
        0.03496713,
        0.020329995,
        -0.029065993,
        0.0062598335,
        -0.004208899,
        0.02120938,
        0.025085617,
        0.038669802,
        -0.019658886,
        -0.014243725,
        -0.0051056407,
        -0.0092509,
        -0.014371004,
        0.026358413,
        -0.012299821,
        0.012947788,
        0.017599273,
        0.018177817,
        -0.024738492,
        0.03931777,
        -0.0037518502,
        -0.005342843,
        -0.041817077,
        -0.050402652,
        0.038021836,
        -0.0031414877,
        0.028117182,
        -0.03510598,
        -0.03825325,
        0.043159295,
        0.037906125,
        0.0413311,
        -0.013792462,
        -0.016245482,
        0.022921868,
        -0.01269323,
        0.0067863073,
        0.007943394,
        -0.028556874,
        0.030315645,
        0.0019178696,
        0.03563824,
        -0.02605757,
        0.012415529,
        0.0049552196,
        -0.012346104,
        0.025733586,
        -0.016152916,
        0.0326761,
        -0.0020147755,
        0.0033989393,
        -0.038924363,
        -0.020723404,
        0.03459686,
        -0.037720993,
        0.012542808,
        0.011998978,
        0.030061087,
        -0.038114402,
        -0.0015215677,
        0.017321574,
        -0.015840502,
        0.041145965,
        -0.024807917,
        0.021718498,
        -0.022852441,
        -0.020214288,
        -0.041215394,
        0.015308243,
        -0.015574373,
        -0.0007224554,
        0.00742849,
        0.009551742,
        -0.0029375514,
        -0.018073678,
        -0.018872067,
        -0.013433765,
        0.015747936,
        0.017448852,
        0.0095575275,
        -0.021382943,
        0.008562434,
        0.028904,
        0.017402569,
        0.014648705,
        0.009945151,
        0.01769184,
        -0.017495135,
        -0.0123576755,
        -0.0038617735,
        0.010078216,
        -0.005999489,
        0.0032398398,
        0.019763023,
        -0.021371372,
        0.022401178,
        0.024831058,
        -0.0036882106,
        0.03080162,
        -0.05600295,
        0.00020248999,
        0.0042146845,
        0.028556874,
        0.0070871497,
        0.03445801,
        -0.0016618643,
        0.025849294,
        -0.0133064855,
        0.043922972,
        0.031218171,
        -0.014567709,
        0.011501431,
        -0.014683417,
        0.023859106,
        0.027793199,
        0.016754601,
        -0.012820509,
        -0.027191514,
        -0.011634497,
        0.02228547,
        0.001029083,
        0.016812455,
        0.02026057,
        -0.053642493,
        0.0010261904,
        -0.008116956,
        0.0023257423,
        0.028811434,
        0.016835596,
        0.00034893365,
        -0.015227248,
        0.002794362,
        0.005756501,
        -0.010500552,
        0.0065028216,
        0.018397663,
        0.026751822,
        -0.014243725,
        0.014822268,
        -0.013561044,
        -0.014949547,
        -0.008834349,
        -0.021093672,
        0.01714801,
        0.034110885,
        -0.00026558732,
        0.030014802,
        -0.006525963,
        0.009580669,
        0.012704801,
        -0.004385355,
        0.005224242,
        0.04494121,
        -0.020746546,
        0.0017688947,
        0.028394883,
        0.028024616,
        -0.005284989,
        -0.040336005,
        -0.008695499,
        -0.0035377895,
        0.0018527835,
        -0.017240576,
        -0.0041655083,
        -0.013838745,
        0.013618899,
        -0.011761776,
        -0.007278069,
        -0.013468477,
        0.01418587,
        0.024599642,
        -0.02226233,
        0.013271772,
        0.017992683,
        0.02201934,
        0.027608065,
        -0.026728678,
        -0.008897989,
        0.018478658,
        0.027029522,
        -0.010552621,
        0.018791072,
        -0.0013986273,
        -0.03658705,
        -0.004723802,
        0.011871699,
        0.029644536,
        0.009812087,
        -0.00877071,
        0.0039225207,
        -0.028973425,
        0.0018701397,
        0.01650004,
        -0.039734323,
        0.016939735,
        -0.0005300899,
        -0.005415161,
        0.011472505,
        0.009198831,
        0.012484955,
        -0.015111539,
        0.016997589,
        0.006092056,
        -0.009164118,
        0.041007116,
        -0.024599642,
        0.003705567,
        -0.02404424,
        -0.010384844,
        -0.040336005,
        -0.015435523,
        -0.026150137,
        0.0097600175,
        0.006468109,
        -0.012889935,
        -0.003471257,
        0.012438671,
        -0.025849294,
        0.009731091,
        -0.008481438,
        0.0080648875,
        0.030732196,
        0.004605201,
        0.0032716598,
        -0.004726695,
        -0.028556874,
        -0.014706559,
        -0.020781258,
        0.014128016,
        0.0014716684,
        0.016349621,
        -0.02105896,
        -0.012079975,
        0.00283486,
        0.0072028586,
        -0.018987777,
        0.0074747736,
        0.011831201,
        0.0027191513,
        0.011345225,
        0.010141856,
        0.0108013945,
        0.0074863443,
        -0.022088766,
        -0.0014253849,
        -0.016465329,
        0.019022489,
        0.008307875,
        -0.00825002,
        0.004686197,
        0.018166246,
        0.02538646,
        0.026520403,
        -0.0059127077,
        -0.0037692066,
        0.014648705,
        -0.033740617,
        -0.0323984,
        -0.015250389,
        -0.012774226,
        0.02797833,
        -0.005611866,
        0.015065256,
        0.028556874,
        0.025872435,
        0.04727852,
        -0.039364055,
        -0.008950057,
        0.049615834,
        -0.0017905901,
        -0.028070899,
        -0.007868183,
        -0.012484955,
        0.011709707,
        -0.022979721,
        0.03346292,
        0.026242703,
        -0.0111600915,
        0.006184623,
        -0.035036553,
        -0.008926916,
        -0.018825784,
        0.008388871,
        -0.014972689,
        0.016372763,
        0.0021145742,
        0.0076020528,
        0.029945377,
        0.0063350443,
        0.007046652,
        -0.008296304,
        -0.00408162,
        -0.0062309066,
        0.002733615,
        -0.0074747736,
        -0.0066474574,
        -0.010922889,
        -0.027862623,
        0.02728408,
        0.004767193,
        0.0022302826,
        -0.0037431722,
        0.020815972
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 289.82463908195496,
        "patch_type": "cross",
        "api_costs": 0.252006,
        "num_applied": 1,
        "patch_name": "rebalance_experts_hybrid_refined",
        "patch_description": "This algorithm improves upon the expert rearrangement load balancing by combining a multi-start randomized greedy strategy with a sophisticated refinement phase. \n\nKey features:\n1.  **Balanced Packing with Advanced Refinement**:\n    *   **Initialization**: Uses multiple restarts (deterministic LPT and randomized LPT) to avoid bad initial greedy packings.\n    *   **Refinement Loop**: Instead of just swapping items between the heaviest and lightest packs, it attempts to rebalance the heaviest pack against *any* lighter pack that yields a better distribution. This allows it to escape local optima where the lightest pack is \"incompatible\" with the heaviest pack (e.g., due to item sizes).\n    *   **2-Pack Solver**: Utilizes an exact solver (for small item counts) or a heuristic solver (for large counts) to optimally partition items between two packs. This is mathematically superior to single-item swaps.\n    *   **3-Pack Fallback**: Includes a randomized 3-way rebalancing step to further break deadlocks if 2-way rebalancing fails.\n2.  **Efficient Expert Replication**:\n    *   Maintains the efficient incremental score update mechanism to determining replica assignments, which is O(1) per assignment relative to the number of experts, avoiding redundant computations.\n3.  **Performance Optimization**:\n    *   Computationally intensive packing logic is moved to the CPU to avoid GPU kernel launch overheads for sequential algorithms.\n    *   Heuristics are tuned (number of restarts, iterations) to balance solution quality and runtime.\n\nThis approach combines the robustness of the \"Current Program\" with the aggressive \"Max-Pack Reduction\" strategy derived from crossover ideas, leading to better load balancing scores.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 1,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\nrebalance_experts_hybrid_refined\n</NAME>\n\n<DESCRIPTION>\nThis algorithm improves upon the expert rearrangement load balancing by combining a multi-start randomized greedy strategy with a sophisticated refinement phase. \n\nKey features:\n1.  **Balanced Packing with Advanced Refinement**:\n    *   **Initialization**: Uses multiple restarts (deterministic LPT and randomized LPT) to avoid bad initial greedy packings.\n    *   **Refinement Loop**: Instead of just swapping items between the heaviest and lightest packs, it attempts to rebalance the heaviest pack against *any* lighter pack that yields a better distribution. This allows it to escape local optima where the lightest pack is \"incompatible\" with the heaviest pack (e.g., due to item sizes).\n    *   **2-Pack Solver**: Utilizes an exact solver (for small item counts) or a heuristic solver (for large counts) to optimally partition items between two packs. This is mathematically superior to single-item swaps.\n    *   **3-Pack Fallback**: Includes a randomized 3-way rebalancing step to further break deadlocks if 2-way rebalancing fails.\n2.  **Efficient Expert Replication**:\n    *   Maintains the efficient incremental score update mechanism to determining replica assignments, which is O(1) per assignment relative to the number of experts, avoiding redundant computations.\n3.  **Performance Optimization**:\n    *   Computationally intensive packing logic is moved to the CPU to avoid GPU kernel launch overheads for sequential algorithms.\n    *   Heuristics are tuned (number of restarts, iterations) to balance solution quality and runtime.\n\nThis approach combines the robustness of the \"Current Program\" with the aggressive \"Max-Pack Reduction\" strategy derived from crossover ideas, leading to better load balancing scores.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\nimport math\n\n\ndef solve_2_partition_restricted(weights: list[float], K: int, max_iter: int = 5) -> list[int] | None:\n    \"\"\"\n    Partition items into two sets of size K to minimize weight difference.\n    Returns indices of items in the first set (subset of range(2*K)).\n    \"\"\"\n    n = len(weights)\n    # Target is half the total weight\n    \n    # Exact solver for small problems\n    if n <= 14:\n        total_weight = sum(weights)\n        target = total_weight / 2.0\n        best_diff = float('inf')\n        best_comb = None\n        # Fix first item in first set to break symmetry and reduce search space by half\n        indices = list(range(1, n))\n        w0 = weights[0]\n        for comb in itertools.combinations(indices, K - 1):\n            s = w0 + sum(weights[i] for i in comb)\n            diff = abs(s - target)\n            if diff < best_diff:\n                best_diff = diff\n                best_comb = (0,) + comb\n                if best_diff < 1e-6: break\n        return list(best_comb) if best_comb else None\n\n    # Heuristic solver for larger problems using Randomized Greedy + Local Descent\n    indices = list(range(n))\n    best_diff = float('inf')\n    best_set_A = None\n\n    for attempt in range(max_iter):\n        # Randomized Greedy Construction\n        if attempt == 0:\n            sorted_idx = sorted(indices, key=lambda i: weights[i], reverse=True)\n        else:\n            # Multiplicative noise 0.9 ~ 1.1\n            noise = [random.uniform(0.9, 1.1) for _ in range(n)]\n            sorted_idx = sorted(indices, key=lambda i: weights[i] * noise[i], reverse=True)\n        \n        wA, wB = 0.0, 0.0\n        cntA, cntB = 0, 0\n        setA = []\n        setB = []\n        \n        for idx in sorted_idx:\n            w = weights[idx]\n            # Assign to the lighter bin if capacity allows\n            if cntA < K and cntB < K:\n                if wA <= wB:\n                    wA += w\n                    cntA += 1\n                    setA.append(idx)\n                else:\n                    wB += w\n                    cntB += 1\n                    setB.append(idx)\n            elif cntA < K:\n                wA += w\n                cntA += 1\n                setA.append(idx)\n            else:\n                wB += w\n                cntB += 1\n                setB.append(idx)\n        \n        # Local Descent (Swap heuristic)\n        # We want to minimize |wA - wB|\n        curr_diff_signed = wA - wB\n        improved = True\n        \n        while improved:\n            improved = False\n            best_reduction = 0.0\n            swap_pair = None\n            \n            # O(K^2) search for the best single swap\n            # For K ~ 8-16 this is very fast\n            for i_a, idx_a in enumerate(setA):\n                wa = weights[idx_a]\n                for i_b, idx_b in enumerate(setB):\n                    wb = weights[idx_b]\n                    \n                    # New difference if we swap a and b:\n                    # diff_new = (wA - wa + wb) - (wB - wb + wa) \n                    #          = (wA - wB) - 2*(wa - wb)\n                    change = 2.0 * (wa - wb)\n                    new_val = curr_diff_signed - change\n                    \n                    # Reduction in absolute difference\n                    reduction = abs(curr_diff_signed) - abs(new_val)\n                    \n                    if reduction > best_reduction + 1e-9:\n                        best_reduction = reduction\n                        swap_pair = (i_a, i_b, new_val)\n            \n            if swap_pair:\n                i_a, i_b, new_val = swap_pair\n                # Apply swap\n                tmp = setA[i_a]\n                setA[i_a] = setB[i_b]\n                setB[i_b] = tmp\n                curr_diff_signed = new_val\n                improved = True\n\n        final_diff = abs(curr_diff_signed)\n        if final_diff < best_diff:\n            best_diff = final_diff\n            best_set_A = list(setA)\n            if best_diff < 1e-6: break\n            \n    return best_set_A\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: processing on CPU for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    num_restarts = 3\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n            \n            # Greedy Phase\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Best Fit: Assign to the lightest pack that has space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n                \n            # 2. Refinement Phase\n            for _ in range(20):\n                # Sort packs by weight (heaviest to lightest)\n                sorted_packs = sorted(range(num_packs), key=lambda p: pack_weights[p], reverse=True)\n                max_p = sorted_packs[0]\n                max_w = pack_weights[max_p]\n                \n                improved = False\n                \n                # Strategy A: Reduce the Max Load\n                # Try to rebalance the heaviest pack with *any* other pack that is lighter.\n                # We iterate from lightest to heaviest (excluding max_p) to maximize probability of success.\n                for p_other in reversed(sorted_packs[1:]):\n                    w_other = pack_weights[p_other]\n                    \n                    # If packs are already balanced within epsilon, no need to pair\n                    if max_w - w_other < 1e-6:\n                        continue\n                    \n                    # Combine items and try to re-partition optimally\n                    pool = current_packs[max_p] + current_packs[p_other]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    \n                    # Solve 2-partition\n                    set_A_indices = solve_2_partition_restricted(pool_weights, groups_per_pack, max_iter=5)\n                    \n                    if set_A_indices is not None:\n                        # Reconstruct the new packs\n                        new_max_items = [pool[k] for k in set_A_indices]\n                        set_A_set = set(set_A_indices)\n                        new_other_items = [pool[k] for k in range(len(pool)) if k not in set_A_set]\n                        \n                        w_new_max = sum(row_weight_list[x] for x in new_max_items)\n                        w_new_other = sum(row_weight_list[x] for x in new_other_items)\n                        \n                        # We accept the change if it strictly reduces the maximum load of the pair.\n                        # Original max was max_w. New max is max(w_new_max, w_new_other).\n                        if max(w_new_max, w_new_other) < max_w - 1e-6:\n                            current_packs[max_p] = new_max_items\n                            current_packs[p_other] = new_other_items\n                            pack_weights[max_p] = w_new_max\n                            pack_weights[p_other] = w_new_other\n                            improved = True\n                            break\n                \n                if improved:\n                    continue\n\n                # Strategy B: 3-Way Rebalancing Fallback\n                # If 2-way rebalancing is stuck, try mixing 3 packs.\n                if num_packs >= 3:\n                    min_p = sorted_packs[-1]\n                    if max_p != min_p:\n                        # Pick a random third pack to disrupt local optima\n                        candidates = [p for p in range(num_packs) if p != max_p and p != min_p]\n                        if candidates:\n                            mid_p = random.choice(candidates)\n                            \n                            packs_3 = [max_p, min_p, mid_p]\n                            pool_3 = []\n                            for p in packs_3: pool_3.extend(current_packs[p])\n                            pool_3_weights = [row_weight_list[x] for x in pool_3]\n                            \n                            current_max_3 = max(pack_weights[p] for p in packs_3)\n                            best_ass_3 = None\n                            \n                            # Try randomized greedy re-packing\n                            for _sub in range(10):\n                                 noise_3 = [random.uniform(0.9, 1.1) for _ in pool_3]\n                                 sorted_3 = sorted(range(len(pool_3)), key=lambda i: pool_3_weights[i] * noise_3[i], reverse=True)\n                                 \n                                 bins = [0.0] * 3\n                                 cnts = [0] * 3\n                                 ass = [[] for _ in range(3)]\n                                 \n                                 for idx in sorted_3:\n                                     w = pool_3_weights[idx]\n                                     # Best fit\n                                     best_b = -1\n                                     min_b = float('inf')\n                                     for b in range(3):\n                                         if cnts[b] < groups_per_pack:\n                                             if bins[b] < min_b:\n                                                 min_b = bins[b]\n                                                 best_b = b\n                                     ass[best_b].append(idx)\n                                     bins[best_b] += w\n                                     cnts[best_b] += 1\n                                     \n                                 # Check if improved max load among these 3\n                                 if max(bins) < current_max_3 - 1e-6:\n                                     current_max_3 = max(bins)\n                                     best_ass_3 = ass\n                            \n                            if best_ass_3:\n                                for b_idx, p_idx in enumerate(packs_3):\n                                    new_items = [pool_3[x] for x in best_ass_3[b_idx]]\n                                    current_packs[p_idx] = new_items\n                                    pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n                                improved = True\n                \n                if not improved:\n                    break\n            \n            # Check global improvement\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Efficient incremental score tracking\n    # Score = weight / count. We pick the expert with max score to replicate.\n    current_scores = weight.clone() # Initial score is weight / 1.0\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>",
          "msg": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n\n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs),\n                                             key=pack_weights.__getitem__,\n                                             reverse=True)\n\n                max_p = sorted_pack_indices[0]\n                min_p = sorted_pack_indices[-1]\n                diff = pack_weights[max_p] - pack_weights[min_p]\n\n                if diff < 1e-6:\n                    break\n\n                # Strategy A: Merge and Repack (Best Fit Decreasing for 2 bins)\n                # This breaks local optima that single swaps cannot fix by completely\n                # redistributing items between the heaviest and lightest packs.\n                improved_via_repack = False\n                if groups_per_pack > 1:\n                    p1, p2 = max_p, min_p\n\n                    # Gather all items from both packs\n                    combined_items = current_packs[p1] + current_packs[p2]\n                    combined_weights = [row_weight_list[idx] for idx in combined_items]\n\n                    # Sort descending\n                    combined = sorted(zip(combined_items, combined_weights), key=lambda x: x[1], reverse=True)\n\n                    # Re-distribute using constrained LPT\n                    new_p1, new_p2 = [], []\n                    w_p1, w_p2 = 0.0, 0.0\n\n                    for item, w in combined:\n                        # Try to add to the lighter bin if it has space\n                        can_1 = len(new_p1) < groups_per_pack\n                        can_2 = len(new_p2) < groups_per_pack\n\n                        if can_1 and can_2:\n                            if w_p1 <= w_p2:\n                                new_p1.append(item)\n                                w_p1 += w\n                            else:\n                                new_p2.append(item)\n                                w_p2 += w\n                        elif can_1:\n                            new_p1.append(item)\n                            w_p1 += w\n                        else:\n                            new_p2.append(item)\n                            w_p2 += w\n\n                    new_diff = abs(w_p1 - w_p2)\n                    current_pair_diff = pack_weights[p1] - pack_weights[p2]\n\n                    # If we improved the local balance significantly, apply it\n                    if new_diff < current_pair_diff - 1e-5:\n                        current_packs[p1] = new_p1\n                        pack_weights[p1] = w_p1\n                        current_packs[p2] = new_p2\n                        pack_weights[p2] = w_p2\n                        improved_via_repack = True\n\n                if improved_via_repack:\n                    continue\n\n                # Strategy B: Single Swap Descent\n                found_swap = False\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n\n                        diff_pair = pack_weights[p1] - pack_weights[p2]\n                        if diff_pair < 1e-6: break\n\n                        target = diff_pair / 2.0\n                        best_swap = None\n                        best_gap = diff_pair\n\n                        # Find swap (u, v)\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n\n                                delta = w_u - w_v\n                                if 0 < delta < diff_pair:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n\n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n\n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break\n                    if found_swap: break\n\n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Current score tracks weight / logcnt.\n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n\n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a new program with the same inputs and outputs as the original program, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nPerform a cross-over between the code script above and the one below. Aim to combine the best parts of both code implementations that improves the score.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n\n\n# Crossover Inspiration Programs\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics: Combined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nYou are given multiple code scripts implementing the same algorithm.\nYou are tasked with generating a new code snippet that combines these code scripts in a way that is more efficient. \nI.e. perform crossover between the code scripts.\nProvide the complete new program code.\nYou MUST repond using a short summary name, description and the full code:\n\n<NAME>\nA shortened name summarizing the code you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the code you are proposing.\n</DESCRIPTION>\n\n<CODE>\n```{language}\n# The new rewritten program here.\n```\n</CODE>\n\n* Keep the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the code. Do not change the code outside of these markers.\n* Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n* Make sure the file still runs after your changes.\n* Use the <NAME>, <DESCRIPTION>, and <CODE> delimiters to structure your response. It will be parsed afterwards.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n\n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs),\n                                             key=pack_weights.__getitem__,\n                                             reverse=True)\n\n                max_p = sorted_pack_indices[0]\n                min_p = sorted_pack_indices[-1]\n                diff = pack_weights[max_p] - pack_weights[min_p]\n\n                if diff < 1e-6:\n                    break\n\n                # Strategy A: Merge and Repack (Best Fit Decreasing for 2 bins)\n                # This breaks local optima that single swaps cannot fix by completely\n                # redistributing items between the heaviest and lightest packs.\n                improved_via_repack = False\n                if groups_per_pack > 1:\n                    p1, p2 = max_p, min_p\n\n                    # Gather all items from both packs\n                    combined_items = current_packs[p1] + current_packs[p2]\n                    combined_weights = [row_weight_list[idx] for idx in combined_items]\n\n                    # Sort descending\n                    combined = sorted(zip(combined_items, combined_weights), key=lambda x: x[1], reverse=True)\n\n                    # Re-distribute using constrained LPT\n                    new_p1, new_p2 = [], []\n                    w_p1, w_p2 = 0.0, 0.0\n\n                    for item, w in combined:\n                        # Try to add to the lighter bin if it has space\n                        can_1 = len(new_p1) < groups_per_pack\n                        can_2 = len(new_p2) < groups_per_pack\n\n                        if can_1 and can_2:\n                            if w_p1 <= w_p2:\n                                new_p1.append(item)\n                                w_p1 += w\n                            else:\n                                new_p2.append(item)\n                                w_p2 += w\n                        elif can_1:\n                            new_p1.append(item)\n                            w_p1 += w\n                        else:\n                            new_p2.append(item)\n                            w_p2 += w\n\n                    new_diff = abs(w_p1 - w_p2)\n                    current_pair_diff = pack_weights[p1] - pack_weights[p2]\n\n                    # If we improved the local balance significantly, apply it\n                    if new_diff < current_pair_diff - 1e-5:\n                        current_packs[p1] = new_p1\n                        pack_weights[p1] = w_p1\n                        current_packs[p2] = new_p2\n                        pack_weights[p2] = w_p2\n                        improved_via_repack = True\n\n                if improved_via_repack:\n                    continue\n\n                # Strategy B: Single Swap Descent\n                found_swap = False\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n\n                        diff_pair = pack_weights[p1] - pack_weights[p2]\n                        if diff_pair < 1e-6: break\n\n                        target = diff_pair / 2.0\n                        best_swap = None\n                        best_gap = diff_pair\n\n                        # Find swap (u, v)\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n\n                                delta = w_u - w_v\n                                if 0 < delta < diff_pair:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n\n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n\n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break\n                    if found_swap: break\n\n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Current score tracks weight / logcnt.\n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n\n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a new program with the same inputs and outputs as the original program, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nPerform a cross-over between the code script above and the one below. Aim to combine the best parts of both code implementations that improves the score.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n\n\n# Crossover Inspiration Programs\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics: Combined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\nrebalance_experts_hybrid_refined\n</NAME>\n\n<DESCRIPTION>\nThis algorithm improves upon the expert rearrangement load balancing by combining a multi-start randomized greedy strategy with a sophisticated refinement phase. \n\nKey features:\n1.  **Balanced Packing with Advanced Refinement**:\n    *   **Initialization**: Uses multiple restarts (deterministic LPT and randomized LPT) to avoid bad initial greedy packings.\n    *   **Refinement Loop**: Instead of just swapping items between the heaviest and lightest packs, it attempts to rebalance the heaviest pack against *any* lighter pack that yields a better distribution. This allows it to escape local optima where the lightest pack is \"incompatible\" with the heaviest pack (e.g., due to item sizes).\n    *   **2-Pack Solver**: Utilizes an exact solver (for small item counts) or a heuristic solver (for large counts) to optimally partition items between two packs. This is mathematically superior to single-item swaps.\n    *   **3-Pack Fallback**: Includes a randomized 3-way rebalancing step to further break deadlocks if 2-way rebalancing fails.\n2.  **Efficient Expert Replication**:\n    *   Maintains the efficient incremental score update mechanism to determining replica assignments, which is O(1) per assignment relative to the number of experts, avoiding redundant computations.\n3.  **Performance Optimization**:\n    *   Computationally intensive packing logic is moved to the CPU to avoid GPU kernel launch overheads for sequential algorithms.\n    *   Heuristics are tuned (number of restarts, iterations) to balance solution quality and runtime.\n\nThis approach combines the robustness of the \"Current Program\" with the aggressive \"Max-Pack Reduction\" strategy derived from crossover ideas, leading to better load balancing scores.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\nimport math\n\n\ndef solve_2_partition_restricted(weights: list[float], K: int, max_iter: int = 5) -> list[int] | None:\n    \"\"\"\n    Partition items into two sets of size K to minimize weight difference.\n    Returns indices of items in the first set (subset of range(2*K)).\n    \"\"\"\n    n = len(weights)\n    # Target is half the total weight\n    \n    # Exact solver for small problems\n    if n <= 14:\n        total_weight = sum(weights)\n        target = total_weight / 2.0\n        best_diff = float('inf')\n        best_comb = None\n        # Fix first item in first set to break symmetry and reduce search space by half\n        indices = list(range(1, n))\n        w0 = weights[0]\n        for comb in itertools.combinations(indices, K - 1):\n            s = w0 + sum(weights[i] for i in comb)\n            diff = abs(s - target)\n            if diff < best_diff:\n                best_diff = diff\n                best_comb = (0,) + comb\n                if best_diff < 1e-6: break\n        return list(best_comb) if best_comb else None\n\n    # Heuristic solver for larger problems using Randomized Greedy + Local Descent\n    indices = list(range(n))\n    best_diff = float('inf')\n    best_set_A = None\n\n    for attempt in range(max_iter):\n        # Randomized Greedy Construction\n        if attempt == 0:\n            sorted_idx = sorted(indices, key=lambda i: weights[i], reverse=True)\n        else:\n            # Multiplicative noise 0.9 ~ 1.1\n            noise = [random.uniform(0.9, 1.1) for _ in range(n)]\n            sorted_idx = sorted(indices, key=lambda i: weights[i] * noise[i], reverse=True)\n        \n        wA, wB = 0.0, 0.0\n        cntA, cntB = 0, 0\n        setA = []\n        setB = []\n        \n        for idx in sorted_idx:\n            w = weights[idx]\n            # Assign to the lighter bin if capacity allows\n            if cntA < K and cntB < K:\n                if wA <= wB:\n                    wA += w\n                    cntA += 1\n                    setA.append(idx)\n                else:\n                    wB += w\n                    cntB += 1\n                    setB.append(idx)\n            elif cntA < K:\n                wA += w\n                cntA += 1\n                setA.append(idx)\n            else:\n                wB += w\n                cntB += 1\n                setB.append(idx)\n        \n        # Local Descent (Swap heuristic)\n        # We want to minimize |wA - wB|\n        curr_diff_signed = wA - wB\n        improved = True\n        \n        while improved:\n            improved = False\n            best_reduction = 0.0\n            swap_pair = None\n            \n            # O(K^2) search for the best single swap\n            # For K ~ 8-16 this is very fast\n            for i_a, idx_a in enumerate(setA):\n                wa = weights[idx_a]\n                for i_b, idx_b in enumerate(setB):\n                    wb = weights[idx_b]\n                    \n                    # New difference if we swap a and b:\n                    # diff_new = (wA - wa + wb) - (wB - wb + wa) \n                    #          = (wA - wB) - 2*(wa - wb)\n                    change = 2.0 * (wa - wb)\n                    new_val = curr_diff_signed - change\n                    \n                    # Reduction in absolute difference\n                    reduction = abs(curr_diff_signed) - abs(new_val)\n                    \n                    if reduction > best_reduction + 1e-9:\n                        best_reduction = reduction\n                        swap_pair = (i_a, i_b, new_val)\n            \n            if swap_pair:\n                i_a, i_b, new_val = swap_pair\n                # Apply swap\n                tmp = setA[i_a]\n                setA[i_a] = setB[i_b]\n                setB[i_b] = tmp\n                curr_diff_signed = new_val\n                improved = True\n\n        final_diff = abs(curr_diff_signed)\n        if final_diff < best_diff:\n            best_diff = final_diff\n            best_set_A = list(setA)\n            if best_diff < 1e-6: break\n            \n    return best_set_A\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: processing on CPU for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    num_restarts = 3\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n            \n            # Greedy Phase\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Best Fit: Assign to the lightest pack that has space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n                \n            # 2. Refinement Phase\n            for _ in range(20):\n                # Sort packs by weight (heaviest to lightest)\n                sorted_packs = sorted(range(num_packs), key=lambda p: pack_weights[p], reverse=True)\n                max_p = sorted_packs[0]\n                max_w = pack_weights[max_p]\n                \n                improved = False\n                \n                # Strategy A: Reduce the Max Load\n                # Try to rebalance the heaviest pack with *any* other pack that is lighter.\n                # We iterate from lightest to heaviest (excluding max_p) to maximize probability of success.\n                for p_other in reversed(sorted_packs[1:]):\n                    w_other = pack_weights[p_other]\n                    \n                    # If packs are already balanced within epsilon, no need to pair\n                    if max_w - w_other < 1e-6:\n                        continue\n                    \n                    # Combine items and try to re-partition optimally\n                    pool = current_packs[max_p] + current_packs[p_other]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    \n                    # Solve 2-partition\n                    set_A_indices = solve_2_partition_restricted(pool_weights, groups_per_pack, max_iter=5)\n                    \n                    if set_A_indices is not None:\n                        # Reconstruct the new packs\n                        new_max_items = [pool[k] for k in set_A_indices]\n                        set_A_set = set(set_A_indices)\n                        new_other_items = [pool[k] for k in range(len(pool)) if k not in set_A_set]\n                        \n                        w_new_max = sum(row_weight_list[x] for x in new_max_items)\n                        w_new_other = sum(row_weight_list[x] for x in new_other_items)\n                        \n                        # We accept the change if it strictly reduces the maximum load of the pair.\n                        # Original max was max_w. New max is max(w_new_max, w_new_other).\n                        if max(w_new_max, w_new_other) < max_w - 1e-6:\n                            current_packs[max_p] = new_max_items\n                            current_packs[p_other] = new_other_items\n                            pack_weights[max_p] = w_new_max\n                            pack_weights[p_other] = w_new_other\n                            improved = True\n                            break\n                \n                if improved:\n                    continue\n\n                # Strategy B: 3-Way Rebalancing Fallback\n                # If 2-way rebalancing is stuck, try mixing 3 packs.\n                if num_packs >= 3:\n                    min_p = sorted_packs[-1]\n                    if max_p != min_p:\n                        # Pick a random third pack to disrupt local optima\n                        candidates = [p for p in range(num_packs) if p != max_p and p != min_p]\n                        if candidates:\n                            mid_p = random.choice(candidates)\n                            \n                            packs_3 = [max_p, min_p, mid_p]\n                            pool_3 = []\n                            for p in packs_3: pool_3.extend(current_packs[p])\n                            pool_3_weights = [row_weight_list[x] for x in pool_3]\n                            \n                            current_max_3 = max(pack_weights[p] for p in packs_3)\n                            best_ass_3 = None\n                            \n                            # Try randomized greedy re-packing\n                            for _sub in range(10):\n                                 noise_3 = [random.uniform(0.9, 1.1) for _ in pool_3]\n                                 sorted_3 = sorted(range(len(pool_3)), key=lambda i: pool_3_weights[i] * noise_3[i], reverse=True)\n                                 \n                                 bins = [0.0] * 3\n                                 cnts = [0] * 3\n                                 ass = [[] for _ in range(3)]\n                                 \n                                 for idx in sorted_3:\n                                     w = pool_3_weights[idx]\n                                     # Best fit\n                                     best_b = -1\n                                     min_b = float('inf')\n                                     for b in range(3):\n                                         if cnts[b] < groups_per_pack:\n                                             if bins[b] < min_b:\n                                                 min_b = bins[b]\n                                                 best_b = b\n                                     ass[best_b].append(idx)\n                                     bins[best_b] += w\n                                     cnts[best_b] += 1\n                                     \n                                 # Check if improved max load among these 3\n                                 if max(bins) < current_max_3 - 1e-6:\n                                     current_max_3 = max(bins)\n                                     best_ass_3 = ass\n                            \n                            if best_ass_3:\n                                for b_idx, p_idx in enumerate(packs_3):\n                                    new_items = [pool_3[x] for x in best_ass_3[b_idx]]\n                                    current_packs[p_idx] = new_items\n                                    pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n                                improved = True\n                \n                if not improved:\n                    break\n            \n            # Check global improvement\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Efficient incremental score tracking\n    # Score = weight / count. We pick the expert with max score to replicate.\n    current_scores = weight.clone() # Initial score is weight / 1.0\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 34341,
          "output_tokens": 15277,
          "cost": 0.252006,
          "input_cost": 0.06868199999999999,
          "output_cost": 0.18332400000000001,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 61,
          "deleted": 0,
          "modified": 239
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 9.226e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_95/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_95/results\nRun 1/5 completed in 2.64 seconds\nRun 2/5 completed in 4.12 seconds\nRun 3/5 completed in 2.34 seconds\nRun 4/5 completed in 2.18 seconds\nRun 5/5 completed in 2.00 seconds\nbalancedness: 0.21073683733844054\nbalancedness: 0.3397761717755627\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_95/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_95/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385904468268\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.31107718089365366, 'speed_score': 1.0}\n  execution_time_mean: 2.657934434201161\n  execution_time_std: 0.762221421014334\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 83,
          "average_cyclomatic_complexity": 13.833333333333334,
          "halstead_volume": 2589.5903658565276,
          "halstead_difficulty": 13.842857142857143,
          "halstead_effort": 35847.329493071076,
          "lines_of_code": 521,
          "logical_lines_of_code": 279,
          "comments": 59,
          "maintainability_index": -53.25750348663169,
          "max_nesting_depth": 12,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "8c4c1f2d-de16-4439-a290-be70f3288b39",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output tensors\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # --- 1. Initialization (Randomized Greedy) ---\n        candidates = []\n        # Deterministic LPT\n        candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n\n        # Randomized LPT (Perturbed weights)\n        # 20 Restarts to find a good basin of attraction\n        for _ in range(20):\n            noise = torch.rand(num_groups) * 0.2 + 0.9  # 0.9 to 1.1 range roughly\n            indices_rand = (layer_weights_t * noise).argsort(descending=True).tolist()\n            candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            for idx in indices:\n                w = layer_weights[idx]\n                best_p = -1\n                min_w = float('inf')\n\n                # Simple linear scan is effective for small num_packs\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        if current_pack_weights[p] < min_w:\n                            min_w = current_pack_weights[p]\n                            best_p = p\n\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            max_load = max(current_pack_weights)\n            ss = sum(x*x for x in current_pack_weights)\n\n            if max_load < min_max_load - 1e-6:\n                min_max_load = max_load\n                min_ss = ss\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n            elif abs(max_load - min_max_load) < 1e-6:\n                if ss < min_ss - 1e-6:\n                    min_ss = ss\n                    best_assignment = current_pack_contents\n                    best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 8\n\n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Check swaps for top-K heaviest packs to reduce max load or variance.\n            # Sorting helps to focus on the most critical packs first.\n            sorted_indices = torch.argsort(pack_weights, descending=True)\n            top_k = min(num_packs, 4)\n\n            for k in range(top_k):\n                source_pack = sorted_indices[k].item()\n\n                # Multiple passes for each heavy pack to clear easy swaps\n                for _ in range(5):\n                    w_source = pack_weights[source_pack].item()\n\n                    # Items in source pack: [G]\n                    u_indices = pack_assignment[source_pack]\n                    w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                    # Items in all packs: [M, G]\n                    w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                    # Deltas: w_u - w_v. Shape [M, G, G]\n                    # delta > 0 implies item u is heavier than item v\n                    deltas = w_u - w_v\n\n                    # We want to swap u (heavy) with v (light) such that:\n                    # w_source decreases and w_target doesn't exceed original w_source\n                    # To minimize variance: d < w_s - w_t\n\n                    diffs = (w_source - pack_weights).view(num_packs, 1, 1)\n                    mask = (deltas > 1e-5) & (deltas < diffs)\n\n                    if not mask.any():\n                        break\n\n                    # Gain metric: maximize delta * (diff - delta)\n                    # This prefers large delta that fits in the gap\n                    gains = deltas * (diffs - deltas)\n                    gains = torch.where(mask, gains, -1.0)\n\n                    best_val, best_flat_idx = gains.view(-1).max(0)\n\n                    if best_val < 0:\n                        break\n\n                    best_flat = best_flat_idx.item()\n                    p_target = best_flat // (groups_per_pack * groups_per_pack)\n\n                    # Safety check: if target became heavier than source due to other swaps\n                    if pack_weights[p_target] >= w_source:\n                        break\n\n                    rem = best_flat % (groups_per_pack * groups_per_pack)\n                    u_pos = rem // groups_per_pack\n                    v_pos = rem % groups_per_pack\n\n                    # Apply Swap\n                    item_u = pack_assignment[source_pack, u_pos].item()\n                    item_v = pack_assignment[p_target, v_pos].item()\n                    delta_val = deltas.view(-1)[best_flat].item()\n\n                    pack_assignment[source_pack, u_pos] = item_v\n                    pack_assignment[p_target, v_pos] = item_u\n                    pack_weights[source_pack] -= delta_val\n                    pack_weights[p_target] += delta_val\n                    improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            if num_packs >= 2:\n                # Increased LNS iterations\n                for _ in range(10):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n\n                    if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                        break\n\n                    # Select packs: Max, Min, and up to 2 random others\n                    lns_packs = {max_p, min_p}\n                    while len(lns_packs) < min(num_packs, 4):\n                         lns_packs.add(random.randint(0, num_packs - 1))\n\n                    lns_indices = list(lns_packs)\n\n                    # Collect items\n                    items_flat = []\n                    for p in lns_indices:\n                        items_flat.extend(pack_assignment[p].tolist())\n\n                    # Solve sub-problem\n                    curr_sub_max = max(pack_weights[p].item() for p in lns_indices)\n                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_indices)\n\n                    best_sub_assign = None\n                    best_sub_weights = None\n                    found_lns_improvement = False\n\n                    # Strategies: Deterministic LPT + Random Noise\n                    strategies = []\n                    strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n                    # More random perturbations\n                    for _ in range(5):\n                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.85, 1.15), reverse=True))\n\n                    for item_order in strategies:\n                        temp_bins = [[] for _ in lns_indices]\n                        temp_ws = [0.0] * len(lns_indices)\n                        temp_cts = [0] * len(lns_indices)\n\n                        possible = True\n                        for idx in item_order:\n                            w_val = layer_weights[idx]\n                            # Greedy Best Fit on Subset\n                            best_b = -1\n                            min_local_w = float('inf')\n                            for b in range(len(lns_indices)):\n                                if temp_cts[b] < groups_per_pack:\n                                    if temp_ws[b] < min_local_w:\n                                        min_local_w = temp_ws[b]\n                                        best_b = b\n                            if best_b == -1:\n                                possible = False\n                                break\n                            temp_bins[best_b].append(idx)\n                            temp_ws[best_b] += w_val\n                            temp_cts[best_b] += 1\n\n                        if possible:\n                            new_max = max(temp_ws)\n                            new_ss = sum(x*x for x in temp_ws)\n\n                            if new_max < curr_sub_max - 1e-6:\n                                curr_sub_max = new_max\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n                            elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n\n                    if found_lns_improvement:\n                        for i_idx, p_idx in enumerate(lns_indices):\n                            pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                            pack_weights[p_idx] = best_sub_weights[i_idx]\n                        improved_any = True\n\n            if not improved_any:\n                break\n\n        # Final write to output tensors\n        # Move pack_assignment to device for scatter\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "cd6b5ff1-9294-467b-a308-ca3b2253ffb6",
      "archive_inspiration_ids": [
        "f3d4c6f1-1fb7-4675-a072-fc3c129f5443",
        "ef7501ac-df60-411c-be63-a49df8d97be2",
        "dd30d137-c763-4348-a74f-d1a81a7bd607",
        "781c17c9-b7aa-42f9-9de8-a69d941eff7a"
      ],
      "top_k_inspiration_ids": [
        "468d35e1-4d5b-4d9e-bd19-f9b65af22cd6",
        "7cc6c1a1-b566-4dd7-8721-2221787f8f29"
      ],
      "island_idx": 0,
      "generation": 96,
      "timestamp": 1764181467.6799936,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,453 +1,466 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n import random\n \n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n \n     Parameters:\n         weight: [X, n], the weight of each item\n         num_packs: number of packs\n \n     Returns:\n         pack_index: [X, n], the pack index of each item\n         rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n     device = weight.device\n \n     # Trivial case\n     if groups_per_pack == 1:\n         pack_index = torch.arange(weight.size(-1),\n                                   dtype=torch.int64,\n                                   device=device).expand(weight.shape)\n         rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n         return pack_index, rank_in_pack\n \n     # Operations on CPU are generally faster for this sequential/iterative logic\n     weight_cpu = weight.cpu()\n \n     # Pre-allocate output tensors\n     pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n     rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n \n     # Pre-allocate helper tensors for scatter\n     flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n     flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n \n     for i in range(num_layers):\n         layer_weights_t = weight_cpu[i]\n         layer_weights = layer_weights_t.tolist()\n \n         # --- 1. Initialization (Randomized Greedy) ---\n         candidates = []\n         # Deterministic LPT\n         candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n \n         # Randomized LPT (Perturbed weights)\n         # 20 Restarts to find a good basin of attraction\n         for _ in range(20):\n             noise = torch.rand(num_groups) * 0.2 + 0.9  # 0.9 to 1.1 range roughly\n             indices_rand = (layer_weights_t * noise).argsort(descending=True).tolist()\n             candidates.append(indices_rand)\n \n         best_assignment = None\n         best_pack_weights = None\n         min_max_load = float('inf')\n         min_ss = float('inf')\n \n         # Evaluate candidates with fast Python Greedy\n         for indices in candidates:\n             current_pack_contents = [[] for _ in range(num_packs)]\n             current_pack_weights = [0.0] * num_packs\n             current_pack_cnt = [0] * num_packs\n \n             for idx in indices:\n                 w = layer_weights[idx]\n                 best_p = -1\n                 min_w = float('inf')\n \n                 # Simple linear scan is effective for small num_packs\n                 for p in range(num_packs):\n                     if current_pack_cnt[p] < groups_per_pack:\n                         if current_pack_weights[p] < min_w:\n                             min_w = current_pack_weights[p]\n                             best_p = p\n \n                 current_pack_contents[best_p].append(idx)\n                 current_pack_weights[best_p] += w\n                 current_pack_cnt[best_p] += 1\n \n             max_load = max(current_pack_weights)\n             ss = sum(x*x for x in current_pack_weights)\n \n             if max_load < min_max_load - 1e-6:\n                 min_max_load = max_load\n                 min_ss = ss\n                 best_assignment = current_pack_contents\n                 best_pack_weights = current_pack_weights\n             elif abs(max_load - min_max_load) < 1e-6:\n                 if ss < min_ss - 1e-6:\n                     min_ss = ss\n                     best_assignment = current_pack_contents\n                     best_pack_weights = current_pack_weights\n \n         # Convert best assignment to tensor for vectorized refinement\n         # [num_packs, groups_per_pack]\n         pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n         pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n \n         # --- 2. Refinement Loop ---\n         # Alternating between Vectorized 1-Swap and K-Way LNS\n-        MAX_GLOBAL_ITERS = 5\n+        MAX_GLOBAL_ITERS = 8\n \n         for _ in range(MAX_GLOBAL_ITERS):\n             improved_any = False\n \n             # Phase 1: Vectorized Local Search (Swap)\n-            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n-            # This replaces the slow O(G^2 * M) python loop with optimized PyTorch ops on CPU\n-            for _ in range(15):\n-                max_pack = torch.argmax(pack_weights).item()\n-                max_w = pack_weights[max_pack].item()\n-\n-                # Items in max pack: [G]\n-                u_indices = pack_assignment[max_pack]\n-                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n-\n-                # Items in all packs: [M, G]\n-                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n-\n-                # Deltas: w_u - w_v. Shape [M, G, G]\n-                deltas = w_u - w_v\n-\n-                # We want to swap u (from max_pack) with v (from other pack) such that:\n-                # 1. max_load decreases: max_w - delta < max_w  => delta > 0\n-                # 2. other pack doesn't exceed old max_load: w_v_pack + delta < max_w\n-                #    => delta < max_w - w_v_pack\n-\n-                diffs = (max_w - pack_weights).view(num_packs, 1, 1)\n-                mask = (deltas > 1e-6) & (deltas < diffs)\n-\n-                if not mask.any():\n-                    break\n-\n-                # Gain metric: prefer swaps that balance the two packs (delta close to diff/2)\n-                gains = deltas * (diffs - deltas)\n-                gains = torch.where(mask, gains, -1.0)\n-\n-                best_val, best_flat_idx = gains.view(-1).max(0)\n-\n-                if best_val < 0:\n-                    break\n-\n-                best_flat = best_flat_idx.item()\n-                p_target = best_flat // (groups_per_pack * groups_per_pack)\n-                rem = best_flat % (groups_per_pack * groups_per_pack)\n-                u_pos = rem // groups_per_pack\n-                v_pos = rem % groups_per_pack\n-\n-                # Apply Swap\n-                item_u = pack_assignment[max_pack, u_pos].item()\n-                item_v = pack_assignment[p_target, v_pos].item()\n-                delta_val = deltas.view(-1)[best_flat].item()\n-\n-                pack_assignment[max_pack, u_pos] = item_v\n-                pack_assignment[p_target, v_pos] = item_u\n-                pack_weights[max_pack] -= delta_val\n-                pack_weights[p_target] += delta_val\n-                improved_any = True\n+            # Check swaps for top-K heaviest packs to reduce max load or variance.\n+            # Sorting helps to focus on the most critical packs first.\n+            sorted_indices = torch.argsort(pack_weights, descending=True)\n+            top_k = min(num_packs, 4)\n+\n+            for k in range(top_k):\n+                source_pack = sorted_indices[k].item()\n+\n+                # Multiple passes for each heavy pack to clear easy swaps\n+                for _ in range(5):\n+                    w_source = pack_weights[source_pack].item()\n+\n+                    # Items in source pack: [G]\n+                    u_indices = pack_assignment[source_pack]\n+                    w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n+\n+                    # Items in all packs: [M, G]\n+                    w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n+\n+                    # Deltas: w_u - w_v. Shape [M, G, G]\n+                    # delta > 0 implies item u is heavier than item v\n+                    deltas = w_u - w_v\n+\n+                    # We want to swap u (heavy) with v (light) such that:\n+                    # w_source decreases and w_target doesn't exceed original w_source\n+                    # To minimize variance: d < w_s - w_t\n+\n+                    diffs = (w_source - pack_weights).view(num_packs, 1, 1)\n+                    mask = (deltas > 1e-5) & (deltas < diffs)\n+\n+                    if not mask.any():\n+                        break\n+\n+                    # Gain metric: maximize delta * (diff - delta)\n+                    # This prefers large delta that fits in the gap\n+                    gains = deltas * (diffs - deltas)\n+                    gains = torch.where(mask, gains, -1.0)\n+\n+                    best_val, best_flat_idx = gains.view(-1).max(0)\n+\n+                    if best_val < 0:\n+                        break\n+\n+                    best_flat = best_flat_idx.item()\n+                    p_target = best_flat // (groups_per_pack * groups_per_pack)\n+\n+                    # Safety check: if target became heavier than source due to other swaps\n+                    if pack_weights[p_target] >= w_source:\n+                        break\n+\n+                    rem = best_flat % (groups_per_pack * groups_per_pack)\n+                    u_pos = rem // groups_per_pack\n+                    v_pos = rem % groups_per_pack\n+\n+                    # Apply Swap\n+                    item_u = pack_assignment[source_pack, u_pos].item()\n+                    item_v = pack_assignment[p_target, v_pos].item()\n+                    delta_val = deltas.view(-1)[best_flat].item()\n+\n+                    pack_assignment[source_pack, u_pos] = item_v\n+                    pack_assignment[p_target, v_pos] = item_u\n+                    pack_weights[source_pack] -= delta_val\n+                    pack_weights[p_target] += delta_val\n+                    improved_any = True\n \n             # Phase 2: K-Way LNS (Ruin & Recreate)\n-            # Pick max, min, and a random pack to reshuffle together\n             if num_packs >= 2:\n-                for _ in range(5):\n+                # Increased LNS iterations\n+                for _ in range(10):\n                     max_p = torch.argmax(pack_weights).item()\n                     min_p = torch.argmin(pack_weights).item()\n \n                     if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n-                        break # Perfectly balanced\n-\n-                    lns_packs = [max_p, min_p]\n-                    if num_packs > 2:\n-                        p3 = random.randint(0, num_packs - 1)\n-                        while p3 in lns_packs:\n-                            p3 = random.randint(0, num_packs - 1)\n-                        lns_packs.append(p3)\n+                        break\n+\n+                    # Select packs: Max, Min, and up to 2 random others\n+                    lns_packs = {max_p, min_p}\n+                    while len(lns_packs) < min(num_packs, 4):\n+                         lns_packs.add(random.randint(0, num_packs - 1))\n+\n+                    lns_indices = list(lns_packs)\n \n                     # Collect items\n                     items_flat = []\n-                    for p in lns_packs:\n+                    for p in lns_indices:\n                         items_flat.extend(pack_assignment[p].tolist())\n \n                     # Solve sub-problem\n-                    curr_sub_max = max(pack_weights[p].item() for p in lns_packs)\n-                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n+                    curr_sub_max = max(pack_weights[p].item() for p in lns_indices)\n+                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_indices)\n \n                     best_sub_assign = None\n                     best_sub_weights = None\n                     found_lns_improvement = False\n \n                     # Strategies: Deterministic LPT + Random Noise\n                     strategies = []\n                     strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n-                    for _ in range(3):\n-                         # Perturb weights\n-                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.9, 1.1), reverse=True))\n+                    # More random perturbations\n+                    for _ in range(5):\n+                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.85, 1.15), reverse=True))\n \n                     for item_order in strategies:\n-                        temp_bins = [[] for _ in lns_packs]\n-                        temp_ws = [0.0] * len(lns_packs)\n-                        temp_cts = [0] * len(lns_packs)\n+                        temp_bins = [[] for _ in lns_indices]\n+                        temp_ws = [0.0] * len(lns_indices)\n+                        temp_cts = [0] * len(lns_indices)\n \n                         possible = True\n                         for idx in item_order:\n                             w_val = layer_weights[idx]\n+                            # Greedy Best Fit on Subset\n                             best_b = -1\n                             min_local_w = float('inf')\n-                            for b in range(len(lns_packs)):\n+                            for b in range(len(lns_indices)):\n                                 if temp_cts[b] < groups_per_pack:\n                                     if temp_ws[b] < min_local_w:\n                                         min_local_w = temp_ws[b]\n                                         best_b = b\n                             if best_b == -1:\n                                 possible = False\n                                 break\n                             temp_bins[best_b].append(idx)\n                             temp_ws[best_b] += w_val\n                             temp_cts[best_b] += 1\n \n                         if possible:\n                             new_max = max(temp_ws)\n                             new_ss = sum(x*x for x in temp_ws)\n \n                             if new_max < curr_sub_max - 1e-6:\n                                 curr_sub_max = new_max\n                                 curr_sub_ss = new_ss\n                                 best_sub_assign = temp_bins\n                                 best_sub_weights = temp_ws\n                                 found_lns_improvement = True\n                             elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                 curr_sub_ss = new_ss\n                                 best_sub_assign = temp_bins\n                                 best_sub_weights = temp_ws\n                                 found_lns_improvement = True\n \n                     if found_lns_improvement:\n-                        for i_idx, p_idx in enumerate(lns_packs):\n+                        for i_idx, p_idx in enumerate(lns_indices):\n                             pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                             pack_weights[p_idx] = best_sub_weights[i_idx]\n                         improved_any = True\n \n             if not improved_any:\n                 break\n \n         # Final write to output tensors\n         # Move pack_assignment to device for scatter\n         flat_experts = pack_assignment.view(-1).to(device)\n         pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n         rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n \n     return pack_index, rank_in_pack\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n \n     Parameters:\n         weight: [X, num_log]\n         num_phy: total number of experts after replication\n \n     Returns:\n         phy2log: [X, num_phy], logical expert id of each physical expert\n         rank: [X, num_phy], the replica rank\n         logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n     for i in range(num_log, num_phy):\n         redundant_indices = (weight / logcnt).max(dim=-1).indices\n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n         logcnt[arangen, redundant_indices] += 1\n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Parameters:\n         weight: [num_moe_layers, num_logical_experts]\n         num_physical_experts: number of physical experts after replication\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n         (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [num_moe_layers, num_physical_experts]\n         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n         logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n \n     Parameters:\n         weight: [layers, num_logical_experts], the load statistics for all\n             logical experts\n         num_replicas: number of physical experts, must be a multiple of\n             `num_gpus`\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n             (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [layers, num_replicas], the expert index of\n             each replica\n         logical_to_physical_map: [layers, num_logical_experts, X], the replica\n             indices for each expert\n         expert_count: [layers, num_logical_experts], number of physical\n             replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n \n \n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385873149429,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.3110771746298858,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.05481871,
        0.021612989,
        0.013796501,
        -0.040907428,
        -0.025848353,
        0.01688407,
        -0.010318681,
        -0.0076557957,
        -0.022921475,
        0.029498342,
        0.03170211,
        0.022588614,
        -0.0068523386,
        -0.020993179,
        0.016929982,
        0.017595705,
        -0.010404766,
        0.014335965,
        -0.0076443176,
        0.053992298,
        0.0047662207,
        -0.01099588,
        0.027317531,
        -0.04044831,
        -0.0029613122,
        0.011294307,
        0.061062716,
        -0.0446722,
        0.030485447,
        -0.047931936,
        0.080024295,
        -0.01105327,
        0.015196811,
        0.004387448,
        -0.015104988,
        0.033079464,
        -0.0064735664,
        0.008384646,
        0.013440684,
        0.06143001,
        0.02867193,
        -0.026054956,
        -0.045314964,
        0.039690766,
        -0.036706496,
        0.028717842,
        0.007787792,
        -0.01026703,
        0.07864694,
        0.0047375257,
        0.03808385,
        0.015690364,
        -0.0012310107,
        0.06652623,
        0.027363444,
        0.041205857,
        0.019260008,
        0.020912834,
        0.01678077,
        -0.04646276,
        0.051880352,
        -0.017962998,
        0.07153061,
        0.041274723,
        -0.032643303,
        0.0033859964,
        -0.03675241,
        0.028648974,
        0.022542702,
        -0.01212072,
        -0.03835932,
        0.04405239,
        -0.023323203,
        -0.027478222,
        0.000635233,
        0.008344472,
        -0.01946661,
        0.042009313,
        -0.028120987,
        -0.044741064,
        -0.029704945,
        -0.0078107477,
        0.049906146,
        0.019087838,
        0.012832353,
        -0.07580041,
        -0.021532642,
        -0.040126927,
        -0.032253053,
        -0.024470998,
        0.0353521,
        -0.04880426,
        -0.0010782103,
        0.03220714,
        0.041527238,
        -0.031885758,
        0.060787246,
        0.013934237,
        0.034755245,
        0.056379713,
        -0.013302949,
        0.017239887,
        -0.056471534,
        -0.0004379557,
        0.027019104,
        0.009865302,
        0.0058681043,
        -0.0021894197,
        0.013038956,
        -0.01828438,
        -0.039920326,
        0.019707648,
        0.02995746,
        0.009750522,
        0.015954357,
        0.0065826066,
        -0.042330697,
        -0.01997164,
        0.009526702,
        -0.025802441,
        -0.026766589,
        -0.037555866,
        0.025228543,
        -0.025274456,
        0.00936601,
        -0.038795486,
        0.009779217,
        -0.03289582,
        0.006823644,
        0.00025359105,
        0.043248933,
        0.023277292,
        0.010904057,
        -0.022014717,
        -0.021590032,
        0.0032396526,
        -0.022646004,
        0.0059685363,
        -0.005474984,
        -0.016413474,
        -0.02340355,
        0.030324755,
        -0.0145425685,
        -0.009630004,
        -0.049171556,
        0.051650796,
        -0.002592583,
        0.0140031045,
        -0.040746737,
        0.03181689,
        0.015437849,
        -0.033584494,
        -0.0127290515,
        -0.011196745,
        0.0015437849,
        -0.012281411,
        0.006525217,
        0.015621495,
        0.08112618,
        -0.03441091,
        -0.026422251,
        0.027065016,
        -0.02518263,
        0.023300247,
        0.034089524,
        0.029590167,
        -0.04976841,
        0.00375903,
        -0.05858348,
        -0.062072776,
        -0.00070732896,
        -0.023483895,
        -0.0059226244,
        -0.015885489,
        0.0023113731,
        0.0140031045,
        -0.024677603,
        -0.036545806,
        -0.03080683,
        -0.041114032,
        -0.022795217,
        -0.01497873,
        -0.015977312,
        -0.008987239,
        -0.05082438,
        0.027133884,
        -0.02855715,
        -0.013521031,
        -0.010651542,
        -0.0055725467,
        0.015587062,
        0.04432786,
        -0.03608669,
        0.032138273,
        -0.0017575617,
        -0.019225573,
        0.052523118,
        0.015403415,
        0.002731753,
        -0.0076328395,
        -0.038795486,
        -0.010066166,
        0.03707379,
        -0.04304233,
        0.04639389,
        0.0384741,
        -0.011133616,
        0.012407669,
        0.012051852,
        -0.007311457,
        0.035329144,
        -0.024425087,
        0.034479775,
        -0.0018149515,
        -0.027684826,
        -0.026261559,
        -0.049171556,
        0.014990209,
        0.0031994798,
        0.06693943,
        -0.019765038,
        0.018215513,
        -0.027019104,
        0.0048953476,
        -0.042238872,
        0.020120854,
        0.051191676,
        -0.017216932,
        0.007288501,
        0.006301397,
        -0.030393623,
        -0.0015409153,
        -0.010984402,
        -0.027225707,
        0.03080683,
        -0.030370668,
        -0.03422726,
        0.018938625,
        -0.014462222,
        -0.035719395,
        0.020476671,
        0.042147048,
        0.009572614,
        -0.045154274,
        0.006548173,
        0.017595705,
        -0.040838562,
        -0.01453109,
        0.0056471536,
        -0.022186887,
        0.022359055,
        -0.045200184,
        0.02463169,
        -0.058675304,
        -0.016929982,
        0.032574434,
        -0.01845655,
        -0.053946387,
        -0.018376205,
        -0.027524134,
        0.016252784,
        -0.017182497,
        -0.0035839912,
        -0.022932952,
        -0.019776516,
        -0.0020143809,
        -0.0028924444,
        0.03597191,
        -0.044809934,
        -0.020293023,
        0.029544255,
        0.016011747,
        -0.016011747,
        0.038014986,
        -0.04292755,
        -0.01577071,
        0.0034806896,
        -0.01784822,
        -0.034525685,
        -0.04444264,
        -0.024379175,
        -0.001231728,
        0.040654913,
        -0.000640972,
        0.012476536,
        -0.00364712,
        -0.002615539,
        0.027845517,
        0.009641482,
        -0.02245088,
        0.002199463,
        -0.023920057,
        0.03897913,
        0.013429207,
        -0.007443453,
        -0.021027612,
        -0.05757342,
        -0.01610357,
        -0.0016370432,
        -0.008510903,
        0.010628586,
        -0.0011234048,
        -0.0073745856,
        0.0073860637,
        -0.006536695,
        -0.025274456,
        -0.015518194,
        0.01744649,
        -0.015621495,
        -0.023988925,
        -0.01453109,
        0.010904057,
        -0.021463774,
        -0.00065137394,
        -0.028258724,
        0.0025768008,
        0.032803994,
        0.004134933,
        -0.014335965,
        -0.052660853,
        -0.055231918,
        -0.044075344,
        0.040149882,
        0.027294576,
        0.0017216932,
        0.022404967,
        -0.046554584,
        0.018651675,
        -0.0066399965,
        -0.013038956,
        0.005021605,
        0.039048,
        0.02828168,
        0.027363444,
        0.014094928,
        -0.04448855,
        0.0316562,
        -0.004628485,
        0.044190124,
        0.018984536,
        -0.060833156,
        0.024976028,
        -0.015311591,
        -0.024838293,
        -0.04669232,
        0.017664572,
        0.058445744,
        0.027799604,
        0.026422251,
        0.07814191,
        -0.0361326,
        -0.017687527,
        -0.015495238,
        0.016229827,
        0.012935654,
        -0.024172572,
        -0.0003063179,
        0.004169367,
        -0.043157108,
        0.0042841462,
        -0.026238604,
        -0.0057389773,
        0.028717842,
        -0.0061579226,
        -0.0068465997,
        0.06648031,
        0.031564374,
        0.013612853,
        0.010140773,
        0.007747619,
        0.041894533,
        -0.0029369215,
        -0.023690498,
        0.005193774,
        -0.013957192,
        -0.015839577,
        0.023185467,
        0.053211797,
        -0.026399296,
        0.0047145695,
        0.02362163,
        0.019948684,
        -0.020557016,
        0.009015933,
        0.01857133,
        0.03317129,
        -0.011070487,
        0.017721962,
        -0.07134696,
        0.00869455,
        0.04829923,
        -0.015472283,
        -0.021612989,
        -0.047610555,
        0.03640807,
        -0.01497873,
        -0.03776247,
        -0.023713453,
        0.04669232,
        0.009951387,
        -0.010628586,
        0.007110593,
        -0.038221586,
        -0.017825263,
        -0.02715684,
        0.013750589,
        0.04556748,
        0.01862872,
        -0.0054405504,
        0.042491388,
        0.032620344,
        -0.033538584,
        0.013199648,
        0.005268381,
        0.011208222,
        -0.03438795,
        0.005549591,
        0.037165616,
        0.004180845,
        -0.005595503,
        -0.007885355,
        -0.0071048536,
        0.018445073,
        -0.0073458906,
        -0.01851394,
        0.015954357,
        0.017205454,
        -0.014267097,
        0.013704677,
        -0.06147592,
        -0.011730469,
        0.0044390988,
        0.06441428,
        -0.030118152,
        0.021865504,
        0.036385115,
        -0.005592633,
        0.028120987,
        -9.702458e-05,
        -0.0023386332,
        0.0076443176,
        -0.014944296,
        -0.012384713,
        -0.018192558,
        0.021394907,
        -0.014221186,
        0.0038537232,
        -0.052247647,
        0.051145766,
        -0.007443453,
        0.01408345,
        -0.016344607,
        0.054221857,
        0.0041205855,
        -0.021670377,
        -0.05279859,
        0.07341299,
        0.03310242,
        0.050640736,
        -0.020270068,
        0.043639183,
        0.015414893,
        0.0011069052,
        -0.029314695,
        0.052431297,
        0.015139421,
        0.004875261,
        -0.0050244746,
        0.007994395,
        0.027960297,
        0.06037404,
        -0.0477942,
        -0.0034749506,
        0.038910266,
        -0.03085274,
        0.009406184,
        -0.016792247,
        0.06363378,
        0.029773813,
        -0.048941996,
        0.02839646,
        -0.049171556,
        -0.032230094,
        -0.041756798,
        0.027868474,
        0.02715684,
        0.03507663,
        0.0035552965,
        0.0033458236,
        0.025343323,
        0.0281669,
        -0.014622914,
        0.008063263,
        -0.009911214,
        0.0008744766,
        -0.007523799,
        -0.014462222,
        -0.025044896,
        0.0038164197,
        0.049171556,
        0.008803591,
        -0.086543776,
        -0.05885895,
        -0.021073524,
        0.017526837,
        -0.036821276,
        -0.031403683,
        0.0028766622,
        -0.0036844234,
        0.03877253,
        -0.020178244,
        -0.006502261,
        0.027271619,
        0.031495508,
        -0.00847073,
        0.03539801,
        -0.00678921,
        0.012614272,
        0.006289919,
        0.031495508,
        -0.031128213,
        -0.020270068,
        -0.04797785,
        0.026330426,
        0.03073796,
        -0.036040775,
        -0.015472283,
        -0.057940714,
        0.0141752735,
        -0.004932651,
        -0.017262843,
        -0.013429207,
        -0.053028148,
        0.02851124,
        -0.018950103,
        0.027615959,
        -0.0018407769,
        -0.039621897,
        -0.030232932,
        -0.039461207,
        0.0045854426,
        0.015013164,
        0.020499626,
        0.020786576,
        0.009044628,
        -0.040769693,
        0.0695564,
        0.028924445,
        0.027615959,
        0.026054956,
        0.0071507655,
        -0.044626288,
        0.0021664638,
        -0.004068935,
        -0.027570046,
        -0.018984536,
        -0.011236917,
        -0.046646405,
        0.028143944,
        0.04662345,
        0.023552762,
        -0.0055696773,
        0.009492268,
        -0.00019655997,
        0.001946948,
        0.009687393,
        0.020855444,
        -0.043478493,
        0.016849637,
        0.0041951924,
        -0.011971506,
        0.013176692,
        0.010146512,
        -0.06441428,
        0.02294443,
        -0.0022468097,
        0.02154412,
        -0.024884205,
        -0.005099081,
        -0.010858145,
        -0.027340487,
        -0.021027612,
        -0.018307338,
        -0.026973194,
        -0.053579092,
        -0.00914219,
        -0.02979677,
        -0.011856726,
        -0.004157889,
        -0.027478222,
        -0.0042152787,
        -0.00020588581,
        0.036155555,
        -0.01733171,
        0.01503612,
        -0.004815002,
        -0.040241707,
        0.011787859,
        0.02766187,
        0.009962864,
        -0.018031865,
        0.06285328,
        0.0005638545,
        0.019673213,
        -0.028580107,
        0.002373067,
        0.0074262363,
        0.0076156226,
        0.002165029,
        -0.03278104,
        -0.00802309,
        -0.016424952,
        -0.030944565,
        -0.010559718,
        -0.0076615345,
        0.005638545,
        0.05532374,
        0.0017948651,
        0.011472215,
        -0.01958139,
        -0.009607048,
        0.042330697,
        0.010961446,
        -0.016424952,
        -0.0008658682,
        -0.0102383355,
        -0.011701775,
        -0.0046973526,
        -0.028258724,
        0.015414893,
        -0.03881844,
        -0.014898385,
        -0.02266896,
        0.025802441,
        -0.000824978,
        0.06505705,
        0.024470998,
        0.0332172,
        0.008574032,
        -0.012040374,
        0.028442372,
        -0.0060546207,
        0.015942879,
        -0.039002087,
        0.013543986,
        0.02266896,
        -0.0030330494,
        -0.0052482947,
        0.008855241,
        -0.0106917145,
        -0.004229626,
        -0.018077778,
        0.034938894,
        0.03590304,
        0.030623183,
        -0.015632974,
        -0.0102096405,
        -0.036614675,
        -0.027845517,
        -0.00043939042,
        -0.03730335,
        -0.01122544,
        -0.009991559,
        -0.022370532,
        0.01536898,
        0.026835456,
        0.020843966,
        0.0013479423,
        0.0040000672,
        0.050640736,
        -0.009406184,
        0.027340487,
        0.024861248,
        -0.04393761,
        -0.037119705,
        -0.018307338,
        -0.028258724,
        0.01492134,
        0.0008407601,
        0.01969617,
        0.010571196,
        -0.020407803,
        -0.03080683,
        -0.0076557957,
        -0.010812233,
        0.027822562,
        0.023265813,
        -0.0017876914,
        0.03569644,
        -0.019891296,
        0.014152317,
        -0.013509552,
        -0.03558166,
        -0.014037538,
        0.016241305,
        0.04398352,
        0.0077648363,
        0.008872459,
        -0.018525418,
        -0.046600495,
        -0.010020254,
        0.00039240255,
        -0.028534194,
        -0.01206333,
        -0.039369382,
        -0.020074941,
        -0.045154274,
        0.046164334,
        0.02239349,
        -0.0024333263,
        -0.042078182,
        0.0035438184,
        -0.020671796,
        -0.020235633,
        -0.07198973,
        0.0037848554,
        -6.985411e-05,
        0.0111450935,
        0.025274456,
        -0.040999252,
        -0.0076615345,
        0.0036959013,
        -0.038405236,
        0.0020100768,
        0.048850175,
        0.01604618,
        0.013911281,
        0.0035811218,
        0.006215312,
        0.00036316965,
        0.010800755,
        -0.017802307,
        0.019432176,
        -0.034938894,
        0.037555866,
        -0.006255485,
        -0.0003034484,
        -0.03344676,
        -0.024103705,
        0.011300046,
        -0.0068810335,
        -0.025320368,
        0.018020388,
        -0.004140672,
        0.010640063,
        0.0019828165,
        -0.0042841462,
        0.035099585,
        -0.015610018,
        0.022921475,
        -0.033033554,
        0.0064219153,
        -0.026743634,
        -0.0024921508,
        0.044649243,
        0.032574434,
        0.017538315,
        -0.009079061,
        -0.0039082435,
        0.010376071,
        -0.019604346,
        -0.018112212,
        -0.020488149,
        0.018031865,
        0.011960029,
        0.0030847003,
        -0.047380995,
        -0.0036643369,
        0.012763485,
        -0.041664973,
        -0.023667542,
        -0.008660116,
        0.049355205,
        0.049447026,
        0.025802441,
        -0.03558166,
        0.013176692,
        -0.053303618,
        0.00768449,
        -0.02199176,
        -0.015954357,
        -0.019501043,
        -0.031610288,
        0.0018881235,
        0.0043903175,
        0.0051909047,
        -0.058170274,
        -0.020453714,
        -0.011305785,
        -0.011489432,
        -0.06165957,
        -0.014278575,
        -0.0011341653,
        -0.02294443,
        -0.013452162,
        0.015805144,
        -0.03702788,
        -0.051145766,
        0.008958544,
        0.016482342,
        -0.0032568695,
        0.003429039,
        0.023828233,
        -0.001553828,
        -0.009997298,
        -0.009664438,
        -0.05504827,
        0.0036385115,
        -0.03881844,
        0.018387683,
        0.018192558,
        -4.7122383e-05,
        -0.035260275,
        0.0047260476,
        0.06514887,
        -0.025090808,
        -0.04607251,
        -0.04499358,
        0.027570046,
        -0.01167308,
        -0.025504015,
        -0.0462332,
        0.042973462,
        0.009911214,
        -0.05008979,
        -0.0132111255,
        -0.013601376,
        0.0016729118,
        0.010370332,
        -0.016734857,
        0.0010782103,
        -0.023759365,
        0.009566875,
        0.012017418,
        0.004832219,
        0.01357842,
        0.005408986,
        -0.007839443,
        -0.0068064267,
        0.025779486,
        0.032528523,
        0.008126392,
        3.7056754e-05,
        -0.026261559,
        0.016711902,
        0.0115697775,
        0.03799203,
        0.03753291,
        -0.026169736,
        -0.017308755,
        -0.016734857,
        0.011437781,
        0.025090808,
        -0.01206333,
        -0.0053946385,
        0.01919114,
        0.017148064,
        -0.0071220705,
        0.012889743,
        -0.008786374,
        -0.013934237,
        -0.040081017,
        0.011173788,
        -0.028143944,
        0.006347309,
        -0.02529741,
        0.026307471,
        0.03216123,
        -0.003394605,
        0.00021700507,
        0.012281411,
        -0.03248261,
        0.01979947,
        0.020040508,
        -0.010014515,
        -0.018674633,
        -0.013991626,
        0.01750388,
        -0.043065283,
        -0.011741947,
        -0.0019885555,
        -0.014909863,
        -0.014313009,
        0.0061349664,
        -0.0038738095,
        0.019432176,
        0.008487947,
        -0.0023013297,
        0.034709334,
        0.024103705,
        -0.0022138103,
        0.008109175,
        0.016367562,
        0.018502463,
        0.030232932,
        0.027432311,
        -0.0062210513,
        -0.002289852,
        0.027225707,
        -0.004341536,
        -0.009710349,
        0.0018379075,
        -0.016470864,
        0.045751125,
        -0.01756127,
        -0.012315845,
        -0.0055122874,
        0.01004321,
        0.028694885,
        -0.051880352,
        0.07139288,
        -0.008998716,
        -0.0316562,
        -0.0115984725,
        0.00880933,
        -0.024585778,
        0.014358921,
        0.026284516,
        0.011529605,
        -0.003360171,
        0.026996149,
        -0.023828233,
        0.0066342577,
        0.012614272,
        0.0084535135,
        -0.003959894,
        0.008901154,
        -0.03620147,
        0.053670913,
        -0.013601376,
        0.01251097,
        -0.022370532,
        0.02171629,
        -0.00274897,
        0.0030330494,
        -0.011667341,
        -0.014795084,
        -0.008338734,
        -0.014565524,
        0.004367362,
        -0.052477207,
        -0.007713185,
        -0.0039197216,
        0.015173855,
        -0.03317129,
        -0.031151168,
        -0.0025839745,
        -0.0145425685,
        -0.013543986,
        -0.018112212,
        0.0316562,
        -0.05036526,
        0.053716827,
        0.0020330327,
        -0.03287286,
        0.03427317,
        0.00768449,
        -0.0049957796,
        0.002249679,
        0.021440819,
        0.042330697,
        -0.0047604814,
        -0.024700558,
        0.0036069471,
        0.012017418,
        0.009767739,
        0.008223955,
        -0.005222469,
        -0.04618729,
        0.013165213,
        0.03287286,
        -0.022014717,
        0.020579971,
        -0.0070761587,
        0.00937175,
        -0.042904593,
        0.008143608,
        -0.014611436,
        0.05858348,
        -0.0158281,
        0.018169602,
        0.0067031253,
        -0.041619062,
        0.03080683,
        0.054680973,
        -0.005592633,
        0.04584295,
        0.0024792382,
        0.0054950705,
        -0.026123824,
        0.054956444,
        0.027133884,
        0.00785666,
        -0.0062325294,
        0.010192423,
        0.011833771,
        -0.012878264,
        -0.018502463,
        -0.021647422,
        -0.00555533,
        -0.036224425,
        0.007805009,
        0.028694885,
        -0.0037791166,
        0.0089068925,
        0.006266963,
        0.017193975,
        -0.018387683,
        0.006347309,
        0.0041091074,
        0.026766589,
        -0.035030715,
        -0.019650258,
        0.014783605,
        -0.039575987,
        -0.013279993,
        -0.033469714,
        0.009176624,
        -0.028258724,
        -0.008665855,
        -0.006278441,
        -0.042147048,
        0.0005405399,
        -0.012648705,
        -0.014852473,
        0.008516642,
        0.023667542,
        -0.045475654,
        0.021016134,
        -0.020338936,
        0.028580107,
        -0.0071507655,
        -0.030898653,
        0.018422117,
        -0.012201065,
        -0.04017284,
        -0.0039025045,
        0.024539866,
        0.024539866,
        0.0011678819,
        -0.024976028,
        0.0310823,
        -0.02502194,
        0.016264262,
        0.027019104,
        -0.0058709737,
        -0.0058594956,
        0.013658766,
        -0.016459387,
        -0.0073745856,
        -0.05803254,
        -0.0046715275,
        -0.0102096405,
        0.028189857,
        0.026307471,
        0.019902773,
        -0.0001681341,
        7.505506e-05,
        -0.0038967654,
        -0.008625682,
        0.021199781,
        0.0069728573,
        -0.042238872,
        -0.019225573,
        0.010450677,
        0.009572614,
        -0.027524134,
        -0.021234216,
        0.0012044678,
        0.001091123,
        0.0029326172,
        0.008660116,
        -0.012017418,
        0.021303084,
        0.009572614,
        -0.0059168856,
        0.00448788,
        0.018640198,
        -0.011202483,
        -0.04662345,
        -0.008005873,
        0.0035151234,
        5.2502673e-05,
        -0.008384646,
        -0.01548376,
        0.043271888,
        0.038910266,
        0.001144926,
        0.014795084,
        -0.027615959,
        -0.0022410706,
        0.024149615,
        0.02715684,
        -0.009876779,
        0.016000269,
        -0.020970222,
        0.020051986,
        0.017997433,
        -0.023082167,
        0.012706095,
        0.00043149936,
        0.003119134,
        -0.0043817093,
        -0.010450677,
        -0.027593002,
        -0.0433178,
        -0.012028896,
        -0.010479372,
        0.028626017,
        -0.010955707,
        0.029360607,
        -0.015059076,
        0.020281546,
        0.028717842,
        -0.0066973865,
        -0.02490716,
        0.0038623316,
        -0.005067517,
        0.020648839,
        0.020981701,
        -0.025320368,
        0.0013235516,
        -0.029498342,
        0.03496185,
        -0.03340085,
        -0.005056039,
        0.008677334,
        0.026100868,
        0.01633313,
        -0.0034778202,
        0.028534194,
        -0.060465865,
        0.034640465,
        0.022026194,
        -0.010990141,
        -0.020993179,
        -0.030715005,
        0.0076271007,
        -0.0064333933,
        0.03539801,
        -0.0013579854,
        -0.017021807,
        0.042675033,
        0.014071972,
        -0.002827881,
        -0.005314293,
        0.0066055628,
        0.07171426,
        0.006272702,
        -0.0033085204,
        0.009343055,
        0.011173788,
        0.026996149,
        -0.01890419,
        -0.0068465997,
        0.020178244,
        -0.041136988,
        -0.03046249,
        0.02991155,
        -0.0045481394,
        -0.021498209,
        -0.005503679,
        0.017974477,
        -0.043455534,
        0.015196811,
        -0.019397743,
        0.013888325,
        -0.0066629522,
        -0.00018956559,
        -0.003652859,
        -0.022760784,
        0.0017733439,
        -0.033033554,
        0.0026772327,
        -0.021704812,
        -0.015965834,
        0.021612989,
        -0.023300247,
        -0.026215648,
        0.009113496,
        0.0074549313,
        -0.01655121,
        0.014221186,
        0.020866921,
        0.004582573,
        -0.0012281411,
        0.008912631,
        -0.016929982,
        -0.0024505432,
        -0.031885758,
        -0.016356084,
        -0.019673213,
        -0.008551076,
        -0.017090674,
        0.017905608,
        0.006978596,
        0.0053659435,
        0.008378906,
        -0.01627574,
        0.004668658,
        -0.024700558,
        -0.024976028,
        0.0006384612,
        0.032298964,
        0.059501715,
        -0.03909391,
        0.010668758,
        -0.006726081,
        -0.0052769897,
        -0.005928363,
        0.028258724,
        0.019765038,
        -0.014726215,
        -0.013566942,
        -0.024976028,
        -0.012797919,
        0.029590167,
        -0.028465327,
        -0.0006305701,
        -0.0058881906,
        -0.02177368,
        0.028098032,
        -0.004470663,
        -0.013050434,
        0.024769425,
        0.020361891,
        -0.03328607,
        -0.0128438305,
        0.007368847,
        -0.00033429542,
        0.012028896,
        -0.028970357,
        -0.02591722,
        0.030875698,
        0.022909997,
        -0.025802441,
        0.003053136,
        -0.0056930655,
        0.020878399,
        0.028327592,
        0.03966781,
        -0.020855444,
        -0.011891161,
        -0.004200931,
        -0.008637161,
        -0.013543986,
        0.023943013,
        -0.011317263,
        0.012614272,
        0.013440684,
        0.020109376,
        -0.02385119,
        0.03753291,
        -0.0035495574,
        -0.007064681,
        -0.042996418,
        -0.04903382,
        0.03815272,
        -0.0039426773,
        0.027570046,
        -0.03893322,
        -0.039805546,
        0.03897913,
        0.041435417,
        0.037670646,
        -0.0153919365,
        -0.016149482,
        0.021417862,
        -0.010576935,
        0.008883936,
        0.006829383,
        -0.035489835,
        0.027340487,
        0.0044075344,
        0.03516845,
        -0.024080748,
        0.011621429,
        0.0037963334,
        -0.015288635,
        0.028419415,
        -0.016287217,
        0.035994865,
        0.0006847317,
        0.0054003773,
        -0.038175676,
        -0.018376205,
        0.038841397,
        -0.03955303,
        0.011248395,
        0.012269933,
        0.031220036,
        -0.03831341,
        0.0015983052,
        0.021532642,
        -0.017974477,
        0.03652285,
        -0.021394907,
        0.024815338,
        -0.025871309,
        -0.020602928,
        -0.040609002,
        0.01610357,
        -0.016826682,
        -0.0040947604,
        0.011179527,
        0.010594152,
        0.00015979464,
        -0.01694146,
        -0.024585778,
        -0.015219768,
        0.018031865,
        0.014565524,
        0.010094861,
        -0.02183107,
        0.007563972,
        0.027960297,
        0.017090674,
        0.010640063,
        0.0057102824,
        0.019707648,
        -0.021440819,
        -0.011535344,
        -0.0056815874,
        0.009400445,
        -0.006530956,
        0.0035983387,
        0.019719126,
        -0.01907636,
        0.023162512,
        0.024310308,
        -0.0019785124,
        0.031403683,
        -0.057986625,
        0.0011693166,
        0.00392833,
        0.028763754,
        0.006708864,
        0.03473229,
        -0.0008056089,
        0.023828233,
        -0.013176692,
        0.044006478,
        0.031288903,
        -0.01734319,
        0.006599824,
        -0.010599891,
        0.021245694,
        0.029475387,
        0.01554115,
        -0.011960029,
        -0.029131047,
        -0.011678819,
        0.02199176,
        -0.0012023157,
        0.01689555,
        0.02115387,
        -0.054543238,
        0.0011901204,
        -0.0065653897,
        0.0012719008,
        0.025963133,
        0.017297277,
        0.00065496075,
        -0.015862532,
        0.0034347777,
        0.0072425893,
        -0.010014515,
        0.007868137,
        0.017928565,
        0.02428735,
        -0.01688407,
        0.01639052,
        -0.011810815,
        -0.01167308,
        -0.008223955,
        -0.019925728,
        0.017274322,
        0.034640465,
        -0.002827881,
        0.029222872,
        -0.0074491925,
        0.00970461,
        0.011242656,
        -0.0011858161,
        0.0015122205,
        0.04421308,
        -0.025664706,
        -0.0010538197,
        0.02490716,
        0.02715684,
        -0.004060326,
        -0.0398285,
        -0.0067146034,
        -0.0045309225,
        0.006089055,
        -0.017607182,
        -0.0030502663,
        -0.014990209,
        0.0153919365,
        -0.010909796,
        -0.0043243193,
        -0.0165053,
        0.014519612,
        0.0281669,
        -0.025343323,
        0.015070554,
        0.016585644,
        0.02502194,
        0.029154005,
        -0.026468163,
        -0.009211059,
        0.018720543,
        0.027707782,
        -0.012212544,
        0.018674633,
        -0.0029813987,
        -0.034204304,
        -0.008189521,
        0.011632906,
        0.027753694,
        0.010330159,
        -0.00751806,
        0.0064276545,
        -0.03271217,
        -0.0016757813,
        0.016023224,
        -0.039415296,
        0.018938625,
        0.0014376137,
        -0.004573965,
        0.01295861,
        0.008820808,
        0.009796434,
        -0.015759232,
        0.01845655,
        0.009498008,
        -0.009773478,
        0.042835724,
        -0.027087972,
        0.008310039,
        -0.025779486,
        -0.00959557,
        -0.040861517,
        -0.017515358,
        -0.024884205,
        0.009980082,
        0.007277023,
        -0.012189588,
        -0.0070876367,
        0.009968603,
        -0.02373641,
        0.009836607,
        -0.007879616,
        0.012017418,
        0.030646138,
        0.0019268616,
        0.0019239921,
        -0.0050129965,
        -0.028924445,
        -0.016356084,
        -0.01829586,
        0.019225573,
        0.00028874227,
        0.017974477,
        -0.02474647,
        -0.010806494,
        0.002901053,
        0.00964722,
        -0.018410638,
        0.006800688,
        0.015219768,
        0.0034175608,
        0.015759232,
        0.008981499,
        0.007948483,
        0.0089355875,
        -0.023208424,
        -0.006266963,
        -0.01946661,
        0.021314561,
        0.008464991,
        -0.010697453,
        0.0069269454,
        0.020040508,
        0.022026194,
        0.030600226,
        -0.00735163,
        -0.007053203,
        0.011477955,
        -0.035925996,
        -0.028258724,
        -0.015885489,
        -0.01678077,
        0.02502194,
        -0.002199463,
        0.016918505,
        0.030118152,
        0.02591722,
        0.04549861,
        -0.038726617,
        -0.01172473,
        0.04448855,
        -0.0008407601,
        -0.027294576,
        -0.006766254,
        -0.013406251,
        0.012465059,
        -0.021394907,
        0.030600226,
        0.026468163,
        -0.011104921,
        0.0016456516,
        -0.031518463,
        -0.009607048,
        -0.016803725,
        0.010485111,
        -0.01627574,
        0.01924853,
        0.004275538,
        0.00549794,
        0.031862803,
        0.0033228677,
        0.0035036455,
        -0.008706029,
        -0.003957025,
        -0.0051536015,
        0.0033171289,
        -0.007099115,
        -0.0034835592,
        -0.010657281,
        -0.029704945,
        0.029154005,
        0.0056414143,
        0.000782653,
        -0.0054864623,
        0.017607182
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 106.43783497810364,
        "patch_type": "diff",
        "api_costs": 0.49764200000000003,
        "num_applied": 1,
        "patch_name": "vectorized_topk_swap_lns_v2",
        "patch_description": "1. Improved the vectorized swap heuristic: Instead of only attempting to balance the single heaviest pack against others, the new \"Top-K vs All\" strategy selects the K heaviest packs (e.g., K=4) and searches for optimal 1-swaps against all other packs. This uses tensor broadcasting to efficiently evaluate thousands of potential swaps in parallel, maximizing the reduction in the Sum of Squared Loads (variance). This broader search helps the system escape local optima where the max pack is stuck but variance can still be reduced.\n2. Enhanced the LNS (Ruin & Recreate) phase: Increased the number of packs involved in the local search from 2-3 to up to 4, allowing for more complex cyclic exchanges (3-way/4-way). Increased the number of randomized restarts within the LNS subroutine to better explore the sub-problem space.\n3. Increased global refinement iterations to utilize the available speed budget for better quality.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 2,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\nvectorized_topk_swap_lns_v2\n</NAME>\n\n<DESCRIPTION>\n1. Improved the vectorized swap heuristic: Instead of only attempting to balance the single heaviest pack against others, the new \"Top-K vs All\" strategy selects the K heaviest packs (e.g., K=4) and searches for optimal 1-swaps against all other packs. This uses tensor broadcasting to efficiently evaluate thousands of potential swaps in parallel, maximizing the reduction in the Sum of Squared Loads (variance). This broader search helps the system escape local optima where the max pack is stuck but variance can still be reduced.\n2. Enhanced the LNS (Ruin & Recreate) phase: Increased the number of packs involved in the local search from 2-3 to up to 4, allowing for more complex cyclic exchanges (3-way/4-way). Increased the number of randomized restarts within the LNS subroutine to better explore the sub-problem space.\n3. Increased global refinement iterations to utilize the available speed budget for better quality.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 5\n        \n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            # This replaces the slow O(G^2 * M) python loop with optimized PyTorch ops on CPU\n            for _ in range(15):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                # Deltas: w_u - w_v. Shape [M, G, G]\n                deltas = w_u - w_v\n                \n                # We want to swap u (from max_pack) with v (from other pack) such that:\n                # 1. max_load decreases: max_w - delta < max_w  => delta > 0\n                # 2. other pack doesn't exceed old max_load: w_v_pack + delta < max_w\n                #    => delta < max_w - w_v_pack\n                \n                diffs = (max_w - pack_weights).view(num_packs, 1, 1)\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                # Gain metric: prefer swaps that balance the two packs (delta close to diff/2)\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Apply Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Pick max, min, and a random pack to reshuffle together\n            if num_packs >= 2:\n                for _ in range(5):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n                    \n                    if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                        break # Perfectly balanced\n\n                    lns_packs = [max_p, min_p]\n                    if num_packs > 2:\n                        p3 = random.randint(0, num_packs - 1)\n                        while p3 in lns_packs:\n                            p3 = random.randint(0, num_packs - 1)\n                        lns_packs.append(p3)\n\n                    # Collect items\n                    items_flat = []\n                    for p in lns_packs:\n                        items_flat.extend(pack_assignment[p].tolist())\n                    \n                    # Solve sub-problem\n                    curr_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                    best_sub_assign = None\n                    best_sub_weights = None\n                    found_lns_improvement = False\n\n                    # Strategies: Deterministic LPT + Random Noise\n                    strategies = []\n                    strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n                    for _ in range(3):\n                         # Perturb weights\n                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.9, 1.1), reverse=True))\n                    \n                    for item_order in strategies:\n                        temp_bins = [[] for _ in lns_packs]\n                        temp_ws = [0.0] * len(lns_packs)\n                        temp_cts = [0] * len(lns_packs)\n                        \n                        possible = True\n                        for idx in item_order:\n                            w_val = layer_weights[idx]\n                            best_b = -1\n                            min_local_w = float('inf')\n                            for b in range(len(lns_packs)):\n                                if temp_cts[b] < groups_per_pack:\n                                    if temp_ws[b] < min_local_w:\n                                        min_local_w = temp_ws[b]\n                                        best_b = b\n                            if best_b == -1:\n                                possible = False\n                                break\n                            temp_bins[best_b].append(idx)\n                            temp_ws[best_b] += w_val\n                            temp_cts[best_b] += 1\n                        \n                        if possible:\n                            new_max = max(temp_ws)\n                            new_ss = sum(x*x for x in temp_ws)\n\n                            if new_max < curr_sub_max - 1e-6:\n                                curr_sub_max = new_max\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n                            elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n\n                    if found_lns_improvement:\n                        for i_idx, p_idx in enumerate(lns_packs):\n                            pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                            pack_weights[p_idx] = best_sub_weights[i_idx]\n                        improved_any = True\n\n            if not improved_any:\n                break\n=======\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 8\n        \n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Check swaps for top-K heaviest packs to reduce max load or variance.\n            # Sorting helps to focus on the most critical packs first.\n            sorted_indices = torch.argsort(pack_weights, descending=True)\n            top_k = min(num_packs, 4)\n            \n            for k in range(top_k):\n                source_pack = sorted_indices[k].item()\n                \n                # Multiple passes for each heavy pack to clear easy swaps\n                for _ in range(5):\n                    w_source = pack_weights[source_pack].item()\n                    \n                    # Items in source pack: [G]\n                    u_indices = pack_assignment[source_pack]\n                    w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                    # Items in all packs: [M, G]\n                    w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                    # Deltas: w_u - w_v. Shape [M, G, G]\n                    # delta > 0 implies item u is heavier than item v\n                    deltas = w_u - w_v\n                    \n                    # We want to swap u (heavy) with v (light) such that:\n                    # w_source decreases and w_target doesn't exceed original w_source\n                    # To minimize variance: d < w_s - w_t\n                    \n                    diffs = (w_source - pack_weights).view(num_packs, 1, 1)\n                    mask = (deltas > 1e-5) & (deltas < diffs)\n\n                    if not mask.any():\n                        break\n\n                    # Gain metric: maximize delta * (diff - delta)\n                    # This prefers large delta that fits in the gap\n                    gains = deltas * (diffs - deltas)\n                    gains = torch.where(mask, gains, -1.0)\n\n                    best_val, best_flat_idx = gains.view(-1).max(0)\n\n                    if best_val < 0:\n                        break\n                    \n                    best_flat = best_flat_idx.item()\n                    p_target = best_flat // (groups_per_pack * groups_per_pack)\n                    \n                    # Safety check: if target became heavier than source due to other swaps\n                    if pack_weights[p_target] >= w_source:\n                        break\n\n                    rem = best_flat % (groups_per_pack * groups_per_pack)\n                    u_pos = rem // groups_per_pack\n                    v_pos = rem % groups_per_pack\n\n                    # Apply Swap\n                    item_u = pack_assignment[source_pack, u_pos].item()\n                    item_v = pack_assignment[p_target, v_pos].item()\n                    delta_val = deltas.view(-1)[best_flat].item()\n\n                    pack_assignment[source_pack, u_pos] = item_v\n                    pack_assignment[p_target, v_pos] = item_u\n                    pack_weights[source_pack] -= delta_val\n                    pack_weights[p_target] += delta_val\n                    improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            if num_packs >= 2:\n                # Increased LNS iterations\n                for _ in range(10):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n                    \n                    if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                        break \n\n                    # Select packs: Max, Min, and up to 2 random others\n                    lns_packs = {max_p, min_p}\n                    while len(lns_packs) < min(num_packs, 4):\n                         lns_packs.add(random.randint(0, num_packs - 1))\n                    \n                    lns_indices = list(lns_packs)\n                    \n                    # Collect items\n                    items_flat = []\n                    for p in lns_indices:\n                        items_flat.extend(pack_assignment[p].tolist())\n                    \n                    # Solve sub-problem\n                    curr_sub_max = max(pack_weights[p].item() for p in lns_indices)\n                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_indices)\n\n                    best_sub_assign = None\n                    best_sub_weights = None\n                    found_lns_improvement = False\n\n                    # Strategies: Deterministic LPT + Random Noise\n                    strategies = []\n                    strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n                    # More random perturbations\n                    for _ in range(5):\n                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.85, 1.15), reverse=True))\n                    \n                    for item_order in strategies:\n                        temp_bins = [[] for _ in lns_indices]\n                        temp_ws = [0.0] * len(lns_indices)\n                        temp_cts = [0] * len(lns_indices)\n                        \n                        possible = True\n                        for idx in item_order:\n                            w_val = layer_weights[idx]\n                            # Greedy Best Fit on Subset\n                            best_b = -1\n                            min_local_w = float('inf')\n                            for b in range(len(lns_indices)):\n                                if temp_cts[b] < groups_per_pack:\n                                    if temp_ws[b] < min_local_w:\n                                        min_local_w = temp_ws[b]\n                                        best_b = b\n                            if best_b == -1:\n                                possible = False\n                                break\n                            temp_bins[best_b].append(idx)\n                            temp_ws[best_b] += w_val\n                            temp_cts[best_b] += 1\n                        \n                        if possible:\n                            new_max = max(temp_ws)\n                            new_ss = sum(x*x for x in temp_ws)\n\n                            if new_max < curr_sub_max - 1e-6:\n                                curr_sub_max = new_max\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n                            elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n\n                    if found_lns_improvement:\n                        for i_idx, p_idx in enumerate(lns_indices):\n                            pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                            pack_weights[p_idx] = best_sub_weights[i_idx]\n                        improved_any = True\n\n            if not improved_any:\n                break\n>>>>>>> REPLACE\n</DIFF>",
          "msg": "The previous edit was not successful. This was the error message: \n\nNo changes applied.\n\n Try again.",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nYou MUST repond using a edit name, description and the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<NAME>\nA shortened name summarizing the edit you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the edit you are proposing.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly including indentation)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\n</DIFF>\n\n\nExample of a valid diff format:\n<DIFF>\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\n</DIFF>\n\n* You may only modify text that lies below a line containing \"EVOLVE-BLOCK-START\" and above the next \"EVOLVE-BLOCK-END\". Everything outside those markers is read-only.\n* Do not repeat the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the SEARCH/REPLACE blocks.  \n* Every block\u2019s SEARCH section must be copied **verbatim** from the current file.  Including indentation.\n* You can propose multiple independent edits. SEARCH/REPLACE blocks follow one after another. DO NOT ADD ANY OTHER TEXT BETWEEN THESE BLOCKS.\n* Make sure the file still runs after your changes.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output tensors\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Number of restarts for randomized greedy\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_weights = weight_cpu[i]\n\n        # Base sort indices (LPT)\n        base_indices = layer_weights.argsort(descending=True).tolist()\n\n        best_assignment = None\n        best_max_load = float('inf')\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Randomized Candidate Generation\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to perturb sort order\n                # 5% noise is usually sufficient to swap similar items\n                noise = torch.rand(num_groups) * 0.05\n                indices = (layer_weights * (1 + noise)).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT / Best Fit)\n            # pack_contents: list of lists storing item indices\n            pack_contents = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_sizes = [0] * num_packs\n\n            for idx in indices:\n                w = layer_weights[idx].item()\n\n                # Find lightest valid pack\n                best_p = -1\n                min_w = float('inf')\n\n                # Simple linear scan is fast for small num_packs\n                for p in range(num_packs):\n                    if pack_sizes[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                pack_contents[best_p].append(idx)\n                pack_weights[best_p] += w\n                pack_sizes[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            # Iteratively improve by repacking subsets of bins\n\n            MAX_LNS_STEPS = 50\n            consecutive_no_improve = 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Sort packs by weight\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                max_p = sorted_packs[0]\n                min_p = sorted_packs[-1]\n\n                # If balanced enough, stop\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                    break\n\n                # Select candidates for LNS: Heaviest, Lightest, and potentially a random one\n                candidates = [max_p, min_p]\n                if num_packs > 2:\n                    # Pick a random pack that is not max or min to facilitate 3-way/4-way cyclic shifts\n                    # Use a simple pseudo-random approach based on step\n                    candidates.append(sorted_packs[(step + 1) % (num_packs - 1) + 1])\n\n                # Collect items from candidates\n                items_to_repack = []\n                for p in candidates:\n                    items_to_repack.extend(pack_contents[p])\n\n                # Sort descending (LPT)\n                items_to_repack.sort(key=lambda x: layer_weights[x].item(), reverse=True)\n\n                # Repack into these bins using Bounded Best Fit\n                new_loads = {p: 0.0 for p in candidates}\n                new_contents = {p: [] for p in candidates}\n                possible = True\n\n                for item_idx in items_to_repack:\n                    w = layer_weights[item_idx].item()\n                    # Assign to candidate bin with min current load that has space\n                    best_local_p = -1\n                    min_local_w = float('inf')\n                    for p in candidates:\n                        if len(new_contents[p]) < groups_per_pack:\n                            if new_loads[p] < min_local_w:\n                                min_local_w = new_loads[p]\n                                best_local_p = p\n\n                    if best_local_p == -1:\n                        possible = False\n                        break\n\n                    new_contents[best_local_p].append(item_idx)\n                    new_loads[best_local_p] += w\n\n                if possible:\n                    # Check improvement criteria\n                    old_local_max = max(pack_weights[p] for p in candidates)\n                    new_local_max = max(new_loads.values())\n\n                    # Accept if max load decreases OR max load is same but variance decreases (better balance)\n                    # Sum of squares is a good proxy for variance\n                    old_ss = sum(pack_weights[p]**2 for p in candidates)\n                    new_ss = sum(val**2 for val in new_loads.values())\n\n                    if new_local_max < old_local_max - 1e-6 or (abs(new_local_max - old_local_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                        # Apply Update\n                        for p in candidates:\n                            pack_contents[p] = new_contents[p]\n                            pack_weights[p] = new_loads[p]\n                            pack_sizes[p] = groups_per_pack # Should be full\n                        consecutive_no_improve = 0\n                    else:\n                        consecutive_no_improve += 1\n                else:\n                    consecutive_no_improve += 1\n\n                if consecutive_no_improve >= 5:\n                    break\n\n            # 4. Check global best\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in pack_contents]\n\n        # 5. Write best assignment to output tensors\n        # Flatten for scatter\n        flat_indices = []\n        flat_packs = []\n        flat_ranks = []\n\n        for p, items in enumerate(best_assignment):\n            for r, idx in enumerate(items):\n                flat_indices.append(idx)\n                flat_packs.append(p)\n                flat_ranks.append(r)\n\n        idx_tensor = torch.tensor(flat_indices, dtype=torch.int64, device=device)\n        pack_tensor = torch.tensor(flat_packs, dtype=torch.int64, device=device)\n        rank_tensor = torch.tensor(flat_ranks, dtype=torch.int64, device=device)\n\n        pack_index[i].scatter_(0, idx_tensor, pack_tensor)\n        rank_in_pack[i].scatter_(0, idx_tensor, rank_tensor)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        # Extract weights for this layer as a list for fast Python iteration\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # Candidate generation:\n        # We try:\n        # 1. Deterministic LPT (sort descending)\n        # 2. Randomized LPT (multiple attempts)\n\n        candidates = []\n\n        # 1. Deterministic\n        indices_det = layer_weights_t.sort(descending=True).indices.tolist()\n        candidates.append(indices_det)\n\n        # 2. Perturbed (only if we have enough groups for it to matter)\n        if groups_per_pack > 1:\n            for attempt in range(4):\n                # Add small random noise to explore different greedy decisions\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # +/- 5%\n                indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n                candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            # Re-init packs using lists for speed\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n\n                # Find best pack: valid (not full) and min weight\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        pw = current_pack_weights[p]\n                        if pw < min_w:\n                            min_w = pw\n                            best_p = p\n\n                # Assign\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            # Metric: minimize max load\n            max_load = max(current_pack_weights)\n            if max_load < min_max_load:\n                min_max_load = max_load\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # Global Refinement Loop\n        # Alternates between Vectorized Pairwise Swaps and Large Neighborhood Search (LNS)\n\n        NUM_GLOBAL_ITER = 3\n\n        for global_iter in range(NUM_GLOBAL_ITER):\n\n            # Phase 1: Vectorized Local Search (Pairwise Swaps)\n            # Efficiently checks swaps between max pack and others\n\n            improved_swap = False\n            for _ in range(20): # Limit iterations per phase\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1) # [1, G, 1]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack) # [M, 1, G]\n\n                # Compute deltas: w_u - w_v\n                deltas = w_u - w_v # [M, G, G]\n\n                # Diff with max pack\n                diffs = (max_w - pack_weights).view(num_packs, 1, 1) # [M, 1, 1]\n\n                # Gain metric: delta * (diff - delta)\n                # We want 0 < delta < diff\n\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_flat = torch.argmax(gains).item()\n                max_gain = gains.view(-1)[best_flat].item()\n\n                if max_gain < 0:\n                    break\n\n                # Perform Swap\n                best_p = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                best_u_idx = rem // groups_per_pack\n                best_v_idx = rem % groups_per_pack\n\n                u_val = pack_assignment[max_pack, best_u_idx].item()\n                v_val = pack_assignment[best_p, best_v_idx].item()\n\n                pack_assignment[max_pack, best_u_idx] = v_val\n                pack_assignment[best_p, best_v_idx] = u_val\n\n                d_val = deltas[best_p, best_u_idx, best_v_idx].item()\n                pack_weights[max_pack] -= d_val\n                pack_weights[best_p] += d_val\n                improved_swap = True\n\n            # Phase 2: Large Neighborhood Search (LNS)\n            # Ruin and Recreate 3 packs (Max, Min, Random)\n            # This helps to perform 3-way exchanges or more complex reshuffling\n\n            improved_lns = False\n            if num_packs >= 3:\n                # Number of LNS attempts\n                for _ in range(15):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n\n                    if max_p == min_p:\n                        break\n\n                    # Pick 3rd pack random\n                    rand_p = torch.randint(0, num_packs, (1,)).item()\n                    while rand_p == max_p or rand_p == min_p:\n                        rand_p = torch.randint(0, num_packs, (1,)).item()\n\n                    indices_list = [max_p, min_p, rand_p]\n\n                    # Collect items\n                    items = []\n                    for p in indices_list:\n                         items.extend(pack_assignment[p].tolist())\n\n                    # Sort items LPT\n                    items.sort(key=lambda x: layer_weights[x], reverse=True)\n\n                    # Repack Greedy into these 3\n                    temp_packs = {p: [] for p in indices_list}\n                    temp_weights = {p: 0.0 for p in indices_list}\n                    temp_counts = {p: 0 for p in indices_list}\n\n                    possible = True\n                    for item_idx in items:\n                        w = layer_weights[item_idx]\n                        best_local_p = -1\n                        min_local_w = float('inf')\n                        found = False\n\n                        # Greedy Best Fit on subset\n                        for p in indices_list:\n                             if temp_counts[p] < groups_per_pack:\n                                 if temp_weights[p] < min_local_w:\n                                     min_local_w = temp_weights[p]\n                                     best_local_p = p\n                                     found = True\n\n                        if not found:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        old_max = max(pack_weights[p].item() for p in indices_list)\n                        new_max = max(temp_weights.values())\n\n                        old_ss = sum(pack_weights[p].item()**2 for p in indices_list)\n                        new_ss = sum(w**2 for w in temp_weights.values())\n\n                        # Accept if improves max load or variance\n                        if new_max < old_max - 1e-6 or (abs(new_max - old_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                            for p in indices_list:\n                                pack_assignment[p] = torch.tensor(temp_packs[p], dtype=torch.int64)\n                                pack_weights[p] = temp_weights[p]\n                            improved_lns = True\n\n            if not improved_swap and not improved_lns:\n                break\n\n        # Final write to output tensors\n        # pack_assignment contains expert indices in packed order\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n\n        best_max_load = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                # Deterministic LPT\n                indices = layer_w.argsort(descending=True).tolist()\n            else:\n                # Randomized LPT (Perturbed weights)\n                noise = torch.rand(num_groups) * 0.4 + 0.8  # 0.8 to 1.2\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_cnt = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w[g_idx].item()\n                # Best fit among non-full packs (min current load)\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_cnt[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_cnt[best_p] += 1\n\n            # 3. Refinement Phase 1: Vectorized 2-Opt (Swap)\n            for _ in range(10):\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                improved = False\n                for p_idx in range(min(3, num_packs)):\n                    max_p = sorted_packs[p_idx]\n                    max_w = pack_weights[max_p]\n                    best_swap = None\n                    best_gain = 0.0\n\n                    u_nodes = packs[max_p]\n                    w_u = layer_w[u_nodes]\n\n                    for p in range(num_packs):\n                        if p == max_p: continue\n                        if pack_weights[p] >= max_w: continue\n\n                        diff = max_w - pack_weights[p]\n                        if diff < 1e-6: continue\n\n                        v_nodes = packs[p]\n                        w_v = layer_w[v_nodes]\n\n                        deltas = w_u.unsqueeze(1) - w_v.unsqueeze(0)\n                        mask = (deltas > 1e-6) & (deltas < diff)\n                        if not mask.any(): continue\n\n                        gains = deltas * (diff - deltas)\n                        gains = torch.where(mask, gains, -1.0)\n                        curr_max_gain, curr_idx = gains.flatten().max(0)\n\n                        if curr_max_gain.item() > best_gain:\n                            best_gain = curr_max_gain.item()\n                            idx = curr_idx.item()\n                            u_idx = idx // len(v_nodes)\n                            v_idx = idx % len(v_nodes)\n                            best_swap = (max_p, p, u_idx, v_idx, deltas.flatten()[idx].item())\n\n                    if best_swap:\n                        p1, p2, u_i, v_i, delta = best_swap\n                        packs[p1][u_i], packs[p2][v_i] = packs[p2][v_i], packs[p1][u_i]\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        improved = True\n                        break\n                if not improved: break\n\n            # 4. Refinement Phase 2: Pairwise Rebalancing (Ruin & Recreate)\n            # Focus on reducing the gap between heaviest and lightest packs\n            for _ in range(15):\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n                if max_p == min_p: break\n\n                diff = pack_weights[max_p] - pack_weights[min_p]\n                if diff < 1e-6: break\n\n                items_pair = packs[max_p] + packs[min_p]\n                # Optimization: Extract weights once\n                w_pair = [(layer_w[idx].item(), idx) for idx in items_pair]\n                w_pair.sort(key=lambda x: x[0], reverse=True)\n\n                best_pair_res = None\n                best_pair_diff = diff\n\n                # Try Deterministic and Randomized Greedy on this pair\n                # 1 Deterministic + 5 Randomized\n                for attempt_pair in range(6):\n                    if attempt_pair > 0:\n                        # Perturb weights for randomization\n                        current_w_pair = [(w * (1.0 + torch.rand(1).item() * 0.1), w, idx) for w, idx in w_pair]\n                        current_w_pair.sort(key=lambda x: x[0], reverse=True)\n                        iter_items = [(w_real, idx) for _, w_real, idx in current_w_pair]\n                    else:\n                        iter_items = w_pair\n\n                    p1_new, p2_new = [], []\n                    w1_new, w2_new = 0.0, 0.0\n\n                    for w_val, idx in iter_items:\n                        if len(p1_new) < groups_per_pack and len(p2_new) < groups_per_pack:\n                            if w1_new < w2_new:\n                                p1_new.append(idx); w1_new += w_val\n                            else:\n                                p2_new.append(idx); w2_new += w_val\n                        elif len(p1_new) < groups_per_pack:\n                            p1_new.append(idx); w1_new += w_val\n                        else:\n                            p2_new.append(idx); w2_new += w_val\n\n                    curr_diff = abs(w1_new - w2_new)\n                    if curr_diff < best_pair_diff - 1e-6:\n                        best_pair_diff = curr_diff\n                        best_pair_res = (p1_new, p2_new, w1_new, w2_new)\n\n                if best_pair_res:\n                    p1_idx, p2_idx, w1_v, w2_v = best_pair_res\n                    packs[max_p] = p1_idx\n                    pack_weights[max_p] = w1_v\n                    packs[min_p] = p2_idx\n                    pack_weights[min_p] = w2_v\n                else:\n                    break\n\n            # 5. Evaluation\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # --- 1. Initialization (Randomized Greedy) ---\n        candidates = []\n        # Deterministic LPT\n        candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n\n        # Randomized LPT (Perturbed weights)\n        # Generate multiple candidates to improve diversity\n        for _ in range(4):\n            noise = torch.rand(num_groups) * 0.1 + 0.95  # +/- 5% noise\n            indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n            candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n                # Best fit among non-full packs\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        if current_pack_weights[p] < min_w:\n                            min_w = current_pack_weights[p]\n                            best_p = p\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            max_load = max(current_pack_weights)\n            ss = sum(x*x for x in current_pack_weights)\n\n            if max_load < min_max_load - 1e-6:\n                min_max_load = max_load\n                min_ss = ss\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n            elif abs(max_load - min_max_load) < 1e-6:\n                if ss < min_ss - 1e-6:\n                    min_ss = ss\n                    best_assignment = current_pack_contents\n                    best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # --- 2. Refinement Loop ---\n        MAX_OUTER_LOOPS = 5\n        \n        for _ in range(MAX_OUTER_LOOPS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            for _ in range(10):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment]\n\n                # Deltas: w_u - w_v. Shape [M, G, G] (via broadcasting)\n                # Gain function aims to balance the pair (max_pack, p)\n                diffs = (max_w - pack_weights).view(-1, 1, 1) # [M, 1, 1]\n                deltas = w_u.view(1, groups_per_pack, 1) - w_v.view(num_packs, 1, groups_per_pack) # [M, G, G]\n\n                # Mask: valid positive delta strictly less than diff (to avoid overshooting too much)\n                # Actually, strictly less than diff ensures w_p < old_max after swap.\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Repack max, min, and a random pack using multiple randomized attempts\n            for _ in range(5):\n                max_p = torch.argmax(pack_weights).item()\n                min_p = torch.argmin(pack_weights).item()\n\n                if max_p == min_p:\n                    break\n\n                lns_packs = [max_p, min_p]\n                if num_packs > 2:\n                    p3 = random.randint(0, num_packs - 1)\n                    while p3 in lns_packs:\n                        p3 = random.randint(0, num_packs - 1)\n                    lns_packs.append(p3)\n\n                # Collect items\n                items_flat = []\n                for p in lns_packs:\n                    items_flat.extend(pack_assignment[p].tolist())\n                \n                # Base sort LPT\n                sub_weights = [(layer_weights[x], x) for x in items_flat]\n                sub_weights.sort(key=lambda x: x[0], reverse=True)\n\n                current_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                current_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                best_sub_assign = None\n                best_sub_weights = None\n                found_lns_improvement = False\n\n                # 4 attempts: 1 deterministic, 3 randomized\n                for attempt in range(4):\n                    if attempt == 0:\n                        order = sub_weights\n                    else:\n                        # Perturb weights for sorting\n                        order = sorted([(w * random.uniform(0.9, 1.1), w, idx) for w, idx in sub_weights], key=lambda x: x[0], reverse=True)\n                        order = [(w, idx) for _, w, idx in order]\n\n                    temp_bins = [[] for _ in lns_packs]\n                    temp_ws = [0.0] * len(lns_packs)\n                    temp_cts = [0] * len(lns_packs)\n                    \n                    possible = True\n                    for w_val, idx in order:\n                        # Greedy Best Fit\n                        best_b = -1\n                        min_local_w = float('inf')\n                        for b in range(len(lns_packs)):\n                            if temp_cts[b] < groups_per_pack:\n                                if temp_ws[b] < min_local_w:\n                                    min_local_w = temp_ws[b]\n                                    best_b = b\n                        if best_b == -1:\n                            possible = False\n                            break\n                        temp_bins[best_b].append(idx)\n                        temp_ws[best_b] += w_val\n                        temp_cts[best_b] += 1\n                    \n                    if possible:\n                        new_max = max(temp_ws)\n                        new_ss = sum(x*x for x in temp_ws)\n\n                        if new_max < current_sub_max - 1e-6:\n                            current_sub_max = new_max\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n                        elif abs(new_max - current_sub_max) < 1e-6 and new_ss < current_sub_ss - 1e-6:\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n\n                if found_lns_improvement:\n                    for i_idx, p_idx in enumerate(lns_packs):\n                        pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                        pack_weights[p_idx] = best_sub_weights[i_idx]\n                    improved_any = True\n\n            if not improved_any:\n                break\n\n        # Final write to output tensors\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_sum_sq = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups) * 0.15 + 0.925\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT/Best Fit)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_counts = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                # Best Fit: Assign to valid pack with min load\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_counts[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_counts[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Identify heavy and light packs\n                # Optimization: Track max/min indices dynamically or just scan\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n                if max_p == min_p:\n                    break\n\n                # If balanced enough, try to optimize variance by picking random packs\n                # Otherwise, target max load reduction\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                     # Already balanced max-min, but maybe high variance?\n                     pass\n\n                candidates = {max_p, min_p}\n                # Add random packs for k-way swaps\n                if num_packs > 2:\n                    k_random = min(2, num_packs - 2)\n                    for _ in range(k_random):\n                        candidates.add(torch.randint(0, num_packs, (1,)).item())\n\n                cand_list = list(candidates)\n\n                # Ruin\n                items = []\n                for p in cand_list:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                best_sub_weights = [pack_weights[p] for p in cand_list]\n                best_sub_packs = [list(packs[p]) for p in cand_list]\n                best_sub_max = max(best_sub_weights)\n                best_sub_ss = sum(w*w for w in best_sub_weights)\n\n                improved_sub = False\n\n                # 0. Deterministic LPT attempt\n                # 1..N. Randomized LPT attempts\n\n                # Prepare LPT sort once\n                items_sorted = sorted(items, key=lambda x: layer_w_list[x], reverse=True)\n\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        # We use a list of tuples (perturbed_weight, index)\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n\n                if improved_sub:\n                    for idx, p in enumerate(cand_list):\n                        packs[p] = best_sub_packs[idx]\n                        pack_weights[p] = best_sub_weights[idx]\n                        pack_counts[p] = groups_per_pack # Should remain full\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w*w for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6 and current_ss < best_sum_sq - 1e-6:\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights for fast scalar access\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 20\n\n    import random\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_ss = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                # Deterministic LPT\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                indices = sorted(range(num_groups),\n                                 key=lambda x: layer_w_list[x] * (0.8 + 0.4 * random.random()),\n                                 reverse=True)\n\n            # 2. Greedy Construction (Least Loaded)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_cnt = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if pack_cnt[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_cnt[best_p] += 1\n\n            # 3. Refinement: Ruin & Recreate (LNS)\n            LNS_STEPS = 50 if num_packs > 1 else 0\n\n            for step in range(LNS_STEPS):\n                # Identify max and min packs\n                max_p = -1\n                min_p = -1\n                max_w = -1.0\n                min_w = float('inf')\n\n                for p_idx, pw in enumerate(pack_weights):\n                    if pw > max_w:\n                        max_w = pw\n                        max_p = p_idx\n                    if pw < min_w:\n                        min_w = pw\n                        min_p = p_idx\n\n                if max_p == min_p or (max_w - min_w < 1e-6):\n                    break\n\n                # Candidates for Ruin: Max, Min, and potentially Randoms\n                candidates = [max_p, min_p]\n\n                # Add random packs for 3-way/4-way cyclic shifts\n                if num_packs > 2:\n                    num_extra = 1 if (num_packs == 3) else random.randint(1, 2)\n                    for _ in range(num_extra):\n                        rand_p = random.randint(0, num_packs - 1)\n                        if rand_p not in candidates:\n                            candidates.append(rand_p)\n\n                # Pool items\n                items = []\n                for p in candidates:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                current_sub_max = max(pack_weights[p] for p in candidates)\n                current_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n\n                best_sub_packs = None\n                best_sub_weights = None\n                found_better = False\n\n                # Sort LPT for sub-problem\n                item_data = [(layer_w_list[idx], idx) for idx in items]\n                item_data.sort(key=lambda x: x[0], reverse=True)\n\n                # Sub-problem restarts\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        sub_items = item_data\n                    else:\n                        # Perturbed LPT\n                        sub_items = sorted(item_data, key=lambda x: x[0] * (0.85 + 0.3 * random.random()), reverse=True)\n\n                    temp_packs = {p: [] for p in candidates}\n                    temp_weights = {p: 0.0 for p in candidates}\n                    temp_counts = {p: 0 for p in candidates}\n\n                    possible = True\n                    for w, idx in sub_items:\n                        # Greedy Best Fit on Subset\n                        best_local_p = -1\n                        min_local_w = float('inf')\n                        for p in candidates:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        new_max = max(temp_weights.values())\n                        new_ss = sum(v**2 for v in temp_weights.values())\n\n                        # Accept if better\n                        if new_max < current_sub_max - 1e-6:\n                            current_sub_max = new_max\n                            current_sub_ss = new_ss\n                            best_sub_packs = temp_packs\n                            best_sub_weights = temp_weights\n                            found_better = True\n                        elif abs(new_max - current_sub_max) < 1e-6:\n                            if new_ss < current_sub_ss - 1e-6:\n                                current_sub_ss = new_ss\n                                best_sub_packs = temp_packs\n                                best_sub_weights = temp_weights\n                                found_better = True\n\n                if found_better:\n                    for p in candidates:\n                        packs[p] = best_sub_packs[p]\n                        pack_weights[p] = best_sub_weights[p]\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w**2 for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_ss = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6:\n                if current_ss < best_ss - 1e-6:\n                    best_ss = current_ss\n                    best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a modification to it below):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output tensors\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # --- 1. Initialization (Randomized Greedy) ---\n        candidates = []\n        # Deterministic LPT\n        candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n\n        # Randomized LPT (Perturbed weights)\n        # 20 Restarts to find a good basin of attraction\n        for _ in range(20):\n            noise = torch.rand(num_groups) * 0.2 + 0.9  # 0.9 to 1.1 range roughly\n            indices_rand = (layer_weights_t * noise).argsort(descending=True).tolist()\n            candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            for idx in indices:\n                w = layer_weights[idx]\n                best_p = -1\n                min_w = float('inf')\n                \n                # Simple linear scan is effective for small num_packs\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        if current_pack_weights[p] < min_w:\n                            min_w = current_pack_weights[p]\n                            best_p = p\n                            \n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            max_load = max(current_pack_weights)\n            ss = sum(x*x for x in current_pack_weights)\n\n            if max_load < min_max_load - 1e-6:\n                min_max_load = max_load\n                min_ss = ss\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n            elif abs(max_load - min_max_load) < 1e-6:\n                if ss < min_ss - 1e-6:\n                    min_ss = ss\n                    best_assignment = current_pack_contents\n                    best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 5\n        \n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            # This replaces the slow O(G^2 * M) python loop with optimized PyTorch ops on CPU\n            for _ in range(15):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                # Deltas: w_u - w_v. Shape [M, G, G]\n                deltas = w_u - w_v\n                \n                # We want to swap u (from max_pack) with v (from other pack) such that:\n                # 1. max_load decreases: max_w - delta < max_w  => delta > 0\n                # 2. other pack doesn't exceed old max_load: w_v_pack + delta < max_w\n                #    => delta < max_w - w_v_pack\n                \n                diffs = (max_w - pack_weights).view(num_packs, 1, 1)\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                # Gain metric: prefer swaps that balance the two packs (delta close to diff/2)\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Apply Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Pick max, min, and a random pack to reshuffle together\n            if num_packs >= 2:\n                for _ in range(5):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n                    \n                    if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                        break # Perfectly balanced\n\n                    lns_packs = [max_p, min_p]\n                    if num_packs > 2:\n                        p3 = random.randint(0, num_packs - 1)\n                        while p3 in lns_packs:\n                            p3 = random.randint(0, num_packs - 1)\n                        lns_packs.append(p3)\n\n                    # Collect items\n                    items_flat = []\n                    for p in lns_packs:\n                        items_flat.extend(pack_assignment[p].tolist())\n                    \n                    # Solve sub-problem\n                    curr_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                    best_sub_assign = None\n                    best_sub_weights = None\n                    found_lns_improvement = False\n\n                    # Strategies: Deterministic LPT + Random Noise\n                    strategies = []\n                    strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n                    for _ in range(3):\n                         # Perturb weights\n                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.9, 1.1), reverse=True))\n                    \n                    for item_order in strategies:\n                        temp_bins = [[] for _ in lns_packs]\n                        temp_ws = [0.0] * len(lns_packs)\n                        temp_cts = [0] * len(lns_packs)\n                        \n                        possible = True\n                        for idx in item_order:\n                            w_val = layer_weights[idx]\n                            best_b = -1\n                            min_local_w = float('inf')\n                            for b in range(len(lns_packs)):\n                                if temp_cts[b] < groups_per_pack:\n                                    if temp_ws[b] < min_local_w:\n                                        min_local_w = temp_ws[b]\n                                        best_b = b\n                            if best_b == -1:\n                                possible = False\n                                break\n                            temp_bins[best_b].append(idx)\n                            temp_ws[best_b] += w_val\n                            temp_cts[best_b] += 1\n                        \n                        if possible:\n                            new_max = max(temp_ws)\n                            new_ss = sum(x*x for x in temp_ws)\n\n                            if new_max < curr_sub_max - 1e-6:\n                                curr_sub_max = new_max\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n                            elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n\n                    if found_lns_improvement:\n                        for i_idx, p_idx in enumerate(lns_packs):\n                            pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                            pack_weights[p_idx] = best_sub_weights[i_idx]\n                        improved_any = True\n\n            if not improved_any:\n                break\n\n        # Final write to output tensors\n        # Move pack_assignment to device for scatter\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Instructions\n\nMake sure that the changes you propose are consistent with each other. For example, if you refer to a new config variable somewhere, you should also propose a change to add that variable.\n\nNote that the changes you propose will be applied sequentially, so you should assume that the previous changes have already been applied when writing the SEARCH block.\n\n# Task\n\nSuggest a new idea to improve the performance of the code that is inspired by your expert knowledge of the considered subject.\nYour goal is to maximize the `combined_score` of the program.\nDescribe each change with a SEARCH/REPLACE block.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\nvectorized_topk_swap_lns\n</NAME>\n\n<DESCRIPTION>\n1. Improved the vectorized swap heuristic: Instead of only attempting to balance the single heaviest pack against others, the new \"Top-K vs All\" strategy selects the K heaviest packs (e.g., K=4) and searches for optimal 1-swaps against all other packs. This uses tensor broadcasting to efficiently evaluate thousands of potential swaps in parallel, maximizing the reduction in the Sum of Squared Loads (variance). This broader search helps the system escape local optima where the max pack is stuck but variance can still be reduced.\n2. Enhanced the LNS (Ruin & Recreate) phase: Increased the number of packs involved in the local search from 2-3 to up to 4, allowing for more complex cyclic exchanges (3-way/4-way). Increased the number of randomized restarts within the LNS subroutine to better explore the sub-problem space.\n3. Increased global refinement iterations to utilize the available speed budget for better quality.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 5\n        \n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            # This replaces the slow O(G^2 * M) python loop with optimized PyTorch ops on CPU\n            for _ in range(15):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                # Deltas: w_u - w_v. Shape [M, G, G]\n                deltas = w_u - w_v\n                \n                # We want to swap u (from max_pack) with v (from other pack) such that:\n                # 1. max_load decreases: max_w - delta < max_w  => delta > 0\n                # 2. other pack doesn't exceed old max_load: w_v_pack + delta < max_w\n                #    => delta < max_w - w_v_pack\n                \n                diffs = (max_w - pack_weights).view("
            },
            {
              "role": "user",
              "content": "The previous edit was not successful. This was the error message: \n\nNo changes applied.\n\n Try again."
            },
            {
              "role": "assistant",
              "content": "<NAME>\nvectorized_topk_swap_lns_v2\n</NAME>\n\n<DESCRIPTION>\n1. Improved the vectorized swap heuristic: Instead of only attempting to balance the single heaviest pack against others, the new \"Top-K vs All\" strategy selects the K heaviest packs (e.g., K=4) and searches for optimal 1-swaps against all other packs. This uses tensor broadcasting to efficiently evaluate thousands of potential swaps in parallel, maximizing the reduction in the Sum of Squared Loads (variance). This broader search helps the system escape local optima where the max pack is stuck but variance can still be reduced.\n2. Enhanced the LNS (Ruin & Recreate) phase: Increased the number of packs involved in the local search from 2-3 to up to 4, allowing for more complex cyclic exchanges (3-way/4-way). Increased the number of randomized restarts within the LNS subroutine to better explore the sub-problem space.\n3. Increased global refinement iterations to utilize the available speed budget for better quality.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 5\n        \n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            # This replaces the slow O(G^2 * M) python loop with optimized PyTorch ops on CPU\n            for _ in range(15):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                # Deltas: w_u - w_v. Shape [M, G, G]\n                deltas = w_u - w_v\n                \n                # We want to swap u (from max_pack) with v (from other pack) such that:\n                # 1. max_load decreases: max_w - delta < max_w  => delta > 0\n                # 2. other pack doesn't exceed old max_load: w_v_pack + delta < max_w\n                #    => delta < max_w - w_v_pack\n                \n                diffs = (max_w - pack_weights).view(num_packs, 1, 1)\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                # Gain metric: prefer swaps that balance the two packs (delta close to diff/2)\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Apply Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Pick max, min, and a random pack to reshuffle together\n            if num_packs >= 2:\n                for _ in range(5):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n                    \n                    if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                        break # Perfectly balanced\n\n                    lns_packs = [max_p, min_p]\n                    if num_packs > 2:\n                        p3 = random.randint(0, num_packs - 1)\n                        while p3 in lns_packs:\n                            p3 = random.randint(0, num_packs - 1)\n                        lns_packs.append(p3)\n\n                    # Collect items\n                    items_flat = []\n                    for p in lns_packs:\n                        items_flat.extend(pack_assignment[p].tolist())\n                    \n                    # Solve sub-problem\n                    curr_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                    best_sub_assign = None\n                    best_sub_weights = None\n                    found_lns_improvement = False\n\n                    # Strategies: Deterministic LPT + Random Noise\n                    strategies = []\n                    strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n                    for _ in range(3):\n                         # Perturb weights\n                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.9, 1.1), reverse=True))\n                    \n                    for item_order in strategies:\n                        temp_bins = [[] for _ in lns_packs]\n                        temp_ws = [0.0] * len(lns_packs)\n                        temp_cts = [0] * len(lns_packs)\n                        \n                        possible = True\n                        for idx in item_order:\n                            w_val = layer_weights[idx]\n                            best_b = -1\n                            min_local_w = float('inf')\n                            for b in range(len(lns_packs)):\n                                if temp_cts[b] < groups_per_pack:\n                                    if temp_ws[b] < min_local_w:\n                                        min_local_w = temp_ws[b]\n                                        best_b = b\n                            if best_b == -1:\n                                possible = False\n                                break\n                            temp_bins[best_b].append(idx)\n                            temp_ws[best_b] += w_val\n                            temp_cts[best_b] += 1\n                        \n                        if possible:\n                            new_max = max(temp_ws)\n                            new_ss = sum(x*x for x in temp_ws)\n\n                            if new_max < curr_sub_max - 1e-6:\n                                curr_sub_max = new_max\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n                            elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n\n                    if found_lns_improvement:\n                        for i_idx, p_idx in enumerate(lns_packs):\n                            pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                            pack_weights[p_idx] = best_sub_weights[i_idx]\n                        improved_any = True\n\n            if not improved_any:\n                break\n=======\n        # --- 2. Refinement Loop ---\n        # Alternating between Vectorized 1-Swap and K-Way LNS\n        MAX_GLOBAL_ITERS = 8\n        \n        for _ in range(MAX_GLOBAL_ITERS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Check swaps for top-K heaviest packs to reduce max load or variance.\n            # Sorting helps to focus on the most critical packs first.\n            sorted_indices = torch.argsort(pack_weights, descending=True)\n            top_k = min(num_packs, 4)\n            \n            for k in range(top_k):\n                source_pack = sorted_indices[k].item()\n                \n                # Multiple passes for each heavy pack to clear easy swaps\n                for _ in range(5):\n                    w_source = pack_weights[source_pack].item()\n                    \n                    # Items in source pack: [G]\n                    u_indices = pack_assignment[source_pack]\n                    w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1)\n\n                    # Items in all packs: [M, G]\n                    w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack)\n\n                    # Deltas: w_u - w_v. Shape [M, G, G]\n                    # delta > 0 implies item u is heavier than item v\n                    deltas = w_u - w_v\n                    \n                    # We want to swap u (heavy) with v (light) such that:\n                    # w_source decreases and w_target doesn't exceed original w_source\n                    # To minimize variance: d < w_s - w_t\n                    \n                    diffs = (w_source - pack_weights).view(num_packs, 1, 1)\n                    mask = (deltas > 1e-5) & (deltas < diffs)\n\n                    if not mask.any():\n                        break\n\n                    # Gain metric: maximize delta * (diff - delta)\n                    # This prefers large delta that fits in the gap\n                    gains = deltas * (diffs - deltas)\n                    gains = torch.where(mask, gains, -1.0)\n\n                    best_val, best_flat_idx = gains.view(-1).max(0)\n\n                    if best_val < 0:\n                        break\n                    \n                    best_flat = best_flat_idx.item()\n                    p_target = best_flat // (groups_per_pack * groups_per_pack)\n                    \n                    # Safety check: if target became heavier than source due to other swaps\n                    if pack_weights[p_target] >= w_source:\n                        break\n\n                    rem = best_flat % (groups_per_pack * groups_per_pack)\n                    u_pos = rem // groups_per_pack\n                    v_pos = rem % groups_per_pack\n\n                    # Apply Swap\n                    item_u = pack_assignment[source_pack, u_pos].item()\n                    item_v = pack_assignment[p_target, v_pos].item()\n                    delta_val = deltas.view(-1)[best_flat].item()\n\n                    pack_assignment[source_pack, u_pos] = item_v\n                    pack_assignment[p_target, v_pos] = item_u\n                    pack_weights[source_pack] -= delta_val\n                    pack_weights[p_target] += delta_val\n                    improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            if num_packs >= 2:\n                # Increased LNS iterations\n                for _ in range(10):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n                    \n                    if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                        break \n\n                    # Select packs: Max, Min, and up to 2 random others\n                    lns_packs = {max_p, min_p}\n                    while len(lns_packs) < min(num_packs, 4):\n                         lns_packs.add(random.randint(0, num_packs - 1))\n                    \n                    lns_indices = list(lns_packs)\n                    \n                    # Collect items\n                    items_flat = []\n                    for p in lns_indices:\n                        items_flat.extend(pack_assignment[p].tolist())\n                    \n                    # Solve sub-problem\n                    curr_sub_max = max(pack_weights[p].item() for p in lns_indices)\n                    curr_sub_ss = sum(pack_weights[p].item()**2 for p in lns_indices)\n\n                    best_sub_assign = None\n                    best_sub_weights = None\n                    found_lns_improvement = False\n\n                    # Strategies: Deterministic LPT + Random Noise\n                    strategies = []\n                    strategies.append(sorted(items_flat, key=lambda x: layer_weights[x], reverse=True))\n                    # More random perturbations\n                    for _ in range(5):\n                         strategies.append(sorted(items_flat, key=lambda x: layer_weights[x] * random.uniform(0.85, 1.15), reverse=True))\n                    \n                    for item_order in strategies:\n                        temp_bins = [[] for _ in lns_indices]\n                        temp_ws = [0.0] * len(lns_indices)\n                        temp_cts = [0] * len(lns_indices)\n                        \n                        possible = True\n                        for idx in item_order:\n                            w_val = layer_weights[idx]\n                            # Greedy Best Fit on Subset\n                            best_b = -1\n                            min_local_w = float('inf')\n                            for b in range(len(lns_indices)):\n                                if temp_cts[b] < groups_per_pack:\n                                    if temp_ws[b] < min_local_w:\n                                        min_local_w = temp_ws[b]\n                                        best_b = b\n                            if best_b == -1:\n                                possible = False\n                                break\n                            temp_bins[best_b].append(idx)\n                            temp_ws[best_b] += w_val\n                            temp_cts[best_b] += 1\n                        \n                        if possible:\n                            new_max = max(temp_ws)\n                            new_ss = sum(x*x for x in temp_ws)\n\n                            if new_max < curr_sub_max - 1e-6:\n                                curr_sub_max = new_max\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n                            elif abs(new_max - curr_sub_max) < 1e-6 and new_ss < curr_sub_ss - 1e-6:\n                                curr_sub_ss = new_ss\n                                best_sub_assign = temp_bins\n                                best_sub_weights = temp_ws\n                                found_lns_improvement = True\n\n                    if found_lns_improvement:\n                        for i_idx, p_idx in enumerate(lns_indices):\n                            pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                            pack_weights[p_idx] = best_sub_weights[i_idx]\n                        improved_any = True\n\n            if not improved_any:\n                break\n>>>>>>> REPLACE\n</DIFF>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 35659,
          "output_tokens": 13312,
          "cost": 0.231062,
          "input_cost": 0.07131799999999999,
          "output_cost": 0.159744,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 13,
          "deleted": 0,
          "modified": 74
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 8.388e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_96/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_96/results\nRun 1/5 completed in 1.49 seconds\nRun 2/5 completed in 3.57 seconds\nRun 3/5 completed in 3.49 seconds\nRun 4/5 completed in 3.38 seconds\nRun 5/5 completed in 3.31 seconds\nbalancedness: 0.21073683733844054\nbalancedness: 0.3397761404567239\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_96/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_96/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385873149429\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.3110771746298858, 'speed_score': 1.0}\n  execution_time_mean: 3.048489046600298\n  execution_time_std: 0.7856748163552617\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 55,
          "average_cyclomatic_complexity": 11.0,
          "halstead_volume": 2477.3154825253228,
          "halstead_difficulty": 12.83203125,
          "halstead_effort": 31788.98968787377,
          "lines_of_code": 466,
          "logical_lines_of_code": 235,
          "comments": 51,
          "maintainability_index": -43.8775373717221,
          "max_nesting_depth": 10,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "f83cfcb4-9a09-467f-bfe7-b8b938dc35a3",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    num_restarts = 3\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices sorted descending\n        base_indices = sorted(range(num_groups), key=lambda x: row_weight_list[x], reverse=True)\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = sorted(range(num_groups), key=lambda x: row_weight_list[x] * noise[x].item(), reverse=True)\n\n            # Greedy Assignment\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement\n            # Iteratively try to improve the Heaviest Pack\n            for step in range(max_refine_steps):\n                # Identify Max Pack\n                max_p = 0\n                max_val = pack_weights[0]\n                min_p = 0\n                min_val = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val > max_val:\n                        max_val = val\n                        max_p = p\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                \n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n                \n                # Check against packs sorted by weight (ascending)\n                # We try to rebalance Max Pack with Lighter packs\n                sorted_others = sorted([p for p in range(num_packs) if p != max_p], \n                                       key=pack_weights.__getitem__)\n                \n                improved = False\n                \n                for other_p in sorted_others:\n                    # Current load difference\n                    current_pair_diff = abs(pack_weights[max_p] - pack_weights[other_p])\n                    if current_pair_diff < 1e-6:\n                        continue # Cannot improve equal packs\n\n                    # Pool items\n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    total_pool = sum(pool_weights)\n                    target = total_pool / 2.0\n                    \n                    K = groups_per_pack\n                    pool_len = 2 * K\n                    \n                    best_assignment_A = None\n                    best_dev = abs(pack_weights[max_p] - target)\n                    \n                    # 2-Partition Solver\n                    if pool_len <= 14:\n                        # Exact Solver\n                        # Fix item 0 to Set A\n                        w_0 = pool_weights[0]\n                        indices_rest = list(range(1, pool_len))\n                        \n                        for comb in itertools.combinations(indices_rest, K - 1):\n                            s = w_0 + sum(pool_weights[x] for x in comb)\n                            dev = abs(s - target)\n                            if dev < best_dev - 1e-6:\n                                best_dev = dev\n                                best_assignment_A = [0] + list(comb)\n                                if dev < 1e-6: break\n                    else:\n                        # Heuristic Solver\n                        # 1. Greedy (Balanced LPT)\n                        sorted_pool_idx = sorted(range(pool_len), key=lambda x: pool_weights[x], reverse=True)\n                        set_A = []\n                        set_B = []\n                        w_A, w_B = 0.0, 0.0\n                        \n                        for idx in sorted_pool_idx:\n                            w = pool_weights[idx]\n                            if len(set_A) < K and len(set_B) < K:\n                                if w_A <= w_B:\n                                    set_A.append(idx)\n                                    w_A += w\n                                else:\n                                    set_B.append(idx)\n                                    w_B += w\n                            elif len(set_A) < K:\n                                set_A.append(idx)\n                                w_A += w\n                            else:\n                                set_B.append(idx)\n                                w_B += w\n                                \n                        curr_local_dev = abs(w_A - target)\n                        if curr_local_dev < best_dev - 1e-6:\n                            best_dev = curr_local_dev\n                            best_assignment_A = list(set_A)\n                        \n                        # 2. Local Search (Swap)\n                        current_A = set_A if best_assignment_A is None else best_assignment_A\n                        # Recover B\n                        current_A_set = set(current_A)\n                        current_B = [x for x in range(pool_len) if x not in current_A_set]\n                        \n                        w_A = sum(pool_weights[x] for x in current_A)\n                        w_B = sum(pool_weights[x] for x in current_B)\n                        diff_local = w_A - w_B\n                        \n                        for _ in range(20): # Swap iterations\n                            if abs(diff_local) < 1e-6: break\n                            \n                            best_swap = None\n                            best_gain = 0.0\n                            \n                            for i_a, idx_a in enumerate(current_A):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(current_B):\n                                    wb = pool_weights[idx_b]\n                                    \n                                    change = 2 * (wa - wb)\n                                    new_diff = diff_local - change\n                                    gain = abs(diff_local) - abs(new_diff)\n                                    \n                                    if gain > 1e-6 and gain > best_gain:\n                                        best_gain = gain\n                                        best_swap = (i_a, i_b, change, new_diff)\n                            \n                            if best_swap:\n                                i_a, i_b, change, new_diff = best_swap\n                                val_a = current_A[i_a]\n                                val_b = current_B[i_b]\n                                current_A[i_a] = val_b\n                                current_B[i_b] = val_a\n                                diff_local = new_diff\n                                \n                                if abs(diff_local / 2.0) < best_dev - 1e-6:\n                                    best_dev = abs(diff_local / 2.0)\n                                    best_assignment_A = list(current_A)\n                            else:\n                                break\n\n                    # Update if improved\n                    if best_assignment_A is not None:\n                        # Retrieve global indices\n                        new_max = [pool[x] for x in best_assignment_A]\n                        set_A_indices = set(best_assignment_A)\n                        new_other = [pool[x] for x in range(pool_len) if x not in set_A_indices]\n                        \n                        current_packs[max_p] = new_max\n                        current_packs[other_p] = new_other\n                        pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                        pack_weights[other_p] = sum(row_weight_list[x] for x in new_other)\n                        improved = True\n                        break # Break sorted_others loop to re-evaluate max pack\n                \n                if not improved:\n                    break # Optimal given the 2-swap constraints from max_p\n            \n            # Update Global Best\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Output Results\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() \n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "b96cb298-f1bc-4791-bc63-23f021d2c874",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "ff8c92d6-b462-4c38-9b71-d2f558464751"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 97,
      "timestamp": 1764181733.1770098,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,460 +1,439 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n import random\n import itertools\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     # Handle trivial case\n     if groups_per_pack == 1:\n         pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n                                   device=weight.device).expand(num_layers, -1)\n         rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n-    # CPU processing for complex sequential logic\n+    # Move computation to CPU\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n \n-    # Heuristic parameters\n-    num_restarts = 2\n+    num_restarts = 3\n     max_refine_steps = 20\n \n     for i in range(num_layers):\n         row_weight = weight_cpu[i]\n         row_weight_list = row_weight.tolist()\n \n         best_diff = float('inf')\n         best_packs = None\n-\n-        # Base indices for deterministic LPT\n-        base_indices = torch.argsort(row_weight, descending=True).tolist()\n+        \n+        # Base indices sorted descending\n+        base_indices = sorted(range(num_groups), key=lambda x: row_weight_list[x], reverse=True)\n \n         for attempt in range(num_restarts):\n             # 1. Initialization\n+            current_packs = [[] for _ in range(num_packs)]\n+            pack_weights = [0.0] * num_packs\n+            \n             if attempt == 0:\n                 indices = base_indices\n             else:\n+                # Randomized LPT\n                 noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n-                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n-\n-            current_packs = [[] for _ in range(num_packs)]\n-            pack_weights = [0.0] * num_packs\n-\n-            # Greedy Packing\n+                indices = sorted(range(num_groups), key=lambda x: row_weight_list[x] * noise[x].item(), reverse=True)\n+\n+            # Greedy Assignment\n             for group_idx in indices:\n                 w = row_weight_list[group_idx]\n                 best_p = -1\n                 min_val = float('inf')\n                 for p in range(num_packs):\n                     if len(current_packs[p]) < groups_per_pack:\n                         if pack_weights[p] < min_val:\n                             min_val = pack_weights[p]\n                             best_p = p\n                 current_packs[best_p].append(group_idx)\n                 pack_weights[best_p] += w\n \n-            # 2. Refinement Phase\n+            # 2. Refinement\n+            # Iteratively try to improve the Heaviest Pack\n             for step in range(max_refine_steps):\n-                # Identify max and min packs\n+                # Identify Max Pack\n+                max_p = 0\n+                max_val = pack_weights[0]\n                 min_p = 0\n-                max_p = 0\n                 min_val = pack_weights[0]\n-                max_val = pack_weights[0]\n-\n-                # Random perturbation occasionally\n-                if step > 0 and step % 6 == 0:\n-                    p1 = random.randint(0, num_packs - 1)\n-                    p2 = random.randint(0, num_packs - 2)\n-                    if p2 >= p1: p2 += 1\n-                    max_p, min_p = p1, p2\n-                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n-                else:\n-                    for p in range(1, num_packs):\n-                        val = pack_weights[p]\n-                        if val < min_val:\n-                            min_val = val\n-                            min_p = p\n-                        elif val > max_val:\n-                            max_val = val\n-                            max_p = p\n-\n+                \n+                for p in range(1, num_packs):\n+                    val = pack_weights[p]\n+                    if val > max_val:\n+                        max_val = val\n+                        max_p = p\n+                    if val < min_val:\n+                        min_val = val\n+                        min_p = p\n+                \n                 diff = max_val - min_val\n                 if diff < 1e-6:\n-                    if step % 6 != 0: break\n-                    else: continue\n-\n-                # Try 2-Pack Rebalancing\n-                pool = current_packs[max_p] + current_packs[min_p]\n-                pool_weights = [row_weight_list[x] for x in pool]\n-                total_pool = sum(pool_weights)\n-                target_half = total_pool / 2.0\n-                K = groups_per_pack\n-                pool_len = 2 * K\n-\n+                    break\n+                \n+                # Check against packs sorted by weight (ascending)\n+                # We try to rebalance Max Pack with Lighter packs\n+                sorted_others = sorted([p for p in range(num_packs) if p != max_p], \n+                                       key=pack_weights.__getitem__)\n+                \n                 improved = False\n-                best_dev = abs(pack_weights[max_p] - target_half)\n-                best_assignment = None\n-\n-                # EXACT SOLVER for small K\n-                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n-                if pool_len <= 14:\n-                    # Fix first element to be in Set A to reduce symmetry\n-                    indices_rest = list(range(1, pool_len))\n-                    w_0 = pool_weights[0]\n-\n-                    for comb in itertools.combinations(indices_rest, K - 1):\n-                        s = w_0\n-                        for idx in comb:\n-                            s += pool_weights[idx]\n-                        dev = abs(s - target_half)\n-                        if dev < best_dev - 1e-6:\n-                            best_dev = dev\n-                            best_assignment = (0,) + comb\n-                            if dev < 1e-6: break\n-                else:\n-                    # Heuristic Solver with Local Search\n-                    pool_indices = list(range(pool_len))\n-                    sub_trials = 15\n-                    for sub in range(sub_trials):\n-                        # 1. Randomized Greedy Construction\n-                        if sub == 0:\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n-                        else:\n-                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n-\n+                \n+                for other_p in sorted_others:\n+                    # Current load difference\n+                    current_pair_diff = abs(pack_weights[max_p] - pack_weights[other_p])\n+                    if current_pair_diff < 1e-6:\n+                        continue # Cannot improve equal packs\n+\n+                    # Pool items\n+                    pool = current_packs[max_p] + current_packs[other_p]\n+                    pool_weights = [row_weight_list[x] for x in pool]\n+                    total_pool = sum(pool_weights)\n+                    target = total_pool / 2.0\n+                    \n+                    K = groups_per_pack\n+                    pool_len = 2 * K\n+                    \n+                    best_assignment_A = None\n+                    best_dev = abs(pack_weights[max_p] - target)\n+                    \n+                    # 2-Partition Solver\n+                    if pool_len <= 14:\n+                        # Exact Solver\n+                        # Fix item 0 to Set A\n+                        w_0 = pool_weights[0]\n+                        indices_rest = list(range(1, pool_len))\n+                        \n+                        for comb in itertools.combinations(indices_rest, K - 1):\n+                            s = w_0 + sum(pool_weights[x] for x in comb)\n+                            dev = abs(s - target)\n+                            if dev < best_dev - 1e-6:\n+                                best_dev = dev\n+                                best_assignment_A = [0] + list(comb)\n+                                if dev < 1e-6: break\n+                    else:\n+                        # Heuristic Solver\n+                        # 1. Greedy (Balanced LPT)\n+                        sorted_pool_idx = sorted(range(pool_len), key=lambda x: pool_weights[x], reverse=True)\n+                        set_A = []\n+                        set_B = []\n                         w_A, w_B = 0.0, 0.0\n-                        cnt_A, cnt_B = 0, 0\n-                        set_A_local = []\n-                        set_B_local = []\n-\n-                        for idx in sorted_idx:\n+                        \n+                        for idx in sorted_pool_idx:\n                             w = pool_weights[idx]\n-                            if cnt_A < K and cnt_B < K:\n+                            if len(set_A) < K and len(set_B) < K:\n                                 if w_A <= w_B:\n+                                    set_A.append(idx)\n                                     w_A += w\n-                                    cnt_A += 1\n-                                    set_A_local.append(idx)\n                                 else:\n+                                    set_B.append(idx)\n                                     w_B += w\n-                                    cnt_B += 1\n-                                    set_B_local.append(idx)\n-                            elif cnt_A < K:\n+                            elif len(set_A) < K:\n+                                set_A.append(idx)\n                                 w_A += w\n-                                cnt_A += 1\n-                                set_A_local.append(idx)\n                             else:\n+                                set_B.append(idx)\n                                 w_B += w\n-                                cnt_B += 1\n-                                set_B_local.append(idx)\n-\n+                                \n+                        curr_local_dev = abs(w_A - target)\n+                        if curr_local_dev < best_dev - 1e-6:\n+                            best_dev = curr_local_dev\n+                            best_assignment_A = list(set_A)\n+                        \n                         # 2. Local Search (Swap)\n-                        # Iteratively improve the partition by swapping pairs\n-                        curr_diff = w_A - w_B\n-\n-                        while True:\n-                            # We want to reduce |curr_diff|.\n-                            # Swap a (from A) and b (from B).\n-                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n-                            #          = w_A - w_B - 2*wa + 2*wb\n-                            #          = curr_diff - 2*(wa - wb)\n-\n-                            if abs(curr_diff) < 1e-6: break\n-\n-                            best_swap_gain = 0.0\n-                            best_pair = None\n-\n-                            # O(K^2) scan\n-                            for i_a, idx_a in enumerate(set_A_local):\n+                        current_A = set_A if best_assignment_A is None else best_assignment_A\n+                        # Recover B\n+                        current_A_set = set(current_A)\n+                        current_B = [x for x in range(pool_len) if x not in current_A_set]\n+                        \n+                        w_A = sum(pool_weights[x] for x in current_A)\n+                        w_B = sum(pool_weights[x] for x in current_B)\n+                        diff_local = w_A - w_B\n+                        \n+                        for _ in range(20): # Swap iterations\n+                            if abs(diff_local) < 1e-6: break\n+                            \n+                            best_swap = None\n+                            best_gain = 0.0\n+                            \n+                            for i_a, idx_a in enumerate(current_A):\n                                 wa = pool_weights[idx_a]\n-                                for i_b, idx_b in enumerate(set_B_local):\n+                                for i_b, idx_b in enumerate(current_B):\n                                     wb = pool_weights[idx_b]\n-\n-                                    change = 2.0 * (wa - wb)\n-                                    new_diff = curr_diff - change\n-\n-                                    # gain = reduction in absolute difference\n-                                    gain = abs(curr_diff) - abs(new_diff)\n-\n-                                    if gain > best_swap_gain + 1e-6:\n-                                        best_swap_gain = gain\n-                                        best_pair = (i_a, i_b, change, new_diff)\n-\n-                            if best_pair:\n-                                i_a, i_b, change, new_diff = best_pair\n-                                # Apply swap\n-                                val_a = set_A_local[i_a]\n-                                val_b = set_B_local[i_b]\n-                                set_A_local[i_a] = val_b\n-                                set_B_local[i_b] = val_a\n-\n-                                curr_diff = new_diff\n-                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n+                                    \n+                                    change = 2 * (wa - wb)\n+                                    new_diff = diff_local - change\n+                                    gain = abs(diff_local) - abs(new_diff)\n+                                    \n+                                    if gain > 1e-6 and gain > best_gain:\n+                                        best_gain = gain\n+                                        best_swap = (i_a, i_b, change, new_diff)\n+                            \n+                            if best_swap:\n+                                i_a, i_b, change, new_diff = best_swap\n+                                val_a = current_A[i_a]\n+                                val_b = current_B[i_b]\n+                                current_A[i_a] = val_b\n+                                current_B[i_b] = val_a\n+                                diff_local = new_diff\n+                                \n+                                if abs(diff_local / 2.0) < best_dev - 1e-6:\n+                                    best_dev = abs(diff_local / 2.0)\n+                                    best_assignment_A = list(current_A)\n                             else:\n                                 break\n \n-                        dev = abs(w_A - target_half)\n-                        if dev < best_dev - 1e-6:\n-                            best_dev = dev\n-                            best_assignment = list(set_A_local)\n-                            if dev < 1e-6: break\n-\n-                if best_assignment is not None:\n-                    set_A_indices = set(best_assignment)\n-                    new_max = [pool[i] for i in best_assignment]\n-                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n-                    current_packs[max_p] = new_max\n-                    current_packs[min_p] = new_min\n-                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n-                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n-                    improved = True\n-\n-                # 3-Way Rebalancing Fallback\n-                if not improved and num_packs >= 3:\n-                     # Pick random 3rd pack\n-                     while True:\n-                         mid_p = random.randint(0, num_packs - 1)\n-                         if mid_p != max_p and mid_p != min_p: break\n-\n-                     packs_3 = [max_p, min_p, mid_p]\n-                     pool_3 = []\n-                     for p in packs_3:\n-                         pool_3.extend(current_packs[p])\n-\n-                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n-                     total_3 = sum(pool_3_weights)\n-\n-                     # Check if we can improve deviation of these 3 packs\n-                     current_loads = [pack_weights[p] for p in packs_3]\n-                     best_spread_3 = max(current_loads) - min(current_loads)\n-\n-                     pool_3_indices = list(range(3 * K))\n-                     best_assignment_3 = None\n-\n-                     for sub in range(20):\n-                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n-                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n-\n-                         bins = [0.0] * 3\n-                         counts = [0] * 3\n-                         assignment = [[] for _ in range(3)]\n-\n-                         for idx in sorted_idx:\n-                             w = pool_3_weights[idx]\n-                             # Assign to valid bin with min load\n-                             best_b = -1\n-                             min_b_val = float('inf')\n-                             for b in range(3):\n-                                 if counts[b] < K:\n-                                     if bins[b] < min_b_val:\n-                                         min_b_val = bins[b]\n-                                         best_b = b\n-                             bins[best_b] += w\n-                             counts[best_b] += 1\n-                             assignment[best_b].append(idx)\n-\n-                         spread = max(bins) - min(bins)\n-                         if spread < best_spread_3 - 1e-6:\n-                             best_spread_3 = spread\n-                             best_assignment_3 = assignment\n-\n-                     if best_assignment_3 is not None:\n-                         for b_idx, p_idx in enumerate(packs_3):\n-                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n-                             current_packs[p_idx] = new_items\n-                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n-\n-            # Check result\n+                    # Update if improved\n+                    if best_assignment_A is not None:\n+                        # Retrieve global indices\n+                        new_max = [pool[x] for x in best_assignment_A]\n+                        set_A_indices = set(best_assignment_A)\n+                        new_other = [pool[x] for x in range(pool_len) if x not in set_A_indices]\n+                        \n+                        current_packs[max_p] = new_max\n+                        current_packs[other_p] = new_other\n+                        pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n+                        pack_weights[other_p] = sum(row_weight_list[x] for x in new_other)\n+                        improved = True\n+                        break # Break sorted_others loop to re-evaluate max pack\n+                \n+                if not improved:\n+                    break # Optimal given the 2-swap constraints from max_p\n+            \n+            # Update Global Best\n             current_diff = max(pack_weights) - min(pack_weights)\n             if current_diff < best_diff:\n                 best_diff = current_diff\n                 best_packs = [list(p) for p in current_packs]\n                 if best_diff < 1e-6:\n                     break\n \n-        # Fill tensors\n+        # Output Results\n         for p in range(num_packs):\n             for r, g in enumerate(best_packs[p]):\n                 pack_index[i, g] = p\n                 rank_in_pack[i, g] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n+\n+    Parameters:\n+        weight: [X, num_log]\n+        num_phy: total number of experts after replication\n+\n+    Returns:\n+        phy2log: [X, num_phy], logical expert id of each physical expert\n+        rank: [X, num_phy], the replica rank\n+        logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n \n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n \n     # Efficient incremental update of scores\n-    current_scores = weight.clone() # weight / 1\n+    current_scores = weight.clone() \n \n     for i in range(num_log, num_phy):\n         # Pick expert with max current load\n         redundant_indices = current_scores.max(dim=-1).indices\n \n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n \n         logcnt[arangen, redundant_indices] += 1\n \n         # Update score: weight / new_count\n         selected_weights = weight[arangen, redundant_indices]\n         selected_counts = logcnt[arangen, redundant_indices].float()\n         current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n \n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n-    Hierarchical rebalancing strategy.\n+    Parameters:\n+        weight: [num_moe_layers, num_logical_experts]\n+        num_physical_experts: number of physical experts after replication\n+        num_groups: number of expert groups\n+        num_nodes: number of server nodes, where the intra-node network\n+        (e.g, NVLink) is faster\n+        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n+\n+    Returns:\n+        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n+        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n+        logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n+    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n+    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n-        -1, pphy2phy)\n+        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n+\n+    Parameters:\n+        weight: [layers, num_logical_experts], the load statistics for all\n+            logical experts\n+        num_replicas: number of physical experts, must be a multiple of\n+            `num_gpus`\n+        num_groups: number of expert groups\n+        num_nodes: number of server nodes, where the intra-node network\n+            (e.g, NVLink) is faster\n+        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n+\n+    Returns:\n+        physical_to_logical_map: [layers, num_replicas], the expert index of\n+            each replica\n+        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n+            indices for each expert\n+        expert_count: [layers, num_logical_experts], number of physical\n+            replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385904468268,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.31107718089365366,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.055797357,
        0.019596301,
        0.015204219,
        -0.037892904,
        -0.022643868,
        0.011887751,
        -0.010778526,
        -0.011058633,
        -0.023573823,
        0.027002335,
        0.031551275,
        0.025232058,
        -0.012010997,
        -0.023708275,
        0.017624347,
        0.017489895,
        -0.013568394,
        0.0113947615,
        -0.007103519,
        0.05073302,
        0.010207107,
        -0.01105303,
        0.023685867,
        -0.043248553,
        -0.006985874,
        0.007534884,
        0.059741266,
        -0.045018833,
        0.033164695,
        -0.042934835,
        0.07659252,
        -0.0072939917,
        0.020503849,
        -0.0016078154,
        -0.0070811105,
        0.032895792,
        -0.0069298525,
        0.0124927815,
        0.013893317,
        0.06126505,
        0.02346178,
        -0.02928801,
        -0.049791858,
        0.04660984,
        -0.04425694,
        0.030363621,
        0.008235152,
        -0.0073276046,
        0.07363459,
        0.003456523,
        0.039461505,
        0.014957725,
        0.0033948994,
        0.0781163,
        0.02727124,
        0.040716384,
        0.020895999,
        0.021366578,
        0.013153835,
        -0.041478276,
        0.049074784,
        -0.009277151,
        0.07094555,
        0.035472777,
        -0.028257215,
        0.013277082,
        -0.03654839,
        0.029780999,
        0.016235014,
        -0.019809183,
        -0.029377645,
        0.05342205,
        -0.025545778,
        -0.022027632,
        0.0046861935,
        0.011630052,
        -0.019954838,
        0.03571927,
        -0.026576573,
        -0.04537737,
        -0.03354564,
        -0.010767321,
        0.054721747,
        0.023573823,
        0.010599257,
        -0.07802667,
        -0.016739206,
        -0.042553887,
        -0.028391667,
        -0.025545778,
        0.0313496,
        -0.050329663,
        -0.0006333924,
        0.03796013,
        0.036884516,
        -0.03208908,
        0.061220232,
        0.014453532,
        0.030363621,
        0.04902997,
        -0.012616029,
        0.013209856,
        -0.054139122,
        0.007490067,
        0.025702639,
        0.0077813785,
        0.00017865589,
        -0.0030083514,
        0.015080973,
        -0.02505279,
        -0.04692356,
        0.024783887,
        0.031999446,
        0.0093499785,
        0.01157403,
        0.002635809,
        -0.039170194,
        -0.02140019,
        0.011910159,
        -0.02836926,
        -0.023641048,
        -0.035853725,
        0.02646453,
        -0.029108742,
        0.007932636,
        -0.031125514,
        0.004478914,
        -0.030049901,
        0.0042464253,
        0.0031988244,
        0.041366234,
        0.024559801,
        0.0022800728,
        -0.016638368,
        -0.023372145,
        0.005753402,
        -0.01747869,
        0.011898954,
        -0.006756186,
        -0.013960544,
        -0.021310557,
        0.030901428,
        -0.015058564,
        -0.0072939917,
        -0.05673852,
        0.050150394,
        0.006022305,
        0.012705663,
        -0.04109733,
        0.027540142,
        0.024447758,
        -0.032201126,
        -0.011562826,
        -0.016873658,
        0.0035097434,
        -0.00561615,
        0.008380808,
        0.01669439,
        0.08425625,
        -0.03303024,
        -0.029691365,
        0.02361864,
        -0.027338464,
        0.023797909,
        0.032201126,
        0.02803313,
        -0.049702223,
        0.0038122593,
        -0.04880588,
        -0.058038216,
        -0.006448068,
        -0.014655209,
        -0.01259362,
        -0.015237832,
        0.002983142,
        0.012694459,
        -0.02346178,
        -0.034912564,
        -0.032357987,
        -0.043539867,
        -0.024783887,
        -0.014688822,
        -0.01836383,
        -0.012918545,
        -0.044055264,
        0.03244762,
        -0.029175967,
        -0.01173089,
        -0.008744948,
        -0.009988624,
        0.01441992,
        0.05481138,
        -0.034061037,
        0.027674593,
        -0.006756186,
        -0.01718738,
        0.053287596,
        0.018587915,
        0.008991442,
        0.0028963087,
        -0.037287872,
        -0.018464668,
        0.036257077,
        -0.037086196,
        0.03701897,
        0.039708,
        -0.009355581,
        0.008498453,
        0.004817844,
        -0.00684582,
        0.024694253,
        -0.033433598,
        0.039125375,
        -0.0005125962,
        -0.027159195,
        -0.024828704,
        -0.0582623,
        0.020571074,
        0.0028823032,
        0.0721108,
        -0.02134417,
        0.024985563,
        -0.018543098,
        0.008089497,
        -0.04203849,
        0.01975316,
        0.047013193,
        -0.014924113,
        0.0065825195,
        0.007988658,
        -0.027495325,
        -0.0014901704,
        -0.009120291,
        -0.02805554,
        0.03195463,
        -0.035920948,
        -0.038565163,
        0.025276875,
        -0.011383557,
        -0.036324304,
        0.025097607,
        0.03399381,
        0.007921432,
        -0.040223397,
        0.0129409535,
        0.020963224,
        -0.037736043,
        -0.009674903,
        0.0025993949,
        -0.025702639,
        0.015170607,
        -0.045780722,
        0.030789385,
        -0.05893456,
        -0.0128401145,
        0.03195463,
        -0.017131357,
        -0.055662904,
        -0.016817637,
        -0.03876684,
        0.012985771,
        -0.020403009,
        -0.0028514913,
        -0.024044404,
        -0.023685867,
        0.00096216827,
        -0.0044873175,
        0.037243057,
        -0.050284848,
        -0.021176105,
        0.028593345,
        0.017646754,
        -0.017960474,
        0.039595954,
        -0.044861972,
        -0.020492643,
        0.0017898851,
        -0.015887681,
        -0.027988313,
        -0.04031303,
        -0.028929474,
        -0.0040503503,
        0.03713101,
        -0.0028542925,
        0.009758935,
        -0.0077029485,
        -0.005509709,
        0.025747456,
        0.014991338,
        -0.022789523,
        0.0063696383,
        -0.015742026,
        0.038206626,
        0.016526327,
        -0.009641291,
        -0.015417101,
        -0.05700742,
        -0.02277832,
        -0.0038710816,
        -0.008476044,
        0.009288355,
        -0.009394796,
        -0.007058702,
        0.006089531,
        -0.006358434,
        -0.023484189,
        -0.017814819,
        0.016156584,
        -0.01196618,
        -0.027204012,
        -0.01345635,
        0.0035517595,
        -0.013960544,
        0.00027503027,
        -0.025904315,
        0.0018907237,
        0.03731028,
        0.0032380393,
        -0.020380601,
        -0.05118119,
        -0.05306351,
        -0.039416686,
        0.044861972,
        0.023080835,
        0.0076581314,
        0.023753092,
        -0.03876684,
        0.0182854,
        -0.015249037,
        -0.010526429,
        0.011428375,
        0.034509208,
        0.027069561,
        0.029736182,
        0.0078542065,
        -0.04410008,
        0.036279485,
        -0.0049606985,
        0.041321415,
        0.023484189,
        -0.063640356,
        0.017814819,
        -0.014341489,
        -0.017747594,
        -0.048402525,
        0.022083653,
        0.057903763,
        0.029825816,
        0.023439372,
        0.075561725,
        -0.03336637,
        -0.01024072,
        -0.019215355,
        0.016347056,
        0.012246287,
        -0.02393236,
        -0.0011533415,
        0.007899024,
        -0.044615477,
        0.0035797702,
        -0.028077947,
        -0.014464737,
        0.02962414,
        -0.00901385,
        -0.007439648,
        0.067136094,
        0.032223534,
        0.013758866,
        0.00830798,
        0.013109018,
        0.03872202,
        -0.010705697,
        -0.020515053,
        0.008728141,
        -0.008145518,
        -0.018330216,
        0.028862247,
        0.05893456,
        -0.03415067,
        0.0003312268,
        0.02285675,
        0.023842726,
        -0.022195695,
        0.008565678,
        0.019260172,
        0.036458757,
        -0.0061455523,
        0.020358192,
        -0.067942806,
        0.010716902,
        0.054721747,
        -0.014980134,
        -0.023753092,
        -0.049343687,
        0.032223534,
        -0.015237832,
        -0.0360554,
        -0.025209649,
        0.042710748,
        0.0030979859,
        -0.0051819836,
        0.0051847845,
        -0.037265465,
        -0.01841985,
        -0.030453257,
        0.009585269,
        0.043719135,
        0.018767184,
        -0.0005273018,
        0.04253148,
        0.029668957,
        -0.027831452,
        0.010761719,
        0.009641291,
        0.0060503157,
        -0.034307532,
        0.004966301,
        0.03388177,
        0.0060335095,
        -0.01441992,
        -0.0059550796,
        -0.0029691365,
        0.017736388,
        -0.0035433562,
        -0.021624276,
        0.015764434,
        0.012302309,
        -0.015293854,
        0.01110345,
        -0.060727242,
        -0.013097813,
        0.005420075,
        0.061758038,
        -0.023797909,
        0.023484189,
        0.039932083,
        -0.0025853897,
        0.021781137,
        -0.0031652115,
        0.0029215182,
        0.003296862,
        -0.014094995,
        -0.004977505,
        -0.0214226,
        0.020279761,
        -0.017254604,
        0.009047463,
        -0.05888974,
        0.053780586,
        -0.013445146,
        0.015708413,
        -0.014319081,
        0.05588699,
        0.0037310282,
        -0.026218036,
        -0.049254052,
        0.06516414,
        0.03621226,
        0.04611685,
        -0.018722367,
        0.038072173,
        0.01259362,
        0.0048682634,
        -0.01875598,
        0.05024003,
        0.010991408,
        0.004812242,
        -0.0054901014,
        0.009613279,
        0.026038766,
        0.055080283,
        -0.0459824,
        -0.005005516,
        0.038789246,
        -0.028279625,
        0.0075909053,
        -0.017377852,
        0.06646384,
        0.034083445,
        -0.040425073,
        0.029220784,
        -0.04723728,
        -0.033612866,
        -0.042710748,
        0.024380531,
        0.004817844,
        0.034352347,
        0.0047170054,
        0.00043486644,
        0.023058426,
        0.03466607,
        -0.012156653,
        0.006795401,
        -0.009036259,
        0.0030951847,
        -0.0057253917,
        -0.01528265,
        -0.02883984,
        0.0018851216,
        0.052167166,
        0.0043780757,
        -0.08869315,
        -0.053780586,
        -0.018834408,
        0.016840046,
        -0.030587709,
        -0.030766977,
        -0.0004733812,
        -0.0014509554,
        0.036301896,
        -0.016055746,
        -0.009422807,
        0.026240444,
        0.030498074,
        -0.0075236796,
        0.037579183,
        -0.002354301,
        0.004193205,
        0.008616098,
        0.034240305,
        -0.03069975,
        -0.01873357,
        -0.045937583,
        0.019428236,
        0.02946728,
        -0.031573687,
        -0.015080973,
        -0.044032853,
        0.011467589,
        -0.004812242,
        -0.017601937,
        -0.013209856,
        -0.056648884,
        0.035136648,
        -0.018935248,
        0.027764227,
        0.0018963258,
        -0.04096288,
        -0.0269127,
        -0.041590318,
        0.0074676583,
        0.017758798,
        0.023192877,
        0.019260172,
        0.0127392765,
        -0.03556241,
        0.068435796,
        0.030027494,
        0.02677825,
        0.02646453,
        0.010207107,
        -0.045086056,
        0.0024621424,
        -0.003142803,
        -0.028324442,
        -0.020055676,
        -0.01345635,
        -0.04902997,
        0.026554164,
        0.048133623,
        0.015954906,
        -0.009467624,
        0.008845786,
        0.0030923837,
        0.0040951674,
        0.011333138,
        0.023529006,
        -0.042890016,
        0.012470373,
        -0.00049684016,
        -0.013478759,
        0.012537599,
        0.0072043575,
        -0.05454248,
        0.027159195,
        0.00011817023,
        0.018251786,
        -0.027786635,
        -0.0061959717,
        -0.008913011,
        -0.025120014,
        -0.02053746,
        -0.01608936,
        -0.029220784,
        -0.05149491,
        -0.008733743,
        -0.03164091,
        -0.013221061,
        -0.007501271,
        -0.028414076,
        0.0010419989,
        -0.0005448085,
        0.033904176,
        -0.011349944,
        0.020044472,
        -0.0049466933,
        -0.041836813,
        0.012380739,
        0.027809044,
        0.011820524,
        -0.02061589,
        0.065119326,
        0.005268817,
        0.020268558,
        -0.029198376,
        0.0012506787,
        0.0064256596,
        0.0055321176,
        0.0017380653,
        -0.031551275,
        -0.0056497627,
        -0.016167788,
        -0.034397166,
        -0.00038829862,
        -0.007148336,
        0.0024369329,
        0.05431839,
        0.009137098,
        0.010078258,
        -0.019663526,
        -0.010151085,
        0.042621113,
        0.013624415,
        -0.01496893,
        0.003773044,
        -0.013153835,
        -0.013770071,
        -0.003848673,
        -0.026979927,
        0.016627165,
        -0.03825144,
        -0.014711231,
        -0.022184491,
        0.0305653,
        0.002071393,
        0.066284575,
        0.018901635,
        0.031080697,
        0.004190404,
        -0.012425556,
        0.027495325,
        -0.0044817156,
        0.01363562,
        -0.04380877,
        0.0150361555,
        0.019327398,
        -0.004008334,
        -0.004338861,
        0.014509554,
        -0.009579667,
        0.0006978171,
        -0.020750342,
        0.032044265,
        0.03309747,
        0.025545778,
        -0.018375034,
        -0.013971748,
        -0.031730544,
        -0.028279625,
        -0.0010763119,
        -0.033187103,
        -0.008896206,
        -0.01363562,
        -0.026038766,
        0.012963362,
        0.03132719,
        0.020895999,
        -0.002110608,
        0.006722573,
        0.052167166,
        -0.012571212,
        0.033971403,
        0.02132176,
        -0.04280038,
        -0.02866057,
        -0.019248968,
        -0.029870633,
        0.010890569,
        0.0017212589,
        0.02092961,
        0.01834142,
        -0.023797909,
        -0.03038603,
        -0.0013683237,
        -0.007058702,
        0.023484189,
        0.021590665,
        8.617673e-05,
        0.04201608,
        -0.019797977,
        0.015999723,
        -0.008588087,
        -0.036503572,
        -0.012414352,
        0.015181811,
        0.04224017,
        0.010375171,
        0.008195937,
        -0.023865135,
        -0.028122764,
        -0.01329949,
        -0.005966284,
        -0.029691365,
        -0.017288217,
        -0.04064916,
        -0.014677618,
        -0.044615477,
        0.050643384,
        0.027809044,
        -0.00295233,
        -0.039595954,
        0.0032912598,
        -0.023573823,
        -0.02197161,
        -0.06807726,
        0.0102967415,
        -0.0006862627,
        0.009865376,
        0.02834685,
        -0.03887888,
        -0.0062631974,
        -0.0019943633,
        -0.036413938,
        0.004238022,
        0.05006076,
        0.016403079,
        0.012873728,
        -0.0024761478,
        0.014128608,
        -0.0073556155,
        0.00846484,
        -0.017960474,
        0.015226629,
        -0.03497979,
        0.039775226,
        -0.009630086,
        -0.0020671913,
        -0.034845337,
        -0.022195695,
        0.013198652,
        -0.0071315295,
        -0.024582209,
        0.0057309936,
        -0.004770226,
        0.008907409,
        0.0028066742,
        -0.0055377195,
        0.032380395,
        -0.01789325,
        0.021153698,
        -0.034867745,
        0.005481698,
        -0.030610116,
        -0.0075124754,
        0.048402525,
        0.037713636,
        0.0153834885,
        -0.008672119,
        -0.00681781,
        0.0099998275,
        -0.014856887,
        -0.015954906,
        -0.021131288,
        0.021825954,
        0.015842864,
        0.0035517595,
        -0.042598706,
        -0.0031400018,
        0.009490033,
        -0.04201608,
        -0.02646453,
        -0.0099998275,
        0.046565022,
        0.046430573,
        0.024156446,
        -0.04172477,
        0.013714049,
        -0.05857602,
        0.0048822686,
        -0.025276875,
        -0.013030588,
        -0.025613004,
        -0.034083445,
        0.005753402,
        0.0031680125,
        0.0019397425,
        -0.05812785,
        -0.021691503,
        -0.011148267,
        -0.010722504,
        -0.06534341,
        -0.014431124,
        -0.0011974584,
        -0.027764227,
        -0.010991408,
        0.012010997,
        -0.03982004,
        -0.041679952,
        0.01363562,
        0.020604687,
        -0.008504055,
        0.0022926775,
        0.019999655,
        -0.0030867816,
        -0.012425556,
        -0.016347056,
        -0.056290347,
        0.0054536876,
        -0.03748955,
        0.021456212,
        0.019450646,
        -0.0010980202,
        -0.028705386,
        0.0049550966,
        0.060189437,
        -0.027988313,
        -0.045108467,
        -0.047282096,
        0.02962414,
        -0.012627233,
        -0.024963155,
        -0.045108467,
        0.041702364,
        0.0121454485,
        -0.044637885,
        -0.010033441,
        -0.01204461,
        0.00064774795,
        0.014599188,
        -0.014330285,
        0.0036694044,
        -0.025164831,
        0.0043052477,
        0.0076917442,
        0.0029607334,
        0.011854137,
        0.007153938,
        -0.0035853724,
        -0.0075909053,
        0.024828704,
        0.035808906,
        0.0072435727,
        0.002231054,
        -0.029265601,
        0.01314263,
        0.0154843265,
        0.037736043,
        0.036951743,
        -0.024627026,
        -0.016593551,
        -0.022307739,
        0.0061959717,
        0.029893043,
        -0.01424065,
        -0.0095012365,
        0.021501029,
        0.014016565,
        -0.011686073,
        0.013747662,
        -0.0071875514,
        -0.01771398,
        -0.044951607,
        0.014722435,
        -0.03168573,
        0.00629681,
        -0.027047154,
        0.028257215,
        0.03560723,
        -0.003613383,
        -0.0009096482,
        0.012403147,
        -0.034688476,
        0.024492575,
        0.021153698,
        -0.011484396,
        -0.01771398,
        -0.010526429,
        0.012033406,
        -0.039730407,
        -0.012716868,
        -0.0023529006,
        -0.015170607,
        -0.010307945,
        0.008772958,
        -0.007221164,
        0.014890499,
        0.0049242848,
        -0.0010412986,
        0.030968653,
        0.025478553,
        -0.004193205,
        0.0026035965,
        0.010627268,
        0.022162084,
        0.02536651,
        0.027898679,
        -0.008828979,
        -0.0022408578,
        0.027159195,
        -0.00056371576,
        -0.0076133143,
        0.007181949,
        -0.017702775,
        0.047013193,
        -0.01648151,
        -0.014251855,
        -0.0020727934,
        0.012526395,
        0.02677825,
        -0.05006076,
        0.070004396,
        -0.011019418,
        -0.03717583,
        -0.0063416273,
        0.0038738828,
        -0.026419712,
        0.0068850354,
        0.027002335,
        0.010352762,
        0.0018234979,
        0.027517732,
        -0.017826023,
        0.002387914,
        0.015327467,
        0.011630052,
        -0.003064373,
        0.009887785,
        -0.036794882,
        0.046206485,
        -0.014946521,
        0.012100631,
        -0.024447758,
        0.027786635,
        -0.0021568255,
        0.0042464253,
        -0.011428375,
        -0.01141717,
        -0.007764572,
        -0.013310695,
        0.0024887526,
        -0.05561809,
        -0.006089531,
        -0.0058430363,
        0.01722099,
        -0.025456144,
        -0.0352711,
        -0.0087505495,
        -0.011473192,
        -0.016347056,
        -0.015473123,
        0.028234808,
        -0.04880588,
        0.056200713,
        0.0019579495,
        -0.030879019,
        0.033052653,
        0.009596474,
        -0.005515311,
        -0.0038346678,
        0.016940884,
        0.04253148,
        -0.006027907,
        -0.02249821,
        0.0026246046,
        0.012716868,
        0.012414352,
        0.0030867816,
        -0.0069298525,
        -0.041299008,
        0.014229447,
        0.028750205,
        -0.021332966,
        0.021859568,
        -0.0013795281,
        0.0054732948,
        -0.048402525,
        0.005831832,
        -0.015461918,
        0.060234256,
        -0.019327398,
        0.016257422,
        0.008504055,
        -0.042733155,
        0.032850973,
        0.05499065,
        -0.008184733,
        0.046968378,
        0.004764624,
        0.0053836606,
        -0.023708275,
        0.058396753,
        0.033007834,
        0.010688892,
        -0.0068850354,
        0.013377921,
        0.01630224,
        -0.021142492,
        -0.016840046,
        -0.021478621,
        -0.006649745,
        -0.036481164,
        0.010403182,
        0.025881907,
        -0.004316452,
        0.011484396,
        0.0069634654,
        0.015226629,
        -0.020414215,
        0.0009390594,
        0.0061455523,
        0.033142287,
        -0.03887888,
        -0.017882045,
        0.0122911045,
        -0.03780327,
        -0.006179165,
        -0.031752955,
        0.00412878,
        -0.030520482,
        -0.0048346506,
        -0.0028304835,
        -0.04078361,
        -0.0034705284,
        -0.012526395,
        -0.010784128,
        0.01173089,
        0.02071673,
        -0.042441845,
        0.022330146,
        -0.021377783,
        0.02928801,
        -0.0049466933,
        -0.029175967,
        0.026688615,
        -0.015809251,
        -0.037892904,
        -0.006722573,
        0.031080697,
        0.026419712,
        0.00012744879,
        -0.02393236,
        0.03208908,
        -0.030542891,
        0.013030588,
        0.028951881,
        -0.005932671,
        -0.0011183281,
        0.01369164,
        -0.010431193,
        -0.010772923,
        -0.05767968,
        -0.0054480853,
        -0.0151369935,
        0.025478553,
        0.026755841,
        0.018139742,
        0.00072407717,
        0.0010833147,
        -0.0007415839,
        -0.0032800555,
        0.02285675,
        0.0021274143,
        -0.040850837,
        -0.017389055,
        0.009036259,
        0.013165039,
        -0.028951881,
        -0.018218173,
        0.004296845,
        0.0039775223,
        0.00058927556,
        0.0130417915,
        -0.013904522,
        0.02095202,
        0.008408818,
        -0.002988744,
        0.002677825,
        0.014890499,
        -0.012302309,
        -0.04533255,
        -0.010307945,
        0.0033920985,
        0.0032828567,
        -0.0013781275,
        -0.0124927815,
        0.03323192,
        0.03618985,
        0.0018108932,
        0.01685125,
        -0.0261284,
        -0.004280038,
        0.023708275,
        0.027540142,
        -0.009153903,
        0.013568394,
        -0.023797909,
        0.020156516,
        0.020627094,
        -0.020795159,
        0.011921363,
        0.0008872396,
        0.004994312,
        -0.0019621511,
        -0.008380808,
        -0.029355235,
        -0.047013193,
        -0.012414352,
        -0.010554439,
        0.024492575,
        -0.008369603,
        0.033792134,
        -0.020604687,
        0.023506597,
        0.03150646,
        -0.0034761305,
        -0.02771941,
        -0.001995764,
        -0.0064256596,
        0.015495531,
        0.020571074,
        -0.02740569,
        0.0021050058,
        -0.03432994,
        0.0368397,
        -0.03101347,
        -0.005820628,
        0.0043500653,
        0.023775501,
        0.0151369935,
        -0.0022646668,
        0.029579323,
        -0.06095133,
        0.032806158,
        0.024783887,
        -0.010218311,
        -0.026352488,
        -0.030273987,
        0.004498522,
        -0.0055293166,
        0.035338327,
        -0.0009572664,
        -0.016391873,
        0.038229033,
        0.015305058,
        -0.0039803237,
        -0.0061119394,
        0.011058633,
        0.0731416,
        0.0057225903,
        -0.0016806433,
        0.00822955,
        0.010251924,
        0.023775501,
        -0.01865514,
        -0.008128711,
        0.016447896,
        -0.04674429,
        -0.029668957,
        0.028167581,
        0.00031442035,
        -0.021478621,
        -0.0078374,
        0.018038904,
        -0.046565022,
        0.015103381,
        -0.015921295,
        0.011170676,
        -0.0061567565,
        -0.0046861935,
        -0.0055041066,
        -0.021445008,
        -0.0018150947,
        -0.032649297,
        0.0030951847,
        -0.029579323,
        -0.018229378,
        0.020727934,
        -0.024425348,
        -0.022722296,
        0.0072771856,
        0.0037002163,
        -0.0143863065,
        0.008817775,
        0.022688685,
        0.006240789,
        -0.004316452,
        0.010263128,
        -0.014957725,
        -0.0027786635,
        -0.02583709,
        -0.01651512,
        -0.018330216,
        -0.0063808425,
        -0.014767252,
        0.015495531,
        -0.00028150776,
        0.008991442,
        0.00684582,
        -0.018711163,
        0.00488507,
        -0.02518724,
        -0.024806295,
        3.5888736e-06,
        0.034576435,
        0.06099615,
        -0.038229033,
        0.0061511546,
        -0.006873831,
        -0.005072742,
        -0.003649797,
        0.034083445,
        0.015719617,
        -0.015719617,
        -0.018206969,
        -0.021131288,
        -0.01747869,
        0.031820178,
        -0.026733432,
        -0.0014649607,
        -0.009069871,
        -0.018812,
        0.031551275,
        -0.006801003,
        -0.015092176,
        0.02283434,
        0.020526256,
        -0.043046877,
        -0.013321899,
        0.010447999,
        8.867144e-05,
        0.012459169,
        -0.03217872,
        -0.03072216,
        0.032313168,
        0.024223672,
        -0.02693511,
        0.002285675,
        -0.00077729754,
        0.025456144,
        0.02503038,
        0.04457066,
        -0.019573892,
        -0.009237936,
        -0.0018291001,
        -0.0100502465,
        -0.012974566,
        0.023820318,
        -0.005554526,
        0.013590802,
        0.018330216,
        0.018509485,
        -0.030296396,
        0.038004946,
        -0.003764641,
        -0.0057646064,
        -0.044481024,
        -0.052211985,
        0.038811654,
        0.0018893231,
        0.025254466,
        -0.042307395,
        -0.035047013,
        0.03466607,
        0.0368397,
        0.03825144,
        -0.011876546,
        -0.016100563,
        0.024358124,
        -0.012660846,
        0.003571367,
        0.0006691061,
        -0.032021858,
        0.031416826,
        0.00446771,
        0.03654839,
        -0.027114378,
        0.013926931,
        0.0058038216,
        -0.008067088,
        0.03258207,
        -0.014285468,
        0.032223534,
        -0.0010237918,
        0.003294061,
        -0.036660433,
        -0.018711163,
        0.040425073,
        -0.038677204,
        0.009271549,
        0.0145879835,
        0.02740569,
        -0.04203849,
        0.0010132878,
        0.020380601,
        -0.015092176,
        0.034262713,
        -0.019417033,
        0.023080835,
        -0.024470165,
        -0.01718738,
        -0.040738795,
        0.019730752,
        -0.01651512,
        -0.0012884932,
        0.0070530996,
        0.0075180777,
        0.0030587707,
        -0.01954028,
        -0.025657821,
        -0.018912839,
        0.020134106,
        0.0154843265,
        0.0138372965,
        -0.020705525,
        0.0031624103,
        0.031282373,
        0.018498281,
        0.013131427,
        0.005966284,
        0.02014531,
        -0.018520689,
        -0.009921397,
        -0.0031596094,
        0.004428495,
        -0.0034397165,
        0.004403285,
        0.019349806,
        -0.024559801,
        0.018319013,
        0.026330078,
        0.0008914412,
        0.033971403,
        -0.060727242,
        0.0018164953,
        0.002285675,
        0.028391667,
        0.0075572925,
        0.03069975,
        0.0061903694,
        0.022419782,
        -0.011876546,
        0.03952873,
        0.031215148,
        -0.023349738,
        0.0023108844,
        -0.008957828,
        0.017680367,
        0.029265601,
        0.017657958,
        -0.018184561,
        -0.030766977,
        -0.0132882865,
        0.024761477,
        -0.004504124,
        0.01614538,
        0.021825954,
        -0.055842176,
        -0.0015770036,
        -0.005280021,
        0.0022954787,
        0.027517732,
        0.016582347,
        0.0060391114,
        -0.01836383,
        0.0046665864,
        0.008997044,
        -0.010358365,
        0.0058822515,
        0.017747594,
        0.028279625,
        -0.014218242,
        0.016671982,
        -0.015002542,
        -0.018173356,
        -0.0044396995,
        -0.02361864,
        0.01841985,
        0.033747315,
        -0.0037982538,
        0.027584959,
        -0.008055883,
        0.014431124,
        0.011237902,
        -9.304812e-05,
        -0.003991528,
        0.048850697,
        -0.032201126,
        -0.0013137028,
        0.022744706,
        0.02171391,
        -0.003949512,
        -0.041321415,
        -0.01165246,
        -0.0063976487,
        0.009725323,
        -0.019271376,
        -0.0010258927,
        -0.017389055,
        0.015529144,
        -0.014722435,
        -0.0070474977,
        -0.010123075,
        0.015461918,
        0.027472915,
        -0.02693511,
        0.012279901,
        0.013523577,
        0.027360873,
        0.030027494,
        -0.019495463,
        -0.011221095,
        0.02030217,
        0.029063925,
        -0.007344411,
        0.018935248,
        -0.007607712,
        -0.031752955,
        -0.0024677445,
        0.01196618,
        0.028234808,
        0.015921295,
        -0.002735247,
        0.0042884415,
        -0.031170331,
        -0.0024705457,
        0.013702845,
        -0.035876133,
        0.015170607,
        -0.00038164607,
        -0.0023767096,
        0.016716799,
        0.0069186483,
        0.010772923,
        -0.010806536,
        0.0154843265,
        0.0077029485,
        -0.011204288,
        0.044346575,
        -0.026374895,
        0.010212709,
        -0.030318804,
        -0.009742129,
        -0.04365191,
        -0.014901704,
        -0.025164831,
        0.012974566,
        0.005285623,
        -0.012627233,
        -0.009075474,
        0.013658028,
        -0.018587915,
        0.009187517,
        -0.0113947615,
        0.008834582,
        0.029310418,
        0.0001653508,
        -0.00024491875,
        -0.009462021,
        -0.030677343,
        -0.009260344,
        -0.023909952,
        0.015562757,
        -0.004582554,
        0.017176174,
        -0.028122764,
        -0.012212674,
        -0.000728979,
        0.008660915,
        -0.020178923,
        0.006683358,
        0.014957725,
        0.0068402183,
        0.012055814,
        0.008324786,
        0.0082519585,
        0.0049999137,
        -0.02787627,
        -0.008896206,
        -0.017758798,
        0.020918407,
        0.0076133143,
        -0.008476044,
        0.0023529006,
        0.015159402,
        0.01991002,
        0.030879019,
        -0.007971851,
        -0.004708602,
        0.009411602,
        -0.041948855,
        -0.026173217,
        -0.01708654,
        -0.013321899,
        0.029310418,
        -0.0036638023,
        0.019036086,
        0.030318804,
        0.021960406,
        0.04723728,
        -0.033769727,
        -0.013523577,
        0.049074784,
        -0.0021218122,
        -0.031259965,
        -0.007697346,
        -0.013602006,
        0.0087505495,
        -0.024873521,
        0.033747315,
        0.026576573,
        -0.008649711,
        0.0025615804,
        -0.033926588,
        -0.010291139,
        -0.018901635,
        0.013411533,
        -0.020078085,
        0.022800727,
        0.0022268523,
        0.0061567565,
        0.030161945,
        0.009434011,
        0.005406069,
        -0.00033875467,
        -0.007092315,
        -0.0056133484,
        0.005618951,
        -0.0023010809,
        -0.004299646,
        -0.012728072,
        -0.029780999,
        0.031596094,
        0.0031007868,
        0.0058038216,
        -0.00566937,
        0.014453532
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 267.4988601207733,
        "patch_type": "cross",
        "api_costs": 0.20152599999999998,
        "num_applied": 1,
        "patch_name": "moe_eplb_hybrid_partition",
        "patch_description": "This program improves the expert load balancing algorithm by combining an efficient multi-start initialization strategy with a robust pairwise partition refinement. \nThe `balanced_packing` function performs calculations on the CPU to avoid GPU overhead. It uses a restart mechanism with both deterministic and randomized Longest Processing Time (LPT) greedy initializations. \nThe core refinement phase iteratively identifies the heaviest pack (Max Pack) and attempts to rebalance it against lighter packs using a \"2-Pack Partition Solver\". \nThis solver pools the items from the two packs and redistributes them to minimize the load difference. For small group sizes, an exact solver (using combinations) is used; for larger sizes, a heuristic (greedy + local swap) is employed. This approach is more powerful than simple single-item swaps as it can rearrange multiple items simultaneously to achieve balance. The 3-way rebalancing fallback from prior implementations is removed in favor of iterating through multiple 2-way pairings (Max vs Min, Max vs 2nd Min, etc.), which is cleaner and efficiently escapes local optima.\n`replicate_experts` utilizes an incremental score update mechanism to minimize redundant computations.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 1,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\nmoe_eplb_hybrid_partition\n</NAME>\n\n<DESCRIPTION>\nThis program improves the expert load balancing algorithm by combining an efficient multi-start initialization strategy with a robust pairwise partition refinement. \nThe `balanced_packing` function performs calculations on the CPU to avoid GPU overhead. It uses a restart mechanism with both deterministic and randomized Longest Processing Time (LPT) greedy initializations. \nThe core refinement phase iteratively identifies the heaviest pack (Max Pack) and attempts to rebalance it against lighter packs using a \"2-Pack Partition Solver\". \nThis solver pools the items from the two packs and redistributes them to minimize the load difference. For small group sizes, an exact solver (using combinations) is used; for larger sizes, a heuristic (greedy + local swap) is employed. This approach is more powerful than simple single-item swaps as it can rearrange multiple items simultaneously to achieve balance. The 3-way rebalancing fallback from prior implementations is removed in favor of iterating through multiple 2-way pairings (Max vs Min, Max vs 2nd Min, etc.), which is cleaner and efficiently escapes local optima.\n`replicate_experts` utilizes an incremental score update mechanism to minimize redundant computations.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    num_restarts = 3\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices sorted descending\n        base_indices = sorted(range(num_groups), key=lambda x: row_weight_list[x], reverse=True)\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = sorted(range(num_groups), key=lambda x: row_weight_list[x] * noise[x].item(), reverse=True)\n\n            # Greedy Assignment\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement\n            # Iteratively try to improve the Heaviest Pack\n            for step in range(max_refine_steps):\n                # Identify Max Pack\n                max_p = 0\n                max_val = pack_weights[0]\n                min_p = 0\n                min_val = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val > max_val:\n                        max_val = val\n                        max_p = p\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                \n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n                \n                # Check against packs sorted by weight (ascending)\n                # We try to rebalance Max Pack with Lighter packs\n                sorted_others = sorted([p for p in range(num_packs) if p != max_p], \n                                       key=pack_weights.__getitem__)\n                \n                improved = False\n                \n                for other_p in sorted_others:\n                    # Current load difference\n                    current_pair_diff = abs(pack_weights[max_p] - pack_weights[other_p])\n                    if current_pair_diff < 1e-6:\n                        continue # Cannot improve equal packs\n\n                    # Pool items\n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    total_pool = sum(pool_weights)\n                    target = total_pool / 2.0\n                    \n                    K = groups_per_pack\n                    pool_len = 2 * K\n                    \n                    best_assignment_A = None\n                    best_dev = abs(pack_weights[max_p] - target)\n                    \n                    # 2-Partition Solver\n                    if pool_len <= 14:\n                        # Exact Solver\n                        # Fix item 0 to Set A\n                        w_0 = pool_weights[0]\n                        indices_rest = list(range(1, pool_len))\n                        \n                        for comb in itertools.combinations(indices_rest, K - 1):\n                            s = w_0 + sum(pool_weights[x] for x in comb)\n                            dev = abs(s - target)\n                            if dev < best_dev - 1e-6:\n                                best_dev = dev\n                                best_assignment_A = [0] + list(comb)\n                                if dev < 1e-6: break\n                    else:\n                        # Heuristic Solver\n                        # 1. Greedy (Balanced LPT)\n                        sorted_pool_idx = sorted(range(pool_len), key=lambda x: pool_weights[x], reverse=True)\n                        set_A = []\n                        set_B = []\n                        w_A, w_B = 0.0, 0.0\n                        \n                        for idx in sorted_pool_idx:\n                            w = pool_weights[idx]\n                            if len(set_A) < K and len(set_B) < K:\n                                if w_A <= w_B:\n                                    set_A.append(idx)\n                                    w_A += w\n                                else:\n                                    set_B.append(idx)\n                                    w_B += w\n                            elif len(set_A) < K:\n                                set_A.append(idx)\n                                w_A += w\n                            else:\n                                set_B.append(idx)\n                                w_B += w\n                                \n                        curr_local_dev = abs(w_A - target)\n                        if curr_local_dev < best_dev - 1e-6:\n                            best_dev = curr_local_dev\n                            best_assignment_A = list(set_A)\n                        \n                        # 2. Local Search (Swap)\n                        current_A = set_A if best_assignment_A is None else best_assignment_A\n                        # Recover B\n                        current_A_set = set(current_A)\n                        current_B = [x for x in range(pool_len) if x not in current_A_set]\n                        \n                        w_A = sum(pool_weights[x] for x in current_A)\n                        w_B = sum(pool_weights[x] for x in current_B)\n                        diff_local = w_A - w_B\n                        \n                        for _ in range(20): # Swap iterations\n                            if abs(diff_local) < 1e-6: break\n                            \n                            best_swap = None\n                            best_gain = 0.0\n                            \n                            for i_a, idx_a in enumerate(current_A):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(current_B):\n                                    wb = pool_weights[idx_b]\n                                    \n                                    change = 2 * (wa - wb)\n                                    new_diff = diff_local - change\n                                    gain = abs(diff_local) - abs(new_diff)\n                                    \n                                    if gain > 1e-6 and gain > best_gain:\n                                        best_gain = gain\n                                        best_swap = (i_a, i_b, change, new_diff)\n                            \n                            if best_swap:\n                                i_a, i_b, change, new_diff = best_swap\n                                val_a = current_A[i_a]\n                                val_b = current_B[i_b]\n                                current_A[i_a] = val_b\n                                current_B[i_b] = val_a\n                                diff_local = new_diff\n                                \n                                if abs(diff_local / 2.0) < best_dev - 1e-6:\n                                    best_dev = abs(diff_local / 2.0)\n                                    best_assignment_A = list(current_A)\n                            else:\n                                break\n\n                    # Update if improved\n                    if best_assignment_A is not None:\n                        # Retrieve global indices\n                        new_max = [pool[x] for x in best_assignment_A]\n                        set_A_indices = set(best_assignment_A)\n                        new_other = [pool[x] for x in range(pool_len) if x not in set_A_indices]\n                        \n                        current_packs[max_p] = new_max\n                        current_packs[other_p] = new_other\n                        pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                        pack_weights[other_p] = sum(row_weight_list[x] for x in new_other)\n                        improved = True\n                        break # Break sorted_others loop to re-evaluate max pack\n                \n                if not improved:\n                    break # Optimal given the 2-swap constraints from max_p\n            \n            # Update Global Best\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Output Results\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() \n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n```\n</CODE>",
          "msg": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move weights to CPU and convert to list for faster access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.empty_like(weight, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty_like(weight, dtype=torch.int64, device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        current_packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy packing\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Pairwise swapping\n        for _ in range(20):\n            found_improvement = False\n            # Sort packs by weight descending\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n                # Check against lighter packs\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6: break\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Try to swap item u from heavier pack with item v from lighter pack\n                    for idx_u, u in enumerate(current_packs[p1]):\n                        w_u = row_weight[u]\n                        for idx_v, v in enumerate(current_packs[p2]):\n                            w_v = row_weight[v]\n                            delta = w_u - w_v\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (idx_u, idx_v, delta)\n                                    if gap < 1e-5: break\n                        if best_swap and best_gap < 1e-5: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta = best_swap\n                        u = current_packs[p1][idx_u]\n                        v = current_packs[p2][idx_v]\n                        current_packs[p1][idx_u] = v\n                        current_packs[p2][idx_v] = u\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n                if found_improvement: break\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a new program with the same inputs and outputs as the original program, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nPerform a cross-over between the code script above and the one below. Aim to combine the best parts of both code implementations that improves the score.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n\n\n# Crossover Inspiration Programs\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics: Combined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nYou are given multiple code scripts implementing the same algorithm.\nYou are tasked with generating a new code snippet that combines these code scripts in a way that is more efficient. \nI.e. perform crossover between the code scripts.\nProvide the complete new program code.\nYou MUST repond using a short summary name, description and the full code:\n\n<NAME>\nA shortened name summarizing the code you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the code you are proposing.\n</DESCRIPTION>\n\n<CODE>\n```{language}\n# The new rewritten program here.\n```\n</CODE>\n\n* Keep the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the code. Do not change the code outside of these markers.\n* Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n* Make sure the file still runs after your changes.\n* Use the <NAME>, <DESCRIPTION>, and <CODE> delimiters to structure your response. It will be parsed afterwards.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move weights to CPU and convert to list for faster access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.empty_like(weight, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty_like(weight, dtype=torch.int64, device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        current_packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy packing\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Pairwise swapping\n        for _ in range(20):\n            found_improvement = False\n            # Sort packs by weight descending\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n                # Check against lighter packs\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6: break\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Try to swap item u from heavier pack with item v from lighter pack\n                    for idx_u, u in enumerate(current_packs[p1]):\n                        w_u = row_weight[u]\n                        for idx_v, v in enumerate(current_packs[p2]):\n                            w_v = row_weight[v]\n                            delta = w_u - w_v\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (idx_u, idx_v, delta)\n                                    if gap < 1e-5: break\n                        if best_swap and best_gap < 1e-5: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta = best_swap\n                        u = current_packs[p1][idx_u]\n                        v = current_packs[p2][idx_v]\n                        current_packs[p1][idx_u] = v\n                        current_packs[p2][idx_v] = u\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n                if found_improvement: break\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a new program with the same inputs and outputs as the original program, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 2\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max and min packs\n                min_p = 0\n                max_p = 0\n                min_val = pack_weights[0]\n                max_val = pack_weights[0]\n\n                # Random perturbation occasionally\n                if step > 0 and step % 6 == 0:\n                    p1 = random.randint(0, num_packs - 1)\n                    p2 = random.randint(0, num_packs - 2)\n                    if p2 >= p1: p2 += 1\n                    max_p, min_p = p1, p2\n                    max_val, min_val = pack_weights[max_p], pack_weights[min_p]\n                else:\n                    for p in range(1, num_packs):\n                        val = pack_weights[p]\n                        if val < min_val:\n                            min_val = val\n                            min_p = p\n                        elif val > max_val:\n                            max_val = val\n                            max_p = p\n\n                diff = max_val - min_val\n                if diff < 1e-6:\n                    if step % 6 != 0: break\n                    else: continue\n\n                # Try 2-Pack Rebalancing\n                pool = current_packs[max_p] + current_packs[min_p]\n                pool_weights = [row_weight_list[x] for x in pool]\n                total_pool = sum(pool_weights)\n                target_half = total_pool / 2.0\n                K = groups_per_pack\n                pool_len = 2 * K\n\n                improved = False\n                best_dev = abs(pack_weights[max_p] - target_half)\n                best_assignment = None\n\n                # EXACT SOLVER for small K\n                # 2K <= 14 => K <= 7. (13 choose 6) = 1716. Very fast.\n                if pool_len <= 14:\n                    # Fix first element to be in Set A to reduce symmetry\n                    indices_rest = list(range(1, pool_len))\n                    w_0 = pool_weights[0]\n\n                    for comb in itertools.combinations(indices_rest, K - 1):\n                        s = w_0\n                        for idx in comb:\n                            s += pool_weights[idx]\n                        dev = abs(s - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = (0,) + comb\n                            if dev < 1e-6: break\n                else:\n                    # Heuristic Solver with Local Search\n                    pool_indices = list(range(pool_len))\n                    sub_trials = 15\n                    for sub in range(sub_trials):\n                        # 1. Randomized Greedy Construction\n                        if sub == 0:\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i], reverse=True)\n                        else:\n                            noise = [random.uniform(0.8, 1.2) for _ in pool]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise[i], reverse=True)\n\n                        w_A, w_B = 0.0, 0.0\n                        cnt_A, cnt_B = 0, 0\n                        set_A_local = []\n                        set_B_local = []\n\n                        for idx in sorted_idx:\n                            w = pool_weights[idx]\n                            if cnt_A < K and cnt_B < K:\n                                if w_A <= w_B:\n                                    w_A += w\n                                    cnt_A += 1\n                                    set_A_local.append(idx)\n                                else:\n                                    w_B += w\n                                    cnt_B += 1\n                                    set_B_local.append(idx)\n                            elif cnt_A < K:\n                                w_A += w\n                                cnt_A += 1\n                                set_A_local.append(idx)\n                            else:\n                                w_B += w\n                                cnt_B += 1\n                                set_B_local.append(idx)\n\n                        # 2. Local Search (Swap)\n                        # Iteratively improve the partition by swapping pairs\n                        curr_diff = w_A - w_B\n\n                        while True:\n                            # We want to reduce |curr_diff|.\n                            # Swap a (from A) and b (from B).\n                            # New diff = (w_A - wa + wb) - (w_B - wb + wa)\n                            #          = w_A - w_B - 2*wa + 2*wb\n                            #          = curr_diff - 2*(wa - wb)\n\n                            if abs(curr_diff) < 1e-6: break\n\n                            best_swap_gain = 0.0\n                            best_pair = None\n\n                            # O(K^2) scan\n                            for i_a, idx_a in enumerate(set_A_local):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(set_B_local):\n                                    wb = pool_weights[idx_b]\n\n                                    change = 2.0 * (wa - wb)\n                                    new_diff = curr_diff - change\n\n                                    # gain = reduction in absolute difference\n                                    gain = abs(curr_diff) - abs(new_diff)\n\n                                    if gain > best_swap_gain + 1e-6:\n                                        best_swap_gain = gain\n                                        best_pair = (i_a, i_b, change, new_diff)\n\n                            if best_pair:\n                                i_a, i_b, change, new_diff = best_pair\n                                # Apply swap\n                                val_a = set_A_local[i_a]\n                                val_b = set_B_local[i_b]\n                                set_A_local[i_a] = val_b\n                                set_B_local[i_b] = val_a\n\n                                curr_diff = new_diff\n                                w_A = w_A - pool_weights[val_a] + pool_weights[val_b]\n                            else:\n                                break\n\n                        dev = abs(w_A - target_half)\n                        if dev < best_dev - 1e-6:\n                            best_dev = dev\n                            best_assignment = list(set_A_local)\n                            if dev < 1e-6: break\n\n                if best_assignment is not None:\n                    set_A_indices = set(best_assignment)\n                    new_max = [pool[i] for i in best_assignment]\n                    new_min = [pool[i] for i in range(pool_len) if i not in set_A_indices]\n                    current_packs[max_p] = new_max\n                    current_packs[min_p] = new_min\n                    pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                    pack_weights[min_p] = sum(row_weight_list[x] for x in new_min)\n                    improved = True\n\n                # 3-Way Rebalancing Fallback\n                if not improved and num_packs >= 3:\n                     # Pick random 3rd pack\n                     while True:\n                         mid_p = random.randint(0, num_packs - 1)\n                         if mid_p != max_p and mid_p != min_p: break\n\n                     packs_3 = [max_p, min_p, mid_p]\n                     pool_3 = []\n                     for p in packs_3:\n                         pool_3.extend(current_packs[p])\n\n                     pool_3_weights = [row_weight_list[x] for x in pool_3]\n                     total_3 = sum(pool_3_weights)\n\n                     # Check if we can improve deviation of these 3 packs\n                     current_loads = [pack_weights[p] for p in packs_3]\n                     best_spread_3 = max(current_loads) - min(current_loads)\n\n                     pool_3_indices = list(range(3 * K))\n                     best_assignment_3 = None\n\n                     for sub in range(20):\n                         noise = [random.uniform(0.8, 1.2) for _ in pool_3]\n                         sorted_idx = sorted(pool_3_indices, key=lambda i: pool_3_weights[i] * noise[i], reverse=True)\n\n                         bins = [0.0] * 3\n                         counts = [0] * 3\n                         assignment = [[] for _ in range(3)]\n\n                         for idx in sorted_idx:\n                             w = pool_3_weights[idx]\n                             # Assign to valid bin with min load\n                             best_b = -1\n                             min_b_val = float('inf')\n                             for b in range(3):\n                                 if counts[b] < K:\n                                     if bins[b] < min_b_val:\n                                         min_b_val = bins[b]\n                                         best_b = b\n                             bins[best_b] += w\n                             counts[best_b] += 1\n                             assignment[best_b].append(idx)\n\n                         spread = max(bins) - min(bins)\n                         if spread < best_spread_3 - 1e-6:\n                             best_spread_3 = spread\n                             best_assignment_3 = assignment\n\n                     if best_assignment_3 is not None:\n                         for b_idx, p_idx in enumerate(packs_3):\n                             new_items = [pool_3[x] for x in best_assignment_3[b_idx]]\n                             current_packs[p_idx] = new_items\n                             pack_weights[p_idx] = sum(row_weight_list[x] for x in new_items)\n\n            # Check result\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nPerform a cross-over between the code script above and the one below. Aim to combine the best parts of both code implementations that improves the score.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n\n\n# Crossover Inspiration Programs\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics: Combined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\nmoe_eplb_hybrid_partition\n</NAME>\n\n<DESCRIPTION>\nThis program improves the expert load balancing algorithm by combining an efficient multi-start initialization strategy with a robust pairwise partition refinement. \nThe `balanced_packing` function performs calculations on the CPU to avoid GPU overhead. It uses a restart mechanism with both deterministic and randomized Longest Processing Time (LPT) greedy initializations. \nThe core refinement phase iteratively identifies the heaviest pack (Max Pack) and attempts to rebalance it against lighter packs using a \"2-Pack Partition Solver\". \nThis solver pools the items from the two packs and redistributes them to minimize the load difference. For small group sizes, an exact solver (using combinations) is used; for larger sizes, a heuristic (greedy + local swap) is employed. This approach is more powerful than simple single-item swaps as it can rearrange multiple items simultaneously to achieve balance. The 3-way rebalancing fallback from prior implementations is removed in favor of iterating through multiple 2-way pairings (Max vs Min, Max vs 2nd Min, etc.), which is cleaner and efficiently escapes local optima.\n`replicate_experts` utilizes an incremental score update mechanism to minimize redundant computations.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    num_restarts = 3\n    max_refine_steps = 20\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices sorted descending\n        base_indices = sorted(range(num_groups), key=lambda x: row_weight_list[x], reverse=True)\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = sorted(range(num_groups), key=lambda x: row_weight_list[x] * noise[x].item(), reverse=True)\n\n            # Greedy Assignment\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement\n            # Iteratively try to improve the Heaviest Pack\n            for step in range(max_refine_steps):\n                # Identify Max Pack\n                max_p = 0\n                max_val = pack_weights[0]\n                min_p = 0\n                min_val = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    val = pack_weights[p]\n                    if val > max_val:\n                        max_val = val\n                        max_p = p\n                    if val < min_val:\n                        min_val = val\n                        min_p = p\n                \n                diff = max_val - min_val\n                if diff < 1e-6:\n                    break\n                \n                # Check against packs sorted by weight (ascending)\n                # We try to rebalance Max Pack with Lighter packs\n                sorted_others = sorted([p for p in range(num_packs) if p != max_p], \n                                       key=pack_weights.__getitem__)\n                \n                improved = False\n                \n                for other_p in sorted_others:\n                    # Current load difference\n                    current_pair_diff = abs(pack_weights[max_p] - pack_weights[other_p])\n                    if current_pair_diff < 1e-6:\n                        continue # Cannot improve equal packs\n\n                    # Pool items\n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n                    total_pool = sum(pool_weights)\n                    target = total_pool / 2.0\n                    \n                    K = groups_per_pack\n                    pool_len = 2 * K\n                    \n                    best_assignment_A = None\n                    best_dev = abs(pack_weights[max_p] - target)\n                    \n                    # 2-Partition Solver\n                    if pool_len <= 14:\n                        # Exact Solver\n                        # Fix item 0 to Set A\n                        w_0 = pool_weights[0]\n                        indices_rest = list(range(1, pool_len))\n                        \n                        for comb in itertools.combinations(indices_rest, K - 1):\n                            s = w_0 + sum(pool_weights[x] for x in comb)\n                            dev = abs(s - target)\n                            if dev < best_dev - 1e-6:\n                                best_dev = dev\n                                best_assignment_A = [0] + list(comb)\n                                if dev < 1e-6: break\n                    else:\n                        # Heuristic Solver\n                        # 1. Greedy (Balanced LPT)\n                        sorted_pool_idx = sorted(range(pool_len), key=lambda x: pool_weights[x], reverse=True)\n                        set_A = []\n                        set_B = []\n                        w_A, w_B = 0.0, 0.0\n                        \n                        for idx in sorted_pool_idx:\n                            w = pool_weights[idx]\n                            if len(set_A) < K and len(set_B) < K:\n                                if w_A <= w_B:\n                                    set_A.append(idx)\n                                    w_A += w\n                                else:\n                                    set_B.append(idx)\n                                    w_B += w\n                            elif len(set_A) < K:\n                                set_A.append(idx)\n                                w_A += w\n                            else:\n                                set_B.append(idx)\n                                w_B += w\n                                \n                        curr_local_dev = abs(w_A - target)\n                        if curr_local_dev < best_dev - 1e-6:\n                            best_dev = curr_local_dev\n                            best_assignment_A = list(set_A)\n                        \n                        # 2. Local Search (Swap)\n                        current_A = set_A if best_assignment_A is None else best_assignment_A\n                        # Recover B\n                        current_A_set = set(current_A)\n                        current_B = [x for x in range(pool_len) if x not in current_A_set]\n                        \n                        w_A = sum(pool_weights[x] for x in current_A)\n                        w_B = sum(pool_weights[x] for x in current_B)\n                        diff_local = w_A - w_B\n                        \n                        for _ in range(20): # Swap iterations\n                            if abs(diff_local) < 1e-6: break\n                            \n                            best_swap = None\n                            best_gain = 0.0\n                            \n                            for i_a, idx_a in enumerate(current_A):\n                                wa = pool_weights[idx_a]\n                                for i_b, idx_b in enumerate(current_B):\n                                    wb = pool_weights[idx_b]\n                                    \n                                    change = 2 * (wa - wb)\n                                    new_diff = diff_local - change\n                                    gain = abs(diff_local) - abs(new_diff)\n                                    \n                                    if gain > 1e-6 and gain > best_gain:\n                                        best_gain = gain\n                                        best_swap = (i_a, i_b, change, new_diff)\n                            \n                            if best_swap:\n                                i_a, i_b, change, new_diff = best_swap\n                                val_a = current_A[i_a]\n                                val_b = current_B[i_b]\n                                current_A[i_a] = val_b\n                                current_B[i_b] = val_a\n                                diff_local = new_diff\n                                \n                                if abs(diff_local / 2.0) < best_dev - 1e-6:\n                                    best_dev = abs(diff_local / 2.0)\n                                    best_assignment_A = list(current_A)\n                            else:\n                                break\n\n                    # Update if improved\n                    if best_assignment_A is not None:\n                        # Retrieve global indices\n                        new_max = [pool[x] for x in best_assignment_A]\n                        set_A_indices = set(best_assignment_A)\n                        new_other = [pool[x] for x in range(pool_len) if x not in set_A_indices]\n                        \n                        current_packs[max_p] = new_max\n                        current_packs[other_p] = new_other\n                        pack_weights[max_p] = sum(row_weight_list[x] for x in new_max)\n                        pack_weights[other_p] = sum(row_weight_list[x] for x in new_other)\n                        improved = True\n                        break # Break sorted_others loop to re-evaluate max pack\n                \n                if not improved:\n                    break # Optimal given the 2-swap constraints from max_p\n            \n            # Update Global Best\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Output Results\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() \n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n```\n</CODE>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 33521,
          "output_tokens": 11207,
          "cost": 0.20152599999999998,
          "input_cost": 0.06704199999999999,
          "output_cost": 0.134484,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 0,
          "deleted": 21,
          "modified": 186
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 7.588e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_97/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_97/results\nRun 1/5 completed in 0.53 seconds\nRun 2/5 completed in 1.02 seconds\nRun 3/5 completed in 0.98 seconds\nRun 4/5 completed in 0.96 seconds\nRun 5/5 completed in 0.92 seconds\nbalancedness: 0.21073683733844054\nbalancedness: 0.3397761717755627\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_97/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_97/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385904468268\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.31107718089365366, 'speed_score': 1.0}\n  execution_time_mean: 0.879367819201434\n  execution_time_std: 0.1792628849149377\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 68,
          "average_cyclomatic_complexity": 13.6,
          "halstead_volume": 2409.0948004846173,
          "halstead_difficulty": 15.428571428571429,
          "halstead_effort": 37168.891207476954,
          "lines_of_code": 439,
          "logical_lines_of_code": 238,
          "comments": 42,
          "maintainability_index": -45.263081843490355,
          "max_nesting_depth": 10,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "1c186c39-57ed-4a94-8556-256b98868004",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Trivial case: 1 item per pack\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move computation to CPU to avoid GPU overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Strategy: Multi-start with different initializations + All-Pairs Descent Refinement\n    # Candidates:\n    # 0: Deterministic Greedy (LPT)\n    # 1: ZigZag (Snake) Packing\n    # 2, 3: Randomized Greedy\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Create list of (original_index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort desc for deterministic heuristics\n        items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        for attempt in range(num_restarts):\n            # Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Greedy LPT\n                for idx, w in items_sorted:\n                    # Assign to lightest pack with capacity\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n                    \n            elif attempt == 1:\n                # ZigZag / Snake Packing\n                # Distributes sorted items: 0->M, M->0, 0->M...\n                for k, (idx, w) in enumerate(items_sorted):\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n                    \n            else:\n                # Randomized Greedy\n                # Add noise to weights to perturb sort order\n                # Use a lightweight pseudo-random approach\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                noisy_items = []\n                for k, (idx, w) in enumerate(items):\n                    noisy_items.append((idx, w, w * noise[k]))\n                # Sort by noisy weight\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # Refinement: All-Pairs Descent\n            # Try to balance every pair of packs, prioritizing the heaviest\n            for _ in range(20): # Max iterations\n                # Identify packing order\n                pack_indices_ordered = sorted(range(num_packs), \n                                              key=lambda p: pack_weights[p], \n                                              reverse=True)\n                \n                max_w = pack_weights[pack_indices_ordered[0]]\n                min_w = pack_weights[pack_indices_ordered[-1]]\n                if (max_w - min_w) < 1e-6:\n                    break\n                \n                improved = False\n                \n                # Double loop: Try to move weight from Heavier -> Lighter\n                # We limit the outer loop to top few heaviest packs to save time\n                for i_h in range(min(num_packs, 5)):\n                    p_heavy = pack_indices_ordered[i_h]\n                    w_heavy = pack_weights[p_heavy]\n                    \n                    # Try to swap with lighter packs\n                    for i_l in range(num_packs - 1, i_h, -1):\n                        p_light = pack_indices_ordered[i_l]\n                        w_light = pack_weights[p_light]\n                        \n                        diff = w_heavy - w_light\n                        if diff < 1e-6: continue\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u in heavy, v in light)\n                        ph_items = current_packs[p_heavy]\n                        pl_items = current_packs[p_light]\n                        \n                        for u_i, (idx_u, w_u) in enumerate(ph_items):\n                            for v_i, (idx_v, w_v) in enumerate(pl_items):\n                                delta = w_u - w_v\n                                # Valid swap must reduce heavy pack weight\n                                if delta > 0 and delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (u_i, v_i, delta, idx_u, w_u, idx_v, w_v)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            u_i, v_i, delta, idx_u, w_u, idx_v, w_v = best_swap\n                            \n                            # Execute Swap\n                            current_packs[p_heavy][u_i] = (idx_v, w_v)\n                            current_packs[p_light][v_i] = (idx_u, w_u)\n                            pack_weights[p_heavy] -= delta\n                            pack_weights[p_light] += delta\n                            improved = True\n                            break # Break to re-sort\n                    \n                    if improved: break\n                \n                if not improved:\n                    break\n\n            # Check if this restart is best\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    # Run on CPU to avoid kernel launch overhead for sequential operations\n    device = weight.device\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=\"cpu\").repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=\"cpu\")\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=\"cpu\")\n    arangen = torch.arange(n, dtype=torch.int64, device=\"cpu\")\n    \n    # Maintain current scores (load / count)\n    current_scores = weight_cpu.clone()\n\n    for i in range(num_log, num_phy):\n        # Find expert with max current load\n        # Argmax over the num_log dimension\n        redundant_indices = current_scores.argmax(dim=-1)\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores for affected experts\n        # score = weight / new_count\n        selected_weights = weight_cpu[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log.to(device), rank.to(device), logcnt.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "a1e1ec7f-cdca-4da0-b07c-9009e6e7e2b4",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "cc65fbeb-85e1-487a-ab5b-b4b387d4e351"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 98,
      "timestamp": 1764181882.7908542,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,333 +1,410 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n+import random\n+import math\n \n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n \n     Parameters:\n         weight: [X, n], the weight of each item\n         num_packs: number of packs\n \n     Returns:\n         pack_index: [X, n], the pack index of each item\n         rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n+    # Trivial case: 1 item per pack\n     if groups_per_pack == 1:\n-        pack_index = torch.arange(weight.size(-1),\n+        pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n-                                  device=weight.device).expand(weight.shape)\n-        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n+                                  device=weight.device).expand(num_layers, -1)\n+        rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n-    # Optimization: Move weights to CPU and use Python lists for the sequential greedy/swap logic.\n-    # This avoids high kernel launch overheads for sequential scalar operations on GPU.\n+    # Optimization: Move computation to CPU to avoid GPU overhead for sequential logic\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n-    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n-    weight_list = weight_cpu.tolist()\n-\n-    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n-    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n+    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n+    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n+\n+    # Strategy: Multi-start with different initializations + All-Pairs Descent Refinement\n+    # Candidates:\n+    # 0: Deterministic Greedy (LPT)\n+    # 1: ZigZag (Snake) Packing\n+    # 2, 3: Randomized Greedy\n+    num_restarts = 4\n \n     for i in range(num_layers):\n-        row_weight = weight_list[i]\n-        # current_packs stores tuples of (expert_index, weight)\n-        current_packs = [[] for _ in range(num_packs)]\n-        pack_weights = [0.0] * num_packs\n-\n-        # 1. Greedy packing (LPT: Longest Processing Time first)\n-        # Assign heaviest items first to the least loaded pack that has space.\n-        for group in indices[i]:\n-            w = row_weight[group]\n-            best_pack = -1\n-            min_val = float('inf')\n+        row_weight = weight_cpu[i]\n+        \n+        # Create list of (original_index, weight)\n+        items = []\n+        for idx in range(num_groups):\n+            items.append((idx, row_weight[idx].item()))\n+        \n+        # Sort desc for deterministic heuristics\n+        items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n+        \n+        best_diff = float('inf')\n+        best_packs = None\n+        \n+        for attempt in range(num_restarts):\n+            # Initialization\n+            current_packs = [[] for _ in range(num_packs)]\n+            pack_weights = [0.0] * num_packs\n             \n-            # Find the least loaded pack with capacity\n-            for p in range(num_packs):\n-                if len(current_packs[p]) < groups_per_pack:\n-                    if pack_weights[p] < min_val:\n-                        min_val = pack_weights[p]\n-                        best_pack = p\n+            if attempt == 0:\n+                # Deterministic Greedy LPT\n+                for idx, w in items_sorted:\n+                    # Assign to lightest pack with capacity\n+                    best_p = -1\n+                    min_load = float('inf')\n+                    for p in range(num_packs):\n+                        if len(current_packs[p]) < groups_per_pack:\n+                            if pack_weights[p] < min_load:\n+                                min_load = pack_weights[p]\n+                                best_p = p\n+                    current_packs[best_p].append((idx, w))\n+                    pack_weights[best_p] += w\n+                    \n+            elif attempt == 1:\n+                # ZigZag / Snake Packing\n+                # Distributes sorted items: 0->M, M->0, 0->M...\n+                for k, (idx, w) in enumerate(items_sorted):\n+                    cycle_pos = k % (2 * num_packs)\n+                    if cycle_pos < num_packs:\n+                        p = cycle_pos\n+                    else:\n+                        p = (2 * num_packs - 1) - cycle_pos\n+                    current_packs[p].append((idx, w))\n+                    pack_weights[p] += w\n+                    \n+            else:\n+                # Randomized Greedy\n+                # Add noise to weights to perturb sort order\n+                # Use a lightweight pseudo-random approach\n+                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n+                noisy_items = []\n+                for k, (idx, w) in enumerate(items):\n+                    noisy_items.append((idx, w, w * noise[k]))\n+                # Sort by noisy weight\n+                noisy_items.sort(key=lambda x: x[2], reverse=True)\n+                \n+                for idx, w, _ in noisy_items:\n+                    best_p = -1\n+                    min_load = float('inf')\n+                    for p in range(num_packs):\n+                        if len(current_packs[p]) < groups_per_pack:\n+                            if pack_weights[p] < min_load:\n+                                min_load = pack_weights[p]\n+                                best_p = p\n+                    current_packs[best_p].append((idx, w))\n+                    pack_weights[best_p] += w\n+\n+            # Refinement: All-Pairs Descent\n+            # Try to balance every pair of packs, prioritizing the heaviest\n+            for _ in range(20): # Max iterations\n+                # Identify packing order\n+                pack_indices_ordered = sorted(range(num_packs), \n+                                              key=lambda p: pack_weights[p], \n+                                              reverse=True)\n+                \n+                max_w = pack_weights[pack_indices_ordered[0]]\n+                min_w = pack_weights[pack_indices_ordered[-1]]\n+                if (max_w - min_w) < 1e-6:\n+                    break\n+                \n+                improved = False\n+                \n+                # Double loop: Try to move weight from Heavier -> Lighter\n+                # We limit the outer loop to top few heaviest packs to save time\n+                for i_h in range(min(num_packs, 5)):\n+                    p_heavy = pack_indices_ordered[i_h]\n+                    w_heavy = pack_weights[p_heavy]\n+                    \n+                    # Try to swap with lighter packs\n+                    for i_l in range(num_packs - 1, i_h, -1):\n+                        p_light = pack_indices_ordered[i_l]\n+                        w_light = pack_weights[p_light]\n+                        \n+                        diff = w_heavy - w_light\n+                        if diff < 1e-6: continue\n+                        \n+                        target = diff / 2.0\n+                        best_swap = None\n+                        best_gap = diff\n+                        \n+                        # Find swap (u in heavy, v in light)\n+                        ph_items = current_packs[p_heavy]\n+                        pl_items = current_packs[p_light]\n+                        \n+                        for u_i, (idx_u, w_u) in enumerate(ph_items):\n+                            for v_i, (idx_v, w_v) in enumerate(pl_items):\n+                                delta = w_u - w_v\n+                                # Valid swap must reduce heavy pack weight\n+                                if delta > 0 and delta < diff:\n+                                    gap = abs(delta - target)\n+                                    if gap < best_gap:\n+                                        best_gap = gap\n+                                        best_swap = (u_i, v_i, delta, idx_u, w_u, idx_v, w_v)\n+                                        if gap < 1e-5: break\n+                            if best_swap and best_gap < 1e-5: break\n+                        \n+                        if best_swap:\n+                            u_i, v_i, delta, idx_u, w_u, idx_v, w_v = best_swap\n+                            \n+                            # Execute Swap\n+                            current_packs[p_heavy][u_i] = (idx_v, w_v)\n+                            current_packs[p_light][v_i] = (idx_u, w_u)\n+                            pack_weights[p_heavy] -= delta\n+                            pack_weights[p_light] += delta\n+                            improved = True\n+                            break # Break to re-sort\n+                    \n+                    if improved: break\n+                \n+                if not improved:\n+                    break\n+\n+            # Check if this restart is best\n+            curr_max = max(pack_weights)\n+            curr_min = min(pack_weights)\n+            curr_diff = curr_max - curr_min\n             \n-            current_packs[best_pack].append((group, w))\n-            pack_weights[best_pack] += w\n-\n-        # 2. Refinement: Pairwise swapping\n-        # Try to swap items between the heaviest and lightest packs to balance load.\n-        for _ in range(20):\n-            sorted_packs = sorted(range(num_packs),\n-                                  key=pack_weights.__getitem__,\n-                                  reverse=True)\n-            found_improvement = False\n-\n-            for i1 in range(num_packs):\n-                p1 = sorted_packs[i1]\n-                # Compare against lighter packs\n-                for i2 in range(num_packs - 1, i1, -1):\n-                    p2 = sorted_packs[i2]\n-\n-                    diff = pack_weights[p1] - pack_weights[p2]\n-                    if diff < 1e-6:\n-                        break # Since packs are sorted, subsequent diffs will be smaller\n-\n-                    target = diff / 2.0\n-                    best_swap = None\n-                    best_gap = diff\n-\n-                    # Find best swap: u from p1, v from p2 such that w_u - w_v approx target\n-                    for idx_u, (u, w_u) in enumerate(current_packs[p1]):\n-                        for idx_v, (v, w_v) in enumerate(current_packs[p2]):\n-                            delta = w_u - w_v\n-                            # We need w_u > w_v to reduce diff\n-                            if 0 < delta < diff:\n-                                gap = abs(delta - target)\n-                                if gap < best_gap:\n-                                    best_gap = gap\n-                                    # Store swap details: indices and the actual values to swap\n-                                    best_swap = (idx_u, idx_v, delta, v, w_v, u, w_u)\n-                                    if gap < 1e-5: break\n-                        if best_swap and best_gap < 1e-5: break\n-\n-                    if best_swap:\n-                        idx_u, idx_v, delta, val_v, weight_v, val_u, weight_u = best_swap\n-                        \n-                        # Apply swap\n-                        current_packs[p1][idx_u] = (val_v, weight_v)\n-                        current_packs[p2][idx_v] = (val_u, weight_u)\n-                        pack_weights[p1] -= delta\n-                        pack_weights[p2] += delta\n-                        found_improvement = True\n-                        break # Break inner loop to re-sort packs\n-                \n-                if found_improvement: break\n-            \n-            if not found_improvement:\n-                break\n-\n-        # 3. Fill result tensors\n+            if curr_diff < best_diff:\n+                best_diff = curr_diff\n+                best_packs = [list(p) for p in current_packs] # Deep copy\n+                if best_diff < 1e-6:\n+                    break\n+        \n+        # Fill result tensors\n         for p in range(num_packs):\n-            for r, (g, _) in enumerate(current_packs[p]):\n-                pack_index[i, g] = p\n-                rank_in_pack[i, g] = r\n+            for r, (idx, _) in enumerate(best_packs[p]):\n+                pack_index[i, idx] = p\n+                rank_in_pack[i, idx] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n \n     Parameters:\n         weight: [X, num_log]\n         num_phy: total number of experts after replication\n \n     Returns:\n         phy2log: [X, num_phy], logical expert id of each physical expert\n         rank: [X, num_phy], the replica rank\n         logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n+    # Run on CPU to avoid kernel launch overhead for sequential operations\n+    device = weight.device\n+    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n+    \n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n-    device = weight.device\n+\n+    phy2log = torch.arange(num_phy, dtype=torch.int64,\n+                           device=\"cpu\").repeat(n, 1)\n+    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=\"cpu\")\n+    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=\"cpu\")\n+    arangen = torch.arange(n, dtype=torch.int64, device=\"cpu\")\n     \n-    phy2log = torch.arange(num_phy, dtype=torch.int64,\n-                           device=device).repeat(n, 1)\n-    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n-    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n-    arangen = torch.arange(n, dtype=torch.int64, device=device)\n-    \n-    # Optimization: Track current scores (load/count) to avoid full matrix recalculation\n-    current_scores = weight.clone()\n-    \n+    # Maintain current scores (load / count)\n+    current_scores = weight_cpu.clone()\n+\n     for i in range(num_log, num_phy):\n-        # Pick the expert with the max current load per replica\n-        redundant_indices = current_scores.max(dim=-1).indices\n+        # Find expert with max current load\n+        # Argmax over the num_log dimension\n+        redundant_indices = current_scores.argmax(dim=-1)\n         \n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n         \n-        # Increment count\n+        # Update counts\n         logcnt[arangen, redundant_indices] += 1\n         \n-        # Update scores only for the experts that got a new replica\n-        # score = weight / count\n-        # We use advanced indexing to update only the modified positions\n-        updated_weights = weight[arangen, redundant_indices]\n-        updated_counts = logcnt[arangen, redundant_indices].float()\n-        current_scores[arangen, redundant_indices] = updated_weights / updated_counts\n-        \n-    return phy2log, rank, logcnt\n+        # Update scores for affected experts\n+        # score = weight / new_count\n+        selected_weights = weight_cpu[arangen, redundant_indices]\n+        selected_counts = logcnt[arangen, redundant_indices].float()\n+        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n+\n+    return phy2log.to(device), rank.to(device), logcnt.to(device)\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Parameters:\n         weight: [num_moe_layers, num_logical_experts]\n         num_physical_experts: number of physical experts after replication\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n         (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [num_moe_layers, num_physical_experts]\n         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n         logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n \n     Parameters:\n         weight: [layers, num_logical_experts], the load statistics for all\n             logical experts\n         num_replicas: number of physical experts, must be a multiple of\n             `num_gpus`\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n             (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [layers, num_replicas], the expert index of\n             each replica\n         logical_to_physical_map: [layers, num_logical_experts, X], the replica\n             indices for each expert\n         expert_count: [layers, num_logical_experts], number of physical\n             replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n \n \n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385917818743,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.3110771835637488,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.0533328,
        0.02105726,
        0.013792965,
        -0.040436376,
        -0.025953762,
        0.017712466,
        -0.008609109,
        -0.008074631,
        -0.02531009,
        0.027907765,
        0.03170083,
        0.020861859,
        -0.01033323,
        -0.022896321,
        0.014080319,
        0.01672397,
        -0.011091842,
        0.015402144,
        -0.0054453476,
        0.052964985,
        0.006620623,
        -0.0093504805,
        0.026942257,
        -0.04091913,
        -0.0043476573,
        0.010160818,
        0.06170053,
        -0.042689227,
        0.03144796,
        -0.048459284,
        0.07820611,
        -0.0109539125,
        0.014574566,
        0.0013369118,
        -0.01544812,
        0.03225255,
        -0.007051653,
        0.010120587,
        0.014298706,
        0.062114317,
        0.026597433,
        -0.023815852,
        -0.046160456,
        0.041080046,
        -0.037493877,
        0.033930693,
        0.006540164,
        -0.00795969,
        0.07793025,
        0.0050200643,
        0.0374479,
        0.015206744,
        -0.001826131,
        0.0658844,
        0.026229622,
        0.041723717,
        0.022367591,
        0.021551507,
        0.018850384,
        -0.04425243,
        0.052827056,
        -0.015126284,
        0.07172342,
        0.040436376,
        -0.03009165,
        0.0052413265,
        -0.035287,
        0.027470987,
        0.020965306,
        -0.010833224,
        -0.040689245,
        0.045654714,
        -0.022080237,
        -0.026735364,
        0.0016522822,
        0.008109114,
        -0.021045765,
        0.043447837,
        -0.030183604,
        -0.043217957,
        -0.028873272,
        -0.0074826833,
        0.05209143,
        0.020183705,
        0.013218258,
        -0.07452799,
        -0.021413578,
        -0.0386203,
        -0.034436435,
        -0.023631947,
        0.035447918,
        -0.046827115,
        0.0008275779,
        0.033264033,
        0.040298447,
        -0.032206573,
        0.061884437,
        0.014930884,
        0.03289622,
        0.057654593,
        -0.01278148,
        0.014896402,
        -0.05622932,
        0.001095535,
        0.027999718,
        0.010758513,
        0.002739915,
        -0.0024324467,
        0.012942399,
        -0.016792934,
        -0.040712234,
        0.01872395,
        0.03370081,
        0.009430939,
        0.015379156,
        0.006873494,
        -0.04186165,
        -0.021551507,
        0.009729787,
        -0.025792845,
        -0.027103176,
        -0.036528368,
        0.024758372,
        -0.027999718,
        0.009706799,
        -0.03742491,
        0.008080378,
        -0.032574385,
        0.009051633,
        0.0009899326,
        0.044689205,
        0.024689406,
        0.008034402,
        -0.02111473,
        -0.022413569,
        0.0036436415,
        -0.021850355,
        0.0066723465,
        -0.0055344272,
        -0.017884878,
        -0.024689406,
        0.030666359,
        -0.011695284,
        -0.007632107,
        -0.049470767,
        0.052689124,
        -0.0021005536,
        0.015218237,
        -0.0382295,
        0.03011464,
        0.016643511,
        -0.037103076,
        -0.012402174,
        -0.011212531,
        0.0014899275,
        -0.010373459,
        0.00752866,
        0.02131013,
        0.08284974,
        -0.033103116,
        -0.02903419,
        0.02944798,
        -0.025815831,
        0.022804368,
        0.033884715,
        0.028758332,
        -0.051401783,
        0.0031896231,
        -0.05839022,
        -0.060275257,
        -0.005732701,
        -0.021241166,
        -0.0050344323,
        -0.0164711,
        0.0029453726,
        0.014666519,
        -0.023356088,
        -0.03583872,
        -0.026735364,
        -0.039746728,
        -0.022608967,
        -0.012655045,
        -0.01605731,
        -0.0076550953,
        -0.0482294,
        0.026459504,
        -0.030804288,
        -0.013321705,
        -0.011718273,
        -0.0065056817,
        0.013838941,
        0.045057017,
        -0.036206532,
        0.033241045,
        0.00013801944,
        -0.019953823,
        0.05475807,
        0.017264195,
        0.0049137436,
        -0.005307418,
        -0.039539833,
        -0.011907926,
        0.04036741,
        -0.038252488,
        0.045355864,
        0.03475827,
        -0.011022878,
        0.010367712,
        0.010827477,
        -0.0048792614,
        0.032091632,
        -0.024275618,
        0.037792724,
        -0.0038103065,
        -0.027425012,
        -0.03011464,
        -0.05232131,
        0.016482593,
        0.003183876,
        0.06832115,
        -0.020344622,
        0.017988324,
        -0.023907805,
        0.004497081,
        -0.040574305,
        0.020091752,
        0.049056977,
        -0.016988335,
        0.005540174,
        0.0063217757,
        -0.029700851,
        -0.00092958834,
        -0.01205735,
        -0.028229602,
        0.03227554,
        -0.030827276,
        -0.033195067,
        0.019563021,
        -0.016344663,
        -0.034183566,
        0.01905728,
        0.042942096,
        0.010293,
        -0.044965066,
        0.009609099,
        0.01791936,
        -0.04142487,
        -0.015884899,
        0.006459705,
        -0.02439056,
        0.02103427,
        -0.04487311,
        0.024942277,
        -0.058849983,
        -0.013459635,
        0.030827276,
        -0.021413578,
        -0.053378772,
        -0.017356148,
        -0.031057158,
        0.016080298,
        -0.017195228,
        -0.003344794,
        -0.022907816,
        -0.019723939,
        -0.00055890245,
        -0.0031551407,
        0.037103076,
        -0.047309868,
        -0.020930825,
        0.030689346,
        0.015517085,
        -0.015597545,
        0.03742491,
        -0.041723717,
        -0.018907856,
        0.003474103,
        -0.016953852,
        -0.031792782,
        -0.04199958,
        -0.024436535,
        0.0016321675,
        0.03917202,
        -0.0008793015,
        0.0133332,
        -0.0029999698,
        -0.0045890342,
        0.028735343,
        0.008988415,
        -0.023769876,
        0.0050574206,
        -0.021068754,
        0.03878122,
        0.013988365,
        -0.0110401185,
        -0.020896342,
        -0.056505177,
        -0.015183755,
        -0.0014999849,
        -0.0071378592,
        0.008735544,
        -0.0046493784,
        -0.008701062,
        0.006545911,
        -0.0097240405,
        -0.024551477,
        -0.015988344,
        0.017436607,
        -0.016229723,
        -0.022528509,
        -0.012367692,
        0.011132072,
        -0.018425101,
        -0.00071515085,
        -0.028712355,
        0.0022327362,
        0.032551397,
        0.0026249737,
        -0.015781451,
        -0.05434428,
        -0.05383854,
        -0.04197659,
        0.0415628,
        0.023631947,
        0.0002841207,
        0.023677923,
        -0.043976568,
        0.016827418,
        -0.008068885,
        -0.015275708,
        0.006367752,
        0.04025247,
        0.031333018,
        0.024275618,
        0.011597585,
        -0.04252831,
        0.033746786,
        -0.0029511198,
        0.04303405,
        0.019344633,
        -0.058712054,
        0.024873313,
        -0.012149303,
        -0.023539994,
        -0.047769636,
        0.018953832,
        0.057608616,
        0.028436495,
        0.025769856,
        0.07558545,
        -0.037493877,
        -0.018126255,
        -0.015080309,
        0.016206734,
        0.013999859,
        -0.02503423,
        0.0012693838,
        0.0037499622,
        -0.044712193,
        0.0053102914,
        -0.027815811,
        -0.0056436216,
        0.028528448,
        -0.0042240955,
        -0.009028645,
        0.064826936,
        0.029011203,
        0.014746978,
        0.008953933,
        0.009172321,
        0.041516826,
        -0.0037700771,
        -0.026160656,
        0.010212541,
        -0.010632077,
        -0.016275698,
        0.023160687,
        0.05383854,
        -0.028965225,
        0.0036292737,
        0.024689406,
        0.019792905,
        -0.021390589,
        0.010201047,
        0.018413607,
        0.035930675,
        -0.011574596,
        0.017827407,
        -0.072551,
        0.0094654225,
        0.05112592,
        -0.013252741,
        -0.02050554,
        -0.045470808,
        0.035470907,
        -0.012114821,
        -0.03797663,
        -0.025723878,
        0.045355864,
        0.010126335,
        -0.010913683,
        0.005511439,
        -0.03981569,
        -0.017654995,
        -0.025953762,
        0.013620553,
        0.047309868,
        0.01819522,
        -0.005011444,
        0.043953583,
        0.02797673,
        -0.03344794,
        0.01205735,
        0.005350521,
        0.012597575,
        -0.0362755,
        0.004295934,
        0.0403904,
        0.0033275527,
        -0.010103347,
        -0.007994172,
        -0.009557375,
        0.019068774,
        -0.004330416,
        -0.017425112,
        0.016563052,
        0.015344673,
        -0.015873404,
        0.011850456,
        -0.062298223,
        -0.012034362,
        0.0048045493,
        0.06432119,
        -0.030068664,
        0.022482533,
        0.03756284,
        -0.005157994,
        0.027057199,
        -0.003060314,
        -0.004505702,
        0.008603361,
        -0.014517095,
        -0.012459645,
        -0.020494048,
        0.022413569,
        -0.012379186,
        0.0054281065,
        -0.0511719,
        0.050022487,
        -0.0075401543,
        0.013735494,
        -0.017356148,
        0.05209143,
        0.0033591616,
        -0.022022767,
        -0.054712094,
        0.07402224,
        0.03395368,
        0.04997651,
        -0.024091711,
        0.04050534,
        0.015459615,
        0.0018922223,
        -0.028160637,
        0.054298304,
        0.015746968,
        0.008373479,
        -0.0023318732,
        0.009344733,
        0.027218116,
        0.06114881,
        -0.04689608,
        -0.0037873182,
        0.039539833,
        -0.028735343,
        0.011132072,
        -0.015103296,
        0.06620623,
        0.030597394,
        -0.04717194,
        0.028505461,
        -0.04639034,
        -0.030413488,
        -0.039769717,
        0.027356047,
        0.028758332,
        0.034390457,
        0.0025301469,
        0.0013017111,
        0.028160637,
        0.029126143,
        -0.016011333,
        0.011235519,
        -0.009948175,
        7.90222e-05,
        -0.0055344272,
        -0.014792955,
        -0.027287083,
        0.0034511148,
        0.04891905,
        0.0089481855,
        -0.084688805,
        -0.060505137,
        -0.021654954,
        0.016827418,
        -0.03503413,
        -0.030505441,
        0.00029058615,
        -0.005264315,
        0.039126042,
        -0.018563032,
        -0.008557385,
        0.026482493,
        0.02903419,
        -0.0074079717,
        0.03636745,
        -0.006126375,
        0.009798752,
        0.008224055,
        0.030827276,
        -0.030298546,
        -0.02111473,
        -0.05006846,
        0.025149172,
        0.03181577,
        -0.03455138,
        -0.015229732,
        -0.054252326,
        0.014034342,
        -0.005571783,
        -0.015838921,
        -0.014379166,
        -0.052413266,
        0.02917212,
        -0.019080268,
        0.028988214,
        -0.0011451035,
        -0.041723717,
        -0.030781299,
        -0.03875823,
        0.005907987,
        0.014126294,
        0.019195208,
        0.020942317,
        0.011132072,
        -0.038712256,
        0.0703901,
        0.027792824,
        0.029080167,
        0.025677903,
        0.009126345,
        -0.04478116,
        0.0017672236,
        -0.003930995,
        -0.029379016,
        -0.01991934,
        -0.01378147,
        -0.045769654,
        0.028160637,
        0.048551235,
        0.021723919,
        -0.004255704,
        0.010212541,
        -0.0002796308,
        0.00064474926,
        0.010045876,
        0.023137698,
        -0.041378893,
        0.01572398,
        0.0039281216,
        -0.010597595,
        0.012287233,
        0.0095803635,
        -0.060964905,
        0.024689406,
        -0.004212601,
        0.019011304,
        -0.02503423,
        -0.004307428,
        -0.009315998,
        -0.028298566,
        -0.023103217,
        -0.014425143,
        -0.026758352,
        -0.056689084,
        -0.0077470485,
        -0.030942218,
        -0.012413668,
        -0.0035861707,
        -0.027425012,
        -0.00509765,
        -0.0006957545,
        0.0356778,
        -0.015988344,
        0.015229732,
        -0.005109144,
        -0.03811456,
        0.0110113835,
        0.026827317,
        0.008218308,
        -0.016126275,
        0.062436152,
        0.0034252529,
        0.02091933,
        -0.027264094,
        0.002307448,
        0.0075401543,
        0.0069999294,
        0.0034683559,
        -0.032850243,
        -0.009712546,
        -0.016436616,
        -0.031378996,
        -0.007511419,
        -0.008022908,
        0.004416622,
        0.05609139,
        0.004393634,
        0.012218268,
        -0.019137738,
        -0.009011404,
        0.042873133,
        0.013551588,
        -0.016517075,
        -0.00048347216,
        -0.009999899,
        -0.011907926,
        -0.0025588823,
        -0.027631907,
        0.015746968,
        -0.037884675,
        -0.015850415,
        -0.021264154,
        0.02758593,
        -0.0016235469,
        0.06717174,
        0.02319517,
        0.035907686,
        0.00772406,
        -0.013045846,
        0.02758593,
        -0.006287293,
        0.013068834,
        -0.040160514,
        0.01291941,
        0.022275638,
        -0.003393644,
        -0.005761436,
        0.0071665947,
        -0.011074602,
        -0.002739915,
        -0.017160747,
        0.03383874,
        0.036666296,
        0.030482452,
        -0.017677983,
        -0.011166554,
        -0.033401962,
        -0.028574426,
        0.0007198203,
        -0.036551356,
        -0.009471169,
        -0.0110401185,
        -0.023126204,
        0.015241226,
        0.026436515,
        0.021700932,
        0.002844799,
        0.005166615,
        0.049792603,
        -0.006540164,
        0.02956292,
        0.024252629,
        -0.044712193,
        -0.037930652,
        -0.018597513,
        -0.027861789,
        0.013172281,
        0.0017700972,
        0.018321656,
        0.010315988,
        -0.01958601,
        -0.031424973,
        -0.0077642896,
        -0.010183806,
        0.026298586,
        0.021344613,
        -0.0027241106,
        0.03558585,
        -0.018563032,
        0.015965357,
        -0.012436656,
        -0.037677784,
        -0.015804438,
        0.017103277,
        0.04358577,
        0.008580374,
        0.010287253,
        -0.01872395,
        -0.043746687,
        -0.01125276,
        -0.0004676677,
        -0.027539954,
        -0.01152862,
        -0.040988095,
        -0.018804409,
        -0.044390358,
        0.04650528,
        0.02244805,
        -0.0013994112,
        -0.04009155,
        0.0036580092,
        -0.02250552,
        -0.019022796,
        -0.06868897,
        0.0041493834,
        -0.0026996855,
        0.012045856,
        0.026091691,
        -0.04211452,
        -0.007873484,
        0.0027011223,
        -0.038574323,
        0.0013656472,
        0.048459284,
        0.016700981,
        0.014815943,
        0.0039511095,
        0.0057298276,
        -0.0027111797,
        0.010752765,
        -0.016149262,
        0.018528549,
        -0.03383874,
        0.040459365,
        -0.008465433,
        -0.0005423796,
        -0.03356288,
        -0.024850326,
        0.012137809,
        -0.0078332545,
        -0.023402063,
        0.013448141,
        -0.0050258115,
        0.009925188,
        0.0038562831,
        -0.0033850234,
        0.034321494,
        -0.015011343,
        0.022344602,
        -0.033792764,
        0.006448211,
        -0.026873292,
        -0.0023002643,
        0.042804167,
        0.032850243,
        0.014298706,
        -0.0068332646,
        -0.005304544,
        0.01025277,
        -0.017758442,
        -0.017218217,
        -0.021815872,
        0.017804418,
        0.0140458355,
        0.0052585676,
        -0.047861587,
        -0.0040258216,
        0.0110401185,
        -0.041194987,
        -0.024298606,
        -0.008660832,
        0.047217917,
        0.049011,
        0.02639054,
        -0.03956282,
        0.013746988,
        -0.052275337,
        0.006942459,
        -0.021287141,
        -0.015953863,
        -0.022471039,
        -0.03250542,
        0.0023606084,
        0.0028146268,
        0.004373519,
        -0.058436193,
        -0.022551497,
        -0.011695284,
        -0.011735514,
        -0.060826976,
        -0.014655025,
        0.0009410825,
        -0.021540014,
        -0.01219528,
        0.016517075,
        -0.036620323,
        -0.051217876,
        0.009149333,
        0.017321665,
        -0.0051809824,
        0.0027729606,
        0.022149203,
        -0.0017715339,
        -0.011976891,
        -0.009902199,
        -0.05636725,
        0.0053332797,
        -0.040597294,
        0.017103277,
        0.018965326,
        0.00080818153,
        -0.03386173,
        0.005560289,
        0.06445912,
        -0.024206653,
        -0.045217935,
        -0.044827137,
        0.03009165,
        -0.010425182,
        -0.026827317,
        -0.048045494,
        0.04379266,
        0.009907946,
        -0.047861587,
        -0.013724,
        -0.013068834,
        0.0029482462,
        0.011287243,
        -0.01544812,
        0.002127852,
        -0.022195179,
        0.0071665947,
        0.010930925,
        0.0044942074,
        0.01191942,
        0.0047183433,
        -0.0067298175,
        -0.0063102813,
        0.025769856,
        0.03289622,
        0.008367732,
        0.0006314592,
        -0.025539974,
        0.017563041,
        0.011471149,
        0.038988113,
        0.038275477,
        -0.025356067,
        -0.015678003,
        -0.017195228,
        0.012126314,
        0.026873292,
        -0.012022868,
        -0.0064654523,
        0.018045796,
        0.016206734,
        -0.006540164,
        0.014068824,
        -0.007930955,
        -0.017172242,
        -0.041103035,
        0.011683791,
        -0.029356027,
        0.0068964823,
        -0.024597453,
        0.027677882,
        0.034436435,
        -0.0035804238,
        -0.0013663656,
        0.011281496,
        -0.03036751,
        0.019965317,
        0.020126235,
        -0.012609068,
        -0.017769936,
        -0.015494097,
        0.016275698,
        -0.042781178,
        -0.012563092,
        -0.0015933748,
        -0.016804429,
        -0.014344683,
        0.007103377,
        -0.0036637562,
        0.020356117,
        0.005218338,
        -0.0031465201,
        0.033126105,
        0.024160676,
        -0.0013929458,
        0.006080399,
        0.015482603,
        0.01805729,
        0.029608898,
        0.028505461,
        -0.008045896,
        -0.002462619,
        0.0278388,
        -0.0040085805,
        -0.010126335,
        0.0033821499,
        -0.015838921,
        0.047355846,
        -0.017896371,
        -0.012103327,
        -0.0065516583,
        0.011683791,
        0.030160617,
        -0.05232131,
        0.07209123,
        -0.010442424,
        -0.032666337,
        -0.010413689,
        0.0063964874,
        -0.025884798,
        0.013701011,
        0.025861809,
        0.009649328,
        -0.0011565975,
        0.027861789,
        -0.022091731,
        0.0044396105,
        0.011930915,
        0.009775763,
        -0.0021077374,
        0.009706799,
        -0.03799962,
        0.0533328,
        -0.013965377,
        0.013873423,
        -0.022022767,
        0.023298616,
        -0.0021767023,
        0.005157994,
        -0.0091780685,
        -0.013999859,
        -0.007511419,
        -0.015264214,
        0.005157994,
        -0.051723618,
        -0.009229792,
        -0.0025344572,
        0.017712466,
        -0.03211462,
        -0.033884715,
        -0.003844789,
        -0.012574586,
        -0.014402154,
        -0.01791936,
        0.03236749,
        -0.05006846,
        0.054298304,
        0.003226979,
        -0.032459445,
        0.034482412,
        0.006609129,
        -0.0003990621,
        0.0024726763,
        0.020321636,
        0.041080046,
        -0.003548815,
        -0.02356298,
        0.004807423,
        0.013080328,
        0.0090056565,
        0.0041378895,
        -0.004709723,
        -0.04675815,
        0.011769997,
        0.034298506,
        -0.021413578,
        0.02164346,
        -0.0050689145,
        0.011074602,
        -0.04542483,
        0.007787278,
        -0.012907916,
        0.056183342,
        -0.014298706,
        0.017091783,
        0.0048533995,
        -0.041194987,
        0.030068664,
        0.054574165,
        -0.0053217853,
        0.04636735,
        0.002844799,
        0.006793035,
        -0.025677903,
        0.057056896,
        0.029011203,
        0.009706799,
        -0.0060574105,
        0.009838982,
        0.012609068,
        -0.013701011,
        -0.018712455,
        -0.022229662,
        -0.00552868,
        -0.03519505,
        0.0096665695,
        0.027930753,
        -0.0041005337,
        0.009942429,
        0.00438214,
        0.019930834,
        -0.01736764,
        0.005545921,
        0.0054827034,
        0.02756294,
        -0.037218016,
        -0.017804418,
        0.014494107,
        -0.039401904,
        -0.009603351,
        -0.032735303,
        0.010999889,
        -0.027792824,
        -0.008396467,
        -0.0068275174,
        -0.044275418,
        0.0027887651,
        -0.012769987,
        -0.014436636,
        0.010281506,
        0.022861838,
        -0.044183463,
        0.021080248,
        -0.020091752,
        0.027356047,
        -0.005864884,
        -0.029516945,
        0.019574516,
        -0.013494117,
        -0.04011454,
        -0.004109154,
        0.02678134,
        0.022907816,
        0.0019281416,
        -0.025976751,
        0.03174681,
        -0.026896281,
        0.017022816,
        0.029011203,
        -0.0066378643,
        -0.005976951,
        0.012448151,
        -0.015678003,
        -0.010655065,
        -0.0578385,
        -0.004152257,
        -0.010132082,
        0.029149132,
        0.025815831,
        0.0201952,
        -0.0008311698,
        0.0028979594,
        -0.0038160535,
        -0.008166584,
        0.021471048,
        0.0056436216,
        -0.043470826,
        -0.018080277,
        0.010913683,
        0.011637814,
        -0.026965246,
        -0.019333139,
        -0.0003633225,
        0.00039439258,
        0.0010402194,
        0.0072413064,
        -0.014172271,
        0.021367602,
        0.008942439,
        -0.005005697,
        0.0055516683,
        0.01931015,
        -0.009011404,
        -0.049011,
        -0.006442464,
        0.0022327362,
        0.0027126165,
        -0.0048447787,
        -0.014930884,
        0.04248233,
        0.03928696,
        0.0020646343,
        0.015930874,
        -0.02491929,
        -0.003436747,
        0.022689426,
        0.027241105,
        -0.009942429,
        0.014574566,
        -0.02183886,
        0.01891935,
        0.017356148,
        -0.02250552,
        0.0114136785,
        0.0023577348,
        0.0033591616,
        -0.0045890342,
        -0.010218288,
        -0.027654894,
        -0.044160474,
        -0.011206784,
        -0.010798742,
        0.027356047,
        -0.010453918,
        0.028827297,
        -0.01591938,
        0.021965297,
        0.029356027,
        -0.004893629,
        -0.023206662,
        0.002597675,
        -0.0064884406,
        0.020034282,
        0.021494037,
        -0.023976771,
        0.0023088849,
        -0.02797673,
        0.035654813,
        -0.03183876,
        -0.0051608677,
        0.008965427,
        0.023999758,
        0.017999819,
        -0.00447984,
        0.028459484,
        -0.05995342,
        0.03517206,
        0.022482533,
        -0.009109104,
        -0.020563012,
        -0.032160595,
        0.008149344,
        -0.0059194807,
        0.035287,
        4.7772508e-05,
        -0.018333148,
        0.042137507,
        0.016712476,
        -0.001462629,
        -0.0038246743,
        0.006953953,
        0.07190732,
        0.0050488,
        -0.0033419204,
        0.00909761,
        0.012425163,
        0.026942257,
        -0.02131013,
        -0.0060574105,
        0.018264184,
        -0.042804167,
        -0.029930733,
        0.031333018,
        -0.00567523,
        -0.020769905,
        -0.0053792563,
        0.01736764,
        -0.0415628,
        0.01564352,
        -0.019275669,
        0.014287213,
        -0.0063964874,
        -0.0005994911,
        -0.0052499473,
        -0.01986187,
        0.00088073825,
        -0.03211462,
        0.0033965176,
        -0.021563001,
        -0.017172242,
        0.021517025,
        -0.024045736,
        -0.027241105,
        0.00829302,
        0.0067585525,
        -0.015402144,
        0.015678003,
        0.021953803,
        0.0046177697,
        -0.0015402144,
        0.008224055,
        -0.016953852,
        -0.0037614563,
        -0.03091923,
        -0.01558605,
        -0.020436576,
        -0.008281526,
        -0.020126235,
        0.017965337,
        0.006166605,
        0.0044769663,
        0.0077815307,
        -0.013735494,
        0.00409766,
        -0.0241147,
        -0.024321595,
        0.0028232476,
        0.034160577,
        0.06179248,
        -0.040459365,
        0.010361965,
        -0.006614876,
        -0.004209728,
        -0.0057901717,
        0.029264074,
        0.016769946,
        -0.01711477,
        -0.014735484,
        -0.023792865,
        -0.013528599,
        0.029677862,
        -0.02691927,
        -0.0015359041,
        -0.00586201,
        -0.02164346,
        0.02972384,
        -0.0052154646,
        -0.012448151,
        0.02466642,
        0.018080277,
        -0.03462034,
        -0.012091832,
        0.00809762,
        -0.0008965427,
        0.012068844,
        -0.029424991,
        -0.027999718,
        0.03264335,
        0.023091722,
        -0.027539954,
        0.002863477,
        -0.0044769663,
        0.021850355,
        0.027126163,
        0.04087315,
        -0.019597504,
        -0.012367692,
        -0.0058361483,
        -0.007448201,
        -0.013045846,
        0.02491929,
        -0.0124711385,
        0.012884928,
        0.013666529,
        0.01978141,
        -0.025011243,
        0.037241004,
        -0.0035804238,
        -0.0077815307,
        -0.042689227,
        -0.050206393,
        0.037195027,
        -0.0033333,
        0.027700871,
        -0.039539833,
        -0.038183525,
        0.037884675,
        0.040850163,
        0.03625251,
        -0.01678144,
        -0.016413627,
        0.02180438,
        -0.011804479,
        0.0074884305,
        0.006166605,
        -0.034137588,
        0.028988214,
        0.005252821,
        0.036068603,
        -0.021758402,
        0.012022868,
        0.0058447686,
        -0.013011363,
        0.028436495,
        -0.015402144,
        0.036137566,
        0.0006253529,
        0.0031264054,
        -0.037493877,
        -0.015965357,
        0.03809157,
        -0.038735244,
        0.011792985,
        0.008591868,
        0.030321535,
        -0.040459365,
        0.0001923472,
        0.020942317,
        -0.015689498,
        0.03701112,
        -0.021930814,
        0.023264134,
        -0.025976751,
        -0.019654974,
        -0.041493837,
        0.017494077,
        -0.016965346,
        -0.0033160585,
        0.011850456,
        0.009315998,
        6.1174853e-07,
        -0.017896371,
        -0.023815852,
        -0.0166665,
        0.017965337,
        0.015609038,
        0.012666539,
        -0.023631947,
        0.007051653,
        0.02864339,
        0.017769936,
        0.0124711385,
        0.0075401543,
        0.019160727,
        -0.020264164,
        -0.009568869,
        -0.006218328,
        0.009603351,
        -0.0062470636,
        0.0025129057,
        0.01825269,
        -0.020413587,
        0.020746918,
        0.026620422,
        0.00024209527,
        0.029631887,
        -0.057010923,
        0.00058799697,
        0.0040344424,
        0.028482473,
        0.007999919,
        0.033654835,
        0.00026562234,
        0.021942308,
        -0.011804479,
        0.04262026,
        0.032988176,
        -0.016907876,
        0.0048102965,
        -0.010884948,
        0.021540014,
        0.02944798,
        0.016517075,
        -0.013804459,
        -0.030804288,
        -0.011988386,
        0.024597453,
        0.00032201543,
        0.017264195,
        0.020838872,
        -0.054712094,
        0.0022442304,
        -0.007775784,
        0.0002659815,
        0.026873292,
        0.014965367,
        0.0011616262,
        -0.015528579,
        0.0034022646,
        0.010229782,
        -0.008574626,
        0.009614846,
        0.017930854,
        0.025218137,
        -0.015218237,
        0.016746959,
        -0.013620553,
        -0.012540104,
        -0.0069826883,
        -0.022287132,
        0.019574516,
        0.03395368,
        -0.0025258367,
        0.030321535,
        -0.008793015,
        0.010281506,
        0.0110975895,
        -0.0031177846,
        0.0028491092,
        0.04370071,
        -0.025953762,
        -0.00083835365,
        0.024344582,
        0.02717214,
        -0.003818927,
        -0.038988113,
        -0.008637845,
        -0.005091903,
        0.006534417,
        -0.017873384,
        -0.0030459464,
        -0.015080309,
        0.01758603,
        -0.011505632,
        -0.004824664,
        -0.013482623,
        0.014367672,
        0.027539954,
        -0.025287103,
        0.014689508,
        0.014321695,
        0.026528468,
        0.029746827,
        -0.025149172,
        -0.008718303,
        0.019517045,
        0.02717214,
        -0.010792995,
        0.017091783,
        -0.0040085805,
        -0.034321494,
        -0.0046378844,
        0.010155071,
        0.029149132,
        0.00866658,
        -0.008143596,
        0.0070861354,
        -0.029493956,
        -0.00078160135,
        0.015850415,
        -0.04048235,
        0.017448101,
        0.0007187428,
        -0.005123512,
        0.0127010215,
        0.008810257,
        0.009614846,
        -0.014769967,
        0.017769936,
        0.008103367,
        -0.009752776,
        0.045102995,
        -0.025103197,
        0.008373479,
        -0.024965266,
        -0.00825279,
        -0.040827174,
        -0.016838912,
        -0.025287103,
        0.012172291,
        0.008183826,
        -0.012436656,
        -0.005091903,
        0.011005636,
        -0.022459544,
        0.009683811,
        -0.006867747,
        0.009022898,
        0.029746827,
        0.0010833225,
        -0.00038972308,
        -0.005002823,
        -0.028827297,
        -0.014356177,
        -0.021953803,
        0.019172221,
        -0.00019737589,
        0.016229723,
        -0.024298606,
        -0.01219528,
        0.0036235268,
        0.008218308,
        -0.018229702,
        0.0067298175,
        0.014758472,
        0.0041378895,
        0.016482593,
        0.0090343915,
        0.008758533,
        0.01005737,
        -0.024298606,
        -0.0060918927,
        -0.01905728,
        0.021413578,
        0.0071551003,
        -0.010045876,
        0.0064884406,
        0.020103246,
        0.02319517,
        0.030160617,
        -0.0054740827,
        -0.0064022345,
        0.011143566,
        -0.037218016,
        -0.030252568,
        -0.017356148,
        -0.018149244,
        0.027631907,
        -0.0022686555,
        0.01613777,
        0.03119509,
        0.024873313,
        0.045746665,
        -0.03836743,
        -0.011218278,
        0.04478116,
        -0.0020014166,
        -0.026850305,
        -0.0058275275,
        -0.013643541,
        0.012126314,
        -0.022264143,
        0.03197669,
        0.027126163,
        -0.013413658,
        0.0021005536,
        -0.033333,
        -0.008413709,
        -0.017746948,
        0.008781521,
        -0.016218228,
        0.020149224,
        0.0031149113,
        0.0036378945,
        0.03174681,
        0.006034422,
        0.005109144,
        -0.005502818,
        -0.0016436616,
        -0.0072240653,
        0.0022801494,
        -0.00709763,
        -0.005218338,
        -0.009632087,
        -0.02931005,
        0.030022686,
        0.0072355596,
        -0.00045222248,
        -0.003307438,
        0.017022816
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 151.6157751083374,
        "patch_type": "full",
        "api_costs": 0.390104,
        "num_applied": 1,
        "patch_name": "eplb_hybrid_descent",
        "patch_description": "This algorithm improves load balancing by employing a hybrid multi-start strategy (LPT Greedy, ZigZag, and Randomized LPT) combined with an aggressive all-pairs descent refinement. The computation is moved to the CPU to eliminate GPU kernel launch overheads for sequential scalar operations. The refinement phase iterates through sorted packs to perform beneficial swaps that reduce the load variance, effectively minimizing the makespan.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 2,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\neplb_hybrid_descent\n</NAME>\n\n<DESCRIPTION>\nThis algorithm improves load balancing by employing a hybrid multi-start strategy (LPT Greedy, ZigZag, and Randomized LPT) combined with an aggressive all-pairs descent refinement. The computation is moved to the CPU to eliminate GPU kernel launch overheads for sequential scalar operations. The refinement phase iterates through sorted packs to perform beneficial swaps that reduce the load variance, effectively minimizing the makespan.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Trivial case: 1 item per pack\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move computation to CPU to avoid GPU overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Strategy: Multi-start with different initializations + All-Pairs Descent Refinement\n    # Candidates:\n    # 0: Deterministic Greedy (LPT)\n    # 1: ZigZag (Snake) Packing\n    # 2, 3: Randomized Greedy\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Create list of (original_index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort desc for deterministic heuristics\n        items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        for attempt in range(num_restarts):\n            # Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Greedy LPT\n                for idx, w in items_sorted:\n                    # Assign to lightest pack with capacity\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n                    \n            elif attempt == 1:\n                # ZigZag / Snake Packing\n                # Distributes sorted items: 0->M, M->0, 0->M...\n                for k, (idx, w) in enumerate(items_sorted):\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n                    \n            else:\n                # Randomized Greedy\n                # Add noise to weights to perturb sort order\n                # Use a lightweight pseudo-random approach\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                noisy_items = []\n                for k, (idx, w) in enumerate(items):\n                    noisy_items.append((idx, w, w * noise[k]))\n                # Sort by noisy weight\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # Refinement: All-Pairs Descent\n            # Try to balance every pair of packs, prioritizing the heaviest\n            for _ in range(20): # Max iterations\n                # Identify packing order\n                pack_indices_ordered = sorted(range(num_packs), \n                                              key=lambda p: pack_weights[p], \n                                              reverse=True)\n                \n                max_w = pack_weights[pack_indices_ordered[0]]\n                min_w = pack_weights[pack_indices_ordered[-1]]\n                if (max_w - min_w) < 1e-6:\n                    break\n                \n                improved = False\n                \n                # Double loop: Try to move weight from Heavier -> Lighter\n                # We limit the outer loop to top few heaviest packs to save time\n                for i_h in range(min(num_packs, 5)):\n                    p_heavy = pack_indices_ordered[i_h]\n                    w_heavy = pack_weights[p_heavy]\n                    \n                    # Try to swap with lighter packs\n                    for i_l in range(num_packs - 1, i_h, -1):\n                        p_light = pack_indices_ordered[i_l]\n                        w_light = pack_weights[p_light]\n                        \n                        diff = w_heavy - w_light\n                        if diff < 1e-6: continue\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u in heavy, v in light)\n                        ph_items = current_packs[p_heavy]\n                        pl_items = current_packs[p_light]\n                        \n                        for u_i, (idx_u, w_u) in enumerate(ph_items):\n                            for v_i, (idx_v, w_v) in enumerate(pl_items):\n                                delta = w_u - w_v\n                                # Valid swap must reduce heavy pack weight\n                                if delta > 0 and delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (u_i, v_i, delta, idx_u, w_u, idx_v, w_v)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            u_i, v_i, delta, idx_u, w_u, idx_v, w_v = best_swap\n                            \n                            # Execute Swap\n                            current_packs[p_heavy][u_i] = (idx_v, w_v)\n                            current_packs[p_light][v_i] = (idx_u, w_u)\n                            pack_weights[p_heavy] -= delta\n                            pack_weights[p_light] += delta\n                            improved = True\n                            break # Break to re-sort\n                    \n                    if improved: break\n                \n                if not improved:\n                    break\n\n            # Check if this restart is best\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    # Run on CPU to avoid kernel launch overhead for sequential operations\n    device = weight.device\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=\"cpu\").repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=\"cpu\")\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=\"cpu\")\n    arangen = torch.arange(n, dtype=torch.int64, device=\"cpu\")\n    \n    # Maintain current scores (load / count)\n    current_scores = weight_cpu.clone()\n\n    for i in range(num_log, num_phy):\n        # Find expert with max current load\n        # Argmax over the num_log dimension\n        redundant_indices = current_scores.argmax(dim=-1)\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores for affected experts\n        # score = weight / new_count\n        selected_weights = weight_cpu[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log.to(device), rank.to(device), logcnt.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>",
          "msg": "The previous edit was not successful. This was the error message: \n\nCould not extract code from patch string\n\n Try again.",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nCreate a novel algorithm that draws inspiration from the provided context programs but implements a fundamentally different approach.\nStudy the patterns and techniques from the examples, then design something new.\nYou MUST respond using a short summary name, description and the full code:\n\n<NAME>\nA shortened name summarizing the code you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nExplain how you drew inspiration from the context programs and what novel approach you are implementing. Detail the key insights that led to this design.\n</DESCRIPTION>\n\n<CODE>\n```{language}\n# The inspired but novel algorithm implementation here.\n```\n</CODE>\n\n* Keep the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the code.\n* Learn from the context programs but don't copy their approaches directly.\n* Combine ideas in novel ways or apply insights to different algorithmic paradigms.\n* Maintain the same inputs and outputs as the original program.\n* Use the <NAME>, <DESCRIPTION>, and <CODE> delimiters to structure your response. It will be parsed afterwards.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move weights to CPU and use Python lists for the sequential greedy/swap logic.\n    # This avoids high kernel launch overheads for sequential scalar operations on GPU.\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        # current_packs stores tuples of (expert_index, weight)\n        current_packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy packing (LPT: Longest Processing Time first)\n        # Assign heaviest items first to the least loaded pack that has space.\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n\n            # Find the least loaded pack with capacity\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n\n            current_packs[best_pack].append((group, w))\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Pairwise swapping\n        # Try to swap items between the heaviest and lightest packs to balance load.\n        for _ in range(20):\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n            found_improvement = False\n\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n                # Compare against lighter packs\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6:\n                        break # Since packs are sorted, subsequent diffs will be smaller\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Find best swap: u from p1, v from p2 such that w_u - w_v approx target\n                    for idx_u, (u, w_u) in enumerate(current_packs[p1]):\n                        for idx_v, (v, w_v) in enumerate(current_packs[p2]):\n                            delta = w_u - w_v\n                            # We need w_u > w_v to reduce diff\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    # Store swap details: indices and the actual values to swap\n                                    best_swap = (idx_u, idx_v, delta, v, w_v, u, w_u)\n                                    if gap < 1e-5: break\n                        if best_swap and best_gap < 1e-5: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta, val_v, weight_v, val_u, weight_u = best_swap\n\n                        # Apply swap\n                        current_packs[p1][idx_u] = (val_v, weight_v)\n                        current_packs[p2][idx_v] = (val_u, weight_u)\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break # Break inner loop to re-sort packs\n\n                if found_improvement: break\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, (g, _) in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Optimization: Track current scores (load/count) to avoid full matrix recalculation\n    current_scores = weight.clone()\n\n    for i in range(num_log, num_phy):\n        # Pick the expert with the max current load per replica\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        # Increment count\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update scores only for the experts that got a new replica\n        # score = weight / count\n        # We use advanced indexing to update only the modified positions\n        updated_weights = weight[arangen, redundant_indices]\n        updated_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = updated_weights / updated_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move weights to CPU and use Python lists for the sequential greedy/swap logic.\n    # This avoids high kernel launch overheads for sequential scalar operations on GPU.\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        # current_packs stores tuples of (expert_index, weight)\n        current_packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy packing (LPT: Longest Processing Time first)\n        # Assign heaviest items first to the least loaded pack that has space.\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            \n            # Find the least loaded pack with capacity\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            \n            current_packs[best_pack].append((group, w))\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Pairwise swapping\n        # Try to swap items between the heaviest and lightest packs to balance load.\n        for _ in range(20):\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n            found_improvement = False\n\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n                # Compare against lighter packs\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6:\n                        break # Since packs are sorted, subsequent diffs will be smaller\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Find best swap: u from p1, v from p2 such that w_u - w_v approx target\n                    for idx_u, (u, w_u) in enumerate(current_packs[p1]):\n                        for idx_v, (v, w_v) in enumerate(current_packs[p2]):\n                            delta = w_u - w_v\n                            # We need w_u > w_v to reduce diff\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    # Store swap details: indices and the actual values to swap\n                                    best_swap = (idx_u, idx_v, delta, v, w_v, u, w_u)\n                                    if gap < 1e-5: break\n                        if best_swap and best_gap < 1e-5: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta, val_v, weight_v, val_u, weight_u = best_swap\n                        \n                        # Apply swap\n                        current_packs[p1][idx_u] = (val_v, weight_v)\n                        current_packs[p2][idx_v] = (val_u, weight_u)\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break # Break inner loop to re-sort packs\n                \n                if found_improvement: break\n            \n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, (g, _) in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Track current scores (load/count) to avoid full matrix recalculation\n    current_scores = weight.clone()\n    \n    for i in range(num_log, num_phy):\n        # Pick the expert with the max current load per replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment count\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for the experts that got a new replica\n        # score = weight / count\n        # We use advanced indexing to update only the modified positions\n        updated_weights = weight[arangen, redundant_indices]\n        updated_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = updated_weights / updated_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\neplb_hybrid_descent\n</NAME>\n\n<DESCRIPTION>\nThis algorithm improves load balancing by employing a hybrid multi-start strategy (LPT Greedy, ZigZag, and Randomized LPT) combined with an aggressive all-pairs descent refinement. The computation is moved to the CPU to eliminate GPU kernel launch overheads for sequential scalar operations. The refinement phase iterates through sorted packs to perform beneficial swaps that reduce the load variance, effectively minimizing the makespan.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Trivial case: 1 item per pack\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move computation to CPU to avoid GPU overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Strategy: Multi-start with different initializations + All-Pairs Descent Refinement\n    # Candidates:\n    # 0: Deterministic Greedy (LPT)\n    # 1: ZigZag (Snake) Packing\n    # 2, 3: Randomized Greedy\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Create list of (original_index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort desc for deterministic heuristics\n        items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        for attempt in range(num_restarts):\n            # Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Greedy LPT\n                for idx, w in items_sorted:\n                    # Assign to lightest pack with capacity\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n                    \n            elif attempt == 1:\n                # ZigZag / Snake Packing\n                # Distributes sorted items: 0->M, M->0, 0->M...\n                for k, (idx, w) in enumerate(items_sorted):\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n                    \n            else:\n                # Randomized Greedy\n                # Add noise to weights to perturb sort order\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                noisy_items = []\n                for k, (idx, w) in enumerate(items):\n                    noisy_items.append((idx, w, w * noise[k]))\n                # Sort by noisy weight\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # Refinement: All-Pairs Descent\n            # Try to balance every pair of packs, prioritizing the heaviest\n            for _ in range(20): # Max iterations\n                # Identify packing order\n                pack_indices_ordered = sorted(range(num_packs), \n                                              key=lambda p: pack_weights[p], \n                                              reverse=True)\n                \n                max_w = pack_weights[pack_indices_ordered[0]]\n                min_w = pack_weights[pack_indices_ordered[-1]]\n                if (max_w - min_w) < 1e-6:\n                    break\n                \n                improved = False\n                \n                # Double loop: Try to move weight from Heavier -> Lighter\n                for i_h in range(num_packs):\n                    p_heavy = pack_indices_ordered[i_h]\n                    w_heavy = pack_weights[p_heavy]\n                    \n                    for i_l in range(num_packs - 1, i_h, -1):\n                        p_light = pack_indices_ordered[i_l]\n                        w_light = pack_weights[p_light]\n                        \n                        diff = w_heavy - w_light\n                        if diff < 1e-6: continue\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u in heavy, v in light)\n                        ph_items = current_packs[p_heavy]\n                        pl_items = current_packs[p_light]\n                        \n                        for u_i, (idx_u, w_u) in enumerate(ph_items):\n                            for v_i, (idx_v, w_v) in enumerate(pl_items):\n                                delta = w_u - w_v\n                                # Valid swap must reduce heavy pack weight\n                                if delta > 0 and delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (u_i, v_i, delta, idx_u, w_u, idx_v, w_v)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            u_i, v_i, delta, idx_u, w_u, idx_v, w_v = best_swap\n                            \n                            # Execute Swap\n                            current_packs[p_heavy][u_i] = (idx_v, w_v)\n                            current_packs[p_light][v_i] = (idx_u, w_u)\n                            pack_weights[p_heavy] -= delta\n                            pack_weights[p_light] += delta\n                            improved = True\n                            break # Break to re-sort\n                    \n                    if improved: break\n                \n                if not improved:\n                    break\n\n            # Check if this restart is best\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    # Run on CPU to avoid kernel launch overhead for sequential operations\n    device = weight.device\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=\"cpu\").repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=\"cpu\")\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=\"cpu\")\n    arangen = torch.arange(n, dtype=torch.int64, device=\"cpu\")\n    \n    # Maintain current scores (load / count)\n    current_scores = weight_cpu.clone()\n\n    for i in range(num_log, num_phy):\n        # Find expert with max current load\n        # Argmax over the num_log dimension\n        redundant_indices = current_scores.argmax(dim=-1)\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores for affected experts\n        # score = weight / new_count\n        selected_weights = weight_cpu[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log.to(device), rank.to(device), logcnt.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            "
            },
            {
              "role": "user",
              "content": "The previous edit was not successful. This was the error message: \n\nCould not extract code from patch string\n\n Try again."
            },
            {
              "role": "assistant",
              "content": "<NAME>\neplb_hybrid_descent\n</NAME>\n\n<DESCRIPTION>\nThis algorithm improves load balancing by employing a hybrid multi-start strategy (LPT Greedy, ZigZag, and Randomized LPT) combined with an aggressive all-pairs descent refinement. The computation is moved to the CPU to eliminate GPU kernel launch overheads for sequential scalar operations. The refinement phase iterates through sorted packs to perform beneficial swaps that reduce the load variance, effectively minimizing the makespan.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Trivial case: 1 item per pack\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: Move computation to CPU to avoid GPU overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Strategy: Multi-start with different initializations + All-Pairs Descent Refinement\n    # Candidates:\n    # 0: Deterministic Greedy (LPT)\n    # 1: ZigZag (Snake) Packing\n    # 2, 3: Randomized Greedy\n    num_restarts = 4\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        # Create list of (original_index, weight)\n        items = []\n        for idx in range(num_groups):\n            items.append((idx, row_weight[idx].item()))\n        \n        # Sort desc for deterministic heuristics\n        items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        for attempt in range(num_restarts):\n            # Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Greedy LPT\n                for idx, w in items_sorted:\n                    # Assign to lightest pack with capacity\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n                    \n            elif attempt == 1:\n                # ZigZag / Snake Packing\n                # Distributes sorted items: 0->M, M->0, 0->M...\n                for k, (idx, w) in enumerate(items_sorted):\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n                    \n            else:\n                # Randomized Greedy\n                # Add noise to weights to perturb sort order\n                # Use a lightweight pseudo-random approach\n                noise = [random.uniform(0.9, 1.1) for _ in range(num_groups)]\n                noisy_items = []\n                for k, (idx, w) in enumerate(items):\n                    noisy_items.append((idx, w, w * noise[k]))\n                # Sort by noisy weight\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                for idx, w, _ in noisy_items:\n                    best_p = -1\n                    min_load = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_load:\n                                min_load = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # Refinement: All-Pairs Descent\n            # Try to balance every pair of packs, prioritizing the heaviest\n            for _ in range(20): # Max iterations\n                # Identify packing order\n                pack_indices_ordered = sorted(range(num_packs), \n                                              key=lambda p: pack_weights[p], \n                                              reverse=True)\n                \n                max_w = pack_weights[pack_indices_ordered[0]]\n                min_w = pack_weights[pack_indices_ordered[-1]]\n                if (max_w - min_w) < 1e-6:\n                    break\n                \n                improved = False\n                \n                # Double loop: Try to move weight from Heavier -> Lighter\n                # We limit the outer loop to top few heaviest packs to save time\n                for i_h in range(min(num_packs, 5)):\n                    p_heavy = pack_indices_ordered[i_h]\n                    w_heavy = pack_weights[p_heavy]\n                    \n                    # Try to swap with lighter packs\n                    for i_l in range(num_packs - 1, i_h, -1):\n                        p_light = pack_indices_ordered[i_l]\n                        w_light = pack_weights[p_light]\n                        \n                        diff = w_heavy - w_light\n                        if diff < 1e-6: continue\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u in heavy, v in light)\n                        ph_items = current_packs[p_heavy]\n                        pl_items = current_packs[p_light]\n                        \n                        for u_i, (idx_u, w_u) in enumerate(ph_items):\n                            for v_i, (idx_v, w_v) in enumerate(pl_items):\n                                delta = w_u - w_v\n                                # Valid swap must reduce heavy pack weight\n                                if delta > 0 and delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (u_i, v_i, delta, idx_u, w_u, idx_v, w_v)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            u_i, v_i, delta, idx_u, w_u, idx_v, w_v = best_swap\n                            \n                            # Execute Swap\n                            current_packs[p_heavy][u_i] = (idx_v, w_v)\n                            current_packs[p_light][v_i] = (idx_u, w_u)\n                            pack_weights[p_heavy] -= delta\n                            pack_weights[p_light] += delta\n                            improved = True\n                            break # Break to re-sort\n                    \n                    if improved: break\n                \n                if not improved:\n                    break\n\n            # Check if this restart is best\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill result tensors\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    # Run on CPU to avoid kernel launch overhead for sequential operations\n    device = weight.device\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=\"cpu\").repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=\"cpu\")\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=\"cpu\")\n    arangen = torch.arange(n, dtype=torch.int64, device=\"cpu\")\n    \n    # Maintain current scores (load / count)\n    current_scores = weight_cpu.clone()\n\n    for i in range(num_log, num_phy):\n        # Find expert with max current load\n        # Argmax over the num_log dimension\n        redundant_indices = current_scores.argmax(dim=-1)\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores for affected experts\n        # score = weight / new_count\n        selected_weights = weight_cpu[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log.to(device), rank.to(device), logcnt.to(device)\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n```\n</CODE>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 33346,
          "output_tokens": 5722,
          "cost": 0.135356,
          "input_cost": 0.066692,
          "output_cost": 0.068664,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 77,
          "deleted": 0,
          "modified": 107
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 7.252e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_98/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_98/results\nRun 1/5 completed in 0.44 seconds\nRun 2/5 completed in 0.65 seconds\nRun 3/5 completed in 0.61 seconds\nRun 4/5 completed in 0.60 seconds\nRun 5/5 completed in 0.58 seconds\nbalancedness: 0.2107368506889166\nbalancedness: 0.3397761717755627\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_98/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_98/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385917818743\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.3110771835637488, 'speed_score': 1.0}\n  execution_time_mean: 0.5742681349991472\n  execution_time_std: 0.07100531025811523\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 53,
          "average_cyclomatic_complexity": 10.6,
          "halstead_volume": 1871.6552809328061,
          "halstead_difficulty": 11.72680412371134,
          "halstead_effort": 21948.534866608938,
          "lines_of_code": 410,
          "logical_lines_of_code": 197,
          "comments": 50,
          "maintainability_index": -38.322092569699066,
          "max_nesting_depth": 11,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "fd3bed95-2756-4e56-ac76-91362a88c7bb",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\nimport math\n\ndef solve_partition_exact(pool_weights: list[float], K: int, target_avg: float) -> tuple[float, list[int]]:\n    \"\"\"\n    Exact solver for partitioning pool_weights (size 2K) into two sets of size K\n    to minimize max(sum(A), sum(B)).\n    Returns (best_max_val, indices_A).\n    \"\"\"\n    n = len(pool_weights)\n    # Fix first element to A to reduce symmetry\n    # We want to choose K indices. We pick 0, then choose K-1 from remaining n-1.\n    \n    best_max = float('inf')\n    best_A = []\n    \n    total_sum = sum(pool_weights)\n    w0 = pool_weights[0]\n    indices_rest = list(range(1, n))\n    \n    for comb in itertools.combinations(indices_rest, K - 1):\n        # comb is tuple of K-1 indices\n        sum_A = w0\n        for idx in comb:\n            sum_A += pool_weights[idx]\n        \n        sum_B = total_sum - sum_A\n        current_max = max(sum_A, sum_B)\n        \n        if current_max < best_max:\n            best_max = current_max\n            best_A = [0] + list(comb)\n            if abs(current_max - target_avg) < 1e-6:\n                return best_max, best_A\n                \n    return best_max, best_A\n\ndef solve_partition_heuristic(pool_weights: list[float], K: int, trials: int) -> tuple[float, list[int]]:\n    \"\"\"\n    Heuristic solver for partitioning pool_weights into two sets of size K.\n    \"\"\"\n    n = len(pool_weights)\n    indices = list(range(n))\n    best_max = float('inf')\n    best_A = list(range(K))\n    \n    # 1. Randomized Greedy + Swap\n    for _ in range(trials):\n        # Randomize order\n        random.shuffle(indices)\n        \n        # Initial split\n        idx_A = indices[:K]\n        idx_B = indices[K:]\n        \n        sum_A = sum(pool_weights[i] for i in idx_A)\n        sum_B = sum(pool_weights[i] for i in idx_B)\n        \n        # Local Swap Optimization (Hill Climbing)\n        improved = True\n        while improved:\n            improved = False\n            curr_max = max(sum_A, sum_B)\n            \n            # Simple O(K^2) search for best swap\n            best_swap = None\n            best_swap_gain = 0.0\n            \n            # Optimization: Only look for swaps that reduce the max\n            for i in range(K):\n                u = idx_A[i]\n                w_u = pool_weights[u]\n                for j in range(K):\n                    v = idx_B[j]\n                    w_v = pool_weights[v]\n                    \n                    delta = w_u - w_v\n                    \n                    # New sums\n                    new_A = sum_A - delta\n                    new_B = sum_B + delta\n                    new_max = max(new_A, new_B)\n                    \n                    if new_max < curr_max - 1e-6:\n                        gain = curr_max - new_max\n                        if gain > best_swap_gain:\n                            best_swap_gain = gain\n                            best_swap = (i, j, delta)\n            \n            if best_swap:\n                i, j, delta = best_swap\n                # Swap indices\n                tmp = idx_A[i]\n                idx_A[i] = idx_B[j]\n                idx_B[j] = tmp\n                sum_A -= delta\n                sum_B += delta\n                improved = True\n        \n        final_max = max(sum_A, sum_B)\n        if final_max < best_max:\n            best_max = final_max\n            best_A = list(idx_A)\n            \n    return best_max, best_A\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Parameters\n    num_restarts = 8  # Increased restarts\n    max_refine_steps = 20\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Noisy LPT\n                # Noise range [0.9, 1.1]\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n            \n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Find pack with min weight that has space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n                \n            # 2. Refinement Loop\n            for _ in range(max_refine_steps):\n                # Identify Max Pack\n                max_p = 0\n                max_val = pack_weights[0]\n                min_val = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    if pack_weights[p] > max_val:\n                        max_val = pack_weights[p]\n                        max_p = p\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                \n                if max_val - min_val < 1e-6:\n                    break\n                    \n                best_move = None\n                # We want to reduce max_val.\n                # Current best improvement starts at 0 (or slightly negative tolerance)\n                best_new_max = max_val\n                \n                # Try pairing max_p with every other pack\n                # Sorting candidates by weight (lightest first) is a good heuristic\n                candidates = sorted([p for p in range(num_packs) if p != max_p], \n                                    key=pack_weights.__getitem__)\n                                    \n                for other_p in candidates:\n                    other_val = pack_weights[other_p]\n                    target_avg = (max_val + other_val) / 2.0\n                    \n                    # If perfect balancing of this pair doesn't improve upon our best found move, skip.\n                    # We want new_max < best_new_max.\n                    # Best possible new_max for this pair is target_avg.\n                    if target_avg >= best_new_max - 1e-6:\n                        continue\n                        \n                    # Prepare Pool\n                    pool_indices = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool_indices]\n                    pool_len = len(pool_indices)\n                    K = groups_per_pack\n                    \n                    # Solve Partition\n                    if pool_len <= 14:\n                        local_max, idx_A_local = solve_partition_exact(pool_weights, K, target_avg)\n                    else:\n                        local_max, idx_A_local = solve_partition_heuristic(pool_weights, K, trials=20)\n                    \n                    # Check if this result improves the global situation (reduces max_p)\n                    # Note: local_max is the max(new_p1, new_p2). \n                    # We are guaranteed local_max <= max_val because we can always keep original.\n                    if local_max < best_new_max - 1e-6:\n                        best_new_max = local_max\n                        \n                        # Reconstruct items\n                        # idx_A_local are indices into pool_indices\n                        items_A = [pool_indices[i] for i in idx_A_local]\n                        \n                        # items_B are the rest\n                        set_A = set(idx_A_local)\n                        items_B = [pool_indices[i] for i in range(pool_len) if i not in set_A]\n                        \n                        # Recalculate exact sums to avoid float drift\n                        w_A = sum(row_weight_list[x] for x in items_A)\n                        w_B = sum(row_weight_list[x] for x in items_B)\n                        \n                        best_move = (other_p, items_A, items_B, w_A, w_B)\n                        \n                        # If we hit the theoretical limit, stop searching\n                        if abs(local_max - target_avg) < 1e-6:\n                            break\n                            \n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    # No improvement possible for max_p\n                    break\n            \n            # Check Result\n            current_max = max(pack_weights)\n            current_min = min(pack_weights)\n            current_diff = current_max - current_min\n            \n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill Output\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Track current load per replica: weight / count\n    current_scores = weight.clone()\n\n    for i in range(num_log, num_phy):\n        # Greedily split the expert with the highest average load per replica\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "9294c033-5700-4ded-9ee0-128d1051be42",
      "archive_inspiration_ids": [
        "29b9d302-536d-4bc9-a0ee-af060ab21bd7",
        "464977bc-d755-4a6d-8769-721a279a6bfe",
        "20a9bb3a-6828-4cfc-a703-de218bf3e590",
        "f4c9bdd0-7ef6-4b27-bd77-e2ae2c1aeef3"
      ],
      "top_k_inspiration_ids": [
        "ab7770ac-34de-4e9d-bad0-7e53e5153b3c",
        "df875ab2-40cb-4fa5-97ef-3f72994c52a6"
      ],
      "island_idx": 1,
      "generation": 99,
      "timestamp": 1764182069.616472,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,370 +1,442 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n import random\n import itertools\n+import math\n+\n+def solve_partition_exact(pool_weights: list[float], K: int, target_avg: float) -> tuple[float, list[int]]:\n+    \"\"\"\n+    Exact solver for partitioning pool_weights (size 2K) into two sets of size K\n+    to minimize max(sum(A), sum(B)).\n+    Returns (best_max_val, indices_A).\n+    \"\"\"\n+    n = len(pool_weights)\n+    # Fix first element to A to reduce symmetry\n+    # We want to choose K indices. We pick 0, then choose K-1 from remaining n-1.\n+    \n+    best_max = float('inf')\n+    best_A = []\n+    \n+    total_sum = sum(pool_weights)\n+    w0 = pool_weights[0]\n+    indices_rest = list(range(1, n))\n+    \n+    for comb in itertools.combinations(indices_rest, K - 1):\n+        # comb is tuple of K-1 indices\n+        sum_A = w0\n+        for idx in comb:\n+            sum_A += pool_weights[idx]\n+        \n+        sum_B = total_sum - sum_A\n+        current_max = max(sum_A, sum_B)\n+        \n+        if current_max < best_max:\n+            best_max = current_max\n+            best_A = [0] + list(comb)\n+            if abs(current_max - target_avg) < 1e-6:\n+                return best_max, best_A\n+                \n+    return best_max, best_A\n+\n+def solve_partition_heuristic(pool_weights: list[float], K: int, trials: int) -> tuple[float, list[int]]:\n+    \"\"\"\n+    Heuristic solver for partitioning pool_weights into two sets of size K.\n+    \"\"\"\n+    n = len(pool_weights)\n+    indices = list(range(n))\n+    best_max = float('inf')\n+    best_A = list(range(K))\n+    \n+    # 1. Randomized Greedy + Swap\n+    for _ in range(trials):\n+        # Randomize order\n+        random.shuffle(indices)\n+        \n+        # Initial split\n+        idx_A = indices[:K]\n+        idx_B = indices[K:]\n+        \n+        sum_A = sum(pool_weights[i] for i in idx_A)\n+        sum_B = sum(pool_weights[i] for i in idx_B)\n+        \n+        # Local Swap Optimization (Hill Climbing)\n+        improved = True\n+        while improved:\n+            improved = False\n+            curr_max = max(sum_A, sum_B)\n+            \n+            # Simple O(K^2) search for best swap\n+            best_swap = None\n+            best_swap_gain = 0.0\n+            \n+            # Optimization: Only look for swaps that reduce the max\n+            for i in range(K):\n+                u = idx_A[i]\n+                w_u = pool_weights[u]\n+                for j in range(K):\n+                    v = idx_B[j]\n+                    w_v = pool_weights[v]\n+                    \n+                    delta = w_u - w_v\n+                    \n+                    # New sums\n+                    new_A = sum_A - delta\n+                    new_B = sum_B + delta\n+                    new_max = max(new_A, new_B)\n+                    \n+                    if new_max < curr_max - 1e-6:\n+                        gain = curr_max - new_max\n+                        if gain > best_swap_gain:\n+                            best_swap_gain = gain\n+                            best_swap = (i, j, delta)\n+            \n+            if best_swap:\n+                i, j, delta = best_swap\n+                # Swap indices\n+                tmp = idx_A[i]\n+                idx_A[i] = idx_B[j]\n+                idx_B[j] = tmp\n+                sum_A -= delta\n+                sum_B += delta\n+                improved = True\n+        \n+        final_max = max(sum_A, sum_B)\n+        if final_max < best_max:\n+            best_max = final_max\n+            best_A = list(idx_A)\n+            \n+    return best_max, best_A\n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     # Handle trivial case\n     if groups_per_pack == 1:\n         pack_index = torch.arange(num_groups,\n                                   dtype=torch.int64,\n                                   device=weight.device).expand(num_layers, -1)\n         rank_in_pack = torch.zeros_like(pack_index)\n         return pack_index, rank_in_pack\n \n-    # CPU processing for complex sequential logic\n+    # CPU processing\n     weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n \n-    # Heuristic parameters\n-    num_restarts = 3\n-    max_refine_steps = 25\n-\n+    # Parameters\n+    num_restarts = 8  # Increased restarts\n+    max_refine_steps = 20\n+    \n     for i in range(num_layers):\n         row_weight = weight_cpu[i]\n         row_weight_list = row_weight.tolist()\n-\n+        \n         best_diff = float('inf')\n         best_packs = None\n-\n-        # Base indices for deterministic LPT\n+        \n+        # Base LPT indices\n         base_indices = torch.argsort(row_weight, descending=True).tolist()\n-\n+        \n         for attempt in range(num_restarts):\n             # 1. Initialization\n+            current_packs = [[] for _ in range(num_packs)]\n+            pack_weights = [0.0] * num_packs\n+            \n             if attempt == 0:\n                 indices = base_indices\n             else:\n-                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n+                # Noisy LPT\n+                # Noise range [0.9, 1.1]\n+                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                 indices = torch.argsort(row_weight * noise, descending=True).tolist()\n-\n-            current_packs = [[] for _ in range(num_packs)]\n-            pack_weights = [0.0] * num_packs\n-\n+            \n             # Greedy Packing\n             for group_idx in indices:\n                 w = row_weight_list[group_idx]\n+                # Find pack with min weight that has space\n                 best_p = -1\n                 min_val = float('inf')\n                 for p in range(num_packs):\n                     if len(current_packs[p]) < groups_per_pack:\n                         if pack_weights[p] < min_val:\n                             min_val = pack_weights[p]\n                             best_p = p\n                 current_packs[best_p].append(group_idx)\n                 pack_weights[best_p] += w\n-\n-            # 2. Refinement Phase\n-            for step in range(max_refine_steps):\n-                # Identify max pack\n-                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n-                max_val = pack_weights[max_p]\n-\n-                min_val = min(pack_weights)\n+                \n+            # 2. Refinement Loop\n+            for _ in range(max_refine_steps):\n+                # Identify Max Pack\n+                max_p = 0\n+                max_val = pack_weights[0]\n+                min_val = pack_weights[0]\n+                \n+                for p in range(1, num_packs):\n+                    if pack_weights[p] > max_val:\n+                        max_val = pack_weights[p]\n+                        max_p = p\n+                    if pack_weights[p] < min_val:\n+                        min_val = pack_weights[p]\n+                \n                 if max_val - min_val < 1e-6:\n                     break\n-\n+                    \n                 best_move = None\n-                best_move_improvement = -1.0\n-\n-                candidate_packs = [p for p in range(num_packs) if p != max_p]\n-                # Sort candidates by weight: testing lightest first often helps move most weight\n-                candidate_packs.sort(key=pack_weights.__getitem__)\n-\n-                for other_p in candidate_packs:\n+                # We want to reduce max_val.\n+                # Current best improvement starts at 0 (or slightly negative tolerance)\n+                best_new_max = max_val\n+                \n+                # Try pairing max_p with every other pack\n+                # Sorting candidates by weight (lightest first) is a good heuristic\n+                candidates = sorted([p for p in range(num_packs) if p != max_p], \n+                                    key=pack_weights.__getitem__)\n+                                    \n+                for other_p in candidates:\n                     other_val = pack_weights[other_p]\n-\n-                    # Target is average of the pair\n-                    avg = (max_val + other_val) / 2.0\n-                    potential_reduction = max_val - avg\n-\n-                    if potential_reduction < best_move_improvement + 1e-6:\n+                    target_avg = (max_val + other_val) / 2.0\n+                    \n+                    # If perfect balancing of this pair doesn't improve upon our best found move, skip.\n+                    # We want new_max < best_new_max.\n+                    # Best possible new_max for this pair is target_avg.\n+                    if target_avg >= best_new_max - 1e-6:\n                         continue\n-\n-                    pool = current_packs[max_p] + current_packs[other_p]\n-                    pool_weights = [row_weight_list[x] for x in pool]\n-\n+                        \n+                    # Prepare Pool\n+                    pool_indices = current_packs[max_p] + current_packs[other_p]\n+                    pool_weights = [row_weight_list[x] for x in pool_indices]\n+                    pool_len = len(pool_indices)\n                     K = groups_per_pack\n-                    pool_len = 2 * K\n-\n-                    best_local_set_A = None\n-                    best_local_max = float('inf')\n-\n-                    # EXACT SOLVER for small K\n+                    \n+                    # Solve Partition\n                     if pool_len <= 14:\n-                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n-                         indices_rest = list(range(1, pool_len))\n-                         w_0 = pool_weights[0]\n-\n-                         for comb in itertools.combinations(indices_rest, K - 1):\n-                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n-                             other_w = (max_val + other_val) - current_w\n-                             local_max = max(current_w, other_w)\n-\n-                             if local_max < best_local_max:\n-                                 best_local_max = local_max\n-                                 best_local_set_A = [0] + list(comb)\n-                                 if abs(local_max - avg) < 1e-5:\n-                                     break\n+                        local_max, idx_A_local = solve_partition_exact(pool_weights, K, target_avg)\n                     else:\n-                        # Heuristic Solver\n-                        pool_indices = list(range(pool_len))\n-                        sub_trials = 10\n-                        for sub in range(sub_trials):\n-                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n-                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n-\n-                            w1, w2 = 0.0, 0.0\n-                            c1, c2 = 0, 0\n-                            s1, s2 = [], []\n-\n-                            for idx in sorted_idx:\n-                                w = pool_weights[idx]\n-                                if c1 < K and c2 < K:\n-                                    if w1 <= w2:\n-                                        w1 += w; c1 += 1; s1.append(idx)\n-                                    else:\n-                                        w2 += w; c2 += 1; s2.append(idx)\n-                                elif c1 < K:\n-                                    w1 += w; c1 += 1; s1.append(idx)\n-                                else:\n-                                    w2 += w; c2 += 1; s2.append(idx)\n-\n-                            # Swap Local Search\n-                            while True:\n-                                improved_swap = False\n-                                current_max = max(w1, w2)\n-                                for i1, idx1 in enumerate(s1):\n-                                    for i2, idx2 in enumerate(s2):\n-                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n-                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n-                                        nmax = max(nw1, nw2)\n-                                        if nmax < current_max - 1e-6:\n-                                            w1, w2 = nw1, nw2\n-                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n-                                            current_max = nmax\n-                                            improved_swap = True\n-                                            break\n-                                    if improved_swap: break\n-                                if not improved_swap: break\n-\n-                            if max(w1, w2) < best_local_max:\n-                                best_local_max = max(w1, w2)\n-                                best_local_set_A = list(s1)\n-\n-                    # Check improvement\n-                    improvement = max_val - best_local_max\n-                    if improvement > best_move_improvement + 1e-6:\n-                        best_move_improvement = improvement\n-                        set_A_indices = best_local_set_A\n-                        set_A_set = set(set_A_indices)\n-                        new_items_A = [pool[x] for x in set_A_indices]\n-                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n-                        # Calculate exact new weights to avoid drift\n-                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n-                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n-                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n-\n-                        if abs(best_local_max - avg) < 1e-5:\n-                             break\n-\n+                        local_max, idx_A_local = solve_partition_heuristic(pool_weights, K, trials=20)\n+                    \n+                    # Check if this result improves the global situation (reduces max_p)\n+                    # Note: local_max is the max(new_p1, new_p2). \n+                    # We are guaranteed local_max <= max_val because we can always keep original.\n+                    if local_max < best_new_max - 1e-6:\n+                        best_new_max = local_max\n+                        \n+                        # Reconstruct items\n+                        # idx_A_local are indices into pool_indices\n+                        items_A = [pool_indices[i] for i in idx_A_local]\n+                        \n+                        # items_B are the rest\n+                        set_A = set(idx_A_local)\n+                        items_B = [pool_indices[i] for i in range(pool_len) if i not in set_A]\n+                        \n+                        # Recalculate exact sums to avoid float drift\n+                        w_A = sum(row_weight_list[x] for x in items_A)\n+                        w_B = sum(row_weight_list[x] for x in items_B)\n+                        \n+                        best_move = (other_p, items_A, items_B, w_A, w_B)\n+                        \n+                        # If we hit the theoretical limit, stop searching\n+                        if abs(local_max - target_avg) < 1e-6:\n+                            break\n+                            \n                 if best_move:\n                     other_p, items_A, items_B, w_A, w_B = best_move\n                     current_packs[max_p] = items_A\n                     current_packs[other_p] = items_B\n                     pack_weights[max_p] = w_A\n                     pack_weights[other_p] = w_B\n                 else:\n+                    # No improvement possible for max_p\n                     break\n-\n-            current_diff = max(pack_weights) - min(pack_weights)\n+            \n+            # Check Result\n+            current_max = max(pack_weights)\n+            current_min = min(pack_weights)\n+            current_diff = current_max - current_min\n+            \n             if current_diff < best_diff:\n                 best_diff = current_diff\n                 best_packs = [list(p) for p in current_packs]\n                 if best_diff < 1e-6:\n                     break\n-\n+        \n+        # Fill Output\n         for p in range(num_packs):\n             for r, g in enumerate(best_packs[p]):\n                 pack_index[i, g] = p\n                 rank_in_pack[i, g] = r\n \n     return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n \n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n-\n-    # Efficient incremental update of scores\n-    current_scores = weight.clone() # weight / 1\n+    \n+    # Track current load per replica: weight / count\n+    current_scores = weight.clone()\n \n     for i in range(num_log, num_phy):\n-        # Pick expert with max current load\n+        # Greedily split the expert with the highest average load per replica\n         redundant_indices = current_scores.max(dim=-1).indices\n \n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n \n         logcnt[arangen, redundant_indices] += 1\n-\n-        # Update score: weight / new_count\n+        \n+        # Update scores\n         selected_weights = weight[arangen, redundant_indices]\n         selected_counts = logcnt[arangen, redundant_indices].float()\n         current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n \n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Hierarchical rebalancing strategy.\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385873149429,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.3110771746298858,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.045975097,
        -0.0053393487,
        0.038107827,
        -0.03933635,
        -0.03194159,
        0.0032898418,
        -0.028846657,
        0.017541885,
        -0.015663665,
        0.044793826,
        0.027807137,
        0.012934926,
        -0.011227989,
        -0.02003437,
        0.0132538695,
        0.009727773,
        0.0042584846,
        0.012521481,
        -0.027830763,
        0.043021917,
        -0.016833123,
        -0.012415166,
        0.022030719,
        -0.02520834,
        -0.0025102026,
        0.004937716,
        0.050085925,
        -0.03239047,
        0.021003012,
        -0.05093644,
        0.08561858,
        -0.0035969727,
        -0.006266647,
        0.003555628,
        -0.022196097,
        0.03560353,
        -0.00403109,
        0.026389612,
        0.019798115,
        0.043140046,
        0.040659375,
        -0.036997434,
        -0.07092356,
        0.04351805,
        -0.044699326,
        0.0053570676,
        0.0068572825,
        -0.00960374,
        0.06445019,
        0.004621726,
        0.047392625,
        0.013076679,
        -0.003159902,
        0.06345792,
        0.018711345,
        0.037446316,
        0.014435141,
        0.018002583,
        0.019715426,
        -0.022373287,
        0.031965215,
        -0.006101269,
        0.059866853,
        0.048101388,
        -0.038060576,
        -0.0038125548,
        -0.023826253,
        0.013525562,
        0.016183423,
        -0.02011706,
        -0.05906359,
        0.032225095,
        -0.012237975,
        -0.04325817,
        -0.0021868295,
        0.0050587966,
        -0.0033843436,
        0.038651213,
        -0.013501937,
        -0.02655499,
        -0.029744424,
        -0.028752156,
        0.06426118,
        0.02086126,
        0.0023005267,
        -0.078814454,
        -0.040612124,
        -0.02355456,
        -0.03298111,
        -0.04524271,
        0.020306062,
        -0.03213059,
        -0.0018885583,
        0.04399056,
        0.05306273,
        -0.04843214,
        0.05797682,
        0.0075896713,
        0.054149497,
        0.05367699,
        -0.014175261,
        0.006632841,
        -0.030831194,
        0.0036885212,
        0.033099234,
        -0.0042702975,
        -0.0115174,
        0.006284366,
        0.016573243,
        -0.0129939895,
        -0.040848378,
        0.026436863,
        0.008587846,
        -0.013206619,
        0.017222943,
        -0.014116198,
        -0.024310574,
        0.001702508,
        -0.01017075,
        -0.02077857,
        -0.021262892,
        -0.03161083,
        0.01998712,
        -0.032673977,
        -0.0053570676,
        -0.021853529,
        0.017482823,
        -0.041533515,
        -0.0057882317,
        0.0030417747,
        0.041131884,
        0.033217363,
        -0.01790808,
        -0.015663665,
        -0.0035792536,
        -0.0017290866,
        -0.04932991,
        0.004243719,
        -0.009414736,
        -0.03690293,
        -0.03187071,
        0.03886384,
        -0.023400994,
        -0.022975735,
        -0.05410225,
        0.041179135,
        0.010761386,
        0.009467893,
        -0.044911955,
        0.032839354,
        0.012934926,
        -0.040659375,
        -0.016596869,
        -0.0001832817,
        0.013407434,
        -0.017128441,
        -0.021853529,
        0.0050410773,
        0.05386599,
        -0.029224664,
        -0.0061780512,
        0.017482823,
        -0.006798219,
        0.0106019145,
        0.0380842,
        0.02021156,
        -0.039478105,
        0.017943518,
        -0.06449744,
        -0.04928266,
        0.0149312755,
        -0.030122431,
        0.0013281924,
        -0.0057675596,
        0.02542097,
        0.0023507308,
        -0.02421607,
        -0.036548547,
        -0.023460058,
        -0.042242277,
        -0.023660874,
        -0.022550479,
        -0.008564221,
        -0.007861364,
        -0.059914105,
        0.040683,
        -0.025066588,
        -0.021050263,
        -0.025869852,
        0.00097159605,
        0.014458766,
        0.038509462,
        -0.035745285,
        0.033571742,
        0.008351591,
        0.0013916858,
        0.047321748,
        0.03472939,
        -0.0035910662,
        -0.0038863842,
        -0.043234546,
        -0.013726378,
        0.037611693,
        -0.032697603,
        0.025609972,
        0.038745716,
        -0.016809497,
        0.021605462,
        0.0070344736,
        -0.01260417,
        0.034918394,
        -0.032272346,
        0.04451032,
        -0.003372531,
        -0.022574104,
        -0.012178912,
        -0.031445455,
        0.019254731,
        -0.006207583,
        0.081933014,
        -0.017057564,
        0.022609541,
        -0.032319594,
        0.012415166,
        -0.024806708,
        0.0132538695,
        0.047038242,
        -0.031303704,
        0.008434281,
        0.0078082066,
        -0.026531365,
        -0.013490124,
        -0.0069517842,
        -0.014612332,
        0.039218225,
        -0.041486263,
        -0.058165822,
        0.01516753,
        0.003307561,
        -0.05216496,
        0.02499571,
        0.035438154,
        0.002702159,
        -0.05315723,
        0.011871781,
        0.0067509683,
        -0.037139185,
        -0.0021440082,
        -0.0025131558,
        -0.015143904,
        0.0069695036,
        -0.045053706,
        -0.0015947169,
        -0.041580766,
        -0.022538666,
        0.027996141,
        0.007069912,
        -0.053346235,
        -0.02290486,
        -0.046353105,
        0.00042710357,
        -0.029862551,
        -0.013454686,
        -0.004329361,
        -0.0039602136,
        -0.0053452547,
        -0.0066269347,
        0.0128640495,
        -0.048054136,
        -0.0014861876,
        0.011989908,
        0.0020539362,
        -0.012462418,
        0.0012248312,
        -0.018876724,
        -0.020294249,
        0.017128441,
        -0.008451999,
        -0.04994417,
        -0.046400357,
        -0.01555735,
        -0.00042710357,
        0.033571742,
        -2.1652804e-05,
        0.021617273,
        -0.006272553,
        0.004048809,
        0.011180737,
        0.01982174,
        -0.009225733,
        -0.0195973,
        -0.026129732,
        0.03168171,
        -0.0019313793,
        0.009916777,
        -0.013135742,
        -0.05523627,
        -0.016325176,
        0.0223851,
        -0.010861794,
        0.016407864,
        0.0035054241,
        -0.032154217,
        0.0057173553,
        0.02820877,
        -0.04115551,
        -0.016868562,
        0.022763107,
        -0.012190725,
        -0.023448246,
        -0.0104719745,
        0.012840425,
        -0.024405075,
        -0.00013178564,
        -0.016632307,
        -0.02103845,
        0.04006874,
        -0.014340639,
        -0.009296609,
        -0.059299845,
        -0.043659806,
        -0.049660664,
        0.04006874,
        0.024428701,
        0.0071053496,
        0.012545106,
        -0.026129732,
        -0.005773466,
        -0.011287052,
        -0.013631877,
        -0.0004747236,
        0.038131453,
        0.021510959,
        0.022290599,
        -0.0008615901,
        -0.013312933,
        0.03312286,
        -0.002025881,
        0.04984967,
        0.025231965,
        -0.071301565,
        0.01369094,
        -0.017742703,
        -0.024050694,
        -0.030382311,
        0.022314224,
        0.062749155,
        0.027405506,
        0.029059285,
        0.06827751,
        -0.04011599,
        -0.029484544,
        -0.021274704,
        0.01395082,
        0.005596275,
        -0.024523202,
        0.0016183424,
        0.017931705,
        -0.048195887,
        -0.024050694,
        -0.027712636,
        -0.0039808857,
        0.016372427,
        -0.008079899,
        0.014104385,
        0.06808851,
        0.026365986,
        -0.017967144,
        0.032036092,
        0.019668175,
        0.036170542,
        0.0024526156,
        -0.00812715,
        -0.0025102026,
        -0.040541247,
        -0.017093003,
        0.04311642,
        0.046353105,
        -0.009202107,
        0.010489694,
        0.019219292,
        0.008499251,
        -0.028232396,
        0.0010446872,
        0.025231965,
        0.03737544,
        0.0028616309,
        0.018215211,
        -0.04928266,
        0.011735935,
        0.05859108,
        -0.020613194,
        -0.010513319,
        -0.026389612,
        0.0446757,
        -0.010241627,
        -0.0258226,
        -0.015108466,
        0.048266765,
        0.0084697185,
        -0.009503332,
        0.01825065,
        -0.03142183,
        -0.026176983,
        -0.033004735,
        0.025113838,
        0.03489477,
        0.03815508,
        0.005956563,
        0.013915381,
        0.04481745,
        -0.034705766,
        0.023672687,
        0.0007752096,
        0.01477771,
        -0.034611262,
        0.0011295911,
        0.041746143,
        0.012131661,
        0.019455547,
        0.0021366253,
        0.0058384356,
        -0.0040872004,
        -0.0070226607,
        -0.014813148,
        0.0023581139,
        0.03730456,
        -0.021085702,
        0.021073889,
        -0.04824314,
        0.0077432366,
        0.015663665,
        0.06298541,
        -0.022030719,
        0.006089456,
        0.040683,
        0.01317118,
        0.040588498,
        0.021274704,
        0.022621354,
        -0.00760739,
        -0.003405016,
        -0.013844505,
        0.00021650497,
        -0.00068993657,
        -0.011210269,
        0.0024083178,
        -0.04358893,
        0.05032218,
        0.016714996,
        0.028893908,
        -0.03829683,
        0.07541239,
        -0.005371833,
        -0.0017527121,
        -0.044226814,
        0.076026656,
        0.03860396,
        0.03702106,
        0.006003814,
        0.05358249,
        0.012545106,
        0.00118201,
        -0.037847947,
        0.04181702,
        0.022007093,
        0.0031510424,
        -0.011854063,
        -0.013974445,
        0.02872853,
        0.0650172,
        -0.051078193,
        -0.0022444164,
        0.02594073,
        -0.021239266,
        0.00065339095,
        -0.005436803,
        0.049377162,
        0.01851053,
        -0.0420769,
        0.026106106,
        -0.050700184,
        -0.03042956,
        -0.041368138,
        0.023223802,
        0.01586448,
        0.029390043,
        -0.0019048008,
        -0.011092142,
        0.023755375,
        0.030453186,
        0.00026578616,
        -0.0017556652,
        -0.011233895,
        -0.006792313,
        -0.009804556,
        -0.018664094,
        0.0054840543,
        0.0016803591,
        0.044014186,
        0.012675046,
        -0.08027923,
        -0.06279641,
        -0.0018634562,
        0.023873502,
        -0.04824314,
        -0.029862551,
        0.003803695,
        0.00914895,
        0.03907647,
        -0.033807997,
        0.009751399,
        0.009225733,
        0.034327757,
        -0.004955435,
        0.028492276,
        -0.018085271,
        -0.009461987,
        0.011027172,
        0.04032862,
        -0.029153788,
        -0.027311003,
        -0.061048124,
        0.016502367,
        0.036359545,
        -0.03208334,
        -0.03239047,
        -0.06960053,
        0.0052743787,
        -0.005859108,
        -0.01930198,
        -0.02525559,
        -0.060008608,
        0.009940402,
        -0.018286087,
        0.023660874,
        -0.011038985,
        -0.022349663,
        -0.030146057,
        -0.04436857,
        0.0096391775,
        0.008198027,
        0.025231965,
        0.022845797,
        0.00952105,
        -0.027547259,
        0.06265466,
        0.03194159,
        0.019018475,
        0.035532657,
        0.009361579,
        -0.05410225,
        0.0005596275,
        0.0011487869,
        -0.034327757,
        -0.009526957,
        -0.010129405,
        -0.035178274,
        0.018262463,
        0.051125444,
        0.011724123,
        -0.004725087,
        -0.0035083771,
        -0.018829472,
        -0.0149312755,
        0.0050115455,
        0.018451465,
        -0.045786094,
        0.0058148103,
        0.017541885,
        -0.012261601,
        0.027807137,
        -0.0005411701,
        -0.05386599,
        0.027216502,
        0.0091962,
        0.005770513,
        -0.016915811,
        0.0066682794,
        -0.016573243,
        -0.027854389,
        -0.015179343,
        -0.024109757,
        -0.019975306,
        -0.04725087,
        -0.01408076,
        -0.038107827,
        0.009822275,
        -0.013419247,
        -0.023318306,
        0.009727773,
        -0.0037239592,
        0.0433763,
        -0.016844936,
        0.0077845813,
        -0.01677406,
        -0.04947166,
        0.0077963937,
        0.021026637,
        0.006609216,
        -0.0129113,
        0.05859108,
        0.00066114304,
        0.02038875,
        -0.038320456,
        -0.010873606,
        0.012438792,
        0.019408295,
        0.009208013,
        -0.04332905,
        -0.0004396546,
        -0.032839354,
        -0.019762676,
        0.005513586,
        -0.003883431,
        -0.015120279,
        0.031256452,
        0.0053393487,
        0.021829903,
        -0.019160228,
        -0.0022975737,
        0.032036092,
        0.0010601914,
        -0.011352022,
        -0.026389612,
        -0.017317444,
        -0.0151911555,
        -0.0026150404,
        -0.004459301,
        0.016998501,
        -0.034516763,
        -0.0063316165,
        -0.015982607,
        0.013147555,
        0.015545537,
        0.060386613,
        0.046282228,
        0.026247859,
        0.0059004524,
        0.0027508866,
        0.033807997,
        -0.005743934,
        0.013312933,
        -0.03437501,
        0.0128640495,
        0.019585487,
        -0.0153210955,
        0.0024585219,
        0.010064435,
        -0.013218432,
        -0.02464133,
        -0.022928486,
        0.05150345,
        0.027476382,
        0.02950817,
        0.007755049,
        -0.0066919047,
        -0.05259022,
        -0.02738188,
        -0.007306166,
        -0.031091074,
        -0.00339025,
        -0.012722298,
        -0.015781792,
        0.03281573,
        0.0014278623,
        0.027452756,
        0.021274704,
        0.012202538,
        0.05202321,
        0.010336128,
        0.030405935,
        0.030193307,
        -0.028870283,
        -0.034091502,
        -0.016915811,
        -0.012403354,
        -0.00326031,
        -0.012486042,
        0.020317875,
        -0.011570557,
        -0.012923113,
        -0.032059718,
        0.008097618,
        -0.0059034056,
        0.027405506,
        0.009072167,
        -0.006798219,
        0.04751075,
        -0.020353314,
        0.031067448,
        -0.013159367,
        -0.039926987,
        -0.023070239,
        0.02568085,
        0.041628018,
        -0.0023714032,
        0.024570454,
        -0.030807568,
        -0.044959202,
        -0.021321956,
        0.008694161,
        -0.015521911,
        -0.03132733,
        -0.047132745,
        -0.012226163,
        -0.03239047,
        0.057409808,
        0.031894337,
        -0.02473583,
        -0.044226814,
        -0.009036729,
        -0.025609972,
        -0.030972946,
        -0.06629297,
        0.008251184,
        0.011629621,
        0.016762247,
        0.025231965,
        -0.029484544,
        -0.01946736,
        -0.00754242,
        -0.042832915,
        0.0061721453,
        0.04150989,
        0.023211991,
        0.018983038,
        0.010489694,
        0.004116732,
        0.009036729,
        0.02412157,
        -0.024405075,
        0.019550048,
        -0.03685568,
        0.028303271,
        -0.009160763,
        -0.0023492542,
        -0.03834408,
        -0.014104385,
        0.015391971,
        -0.0056494325,
        -0.020695882,
        0.015179343,
        -0.0041078725,
        0.0182979,
        0.00645565,
        0.010359754,
        0.036832053,
        -0.024192447,
        0.03428051,
        -0.02008162,
        0.0069695036,
        -0.020436002,
        0.0085996585,
        0.04843214,
        0.020955762,
        0.017069377,
        -0.0011406656,
        0.00081212434,
        0.01382088,
        -0.01669137,
        -0.025987979,
        -0.018356964,
        0.013147555,
        0.008570127,
        0.0005577818,
        -0.03602879,
        -0.005643526,
        0.01343106,
        -0.030571314,
        -0.0059447503,
        0.005974282,
        0.056086786,
        0.049093656,
        0.017400132,
        -0.027878014,
        0.02038875,
        -0.032319594,
        -0.0016419678,
        -0.02568085,
        -0.0006596665,
        -0.013312933,
        -0.02342462,
        0.0026253765,
        -0.0040340433,
        -0.007406574,
        -0.04519546,
        -0.00050056394,
        -0.0035408621,
        -0.0046453513,
        -0.058307577,
        -0.012899488,
        -0.003405016,
        -0.010312502,
        0.0048786523,
        0.017317444,
        -0.038651213,
        -0.053535238,
        0.0043559396,
        0.008770943,
        -0.005714402,
        0.0011930845,
        0.028067017,
        0.0009819322,
        0.001484711,
        -0.029413667,
        -0.045455337,
        -0.009284796,
        -0.02794889,
        0.02233785,
        0.012663233,
        0.012627795,
        -0.03317011,
        0.0056671514,
        0.057268057,
        -0.018569592,
        -0.04984967,
        -0.04273841,
        0.014529643,
        -0.0037298657,
        -0.03350087,
        -0.046660237,
        0.031799838,
        0.0114465235,
        -0.048479393,
        -0.013029428,
        -0.01630155,
        -0.00047435446,
        0.020270623,
        -0.019325607,
        -0.004488833,
        -0.04155714,
        0.03498927,
        0.010377472,
        0.011328396,
        0.0049761073,
        0.013750004,
        -0.026153358,
        -0.014222512,
        0.0311147,
        0.016277926,
        -0.0075128884,
        -0.016407864,
        -0.013501937,
        0.023530934,
        0.0021292423,
        0.043541677,
        0.030642191,
        -0.03328824,
        -0.03002793,
        -0.02660224,
        0.007908614,
        0.021286517,
        -0.013537374,
        0.0027435038,
        0.015899919,
        0.013407434,
        -0.005463382,
        0.010011278,
        0.0149312755,
        -0.02924829,
        -0.04115551,
        0.008369311,
        -0.031847086,
        0.0072175707,
        -0.01907754,
        0.022574104,
        0.026838494,
        0.010271158,
        -0.0008844772,
        0.016419677,
        -0.032744855,
        0.017199317,
        0.025657224,
        -0.008038554,
        -0.008133057,
        -0.011836343,
        0.011730029,
        -0.025184715,
        -0.010525132,
        0.005959516,
        -0.017872643,
        -0.020436002,
        0.010218001,
        -0.002832099,
        0.007967678,
        0.024546828,
        -5.511256e-06,
        0.031161949,
        0.021782652,
        -0.004689649,
        0.02199528,
        0.03168171,
        0.01630155,
        0.0203415,
        0.024428701,
        0.0054840543,
        0.004725087,
        0.026625866,
        0.0036767083,
        -0.0071644136,
        -0.0025102026,
        -0.01099764,
        0.042927418,
        -0.01490765,
        -0.020246997,
        -0.017329257,
        0.007908614,
        0.029838925,
        -0.039052844,
        0.06856102,
        0.0047841505,
        -0.011204363,
        -0.006532433,
        0.01521478,
        -0.012108035,
        0.009337953,
        0.026460487,
        0.032555852,
        0.0015504193,
        0.022845797,
        -0.026814869,
        -0.00082762854,
        -0.003635364,
        0.03265035,
        -0.011913126,
        0.0062253023,
        -0.012675046,
        0.041320886,
        -0.020057995,
        0.0071526007,
        -0.024003442,
        0.012237975,
        -0.00095018547,
        -0.0113815535,
        0.012001721,
        -0.01643149,
        -0.011233895,
        -0.010914952,
        -0.010005372,
        -0.054291252,
        0.0036914744,
        -0.002616517,
        0.006006767,
        -0.0299098,
        -0.01760095,
        0.004228953,
        -0.0086646285,
        -0.01330112,
        -0.01777814,
        0.03172896,
        -0.050085925,
        0.06615122,
        0.0093674855,
        -0.02490121,
        0.02520834,
        0.0033636715,
        0.013667314,
        0.018959412,
        0.005501773,
        0.030902069,
        -0.002451139,
        -0.011759561,
        0.008971759,
        0.004199421,
        0.03239047,
        0.006798219,
        -0.0124742305,
        -0.05093644,
        0.0067805,
        -0.0028734435,
        -0.003292795,
        0.00048321398,
        -0.008044461,
        -0.0077077984,
        -0.039737985,
        0.028326897,
        -0.02011706,
        0.040588498,
        -0.02199528,
        0.021262892,
        0.009609646,
        -0.03376075,
        0.013750004,
        0.045478962,
        0.00020967574,
        0.030287808,
        0.024452327,
        0.020140683,
        -0.03368987,
        0.047014616,
        0.024405075,
        0.00945608,
        0.00965099,
        0.022361474,
        0.015462847,
        -0.013785441,
        -0.0131239295,
        -0.014765898,
        0.004125592,
        -0.021310143,
        0.0023492542,
        0.023719937,
        -0.012167099,
        -0.0056021814,
        0.0113165835,
        -0.0003560427,
        -0.026176983,
        0.0025426876,
        0.002609134,
        0.018475091,
        -0.01734107,
        -0.024948461,
        0.023141114,
        -0.039359976,
        -0.033193737,
        -0.027665386,
        0.0069458783,
        -0.032036092,
        0.010790918,
        -0.011936751,
        -0.029933427,
        0.006514714,
        -0.015569163,
        -0.00011222082,
        0.027311003,
        0.019632736,
        -0.04384881,
        0.03239047,
        -0.01138746,
        0.016502367,
        -0.012403354,
        -0.032154217,
        0.017896267,
        -0.01395082,
        -0.038485836,
        -0.014128011,
        0.046093225,
        0.031539958,
        -0.005897499,
        -0.0016774059,
        0.038651213,
        -0.01825065,
        0.024830332,
        0.027783513,
        -0.023188366,
        -0.017506449,
        0.009048542,
        -0.02246779,
        0.006479276,
        -0.04554984,
        0.016726809,
        -0.02464133,
        0.015380159,
        0.03286298,
        0.023672687,
        -0.009822275,
        -0.019290168,
        -0.012781361,
        -0.0009317281,
        0.010873606,
        -0.0029280775,
        -0.039619856,
        -0.024145195,
        0.011535119,
        0.005661245,
        -0.036926556,
        -0.026011605,
        -0.012096223,
        -0.0156046,
        0.008841819,
        -0.00016814665,
        -0.012497855,
        0.035627156,
        0.006544246,
        -0.0016153891,
        -0.0008933368,
        0.02608248,
        -0.0060835495,
        -0.060953625,
        0.0071939453,
        0.0149312755,
        -0.009786837,
        -0.009095793,
        -0.012757735,
        0.035957914,
        0.03442226,
        -0.0036619424,
        0.012521481,
        -0.0115174,
        0.016348802,
        0.03338274,
        0.018935787,
        -0.011145299,
        0.020636817,
        -0.032484975,
        0.025279216,
        0.01907754,
        -0.0392891,
        0.0033223268,
        -0.013608251,
        0.008983572,
        0.005416131,
        -0.012958552,
        -0.02603523,
        -0.052968226,
        -0.011499681,
        -0.011741841,
        0.02551547,
        -0.012367915,
        0.022704044,
        -0.004471114,
        0.006697811,
        0.02399163,
        -0.00012449497,
        -0.028563151,
        0.017482823,
        -0.0054722414,
        0.03317011,
        0.0077845813,
        -0.015817229,
        0.0047959634,
        -0.028279647,
        0.03886384,
        -0.031776212,
        -0.0071289754,
        0.0032868888,
        0.014824961,
        0.012438792,
        0.019065727,
        0.021109328,
        -0.06496995,
        0.033784375,
        0.0038538992,
        -0.009267077,
        -0.0048520737,
        -0.012285227,
        0.023365555,
        -0.012946739,
        0.030736692,
        -0.004908184,
        -0.02408613,
        0.03333549,
        0.021286517,
        -0.013336559,
        0.01369094,
        0.010920858,
        0.070781805,
        0.0055933218,
        -0.0132538695,
        0.006567871,
        0.027523633,
        0.017187504,
        -0.033737123,
        -0.008097618,
        0.017045751,
        -0.032059718,
        -0.016088922,
        0.028019767,
        -0.00562876,
        -0.008422468,
        0.008475625,
        0.006319804,
        -0.023708126,
        0.008676441,
        -0.0010151555,
        0.009792743,
        -0.0022591823,
        0.01138746,
        0.0078849895,
        -0.03220147,
        0.009284796,
        -0.0325086,
        0.0014256474,
        -0.011765467,
        -0.015710915,
        0.031539958,
        -0.015415597,
        -0.01917204,
        -0.005185783,
        0.01203716,
        -0.008020835,
        0.018711345,
        0.008570127,
        -0.0014884025,
        0.014104385,
        0.014305201,
        -0.017766329,
        0.0038273206,
        -0.03555628,
        -0.008918602,
        -0.025231965,
        -0.0015533724,
        -0.028775781,
        0.017884456,
        0.011233895,
        0.02051869,
        0.00825709,
        -0.00026947763,
        0.0064733694,
        -0.025113838,
        -0.023105675,
        0.0060215327,
        0.035485405,
        0.05580328,
        -0.03376075,
        0.02225516,
        -0.014730459,
        -0.01799077,
        -0.005740981,
        0.03234322,
        0.030122431,
        -0.013608251,
        -0.011216176,
        -0.013643689,
        -0.01555735,
        0.035957914,
        -0.0378952,
        0.0005518754,
        -0.008056274,
        -0.0312092,
        0.039218225,
        0.0004824757,
        -0.002594368,
        0.028586777,
        0.02768901,
        -0.03893472,
        -0.013371997,
        0.01995168,
        -0.0007497384,
        0.0048136828,
        -0.030051554,
        -0.0103420345,
        0.03333549,
        0.02011706,
        -0.042407658,
        0.012450605,
        -0.0115764635,
        0.037871573,
        0.029484544,
        0.033264615,
        -0.03454039,
        -0.014281576,
        -0.006302085,
        -0.008345685,
        -0.0013104734,
        0.023779001,
        -0.013112117,
        0.0060481117,
        0.0073002595,
        0.021900779,
        -0.038887467,
        0.03586341,
        -0.001266914,
        0.00939111,
        -0.038698465,
        -0.038107827,
        0.041628018,
        -0.009591927,
        0.021262892,
        -0.035131022,
        -0.03834408,
        0.05202321,
        0.039430853,
        0.046164103,
        -0.00684547,
        -0.006449744,
        0.026814869,
        -0.0049140905,
        0.0095742075,
        0.010820449,
        -0.026885746,
        0.019018475,
        -0.0034404541,
        0.044604823,
        -0.031445455,
        0.012391541,
        0.0023728798,
        -0.0107318545,
        0.040493995,
        -0.009904964,
        0.040210493,
        0.013868131,
        0.007648735,
        -0.03586341,
        -0.015273844,
        0.023353742,
        -0.038013328,
        0.00052566594,
        0.018664094,
        0.03317011,
        -0.0487629,
        -0.0016877421,
        0.020069808,
        -0.011930845,
        0.038273204,
        -0.011694591,
        0.021510959,
        -0.026389612,
        -0.023956193,
        -0.043045543,
        0.0189476,
        -0.01273411,
        -0.007471544,
        -0.0058502485,
        0.021381019,
        -0.0056701046,
        -0.023365555,
        -0.029460918,
        -0.011600089,
        0.023956193,
        0.027169252,
        0.0047428063,
        -0.030807568,
        0.0016360615,
        0.028445024,
        0.019136602,
        0.021239266,
        -0.0017792906,
        0.010093967,
        -0.020695882,
        -0.014919463,
        0.008546501,
        0.009904964,
        -0.0049465755,
        0.007914521,
        0.0075778584,
        -0.025326466,
        0.019668175,
        0.015380159,
        -0.0077963937,
        0.031917963,
        -0.043494426,
        0.008617378,
        -0.0027435038,
        0.016136173,
        -0.006154426,
        0.025798976,
        -0.009095793,
        0.03272123,
        -0.017045751,
        0.039950613,
        0.014789523,
        -0.004438629,
        0.017069377,
        -0.010802731,
        0.01917204,
        0.043754306,
        0.0044740667,
        -0.014884025,
        -0.018463278,
        -0.028374149,
        0.015935356,
        -0.0015238406,
        0.010885419,
        0.012757735,
        -0.03763532,
        0.016159797,
        -0.004509505,
        -0.009491519,
        0.042573035,
        0.021629086,
        0.0018457372,
        -0.017955331,
        0.005492914,
        0.00053600204,
        -0.015840854,
        0.016525993,
        0.015817229,
        0.026436863,
        -0.00071799173,
        0.007501076,
        -0.013289307,
        0.0049052313,
        -0.008587846,
        -0.019006664,
        0.00035032092,
        0.027878014,
        0.000793667,
        0.0217354,
        0.0011701974,
        0.0064438377,
        0.0014795429,
        -0.0017408993,
        0.00014636696,
        0.034800265,
        -0.02051869,
        -0.0114465235,
        0.033737123,
        0.027122,
        -0.010028997,
        -0.023708126,
        -0.0063257106,
        0.012686859,
        0.01638424,
        -0.006003814,
        -0.0029162648,
        -0.015309283,
        0.016844936,
        -0.001497262,
        -0.008971759,
        -0.0093674855,
        -0.00045958854,
        0.021227455,
        -0.026484113,
        0.026696742,
        0.030783942,
        0.008369311,
        0.027996141,
        -0.030878445,
        -0.0038125548,
        0.013974445,
        0.03342999,
        -0.027736261,
        0.03704468,
        0.013655501,
        -0.040281367,
        -0.00030140887,
        0.023885315,
        0.019963494,
        0.005971329,
        -0.021227455,
        0.011960377,
        -0.030736692,
        0.006792313,
        0.016502367,
        -0.046093225,
        0.03291023,
        0.01825065,
        -0.013194806,
        0.014340639,
        0.001164291,
        0.0077963937,
        -0.014009884,
        0.024062507,
        -0.00091843883,
        -0.006059924,
        0.038367707,
        -0.024972085,
        0.005168064,
        -0.020743132,
        -0.015569163,
        -0.03312286,
        -0.009397017,
        -0.026578614,
        -0.0057823253,
        -0.007967678,
        -0.03924185,
        -0.0148013355,
        0.00658559,
        -0.031091074,
        0.013702753,
        -0.02516109,
        0.02407432,
        0.028870283,
        -0.012090317,
        0.0140335085,
        0.004618773,
        -0.022302411,
        -0.017849017,
        -0.013312933,
        0.013561,
        0.006166239,
        0.01838059,
        -0.03456401,
        -0.02499571,
        0.0059772353,
        0.011836343,
        -0.019798115,
        0.009981747,
        0.007979491,
        0.0063552423,
        -0.01004081,
        0.010920858,
        -3.4238423e-05,
        0.0008940751,
        -0.025917104,
        0.0062371152,
        -0.0162543,
        0.04325817,
        0.013572813,
        0.0010424723,
        0.021109328,
        0.032957483,
        0.014317014,
        0.017317444,
        -0.0015253172,
        0.0034788453,
        -0.0021085702,
        -0.043187298,
        -0.03307561,
        -0.01852234,
        -0.011133486,
        0.017270194,
        0.002767129,
        0.023176553,
        0.04377793,
        0.01851053,
        0.042762037,
        -0.030902069,
        -0.011800905,
        0.039218225,
        0.008906789,
        -0.0189476,
        -0.0045656157,
        -0.020176122,
        0.009656897,
        -0.031445455,
        0.038698465,
        0.02525559,
        -0.004544943,
        -0.0060008606,
        -0.022727668,
        -0.026814869,
        -0.01891216,
        0.0024496624,
        -0.030146057,
        0.013454686,
        0.009013103,
        0.012639608,
        0.037469942,
        0.006372961,
        0.013667314,
        -0.004459301,
        0.0023226757,
        0.019715426,
        0.013868131,
        -0.0037771165,
        0.004016324,
        0.0008645433,
        -0.037517194,
        0.01503759,
        0.004887512,
        -0.007489263,
        -0.013088492,
        0.013289307
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 188.82791757583618,
        "patch_type": "full",
        "api_costs": 0.249224,
        "num_applied": 1,
        "patch_name": "partition_refinement_v1",
        "patch_description": "Improved balanced packing algorithm with the following optimizations:\n1.  **Iterative Pairwise Refinement**: The core logic repeatedly selects the heaviest pack and pairs it with other packs to offload weight. It uses a pruning strategy to skip pairs that cannot possibly beat the best found move.\n2.  **Hybrid Pairwise Solver**: Uses an exact brute-force solver for small pool sizes ($2K \\le 14$) and a robust randomized greedy + swap heuristic for larger pools. The heuristic trials are increased for better quality.\n3.  **Multi-Start Strategy**: Runs the packing algorithm multiple times (8 restarts) with randomized noise injection (Noisy LPT) to escape local optima.\n4.  **CPU Offloading**: All logic runs on CPU with standard Python lists/floats to avoid GPU kernel launch overheads for sequential scalar logic.\n5.  **Optimized \"Best Fit\" Logic**: The refinement strictly accepts moves that reduce the load of the target heavy pack, breaking ties by minimizing the partner's load deviation.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 1,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\npartition_refinement_v1\n</NAME>\n\n<DESCRIPTION>\nImproved balanced packing algorithm with the following optimizations:\n1.  **Iterative Pairwise Refinement**: The core logic repeatedly selects the heaviest pack and pairs it with other packs to offload weight. It uses a pruning strategy to skip pairs that cannot possibly beat the best found move.\n2.  **Hybrid Pairwise Solver**: Uses an exact brute-force solver for small pool sizes ($2K \\le 14$) and a robust randomized greedy + swap heuristic for larger pools. The heuristic trials are increased for better quality.\n3.  **Multi-Start Strategy**: Runs the packing algorithm multiple times (8 restarts) with randomized noise injection (Noisy LPT) to escape local optima.\n4.  **CPU Offloading**: All logic runs on CPU with standard Python lists/floats to avoid GPU kernel launch overheads for sequential scalar logic.\n5.  **Optimized \"Best Fit\" Logic**: The refinement strictly accepts moves that reduce the load of the target heavy pack, breaking ties by minimizing the partner's load deviation.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\nimport math\n\ndef solve_partition_exact(pool_weights: list[float], K: int, target_avg: float) -> tuple[float, list[int]]:\n    \"\"\"\n    Exact solver for partitioning pool_weights (size 2K) into two sets of size K\n    to minimize max(sum(A), sum(B)).\n    Returns (best_max_val, indices_A).\n    \"\"\"\n    n = len(pool_weights)\n    # Fix first element to A to reduce symmetry\n    # We want to choose K indices. We pick 0, then choose K-1 from remaining n-1.\n    \n    best_max = float('inf')\n    best_A = []\n    \n    total_sum = sum(pool_weights)\n    w0 = pool_weights[0]\n    indices_rest = list(range(1, n))\n    \n    for comb in itertools.combinations(indices_rest, K - 1):\n        # comb is tuple of K-1 indices\n        sum_A = w0\n        for idx in comb:\n            sum_A += pool_weights[idx]\n        \n        sum_B = total_sum - sum_A\n        current_max = max(sum_A, sum_B)\n        \n        if current_max < best_max:\n            best_max = current_max\n            best_A = [0] + list(comb)\n            if abs(current_max - target_avg) < 1e-6:\n                return best_max, best_A\n                \n    return best_max, best_A\n\ndef solve_partition_heuristic(pool_weights: list[float], K: int, trials: int) -> tuple[float, list[int]]:\n    \"\"\"\n    Heuristic solver for partitioning pool_weights into two sets of size K.\n    \"\"\"\n    n = len(pool_weights)\n    indices = list(range(n))\n    best_max = float('inf')\n    best_A = list(range(K))\n    \n    # 1. Randomized Greedy + Swap\n    for _ in range(trials):\n        # Randomize order\n        random.shuffle(indices)\n        \n        # Initial split\n        idx_A = indices[:K]\n        idx_B = indices[K:]\n        \n        sum_A = sum(pool_weights[i] for i in idx_A)\n        sum_B = sum(pool_weights[i] for i in idx_B)\n        \n        # Local Swap Optimization (Hill Climbing)\n        improved = True\n        while improved:\n            improved = False\n            curr_max = max(sum_A, sum_B)\n            \n            # Simple O(K^2) search for best swap\n            best_swap = None\n            best_swap_gain = 0.0\n            \n            # Optimization: Only look for swaps that reduce the max\n            for i in range(K):\n                u = idx_A[i]\n                w_u = pool_weights[u]\n                for j in range(K):\n                    v = idx_B[j]\n                    w_v = pool_weights[v]\n                    \n                    delta = w_u - w_v\n                    \n                    # New sums\n                    new_A = sum_A - delta\n                    new_B = sum_B + delta\n                    new_max = max(new_A, new_B)\n                    \n                    if new_max < curr_max - 1e-6:\n                        gain = curr_max - new_max\n                        if gain > best_swap_gain:\n                            best_swap_gain = gain\n                            best_swap = (i, j, delta)\n            \n            if best_swap:\n                i, j, delta = best_swap\n                # Swap indices\n                tmp = idx_A[i]\n                idx_A[i] = idx_B[j]\n                idx_B[j] = tmp\n                sum_A -= delta\n                sum_B += delta\n                improved = True\n        \n        final_max = max(sum_A, sum_B)\n        if final_max < best_max:\n            best_max = final_max\n            best_A = list(idx_A)\n            \n    return best_max, best_A\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Parameters\n    num_restarts = 8  # Increased restarts\n    max_refine_steps = 20\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Noisy LPT\n                # Noise range [0.9, 1.1]\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n            \n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Find pack with min weight that has space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n                \n            # 2. Refinement Loop\n            for _ in range(max_refine_steps):\n                # Identify Max Pack\n                max_p = 0\n                max_val = pack_weights[0]\n                min_val = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    if pack_weights[p] > max_val:\n                        max_val = pack_weights[p]\n                        max_p = p\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                \n                if max_val - min_val < 1e-6:\n                    break\n                    \n                best_move = None\n                # We want to reduce max_val.\n                # Current best improvement starts at 0 (or slightly negative tolerance)\n                best_new_max = max_val\n                \n                # Try pairing max_p with every other pack\n                # Sorting candidates by weight (lightest first) is a good heuristic\n                candidates = sorted([p for p in range(num_packs) if p != max_p], \n                                    key=pack_weights.__getitem__)\n                                    \n                for other_p in candidates:\n                    other_val = pack_weights[other_p]\n                    target_avg = (max_val + other_val) / 2.0\n                    \n                    # If perfect balancing of this pair doesn't improve upon our best found move, skip.\n                    # We want new_max < best_new_max.\n                    # Best possible new_max for this pair is target_avg.\n                    if target_avg >= best_new_max - 1e-6:\n                        continue\n                        \n                    # Prepare Pool\n                    pool_indices = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool_indices]\n                    pool_len = len(pool_indices)\n                    K = groups_per_pack\n                    \n                    # Solve Partition\n                    if pool_len <= 14:\n                        local_max, idx_A_local = solve_partition_exact(pool_weights, K, target_avg)\n                    else:\n                        local_max, idx_A_local = solve_partition_heuristic(pool_weights, K, trials=20)\n                    \n                    # Check if this result improves the global situation (reduces max_p)\n                    # Note: local_max is the max(new_p1, new_p2). \n                    # We are guaranteed local_max <= max_val because we can always keep original.\n                    if local_max < best_new_max - 1e-6:\n                        best_new_max = local_max\n                        \n                        # Reconstruct items\n                        # idx_A_local are indices into pool_indices\n                        items_A = [pool_indices[i] for i in idx_A_local]\n                        \n                        # items_B are the rest\n                        set_A = set(idx_A_local)\n                        items_B = [pool_indices[i] for i in range(pool_len) if i not in set_A]\n                        \n                        # Recalculate exact sums to avoid float drift\n                        w_A = sum(row_weight_list[x] for x in items_A)\n                        w_B = sum(row_weight_list[x] for x in items_B)\n                        \n                        best_move = (other_p, items_A, items_B, w_A, w_B)\n                        \n                        # If we hit the theoretical limit, stop searching\n                        if abs(local_max - target_avg) < 1e-6:\n                            break\n                            \n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    # No improvement possible for max_p\n                    break\n            \n            # Check Result\n            current_max = max(pack_weights)\n            current_min = min(pack_weights)\n            current_diff = current_max - current_min\n            \n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill Output\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Track current load per replica: weight / count\n    current_scores = weight.clone()\n\n    for i in range(num_log, num_phy):\n        # Greedily split the expert with the highest average load per replica\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n```\n</CODE>",
          "msg": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: move to CPU and convert to list once\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.full(weight.shape,\n                            -1,\n                            dtype=torch.int64,\n                            device=\"cpu\")\n    rank_in_pack = torch.full(weight.shape,\n                              -1,\n                              dtype=torch.int64,\n                              device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n\n        # 1. Greedy packing\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Iterative Pairwise Swapping\n        # We iterate to constantly reduce the load of the heaviest packs.\n        # We restart the search after every swap to ensure we are always\n        # addressing the largest imbalances (Greedy Hill Climbing).\n        for _ in range(100):\n            found_improvement = False\n            # Sort packs by weight descending\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n\n            # Try to offload from heaviest packs to lighter packs\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n\n                # Compare p1 against all lighter packs, starting from the lightest\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6:\n                        # If difference is negligible, no swap can help (and subsequent packs are closer)\n                        break\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Find best swap (u in p1, v in p2) to close the gap\n                    # We want w_u - w_v approx target\n                    for idx_u, u in enumerate(current_packs[p1]):\n                        w_u = row_weight[u]\n                        for idx_v, v in enumerate(current_packs[p2]):\n                            w_v = row_weight[v]\n                            delta = w_u - w_v\n\n                            # Only consider swaps that strictly reduce the gap\n                            # (w_u > w_v) and don't overshoot excessively (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (idx_u, idx_v, delta)\n                                    if gap < 1e-6: break # Perfect swap\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta = best_swap\n                        u = current_packs[p1][idx_u]\n                        v = current_packs[p2][idx_v]\n\n                        current_packs[p1][idx_u] = v\n                        current_packs[p2][idx_v] = u\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n\n                if found_improvement:\n                    break # Restart outer loop (resort packs)\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 3\n    max_refine_steps = 25\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max pack\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                max_val = pack_weights[max_p]\n\n                min_val = min(pack_weights)\n                if max_val - min_val < 1e-6:\n                    break\n\n                best_move = None\n                best_move_improvement = -1.0\n\n                candidate_packs = [p for p in range(num_packs) if p != max_p]\n                # Sort candidates by weight: testing lightest first often helps move most weight\n                candidate_packs.sort(key=pack_weights.__getitem__)\n\n                for other_p in candidate_packs:\n                    other_val = pack_weights[other_p]\n\n                    # Target is average of the pair\n                    avg = (max_val + other_val) / 2.0\n                    potential_reduction = max_val - avg\n\n                    if potential_reduction < best_move_improvement + 1e-6:\n                        continue\n\n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n\n                    K = groups_per_pack\n                    pool_len = 2 * K\n\n                    best_local_set_A = None\n                    best_local_max = float('inf')\n\n                    # EXACT SOLVER for small K\n                    if pool_len <= 14:\n                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n                         indices_rest = list(range(1, pool_len))\n                         w_0 = pool_weights[0]\n\n                         for comb in itertools.combinations(indices_rest, K - 1):\n                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n                             other_w = (max_val + other_val) - current_w\n                             local_max = max(current_w, other_w)\n\n                             if local_max < best_local_max:\n                                 best_local_max = local_max\n                                 best_local_set_A = [0] + list(comb)\n                                 if abs(local_max - avg) < 1e-5:\n                                     break\n                    else:\n                        # Heuristic Solver\n                        pool_indices = list(range(pool_len))\n                        sub_trials = 10\n                        for sub in range(sub_trials):\n                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n\n                            w1, w2 = 0.0, 0.0\n                            c1, c2 = 0, 0\n                            s1, s2 = [], []\n\n                            for idx in sorted_idx:\n                                w = pool_weights[idx]\n                                if c1 < K and c2 < K:\n                                    if w1 <= w2:\n                                        w1 += w; c1 += 1; s1.append(idx)\n                                    else:\n                                        w2 += w; c2 += 1; s2.append(idx)\n                                elif c1 < K:\n                                    w1 += w; c1 += 1; s1.append(idx)\n                                else:\n                                    w2 += w; c2 += 1; s2.append(idx)\n\n                            # Swap Local Search\n                            while True:\n                                improved_swap = False\n                                current_max = max(w1, w2)\n                                for i1, idx1 in enumerate(s1):\n                                    for i2, idx2 in enumerate(s2):\n                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n                                        nmax = max(nw1, nw2)\n                                        if nmax < current_max - 1e-6:\n                                            w1, w2 = nw1, nw2\n                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n                                            current_max = nmax\n                                            improved_swap = True\n                                            break\n                                    if improved_swap: break\n                                if not improved_swap: break\n\n                            if max(w1, w2) < best_local_max:\n                                best_local_max = max(w1, w2)\n                                best_local_set_A = list(s1)\n\n                    # Check improvement\n                    improvement = max_val - best_local_max\n                    if improvement > best_move_improvement + 1e-6:\n                        best_move_improvement = improvement\n                        set_A_indices = best_local_set_A\n                        set_A_set = set(set_A_indices)\n                        new_items_A = [pool[x] for x in set_A_indices]\n                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n                        # Calculate exact new weights to avoid drift\n                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n\n                        if abs(best_local_max - avg) < 1e-5:\n                             break\n\n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    break\n\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\nYou MUST respond using a short summary name, description and the full code:\n\n<NAME>\nA shortened name summarizing the code you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the code you are proposing.\n</DESCRIPTION>\n\n<CODE>\n```{language}\n# The new rewritten program here.\n```\n</CODE>\n\n* Keep the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the code. Do not change the code outside of these markers.\n* Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n* Make sure the file still runs after your changes.\n* Use the <NAME>, <DESCRIPTION>, and <CODE> delimiters to structure your response. It will be parsed afterwards.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n\n    # Optimization: Move weights to CPU to avoid slow element-wise GPU access\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n\n    for i in range(num_layers):\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n        row_weight = weight_cpu[i]\n\n        # 1. Greedy packing\n        for group in indices[i].tolist():\n            w = row_weight[group].item()\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Swap items between max-load and min-load packs\n        for _ in range(20):\n            min_p = min(range(num_packs), key=pack_weights.__getitem__)\n            max_p = max(range(num_packs), key=pack_weights.__getitem__)\n\n            if min_p == max_p:\n                break\n\n            diff = pack_weights[max_p] - pack_weights[min_p]\n            if diff < 1e-6:\n                break\n\n            best_swap = None\n            target = diff / 2.0\n            found_swap = False\n\n            # Try to swap item u from max_p with item v from min_p\n            # We look for a swap that reduces the diff (i.e., w_u > w_v)\n            for idx_u, u in enumerate(current_packs[max_p]):\n                w_u = row_weight[u].item()\n                for idx_v, v in enumerate(current_packs[min_p]):\n                    w_v = row_weight[v].item()\n\n                    delta = w_u - w_v\n                    if 0 < delta < diff:\n                        gap = abs(delta - target)\n                        if best_swap is None or gap < best_swap[0]:\n                            best_swap = (gap, idx_u, idx_v, delta)\n                            found_swap = True\n\n            if found_swap:\n                _, idx_u, idx_v, delta = best_swap\n                u = current_packs[max_p][idx_u]\n                v = current_packs[min_p][idx_v]\n\n                current_packs[max_p][idx_u] = v\n                current_packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport math\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Optimization: handle trivial case efficiently\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    # and convert to float32 for standard arithmetic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Sort items by weight descending for LPT (Longest Processing Time) heuristic\n    sorted_indices_all = torch.argsort(weight_cpu, dim=-1, descending=True)\n\n    for i in range(num_layers):\n        row_w = weight_cpu[i]\n        indices = sorted_indices_all[i].tolist()\n        # Convert to list for faster scalar access\n        row_w_list = row_w.tolist()\n\n        # Track packs and their current weights\n        packs = [[] for _ in range(num_packs)]\n        pack_weights = [0.0] * num_packs\n\n        # 1. Greedy Phase: Assign heaviest available item to the lightest valid pack\n        for idx in indices:\n            w = row_w_list[idx]\n            \n            # Find the pack with minimum weight that has space\n            best_p = -1\n            min_w = float('inf')\n            \n            for p in range(num_packs):\n                if len(packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_w:\n                        min_w = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n\n        # 2. Refinement Phase: Swap items between heaviest and lightest packs\n        # Iterate to reduce the spread (max_weight - min_weight)\n        for _ in range(20): # Fixed iteration limit for performance\n            # Find max and min loaded packs\n            min_p = 0\n            max_p = 0\n            min_val = pack_weights[0]\n            max_val = pack_weights[0]\n            \n            for p in range(1, num_packs):\n                val = pack_weights[p]\n                if val < min_val:\n                    min_val = val\n                    min_p = p\n                elif val > max_val:\n                    max_val = val\n                    max_p = p\n            \n            diff = max_val - min_val\n            if diff < 1e-6:\n                break\n            \n            target = diff / 2.0\n            best_swap = None\n            min_gap = diff\n            \n            # Try to swap item u from max_p with item v from min_p\n            # We want (w_u - w_v) to be approximately equal to target\n            p_max_indices = packs[max_p]\n            p_min_indices = packs[min_p]\n            \n            found_good_swap = False\n            \n            for idx_u, u in enumerate(p_max_indices):\n                w_u = row_w_list[u]\n                for idx_v, v in enumerate(p_min_indices):\n                    w_v = row_w_list[v]\n                    \n                    delta = w_u - w_v\n                    # Only consider swaps that move weight from max to min\n                    if delta > 0 and delta < diff:\n                        gap = abs(delta - target)\n                        if gap < min_gap:\n                            min_gap = gap\n                            best_swap = (idx_u, idx_v, delta)\n                            # Heuristic: if gap is very small, take it immediately\n                            if gap < 1e-4:\n                                found_good_swap = True\n                                break\n                if found_good_swap:\n                    break\n            \n            if best_swap:\n                idx_u, idx_v, delta = best_swap\n                u = packs[max_p][idx_u]\n                v = packs[min_p][idx_v]\n                \n                # Execute swap\n                packs[max_p][idx_u] = v\n                packs[min_p][idx_v] = u\n                pack_weights[max_p] -= delta\n                pack_weights[min_p] += delta\n            else:\n                # No beneficial swap found\n                break\n\n        # Write results to tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Optimization: perform sequential packing logic on CPU to avoid GPU overhead\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    \n    # Configuration for restarts\n    # 1 deterministic run + 2 randomized runs gave good balance/speed trade-off\n    num_restarts = 3 \n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base indices for deterministic LPT (sorted descending)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization Strategy\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add multiplicative noise to weights for sorting\n                # This alters the greedy assignment order slightly\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            # Assign items to the lightest pack that has space\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                \n                # Find best pack (min weight with capacity)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            # Iteratively swap items between heavy and light packs\n            for _ in range(20): # Iteration limit\n                # Sort packs by weight to easily pick heavy/light pairs\n                # We store indices to track which pack is which\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Try to move weight from heavier packs to lighter packs\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        # w_u from pack p1, w_v from pack p2\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loops to resort packs\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check if this is the best solution so far\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                # Deep copy current packing\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break # Optimal found\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Current score tracks weight / logcnt. \n    # Initialized as weight / 1.0\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores incrementally: new_score = weight / new_count\n        # Only update the experts that got a new replica\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimization: move to CPU and convert to list once\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    indices = weight_cpu.sort(-1, descending=True).indices.tolist()\n    weight_list = weight_cpu.tolist()\n\n    pack_index = torch.full(weight.shape,\n                            -1,\n                            dtype=torch.int64,\n                            device=\"cpu\")\n    rank_in_pack = torch.full(weight.shape,\n                              -1,\n                              dtype=torch.int64,\n                              device=\"cpu\")\n\n    for i in range(num_layers):\n        row_weight = weight_list[i]\n        pack_weights = [0.0] * num_packs\n        current_packs = [[] for _ in range(num_packs)]\n\n        # 1. Greedy packing\n        for group in indices[i]:\n            w = row_weight[group]\n            best_pack = -1\n            min_val = float('inf')\n            # Find the least loaded pack that has space\n            for p in range(num_packs):\n                if len(current_packs[p]) < groups_per_pack:\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                        best_pack = p\n            current_packs[best_pack].append(group)\n            pack_weights[best_pack] += w\n\n        # 2. Refinement: Iterative Pairwise Swapping\n        # We iterate to constantly reduce the load of the heaviest packs.\n        # We restart the search after every swap to ensure we are always\n        # addressing the largest imbalances (Greedy Hill Climbing).\n        for _ in range(100):\n            found_improvement = False\n            # Sort packs by weight descending\n            sorted_packs = sorted(range(num_packs),\n                                  key=pack_weights.__getitem__,\n                                  reverse=True)\n\n            # Try to offload from heaviest packs to lighter packs\n            for i1 in range(num_packs):\n                p1 = sorted_packs[i1]\n\n                # Compare p1 against all lighter packs, starting from the lightest\n                for i2 in range(num_packs - 1, i1, -1):\n                    p2 = sorted_packs[i2]\n\n                    diff = pack_weights[p1] - pack_weights[p2]\n                    if diff < 1e-6:\n                        # If difference is negligible, no swap can help (and subsequent packs are closer)\n                        break\n\n                    target = diff / 2.0\n                    best_swap = None\n                    best_gap = diff\n\n                    # Find best swap (u in p1, v in p2) to close the gap\n                    # We want w_u - w_v approx target\n                    for idx_u, u in enumerate(current_packs[p1]):\n                        w_u = row_weight[u]\n                        for idx_v, v in enumerate(current_packs[p2]):\n                            w_v = row_weight[v]\n                            delta = w_u - w_v\n\n                            # Only consider swaps that strictly reduce the gap\n                            # (w_u > w_v) and don't overshoot excessively (delta < diff)\n                            if 0 < delta < diff:\n                                gap = abs(delta - target)\n                                if gap < best_gap:\n                                    best_gap = gap\n                                    best_swap = (idx_u, idx_v, delta)\n                                    if gap < 1e-6: break # Perfect swap\n                        if best_swap and best_gap < 1e-6: break\n\n                    if best_swap:\n                        idx_u, idx_v, delta = best_swap\n                        u = current_packs[p1][idx_u]\n                        v = current_packs[p2][idx_v]\n\n                        current_packs[p1][idx_u] = v\n                        current_packs[p2][idx_v] = u\n                        pack_weights[p1] -= delta\n                        pack_weights[p2] += delta\n                        found_improvement = True\n                        break\n\n                if found_improvement:\n                    break # Restart outer loop (resort packs)\n\n            if not found_improvement:\n                break\n\n        # 3. Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(current_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    \n    # Pre-allocate result tensors\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Multi-start configuration\n    num_restarts = 3\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices (descending weight)\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                # Deterministic LPT\n                indices = base_indices\n            else:\n                # Randomized LPT: Add noise to weights to vary greedy placement\n                # Noise 0.9 ~ 1.1\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            # 2. Greedy Packing\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            for idx in indices:\n                w = row_weight_list[idx]\n                \n                # Find best pack (lightest with space)\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                            \n                current_packs[best_p].append(idx)\n                pack_weights[best_p] += w\n\n            # 3. Refinement Phase (Local Search)\n            for _ in range(20): # Max iterations\n                # Sort packs by weight\n                sorted_pack_indices = sorted(range(num_packs), \n                                             key=pack_weights.__getitem__, \n                                             reverse=True)\n                \n                found_swap = False\n                \n                # Iterate through pairs of packs: Heavier vs Lighter\n                for i1 in range(num_packs):\n                    p1 = sorted_pack_indices[i1]\n                    for i2 in range(num_packs - 1, i1, -1):\n                        p2 = sorted_pack_indices[i2]\n                        \n                        diff = pack_weights[p1] - pack_weights[p2]\n                        if diff < 1e-6:\n                            break # Gap too small to matter\n                        \n                        target = diff / 2.0\n                        best_swap = None\n                        best_gap = diff\n                        \n                        # Find swap (u, v) such that w_u - w_v is close to target\n                        for idx_u, u in enumerate(current_packs[p1]):\n                            w_u = row_weight_list[u]\n                            for idx_v, v in enumerate(current_packs[p2]):\n                                w_v = row_weight_list[v]\n                                \n                                delta = w_u - w_v\n                                if 0 < delta < diff:\n                                    gap = abs(delta - target)\n                                    if gap < best_gap:\n                                        best_gap = gap\n                                        best_swap = (idx_u, idx_v, delta)\n                                        if gap < 1e-5: break\n                            if best_swap and best_gap < 1e-5: break\n                        \n                        if best_swap:\n                            idx_u, idx_v, delta = best_swap\n                            u = current_packs[p1][idx_u]\n                            v = current_packs[p2][idx_v]\n                            \n                            current_packs[p1][idx_u] = v\n                            current_packs[p2][idx_v] = u\n                            pack_weights[p1] -= delta\n                            pack_weights[p2] += delta\n                            found_swap = True\n                            break # Break inner loop to re-sort\n                    if found_swap: break\n                \n                if not found_swap:\n                    break\n\n            # 4. Check global best for this layer\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        # Fill result tensors\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Optimization: Maintain current scores (weight / logcnt) \n    # to avoid repetitive full tensor operations\n    current_scores = weight.clone().float()\n    \n    for i in range(num_log, num_phy):\n        # Find expert with max current average load\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update counts\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores only for changed experts\n        selected_weights = weight[arangen, redundant_indices].float()\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int, \n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n\n\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for scalar efficiency\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Hyperparameters\n    num_restarts = 4\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Original indices sorted by weight descending\n        # We use a stable sort or just standard sort\n        # items: list of (index, weight)\n        original_items = []\n        for idx in range(num_groups):\n            original_items.append((idx, row_weight[idx].item()))\n        \n        # Sort descending\n        original_items.sort(key=lambda x: x[1], reverse=True)\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                # Deterministic Snake/ZigZag Packing\n                # Distributes high/low weights evenly\n                for k, (idx, w) in enumerate(original_items):\n                    # Zig-zag logic\n                    # 0, 1, 2, ..., M-1, M-1, ..., 2, 1, 0\n                    cycle_pos = k % (2 * num_packs)\n                    if cycle_pos < num_packs:\n                        p = cycle_pos\n                    else:\n                        p = (2 * num_packs - 1) - cycle_pos\n                    \n                    current_packs[p].append((idx, w))\n                    pack_weights[p] += w\n            else:\n                # Randomized Greedy\n                # Shuffle items slightly by adding noise to sorting key\n                # Re-sort based on noisy weights\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # 0.95 to 1.05\n                noisy_items = []\n                for k, (idx, w) in enumerate(original_items):\n                    noisy_items.append((idx, w, w * noise[k].item()))\n                noisy_items.sort(key=lambda x: x[2], reverse=True)\n                \n                # Simple Greedy: Min-Load\n                # Just fill in order\n                for idx, w, _ in noisy_items:\n                    # Find pack with min weight that has capacity\n                    best_p = -1\n                    min_w = float('inf')\n                    for p in range(num_packs):\n                        if len(current_packs[p]) < groups_per_pack:\n                            if pack_weights[p] < min_w:\n                                min_w = pack_weights[p]\n                                best_p = p\n                    current_packs[best_p].append((idx, w))\n                    pack_weights[best_p] += w\n\n            # 2. Refinement Loop\n            # We want to minimize the Makespan (Max Load).\n            # Strategy: Repeatedly take the Heaviest Pack and try to offload to lighter packs.\n            \n            # Optimization: keep packs somewhat sorted or just identify Max/Min\n            for _ in range(25): # Iterations\n                # Find Max Pack\n                max_p = 0\n                max_w = pack_weights[0]\n                min_p = 0\n                min_w = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    w = pack_weights[p]\n                    if w > max_w:\n                        max_w = w\n                        max_p = p\n                    if w < min_w:\n                        min_w = w\n                        min_p = p\n                \n                diff_global = max_w - min_w\n                if diff_global < 1e-6:\n                    break\n                \n                # If we've improved beyond best, save immediately (optional, but we do it at end of restart)\n                \n                # Attempt to swap items from max_p with items from other packs\n                # We prioritize swapping with the lightest packs to maximize 'headroom'\n                # But any pack p_other where we can swap (u, v) such that:\n                # new_max < current_max and new_other < current_max is valid.\n                \n                # Sort other packs by weight ascending (lightest first)\n                other_packs = sorted([p for p in range(num_packs) if p != max_p], \n                                     key=pack_weights.__getitem__)\n                \n                swap_executed = False\n                \n                for p_other in other_packs:\n                    w_other = pack_weights[p_other]\n                    # Allowed gap: we can transfer at most (max_w - w_other)\n                    # Ideally we transfer (max_w - w_other) / 2\n                    \n                    gap = max_w - w_other\n                    if gap < 1e-6: continue\n                    \n                    target = gap / 2.0\n                    \n                    best_swap = None\n                    best_dev = float('inf') # Deviation from target\n                    \n                    # Search for u in max_p, v in p_other\n                    # delta = w_u - w_v\n                    # We want delta > 0 and delta < gap (strictly, to ensure max_p decreases and p_other doesn't exceed old max_p)\n                    # Actually, to guarantee max_p reduces, we just need delta > 0.\n                    # But we must ensure p_other + delta < max_p.\n                    \n                    p_max_items = current_packs[max_p]\n                    p_other_items = current_packs[p_other]\n                    \n                    for i_u, (idx_u, w_u) in enumerate(p_max_items):\n                        for i_v, (idx_v, w_v) in enumerate(p_other_items):\n                            delta = w_u - w_v\n                            if delta > 0 and delta < gap:\n                                # This swap is valid (reduces max, doesn't create new max >= old max)\n                                # How good is it? Closer to target is better for balance.\n                                dev = abs(delta - target)\n                                if dev < best_dev:\n                                    best_dev = dev\n                                    best_swap = (i_u, i_v, delta, idx_u, w_u, idx_v, w_v)\n                                    if dev < 1e-5: break # Perfect\n                        if best_swap and best_dev < 1e-5: break\n                    \n                    if best_swap:\n                        i_u, i_v, delta, idx_u, w_u, idx_v, w_v = best_swap\n                        \n                        # Execute Swap\n                        current_packs[max_p][i_u] = (idx_v, w_v)\n                        current_packs[p_other][i_v] = (idx_u, w_u)\n                        pack_weights[max_p] -= delta\n                        pack_weights[p_other] += delta\n                        \n                        swap_executed = True\n                        break # Break inner loop to re-evaluate Max Pack\n                \n                if not swap_executed:\n                    # If we couldn't swap with any pack to reduce Max,\n                    # we are in a local optimum w.r.t 1-item swaps from Max.\n                    # Stop this restart.\n                    break\n\n            # Evaluate this restart\n            curr_max = max(pack_weights)\n            curr_min = min(pack_weights)\n            curr_diff = curr_max - curr_min\n            \n            if curr_diff < best_diff:\n                best_diff = curr_diff\n                best_packs = [list(p) for p in current_packs] # Deep copy\n                if best_diff < 1e-6:\n                    break\n\n        # Write result\n        for p in range(num_packs):\n            for r, (idx, _) in enumerate(best_packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    \n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Maintain running scores to speed up max selection\n    # Score = weight / count\n    current_scores = weight.clone() # Float copy\n    \n    for i in range(num_log, num_phy):\n        # Select expert with max load/replica\n        redundant_indices = current_scores.max(dim=-1).indices\n        \n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Update state\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Incremental score update\n        # Only update the modified indices\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to \npropose a new program with the same inputs and outputs as the original \nprogram, but with improved internal implementation):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing for complex sequential logic\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Heuristic parameters\n    num_restarts = 3\n    max_refine_steps = 25\n\n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n\n        best_diff = float('inf')\n        best_packs = None\n\n        # Base indices for deterministic LPT\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n\n        for attempt in range(num_restarts):\n            # 1. Initialization\n            if attempt == 0:\n                indices = base_indices\n            else:\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.15 + 0.925\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n\n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n\n            # 2. Refinement Phase\n            for step in range(max_refine_steps):\n                # Identify max pack\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                max_val = pack_weights[max_p]\n\n                min_val = min(pack_weights)\n                if max_val - min_val < 1e-6:\n                    break\n\n                best_move = None\n                best_move_improvement = -1.0\n\n                candidate_packs = [p for p in range(num_packs) if p != max_p]\n                # Sort candidates by weight: testing lightest first often helps move most weight\n                candidate_packs.sort(key=pack_weights.__getitem__)\n\n                for other_p in candidate_packs:\n                    other_val = pack_weights[other_p]\n\n                    # Target is average of the pair\n                    avg = (max_val + other_val) / 2.0\n                    potential_reduction = max_val - avg\n\n                    if potential_reduction < best_move_improvement + 1e-6:\n                        continue\n\n                    pool = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool]\n\n                    K = groups_per_pack\n                    pool_len = 2 * K\n\n                    best_local_set_A = None\n                    best_local_max = float('inf')\n\n                    # EXACT SOLVER for small K\n                    if pool_len <= 14:\n                         # Fix first element of pool to Set A to reduce symmetry (13 choose 6 vs 14 choose 7)\n                         indices_rest = list(range(1, pool_len))\n                         w_0 = pool_weights[0]\n\n                         for comb in itertools.combinations(indices_rest, K - 1):\n                             current_w = w_0 + sum(pool_weights[idx] for idx in comb)\n                             other_w = (max_val + other_val) - current_w\n                             local_max = max(current_w, other_w)\n\n                             if local_max < best_local_max:\n                                 best_local_max = local_max\n                                 best_local_set_A = [0] + list(comb)\n                                 if abs(local_max - avg) < 1e-5:\n                                     break\n                    else:\n                        # Heuristic Solver\n                        pool_indices = list(range(pool_len))\n                        sub_trials = 10\n                        for sub in range(sub_trials):\n                            noise_arr = [random.uniform(0.9, 1.1) for _ in range(pool_len)]\n                            sorted_idx = sorted(pool_indices, key=lambda i: pool_weights[i] * noise_arr[i], reverse=True)\n\n                            w1, w2 = 0.0, 0.0\n                            c1, c2 = 0, 0\n                            s1, s2 = [], []\n\n                            for idx in sorted_idx:\n                                w = pool_weights[idx]\n                                if c1 < K and c2 < K:\n                                    if w1 <= w2:\n                                        w1 += w; c1 += 1; s1.append(idx)\n                                    else:\n                                        w2 += w; c2 += 1; s2.append(idx)\n                                elif c1 < K:\n                                    w1 += w; c1 += 1; s1.append(idx)\n                                else:\n                                    w2 += w; c2 += 1; s2.append(idx)\n\n                            # Swap Local Search\n                            while True:\n                                improved_swap = False\n                                current_max = max(w1, w2)\n                                for i1, idx1 in enumerate(s1):\n                                    for i2, idx2 in enumerate(s2):\n                                        diff_w = pool_weights[idx1] - pool_weights[idx2]\n                                        nw1, nw2 = w1 - diff_w, w2 + diff_w\n                                        nmax = max(nw1, nw2)\n                                        if nmax < current_max - 1e-6:\n                                            w1, w2 = nw1, nw2\n                                            s1[i1], s2[i2] = s2[i2], s1[i1]\n                                            current_max = nmax\n                                            improved_swap = True\n                                            break\n                                    if improved_swap: break\n                                if not improved_swap: break\n\n                            if max(w1, w2) < best_local_max:\n                                best_local_max = max(w1, w2)\n                                best_local_set_A = list(s1)\n\n                    # Check improvement\n                    improvement = max_val - best_local_max\n                    if improvement > best_move_improvement + 1e-6:\n                        best_move_improvement = improvement\n                        set_A_indices = best_local_set_A\n                        set_A_set = set(set_A_indices)\n                        new_items_A = [pool[x] for x in set_A_indices]\n                        new_items_B = [pool[x] for x in range(pool_len) if x not in set_A_set]\n                        # Calculate exact new weights to avoid drift\n                        w_A_exact = sum(row_weight_list[x] for x in new_items_A)\n                        w_B_exact = sum(row_weight_list[x] for x in new_items_B)\n                        best_move = (other_p, new_items_A, new_items_B, w_A_exact, w_B_exact)\n\n                        if abs(best_local_max - avg) < 1e-5:\n                             break\n\n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    break\n\n            current_diff = max(pack_weights) - min(pack_weights)\n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Efficient incremental update of scores\n    current_scores = weight.clone() # weight / 1\n\n    for i in range(num_log, num_phy):\n        # Pick expert with max current load\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n\n        # Update score: weight / new_count\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Task\n\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs as the original program, but with improved internal implementation.\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\npartition_refinement_v1\n</NAME>\n\n<DESCRIPTION>\nImproved balanced packing algorithm with the following optimizations:\n1.  **Iterative Pairwise Refinement**: The core logic repeatedly selects the heaviest pack and pairs it with other packs to offload weight. It uses a pruning strategy to skip pairs that cannot possibly beat the best found move.\n2.  **Hybrid Pairwise Solver**: Uses an exact brute-force solver for small pool sizes ($2K \\le 14$) and a robust randomized greedy + swap heuristic for larger pools. The heuristic trials are increased for better quality.\n3.  **Multi-Start Strategy**: Runs the packing algorithm multiple times (8 restarts) with randomized noise injection (Noisy LPT) to escape local optima.\n4.  **CPU Offloading**: All logic runs on CPU with standard Python lists/floats to avoid GPU kernel launch overheads for sequential scalar logic.\n5.  **Optimized \"Best Fit\" Logic**: The refinement strictly accepts moves that reduce the load of the target heavy pack, breaking ties by minimizing the partner's load deviation.\n</DESCRIPTION>\n\n<CODE>\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport itertools\nimport math\n\ndef solve_partition_exact(pool_weights: list[float], K: int, target_avg: float) -> tuple[float, list[int]]:\n    \"\"\"\n    Exact solver for partitioning pool_weights (size 2K) into two sets of size K\n    to minimize max(sum(A), sum(B)).\n    Returns (best_max_val, indices_A).\n    \"\"\"\n    n = len(pool_weights)\n    # Fix first element to A to reduce symmetry\n    # We want to choose K indices. We pick 0, then choose K-1 from remaining n-1.\n    \n    best_max = float('inf')\n    best_A = []\n    \n    total_sum = sum(pool_weights)\n    w0 = pool_weights[0]\n    indices_rest = list(range(1, n))\n    \n    for comb in itertools.combinations(indices_rest, K - 1):\n        # comb is tuple of K-1 indices\n        sum_A = w0\n        for idx in comb:\n            sum_A += pool_weights[idx]\n        \n        sum_B = total_sum - sum_A\n        current_max = max(sum_A, sum_B)\n        \n        if current_max < best_max:\n            best_max = current_max\n            best_A = [0] + list(comb)\n            if abs(current_max - target_avg) < 1e-6:\n                return best_max, best_A\n                \n    return best_max, best_A\n\ndef solve_partition_heuristic(pool_weights: list[float], K: int, trials: int) -> tuple[float, list[int]]:\n    \"\"\"\n    Heuristic solver for partitioning pool_weights into two sets of size K.\n    \"\"\"\n    n = len(pool_weights)\n    indices = list(range(n))\n    best_max = float('inf')\n    best_A = list(range(K))\n    \n    # 1. Randomized Greedy + Swap\n    for _ in range(trials):\n        # Randomize order\n        random.shuffle(indices)\n        \n        # Initial split\n        idx_A = indices[:K]\n        idx_B = indices[K:]\n        \n        sum_A = sum(pool_weights[i] for i in idx_A)\n        sum_B = sum(pool_weights[i] for i in idx_B)\n        \n        # Local Swap Optimization (Hill Climbing)\n        improved = True\n        while improved:\n            improved = False\n            curr_max = max(sum_A, sum_B)\n            \n            # Simple O(K^2) search for best swap\n            best_swap = None\n            best_swap_gain = 0.0\n            \n            # Optimization: Only look for swaps that reduce the max\n            for i in range(K):\n                u = idx_A[i]\n                w_u = pool_weights[u]\n                for j in range(K):\n                    v = idx_B[j]\n                    w_v = pool_weights[v]\n                    \n                    delta = w_u - w_v\n                    \n                    # New sums\n                    new_A = sum_A - delta\n                    new_B = sum_B + delta\n                    new_max = max(new_A, new_B)\n                    \n                    if new_max < curr_max - 1e-6:\n                        gain = curr_max - new_max\n                        if gain > best_swap_gain:\n                            best_swap_gain = gain\n                            best_swap = (i, j, delta)\n            \n            if best_swap:\n                i, j, delta = best_swap\n                # Swap indices\n                tmp = idx_A[i]\n                idx_A[i] = idx_B[j]\n                idx_B[j] = tmp\n                sum_A -= delta\n                sum_B += delta\n                improved = True\n        \n        final_max = max(sum_A, sum_B)\n        if final_max < best_max:\n            best_max = final_max\n            best_A = list(idx_A)\n            \n    return best_max, best_A\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups,\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(num_layers, -1)\n        rank_in_pack = torch.zeros_like(pack_index)\n        return pack_index, rank_in_pack\n\n    # CPU processing\n    weight_cpu = weight.to(\"cpu\", dtype=torch.float32)\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=\"cpu\")\n\n    # Parameters\n    num_restarts = 8  # Increased restarts\n    max_refine_steps = 20\n    \n    for i in range(num_layers):\n        row_weight = weight_cpu[i]\n        row_weight_list = row_weight.tolist()\n        \n        best_diff = float('inf')\n        best_packs = None\n        \n        # Base LPT indices\n        base_indices = torch.argsort(row_weight, descending=True).tolist()\n        \n        for attempt in range(num_restarts):\n            # 1. Initialization\n            current_packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            \n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Noisy LPT\n                # Noise range [0.9, 1.1]\n                noise = torch.rand(num_groups, device=\"cpu\") * 0.2 + 0.9\n                indices = torch.argsort(row_weight * noise, descending=True).tolist()\n            \n            # Greedy Packing\n            for group_idx in indices:\n                w = row_weight_list[group_idx]\n                # Find pack with min weight that has space\n                best_p = -1\n                min_val = float('inf')\n                for p in range(num_packs):\n                    if len(current_packs[p]) < groups_per_pack:\n                        if pack_weights[p] < min_val:\n                            min_val = pack_weights[p]\n                            best_p = p\n                current_packs[best_p].append(group_idx)\n                pack_weights[best_p] += w\n                \n            # 2. Refinement Loop\n            for _ in range(max_refine_steps):\n                # Identify Max Pack\n                max_p = 0\n                max_val = pack_weights[0]\n                min_val = pack_weights[0]\n                \n                for p in range(1, num_packs):\n                    if pack_weights[p] > max_val:\n                        max_val = pack_weights[p]\n                        max_p = p\n                    if pack_weights[p] < min_val:\n                        min_val = pack_weights[p]\n                \n                if max_val - min_val < 1e-6:\n                    break\n                    \n                best_move = None\n                # We want to reduce max_val.\n                # Current best improvement starts at 0 (or slightly negative tolerance)\n                best_new_max = max_val\n                \n                # Try pairing max_p with every other pack\n                # Sorting candidates by weight (lightest first) is a good heuristic\n                candidates = sorted([p for p in range(num_packs) if p != max_p], \n                                    key=pack_weights.__getitem__)\n                                    \n                for other_p in candidates:\n                    other_val = pack_weights[other_p]\n                    target_avg = (max_val + other_val) / 2.0\n                    \n                    # If perfect balancing of this pair doesn't improve upon our best found move, skip.\n                    # We want new_max < best_new_max.\n                    # Best possible new_max for this pair is target_avg.\n                    if target_avg >= best_new_max - 1e-6:\n                        continue\n                        \n                    # Prepare Pool\n                    pool_indices = current_packs[max_p] + current_packs[other_p]\n                    pool_weights = [row_weight_list[x] for x in pool_indices]\n                    pool_len = len(pool_indices)\n                    K = groups_per_pack\n                    \n                    # Solve Partition\n                    if pool_len <= 14:\n                        local_max, idx_A_local = solve_partition_exact(pool_weights, K, target_avg)\n                    else:\n                        local_max, idx_A_local = solve_partition_heuristic(pool_weights, K, trials=20)\n                    \n                    # Check if this result improves the global situation (reduces max_p)\n                    # Note: local_max is the max(new_p1, new_p2). \n                    # We are guaranteed local_max <= max_val because we can always keep original.\n                    if local_max < best_new_max - 1e-6:\n                        best_new_max = local_max\n                        \n                        # Reconstruct items\n                        # idx_A_local are indices into pool_indices\n                        items_A = [pool_indices[i] for i in idx_A_local]\n                        \n                        # items_B are the rest\n                        set_A = set(idx_A_local)\n                        items_B = [pool_indices[i] for i in range(pool_len) if i not in set_A]\n                        \n                        # Recalculate exact sums to avoid float drift\n                        w_A = sum(row_weight_list[x] for x in items_A)\n                        w_B = sum(row_weight_list[x] for x in items_B)\n                        \n                        best_move = (other_p, items_A, items_B, w_A, w_B)\n                        \n                        # If we hit the theoretical limit, stop searching\n                        if abs(local_max - target_avg) < 1e-6:\n                            break\n                            \n                if best_move:\n                    other_p, items_A, items_B, w_A, w_B = best_move\n                    current_packs[max_p] = items_A\n                    current_packs[other_p] = items_B\n                    pack_weights[max_p] = w_A\n                    pack_weights[other_p] = w_B\n                else:\n                    # No improvement possible for max_p\n                    break\n            \n            # Check Result\n            current_max = max(pack_weights)\n            current_min = min(pack_weights)\n            current_diff = current_max - current_min\n            \n            if current_diff < best_diff:\n                best_diff = current_diff\n                best_packs = [list(p) for p in current_packs]\n                if best_diff < 1e-6:\n                    break\n        \n        # Fill Output\n        for p in range(num_packs):\n            for r, g in enumerate(best_packs[p]):\n                pack_index[i, g] = p\n                rank_in_pack[i, g] = r\n\n    return pack_index.to(weight.device), rank_in_pack.to(weight.device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Track current load per replica: weight / count\n    current_scores = weight.clone()\n\n    for i in range(num_log, num_phy):\n        # Greedily split the expert with the highest average load per replica\n        redundant_indices = current_scores.max(dim=-1).indices\n\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update scores\n        selected_weights = weight[arangen, redundant_indices]\n        selected_counts = logcnt[arangen, redundant_indices].float()\n        current_scores[arangen, redundant_indices] = selected_weights / selected_counts\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Hierarchical rebalancing strategy.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n# EVOLVE-BLOCK-END\n```\n</CODE>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 29314,
          "output_tokens": 15883,
          "cost": 0.249224,
          "input_cost": 0.058628,
          "output_cost": 0.19059600000000002,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 72,
          "deleted": 0,
          "modified": 130
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 7.348000000000001e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_99/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_99/results\nRun 1/5 completed in 19.55 seconds\nRun 2/5 completed in 55.28 seconds\nRun 3/5 completed in 38.38 seconds\nRun 4/5 completed in 32.71 seconds\nRun 5/5 completed in 29.35 seconds\nbalancedness: 0.21073683733844054\nbalancedness: 0.3397761404567239\nbalancedness: 0.3671579544181455\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_99/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_99/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385873149429\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.3110771746298858, 'speed_score': 1.0}\n  execution_time_mean: 35.05317708400253\n  execution_time_std: 11.818640703573905\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 62,
          "average_cyclomatic_complexity": 8.857142857142858,
          "halstead_volume": 2035.829900494593,
          "halstead_difficulty": 10.974576271186441,
          "halstead_effort": 22342.370518139815,
          "lines_of_code": 442,
          "logical_lines_of_code": 242,
          "comments": 54,
          "maintainability_index": -42.779308272827095,
          "max_nesting_depth": 7,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    },
    {
      "id": "d243aed6-53eb-4c0f-af4c-93204aa077c4",
      "code": "# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 10\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_sum_sq = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups) * 0.15 + 0.925\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT/Best Fit)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_counts = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                # Best Fit: Assign to valid pack with min load\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_counts[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_counts[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 250 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Identify heavy and light packs\n                # Optimization: Track max/min indices dynamically or just scan\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n                if max_p == min_p:\n                    break\n\n                # If balanced enough, try to optimize variance by picking random packs\n                # Otherwise, target max load reduction\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                     # Already balanced max-min, but maybe high variance?\n                     pass\n\n                candidates = {max_p, min_p}\n                # Add random packs for k-way swaps\n                if num_packs > 2:\n                    k_random = min(2, num_packs - 2)\n                    for _ in range(k_random):\n                        candidates.add(torch.randint(0, num_packs, (1,)).item())\n\n                cand_list = list(candidates)\n\n                # Ruin\n                items = []\n                for p in cand_list:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                best_sub_weights = [pack_weights[p] for p in cand_list]\n                best_sub_packs = [list(packs[p]) for p in cand_list]\n                best_sub_max = max(best_sub_weights)\n                best_sub_ss = sum(w*w for w in best_sub_weights)\n\n                improved_sub = False\n\n                # 0. Deterministic LPT attempt\n                # 1..N. Randomized LPT attempts\n\n                # Prepare LPT sort once\n                items_sorted = sorted(items, key=lambda x: layer_w_list[x], reverse=True)\n\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.85 + 0.3 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        # Polish: Attempt pairwise swaps within subset\n                        s_keys = list(temp_weights.keys())\n                        for _ in range(5):\n                            p_max = max(s_keys, key=temp_weights.get)\n                            p_min = min(s_keys, key=temp_weights.get)\n                            w_max = temp_weights[p_max]\n                            w_min = temp_weights[p_min]\n                            if w_max - w_min < 1e-6:\n                                break\n\n                            best_swap = None\n                            best_gain = -1.0\n\n                            for i_idx, u in enumerate(temp_packs[p_max]):\n                                wu = layer_w_list[u]\n                                for j_idx, v in enumerate(temp_packs[p_min]):\n                                    wv = layer_w_list[v]\n                                    delta = wu - wv\n                                    diff = w_max - w_min\n                                    if delta > 1e-6 and delta < diff:\n                                        gain = delta * (diff - delta)\n                                        if gain > best_gain:\n                                            best_gain = gain\n                                            best_swap = (i_idx, j_idx, delta)\n\n                            if best_swap:\n                                i_idx, j_idx, delta = best_swap\n                                u = temp_packs[p_max][i_idx]\n                                v = temp_packs[p_min][j_idx]\n                                temp_packs[p_max][i_idx] = v\n                                temp_packs[p_min][j_idx] = u\n                                temp_weights[p_max] -= delta\n                                temp_weights[p_min] += delta\n                            else:\n                                break\n\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n\n                if improved_sub:\n                    for idx, p in enumerate(cand_list):\n                        packs[p] = best_sub_packs[idx]\n                        pack_weights[p] = best_sub_weights[idx]\n                        pack_counts[p] = groups_per_pack # Should remain full\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w*w for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6 and current_ss < best_sum_sq - 1e-6:\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "language": "python",
      "parent_id": "468d35e1-4d5b-4d9e-bd19-f9b65af22cd6",
      "archive_inspiration_ids": [
        "f3d4c6f1-1fb7-4675-a072-fc3c129f5443",
        "ef7501ac-df60-411c-be63-a49df8d97be2",
        "7f60dee5-c070-44bb-8cac-6fa3c30fd8fc",
        "15b6d1c3-8856-4bb1-9222-308f2baf6543"
      ],
      "top_k_inspiration_ids": [
        "781c17c9-b7aa-42f9-9de8-a69d941eff7a",
        "7cc6c1a1-b566-4dd7-8721-2221787f8f29"
      ],
      "island_idx": 0,
      "generation": 92,
      "timestamp": 1764186942.4290597,
      "code_diff": "--- a/original.py\n+++ b/original.py\n@@ -1,399 +1,434 @@\n # EVOLVE-BLOCK-START\n \"\"\"\n Expert parallelism load balancer (EPLB) for vLLM.\n \n This module implements the core rearrangement algorithm.\n \n The rearrangement algorithm is adapted from\n [DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n \n Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n on how the EPLB algorithm works.\n \"\"\"\n \n import torch\n \n \n def balanced_packing(weight: torch.Tensor,\n                      num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Pack n weighted objects to m packs, such that each bin contains exactly\n     n/m objects and the weights of all packs are as balanced as possible.\n \n     Parameters:\n         weight: [X, n], the weight of each item\n         num_packs: number of packs\n \n     Returns:\n         pack_index: [X, n], the pack index of each item\n         rank_in_pack: [X, n], the rank of the item in the pack\n     \"\"\"\n     num_layers, num_groups = weight.shape\n     assert num_groups % num_packs == 0\n     groups_per_pack = num_groups // num_packs\n \n     device = weight.device\n     if groups_per_pack == 1:\n         pack_index = torch.arange(weight.size(-1),\n                                   dtype=torch.int64,\n                                   device=device).expand(weight.shape)\n         rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n         return pack_index, rank_in_pack\n \n     # Use CPU weights\n     weight_cpu = weight.cpu()\n \n     # Outputs on CPU to avoid device synchronization during fill\n     pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n     rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n \n     # Number of restarts for the randomized heuristic\n-    NUM_RESTARTS = 5\n+    NUM_RESTARTS = 10\n \n     for i in range(num_layers):\n         layer_w = weight_cpu[i]\n         layer_w_list = layer_w.tolist()\n \n         best_max_load = float('inf')\n         best_sum_sq = float('inf')\n         best_assignment = None\n \n         for attempt in range(NUM_RESTARTS):\n             # 1. Candidate Generation\n             if attempt == 0:\n                 indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n             else:\n                 # Randomized LPT\n                 noise = torch.rand(num_groups) * 0.15 + 0.925\n                 indices = (layer_w * noise).argsort(descending=True).tolist()\n \n             # 2. Greedy Construction (LPT/Best Fit)\n             packs = [[] for _ in range(num_packs)]\n             pack_weights = [0.0] * num_packs\n             pack_counts = [0] * num_packs\n \n             for g_idx in indices:\n                 w = layer_w_list[g_idx]\n                 # Best Fit: Assign to valid pack with min load\n                 best_p = -1\n                 min_w = float('inf')\n \n                 for p in range(num_packs):\n                     if pack_counts[p] < groups_per_pack:\n                         if pack_weights[p] < min_w:\n                             min_w = pack_weights[p]\n                             best_p = p\n \n                 packs[best_p].append(g_idx)\n                 pack_weights[best_p] += w\n                 pack_counts[best_p] += 1\n \n             # 3. Refinement: Large Neighborhood Search (LNS)\n-            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n+            MAX_LNS_STEPS = 250 if num_packs > 1 else 0\n \n             for step in range(MAX_LNS_STEPS):\n                 # Identify heavy and light packs\n                 # Optimization: Track max/min indices dynamically or just scan\n                 max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                 min_p = min(range(num_packs), key=pack_weights.__getitem__)\n \n                 if max_p == min_p:\n                     break\n \n                 # If balanced enough, try to optimize variance by picking random packs\n                 # Otherwise, target max load reduction\n                 if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                      # Already balanced max-min, but maybe high variance?\n                      pass\n \n                 candidates = {max_p, min_p}\n                 # Add random packs for k-way swaps\n                 if num_packs > 2:\n                     k_random = min(2, num_packs - 2)\n                     for _ in range(k_random):\n                         candidates.add(torch.randint(0, num_packs, (1,)).item())\n \n                 cand_list = list(candidates)\n \n                 # Ruin\n                 items = []\n                 for p in cand_list:\n                     items.extend(packs[p])\n \n                 # Recreate: Solve sub-problem (minimize max load of these packs)\n                 best_sub_weights = [pack_weights[p] for p in cand_list]\n                 best_sub_packs = [list(packs[p]) for p in cand_list]\n                 best_sub_max = max(best_sub_weights)\n                 best_sub_ss = sum(w*w for w in best_sub_weights)\n \n                 improved_sub = False\n \n                 # 0. Deterministic LPT attempt\n                 # 1..N. Randomized LPT attempts\n \n                 # Prepare LPT sort once\n                 items_sorted = sorted(items, key=lambda x: layer_w_list[x], reverse=True)\n \n                 SUB_RESTARTS = 20\n                 for sub_attempt in range(SUB_RESTARTS):\n                     if sub_attempt == 0:\n                         current_items = items_sorted\n                     else:\n                         # Perturb weights slightly to change sort order\n                         noise_sub = torch.rand(len(items))\n                         # Efficient perturbed sort\n-                        # We use a list of tuples (perturbed_weight, index)\n                         weighted_items = []\n                         for idx, item in enumerate(items):\n-                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n+                            pw = layer_w_list[item] * (0.85 + 0.3 * noise_sub[idx].item())\n                             weighted_items.append((pw, item))\n                         weighted_items.sort(key=lambda x: x[0], reverse=True)\n                         current_items = [x[1] for x in weighted_items]\n \n                     # Greedy Fill (Best Fit)\n                     temp_weights = {p: 0.0 for p in cand_list}\n                     temp_packs = {p: [] for p in cand_list}\n                     temp_counts = {p: 0 for p in cand_list}\n \n                     possible = True\n                     for item_idx in current_items:\n                         w = layer_w_list[item_idx]\n \n                         best_local_p = -1\n                         min_local_w = float('inf')\n \n                         for p in cand_list:\n                             if temp_counts[p] < groups_per_pack:\n                                 if temp_weights[p] < min_local_w:\n                                     min_local_w = temp_weights[p]\n                                     best_local_p = p\n \n                         if best_local_p == -1:\n                             possible = False\n                             break\n \n                         temp_packs[best_local_p].append(item_idx)\n                         temp_weights[best_local_p] += w\n                         temp_counts[best_local_p] += 1\n \n                     if possible:\n+                        # Polish: Attempt pairwise swaps within subset\n+                        s_keys = list(temp_weights.keys())\n+                        for _ in range(5):\n+                            p_max = max(s_keys, key=temp_weights.get)\n+                            p_min = min(s_keys, key=temp_weights.get)\n+                            w_max = temp_weights[p_max]\n+                            w_min = temp_weights[p_min]\n+                            if w_max - w_min < 1e-6:\n+                                break\n+\n+                            best_swap = None\n+                            best_gain = -1.0\n+\n+                            for i_idx, u in enumerate(temp_packs[p_max]):\n+                                wu = layer_w_list[u]\n+                                for j_idx, v in enumerate(temp_packs[p_min]):\n+                                    wv = layer_w_list[v]\n+                                    delta = wu - wv\n+                                    diff = w_max - w_min\n+                                    if delta > 1e-6 and delta < diff:\n+                                        gain = delta * (diff - delta)\n+                                        if gain > best_gain:\n+                                            best_gain = gain\n+                                            best_swap = (i_idx, j_idx, delta)\n+\n+                            if best_swap:\n+                                i_idx, j_idx, delta = best_swap\n+                                u = temp_packs[p_max][i_idx]\n+                                v = temp_packs[p_min][j_idx]\n+                                temp_packs[p_max][i_idx] = v\n+                                temp_packs[p_min][j_idx] = u\n+                                temp_weights[p_max] -= delta\n+                                temp_weights[p_min] += delta\n+                            else:\n+                                break\n+\n                         c_max = max(temp_weights.values())\n                         c_ss = sum(v*v for v in temp_weights.values())\n \n                         # Check improvement\n                         if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                             best_sub_max = c_max\n                             best_sub_ss = c_ss\n                             best_sub_weights = [temp_weights[p] for p in cand_list]\n                             best_sub_packs = [temp_packs[p] for p in cand_list]\n                             improved_sub = True\n \n                 if improved_sub:\n                     for idx, p in enumerate(cand_list):\n                         packs[p] = best_sub_packs[idx]\n                         pack_weights[p] = best_sub_weights[idx]\n                         pack_counts[p] = groups_per_pack # Should remain full\n \n             # 4. Evaluation\n             current_max = max(pack_weights)\n             current_ss = sum(w*w for w in pack_weights)\n \n             if current_max < best_max_load - 1e-6:\n                 best_max_load = current_max\n                 best_sum_sq = current_ss\n                 best_assignment = [list(p) for p in packs]\n             elif abs(current_max - best_max_load) < 1e-6 and current_ss < best_sum_sq - 1e-6:\n                 best_sum_sq = current_ss\n                 best_assignment = [list(p) for p in packs]\n \n         # 5. Final assignment for this layer\n         for p, nodes in enumerate(best_assignment):\n             for r, g_idx in enumerate(nodes):\n                 pack_index[i, g_idx] = p\n                 rank_in_pack[i, g_idx] = r\n \n     return pack_index.to(device), rank_in_pack.to(device)\n \n \n def replicate_experts(\n         weight: torch.Tensor,\n         num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n     load of all replicas is minimized.\n \n     Parameters:\n         weight: [X, num_log]\n         num_phy: total number of experts after replication\n \n     Returns:\n         phy2log: [X, num_phy], logical expert id of each physical expert\n         rank: [X, num_phy], the replica rank\n         logcnt: [X, num_log], number of replicas for each logical expert\n     \"\"\"\n     n, num_log = weight.shape\n     num_redundant = num_phy - num_log\n     assert num_redundant >= 0\n     device = weight.device\n     phy2log = torch.arange(num_phy, dtype=torch.int64,\n                            device=device).repeat(n, 1)\n     rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n     logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n     arangen = torch.arange(n, dtype=torch.int64, device=device)\n     for i in range(num_log, num_phy):\n         redundant_indices = (weight / logcnt).max(dim=-1).indices\n         phy2log[:, i] = redundant_indices\n         rank[:, i] = logcnt[arangen, redundant_indices]\n         logcnt[arangen, redundant_indices] += 1\n     return phy2log, rank, logcnt\n \n \n def rebalance_experts_hierarchical(\n     weight: torch.Tensor,\n     num_physical_experts: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ):\n     \"\"\"\n     Parameters:\n         weight: [num_moe_layers, num_logical_experts]\n         num_physical_experts: number of physical experts after replication\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n         (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [num_moe_layers, num_physical_experts]\n         logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n         logical_count: [num_moe_layers, num_logical_experts]\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     assert num_logical_experts % num_groups == 0\n     group_size = num_logical_experts // num_groups\n     assert num_groups % num_nodes == 0\n     groups_per_node = num_groups // num_nodes\n     assert num_gpus % num_nodes == 0\n     assert num_physical_experts % num_gpus == 0\n     phy_experts_per_gpu = num_physical_experts // num_gpus\n \n     def inverse(perm: torch.Tensor) -> torch.Tensor:\n         inv = torch.empty_like(perm)\n         inv.scatter_(\n             1,\n             perm,\n             torch.arange(perm.size(1), dtype=torch.int64,\n                          device=perm.device).expand(perm.shape),\n         )\n         return inv\n \n     # Step 1: pack groups to nodes\n     tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n     group_pack_index, group_rank_in_pack = balanced_packing(\n         tokens_per_group, num_nodes)\n     log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                  group_size).unsqueeze(-1) +\n                 torch.arange(group_size,\n                              dtype=torch.int64,\n                              device=group_pack_index.device)).flatten(-2)\n     mlog2log = inverse(log2mlog)\n \n     # Step 2: construct redundant experts within nodes\n     # [num_layers * num_nodes, num_logical_experts // num_nodes]\n     tokens_per_mlog = weight.gather(-1, mlog2log).view(\n         -1, num_logical_experts // num_nodes)\n     phy2mlog, phyrank, mlogcnt = replicate_experts(\n         tokens_per_mlog, num_physical_experts // num_nodes)\n \n     # Step 3: pack physical_experts to GPUs\n     # [num_layers * num_nodes, num_physical_experts // num_nodes]\n     tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n     pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                 num_gpus // num_nodes)\n     phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n     pphy2phy = inverse(phy2pphy)\n \n     pphy2mlog = phy2mlog.gather(\n         -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n     pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n         0,\n         num_logical_experts,\n         num_logical_experts // num_nodes,\n         device=group_pack_index.device,\n     ).view(1, -1, 1)).flatten(-2)\n     pphy2log = mlog2log.gather(-1, pphy2mlog)\n     pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n     logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n     return pphy2log, pphyrank, logcnt\n \n \n def rebalance_experts(\n     weight: torch.Tensor,\n     num_replicas: int,\n     num_groups: int,\n     num_nodes: int,\n     num_gpus: int,\n ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n     \"\"\"\n     Entry point for expert-parallelism load balancer.\n \n     Parameters:\n         weight: [layers, num_logical_experts], the load statistics for all\n             logical experts\n         num_replicas: number of physical experts, must be a multiple of\n             `num_gpus`\n         num_groups: number of expert groups\n         num_nodes: number of server nodes, where the intra-node network\n             (e.g, NVLink) is faster\n         num_gpus: number of GPUs, must be a multiple of `num_nodes`\n \n     Returns:\n         physical_to_logical_map: [layers, num_replicas], the expert index of\n             each replica\n         logical_to_physical_map: [layers, num_logical_experts, X], the replica\n             indices for each expert\n         expert_count: [layers, num_logical_experts], number of physical\n             replicas for each logical expert\n     \"\"\"\n     num_layers, num_logical_experts = weight.shape\n     weight = weight.float().cpu()\n     if num_groups % num_nodes == 0:\n         # use hierarchical load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, num_groups, num_nodes, num_gpus)\n     else:\n         # use global load-balance policy\n         phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n             weight, num_replicas, 1, 1, num_gpus)\n     num_redundant_experts = num_replicas - num_logical_experts\n     maxlogcnt = num_redundant_experts + 1\n     log2phy: torch.Tensor = torch.full(\n         (num_layers, num_logical_experts, maxlogcnt),\n         -1,\n         dtype=torch.int64,\n         device=logcnt.device,\n     )\n     log2phy.view(num_layers, -1).scatter_(\n         -1,\n         phy2log * maxlogcnt + phyrank,\n         torch.arange(num_replicas, dtype=torch.int64,\n                      device=log2phy.device).expand(num_layers, -1),\n     )\n     return phy2log, log2phy, logcnt\n \n \n # EVOLVE-BLOCK-END\n \n \n # This part remains fixed (not evolved)\n def run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n              num_nodes: int, num_gpus: int):\n     \"\"\"Run the expert parallelism load balancer\"\"\"\n     phy2log, log2phy, logcnt = rebalance_experts(\n         weight, num_replicas, num_groups, num_nodes, num_gpus\n     )\n     return phy2log, log2phy, logcnt\n \n \n __all__ = [\"rebalance_experts\", \"run_eplb\"]",
      "combined_score": 0.6555385897208916,
      "public_metrics": {
        "results_str": "  balancedness_score = 0.311077\n  speed_score = 1.000000",
        "num_workloads_evaluated": 5
      },
      "private_metrics": {
        "avg_balancedness_score": 0.31107717944178337,
        "speed_score": 1.0
      },
      "text_feedback": "",
      "correct": true,
      "children_count": 0,
      "complexity": 1.0,
      "embedding": [
        0.0537902,
        0.020598048,
        0.013955005,
        -0.041080765,
        -0.0268951,
        0.016988201,
        -0.009410978,
        -0.0085690655,
        -0.022789331,
        0.029870631,
        0.032776963,
        0.021428429,
        -0.009964566,
        -0.023169922,
        0.01612322,
        0.016526878,
        -0.010835311,
        0.013505216,
        -0.005927994,
        0.054020863,
        0.005824196,
        -0.008984256,
        0.026641373,
        -0.04200341,
        -0.0044258125,
        0.008984256,
        0.06117136,
        -0.043618042,
        0.031047003,
        -0.04779301,
        0.07884001,
        -0.011463864,
        0.013655146,
        0.0027765846,
        -0.015016046,
        0.03238484,
        -0.007433058,
        0.01243264,
        0.012813232,
        0.06287825,
        0.027702415,
        -0.023331385,
        -0.044817477,
        0.038843352,
        -0.03665207,
        0.03136993,
        0.0048410026,
        -0.00877666,
        0.07727151,
        0.0053196247,
        0.036375277,
        0.015788762,
        -0.0020370272,
        0.06518487,
        0.026110852,
        0.039396938,
        0.021647558,
        0.020967107,
        0.019906064,
        -0.0438487,
        0.053282745,
        -0.015535034,
        0.07182791,
        0.03974293,
        -0.029409308,
        0.005247543,
        -0.03510664,
        0.029732233,
        0.022674,
        -0.010967942,
        -0.04036572,
        0.045278803,
        -0.024288628,
        -0.025695663,
        -0.0005597139,
        0.008620963,
        -0.020205924,
        0.045301866,
        -0.031139268,
        -0.04546333,
        -0.030677944,
        -0.0072600627,
        0.051437456,
        0.020632649,
        0.013620546,
        -0.07514943,
        -0.021497628,
        -0.037297923,
        -0.034829848,
        -0.025672596,
        0.03706726,
        -0.045117337,
        -0.0013371144,
        0.032338705,
        0.04068864,
        -0.030262755,
        0.061217494,
        0.0147161875,
        0.032108046,
        0.056419738,
        -0.01291703,
        0.017138131,
        -0.0567888,
        -0.0006411662,
        0.026872035,
        0.006418149,
        0.004930384,
        -0.0022965209,
        0.010443187,
        -0.015431237,
        -0.038658824,
        0.020240523,
        0.032038845,
        0.011123639,
        0.016307749,
        0.006764141,
        -0.04207261,
        -0.022501005,
        0.009399446,
        -0.025949389,
        -0.027702415,
        -0.038220566,
        0.026226183,
        -0.028256003,
        0.008292272,
        -0.037874576,
        0.010379756,
        -0.033053756,
        0.007340794,
        0.0005950339,
        0.042764593,
        0.025718728,
        0.011855988,
        -0.023827307,
        -0.019929131,
        0.0034282026,
        -0.02207428,
        0.007185098,
        -0.0082980385,
        -0.019825334,
        -0.023377517,
        0.027633216,
        -0.013839674,
        -0.0086670965,
        -0.049499903,
        0.0537902,
        -0.0035983154,
        0.015604232,
        -0.038474295,
        0.031000871,
        0.016077088,
        -0.035614096,
        -0.0116426265,
        -0.012155848,
        -0.0013846883,
        -0.01186752,
        0.0058616786,
        0.017864713,
        0.08188474,
        -0.032154176,
        -0.027379489,
        0.026987365,
        -0.02358511,
        0.023965703,
        0.033492014,
        0.027863877,
        -0.051252928,
        0.0038693424,
        -0.05766531,
        -0.061079096,
        -0.002387344,
        -0.022697067,
        -0.006268219,
        -0.014958382,
        0.0012340377,
        0.014104934,
        -0.026479911,
        -0.035775557,
        -0.030424217,
        -0.04128836,
        -0.02192435,
        -0.01318229,
        -0.016630676,
        -0.007877082,
        -0.04982283,
        0.026249249,
        -0.028671192,
        -0.013874274,
        -0.00949171,
        -0.006677643,
        0.0139780715,
        0.04373337,
        -0.036398344,
        0.03266163,
        0.000757578,
        -0.019294813,
        0.053467274,
        0.013989604,
        0.0047429716,
        -0.008707462,
        -0.04006586,
        -0.012755566,
        0.038889486,
        -0.04117303,
        0.047077958,
        0.035083573,
        -0.01122167,
        0.012455707,
        0.013678212,
        -0.007606054,
        0.034137864,
        -0.024519289,
        0.035383433,
        -0.005881862,
        -0.027333356,
        -0.028048407,
        -0.050607078,
        0.015189042,
        0.0043104817,
        0.06827573,
        -0.02011366,
        0.016607609,
        -0.025580332,
        0.0030591446,
        -0.041565154,
        0.020621115,
        0.049038578,
        -0.01808384,
        0.006769907,
        0.0055560526,
        -0.031762052,
        -0.0010221176,
        -0.011250502,
        -0.028071472,
        0.031139268,
        -0.03160059,
        -0.033699606,
        0.018764291,
        -0.015881026,
        -0.035475697,
        0.018729692,
        0.04324898,
        0.009630106,
        -0.046224512,
        0.009537842,
        0.016538411,
        -0.040457983,
        -0.017841646,
        0.006942903,
        -0.021982016,
        0.021140102,
        -0.044425353,
        0.022870062,
        -0.059141543,
        -0.01664221,
        0.031877384,
        -0.02018286,
        -0.054159258,
        -0.01687287,
        -0.030424217,
        0.017760916,
        -0.015050646,
        -0.0046853065,
        -0.022247277,
        -0.020551916,
        -0.0012001593,
        -0.0022662466,
        0.03725179,
        -0.046039984,
        -0.021532226,
        0.028832655,
        0.014139534,
        -0.01484305,
        0.0369058,
        -0.041611288,
        -0.01770325,
        0.0053426907,
        -0.018372167,
        -0.030331952,
        -0.044079363,
        -0.02523434,
        -0.0002510243,
        0.040273454,
        -2.2739505e-05,
        0.01201745,
        -0.0060548577,
        -0.003344588,
        0.027656283,
        0.008990021,
        -0.023458248,
        0.003474335,
        -0.024196364,
        0.03635221,
        0.013758943,
        -0.010564284,
        -0.020517318,
        -0.05909541,
        -0.015131378,
        -0.00013848685,
        -0.0084710345,
        0.0101663945,
        -0.0023224703,
        -0.008119276,
        0.005039948,
        -0.007854016,
        -0.025718728,
        -0.016734473,
        0.019110283,
        -0.017091997,
        -0.022950793,
        -0.012259644,
        0.010154861,
        -0.019594673,
        0.00085128413,
        -0.026433779,
        0.0033099889,
        0.03190045,
        0.003105277,
        -0.016665274,
        -0.051898777,
        -0.05540483,
        -0.04264926,
        0.042164873,
        0.025211273,
        -0.0008974164,
        0.024680752,
        -0.04717022,
        0.01906415,
        -0.006470048,
        -0.014266398,
        0.0052042943,
        0.040273454,
        0.028348267,
        0.025626464,
        0.014289464,
        -0.04373337,
        0.029663036,
        -0.004267233,
        0.043940965,
        0.020171326,
        -0.05969513,
        0.02493448,
        -0.012628702,
        -0.021912817,
        -0.047516216,
        0.02026359,
        0.058541823,
        0.02892492,
        0.02636458,
        0.07717925,
        -0.03725179,
        -0.019006487,
        -0.0145431915,
        0.015246708,
        0.0147161875,
        -0.025326604,
        0.00055647024,
        0.0041317195,
        -0.04380257,
        0.0055099204,
        -0.029870631,
        -0.006400849,
        0.0296861,
        -0.006573845,
        -0.007421525,
        0.065138735,
        0.029478507,
        0.014658522,
        0.008517167,
        0.009289881,
        0.043110587,
        -0.0035147006,
        -0.02516514,
        0.007767517,
        -0.010483554,
        -0.015200576,
        0.023850372,
        0.054666713,
        -0.027102696,
        0.005126446,
        0.02207428,
        0.018360635,
        -0.019571606,
        0.010881444,
        0.018625895,
        0.03660594,
        -0.0147161875,
        0.016757539,
        -0.07122819,
        0.009837702,
        0.048438862,
        -0.01333222,
        -0.018129973,
        -0.046039984,
        0.03409173,
        -0.015062179,
        -0.0381283,
        -0.025441935,
        0.04463295,
        0.011308167,
        -0.013113092,
        0.0056512,
        -0.038036037,
        -0.018614363,
        -0.02599552,
        0.015350506,
        0.046731967,
        0.017276527,
        -0.0043912134,
        0.04308752,
        0.030147424,
        -0.03238484,
        0.0114696305,
        0.004676657,
        0.011590728,
        -0.03600622,
        0.004215334,
        0.037413254,
        0.004053871,
        -0.008315338,
        -0.006637277,
        -0.008113509,
        0.019986797,
        -0.0050197653,
        -0.017357258,
        0.017034333,
        0.016780606,
        -0.016411547,
        0.011775256,
        -0.06117136,
        -0.01306696,
        0.006072157,
        0.06481581,
        -0.031023936,
        0.021797488,
        0.037436318,
        -0.0071735648,
        0.02904025,
        -0.002770818,
        -0.0013918964,
        0.008286505,
        -0.013113092,
        -0.013343752,
        -0.021059372,
        0.021105504,
        -0.011855988,
        0.002519974,
        -0.054066993,
        0.051160663,
        -0.008188474,
        0.013205356,
        -0.017207328,
        0.05480511,
        0.005080314,
        -0.019329412,
        -0.05480511,
        0.07311961,
        0.032361772,
        0.049961224,
        -0.023492847,
        0.0423494,
        0.015096778,
        0.0039039415,
        -0.02791001,
        0.05152972,
        0.016965134,
        0.005195644,
        -0.0058155465,
        0.0095032435,
        0.02523434,
        0.061032966,
        -0.049130846,
        -0.0014517242,
        0.03916628,
        -0.030032093,
        0.011164004,
        -0.014116468,
        0.06647657,
        0.030124359,
        -0.050376415,
        0.027010432,
        -0.048300464,
        -0.030516483,
        -0.041034635,
        0.027033497,
        0.02922478,
        0.03374574,
        0.003661747,
        0.001275845,
        0.026802836,
        0.02742562,
        -0.012870898,
        0.009070753,
        -0.010085663,
        -0.0011907887,
        -0.006833339,
        -0.017045865,
        -0.027771613,
        0.003030312,
        0.049592167,
        0.010039531,
        -0.08456041,
        -0.05904928,
        -0.020840243,
        0.018014643,
        -0.034299325,
        -0.0311162,
        0.0034455024,
        -0.004296066,
        0.03958147,
        -0.019421676,
        -0.005287909,
        0.02470382,
        0.027471753,
        -0.008517167,
        0.035152774,
        -0.0052187108,
        0.01178679,
        0.005916461,
        0.0297553,
        -0.029478507,
        -0.021416897,
        -0.049130846,
        0.02576486,
        0.030770209,
        -0.03589089,
        -0.014773852,
        -0.055081904,
        0.014693121,
        -0.0044142795,
        -0.014819984,
        -0.013424484,
        -0.052037176,
        0.028648127,
        -0.01928328,
        0.030101292,
        -0.0027520768,
        -0.039235476,
        -0.031323798,
        -0.03951227,
        0.0048121703,
        0.01359748,
        0.017691717,
        0.021151636,
        0.0112735685,
        -0.03928161,
        0.06919837,
        0.030170491,
        0.029501572,
        0.027310291,
        0.007017868,
        -0.045901585,
        0.001452445,
        -0.0024075266,
        -0.028440531,
        -0.017830113,
        -0.012744034,
        -0.04629371,
        0.028809588,
        0.047700744,
        0.02245487,
        -0.0053830566,
        0.009682005,
        -0.0002852631,
        0.0005287188,
        0.01058735,
        0.022235744,
        -0.042995255,
        0.017011266,
        0.003658864,
        -0.011832922,
        0.010789179,
        0.010247125,
        -0.06629204,
        0.023192987,
        -0.003333055,
        0.020655714,
        -0.02463462,
        -0.003713646,
        -0.009359079,
        -0.02772548,
        -0.023665844,
        -0.017391857,
        -0.027863877,
        -0.054436054,
        -0.010316324,
        -0.029939828,
        -0.01303236,
        -0.004111537,
        -0.028140672,
        -0.0047083725,
        -0.0012571038,
        0.036513675,
        -0.016861336,
        0.016030956,
        -0.005172578,
        -0.039443072,
        0.0110775065,
        0.027587084,
        0.008125043,
        -0.015834894,
        0.06384703,
        0.0023195872,
        0.020067528,
        -0.026387645,
        0.002116317,
        0.006914071,
        0.009099586,
        0.0021465912,
        -0.03238484,
        -0.00836147,
        -0.017311126,
        -0.030101292,
        -0.010379756,
        -0.005432072,
        0.0045584426,
        0.055958416,
        0.0033532379,
        0.013309154,
        -0.020252056,
        -0.008413369,
        0.041357562,
        0.011140938,
        -0.014946848,
        -4.0928855e-05,
        -0.010691148,
        -0.010610417,
        -0.005708866,
        -0.029063316,
        0.015419704,
        -0.039604533,
        -0.015800295,
        -0.021785954,
        0.028117605,
        -0.0011713266,
        0.065230995,
        0.0240349,
        0.035152774,
        0.008540233,
        -0.013770476,
        0.025972456,
        -0.0058155465,
        0.0152813075,
        -0.038935617,
        0.014946848,
        0.023919571,
        -0.002194165,
        -0.004832353,
        0.008788194,
        -0.011948252,
        -0.003788611,
        -0.016838271,
        0.03434546,
        0.035798624,
        0.031093135,
        -0.01612322,
        -0.010183694,
        -0.03660594,
        -0.026456844,
        -2.5228574e-05,
        -0.037436318,
        -0.012421108,
        -0.010051063,
        -0.02282393,
        0.014485526,
        0.026987365,
        0.020909442,
        0.0013522515,
        0.0037424786,
        0.04825433,
        -0.007317728,
        0.028901853,
        0.025257405,
        -0.044494554,
        -0.038658824,
        -0.01868356,
        -0.029132515,
        0.014231798,
        0.001900072,
        0.018925754,
        0.010270191,
        -0.018764291,
        -0.031554457,
        -0.010466253,
        -0.010962175,
        0.02719496,
        0.021497628,
        -0.0016059789,
        0.035983153,
        -0.018360635,
        0.01634235,
        -0.012974694,
        -0.036698204,
        -0.015315906,
        0.01792238,
        0.044010166,
        0.008638264,
        0.010281725,
        -0.019087218,
        -0.042395536,
        -0.011769489,
        0.0007885731,
        -0.02719496,
        -0.0114696305,
        -0.040919304,
        -0.01777245,
        -0.043871768,
        0.04714716,
        0.02004446,
        -0.0015295723,
        -0.04142676,
        0.003007246,
        -0.021197768,
        -0.019075684,
        -0.06993649,
        0.004509427,
        -0.0018741225,
        0.010702682,
        0.024957547,
        -0.041703552,
        -0.007294662,
        0.003508934,
        -0.038059104,
        0.00069450657,
        0.049546033,
        0.015385104,
        0.01314769,
        0.0033071055,
        0.0045238435,
        -0.0017371675,
        0.011406198,
        -0.016907468,
        0.020102127,
        -0.032154176,
        0.037597783,
        -0.0077156187,
        0.00034112635,
        -0.03363041,
        -0.023446715,
        0.012328844,
        -0.006112523,
        -0.026041655,
        0.014485526,
        -0.006470048,
        0.010835311,
        0.004497894,
        -0.0027463103,
        0.033953335,
        -0.015119844,
        0.02101324,
        -0.033584278,
        0.006539246,
        -0.027748547,
        -0.001417125,
        0.04433309,
        0.033215217,
        0.017391857,
        -0.0099703325,
        -0.0048813685,
        0.0089150565,
        -0.019340945,
        -0.019387078,
        -0.020321256,
        0.016365414,
        0.013020827,
        0.002618005,
        -0.04717022,
        -0.0025891725,
        0.012086649,
        -0.041495956,
        -0.024427025,
        -0.009243749,
        0.05033028,
        0.05033028,
        0.0268951,
        -0.0367674,
        0.015511968,
        -0.052360103,
        0.006671876,
        -0.02146303,
        -0.017495655,
        -0.019883,
        -0.031508327,
        0.0031773585,
        0.003451269,
        0.005414773,
        -0.059003145,
        -0.019710002,
        -0.01205205,
        -0.012536438,
        -0.060479376,
        -0.013090026,
        0.001601654,
        -0.0226048,
        -0.011769489,
        0.017541787,
        -0.037528582,
        -0.053697936,
        0.009728137,
        0.016630676,
        -0.003324405,
        0.0008397511,
        0.021509161,
        -0.0014228915,
        -0.010252892,
        -0.010310558,
        -0.056742664,
        0.0058962777,
        -0.03988133,
        0.019790735,
        0.018487498,
        0.00069775025,
        -0.03356121,
        0.006348951,
        0.06310891,
        -0.02312379,
        -0.045578662,
        -0.044194695,
        0.026479911,
        -0.010927577,
        -0.0241041,
        -0.046939563,
        0.044725213,
        0.00904192,
        -0.048992448,
        -0.01333222,
        -0.013943472,
        0.0019260213,
        0.011262035,
        -0.01657301,
        0.0013508099,
        -0.022028148,
        0.006504647,
        0.011210136,
        0.0049851662,
        0.013401418,
        0.0064239157,
        -0.008067377,
        -0.0052446597,
        0.024150232,
        0.032823093,
        0.0085690655,
        6.757653e-05,
        -0.024288628,
        0.017564854,
        0.010760346,
        0.037989907,
        0.039420005,
        -0.026618307,
        -0.016919002,
        -0.016988201,
        0.011890586,
        0.02576486,
        -0.01246724,
        -0.004624758,
        0.01928328,
        0.017230395,
        -0.0057636476,
        0.015073712,
        -0.008321105,
        -0.014081868,
        -0.042118743,
        0.011279334,
        -0.029201712,
        0.007386926,
        -0.023262186,
        0.025280472,
        0.03494518,
        -0.004203801,
        -0.0012808907,
        0.00975697,
        -0.030677944,
        0.019675404,
        0.020759512,
        -0.011106338,
        -0.019202549,
        -0.013470616,
        0.016838271,
        -0.041103832,
        -0.013493682,
        -0.0024118517,
        -0.014623922,
        -0.015569634,
        0.006360484,
        -0.0039241244,
        0.018798891,
        0.006723775,
        -0.002064418,
        0.034322392,
        0.022408739,
        -0.00026580103,
        0.007046701,
        0.014958382,
        0.016584544,
        0.028648127,
        0.028671192,
        -0.0067064757,
        -0.0028371334,
        0.028809588,
        -0.003485868,
        -0.009237982,
        0.0009442695,
        -0.015904093,
        0.04610918,
        -0.016665274,
        -0.012178914,
        -0.006643044,
        0.013090026,
        0.02885572,
        -0.05332888,
        0.07118206,
        -0.010460488,
        -0.030908607,
        -0.01163686,
        0.007185098,
        -0.024219431,
        0.013320686,
        0.025511133,
        0.010126028,
        -0.0007784817,
        0.02945544,
        -0.021982016,
        0.0054176557,
        0.012236578,
        0.009111119,
        -0.004180735,
        0.008557532,
        -0.03732099,
        0.054620583,
        -0.014623922,
        0.013724344,
        -0.021636024,
        0.022881595,
        -0.0026280966,
        0.0049505667,
        -0.011994384,
        -0.013735876,
        -0.009387912,
        -0.015235174,
        0.0038578094,
        -0.05199104,
        -0.011411965,
        -0.00312546,
        0.016238552,
        -0.032615498,
        -0.031254597,
        -0.0041547855,
        -0.013805076,
        -0.013136158,
        -0.01966387,
        0.031416062,
        -0.04922311,
        0.053836334,
        0.0037424786,
        -0.033192154,
        0.034899045,
        0.007986645,
        -0.0020427937,
        0.003950074,
        0.01868356,
        0.04008892,
        -0.003875109,
        -0.02327372,
        0.0038145604,
        0.011804089,
        0.00922645,
        0.008690163,
        -0.0048496528,
        -0.046778098,
        0.0119367195,
        0.034483854,
        -0.023146855,
        0.021901285,
        -0.007617587,
        0.0116426265,
        -0.04516347,
        0.008125043,
        -0.013689744,
        0.057019457,
        -0.014566258,
        0.017484123,
        0.0059020445,
        -0.04087317,
        0.029616904,
        0.055312566,
        -0.003151409,
        0.0482082,
        0.0043277815,
        0.006556546,
        -0.023100723,
        0.055035774,
        0.028186804,
        0.008303804,
        -0.008465268,
        0.011158237,
        0.012594104,
        -0.013805076,
        -0.0169536,
        -0.02245487,
        -0.0045180772,
        -0.03605235,
        0.008742061,
        0.028071472,
        -0.0038808754,
        0.010777647,
        0.0044661784,
        0.019929131,
        -0.017530255,
        0.00580978,
        0.0050082323,
        0.028717324,
        -0.035152774,
        -0.017541787,
        0.014070336,
        -0.039050948,
        -0.009912667,
        -0.031254597,
        0.011083272,
        -0.028117605,
        -0.010270191,
        -0.004604575,
        -0.043318182,
        0.0035665995,
        -0.01359748,
        -0.014358662,
        0.009520543,
        0.023296785,
        -0.0439871,
        0.02071338,
        -0.0211747,
        0.028071472,
        -0.005582002,
        -0.028901853,
        0.018499032,
        -0.013528282,
        -0.03921241,
        -0.0028270418,
        0.026572175,
        0.024427025,
        0.0014538866,
        -0.02606472,
        0.032892294,
        -0.02523434,
        0.017068932,
        0.027056564,
        -0.0066199778,
        -0.006925604,
        0.01306696,
        -0.016400015,
        -0.010368222,
        -0.05886475,
        -0.003932774,
        -0.008770893,
        0.028371332,
        0.025465,
        0.01936401,
        -0.00027210818,
        0.0024666337,
        -0.0022561552,
        -0.008851625,
        0.021751355,
        0.005720399,
        -0.044056296,
        -0.0184183,
        0.009180318,
        0.009981865,
        -0.026110852,
        -0.0213131,
        -0.00015056052,
        0.0011360066,
        0.0011518645,
        0.008269206,
        -0.012663302,
        0.019375544,
        0.008753594,
        -0.0044892444,
        0.002139383,
        0.01778398,
        -0.009987632,
        -0.048484992,
        -0.007461891,
        0.0041317195,
        0.0014113585,
        -0.005541636,
        -0.014370196,
        0.04373337,
        0.03815137,
        0.0030245455,
        0.014266398,
        -0.025672596,
        -0.003038962,
        0.023919571,
        0.027933076,
        -0.009180318,
        0.014600856,
        -0.023400582,
        0.018072309,
        0.017668651,
        -0.023665844,
        0.012248112,
        0.0018582646,
        0.0036242648,
        -0.004042338,
        -0.010304791,
        -0.029409308,
        -0.043871768,
        -0.011821388,
        -0.011192837,
        0.029063316,
        -0.009088052,
        0.028947985,
        -0.01472772,
        0.021497628,
        0.029109448,
        -0.0058328463,
        -0.023538979,
        0.002315262,
        -0.005028415,
        0.021647558,
        0.019167949,
        -0.02613392,
        0.0011987176,
        -0.029363176,
        0.035337303,
        -0.032707762,
        -0.005039948,
        0.010362457,
        0.026572175,
        0.016711406,
        -0.0044258125,
        0.0283944,
        -0.05891088,
        0.03494518,
        0.021451496,
        -0.009768504,
        -0.021762889,
        -0.03190045,
        0.008990021,
        -0.0056713833,
        0.034368526,
        -0.000255169,
        -0.017507188,
        0.04128836,
        0.01649228,
        -0.0022835464,
        -0.003333055,
        0.006302818,
        0.071874045,
        0.0047400887,
        -0.003938541,
        0.008782427,
        0.011821388,
        0.027287224,
        -0.019075684,
        -0.0051869946,
        0.020436585,
        -0.041934215,
        -0.028209869,
        0.030378085,
        -0.0046161083,
        -0.02034432,
        -0.0056425505,
        0.018395234,
        -0.043571908,
        0.01547737,
        -0.020159792,
        0.015189042,
        -0.006660343,
        0.0011179862,
        -0.0035694826,
        -0.021912817,
        0.0013940589,
        -0.033353616,
        0.003419553,
        -0.020609582,
        -0.016699873,
        0.019018019,
        -0.023515914,
        -0.026087787,
        0.008655563,
        0.007669486,
        -0.015016046,
        0.0149122495,
        0.020840243,
        0.0053253914,
        -0.001667969,
        0.009560908,
        -0.017034333,
        -0.002923631,
        -0.030793276,
        -0.016250085,
        -0.020840243,
        -0.0083960695,
        -0.02101324,
        0.01717273,
        0.006810273,
        0.0040798206,
        0.008390303,
        -0.016238552,
        0.0039587235,
        -0.024380893,
        -0.02486528,
        0.0012419666,
        0.033884138,
        0.060848434,
        -0.03902788,
        0.010275958,
        -0.00751379,
        -0.0052273604,
        -0.0041893846,
        0.028140672,
        0.018948821,
        -0.01612322,
        -0.015096778,
        -0.025326604,
        -0.012098182,
        0.029639969,
        -0.027817745,
        -0.0022676883,
        -0.006193254,
        -0.022916194,
        0.028256003,
        -0.006204787,
        -0.01401267,
        0.023538979,
        0.020897908,
        -0.0325463,
        -0.012628702,
        0.007900148,
        -0.0037078795,
        0.011809856,
        -0.02791001,
        -0.026341513,
        0.03224644,
        0.021520693,
        -0.028071472,
        0.00127152,
        -0.0048698355,
        0.022281876,
        0.028417464,
        0.040504113,
        -0.020436585,
        -0.011504229,
        -0.0057348153,
        -0.008240373,
        -0.012144314,
        0.025603397,
        -0.012363442,
        0.012513372,
        0.014531658,
        0.02026359,
        -0.024081033,
        0.037413254,
        -0.0039875563,
        -0.007386926,
        -0.0439179,
        -0.04922311,
        0.037436318,
        -0.0046564736,
        0.027817745,
        -0.038843352,
        -0.03932774,
        0.038774155,
        0.04142676,
        0.03702113,
        -0.015546568,
        -0.017126597,
        0.020609582,
        -0.011925186,
        0.0087651275,
        0.006833339,
        -0.03374574,
        0.029317044,
        0.0046103415,
        0.035129707,
        -0.022743199,
        0.010281725,
        0.0042470503,
        -0.013309154,
        0.028832655,
        -0.015200576,
        0.036513675,
        0.0001892143,
        0.003191775,
        -0.038243633,
        -0.018741226,
        0.039650667,
        -0.038843352,
        0.011140938,
        0.009249516,
        0.031070068,
        -0.039719865,
        0.004192268,
        0.021220835,
        -0.016930535,
        0.037459385,
        -0.023711976,
        0.022650933,
        -0.025857124,
        -0.02177442,
        -0.040250387,
        0.017068932,
        -0.016330816,
        -0.0034483855,
        0.0110025415,
        0.009664706,
        -5.0502196e-05,
        -0.01642308,
        -0.024196364,
        -0.015857961,
        0.018291436,
        0.015016046,
        0.012155848,
        -0.021336164,
        0.007767517,
        0.028048407,
        0.016054023,
        0.011631093,
        0.006187488,
        0.019871466,
        -0.019802267,
        -0.012178914,
        -0.00764642,
        0.009243749,
        -0.0053311577,
        0.0023974353,
        0.01905262,
        -0.020309722,
        0.021232367,
        0.027171895,
        -0.0004883531,
        0.02904025,
        -0.056281343,
        0.0006080086,
        0.004976516,
        0.02922478,
        0.0068794717,
        0.034622252,
        -0.00030634695,
        0.022996925,
        -0.013805076,
        0.04264926,
        0.03238484,
        -0.01725346,
        0.007755984,
        -0.0097973365,
        0.02101324,
        0.029086383,
        0.015961757,
        -0.013170756,
        -0.02922478,
        -0.011060206,
        0.022639401,
        -0.0005409727,
        0.016746007,
        0.020217458,
        -0.055312566,
        0.0009046245,
        -0.0067929737,
        -2.3961513e-06,
        0.02564953,
        0.015811829,
        0.0013825258,
        -0.015765695,
        0.001369551,
        0.0101663945,
        -0.009612807,
        0.008269206,
        0.019998329,
        0.02583406,
        -0.0154543035,
        0.016988201,
        -0.011089039,
        -0.011584961,
        -0.007848249,
        -0.021751355,
        0.019087218,
        0.033169087,
        -0.0031975415,
        0.03005516,
        -0.008834326,
        0.009630106,
        0.010956408,
        -0.00049628207,
        0.0027881179,
        0.04308752,
        -0.025557265,
        0.00027553205,
        0.023711976,
        0.028694259,
        -0.0042701163,
        -0.038935617,
        -0.008067377,
        -0.0038606925,
        0.0055272197,
        -0.018556697,
        -0.0034253194,
        -0.014670054,
        0.019294813,
        -0.009393679,
        -0.0049332674,
        -0.014450926,
        0.0147161875,
        0.027956143,
        -0.024588488,
        0.015212108,
        0.014116468,
        0.025418868,
        0.0296861,
        -0.025557265,
        -0.009168784,
        0.019686937,
        0.02599552,
        -0.011429264,
        0.018372167,
        -0.0021422664,
        -0.033215217,
        -0.0070755337,
        0.011181303,
        0.028209869,
        0.009474411,
        -0.0084479675,
        0.0063258847,
        -0.032338705,
        -0.0014243332,
        0.016526878,
        -0.040573314,
        0.017691717,
        0.001585796,
        -0.005287909,
        0.01216738,
        0.0089381235,
        0.009474411,
        -0.015212108,
        0.01672294,
        0.009572442,
        -0.009733904,
        0.04324898,
        -0.026018588,
        0.010195226,
        -0.024380893,
        -0.008753594,
        -0.042856857,
        -0.016849803,
        -0.026203116,
        0.012824765,
        0.008770893,
        -0.012132782,
        -0.005553169,
        0.010991008,
        -0.022155013,
        0.009180318,
        -0.007288895,
        0.009318714,
        0.030078225,
        0.0013991046,
        0.00019011532,
        -0.0042701163,
        -0.029663036,
        -0.013620546,
        -0.020171326,
        0.019490875,
        -0.0019462042,
        0.016688341,
        -0.024242496,
        -0.012340376,
        0.0047026062,
        0.0096993055,
        -0.020505784,
        0.0057607642,
        0.015050646,
        0.0037828444,
        0.016411547,
        0.009387912,
        0.0088631585,
        0.008978489,
        -0.023896504,
        -0.0055906516,
        -0.019629272,
        0.020332789,
        0.008799726,
        -0.0102182925,
        0.006867938,
        0.021105504,
        0.022731666,
        0.03183125,
        -0.00664881,
        -0.007225463,
        0.0115445955,
        -0.03762085,
        -0.028232936,
        -0.016077088,
        -0.017449522,
        0.026203116,
        -0.0013926172,
        0.016619142,
        0.032177243,
        0.025465,
        0.045624793,
        -0.03695193,
        -0.010754581,
        0.044379223,
        -0.000784969,
        -0.02677977,
        -0.0055387532,
        -0.01306696,
        0.013124624,
        -0.021001706,
        0.030493416,
        0.029017184,
        -0.012963162,
        0.0009810311,
        -0.0325463,
        -0.009912667,
        -0.018164573,
        0.009111119,
        -0.01514291,
        0.020321256,
        0.003800144,
        0.005812663,
        0.03164672,
        0.006210554,
        0.005299442,
        -0.00920915,
        -0.00369058,
        -0.0070986,
        0.0046507074,
        -0.006631511,
        -0.0047602714,
        -0.0090130875,
        -0.030101292,
        0.03035502,
        0.005328275,
        0.0006927045,
        -0.0054753213,
        0.018222239
      ],
      "embedding_pca_2d": [],
      "embedding_pca_3d": [],
      "embedding_cluster_id": null,
      "migration_history": [],
      "metadata": {
        "compute_time": 6449.8620665073395,
        "patch_type": "diff",
        "api_costs": 0.442334,
        "num_applied": 3,
        "patch_name": "polish_lns_heuristic",
        "patch_description": "1. Increase `NUM_RESTARTS` to 10 and `MAX_LNS_STEPS` to 250 to utilize the available time budget for better exploration, as the current speed score is perfect (1.0).\n2. Enhance the Large Neighborhood Search (LNS) \"Recreate\" phase. After the randomized greedy filling of the subset of packs, a new \"Polish\" step is introduced. This step iteratively identifies the heaviest and lightest packs within the subset and attempts to perform 1-vs-1 item swaps to reduce the load difference. This allows the algorithm to overcome the limitations of pure greedy construction (which cannot easily undo a bad early assignment) by locally refining the subset packing using pairwise exchanges, which is computationally cheap for small subsets but effective for balance.",
        "error_attempt": null,
        "novelty_attempt": 1,
        "resample_attempt": 1,
        "patch_attempt": 2,
        "model_name": "gemini-3-pro-preview",
        "temperature": 1.0,
        "max_tokens": 16384,
        "llm_result": {
          "content": "<NAME>\npolish_lns_heuristic\n</NAME>\n\n<DESCRIPTION>\n1. Increase `NUM_RESTARTS` to 10 and `MAX_LNS_STEPS` to 250 to utilize the available time budget for better exploration, as the current speed score is perfect (1.0).\n2. Enhance the Large Neighborhood Search (LNS) \"Recreate\" phase. After the randomized greedy filling of the subset of packs, a new \"Polish\" step is introduced. This step iteratively identifies the heaviest and lightest packs within the subset and attempts to perform 1-vs-1 item swaps to reduce the load difference. This allows the algorithm to overcome the limitations of pure greedy construction (which cannot easily undo a bad early assignment) by locally refining the subset packing using pairwise exchanges, which is computationally cheap for small subsets but effective for balance.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n=======\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 10\n\n    for i in range(num_layers):\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n=======\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 250 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        # We use a list of tuples (perturbed_weight, index)\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n=======\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.85 + 0.3 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        # Polish: Attempt pairwise swaps within subset\n                        s_keys = list(temp_weights.keys())\n                        for _ in range(5):\n                            p_max = max(s_keys, key=temp_weights.get)\n                            p_min = min(s_keys, key=temp_weights.get)\n                            w_max = temp_weights[p_max]\n                            w_min = temp_weights[p_min]\n                            if w_max - w_min < 1e-6:\n                                break\n                            \n                            best_swap = None\n                            best_gain = -1.0\n                            \n                            for i_idx, u in enumerate(temp_packs[p_max]):\n                                wu = layer_w_list[u]\n                                for j_idx, v in enumerate(temp_packs[p_min]):\n                                    wv = layer_w_list[v]\n                                    delta = wu - wv\n                                    diff = w_max - w_min\n                                    if delta > 1e-6 and delta < diff:\n                                        gain = delta * (diff - delta)\n                                        if gain > best_gain:\n                                            best_gain = gain\n                                            best_swap = (i_idx, j_idx, delta)\n                            \n                            if best_swap:\n                                i_idx, j_idx, delta = best_swap\n                                u = temp_packs[p_max][i_idx]\n                                v = temp_packs[p_min][j_idx]\n                                temp_packs[p_max][i_idx] = v\n                                temp_packs[p_min][j_idx] = u\n                                temp_weights[p_max] -= delta\n                                temp_weights[p_min] += delta\n                            else:\n                                break\n\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n>>>>>>> REPLACE\n</DIFF>",
          "msg": "The previous edit was not successful. This was the error message: \n\nNo changes applied.\n\n Try again.",
          "system_msg": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\n\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\n\nYour goal will be two-fold:\n1. Improve the algorithm to achieve better load balancing; while\n2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\n\nThe current algorithm is implemented in the `rebalance_experts` function.\n\nYou MUST repond using a edit name, description and the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<NAME>\nA shortened name summarizing the edit you are proposing. Lowercase, no spaces, underscores allowed.\n</NAME>\n\n<DESCRIPTION>\nA description and argumentation process of the edit you are proposing.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly including indentation)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\n</DIFF>\n\n\nExample of a valid diff format:\n<DIFF>\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\n</DIFF>\n\n* You may only modify text that lies below a line containing \"EVOLVE-BLOCK-START\" and above the next \"EVOLVE-BLOCK-END\". Everything outside those markers is read-only.\n* Do not repeat the markers \"EVOLVE-BLOCK-START\" and \"EVOLVE-BLOCK-END\" in the SEARCH/REPLACE blocks.  \n* Every block\u2019s SEARCH section must be copied **verbatim** from the current file.  Including indentation.\n* You can propose multiple independent edits. SEARCH/REPLACE blocks follow one after another. DO NOT ADD ANY OTHER TEXT BETWEEN THESE BLOCKS.\n* Make sure the file still runs after your changes.\n\n# Potential Recommendations\nThe following are potential recommendations for the next program generations:\n\n\nBased on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
          "new_msg_history": [
            {
              "role": "user",
              "content": "Here are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    # Pre-allocate output tensors\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Number of restarts for randomized greedy\n    NUM_RESTARTS = 20\n\n    for i in range(num_layers):\n        layer_weights = weight_cpu[i]\n\n        # Base sort indices (LPT)\n        base_indices = layer_weights.argsort(descending=True).tolist()\n\n        best_assignment = None\n        best_max_load = float('inf')\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Randomized Candidate Generation\n            if attempt == 0:\n                indices = base_indices\n            else:\n                # Add noise to weights to perturb sort order\n                # 5% noise is usually sufficient to swap similar items\n                noise = torch.rand(num_groups) * 0.05\n                indices = (layer_weights * (1 + noise)).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT / Best Fit)\n            # pack_contents: list of lists storing item indices\n            pack_contents = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_sizes = [0] * num_packs\n\n            for idx in indices:\n                w = layer_weights[idx].item()\n\n                # Find lightest valid pack\n                best_p = -1\n                min_w = float('inf')\n\n                # Simple linear scan is fast for small num_packs\n                for p in range(num_packs):\n                    if pack_sizes[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                pack_contents[best_p].append(idx)\n                pack_weights[best_p] += w\n                pack_sizes[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            # Iteratively improve by repacking subsets of bins\n\n            MAX_LNS_STEPS = 50\n            consecutive_no_improve = 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Sort packs by weight\n                sorted_packs = sorted(range(num_packs), key=lambda x: pack_weights[x], reverse=True)\n                max_p = sorted_packs[0]\n                min_p = sorted_packs[-1]\n\n                # If balanced enough, stop\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                    break\n\n                # Select candidates for LNS: Heaviest, Lightest, and potentially a random one\n                candidates = [max_p, min_p]\n                if num_packs > 2:\n                    # Pick a random pack that is not max or min to facilitate 3-way/4-way cyclic shifts\n                    # Use a simple pseudo-random approach based on step\n                    candidates.append(sorted_packs[(step + 1) % (num_packs - 1) + 1])\n\n                # Collect items from candidates\n                items_to_repack = []\n                for p in candidates:\n                    items_to_repack.extend(pack_contents[p])\n\n                # Sort descending (LPT)\n                items_to_repack.sort(key=lambda x: layer_weights[x].item(), reverse=True)\n\n                # Repack into these bins using Bounded Best Fit\n                new_loads = {p: 0.0 for p in candidates}\n                new_contents = {p: [] for p in candidates}\n                possible = True\n\n                for item_idx in items_to_repack:\n                    w = layer_weights[item_idx].item()\n                    # Assign to candidate bin with min current load that has space\n                    best_local_p = -1\n                    min_local_w = float('inf')\n                    for p in candidates:\n                        if len(new_contents[p]) < groups_per_pack:\n                            if new_loads[p] < min_local_w:\n                                min_local_w = new_loads[p]\n                                best_local_p = p\n\n                    if best_local_p == -1:\n                        possible = False\n                        break\n\n                    new_contents[best_local_p].append(item_idx)\n                    new_loads[best_local_p] += w\n\n                if possible:\n                    # Check improvement criteria\n                    old_local_max = max(pack_weights[p] for p in candidates)\n                    new_local_max = max(new_loads.values())\n\n                    # Accept if max load decreases OR max load is same but variance decreases (better balance)\n                    # Sum of squares is a good proxy for variance\n                    old_ss = sum(pack_weights[p]**2 for p in candidates)\n                    new_ss = sum(val**2 for val in new_loads.values())\n\n                    if new_local_max < old_local_max - 1e-6 or (abs(new_local_max - old_local_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                        # Apply Update\n                        for p in candidates:\n                            pack_contents[p] = new_contents[p]\n                            pack_weights[p] = new_loads[p]\n                            pack_sizes[p] = groups_per_pack # Should be full\n                        consecutive_no_improve = 0\n                    else:\n                        consecutive_no_improve += 1\n                else:\n                    consecutive_no_improve += 1\n\n                if consecutive_no_improve >= 5:\n                    break\n\n            # 4. Check global best\n            current_max = max(pack_weights)\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_assignment = [list(p) for p in pack_contents]\n\n        # 5. Write best assignment to output tensors\n        # Flatten for scatter\n        flat_indices = []\n        flat_packs = []\n        flat_ranks = []\n\n        for p, items in enumerate(best_assignment):\n            for r, idx in enumerate(items):\n                flat_indices.append(idx)\n                flat_packs.append(p)\n                flat_ranks.append(r)\n\n        idx_tensor = torch.tensor(flat_indices, dtype=torch.int64, device=device)\n        pack_tensor = torch.tensor(flat_packs, dtype=torch.int64, device=device)\n        rank_tensor = torch.tensor(flat_ranks, dtype=torch.int64, device=device)\n\n        pack_index[i].scatter_(0, idx_tensor, pack_tensor)\n        rank_in_pack[i].scatter_(0, idx_tensor, rank_tensor)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        # Extract weights for this layer as a list for fast Python iteration\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # Candidate generation:\n        # We try:\n        # 1. Deterministic LPT (sort descending)\n        # 2. Randomized LPT (multiple attempts)\n\n        candidates = []\n\n        # 1. Deterministic\n        indices_det = layer_weights_t.sort(descending=True).indices.tolist()\n        candidates.append(indices_det)\n\n        # 2. Perturbed (only if we have enough groups for it to matter)\n        if groups_per_pack > 1:\n            for attempt in range(4):\n                # Add small random noise to explore different greedy decisions\n                noise = torch.rand(num_groups) * 0.1 + 0.95 # +/- 5%\n                indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n                candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            # Re-init packs using lists for speed\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n\n                # Find best pack: valid (not full) and min weight\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        pw = current_pack_weights[p]\n                        if pw < min_w:\n                            min_w = pw\n                            best_p = p\n\n                # Assign\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            # Metric: minimize max load\n            max_load = max(current_pack_weights)\n            if max_load < min_max_load:\n                min_max_load = max_load\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # Global Refinement Loop\n        # Alternates between Vectorized Pairwise Swaps and Large Neighborhood Search (LNS)\n\n        NUM_GLOBAL_ITER = 3\n\n        for global_iter in range(NUM_GLOBAL_ITER):\n\n            # Phase 1: Vectorized Local Search (Pairwise Swaps)\n            # Efficiently checks swaps between max pack and others\n\n            improved_swap = False\n            for _ in range(20): # Limit iterations per phase\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices].view(1, groups_per_pack, 1) # [1, G, 1]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment].view(num_packs, 1, groups_per_pack) # [M, 1, G]\n\n                # Compute deltas: w_u - w_v\n                deltas = w_u - w_v # [M, G, G]\n\n                # Diff with max pack\n                diffs = (max_w - pack_weights).view(num_packs, 1, 1) # [M, 1, 1]\n\n                # Gain metric: delta * (diff - delta)\n                # We want 0 < delta < diff\n\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_flat = torch.argmax(gains).item()\n                max_gain = gains.view(-1)[best_flat].item()\n\n                if max_gain < 0:\n                    break\n\n                # Perform Swap\n                best_p = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                best_u_idx = rem // groups_per_pack\n                best_v_idx = rem % groups_per_pack\n\n                u_val = pack_assignment[max_pack, best_u_idx].item()\n                v_val = pack_assignment[best_p, best_v_idx].item()\n\n                pack_assignment[max_pack, best_u_idx] = v_val\n                pack_assignment[best_p, best_v_idx] = u_val\n\n                d_val = deltas[best_p, best_u_idx, best_v_idx].item()\n                pack_weights[max_pack] -= d_val\n                pack_weights[best_p] += d_val\n                improved_swap = True\n\n            # Phase 2: Large Neighborhood Search (LNS)\n            # Ruin and Recreate 3 packs (Max, Min, Random)\n            # This helps to perform 3-way exchanges or more complex reshuffling\n\n            improved_lns = False\n            if num_packs >= 3:\n                # Number of LNS attempts\n                for _ in range(15):\n                    max_p = torch.argmax(pack_weights).item()\n                    min_p = torch.argmin(pack_weights).item()\n\n                    if max_p == min_p:\n                        break\n\n                    # Pick 3rd pack random\n                    rand_p = torch.randint(0, num_packs, (1,)).item()\n                    while rand_p == max_p or rand_p == min_p:\n                        rand_p = torch.randint(0, num_packs, (1,)).item()\n\n                    indices_list = [max_p, min_p, rand_p]\n\n                    # Collect items\n                    items = []\n                    for p in indices_list:\n                         items.extend(pack_assignment[p].tolist())\n\n                    # Sort items LPT\n                    items.sort(key=lambda x: layer_weights[x], reverse=True)\n\n                    # Repack Greedy into these 3\n                    temp_packs = {p: [] for p in indices_list}\n                    temp_weights = {p: 0.0 for p in indices_list}\n                    temp_counts = {p: 0 for p in indices_list}\n\n                    possible = True\n                    for item_idx in items:\n                        w = layer_weights[item_idx]\n                        best_local_p = -1\n                        min_local_w = float('inf')\n                        found = False\n\n                        # Greedy Best Fit on subset\n                        for p in indices_list:\n                             if temp_counts[p] < groups_per_pack:\n                                 if temp_weights[p] < min_local_w:\n                                     min_local_w = temp_weights[p]\n                                     best_local_p = p\n                                     found = True\n\n                        if not found:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        old_max = max(pack_weights[p].item() for p in indices_list)\n                        new_max = max(temp_weights.values())\n\n                        old_ss = sum(pack_weights[p].item()**2 for p in indices_list)\n                        new_ss = sum(w**2 for w in temp_weights.values())\n\n                        # Accept if improves max load or variance\n                        if new_max < old_max - 1e-6 or (abs(new_max - old_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                            for p in indices_list:\n                                pack_assignment[p] = torch.tensor(temp_packs[p], dtype=torch.int64)\n                                pack_weights[p] = temp_weights[p]\n                            improved_lns = True\n\n            if not improved_swap and not improved_lns:\n                break\n\n        # Final write to output tensors\n        # pack_assignment contains expert indices in packed order\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\nimport heapq\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n    \n    Algorithm: Beam Search Initialization + Pairwise Cyclic Repartitioning\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # CPU for scalar logic\n    weight_cpu = weight.cpu()\n    \n    # Pre-allocate output on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    for i in range(num_layers):\n        w_tensor = weight_cpu[i]\n        w_list = w_tensor.tolist()\n        \n        # Sort items descending (LPT)\n        sorted_indices = sorted(range(num_groups), key=lambda x: w_list[x], reverse=True)\n        \n        # --- Phase 1: Beam Search Initialization ---\n        # We use beam search for the heaviest items to establish a good structure.\n        # Deep search for the first few items prevents irreversible greedy mistakes.\n        BEAM_WIDTH = 4\n        BEAM_DEPTH = min(num_groups, 24) \n        \n        # State: (score, loads_tuple, counts_tuple, path_tuple)\n        # score: Sum of squared loads (proxy for variance)\n        # path: Tuple of pack indices assigned to the first k items\n        \n        beam = [(0.0, tuple([0.0]*num_packs), tuple([0]*num_packs), ())]\n        \n        for k in range(BEAM_DEPTH):\n            item_idx = sorted_indices[k]\n            w = w_list[item_idx]\n            new_beam = []\n            \n            for score, loads, counts, path in beam:\n                seen_states = set()\n                \n                for p in range(num_packs):\n                    if counts[p] < groups_per_pack:\n                        # Symmetry breaking: if multiple packs have identical load/count, \n                        # they are equivalent. Only try the first one encountered.\n                        # Rounding handles float precision issues.\n                        state_sig = (round(loads[p], 5), counts[p])\n                        if state_sig in seen_states:\n                            continue\n                        seen_states.add(state_sig)\n                        \n                        # Update state\n                        new_loads = list(loads)\n                        new_loads[p] += w\n                        new_counts = list(counts)\n                        new_counts[p] += 1\n                        \n                        # Incremental Score Update: min sum(load^2)\n                        # New term: (L+w)^2 = L^2 + 2Lw + w^2. \n                        # Delta = 2Lw + w^2.\n                        delta_score = 2 * loads[p] * w + w * w\n                        new_score = score + delta_score\n                        \n                        new_beam.append((new_score, tuple(new_loads), tuple(new_counts), path + (p,)))\n            \n            # Prune\n            if len(new_beam) > BEAM_WIDTH:\n                beam = heapq.nsmallest(BEAM_WIDTH, new_beam, key=lambda x: x[0])\n            else:\n                beam = new_beam\n\n        # Reconstruct assignment from best beam state\n        best_node = beam[0]\n        _, current_loads, current_counts, path = best_node\n        \n        packs = [[] for _ in range(num_packs)]\n        pack_weights = list(current_loads)\n        pack_counts = list(current_counts)\n        \n        for k in range(BEAM_DEPTH):\n            idx = sorted_indices[k]\n            p = path[k]\n            packs[p].append(idx)\n        \n        # --- Phase 2: Greedy Finish ---\n        # Fill remaining items using Best Fit (Least Loaded Valid Bin)\n        for k in range(BEAM_DEPTH, num_groups):\n            idx = sorted_indices[k]\n            w = w_list[idx]\n            \n            best_p = -1\n            min_load = float('inf')\n            \n            for p in range(num_packs):\n                if pack_counts[p] < groups_per_pack:\n                    if pack_weights[p] < min_load:\n                        min_load = pack_weights[p]\n                        best_p = p\n            \n            packs[best_p].append(idx)\n            pack_weights[best_p] += w\n            pack_counts[best_p] += 1\n            \n        # --- Phase 3: Pairwise Cyclic Repartitioning ---\n        # Iteratively pick heaviest and lightest packs and re-partition their pooled items.\n        # This acts as a powerful local search that can move multiple items at once.\n        \n        MAX_REFINE_ITER = 20\n        for _ in range(MAX_REFINE_ITER):\n            # Identify extremes\n            max_p = -1; max_w = -1.0\n            min_p = -1; min_w = float('inf')\n            \n            for p in range(num_packs):\n                pw = pack_weights[p]\n                if pw > max_w: max_w = pw; max_p = p\n                if pw < min_w: min_w = pw; min_p = p\n            \n            if max_w - min_w < 1e-6:\n                break\n                \n            # Candidate Pairs: (Max, Min) and optionally (Max, Random) to escape local optima\n            pairs = [(max_p, min_p)]\n            if num_packs > 2:\n                # Try to offload from Max to a random node (not Max/Min)\n                # This facilitates cyclic transfers: Max -> Random -> Min\n                rand_p = random.randint(0, num_packs - 1)\n                if rand_p != max_p and rand_p != min_p:\n                    pairs.append((max_p, rand_p))\n            \n            improved_any = False\n            for p1, p2 in pairs:\n                items = packs[p1] + packs[p2]\n                current_diff = abs(pack_weights[p1] - pack_weights[p2])\n                \n                # We need to split `items` into two sets of equal size `groups_per_pack`\n                # Heuristic: Randomized Greedy Number Partitioning\n                \n                sub_items = sorted(items, key=lambda x: w_list[x], reverse=True)\n                \n                best_split = None\n                best_split_diff = current_diff\n                \n                # 5 attempts: 1 deterministic, 4 randomized\n                for attempt in range(5):\n                    # Prepare item order\n                    if attempt == 0:\n                        order = sub_items\n                    else:\n                        # Shuffle order for variety\n                        order = list(sub_items)\n                        random.shuffle(order)\n                    \n                    l1, l2 = 0.0, 0.0\n                    c1, c2 = 0, 0\n                    ass1, ass2 = [], []\n                    \n                    for idx in order:\n                        w = w_list[idx]\n                        # Put in lighter valid bin\n                        if c1 < groups_per_pack and (c2 == groups_per_pack or l1 < l2):\n                            ass1.append(idx)\n                            l1 += w\n                            c1 += 1\n                        else:\n                            ass2.append(idx)\n                            l2 += w\n                            c2 += 1\n                    \n                    diff = abs(l1 - l2)\n                    if diff < best_split_diff - 1e-6:\n                        best_split_diff = diff\n                        best_split = (ass1, ass2, l1, l2)\n                        if diff < 1e-6: break \n                \n                if best_split:\n                    ass1, ass2, l1, l2 = best_split\n                    packs[p1] = ass1\n                    packs[p2] = ass2\n                    pack_weights[p1] = l1\n                    pack_weights[p2] = l2\n                    improved_any = True\n            \n            if not improved_any:\n                # If we couldn't improve Max/Min or Max/Random, we are likely at a good optimum\n                pass\n\n        # Fill output tensors\n        for p in range(num_packs):\n            for r, idx in enumerate(packs[p]):\n                pack_index[i, idx] = p\n                rank_in_pack[i, idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Algorithm: Hybrid Randomized Greedy + Vectorized Swap + LNS\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    # Handle trivial case\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU for main logic to avoid kernel launch overhead on small loops\n    weight_cpu = weight.cpu()\n    \n    # Pre-allocate outputs\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device=device)\n\n    # Pre-compute scatter indices for final write\n    flat_pack_indices = torch.arange(num_packs, device=device).unsqueeze(1).repeat(1, groups_per_pack).view(-1)\n    flat_rank_indices = torch.arange(groups_per_pack, device=device).unsqueeze(0).repeat(num_packs, 1).view(-1)\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        \n        # --- 1. Randomized Greedy Initialization ---\n        # Run multiple greedy passes with perturbed weights and pick the best one.\n        # This provides a strong starting point for refinement.\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n        \n        # Base LPT order\n        indices_base = torch.argsort(layer_w, descending=True).tolist()\n        \n        NUM_RESTARTS = 10\n        for attempt in range(NUM_RESTARTS): \n            if attempt == 0:\n                indices = indices_base\n            else:\n                # Add noise to weights to explore different greedy decisions\n                noise = torch.rand(num_groups) * 0.2 + 0.9 # Scale 0.9 to 1.1\n                indices = torch.argsort(layer_w * noise, descending=True).tolist()\n            \n            packs = [[] for _ in range(num_packs)]\n            pw = torch.zeros(num_packs, dtype=torch.float32)\n            pc = [0] * num_packs\n            \n            # Greedy Best-Fit\n            for idx in indices:\n                w = layer_w[idx]\n                best_p = -1\n                min_val = float('inf')\n                # Find valid pack with minimum current load\n                for p in range(num_packs):\n                    if pc[p] < groups_per_pack:\n                        val = pw[p].item()\n                        if val < min_val:\n                            min_val = val\n                            best_p = p\n                \n                packs[best_p].append(idx)\n                pw[best_p] += w\n                pc[best_p] += 1\n                \n            max_l = pw.max().item()\n            ss = (pw ** 2).sum().item()\n            \n            # Keep best result (Minimize Max Load, break ties with Sum of Squares)\n            if max_l < min_max_load - 1e-6:\n                min_max_load = max_l\n                min_ss = ss\n                best_assignment = packs\n                best_pack_weights = pw\n            elif abs(max_l - min_max_load) < 1e-6:\n                if ss < min_ss:\n                    min_ss = ss\n                    best_assignment = packs\n                    best_pack_weights = pw\n\n        # Convert to tensor for vectorized operations\n        current_assignment = torch.tensor(best_assignment, dtype=torch.int64) # [M, G]\n        current_weights = best_pack_weights.clone() # [M]\n\n        # --- 2. Vectorized Pairwise Swap Refinement ---\n        # Efficiently evaluate all swaps between the heaviest pack and others.\n        MAX_SWAP_STEPS = 50\n        for _ in range(MAX_SWAP_STEPS):\n            max_p = torch.argmax(current_weights).item()\n            max_w = current_weights[max_p].item()\n            \n            # Identify candidates from Max Pack\n            u_indices = current_assignment[max_p] # [G]\n            w_u = layer_w[u_indices] # [G]\n            \n            # Identify candidates from All Packs\n            w_v = layer_w[current_assignment] # [M, G]\n            \n            # Compute Deltas: w_u - w_v\n            # Shape: [M, G, G] (Target Pack, Index in Max, Index in Target)\n            deltas = w_u.view(1, groups_per_pack, 1) - w_v.view(num_packs, 1, groups_per_pack)\n            \n            # Compute permissible diffs\n            diffs = (max_w - current_weights).view(num_packs, 1, 1)\n            \n            # Validity Mask:\n            # 1. Delta > 0 (reduces max pack)\n            # 2. Delta < Diff (target pack doesn't exceed old max)\n            mask = (deltas > 1e-6) & (deltas < diffs)\n            \n            # Objective: Maximize reduction balancedness: delta * (diff - delta)\n            # This favors swaps that bring the two packs closer to the mean of them\n            gains = deltas * (diffs - deltas)\n            gains = torch.where(mask, gains, -1.0)\n            \n            # Ignore self-swaps\n            gains[max_p] = -1.0\n            \n            best_val, best_flat_idx = gains.view(-1).max(dim=0)\n            \n            if best_val.item() < 0:\n                break\n                \n            # Perform Best Swap\n            flat_idx = best_flat_idx.item()\n            G2 = groups_per_pack * groups_per_pack\n            target_p = flat_idx // G2\n            rem = flat_idx % G2\n            u_idx = rem // groups_per_pack\n            v_idx = rem % groups_per_pack\n            \n            delta = deltas[target_p, u_idx, v_idx].item()\n            val_u = current_assignment[max_p, u_idx].item()\n            val_v = current_assignment[target_p, v_idx].item()\n            \n            current_assignment[max_p, u_idx] = val_v\n            current_assignment[target_p, v_idx] = val_u\n            \n            current_weights[max_p] -= delta\n            current_weights[target_p] += delta\n        \n        # --- 3. Large Neighborhood Search (LNS) ---\n        # Ruin and Recreate strategy for further refinement\n        if num_packs > 2:\n            MAX_LNS_STEPS = 20\n            for _ in range(MAX_LNS_STEPS):\n                # Sort packs by weight\n                sorted_p_indices = torch.argsort(current_weights, descending=True)\n                p_max = sorted_p_indices[0].item()\n                p_min = sorted_p_indices[-1].item()\n                \n                if current_weights[p_max] - current_weights[p_min] < 1e-6:\n                    break\n                \n                # Select a random third pack\n                candidates = [x for x in range(num_packs) if x != p_max and x != p_min]\n                if not candidates:\n                     break\n                p_rand = random.choice(candidates)\n                \n                target_packs = [p_max, p_min, p_rand]\n                \n                # Collect items\n                items = []\n                for p in target_packs:\n                    items.extend(current_assignment[p].tolist())\n                \n                # Sort LPT\n                items.sort(key=lambda x: layer_w[x].item(), reverse=True)\n                \n                # Greedy Repack into target packs\n                temp_assignment = {p: [] for p in target_packs}\n                temp_weights = {p: 0.0 for p in target_packs}\n                temp_counts = {p: 0 for p in target_packs}\n                \n                possible = True\n                for item in items:\n                    w = layer_w[item].item()\n                    best_p = -1\n                    min_local_w = float('inf')\n                    for p in target_packs:\n                        if temp_counts[p] < groups_per_pack:\n                            if temp_weights[p] < min_local_w:\n                                min_local_w = temp_weights[p]\n                                best_p = p\n                    \n                    if best_p == -1:\n                        possible = False\n                        break\n                    temp_assignment[best_p].append(item)\n                    temp_weights[best_p] += w\n                    temp_counts[best_p] += 1\n                \n                if possible:\n                    # Check for improvement\n                    old_max = max(current_weights[p].item() for p in target_packs)\n                    new_max = max(temp_weights.values())\n                    \n                    old_ss = sum(current_weights[p].item()**2 for p in target_packs)\n                    new_ss = sum(v**2 for v in temp_weights.values())\n                    \n                    if new_max < old_max - 1e-6 or (abs(new_max - old_max) < 1e-6 and new_ss < old_ss - 1e-6):\n                        for p in target_packs:\n                            current_assignment[p] = torch.tensor(temp_assignment[p], dtype=torch.int64)\n                            current_weights[p] = temp_weights[p]\n\n        # --- Write Results ---\n        flat_assignment = current_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_assignment, flat_pack_indices)\n        rank_in_pack[i].scatter_(0, flat_assignment, flat_rank_indices)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\nHere are the performance metrics of a set of prioviously implemented programs:\n\n# Prior programs\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\nimport random\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n    device = weight.device\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Operations on CPU are generally faster for this sequential/iterative logic\n    weight_cpu = weight.cpu()\n\n    pack_index = torch.empty(weight.shape, dtype=torch.int64, device=device)\n    rank_in_pack = torch.empty(weight.shape, dtype=torch.int64, device=device)\n\n    # Pre-allocate helper tensors for scatter\n    flat_packs_base = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).reshape(-1)\n    flat_ranks_base = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).reshape(-1)\n\n    for i in range(num_layers):\n        layer_weights_t = weight_cpu[i]\n        layer_weights = layer_weights_t.tolist()\n\n        # --- 1. Initialization (Randomized Greedy) ---\n        candidates = []\n        # Deterministic LPT\n        candidates.append(sorted(range(num_groups), key=lambda x: layer_weights[x], reverse=True))\n\n        # Randomized LPT (Perturbed weights)\n        # Generate multiple candidates to improve diversity\n        for _ in range(4):\n            noise = torch.rand(num_groups) * 0.1 + 0.95  # +/- 5% noise\n            indices_rand = (layer_weights_t * noise).sort(descending=True).indices.tolist()\n            candidates.append(indices_rand)\n\n        best_assignment = None\n        best_pack_weights = None\n        min_max_load = float('inf')\n        min_ss = float('inf')\n\n        # Evaluate candidates with fast Python Greedy\n        for indices in candidates:\n            current_pack_contents = [[] for _ in range(num_packs)]\n            current_pack_weights = [0.0] * num_packs\n            current_pack_cnt = [0] * num_packs\n\n            # Pack\n            for idx in indices:\n                w = layer_weights[idx]\n                # Best fit among non-full packs\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if current_pack_cnt[p] < groups_per_pack:\n                        if current_pack_weights[p] < min_w:\n                            min_w = current_pack_weights[p]\n                            best_p = p\n                current_pack_contents[best_p].append(idx)\n                current_pack_weights[best_p] += w\n                current_pack_cnt[best_p] += 1\n\n            max_load = max(current_pack_weights)\n            ss = sum(x*x for x in current_pack_weights)\n\n            if max_load < min_max_load - 1e-6:\n                min_max_load = max_load\n                min_ss = ss\n                best_assignment = current_pack_contents\n                best_pack_weights = current_pack_weights\n            elif abs(max_load - min_max_load) < 1e-6:\n                if ss < min_ss - 1e-6:\n                    min_ss = ss\n                    best_assignment = current_pack_contents\n                    best_pack_weights = current_pack_weights\n\n        # Convert best assignment to tensor for vectorized refinement\n        # [num_packs, groups_per_pack]\n        pack_assignment = torch.tensor(best_assignment, dtype=torch.int64)\n        pack_weights = torch.tensor(best_pack_weights, dtype=torch.float32)\n\n        # --- 2. Refinement Loop ---\n        MAX_OUTER_LOOPS = 5\n        \n        for _ in range(MAX_OUTER_LOOPS):\n            improved_any = False\n\n            # Phase 1: Vectorized Local Search (Swap)\n            # Uses broadcasting to evaluate swaps between the heaviest pack and all others simultaneously\n            for _ in range(10):\n                max_pack = torch.argmax(pack_weights).item()\n                max_w = pack_weights[max_pack].item()\n\n                # Items in max pack: [G]\n                u_indices = pack_assignment[max_pack]\n                w_u = layer_weights_t[u_indices]\n\n                # Items in all packs: [M, G]\n                w_v = layer_weights_t[pack_assignment]\n\n                # Deltas: w_u - w_v. Shape [M, G, G] (via broadcasting)\n                # Gain function aims to balance the pair (max_pack, p)\n                diffs = (max_w - pack_weights).view(-1, 1, 1) # [M, 1, 1]\n                deltas = w_u.view(1, groups_per_pack, 1) - w_v.view(num_packs, 1, groups_per_pack) # [M, G, G]\n\n                # Mask: valid positive delta strictly less than diff (to avoid overshooting too much)\n                # Actually, strictly less than diff ensures w_p < old_max after swap.\n                mask = (deltas > 1e-6) & (deltas < diffs)\n\n                if not mask.any():\n                    break\n\n                gains = deltas * (diffs - deltas)\n                gains = torch.where(mask, gains, -1.0)\n\n                best_val, best_flat_idx = gains.view(-1).max(0)\n\n                if best_val < 0:\n                    break\n                \n                best_flat = best_flat_idx.item()\n                p_target = best_flat // (groups_per_pack * groups_per_pack)\n                rem = best_flat % (groups_per_pack * groups_per_pack)\n                u_pos = rem // groups_per_pack\n                v_pos = rem % groups_per_pack\n\n                # Swap\n                item_u = pack_assignment[max_pack, u_pos].item()\n                item_v = pack_assignment[p_target, v_pos].item()\n                delta_val = deltas.view(-1)[best_flat].item()\n\n                pack_assignment[max_pack, u_pos] = item_v\n                pack_assignment[p_target, v_pos] = item_u\n                pack_weights[max_pack] -= delta_val\n                pack_weights[p_target] += delta_val\n                improved_any = True\n\n            # Phase 2: K-Way LNS (Ruin & Recreate)\n            # Repack max, min, and a random pack using multiple randomized attempts\n            for _ in range(5):\n                max_p = torch.argmax(pack_weights).item()\n                min_p = torch.argmin(pack_weights).item()\n\n                if max_p == min_p:\n                    break\n\n                lns_packs = [max_p, min_p]\n                if num_packs > 2:\n                    p3 = random.randint(0, num_packs - 1)\n                    while p3 in lns_packs:\n                        p3 = random.randint(0, num_packs - 1)\n                    lns_packs.append(p3)\n\n                # Collect items\n                items_flat = []\n                for p in lns_packs:\n                    items_flat.extend(pack_assignment[p].tolist())\n                \n                # Base sort LPT\n                sub_weights = [(layer_weights[x], x) for x in items_flat]\n                sub_weights.sort(key=lambda x: x[0], reverse=True)\n\n                current_sub_max = max(pack_weights[p].item() for p in lns_packs)\n                current_sub_ss = sum(pack_weights[p].item()**2 for p in lns_packs)\n\n                best_sub_assign = None\n                best_sub_weights = None\n                found_lns_improvement = False\n\n                # 4 attempts: 1 deterministic, 3 randomized\n                for attempt in range(4):\n                    if attempt == 0:\n                        order = sub_weights\n                    else:\n                        # Perturb weights for sorting\n                        order = sorted([(w * random.uniform(0.9, 1.1), w, idx) for w, idx in sub_weights], key=lambda x: x[0], reverse=True)\n                        order = [(w, idx) for _, w, idx in order]\n\n                    temp_bins = [[] for _ in lns_packs]\n                    temp_ws = [0.0] * len(lns_packs)\n                    temp_cts = [0] * len(lns_packs)\n                    \n                    possible = True\n                    for w_val, idx in order:\n                        # Greedy Best Fit\n                        best_b = -1\n                        min_local_w = float('inf')\n                        for b in range(len(lns_packs)):\n                            if temp_cts[b] < groups_per_pack:\n                                if temp_ws[b] < min_local_w:\n                                    min_local_w = temp_ws[b]\n                                    best_b = b\n                        if best_b == -1:\n                            possible = False\n                            break\n                        temp_bins[best_b].append(idx)\n                        temp_ws[best_b] += w_val\n                        temp_cts[best_b] += 1\n                    \n                    if possible:\n                        new_max = max(temp_ws)\n                        new_ss = sum(x*x for x in temp_ws)\n\n                        if new_max < current_sub_max - 1e-6:\n                            current_sub_max = new_max\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n                        elif abs(new_max - current_sub_max) < 1e-6 and new_ss < current_sub_ss - 1e-6:\n                            current_sub_ss = new_ss\n                            best_sub_assign = temp_bins\n                            best_sub_weights = temp_ws\n                            found_lns_improvement = True\n\n                if found_lns_improvement:\n                    for i_idx, p_idx in enumerate(lns_packs):\n                        pack_assignment[p_idx] = torch.tensor(best_sub_assign[i_idx], dtype=torch.int64)\n                        pack_weights[p_idx] = best_sub_weights[i_idx]\n                    improved_any = True\n\n            if not improved_any:\n                break\n\n        # Final write to output tensors\n        flat_experts = pack_assignment.view(-1).to(device)\n        pack_index[i].scatter_(0, flat_experts, flat_packs_base)\n        rank_in_pack[i].scatter_(0, flat_experts, flat_ranks_base)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights for fast scalar access\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 20\n\n    import random\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_ss = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                # Deterministic LPT\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                indices = sorted(range(num_groups),\n                                 key=lambda x: layer_w_list[x] * (0.8 + 0.4 * random.random()),\n                                 reverse=True)\n\n            # 2. Greedy Construction (Least Loaded)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_cnt = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                best_p = -1\n                min_w = float('inf')\n                for p in range(num_packs):\n                    if pack_cnt[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_cnt[best_p] += 1\n\n            # 3. Refinement: Ruin & Recreate (LNS)\n            LNS_STEPS = 50 if num_packs > 1 else 0\n\n            for step in range(LNS_STEPS):\n                # Identify max and min packs\n                max_p = -1\n                min_p = -1\n                max_w = -1.0\n                min_w = float('inf')\n\n                for p_idx, pw in enumerate(pack_weights):\n                    if pw > max_w:\n                        max_w = pw\n                        max_p = p_idx\n                    if pw < min_w:\n                        min_w = pw\n                        min_p = p_idx\n\n                if max_p == min_p or (max_w - min_w < 1e-6):\n                    break\n\n                # Candidates for Ruin: Max, Min, and potentially Randoms\n                candidates = [max_p, min_p]\n\n                # Add random packs for 3-way/4-way cyclic shifts\n                if num_packs > 2:\n                    num_extra = 1 if (num_packs == 3) else random.randint(1, 2)\n                    for _ in range(num_extra):\n                        rand_p = random.randint(0, num_packs - 1)\n                        if rand_p not in candidates:\n                            candidates.append(rand_p)\n\n                # Pool items\n                items = []\n                for p in candidates:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                current_sub_max = max(pack_weights[p] for p in candidates)\n                current_sub_ss = sum(pack_weights[p]**2 for p in candidates)\n\n                best_sub_packs = None\n                best_sub_weights = None\n                found_better = False\n\n                # Sort LPT for sub-problem\n                item_data = [(layer_w_list[idx], idx) for idx in items]\n                item_data.sort(key=lambda x: x[0], reverse=True)\n\n                # Sub-problem restarts\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        sub_items = item_data\n                    else:\n                        # Perturbed LPT\n                        sub_items = sorted(item_data, key=lambda x: x[0] * (0.85 + 0.3 * random.random()), reverse=True)\n\n                    temp_packs = {p: [] for p in candidates}\n                    temp_weights = {p: 0.0 for p in candidates}\n                    temp_counts = {p: 0 for p in candidates}\n\n                    possible = True\n                    for w, idx in sub_items:\n                        # Greedy Best Fit on Subset\n                        best_local_p = -1\n                        min_local_w = float('inf')\n                        for p in candidates:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        new_max = max(temp_weights.values())\n                        new_ss = sum(v**2 for v in temp_weights.values())\n\n                        # Accept if better\n                        if new_max < current_sub_max - 1e-6:\n                            current_sub_max = new_max\n                            current_sub_ss = new_ss\n                            best_sub_packs = temp_packs\n                            best_sub_weights = temp_weights\n                            found_better = True\n                        elif abs(new_max - current_sub_max) < 1e-6:\n                            if new_ss < current_sub_ss - 1e-6:\n                                current_sub_ss = new_ss\n                                best_sub_packs = temp_packs\n                                best_sub_weights = temp_weights\n                                found_better = True\n\n                if found_better:\n                    for p in candidates:\n                        packs[p] = best_sub_packs[p]\n                        pack_weights[p] = best_sub_weights[p]\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w**2 for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_ss = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6:\n                if current_ss < best_ss - 1e-6:\n                    best_ss = current_ss\n                    best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nPerformance metrics:\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n\n# Current program\n\nHere is the current program we are trying to improve (you will need to propose a modification to it below):\n\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    device = weight.device\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Use CPU weights\n    weight_cpu = weight.cpu()\n\n    # Outputs on CPU to avoid device synchronization during fill\n    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64)\n    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64)\n\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_sum_sq = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups) * 0.15 + 0.925\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT/Best Fit)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_counts = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                # Best Fit: Assign to valid pack with min load\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_counts[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p]\n                            best_p = p\n\n                packs[best_p].append(g_idx)\n                pack_weights[best_p] += w\n                pack_counts[best_p] += 1\n\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n                # Identify heavy and light packs\n                # Optimization: Track max/min indices dynamically or just scan\n                max_p = max(range(num_packs), key=pack_weights.__getitem__)\n                min_p = min(range(num_packs), key=pack_weights.__getitem__)\n\n                if max_p == min_p:\n                    break\n\n                # If balanced enough, try to optimize variance by picking random packs\n                # Otherwise, target max load reduction\n                if pack_weights[max_p] - pack_weights[min_p] < 1e-6:\n                     # Already balanced max-min, but maybe high variance?\n                     pass\n\n                candidates = {max_p, min_p}\n                # Add random packs for k-way swaps\n                if num_packs > 2:\n                    k_random = min(2, num_packs - 2)\n                    for _ in range(k_random):\n                        candidates.add(torch.randint(0, num_packs, (1,)).item())\n\n                cand_list = list(candidates)\n\n                # Ruin\n                items = []\n                for p in cand_list:\n                    items.extend(packs[p])\n\n                # Recreate: Solve sub-problem (minimize max load of these packs)\n                best_sub_weights = [pack_weights[p] for p in cand_list]\n                best_sub_packs = [list(packs[p]) for p in cand_list]\n                best_sub_max = max(best_sub_weights)\n                best_sub_ss = sum(w*w for w in best_sub_weights)\n\n                improved_sub = False\n\n                # 0. Deterministic LPT attempt\n                # 1..N. Randomized LPT attempts\n\n                # Prepare LPT sort once\n                items_sorted = sorted(items, key=lambda x: layer_w_list[x], reverse=True)\n\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        # We use a list of tuples (perturbed_weight, index)\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n\n                if improved_sub:\n                    for idx, p in enumerate(cand_list):\n                        packs[p] = best_sub_packs[idx]\n                        pack_weights[p] = best_sub_weights[idx]\n                        pack_counts[p] = groups_per_pack # Should remain full\n\n            # 4. Evaluation\n            current_max = max(pack_weights)\n            current_ss = sum(w*w for w in pack_weights)\n\n            if current_max < best_max_load - 1e-6:\n                best_max_load = current_max\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n            elif abs(current_max - best_max_load) < 1e-6 and current_ss < best_sum_sq - 1e-6:\n                best_sum_sq = current_ss\n                best_assignment = [list(p) for p in packs]\n\n        # 5. Final assignment for this layer\n        for p, nodes in enumerate(best_assignment):\n            for r, g_idx in enumerate(nodes):\n                pack_index[i, g_idx] = p\n                rank_in_pack[i, g_idx] = r\n\n    return pack_index.to(device), rank_in_pack.to(device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_eplb(weight: torch.Tensor, num_replicas: int, num_groups: int,\n             num_nodes: int, num_gpus: int):\n    \"\"\"Run the expert parallelism load balancer\"\"\"\n    phy2log, log2phy, logcnt = rebalance_experts(\n        weight, num_replicas, num_groups, num_nodes, num_gpus\n    )\n    return phy2log, log2phy, logcnt\n\n\n__all__ = [\"rebalance_experts\", \"run_eplb\"]\n```\n\nHere are the performance metrics of the program:\n\nCombined score to maximize: 0.66\nresults_str:   balancedness_score = 0.311077\n  speed_score = 1.000000; num_workloads_evaluated: 5\n\n# Instructions\n\nMake sure that the changes you propose are consistent with each other. For example, if you refer to a new config variable somewhere, you should also propose a change to add that variable.\n\nNote that the changes you propose will be applied sequentially, so you should assume that the previous changes have already been applied when writing the SEARCH block.\n\n# Task\n\nSuggest a new idea to improve the performance of the code that is inspired by your expert knowledge of the considered subject.\nYour goal is to maximize the `combined_score` of the program.\nDescribe each change with a SEARCH/REPLACE block.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n"
            },
            {
              "role": "assistant",
              "content": "<NAME>\npolish_lns_heuristic\n</NAME>\n\n<DESCRIPTION>\nImproves the load balancing algorithm by:\n1. Increasing the number of random restarts for the initial greedy construction to explore more global basins.\n2. Introducing a fast \"Max-Pack Swap\" phase immediately after greedy construction to reduce the peak load by simple pairwise swaps with lighter packs.\n3. Enhancing the Large Neighborhood Search (LNS) \"Recreate\" step with a \"Polish\" phase: after the randomized greedy reconstruction of the subset, a specialized pairwise swap loop runs on the subset to strictly improve the local max load or variance. This allows the LNS to find finer improvements that greedy might miss.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n        layer_w = weight_cpu[i]\n        layer_w_list = layer_w.tolist()\n\n        best_max_load = float('inf')\n        best_sum_sq = float('inf')\n        best_assignment = None\n\n        for attempt in range(NUM_RESTARTS):\n            # 1. Candidate Generation\n            if attempt == 0:\n                indices = sorted(range(num_groups), key=lambda x: layer_w_list[x], reverse=True)\n            else:\n                # Randomized LPT\n                noise = torch.rand(num_groups) * 0.15 + 0.925\n                indices = (layer_w * noise).argsort(descending=True).tolist()\n\n            # 2. Greedy Construction (LPT/Best Fit)\n            packs = [[] for _ in range(num_packs)]\n            pack_weights = [0.0] * num_packs\n            pack_counts = [0] * num_packs\n\n            for g_idx in indices:\n                w = layer_w_list[g_idx]\n                # Best Fit: Assign to valid pack with min load\n                best_p = -1\n                min_w = float('inf')\n\n                for p in range(num_packs):\n                    if pack_counts[p] < groups_per_pack:\n                        if pack_weights[p] < min_w:\n                            min_w = pack_weights[p"
            },
            {
              "role": "user",
              "content": "The previous edit was not successful. This was the error message: \n\nNo changes applied.\n\n Try again."
            },
            {
              "role": "assistant",
              "content": "<NAME>\npolish_lns_heuristic\n</NAME>\n\n<DESCRIPTION>\n1. Increase `NUM_RESTARTS` to 10 and `MAX_LNS_STEPS` to 250 to utilize the available time budget for better exploration, as the current speed score is perfect (1.0).\n2. Enhance the Large Neighborhood Search (LNS) \"Recreate\" phase. After the randomized greedy filling of the subset of packs, a new \"Polish\" step is introduced. This step iteratively identifies the heaviest and lightest packs within the subset and attempts to perform 1-vs-1 item swaps to reduce the load difference. This allows the algorithm to overcome the limitations of pure greedy construction (which cannot easily undo a bad early assignment) by locally refining the subset packing using pairwise exchanges, which is computationally cheap for small subsets but effective for balance.\n</DESCRIPTION>\n\n<DIFF>\n<<<<<<< SEARCH\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 5\n\n    for i in range(num_layers):\n=======\n    # Number of restarts for the randomized heuristic\n    NUM_RESTARTS = 10\n\n    for i in range(num_layers):\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 100 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n=======\n            # 3. Refinement: Large Neighborhood Search (LNS)\n            MAX_LNS_STEPS = 250 if num_packs > 1 else 0\n\n            for step in range(MAX_LNS_STEPS):\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        # We use a list of tuples (perturbed_weight, index)\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n=======\n                SUB_RESTARTS = 20\n                for sub_attempt in range(SUB_RESTARTS):\n                    if sub_attempt == 0:\n                        current_items = items_sorted\n                    else:\n                        # Perturb weights slightly to change sort order\n                        noise_sub = torch.rand(len(items))\n                        # Efficient perturbed sort\n                        weighted_items = []\n                        for idx, item in enumerate(items):\n                            pw = layer_w_list[item] * (0.85 + 0.3 * noise_sub[idx].item())\n                            weighted_items.append((pw, item))\n                        weighted_items.sort(key=lambda x: x[0], reverse=True)\n                        current_items = [x[1] for x in weighted_items]\n\n                    # Greedy Fill (Best Fit)\n                    temp_weights = {p: 0.0 for p in cand_list}\n                    temp_packs = {p: [] for p in cand_list}\n                    temp_counts = {p: 0 for p in cand_list}\n\n                    possible = True\n                    for item_idx in current_items:\n                        w = layer_w_list[item_idx]\n\n                        best_local_p = -1\n                        min_local_w = float('inf')\n\n                        for p in cand_list:\n                            if temp_counts[p] < groups_per_pack:\n                                if temp_weights[p] < min_local_w:\n                                    min_local_w = temp_weights[p]\n                                    best_local_p = p\n\n                        if best_local_p == -1:\n                            possible = False\n                            break\n\n                        temp_packs[best_local_p].append(item_idx)\n                        temp_weights[best_local_p] += w\n                        temp_counts[best_local_p] += 1\n\n                    if possible:\n                        # Polish: Attempt pairwise swaps within subset\n                        s_keys = list(temp_weights.keys())\n                        for _ in range(5):\n                            p_max = max(s_keys, key=temp_weights.get)\n                            p_min = min(s_keys, key=temp_weights.get)\n                            w_max = temp_weights[p_max]\n                            w_min = temp_weights[p_min]\n                            if w_max - w_min < 1e-6:\n                                break\n                            \n                            best_swap = None\n                            best_gain = -1.0\n                            \n                            for i_idx, u in enumerate(temp_packs[p_max]):\n                                wu = layer_w_list[u]\n                                for j_idx, v in enumerate(temp_packs[p_min]):\n                                    wv = layer_w_list[v]\n                                    delta = wu - wv\n                                    diff = w_max - w_min\n                                    if delta > 1e-6 and delta < diff:\n                                        gain = delta * (diff - delta)\n                                        if gain > best_gain:\n                                            best_gain = gain\n                                            best_swap = (i_idx, j_idx, delta)\n                            \n                            if best_swap:\n                                i_idx, j_idx, delta = best_swap\n                                u = temp_packs[p_max][i_idx]\n                                v = temp_packs[p_min][j_idx]\n                                temp_packs[p_max][i_idx] = v\n                                temp_packs[p_min][j_idx] = u\n                                temp_weights[p_max] -= delta\n                                temp_weights[p_min] += delta\n                            else:\n                                break\n\n                        c_max = max(temp_weights.values())\n                        c_ss = sum(v*v for v in temp_weights.values())\n\n                        # Check improvement\n                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):\n                            best_sub_max = c_max\n                            best_sub_ss = c_ss\n                            best_sub_weights = [temp_weights[p] for p in cand_list]\n                            best_sub_packs = [temp_packs[p] for p in cand_list]\n                            improved_sub = True\n>>>>>>> REPLACE\n</DIFF>"
            }
          ],
          "model_name": "gemini-3-pro-preview",
          "kwargs": {
            "temperature": 1.0,
            "max_tokens": 16384
          },
          "input_tokens": 35293,
          "output_tokens": 8806,
          "cost": 0.176258,
          "input_cost": 0.070586,
          "output_cost": 0.105672,
          "thought": "",
          "model_posteriors": {
            "gemini-3-pro-preview": 1.0
          }
        },
        "diff_summary": {
          "added": 35,
          "deleted": 0,
          "modified": 4
        },
        "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
        "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
        "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
        "embed_cost": 7.684e-05,
        "novelty_cost": 0.0,
        "stdout_log": "Remote workload not found, using local: /home/ubuntu/ShinkaEvolve/examples/eplb/../../openevolve_examples/eplb/expert-load.json\nEvaluating program: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_92/main.py\nSaving results to: /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_92/results\nRun 1/5 completed in 1179.10 seconds\nRun 2/5 completed in 1430.64 seconds\nRun 3/5 completed in 1356.87 seconds\nRun 4/5 completed in 1258.87 seconds\nRun 5/5 completed in 1211.97 seconds\nbalancedness: 0.2107368773898687\nbalancedness: 0.3397761717755627\nbalancedness: 0.36715790710736596\nbalancedness: 0.35273856382103885\nbalancedness: 0.2849763771150806\nCorrectness and error status saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_92/results/correct.json\nMetrics saved to /home/ubuntu/zresults/shinka_eplb_gemini3pro_run4_20251126_071036/2025.11.26114554/gen_92/results/metrics.json\nEvaluation and Validation completed successfully.\nMetrics:\n  combined_score: 0.6555385897208916\n  public: {'results_str': '  balancedness_score = 0.311077\\n  speed_score = 1.000000', 'num_workloads_evaluated': 5}\n  private: {'avg_balancedness_score': 0.31107717944178337, 'speed_score': 1.0}\n  execution_time_mean: 1287.4906858423988\n  execution_time_std: 93.35451923557328\n  num_valid_runs: 5\n  num_invalid_runs: 0\n  all_validation_errors: []\n",
        "stderr_log": "",
        "code_analysis_metrics": {
          "cyclomatic_complexity": 69,
          "average_cyclomatic_complexity": 13.8,
          "halstead_volume": 2331.59602182324,
          "halstead_difficulty": 10.92,
          "halstead_effort": 25461.02855830978,
          "lines_of_code": 434,
          "logical_lines_of_code": 229,
          "comments": 38,
          "maintainability_index": -44.98006104102981,
          "max_nesting_depth": 11,
          "complexity_score": 1.0
        }
      },
      "in_archive": false
    }
  ],
  "meta_summary": "**Program Name: Hierarchical Expert Load Balancer with Greedy Packing**\n- **Implementation**: The algorithm employs a hierarchical strategy that packs expert groups onto nodes and physical experts onto GPUs using a greedy sort-and-fill heuristic. It dynamically replicates high-load experts to distribute processing while maintaining node locality to optimize for network topology.\n- **Performance**: It achieves maximum efficiency in execution speed (1.0) but yields a low balancedness score (0.31), leading to a combined score of 0.66.\n- **Feedback**: While the execution is rapid and structurally correct regarding node constraints, the greedy packing logic produces suboptimal load distributions; employing more advanced partitioning or iterative refinement could significantly improve load balance.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy-Swap Packing**\n- **Implementation**: Implements a hierarchical load balancing strategy using a greedy LPT initialization followed by a pairwise swap local search to optimize fixed-cardinality bin packing on CPU.\n- **Performance**: The solution is extremely fast (speed score 1.0) but achieves suboptimal load distribution (balancedness score 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based greedy approach minimizes runtime overhead, the simple swap heuristic limits the algorithm's ability to escape local optima, suggesting a need for a more robust partitioning solver to improve balance.\n**Program Identifier:** Generation 1 - Patch Name refine_packing - Correct Program: True\n\n**Program Name: Vectorized Sort-and-Zigzag Hierarchical Load Balancer**\n- **Implementation**: The solution implements a hierarchical load balancer using a vectorized Sort-and-Zigzag packing algorithm for node and GPU assignment, coupled with proportional replication logic via tensor scatter-gather operations.\n- **Performance**: The program received a score of 0.0, indicating it failed to pass functional validation tests.\n- **Feedback**: The `zigzag_pack` function enforces strict divisibility constraints (asserting items modulo bins equals zero) which causes failures on non-uniform inputs, and the complex vectorized index reconstruction likely produces incorrect physical-to-logical mappings.\n**Program Identifier:** Generation 2 - Patch Name vectorized_zigzag_eplb - Correct Program: False\n\n**Program Name: Hierarchical EPLB with Greedy Packing and CPU Optimization**\n- **Implementation**: The algorithm employs a greedy strategy with swap-based refinement for bin packing, moving tensors to the CPU during iterative steps to eliminate GPU synchronization overhead.\n- **Performance**: It achieves excellent speed (1.0) but moderate load balancing effectiveness (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Moving scalar operations to the CPU successfully maximizes speed, but the current packing heuristic struggles to achieve high balancedness compared to more complex optimization approaches.\n**Program Identifier:** Generation 3 - Patch Name optimize_balanced_packing_with_swap - Correct Program: True\n\n**Program Name: Hierarchical EPLB with LPT and Local Search**\n- **Implementation**: The solution implements a hierarchical balancing strategy using a greedy Longest Processing Time (LPT) algorithm followed by a local search that iteratively swaps items between the heaviest pack and others to minimize variance.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) but lagging in balancedness (0.31).\n- **Feedback**: The perfect speed score confirms the efficiency of the greedy approach, but the low balancedness indicates that the limited local swap logic is insufficient for optimizing highly skewed expert distributions effectively compared to more complex solvers.\n**Program Identifier:** Generation 4 - Patch Name vectorized_local_search - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Greedy Swap Refinement**\n- **Implementation**: This approach utilizes a hierarchical strategy to distribute expert groups across nodes and GPUs, employing a greedy bin-packing algorithm optimized with CPU-based list operations and pairwise swap refinement.\n- **Performance**: The solution maximizes execution speed (score 1.0) but achieves only moderate load balancing (score 0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation's conversion of tensors to CPU lists ensures rapid execution, though the greedy packing with limited local search (20 iterations) limits the algorithm's ability to find globally optimal load distributions.\n**Program Identifier:** Generation 5 - Patch Name improved_balanced_packing_refinement - Correct Program: True\n\n**Program Name: Vectorized Greedy Packing with Local Search for Expert Balancing**\n- **Implementation**: The algorithm uses a greedy Modified Longest Processing Time (LPT) approach for initial assignment, followed by a vectorized local search that swaps items between the heaviest pack and others using tensor operations to minimize maximum load.\n- **Performance**: It achieved a combined score of 0.66, with perfect speed (1.0) but poor balancedness (0.31).\n- **Feedback**: While the vectorized swap logic and CPU-based scalar access ensure high throughput, the low balancedness score indicates the heuristic struggles to escape local optima, suggesting the need for more iterations or a more robust global optimization strategy.\n**Program Identifier:** Generation 6 - Patch Name improved_balanced_packing_local_search - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU Greedy Init and Vectorized Refinement**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based Longest Processing Time (LPT) greedy initialization followed by a vectorized local search that iteratively swaps experts to reduce maximum load.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score of 0.31, prioritizing runtime efficiency.\n- **Feedback**: The hybrid approach of performing sequential sorting/packing on the CPU and vectorized refinement on the GPU effectively minimizes overhead, though the balancedness score indicates potential room for more aggressive optimization logic.\n**Program Identifier:** Generation 7 - Patch Name vectorized_eplb_v2 - Correct Program: True\n\n**Program Name: DeepSeek EPLB Hierarchical Load Balancer with CPU-Offloaded Greedy Packing**\n- **Implementation**: The algorithm utilizes a hierarchical approach that first greedily packs expert groups onto nodes and then refinedly packs physical experts onto GPUs, offloading sequential sorting and swapping logic to the CPU to minimize overhead.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The decision to perform iterative packing operations on the CPU proved highly effective for runtime speed, though the greedy heuristic with pairwise swapping yielded only moderate load balancing quality.\n**Program Identifier:** Generation 8 - Patch Name optimize_balanced_packing_logic - Correct Program: True\n\n**Program Name: Hierarchical EPLB with CPU-Based Greedy LPT and Refinement**\n- **Implementation**: The solution implements a hierarchical load balancer using a `balanced_packing` algorithm that runs on the CPU, combining a greedy Longest Processing Time (LPT) initialization with a swap-based local search refinement phase.\n- **Performance**: The program achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, leading to a combined score of 0.66.\n- **Feedback**: The decision to offload sequential packing logic to the CPU and limit refinement iterations maximized execution speed, but the trade-off was a less optimal load distribution compared to more computationally intensive approaches.\n**Program Identifier:** Generation 9 - Patch Name eplb_greedy_refine_opt - Correct Program: True\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The solution employs a Longest Processing Time (LPT) greedy packing algorithm with pairwise swap refinement, executing sequential operations on the CPU to eliminate GPU kernel launch overheads.\n- **Performance**: The program achieved a perfect speed score of 1.0 and a balancedness score of 0.31.\n- **Feedback**: Moving sequential, iterative packing logic to the CPU was a key optimization that maximized execution speed, although the resulting load balance suggests potential for more sophisticated swapping heuristics.\n**Program Identifier:** Generation 10 - Patch Name eplb_opt_greedy_inc - Correct Program: True\n\n**Program Name: Randomized Greedy CPU-Based Expert Load Balancer**\n- **Implementation**: The algorithm moves weights to CPU to avoid synchronization overhead and uses a multi-restart randomized greedy strategy supplemented by a local search refinement phase that attempts to swap experts between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is computationally efficient due to CPU offloading and simple heuristics, the randomized greedy approach with limited local swaps produces suboptimal load distributions compared to more robust packing algorithms.\n**Program Identifier:** Generation 11 - Patch Name randomized_greedy_restarts - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Local Search**\n- **Implementation**: The algorithm employs CPU-based deterministic and perturbed greedy strategies for initial packing, followed by a vectorized local search refinement that optimizes swaps between the heaviest pack and others. It supports hierarchical load balancing by recursively packing groups to nodes and then experts to GPUs using this packing primitive.\n- **Performance**: The solution achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31 across evaluated workloads.\n- **Feedback**: The use of vectorized operations and CPU offloading ensures minimal overhead resulting in perfect speed, though the balancedness score suggests that the local search depth or heuristic complexity could be increased to further improve packing quality.\n**Program Identifier:** Generation 12 - Patch Name multi_start_balanced_packing - Correct Program: True\n\n**Program Name: Greedy EPLB with Iterative Pairwise Swapping Refinement**\n- **Implementation**: The algorithm utilizes a greedy initial packing of sorted weights followed by an iterative refinement stage that performs pairwise swaps between packs to reduce load disparities, operating purely on CPU lists for efficiency.\n- **Performance**: The solution yields a combined score of 0.66, delivering perfect speed (1.0) but only moderate load balancing (0.31).\n- **Feedback**: While moving operations to the CPU ensures high execution speed, the greedy strategy combined with simple local swapping struggles to find global optima, resulting in suboptimal balancedness scores.\n**Program Identifier:** Generation 13 - Patch Name aggressive_refinement - Correct Program: True\n\n**Program Name: Randomized LPT with Vectorized Local Search for EPLB**\n- **Implementation**: Utilizes a randomized greedy Longest Processing Time (LPT) heuristic with multiple restarts, refined by a vectorized local search that swaps experts between the most heavily loaded pack and others to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) while maintaining moderate balancedness (0.31).\n- **Feedback**: The vectorized swap implementation ensures high throughput, but the lower balancedness score suggests that more aggressive optimization or higher restart counts could improve the final packing quality.\n**Program Identifier:** Generation 14 - Patch Name randomized_restarts_packing - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy LPT and Pairwise Swap Refinement**\n- **Implementation**: The algorithm employs a CPU-based greedy Longest Processing Time (LPT) strategy refined by iterative pairwise swapping for packing, alongside a vectorized greedy method for expert replication.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential packing logic to CPU lists proved highly effective for speed by eliminating GPU synchronization overheads. However, the local search heuristic trades optimal load balancing for execution speed, limiting the final balancedness score compared to global optimization solvers.\n**Program Identifier:** Generation 15 - Patch Name greedy_allpairs_descent_load_balancer - Correct Program: True\n\n**Program Name: Randomized LPT with Local Search for Expert Load Balancing**\n- **Implementation**: The `balanced_packing` function employs a randomized Greedy LPT heuristic with 50 restarts and weight perturbation, refined by a swap-based local search on the CPU to minimize maximum load.\n- **Performance**: Achieves a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: Offloading the iterative heuristic to the CPU effectively prevents GPU synchronization overhead, ensuring high throughput. However, the moderate balancedness score indicates that the local search, limited to single swaps among the heaviest packs, may require more complex moves (e.g., multi-item swaps) to handle highly skewed distributions better.\n**Program Identifier:** Generation 16 - Patch Name improved_balanced_packing_restarts_and_refinement - Correct Program: True\n\n**Program Name:** CPU-Based Randomized Greedy EPLB with Local Search\n- **Implementation**: The solution utilizes a CPU-based randomized greedy strategy that sorts experts by weight (LPT) with noise perturbation across multiple restarts, followed by an iterative local search that refines the assignment by swapping items from the heaviest pack.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While offloading sequential logic to the CPU maximizes execution speed, the randomized greedy heuristic with simple local swaps produces suboptimal packing quality compared to more robust optimization techniques.\n**Program Identifier:** Generation 17 - Patch Name randomized_greedy_with_restarts - Correct Program: True\n\n**Program Name: Randomized Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm utilizes a multi-restart randomized greedy LPT strategy on the CPU, followed by a steepest descent local search that iteratively swaps items from the heaviest pack to lighter ones to minimize load difference.\n- **Performance**: It achieved a combined score of 0.66, characterized by maximum execution speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient due to CPU offloading and vectorized operations, the low balancedness score suggests that the randomized greedy approach with limited local swaps struggles to escape local optima for complex weight distributions.\n**Program Identifier:** Generation 18 - Patch Name iterative_descent_packing - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized LPT with Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, followed by a pairwise swap local search to refine bin weights.\n- **Performance**: It achieved a perfect speed score of 1.00 but a lower balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation is exceptionally fast due to CPU processing and limited iterations, but the greedy heuristic with local search struggles to find optimal packings for complex distributions compared to more exhaustive methods.\n**Program Identifier:** Generation 19 - Patch Name randomized_greedy_packing_eplb - Correct Program: True\n\n**Program Name: Hybrid EPLB with ZigZag Packing and Greedy Local Search**\n- **Implementation**: This approach combines ZigZag packing and projected Best-Fit heuristics to generate initial candidates, followed by an iterative refinement phase that swaps tasks between maximum and minimum load processors to reduce variance.\n- **Performance**: The solution maximizes speed (1.0) with a total score of 0.66, though the balancedness score (0.31) indicates moderate packing efficiency.\n- **Feedback**: The implementation is highly efficient computationally, but the greedy swap mechanism limits the exploration of the solution space, preventing higher balancedness scores on complex workload distributions.\n**Program Identifier:** Generation 20 - Patch Name projected_zigzag_packing - Correct Program: True\n\n**Program Name: Randomized Greedy with Large Neighborhood Search for Expert Balancing**\n- **Implementation**: The solution implements a randomized greedy packing strategy (LPT with noise) followed by a Large Neighborhood Search (LNS) refinement on the CPU to iteratively repack the heaviest, lightest, and random bins.\n- **Performance**: It achieves a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading the sequential iterative logic to the CPU successfully eliminates GPU kernel overheads, while the LNS mechanism effectively targets specific areas of imbalance to improve solution quality efficiently.\n**Program Identifier:** Generation 21 - Patch Name lns_refinement_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Vectorized Swap and Pairwise Refinement**\n- **Implementation**: Utilizes a multi-start randomized greedy strategy followed by vectorized 2-opt swaps and a pairwise \"ruin and recreate\" refinement that re-partitions the heaviest and lightest packs to minimize load variance.\n- **Performance**: Achieved a combined score of 0.66, maximizing speed (1.0) while attaining a balancedness score of 0.31.\n- **Feedback**: The vectorization of swap gain calculations significantly boosts speed, yet the randomized heuristic struggles to achieve high balancedness compared to more computationally intensive exact methods.\n**Program Identifier:** Generation 22 - Patch Name pairwise_rebalancing_and_restarts - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Greedy Packing and Pairwise Swapping**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-optimized greedy assignment strategy followed by an iterative pairwise swapping heuristic to refine expert distribution across nodes and GPUs.\n- **Performance**: Achieved a combined score of 0.66, excelling in speed (1.0) but receiving a lower balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively via CPU offloading and greedy heuristics, but the local search refinement is currently insufficient to achieve high load balancedness for the evaluated workloads.\n**Program Identifier:** Generation 23 - Patch Name randomized_restarts_and_optimized_replication - Correct Program: True\n\n**Program Name: Hybrid CPU-Greedy with Vectorized GPU LNS Refinement**\n- **Implementation**: The solution combines a fast CPU-based randomized greedy initialization with a GPU-accelerated refinement phase using vectorized pairwise swaps and 3-pack Large Neighborhood Search (LNS).\n- **Performance**: Achieved a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While computationally efficient, the low balancedness score indicates that the local search heuristics (swaps and LNS) are insufficient to escape local optima found by the greedy initialization; deeper search or more aggressive perturbation is required.\n**Program Identifier:** Generation 24 - Patch Name iterative_refinement_lns_retry - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The solution utilizes multiple perturbed LPT candidates for initialization and refines the packing using vectorized 1-swaps and a 3-pack Large Neighborhood Search (LNS).\n- **Performance**: It achieved a perfect speed score of 1.00 and a balancedness score of 0.31.\n- **Feedback**: The use of vectorized operations and CPU-based list handling ensures maximum speed, but the lower balancedness score indicates that the local search depth or heuristic complexity may need tuning for better load distribution.\n**Program Identifier:** Generation 25 - Patch Name iterative_refinement_lns - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: Implements a multi-stage heuristic combining randomized greedy initialization with restarts, vectorized pairwise swaps to reduce peak loads, and a 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement.\n- **Performance**: Achieved a combined score of 0.66, delivering perfect speed (1.0) but achieving only moderate load balancedness (0.31).\n- **Feedback**: The algorithm effectively leverages vectorization to maintain high throughput, though the heuristic approach sacrifices some packing quality for execution speed compared to more exhaustive solvers.\n**Program Identifier:** Generation 26 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with LNS and Pairwise Swaps Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic on CPU, combining randomized greedy LPT initialization with 3-pack Large Neighborhood Search (LNS) and pairwise item swaps to refine load distribution, alongside heap-based expert replication.\n- **Performance**: It achieves a combined score of 0.66, characterized by excellent speed (1.0) but limited balancedness (0.31).\n- **Feedback**: The implementation prioritizes execution speed effectively, but the relatively low balancedness suggests the local search heuristics (LNS and swaps) struggle to escape local optima or manage complex weight distributions effectively.\n**Program Identifier:** Generation 27 - Patch Name iterative_lns_packing - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage heuristic starting with randomized greedy initialization, followed by vectorized pairwise swapping, 3-way cyclic exchanges, and a \"ruin and recreate\" Large Neighborhood Search (LNS) on 3-pack subsets.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but a lower balancedness score (~0.31).\n- **Feedback**: The use of vectorized operations and CPU-based scalar logic ensured the algorithm remained extremely fast, but the moderate balancedness score suggests the heuristics may settle into local optima too quickly on difficult distributions.\n**Program Identifier:** Generation 28 - Patch Name three_way_cycle_lns_enhanced - Correct Program: True\n\n**Program Name: Cardinality-Constrained EPLB with LNS and Binary Search**\n- **Implementation**: The algorithm uses a CPU-based solver combining Greedy LPT initialization with an optimized pairwise swap refinement using binary search and a Large Neighborhood Search (Ruin & Recreate) meta-heuristic.\n- **Performance**: The program achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the binary search optimization ensures high throughput, the moderate balancedness suggests the LNS heuristic struggles to fully optimize distributions under strict cardinality constraints.\n**Program Identifier:** Generation 29 - Patch Name eplb_lns_bisect - Correct Program: True\n\n**Program Name: Multi-Strategy Greedy Packing with Cyclic Swap Refinement**\n- **Implementation**: The solution utilizes three CPU-based heuristics (ZigZag, Projected Best-Fit, and Randomized LPT) to generate initial candidates, followed by an iterative refinement phase employing pairwise and 3-way cyclic swaps to minimize maximum load.\n- **Performance**: Achieved a combined score of 0.66, excelling in execution speed (1.0) with a balancedness score of 0.31.\n- **Feedback**: Offloading scalar logic to the CPU avoids GPU launch overheads, while the combination of diverse initialization strategies and targeted local search (swaps) ensures extremely low latency without sacrificing too much solution quality.\n**Program Identifier:** Generation 30 - Patch Name refined_3way_swap_and_restarts - Correct Program: True\n\n**Program Name: Target-Aware Packing with LNS**\n- **Implementation**: The solution implements a \"Target-Aware Best-Fit Decreasing\" algorithm on CPU using Python lists, followed by a Large Neighborhood Search (Ruin and\n**Program Identifier:** Generation 31 - Patch Name lns_repacking_heuristic - Correct Program: False\n\n**Program Name: Hybrid Beam Search and Vectorized Local Search Load Balancer**\n- **Implementation**: The solution employs an LPT-based Beam Search (width 8) for initial packing, followed by a vectorized local search that iteratively attempts to swap items from the heaviest pack to reduce maximum load.\n- **Performance**: Achieved a combined score of 0.66, with perfect speed (1.0) but moderate balancedness (0.31).\n- **Feedback**: While the vectorized refinement ensures high throughput, the restricted swap logic (only targeting the max-load bin) and narrow beam width limit the algorithm's ability to achieve optimal load distribution.\n**Program Identifier:** Generation 32 - Patch Name beam_search_init - Correct Program: True\n\n**Program Name: Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The `balanced_packing` function utilizes a randomized greedy strategy with restarts for initial assignment, followed by Large Neighborhood Search (LNS) on the CPU to iteratively refine the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, distinguishing itself with a perfect speed score (1.00) but a relatively low balancedness score (0.31).\n- **Feedback**: While the heuristic approach is highly efficient computationally, the low balancedness indicates suboptimal load distribution; stronger global optimization techniques or more aggressive refinement steps are needed to improve packing quality.\n**Program Identifier:** Generation 33 - Patch Name lns_repack - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Local Search Refinement**\n- **Implementation**: The solution employs a multi-restart greedy strategy that adds noise to weight sorting for diversity, followed by a heuristic swap refinement phase that attempts to offload tasks from the heaviest to lightest packs to minimize load spread.\n- **Performance**: The program excels in execution speed (1.0) but achieves only moderate load balancing effectiveness (0.31), leading to a combined score of 0.66.\n- **Feedback**: The implementation prioritizes computational efficiency through simple heuristics and CPU processing, which successfully minimizes overhead but leaves room for improvement in handling complex, skewed load distributions compared to more intensive optimization solvers.\n**Program Identifier:** Generation 34 - Patch Name randomized_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Expert Parallelism Load Balancer with Local Search**\n- **Implementation**: Uses a custom `balanced_packing` algorithm combining greedy initialization, vectorized local search for swapping items, and randomized pairwise re-packing to optimize load distribution across expert groups and nodes.\n- **Performance**: Achieved a combined score of 0.0, failing to pass validation tests.\n- **Feedback**: The complex multi-stage packing implementation likely introduced logic errors or state inconsistencies, causing the solver to produce invalid assignments despite the sophisticated optimization attempts.\n**Program Identifier:** Generation 35 - Patch Name add_lns_refinement - Correct Program: False\n\n**Program Name: CPU-Offloaded Greedy Packing with Randomized Swap Refinement**\n- **Implementation**: The solution moves sequential packing logic to the CPU, employing a descending-sort greedy assignment followed by randomized swap-based local search to balance expert loads.\n- **Performance**: It achieves a perfect speed score (1.0) due to efficient CPU execution, but a lower balancedness score (0.31), resulting in a 0.66 combined score.\n- **Feedback**: The implementation excels in speed by avoiding GPU overheads for sequential logic, though the heuristic packing approach struggles to achieve high load uniformity compared to more complex solvers.\n**Program Identifier:** Generation 36 - Patch Name opt_packing_and_repl - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Vectorized Swap and K-Way LNS**\n- **Implementation**: Features a randomized LPT initialization followed by a refinement loop using vectorized pairwise swaps on the heaviest pack and a K-way Ruin-and-Recreate strategy.\n- **Performance**: Achieves maximum speed (1.0) with a combined score of 0.66, though balancedness (0.31) remains limited.\n- **Feedback**: The implementation prioritizes computational efficiency through vectorization and restricted iteration counts, but this trade-off limits the solver's ability to escape local optima and achieve tighter load balancing.\n**Program Identifier:** Generation 38 - Patch Name eplb_hybrid_lns_vectorized - Correct Program: True\n\n**Program Name: Greedy LPT with Cyclic Swaps and Large Neighborhood Search**\n- **Implementation**: Features a CPU-based solver utilizing Greedy LPT initialization, refined by efficient pairwise and 3-way cyclic swaps with binary search, and a stochastic Large Neighborhood Search (Ruin & Recreate) mechanism.\n- **Performance**: Achieves a combined score of 0.66, driven by a perfect speed score (1.0) and a balancedness score of 0.31.\n- **Feedback**: The approach effectively balances implementation complexity and execution time, but the resulting load balance leaves room for improvement, suggesting the need for more exhaustive search strategies given the available time budget.\n**Program Identifier:** Generation 39 - Patch Name three_way_swap - Correct Program: True\n\n**Program Name: Iterated Local Search with Greedy Initialization for Load Balancing**\n- **Implementation**: The solution employs a Greedy Longest Processing Time (LPT) initialization followed by an Iterated Local Search (ILS) on the CPU that perturbs solutions via random swaps and explicitly targets reducing the load gap between the heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.00) but a modest balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: While the approach is extremely fast due to the efficient greedy heuristic and limited search iterations, the local search strategy struggles to escape local optima effectively, resulting in suboptimal load distribution compared to more exhaustive methods.\n**Program Identifier:** Generation 40 - Patch Name ils_balanced_packing - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Large Neighborhood Search**\n- **Implementation**: The solution employs a multi-start randomized Best Fit Descending heuristic constrained by pack capacity, followed by a Large Neighborhood Search (LNS) that iteratively re-optimizes the heaviest and lightest packs to reduce load variance.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The approach is computationally efficient and minimizes synchronization overheads by running on the CPU, though the randomized greedy strategy struggles to find the tightest possible packing compared to more exhaustive search methods.\n**Program Identifier:** Generation 37 - Patch Name lns_repacking - Correct Program: True\n\n**Program Name: Randomized Greedy LPT with Pairwise Swap Refinement**\n- **Implementation**: Performs packing on CPU using a randomized greedy Longest Processing Time (LPT) strategy with limited restarts, refining the distribution via iterative 1-item and 2-item swaps between the heaviest and lightest packs.\n- **Performance**: Achieved a combined score of 0.66, characterized by perfect execution speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: The algorithm prioritizes speed significantly over precision; the limited number of restarts (2) and local search depth restricts the ability to escape local optima, resulting in a lower balancedness score.\n**Program Identifier:** Generation 41 - Patch Name lpt_with_multi_swap_refinement - Correct Program: True\n\n**Program Name: CPU-Offloaded Randomized LPT with Hybrid Local Search Refinement**\n- **Implementation**: The algorithm offloads computation to the CPU, utilizing a restart strategy with randomized LPT initialization followed by a two-stage refinement process involving total repacking of extreme bins and single-item swaps.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient in terms of runtime, the lower balancedness suggests that the current local search heuristics are insufficient for finding optimal packings in complex distributions, favoring speed over precision.\n**Program Identifier:** Generation 42 - Patch Name balanced_packing_merge_repack - Correct Program: True\n\n**Program Name:** CPU-Based Randomized LPT Packing with Pairwise Refinement\n- **Implementation:** The solution offloads packing logic to the CPU, applying a randomized Longest Processing Time (LPT) greedy strategy followed by iterative pairwise bin refinement to balance expert loads.\n- **Performance:** The implementation is extremely fast (speed score 1.0) but yields suboptimal packing quality (balancedness score 0.31), resulting in a combined score of 0.66.\n- **Feedback:** While the CPU-offloaded greedy approach minimizes overhead, the moderate balancedness score suggests that the pairwise refinement heuristic is insufficient for global optimization and could benefit from more aggressive search strategies.\n**Program Identifier:** Generation 43 - Patch Name iterative_2bin_repartitioning - Correct Program: True\n\n**Program Name: Hybrid Vectorized Greedy and LNS Load Balancer**\n- **Implementation**: The algorithm employs CPU-based randomized greedy initialization with Longest Processing Time (LPT) sorting, refined by vectorized pairwise swaps and Large Neighborhood Search (LNS) on heavy and light packs to escape local optima.\n- **Performance**: Achieves a combined score of 0.66, characterized by a perfect speed score (1.0) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU successfully mitigates CUDA kernel overhead, while the multi-stage refinement strategy (swaps plus LNS) efficiently balances computational cost with load distribution quality.\n**Program Identifier:** Generation 44 - Patch Name hybrid_vectorized_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Projected Best-Fit Packing with Local Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using a sorted projected best-fit heuristic that accounts for future item weights, followed by 20 iterations of local swap refinement to minimize the heaviest pack's load.\n- **Performance**: The solution attains a perfect speed score (1.0) but a lower balancedness score (0.31), yielding a combined score of 0.65.\n- **Feedback**: Moving sequential packing logic to the CPU maximizes speed, but the heuristic-based packing and limited refinement steps provide only suboptimal load distribution, suggesting a need for more advanced global optimization strategies to improve balance.\n**Program Identifier:** Generation 45 - Patch Name eplb_projected_greedy - Correct Program: True\n\n**Program Name: Multi-Strategy Heuristic Packing with Cyclic Swapping**\n- **Implementation**: The algorithm generates initial candidate packings on the CPU using ZigZag, Projected Best-Fit, and Randomized LPT strategies, followed by an iterative refinement phase that utilizes pairwise swaps and 3-way cyclic transfers to minimize load variance.\n- **Performance**: The solution achieved a combined score of 0.66, characterized by a perfect speed score (1.00) and a moderate balancedness score (0.31).\n- **Feedback**: Offloading scalar packing logic to the CPU ensures high throughput, while the combination of diverse initialization heuristics and cyclic refinement provides a fast, practical trade-off between execution time and load distribution quality.\n**Program Identifier:** Generation 46 - Patch Name improved_balanced_packing_with_reshuffle - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Vectorized Swaps**\n- **Implementation**: The algorithm utilizes a randomized target-aware greedy initialization followed by vectorized pairwise swaps and a 3-way Large Neighborhood Search (LNS) for refinement.\n- **Performance**: It achieved a combined score of 0.66, excelling in speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The implementation is highly efficient due to vectorization, but the heuristic packing and limited local search depth restrict its ability to find tighter packings compared to more exhaustive solvers.\n**Program Identifier:** Generation 47 - Patch Name target_aware_greedy - Correct Program: True\n\n**Program Name: Randomized Greedy Packing with Ruin-and-Recreate Refinement**\n- **Implementation**: The solution employs a randomized greedy construction based on Longest Processing Time (LPT) with multiple restarts, followed by a Large Neighborhood Search (LNS) refinement that locally re-optimizes the most and least loaded packs using CPU-based operations.\n- **Performance**: The algorithm achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the approach is extremely efficient computationally, the low balancedness score suggests the randomized heuristics and limited local search are insufficient for finding tight packings compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 48 - Patch Name improved_lns_packing - Correct Program: True\n\n**Program Name: Vectorized EPLB with Randomized Greedy and 3-Way LNS**\n- **Implementation**: This approach combines randomized greedy initialization (Best Fit) with vectorized pairwise swaps to target the heaviest bin and a cyclic 3-way Large Neighborhood Search (Ruin & Recreate) for local refinement. It leverages PyTorch broadcasting for efficient swap evaluation and noise injection to diversify search restarts.\n- **Performance**: The solution attained a combined score of 0.66, characterized by perfect speed (1.0) but a modest balancedness score (0.31).\n- **Feedback**: The high speed confirms the efficiency of the vectorized operations, but the low balancedness suggests the local search heuristics (swaps and small-scale LNS) are insufficient for finding globally optimal packings in difficult instances.\n**Program Identifier:** Generation 49 - Patch Name cyclic_lns_balancer - Correct Program: True\n\n**Program Name: Multi-Start Greedy LPT with Vectorized Swap and LNS Refinement**\n- **Implementation**: The algorithm employs a multi-start greedy Longest Processing Time (LPT) strategy with randomized weight perturbations, followed by vectorized swap operations and K-Way Large Neighborhood Search (LNS) to iteratively refine pack assignments.\n- **Performance**: The solution achieved a combined score of 0.66, maintaining a perfect speed score (1.0) while reaching a balancedness score of 0.31.\n- **Feedback**: While the vectorized operations on CPU ensured execution speed was maximized, the lower balancedness score suggests that the local search heuristics may struggle to escape local optima in highly skewed expert weight distributions.\n**Program Identifier:** Generation 50 - Patch Name eplb_hybrid_v1 - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy LPT and LNS**\n- **Implementation**: The algorithm uses CPU-based scalar logic for a \"best-of-k\" randomized greedy LPT initialization, followed by a Large Neighborhood Search (LNS) that iteratively refines the assignment of the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, obtaining a perfect speed score (1.00) but a modest balancedness score (0.31).\n- **Feedback**: Offloading logic to the CPU maximized execution speed, but the lower balancedness suggests the LNS strategy needs more iterations or aggressive perturbation to better escape local optima.\n**Program Identifier:** Generation 51 - Patch Name improved_rebalance_lns - Correct Program: True\n\n**Program Name: Cyclic Large Neighborhood Search Load Balancer**\n- **Implementation**: The algorithm employs a multi-stage metaheuristic that initializes with a randomized greedy Best Fit strategy based on Longest Processing Time (LPT), followed by iterative refinement using pairwise rebalancing and 3-way Large Neighborhood Search (LNS) to smooth load disparities.\n- **Performance**: The solution achieves a combined score of 0.66, with a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the heuristic approach is extremely fast and efficient, the lower balancedness score suggests that the randomized local search steps often struggle to escape local optima compared to more exhaustive optimization methods.\n**Program Identifier:** Generation 52 - Patch Name pairwise_rebalance_refinement - Correct Program: True\n\n**Program Name**: Randomized Greedy Packing with Pairwise Reshuffling\n- **Implementation**: The algorithm employs a CPU-based randomized greedy packing strategy with multiple restarts, refined by a pairwise reshuffling heuristic that iteratively rebalances the heaviest and lightest packs.\n- **Performance**: It attains a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively by avoiding complex solvers, but the greedy heuristic and limited local search depth result in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 53 - Patch Name randomized_restarts_and_reshuffle - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The algorithm employs `NUM_INIT_RESTARTS=8` randomized greedy initializations followed by a refinement loop using pairwise steepest descent swaps and a 3-pack Large Neighborhood Search (LNS) ruin-and-recreate strategy.\n- **Performance**: The solution achieves perfect speed (1.0) but results in suboptimal load distribution (balancedness 0.31), yielding a combined score of 0.66.\n- **Feedback**: While the heuristic approach is extremely fast, the low balancedness score indicates that the randomized greedy and local search methods struggle to escape local optima or achieve tight packing compared to more rigorous optimization techniques.\n**Program Identifier:** Generation 54 - Patch Name hybrid_greedy_swap_lns - Correct Program: True\n\n**Program Name: EPLB with Beam Search and Pairwise Cyclic Repartitioning**\n- **Implementation**: The algorithm initializes assignments using a Beam Search on the heaviest items followed by a greedy fill, and subsequently improves the packing through iterative pairwise repartitioning between the heaviest, lightest, and random packs using randomized splitting.\n- **Performance**: The solution achieves perfect efficiency (Speed: 1.0) but attains a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes speed effectively, but the relatively low balancedness score suggests the local search heuristics (pairwise swapping and randomized greedy partitioning) are insufficient for escaping local optima in highly skewed load distributions.\n**Program Identifier:** Generation 55 - Patch Name beam_cyclic_eplb - Correct Program: True\n\n**Program Name: Target-Aware Greedy with Hybrid Pairwise and 3-Way LNS Refinement**\n- **Implementation**: Uses randomized target-driven greedy initialization followed by iterative refinement via exhaustive pairwise swaps and 3-way Large Neighborhood Search (Ruin & Recreate) to escape local optima.\n- **Performance**: Achieved a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The hybrid approach provides excellent computational efficiency, though the balancedness metrics suggest the local search heuristics could be tuned for deeper exploration to improve load distribution.\n**Program Identifier:** Generation 56 - Patch Name iterative_subset_refinement_balancer - Correct Program: True\n\n**Program Name: Cyclic LNS Load Balancer with Randomized Greedy and Swaps**\n- **Implementation**: The solution employs a randomized greedy construction with restarts, followed by pairwise hill-climbing swaps and a 3-way Large Neighborhood Search (LNS) using ruin-and-recreate strategies on CPU.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but a lower balancedness score (0.31).\n- **Feedback**: While the implementation is highly efficient, the moderate balancedness score suggests that the local search heuristics (swaps and LNS) often settle in local optima and could benefit from more aggressive diversification or longer search times.\n**Program Identifier:** Generation 57 - Patch Name iterative_swaps_refinement - Correct Program: True\n\n**Program Name: Beam Search with Perturbed LPT and Ring Swap Balancer**\n- **Implementation**: The algorithm initializes packing using a beam search for heavy items, completes via greedy assignment, and refines the distribution using pairwise perturbed LPT re-partitioning and 3-way ring swaps to reduce load variance.\n- **Performance**: The program achieves a combined score of 0.66, driven by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation prioritizes execution speed with lightweight heuristics suitable for real-time inference, though the lower balancedness score suggests the local search strategies may struggle to fully optimize highly skewed workload distributions.\n**Program Identifier:** Generation 58 - Patch Name hybrid_beam_ring_packing - Correct Program: True\n\n**Program Name: Vectorized Greedy EPLB with Swap and LNS Refinement**\n- **Implementation**: The algorithm utilizes randomized greedy initialization (LPT) followed by a refinement loop alternating between a vectorized 1-swap local search and K-way Large Neighborhood Search (LNS) on the CPU.\n- **Performance**: It achieves a perfect speed score (1.0) but a lower balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The vectorized operations ensure excellent runtime performance, though the moderate balancedness score suggests that more aggressive shuffling or deeper search strategies might be needed to improve load distribution further.\n**Program Identifier:** Generation 59 - Patch Name vectorized_hybrid_eplb - Correct Program: True\n\n**Program Name: CPU-Optimized Randomized Greedy EPLB with LNS Refinement**\n- **Implementation**: The solution offloads packing logic to the CPU, utilizing a randomized greedy initialization (LPT with noise) refined by Large Neighborhood Search (LNS) through pairwise swaps and 3-way subset repacking.\n- **Performance**: The program achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: Explicitly moving sequential iterative operations to the CPU successfully maximized execution speed, though the heuristic approach traded some load balancing precision for this runtime efficiency.\n**Program Identifier:** Generation 60 - Patch Name improved_lns_with_optimal_swap - Correct Program: True\n\n**Program Name: Vectorized Hierarchical EPLB with Target-Centric Greedy and LNS Refinement**\n- **Implementation**: This solution utilizes a hierarchical rebalancing strategy combining a target-centric randomized greedy initialization with vectorized pairwise swaps and Large Neighborhood Search (LNS) to optimize expert placement.\n- **Performance**: The algorithm achieves a combined score of 0.65, demonstrating perfect speed (1.0) but only moderate load balancing capability (0.31).\n- **Feedback**: While the vectorized swap and limited LNS steps ensure high throughput and low overhead, the approach struggles to achieve tight packing on difficult distributions compared to more exhaustive search methods.\n**Program Identifier:** Generation 61 - Patch Name target_centric_greedy_and_vectorized_swap - Correct Program: True\n\n**Program Name: Randomized LPT with Binary-Search Accelerated 2-Swap Refinement**\n- **Implementation**: This CPU-based implementation uses randomized Longest Processing Time (LPT) initialization mixed with Best Fit heuristics, followed by a refinement phase employing 1-item swaps and binary-search-accelerated 2-item swaps to balance heaviest and lightest packs.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The transition to CPU processing eliminates GPU kernel overheads to maximize speed, but the reliance on greedy heuristics and limited local search depth results in suboptimal load distribution compared to more exhaustive approaches.\n**Program Identifier:** Generation 62 - Patch Name moe_eplb_hybrid_swap - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing with Greedy LPT and Local Search**\n- **Implementation**: The solution implements hierarchical rebalancing using a `balanced_packing` routine that combines Greedy LPT initialization with iterative 1-swap and 2-swap local search refinements executed on the CPU.\n- **Performance**: The program achieves a perfect speed score (1.0) but a low balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation is highly efficient computationally, but the low balancedness score indicates that the greedy approach and limited local search are insufficient for finding optimal packings, likely getting trapped in local minima.\n**Program Identifier:** Generation 63 - Patch Name improved_packing_2swap_retry - Correct Program: True\n\n**Program Name: Randomized Best-Fit Packing with Pairwise Partition Refinement**\n- **Implementation**: The algorithm initializes packings using randomized Best Fit Decreasing and iteratively refines the solution by rebalancing the heaviest and lightest packs using a hybrid exact/greedy 2-partition solver under equal-cardinality constraints.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the implementation is highly efficient and minimizes overhead, the reliance on local pairwise exchanges appears to limit the algorithm's ability to escape local optima, resulting in suboptimal global load distribution compared to slower, more exhaustive approaches.\n**Program Identifier:** Generation 64 - Patch Name pairwise_repartition_eplb - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: Implements a multi-restart randomized greedy initialization followed by vectorized pairwise swaps and a Large Neighborhood Search (LNS) strategy, executed on the CPU to minimize kernel overhead.\n- **Performance**: The solution attains a perfect speed score (1.0) and a balancedness score of 0.31, yielding a combined score of 0.66.\n- **Feedback**: While the CPU-based vectorized logic provides exceptional execution speed, the packing algorithm's ability to minimize maximum load is limited, suggesting the need for more sophisticated global optimization techniques to improve balancedness.\n**Program Identifier:** Generation 65 - Patch Name hybrid_greedy_vector_lns_eplb - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Packing with Pairwise Swap Refinement**\n- **Implementation**: This approach implements hierarchical load balancing using a greedy packing strategy refined by pairwise swapping, explicitly offloading sequential logic to the CPU to avoid GPU kernel launch overheads. Additionally, the expert replication step uses incremental score updates to avoid redundant full-matrix recalculations.\n- **Performance**: Achieved a perfect speed score of 1.0 and a balancedness score of 0.31, demonstrating exceptional runtime efficiency.\n- **Feedback**: Offloading sequential greedy algorithms to the CPU proved highly effective for maximizing speed by eliminating GPU synchronization latency, while incremental updates in the replication phase further reduced computational cost.\n**Program Identifier:** Generation 66 - Patch Name re-greedy_pairwise_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized LPT and Local Search**\n- **Implementation**: The algorithm performs load balancing on the CPU using multi-start randomized LPT packing followed by iterative refinement through randomized merge-repacks and pairwise swaps to reduce peak loads.\n- **Performance**: It achieved a perfect speed score (1.0) and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Moving logic to the CPU and using randomized heuristics ensures minimal overhead and high speed, though the resulting load distribution is suboptimal compared to more computationally intensive methods.\n**Program Identifier:** Generation 67 - Patch Name randomized_repack_refinement - Correct Program: True\n\n**Program Name: CPU-Optimized EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm minimizes GPU synchronization overhead by offloading sequential packing logic to the CPU, employing a multi-start randomized greedy strategy (LPT) followed by swap-based local search to refine load distribution.\n- **Performance**: It achieved a combined score of 0.66, characterized by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation excels in runtime efficiency due to CPU offloading and incremental updates, though the heuristic packing logic struggles to achieve high balancedness, suggesting a need for a more robust optimization strategy to handle complex weight distributions effectively.\n**Program Identifier:** Generation 68 - Patch Name eplb_multistart_pairwise - Correct Program: True\n\n**Program Name: Multi-Restart Greedy Packing with Local Search Refinement**\n- **Implementation**: The algorithm employs a CPU-based multi-restart strategy using deterministic ZigZag and randomized greedy initializations, followed by a local search loop that iteratively swaps items from the heaviest pack to lighter ones to minimize makespan.\n- **Performance**: It achieves a combined score of 0.66, characterized by perfect speed (1.0) but moderate load balancing effectiveness (0.31).\n- **Feedback**: While the lightweight heuristic approach ensures maximum processing speed, the packing quality is limited by local optima, suggesting that a more exhaustive search or stronger initial bounds could improve balance.\n**Program Identifier:** Generation 69 - Patch Name iterated_greedy_packing - Correct Program: True\n\n**Program Name: Hierarchical Randomized Greedy EPLB with Vectorized Refinement**\n- **Implementation**: This solution utilizes randomized greedy initialization with multiple restarts, followed by a refinement phase combining vectorized pairwise swaps and K-way Large Neighborhood Search (LNS).\n- **Performance**: The program achieved a combined score of 0.66, distinguished by a perfect speed score (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The implementation's vectorization ensures minimal runtime overhead, though the moderate balance score suggests the heuristic search could be deepened or diversified to better equalize load distribution.\n**Program Identifier:** Generation 70 - Patch Name vectorized_lns_eplb - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Swap Descent and LNS**\n- **Implementation**: Uses a randomized greedy initialization (LPT) refined by pairwise swap descent and a 3-way Ruin & Recreate Large Neighborhood Search (LNS) to optimize expert allocation on the CPU.\n- **Performance**: Achieved a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes low latency suitable for runtime inference, effectively balancing overhead with packing quality, though the heuristic approach limits the maximum theoretical load balance.\n**Program Identifier:** Generation 71 - Patch Name pairwise_swap_refinement - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Hybrid Exact and Randomized Refinement**\n- **Implementation**: The algorithm utilizes greedy LPT initialization followed by iterative refinement, employing an exact subset-sum solver for small rebalancing sets and randomized heuristics for larger 2-way or 3-way exchanges.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a balancedness score of 0.31, resulting in a combined metric of 0.66.\n- **Feedback**: The hybrid approach ensures extremely low latency by avoiding expensive computations on large sets, though the reliance on randomized heuristics limits the maximum load-balancing precision compared to exhaustive methods.\n**Program Identifier:** Generation 72 - Patch Name exact_solver_and_3way_v2 - Correct Program: True\n\n**Program Name: CPU-Offloaded Greedy Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm executes `balanced_packing` on the CPU using a greedy Longest Processing Time strategy refined by pairwise repartitioning and swapping, while `replicate_experts` utilizes efficient incremental score updates to avoid redundant calculations.\n- **Performance**: The solution achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential scalar operations to the CPU effectively eliminates GPU kernel overhead to maximize speed, though the greedy heuristic packing limits the final load balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 73 - Patch Name pooled_repartition_and_swap - Correct Program: True\n\n**Program Name: CPU-Offloaded Heuristic Load Balancer with Local Refinement**\n- **Implementation**: This approach moves the iterative packing logic to the CPU to avoid CUDA latency, utilizing a multi-start randomized greedy strategy initialized with a ZigZag pattern and refined by pairwise 2-partition local search.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a modest balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential heuristics to the CPU proved highly effective for runtime performance, although the packing algorithm's reliance on randomized greedy steps limits its ability to find globally optimal load distributions.\n**Program Identifier:** Generation 74 - Patch Name pooled_repartitioning - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy and LNS Refinement**\n- **Implementation**: The solution utilizes a randomized greedy \"Best Fit\" initialization with restarts, followed by a refinement phase combining vectorized global swaps and a local neighborhood search (LNS) with pairwise and 3-way re-optimization.\n- **Performance**: It achieved a combined score of 0.66, characterized by perfect speed (1.0) but sub-optimal balancedness (0.31).\n- **Feedback**: The implementation is highly efficient computationally, but the heuristic-based optimization approach struggles to achieve tight load balancing compared to more exhaustive methods, likely getting trapped in local optima under the equal-cardinality constraints.\n**Program Identifier:** Generation 75 - Patch Name eplb_hybrid_repack - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancer with Randomized Greedy Packing**\n- **Implementation**: The algorithm performs balanced packing on the CPU using a randomized greedy approach with local swap refinement and optimizes expert replication by updating load scores incrementally.\n- **Performance**: The solution achieved a combined score of 0.66, excelling in speed (1.0) while attaining moderate balancedness (0.31).\n- **Feedback**: Offloading sequential logic to the CPU successfully eliminates GPU overhead, though the swap-based refinement heuristic limits the achievable balance compared to more exhaustive search methods.\n**Program Identifier:** Generation 76 - Patch Name eplb_hybrid_opt - Correct Program: True\n\n**Program Name: Hierarchical LNS Expert Balancer**\n- **Implementation**: Implements a hierarchical load balancer using a CPU-based packing solver that combines Greedy LPT, pairwise/pooled refinement, and Large Neighborhood Search (Ruin & Recreate) to optimize expert assignment.\n- **Performance**: Score: 0.0 (Validation failed).\n- **Feedback**: The program failed correctness tests, likely due to aggressive casting of tensors to CPU without restoring the original device or errors in reconstructing expert mappings during the hierarchical packing phases.\n**Program Identifier:** Generation 77 - Patch Name pooled_repartition - Correct Program: False\n\n**Program Name: CPU-Optimized Hierarchical Expert Load Balancer**\n- **Implementation**: The algorithm implements hierarchical rebalancing by offloading the sequential `balanced_packing` logic to the CPU, utilizing a greedy Longest Processing Time (LPT) strategy supplemented by iterative pooled repartitioning to refine load distribution.\n- **Performance**: The solution achieves a maximum speed score (1.0) with a balancedness score of 0.31 across 5 workloads.\n- **Feedback**: Offloading sequential scalar operations to the CPU proved highly effective for performance by removing GPU kernel overheads, though the heuristic packing yielded only moderate load balance improvements compared to the speed gains.\n**Program Identifier:** Generation 78 - Patch Name pooled_repartition_refinement - Correct Program: True\n\n**Program Name: Hierarchical Expert Load Balancing via Beam Search and LNS**\n- **Implementation**: The solution implements balanced packing using a Beam Search algorithm on CPU-offloaded weights, followed by a Ruin-and-Recreate refinement phase that iteratively re-optimizes the heaviest and lightest packs.\n- **Performance**: The algorithm achieved a combined score of 0.66, prioritizing execution speed (1.0) over the quality of load balancing (0.31).\n- **Feedback**: While computationally efficient, the heuristic approach struggled to find optimal packings, suggesting that increasing the beam width or the number of local search iterations could improve balancedness at the cost of some speed.\n**Program Identifier:** Generation 79 - Patch Name beam_search_packing - Correct Program: True\n\n**Program Name: Hybrid Randomized Greedy and LNS Expert Load Balancer**\n- **Implementation**: The solution employs a multi-start randomized greedy construction phase followed by iterative refinement using pairwise swaps and Large Neighborhood Search (LNS) performed on CPU tensors to minimize synchronization overhead.\n- **Performance**: Achieved a speed score of 1.0 and a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: Offloading scalar-heavy heuristic logic to the CPU maximized execution speed, while the hybrid refinement strategy effectively targeted load imbalances, though the balancedness score suggests potential for more aggressive optimization at the cost of speed.\n**Program Identifier:** Generation 80 - Patch Name eplb_hybrid_greedy_lns - Correct Program: True\n\n**Program Name: Randomized LPT Packing with Pairwise Refinement**\n- **Implementation**: The solution employs a greedy Longest Processing Time (LPT) packing algorithm on the CPU with randomized restarts and an iterative \"pool-and-split\" refinement strategy that rebalances the heaviest and lightest bins.\n- **Performance**: It achieved a combined score of 0.66, attaining a perfect speed score (1.0) but a lower balancedness score (0.31).\n- **Feedback**: Moving sequential logic to the CPU ensures high efficiency, while the randomized restarts and pairwise refinement help improve load distribution, though the pairwise limitation restricts finding a globally optimal packing.\n**Program Identifier:** Generation 81 - Patch Name rebalance_experts_pool_split - Correct Program: True\n\n**Program Name: Hierarchical EPLB with Randomized Greedy Packing and CPU Offloading**\n- **Implementation**: The algorithm offloads computation to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with restarts, followed by a \"pool-and-split\" refinement that locally redistributes items between the heaviest and lightest packs.\n- **Performance**: The solution achieves a perfect speed score (1.00) but struggles with load distribution quality (balancedness 0.31), resulting in a combined score of 0.66.\n- **Feedback**: Offloading sequential logic to the CPU effectively maximizes speed by avoiding GPU overhead, but the randomized greedy approach with limited local refinement is insufficient for finding high-quality packing solutions.\n**Program Identifier:** Generation 82 - Patch Name pool_split_packing_and_heap_replication - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with Pairwise and 3-Way LNS Refinement**\n- **Implementation**: The algorithm performs load balancing on the CPU using randomized greedy initialization followed by iterative refinement via pairwise rebalancing and a 3-way Large Neighborhood Search shuffle.\n- **Performance**: It attains a perfect speed score (1.00) with a balancedness score of 0.31, resulting in a combined score of 0.66.\n- **Feedback**: The implementation prioritizes execution speed through lightweight heuristics, but the low balancedness score suggests that the randomized greedy approach struggles to escape local optima compared to more exhaustive solvers.\n**Program Identifier:** Generation 83 - Patch Name iterative_pairwise_rebalance_packing - Correct Program: True\n\n**Program Name: Greedy LPT Packing with Local Search Refinement**\n- **Implementation**: The algorithm implements a CPU-based Greedy Longest Processing Time (LPT) initialization followed by iterative refinement using exact solvers for small subsets and heuristic 2-way/3-way swaps with random perturbations to rebalance heavy and light packs.\n- **Performance**: The solution achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), resulting in a combined score of 0.66.\n- **Feedback**: While the heuristic approach and CPU offloading ensure maximum execution speed, the low balancedness score suggests that the local search strategy often settles in local optima, indicating a need for more aggressive optimization to better distribute weights.\n**Program Identifier:** Generation 84 - Patch Name pool_solver_local_search - Correct Program: True\n\n**Program Name: Hybrid Greedy LPT with Vectorized Swaps and LNS**\n- **Implementation**: This approach combines a fast, CPU-based randomized greedy initialization with a two-phase refinement strategy: vectorized pairwise swaps for high-load reduction and Large Neighborhood Search (LNS) for local reshuffling.\n- **Performance**: It achieves a perfect speed score (1.0) with a moderate balancedness score (0.31), resulting in a combined metric of 0.66.\n- **Feedback**: The implementation effectively minimizes runtime overhead through CPU-based list operations and vectorization, though the modest balancedness score suggests the refinement steps settle into local optima quickly and might benefit from more aggressive exploration.\n**Program Identifier:** Generation 85 - Patch Name randomized_lns_refinement - Correct Program: True\n\n**Program Name: CPU-Based Randomized Greedy Packing with Pool-and-Split Refinement**\n- **Implementation**: The algorithm offloads weights to the CPU to execute a randomized Longest Processing Time (LPT) greedy strategy with multiple restarts, refined by iteratively pooling and redistributing items from the heaviest, lightest, and random packs.\n- **Performance**: The solution achieves a combined score of 0.66, driven by a perfect speed score (1.0) despite a moderate balancedness score (0.31).\n- **Feedback**: Offloading sequential greedy logic to the CPU eliminates significant GPU kernel launch overheads, enabling rapid execution of randomized restarts and local search heuristics that provide a reasonable balance-speed trade-off.\n**Program Identifier:** Generation 86 - Patch Name randomized_pool_split_packing - Correct Program: True\n\n**Program Name: CPU-Based EPLB with Randomized Greedy Packing and Refinement**\n- **Implementation**: The algorithm offloads packing logic to the CPU to avoid GPU overheads, employing a randomized Longest Processing Time (LPT) greedy initialization with multiple restarts and pairwise swap refinement.\n- **Performance**: It achieves a perfect speed score (1.0) but a moderate balancedness score (0.31), yielding a combined score of 0.66.\n- **Feedback**: The approach is highly efficient due to sequential CPU execution, but the packing quality suggests the greedy-plus-refinement strategy trades optimal load distribution for execution speed.\n**Program Identifier:** Generation 87 - Patch Name restarts_plus_incremental_refinement - Correct Program: True\n\n**Program Name: Randomized Greedy EPLB with 3-Way LNS Refinement**\n- **Implementation**: The solution utilizes a CPU-based multi-start randomized greedy initialization, refined by 1-item/2-item swaps and a 3-way Large Neighborhood Search (LNS) to balance loads across packs.\n- **Performance**: Achieves a combined score of 0.66, characterized by perfect speed (1.0) but a moderate balancedness score (0.31).\n- **Feedback**: The multi-stage heuristic is highly efficient for runtime performance, though the moderate balance score indicates limited effectiveness in resolving complex packing constraints compared to slower, more exhaustive algorithms.\n**Program Identifier:** Generation 88 - Patch Name randomized_greedy_with_pairwise_refinement - Correct Program: True\n\n**Program Name: Hybrid Greedy Packing with Vectorized Swaps and Beam Search**\n- **Implementation**: The algorithm initializes with multiple randomized greedy candidates, refines using fast vectorized pairwise swaps, and employs Large Neighborhood Search (LNS) with Beam Search to re-optimize the most imbalanced packs.\n- **Performance**: It achieved a combined score of 0.66, maximizing execution speed (1.0) while attaining a moderate balancedness score (0.31).\n- **Feedback**: The perfect speed score validates the efficiency of the vectorized approach, but the lower balance score suggests the Beam Search width or LNS iterations may be insufficient to escape deep local optima in complex distributions.\n**Program Identifier:** Generation 89 - Patch Name hybrid_greedy_beam_lns - Correct Program: True",
  "meta_scratch_pad": "# Analysis of Program Evaluation Results\n\n## Successful Algorithmic Patterns\n- **CPU-Offloaded Greedy LPT with Pairwise Refinement**: The most consistent and effective pattern, exemplified by the **Current Best Program** and **Generation 87**, involves explicitly moving weights to the CPU (`weight.to(\"cpu\")`), sorting indices by weight (Longest Processing Time), and performing a greedy assignment. This is followed by a targeted refinement phase that swaps items between the heaviest and lightest packs. This approach reliably achieves the maximum observed scores (Speed 1.0, Balancedness 0.31).\n- **Monotonic Difference Reduction**: The **Current Best Program** implements a crucial optimization in its swap logic: `if 0 < delta < diff`. This strict inequality ensures that every swap performed strictly reduces the load difference between the max and min packs. This guarantees convergence without the need for complex history tracking (Tabu lists) or acceptance probabilities (Simulated Annealing).\n- **Native Python Scalar State Management**: Successful implementations like the **Current Best Program** and **Generation 80** utilize standard Python lists (`current_packs = [[] ...]`) and scalar floats for tracking pack weights. This avoids the high overhead of GPU kernel launches or PyTorch tensor resizing during the highly iterative refinement phase, securing a perfect Speed Score of 1.0.\n\n## Ineffective Approaches\n- **Advanced Search Meta-Heuristics (Beam Search, LNS)**: Programs incorporating sophisticated search strategies, such as Beam Search (**Generation 89**) and 3-Way Large Neighborhood Search (**Generation 83**, **Generation 88**), failed to improve upon the 0.31 balancedness score set by simple greedy algorithms. The evaluation indicates that the remaining imbalance is likely structural (indivisible heavy items) rather than a local optimum that these complex searches could escape.\n- **Pool-and-Split Refinement**: Techniques that attempt to pool items from multiple packs and redistribute them (**Generation 81**, **Generation 82**, **Generation 86**) proved no more effective than pairwise swapping. Despite the theoretical ability to reshuffle larger subsets of items, these methods saturated at the same 0.31 balancedness score, merely adding implementation complexity without performance gain.\n- **Vectorized Refinement Logic**: **Generation 85** attempted to use vectorized swaps to improve performance. However, since the scalar CPU implementation already achieves a Speed Score of 1.0, vectorization added unnecessary complexity to the code without yielding any tangible runtime benefit.\n\n## Implementation Insights\n- **Explicit Device Decoupling**: The **Current Best Program** demonstrates the critical pattern of `weight_cpu = weight.to(\"cpu\", dtype=torch.float32)`. By performing all sorting, packing, and swapping logic on CPU `float32` types, the program completely decouples the control flow from GPU latency, ensuring the iterative refinement steps are executed at the speed of system memory access.\n- **Targeted Min-Max Pruning**: A highly effective coding pattern in the **Current Best Program** is restricting the search space to only the most imbalanced pair: `min_p = min(...)` and `max_p = max(...)`. Instead of iterating over all $O(M^2)$ pairs of packs, the algorithm focuses strictly on the single pair that defines the objective function (max load - min load), significantly improving efficiency per iteration.\n- **Hard-Coded Iteration Limits**: The **Current Best Program** uses a fixed loop limit `for _ in range(20):` for its refinement phase. This simple heuristic prevents worst-case execution times on difficult inputs while proving experimentally sufficient to reach the saturation point of balancedness (0.31) for this workload.\n\n## Performance Analysis\n- **Universal Balancedness Saturation**: Across all analyzed programs (**Generations 80 through 89**), there is a strict convergence to a **Balancedness Score of 0.31**. Whether the algorithm used randomized restarts, genetic-style pooling, or beam search, none could surpass the baseline established by the Greedy LPT + Swap approach. This strongly suggests the bottleneck is data-dependent (e.g., a specific expert group is significantly larger than the average load), making further algorithmic \"search\" improvements futile.\n- **Speed Score Robustness**: Every evaluated program achieved a **Speed Score of 1.0**. This indicates that the execution time budget is permissive enough for Python-based CPU heuristics of varying complexity (from $O(N^2)$ to $O(N \\cdot BeamWidth)$). The performance differentiator is solely implementation correctness and stability, rather than raw computational efficiency.\n- **Complexity vs. Reward Disparity**: Comparing **Generation 89** (Beam Search) with the **Current Best Program** reveals that increasing code complexity yielded zero performance benefit. The Current Best Program achieves the exact same combined score (0.66) using a straightforward double-loop swap logic, highlighting that simple, robust heuristics are superior to complex meta-heuristics for this specific problem instance.",
  "meta_recommendations": "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min.",
  "meta_recommendations_history": [
    "Based on the analysis of the current best program and global insights, here are 5 actionable recommendations for future program mutations:\n\n1.  **Randomized Greedy with Multiple Restarts**: Since the speed score is a perfect 1.0, the computational budget allows for redundancy. Modify `balanced_packing` to run the core LPT allocation loop multiple times (e.g., 50 iterations) with slight randomization in the sort order of items with similar weights or by randomly choosing among the top-k least loaded bins. Return the packing configuration that yields the lowest load variance.\n2.  **Simulated Annealing for Refinement**: To address the \"stagnant balancedness score\" caused by local optima, replace or augment the fixed-limit swap loop with a Simulated Annealing schedule. Allow swaps that temporarily worsen the balance with a probability proportional to a decaying temperature, enabling the algorithm to escape the local traps inherent in the 1-for-1 greedy swap approach.\n3.  **Multi-Item Swap Heuristics (N-for-1 Swaps)**: The analysis highlights that simple pairwise (1-for-1) swapping is ineffective against load skew. Enhance the refinement phase to detect and execute \"2-for-1\" or \"3-for-1\" swaps, where multiple smaller items from a heavy bin are exchanged for a single large item from a light bin. This is particularly crucial for the `Group-to-Node` packing stage where item granularity is high.\n4.  **Target-Aware Best-Fit Allocation**: Modify the greedy construction phase to target the ideal average load rather than just the minimum current load. Instead of strictly assigning the next item to the bin with the lowest accumulated weight, assign it to the bin where the new weight minimizes the absolute difference from the `total_weight / num_packs` target. This can prevent \"under-filling\" bins that later cannot accommodate large items.\n5.  **Beam Search for Heavy Items**: Implement a limited Beam Search for the initial assignment of the heaviest items (e.g., the top 10% of groups or experts). Maintain a set of the `K` best partial packing states during these critical early steps to avoid irreversible suboptimal placements, then switch to the standard fast greedy LPT for the remaining smaller items.",
    "Based on the analysis of the global insights and the current best program, here are 5 actionable recommendations for future program mutations:\n\n1.  **Implement 3-Way (Cyclic) Swap Refinement**: Since the problem imposes strict item-count constraints per bin, \"2-for-1\" swaps are illegal. The 1-for-1 swap plateau suggests pairwise exchanges are caught in local optima. Implement a **3-way cyclic swap** (Item $a$ from Bin $A$ $\\to$ Bin $B$, $b$ from $B$ $\\to$ Bin $C$, $c$ from $C$ $\\to$ Bin $A$) to uncover weight transfers impossible with simple pairwise swaps.\n2.  **Beam Search Construction for Heaviest Items**: The greedy LPT approach makes irreversible decisions on the largest items (typically groups) that dictate the final imbalance. Replace the greedy loop for the top 10-20% heaviest items with a **Beam Search** (width ~4-8). This explores multiple placement branches for the critical \"boulders\" before switching to fast greedy for the \"sand.\"\n3.  **Large Neighborhood Search (LNS) Strategy**: To break the 0.31 balancedness ceiling, implement an LNS \"ruin and recreate\" phase. Select the $K$ most unbalanced bins (heaviest and lightest), unassign all their items, and re-pack them using a varying heuristic (e.g., changing the sort order or using Best-Fit). This allows the algorithm to reshuffle a subset of the problem space more drastically than single swaps.\n4.  **Target-Aware \"Best Fit\" Allocation**: Modify the initial packing logic to target the ideal average load (`total_weight / num_packs`) rather than just minimizing the current load. Assign the current item to the bin where the resulting weight minimizes the distance to this target. This prevents the \"flat-filling\" behavior of standard greedy, effectively leaving \"holes\" of the right size for subsequent items.\n5.  **Problem-Size Dependent Solving**: The **Group-to-Node** packing often involves fewer items (small $N$) but contributes most to imbalance. Introduce a logic branch: if $N$ (number of groups/experts) is small (e.g., $< 64$), run a computationally intensive **permutational search** or deeply iterated shuffle (thousands of iterations) since the CPU budget (Speed 1.0) can easily absorb O($N^2$) or O($N!$) approximations for small $N$.",
    "Based on the global insights and the performance of the current best program, here are 5 actionable recommendations for future program mutations:\n\n1.  **Implement Target-Aware \"Best Fit\" Initialization**: The current program assigns items to the *least loaded* pack, which creates a \"flat\" filling pattern that may block optimal placement for subsequent items. Change the greedy logic to assign the current item to the valid pack where the resulting weight is closest to the **target average** (`total_weight / num_packs`). This \"Best Fit Decreasing\" strategy creates necessary gaps for future items and often yields a better starting state than pure load minimization.\n\n2.  **Introduce 3-Way Cyclic Swaps**: The plateau at 0.31 balancedness implies that pairwise (2-way) swaps are stuck in local optima. Implement a **3-way swap routine** that searches for items $a \\in \\text{Bin}_A, b \\in \\text{Bin}_B, c \\in \\text{Bin}_C$ to rotate ($a \\to B, b \\to C, c \\to A$). This enables weight transfers between bins that are impossible with zero-sum pairwise exchanges, exploiting the Speed Score budget (1.0) to perform O($N^3$) checks for limited iterations.\n\n3.  **Specialized Small-N Solver for Group Packing**: The insights identify the *Group-to-Node* packing (small $N$) as the likely bottleneck dominating the imbalance. Add a logic branch: if `weight.shape[1]` is small (e.g., $< 64$), replace the greedy heuristic with a computationally intensive **randomized restart** or **Simulated Annealing** loop (running 1000+ iterations). The CPU overhead is negligible for small $N$ but can find the global optimum that the greedy approach misses.\n\n4.  **Beam Search for Heaviest Items**: Standard Greedy LPT makes irreversible suboptimal decisions for the largest items. Replace the standard loop for the top 10% heaviest items with a **Beam Search** (width 4-8). This maintains multiple candidate packing states for the critical \"boulders,\" ensuring that early placements don't preclude a balanced solution, before switching to the fast greedy logic for the remaining items.\n\n5.  **Localized \"Ruin and Recreate\" (LNS)**: To escape the local optima of the swap phase, implement a targeted Large Neighborhood Search. specifically select the **heaviest and lightest $K$ packs** (e.g., $K=2$), unassign all their items, and re-pack them using a recursive solver or a different heuristic (like Best Fit). This acts as a powerful perturbation step that reshuffles the most critical parts of the solution without the cost of a full restart.",
    "Based on the global insights and the performance of the Current Best Program, here are 5 actionable recommendations for future program mutations:\n\n1.  **Implement Target-Aware \"Best Fit\" Initialization**: The current greedy logic assigns items to the *least loaded* pack (`min(pack_weights)`), which levels the bottom but ignores the goal. Change the selection criteria to assign the current item to the valid pack where the new weight is closest to the **target average** (`abs(current_weight + item_weight - total_weight/num_packs)`). This \"Best Fit\" strategy preserves capacity in smaller bins for appropriate future items rather than prematurely filling them.\n\n2.  **Introduce 3-Way Cyclic Swaps**: The balancedness plateau at 0.31 suggests pairwise swaps are stuck in local optima. Implement a scalar loop that searches for items $a \\in \\text{MaxPack}, b \\in \\text{MinPack}, c \\in \\text{RandomPack}$ to perform a cyclic rotation ($a \\to \\text{Min}, b \\to \\text{Random}, c \\to \\text{Max}$). This allows weight transfers that are impossible with zero-sum 2-way exchanges, utilizing the ample CPU time budget (Speed Score 1.0).\n\n3.  **Optimal Two-Bin Re-partitioning**: Instead of swapping single items between the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, implement a routine that **pools all items from both packs** and re-distributes them. Use a local \"Best Fit Decreasing\" or \"Multi-Way Partitioning\" heuristic to split these pooled items back into two valid packs. This effectively solves the sub-problem of minimizing the difference between $P_{max}$ and $P_{min}$ more comprehensively than iterative single swaps.\n\n4.  **Beam Search for Heaviest Items**: Since the placement of the largest \"expert groups\" dictates the final imbalance, replace the greedy loop for the top ~10 heaviest items with a **Beam Search** (width 4-8). This maintains multiple partial packing states during the most critical decisions, preventing the algorithm from getting locked into a structurally imbalanced configuration that later swaps cannot fix.\n\n5.  **Exhaustive Solver for Small-Scale Inputs**: The insights point to the \"Group-to-Node\" packing (where $N$ and $M$ are small) as a primary source of imbalance. Add a check: if `num_groups < 30`, bypass the greedy/swap logic and use a **recursive Branch-and-Bound** or **exhaustive DFS** solver. The computational cost is trivial for small inputs, but finding the mathematical optimum at this high level can break the 0.31 plateau that propagates to lower levels.",
    "Based on the analysis of the global insights and the current best program (which effectively utilizes CPU-based scalar operations but has plateaued at a balancedness score of 0.31), here are 5 actionable recommendations for future program mutations:\n\n1.  **Hybrid Exact Solver for Coarse Hierarchies**: The \"Group-to-Node\" packing step often involves a small number of items ($N < 20$) but dictates the global balance upper bound. Implement a check: if `len(weights) <= 18`, bypass the greedy logic and use a recursive **Branch-and-Bound** or **Exhaustive DFS** solver. Finding the mathematically optimal distribution at this high level is computationally cheap and prevents structural imbalances that lower-level refinements cannot fix.\n\n2.  **Target-Centric \"Best Fit\" Initialization**: The current logic places items in the *lightest* valid bin, which effectively levels the bottom but ignores the ceiling. Change the selection criteria to a \"Best Fit\" strategy: assign the item to the pack where `abs((current_weight + item_weight) - target_average)` is minimized. This ensures that bins reserve capacity for appropriate future items rather than being prematurely filled by smaller debris.\n\n3.  **Optimal Two-Bin Repartitioning**: Instead of swapping single items between the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, implement a refinement step that **pools all items from both packs** into a temporary list. Use a local solver (or exhaustive search if items $< 15$) to redistribute these pooled items back into two valid packs such that the difference between them is minimized. This solves the local sub-problem optimally, overcoming limits of single-item swaps.\n\n4.  **Beam Search for Heaviest Items**: To prevent the greedy algorithm from making irrevocable bad decisions with the largest \"expert groups,\" implement a **Beam Search** (width=4) for the first 20% of items. Maintain 4 parallel packing states and prune them based on load variance; after the largest items are placed, collapse to the best single state and continue with standard greedy packing for the remaining smaller items.\n\n5.  **Scalar 3-Way \"Ring\" Swaps**: The balancedness plateau suggests pairwise (A$\\leftrightarrow$B) swaps are stuck in local optima. Implement a scalar CPU loop that searches for valid 3-way cyclic transfers: Item $i \\in P_{max} \\to P_{rand}$, Item $j \\in P_{rand} \\to P_{min}$, Item $k \\in P_{min} \\to P_{max}$. This pattern allows for net weight transfers that are impossible with zero-sum pairwise exchanges, utilizing the available time budget (Speed Score 1.0).",
    "Based on the global insights and the analysis of the current best program (which successfully leverages CPU scalar operations but faces a structural balancedness plateau), here are 5 actionable recommendations for future program mutations:\n\n1.  **Hybrid Exact Solver for Small Instances**: The \"Group-to-Node\" hierarchical step involves a small number of items but dictates the global balance ceiling. Implement a conditional check in `balanced_packing`: if `num_items <= 20` (a tunable threshold), bypass the greedy logic and use a **recursive backtracking or branch-and-bound solver** to find the mathematically optimal distribution. This utilizes the available compute budget to fix high-level structural imbalances that lower-level greedy heuristics cannot correct.\n\n2.  **Optimal Two-Bin Repartitioning**: Upgrade the current pairwise refinement loop. Instead of swapping single items between the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, **pool all items from both packs** and effectively solve the 2-Partition Problem (minimize the difference between two sums) for this subset. This allows for complex \"2-for-1\" or \"3-for-2\" exchanges that are impossible with simple pairwise swapping, resolving local optima where single swaps fail.\n\n3.  **Target-Centric \"Best Fit\" Initialization**: Modify the initial greedy pass to use a \"Best Fit\" criterion rather than \"Least Loaded.\" For each item, assign it to the pack where `abs((current_load + item_weight) - target_average)` is minimized. This ensures that packs are filled towards the ideal mean, reserving capacity in lighter packs for future large items rather than prematurely filling them with \"debris.\"\n\n4.  **Multi-Item Scalar Swaps**: Explicitly extend the `for` loops in the CPU refinement phase to check for **2-item combinations**. Specifically, iterate through pairs of items in $P_{max}$ and single items in $P_{min}$ (and vice versa) to find swaps where moving two smaller items out and bringing one medium item in reduces the load variance. The current speed score of 1.0 indicates there is ample runtime budget for this $O(n^2)$ local search on small lists.\n\n5.  **Look-Ahead Greedy Placement**: Enhance the greedy construction by peeking at the *next* item to be packed. When placing item $i$, evaluate candidate packs not just on the immediate resulting load, but on whether the *remaining* capacity in that pack can accommodate item $i+1$ better. This simple 1-step lookahead helps prevent \"fragmenting\" the available capacity in a way that blocks the placement of subsequent large items.",
    "Based on the analysis of the current best program (which effectively uses CPU-offloaded greedy logic but hits a balancedness plateau) and the available compute budget (Speed Score 1.0), here are 5 actionable recommendations for future program mutations:\n\n1.  **Hybrid Exact Solver for Small Instances**: The \"Group-to-Node\" hierarchical rebalancing step often involves a small number of items ($N \\le 20$) but dictates the global balance ceiling. Implement a conditional check in `balanced_packing`: if `num_items <= 18`, bypass the greedy logic and use a **recursive branch-and-bound solver** to find the mathematically optimal partition. This leverages the available CPU time to fix high-level structural imbalances that simple heuristics cannot resolve.\n\n2.  **Pooled Two-Bin Repartitioning**: Upgrade the current single-item swap loop to a \"pool and repartition\" strategy. When refining the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, combine all their items into a single list and apply a focused **Number Partitioning heuristic** (like Karmarkar-Karp or a sorted greedy rediscovery) to split them back into two packs with minimal difference. This implicitly enables complex multi-item exchanges (e.g., swapping 2 small items for 1 large one) that pairwise loops miss.\n\n3.  **Variance-Minimizing \"Best Fit\" Construction**: Modify the initial greedy pass to prioritize **Target Variance** over \"Least Loaded\". Pre-calculate the `target_weight` (total weight / num packs). For each item, assign it to the pack where the resulting load minimizes `(new_load - target_weight)^2`. This encourages packs to converge towards the mean during construction, rather than filling lighter packs indiscriminately and leaving no room for later adjustments.\n\n4.  **Three-Way Cyclic Swapping**: Extend the refinement phase to handle local optima where direct Max-Min swaps are impossible. If a pass over Max-Min yields no changes, introduce a **3-way swap check**: search for a valid transfer sequence $Item_A \\in P_{max} \\to P_{rand}$, $Item_B \\in P_{rand} \\to P_{min}$. This intermediate buffer allows weight to flow from Max to Min even when their item granularities are incompatible for a direct trade.\n\n5.  **Look-Ahead Greedy Placement**: Enhance the greedy construction loop with a 1-step lookahead. When placing the current item, evaluate candidate packs based not just on the immediate load, but on the **residual capacity's fitness** for the *next* item in the sorted list. Penalize placements that leave a gap size slightly smaller than the next item's weight, preventing \"fragmentation\" that blocks future placements.",
    "Based on the analysis of the current best program and the consistent balancedness plateau (0.31) alongside the perfect speed score (1.0), here are 5 actionable recommendations for future program mutations. These recommendations leverage the available CPU time budget to introduce smarter, scalar-based optimizations that maintain the efficiency of the current solution while attempting to break the local optima.\n\n1.  **Small-Scale Branch-and-Bound Solver**: The hierarchical nature of the problem means the top-level distribution (groups to nodes) involves small item counts ($N \\le 20$) but dictates the global balance ceiling. Modify `balanced_packing` to check if `num_groups < 18`. If true, bypass the greedy heuristic and employ a recursive **Branch-and-Bound** or **Depth-First Search** solver to find the mathematically optimal partition. This utilizes the idle CPU budget to guarantee optimal structural foundations that heuristics often miss.\n\n2.  **Pool-and-Split Refinement Strategy**: Instead of searching for single pairwise swaps between the heaviest ($P_{max}$) and lightest ($P_{min}$) packs, implement a **full re-partitioning** of these two packs. Combine all items from $P_{max}$ and $P_{min}$ into a temporary pool, sort them descending, and redistribute them into two new packs using a \"Best Fit\" or \"Zig-Zag\" greedy logic. This implicitly performs multi-item exchanges (e.g., swapping two small items for one large item) in a single $O(k \\log k)$ step, escaping local optima that block single-item swaps.\n\n3.  **Variance-Based Greedy Initialization**: The current \"Least Loaded\" greedy construction minimizes the immediate peak but ignores the target mean, often leading to fragmentation. Change the initialization loop to assign items to the pack where the assignment minimizes the **L2 distance from the ideal mean weight** (`(current_weight + item_weight - target_avg)**2`). This ensures packs grow uniformly towards the target size, leaving \"holes\" of appropriate sizes for the final smaller items.\n\n4.  **Three-Way Cyclic Exchange**: Extend the refinement phase to handle situations where no direct $P_{max} \\leftrightarrow P_{min}$ swap is valid. When the 2-way swap search fails, trigger a scan for a **3-way cycle**: move item $u$ from $P_{max}$ to a random pack $P_{rand}$, and item $v$ from $P_{rand}$ to $P_{min}$, such that the variance decreases. This utilizes the intermediate buffer to flow weight from max to min even when their item granularities are incompatible for a direct trade.\n\n5.  **Multi-Start Randomized Greedy**: Since the current solution is extremely fast (Speed Score 1.0), exploit the time budget by running the packing algorithm multiple times with **randomized sort perturbations**. In the initialization phase, add small random noise to item weights during sorting (or shuffle equal-weight items). Run the full construction and refinement loop 5-10 times and return the solution with the lowest final imbalance. This is a robust way to escape bad initial configurations caused by specific item orderings.",
    "Based on the analysis of the current best program (Speed 1.0, Balancedness 0.31) and the demonstrated success of simple scalar CPU heuristics, here are 5 actionable recommendations for future mutations:\n\n1.  **Small-Scale Exact Solver (Branch-and-Bound)**: The problem is hierarchical, and the top-level assignment (Groups to Nodes) often involves very few items ($N \\le 20$). Modify `balanced_packing` to check the input size; if $N$ is small, bypass the greedy logic and use a recursive **Depth-First Search (DFS)** or Branch-and-Bound solver. This guarantees a mathematically optimal foundation for the top-level distribution, which is often the bottleneck for global balance.\n\n2.  **Multi-Start Randomized Greedy**: Since the current implementation achieves a perfect Speed Score of 1.0, exploit the available time budget by running the packing algorithm multiple times. Introduce a loop (e.g., `range(10)`) that runs the construction and refinement steps with **randomized tie-breaking** during the sorting phase or slight weight perturbations ($weight \\times (1 + \\epsilon)$). Return the solution with the minimum final load difference.\n\n3.  **Generalized 2-vs-1 Exchange**: The current refinement only performs 1-to-1 swaps, which fails when item granularities are incompatible (e.g., one heavy item vs. many light items). Extend the refinement loop to check if **two items** from the lightest pack can be swapped for **one item** from the heaviest pack (or vice versa) to reduce the variance. This allows the algorithm to overcome \"granularity barriers\" that block single swaps.\n\n4.  **Variance-Minimizing Construction**: The current \"Least Loaded\" greedy strategy minimizes peak load locally but ignores the target average, often leading to underloaded packs that are hard to fill later. Change the greedy assignment criteria to minimize the **L2 distance to the target mean**: assign item $i$ to the pack $p$ that minimizes $(weight_p + w_i - \\mu)^2$. This keeps all packs growing uniformly towards the ideal size.\n\n5.  **Refinement via Cyclic Shifts (3-Way Swap)**: When a direct swap between the heaviest pack ($P_{max}$) and lightest pack ($P_{min}$) is impossible, search for a **3-way cycle** involving an intermediate pack ($P_{mid}$). Move item $u$ from $P_{max} \\to P_{mid}$ and item $v$ from $P_{mid} \\to P_{min}$ such that the global imbalance decreases. This utilizes intermediate packs as buffers to facilitate weight flow from max to min."
  ],
  "total_programs_meta_processed": 90
}