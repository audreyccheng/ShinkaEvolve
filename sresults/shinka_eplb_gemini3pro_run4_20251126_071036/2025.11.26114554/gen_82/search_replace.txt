<NAME>
pool_split_packing_and_heap_replication
</NAME>

<DESCRIPTION>
1.  **Pool-and-Split Refinement in `balanced_packing`**: Replaces the pairwise swap refinement with a stronger "Pool-and-Split" strategy. This method selects the heaviest and lightest packs, pools their items, sorts them descending, and greedily redistributes them into two new packs. This allows for multi-item exchanges and structural reorganization that single swaps cannot achieve, effectively escaping local optima.
2.  **Heap-Based `replicate_experts`**: Replaces the iterative GPU-based reduction in `replicate_experts` with a CPU-based priority queue (`heapq`). This avoids the overhead of launching $O(\text{num\_redundant})$ GPU kernels for scalar updates and reductions, which is inefficient for sequential decision processes. The CPU implementation is significantly faster for this sequential logic.
3.  **Multi-Start Initialization**: Retains and slightly tunes the multi-start strategy with randomized sorting noise to explore diverse initial packings.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
import torch

def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Optimization: handle trivial case efficiently
    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic
    weight_cpu = weight.to("cpu", dtype=torch.float32)

    # Pre-allocate result tensors on CPU
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")

    # Number of random restarts to escape local optima
    num_restarts = 3

    for i in range(num_layers):
        row_w = weight_cpu[i]
        row_w_list = row_w.tolist()

        best_diff = float('inf')
        best_packs = None

        # Base sorted indices for Deterministic LPT (Longest Processing Time first)
        base_indices = torch.argsort(row_w, descending=True).tolist()

        for attempt in range(num_restarts):
            # 1. Initialization Strategy
            current_packs = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs

            if attempt == 0:
                # Deterministic LPT
                indices = base_indices
            else:
                # Randomized LPT: Add multiplicative noise to weights to vary the greedy order
                noise = torch.rand(num_groups, device="cpu") * 0.2 + 0.9 # range [0.9, 1.1]
                indices = torch.argsort(row_w * noise, descending=True).tolist()

            # Greedy Phase
            for idx in indices:
                w = row_w_list[idx]
                # Assign to the lightest pack that has space
                best_p = -1
                min_w = float('inf')

                # Scan packs (num_packs is typically small, e.g., 4-8)
                for p in range(num_packs):
                    if len(current_packs[p]) < groups_per_pack:
                        if pack_weights[p] < min_w:
                            min_w = pack_weights[p]
                            best_p = p

                current_packs[best_p].append(idx)
                pack_weights[best_p] += w

            # 2. Refinement Phase
            # Iteratively attempt to improve balance by swapping items
            for _ in range(20):
                # Sort packs by weight
                sorted_packs = sorted(range(num_packs), key=pack_weights.__getitem__)
                max_p = sorted_packs[-1]
                max_w = pack_weights[max_p]
                min_w = pack_weights[sorted_packs[0]]

                diff_global = max_w - min_w
                if diff_global < 1e-6:
                    break

                swap_found = False

                # Attempt to swap items from the heaviest pack (max_p) with items from lighter packs.
                # We iterate from the lightest pack upwards to maximize the 'room' for swapping.
                for p_other in sorted_packs[:-1]:
                    w_other = pack_weights[p_other]
                    diff = max_w - w_other
                    if diff < 1e-6: continue

                    target = diff / 2.0
                    best_swap = None
                    best_gap = float('inf')

                    # Search for u in max_p and v in p_other such that w_u - w_v approx target
                    # and 0 < w_u - w_v < diff
                    for idx_u, u in enumerate(current_packs[max_p]):
                        val_u = row_w_list[u]
                        for idx_v, v in enumerate(current_packs[p_other]):
                            val_v = row_w_list[v]

                            delta = val_u - val_v
                            if 0 < delta < diff:
                                gap = abs(delta - target)
                                if gap < best_gap:
                                    best_gap = gap
                                    best_swap = (idx_u, idx_v, delta)
                                    if gap < 1e-5: break
                        if best_swap and best_gap < 1e-5: break

                    if best_swap:
                        idx_u, idx_v, delta = best_swap
                        u = current_packs[max_p][idx_u]
                        v = current_packs[p_other][idx_v]

                        current_packs[max_p][idx_u] = v
                        current_packs[p_other][idx_v] = u
                        pack_weights[max_p] -= delta
                        pack_weights[p_other] += delta
                        swap_found = True
                        break # Break inner loop to re-evaluate max pack

                if not swap_found:
                    break

            # Check if this restart produced a better global result
            curr_max = max(pack_weights)
            curr_min = min(pack_weights)
            curr_diff = curr_max - curr_min

            if curr_diff < best_diff:
                best_diff = curr_diff
                best_packs = [list(p) for p in current_packs]
                if best_diff < 1e-6:
                    break

        # Fill result tensors
        for p in range(num_packs):
            for r, idx in enumerate(best_packs[p]):
                pack_index[i, idx] = p
                rank_in_pack[i, idx] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)


def replicate_experts(
        weight: torch.Tensor,
        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Replicate `num_log` experts to `num_phy` replicas, such that the maximum
    load of all replicas is minimized.

    Parameters:
        weight: [X, num_log]
        num_phy: total number of experts after replication

    Returns:
        phy2log: [X, num_phy], logical expert id of each physical expert
        rank: [X, num_phy], the replica rank
        logcnt: [X, num_log], number of replicas for each logical expert
    """
    n, num_log = weight.shape
    num_redundant = num_phy - num_log
    assert num_redundant >= 0
    device = weight.device

    phy2log = torch.arange(num_phy, dtype=torch.int64,
                           device=device).repeat(n, 1)
    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)
    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)
    arangen = torch.arange(n, dtype=torch.int64, device=device)

    # Optimization: Maintain current scores (weight / logcnt) to avoid
    # re-computing the full matrix in every iteration.
    current_scores = weight.clone().float()

    for i in range(num_log, num_phy):
        # Find expert with max current average load
        redundant_indices = current_scores.max(dim=-1).indices

        phy2log[:, i] = redundant_indices
        rank[:, i] = logcnt[arangen, redundant_indices]

        logcnt[arangen, redundant_indices] += 1

        # Update scores only for the experts that gained a replica
        selected_weights = weight[arangen, redundant_indices].float()
        selected_counts = logcnt[arangen, redundant_indices].float()
        current_scores[arangen, redundant_indices] = selected_weights / selected_counts

    return phy2log, rank, logcnt
=======
import torch
import heapq
import random

def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    # Optimization: handle trivial case efficiently
    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(pack_index)
        return pack_index, rank_in_pack

    # Move computation to CPU to avoid GPU synchronization overhead for sequential logic
    weight_cpu = weight.to("cpu", dtype=torch.float32)

    # Pre-allocate result tensors on CPU
    pack_index = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")
    rank_in_pack = torch.empty((num_layers, num_groups), dtype=torch.int64, device="cpu")

    # Number of random restarts to escape local optima
    num_restarts = 4

    for i in range(num_layers):
        row_w = weight_cpu[i].tolist()

        # Original items (index, weight)
        original_items = sorted(enumerate(row_w), key=lambda x: x[1], reverse=True)

        best_diff = float('inf')
        best_packs = None

        for attempt in range(num_restarts):
            # 1. Initialization Strategy
            current_packs = [[] for _ in range(num_packs)]
            pack_weights = [0.0] * num_packs

            if attempt == 0:
                # Deterministic LPT
                items = original_items
            else:
                # Randomized LPT
                noise = torch.rand(num_groups).tolist()
                noisy_items = [(idx, w, w * (0.9 + 0.2 * noise[k]))
                               for k, (idx, w) in enumerate(original_items)]
                noisy_items.sort(key=lambda x: x[2], reverse=True)
                items = [(idx, w) for idx, w, _ in noisy_items]

            # Greedy Phase
            for idx, w in items:
                # Assign to the lightest pack that has space
                best_p = -1
                min_w = float('inf')
                for p in range(num_packs):
                    if len(current_packs[p]) < groups_per_pack:
                        if pack_weights[p] < min_w:
                            min_w = pack_weights[p]
                            best_p = p
                current_packs[best_p].append(idx)
                pack_weights[best_p] += w

            # 2. Refinement Phase: Pool-and-Split
            # Instead of single swaps, pick two packs (Max and Min), pool items, and re-distribute.
            for _ in range(30):
                # Identify Max and Min packs
                min_p = 0
                max_p = 0
                min_val = pack_weights[0]
                max_val = pack_weights[0]

                for p in range(1, num_packs):
                    val = pack_weights[p]
                    if val < min_val:
                        min_val = val
                        min_p = p
                    elif val > max_val:
                        max_val = val
                        max_p = p

                if max_val - min_val < 1e-6:
                    break

                # Try to improve by pairing Max Pack with Min Pack
                # Only trying Max-Min pair is usually sufficient and fast.
                p1, p2 = max_p, min_p

                # Pool items
                pooled_items = []
                for idx in current_packs[p1]:
                    pooled_items.append((idx, row_w[idx]))
                for idx in current_packs[p2]:
                    pooled_items.append((idx, row_w[idx]))

                # Sort Descending
                pooled_items.sort(key=lambda x: x[1], reverse=True)

                # Re-distribute using constrained greedy into two temp packs
                t_packs = [[], []]
                t_weights = [0.0, 0.0]

                possible = True
                for idx, w in pooled_items:
                    # Put in valid bin with min weight
                    b_best = -1
                    b_min = float('inf')
                    for b in range(2):
                        if len(t_packs[b]) < groups_per_pack:
                            if t_weights[b] < b_min:
                                b_min = t_weights[b]
                                b_best = b
                    if b_best != -1:
                        t_packs[b_best].append(idx)
                        t_weights[b_best] += w
                    else:
                        possible = False
                        break

                if not possible: break

                # Check criteria
                old_local_max = max(pack_weights[p1], pack_weights[p2])
                new_local_max = max(t_weights[0], t_weights[1])
                old_spread = abs(pack_weights[p1] - pack_weights[p2])
                new_spread = abs(t_weights[0] - t_weights[1])

                # Accept if max load reduced, or if max load unchanged but spread reduced
                if new_local_max < old_local_max - 1e-6 or \
                   (abs(new_local_max - old_local_max) < 1e-6 and new_spread < old_spread - 1e-6):
                    current_packs[p1] = t_packs[0]
                    pack_weights[p1] = t_weights[0]
                    current_packs[p2] = t_packs[1]
                    pack_weights[p2] = t_weights[1]
                else:
                    # If Pool-and-Split on Max/Min didn't help, we are likely in a local optimum
                    # reachable by this move.
                    break

            # Check global result
            curr_diff = max(pack_weights) - min(pack_weights)
            if curr_diff < best_diff:
                best_diff = curr_diff
                best_packs = [list(p) for p in current_packs]
                if best_diff < 1e-6: break

        # Fill result tensors
        for p in range(num_packs):
            for r, idx in enumerate(best_packs[p]):
                pack_index[i, idx] = p
                rank_in_pack[i, idx] = r

    return pack_index.to(weight.device), rank_in_pack.to(weight.device)


def replicate_experts(
        weight: torch.Tensor,
        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Replicate `num_log` experts to `num_phy` replicas, such that the maximum
    load of all replicas is minimized.

    Parameters:
        weight: [X, num_log]
        num_phy: total number of experts after replication

    Returns:
        phy2log: [X, num_phy], logical expert id of each physical expert
        rank: [X, num_phy], the replica rank
        logcnt: [X, num_log], number of replicas for each logical expert
    """
    n, num_log = weight.shape
    num_redundant = num_phy - num_log
    assert num_redundant >= 0
    device = weight.device

    phy2log = torch.arange(num_phy, dtype=torch.int64,
                           device=device).repeat(n, 1)
    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)
    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)

    if num_redundant == 0:
        return phy2log, rank, logcnt

    # Move to CPU for efficient priority queue operations
    weight_cpu = weight.to("cpu", dtype=torch.float32)
    phy2log_cpu = phy2log.to("cpu")
    rank_cpu = rank.to("cpu")
    logcnt_cpu = logcnt.to("cpu")

    for layer_idx in range(n):
        w_row = weight_cpu[layer_idx].tolist()

        # Priority queue stores (-score, expert_idx, current_count)
        # Score = weight / count
        # Python heapq is a min-heap, so we store negative score to simulate max-heap
        pq = []
        for i in range(num_log):
            heapq.heappush(pq, (-w_row[i], i, 1))

        # Assign replicas one by one
        for r_idx in range(num_log, num_phy):
            score_neg, expert_idx, count = heapq.heappop(pq)

            # Assign the new replica
            phy2log_cpu[layer_idx, r_idx] = expert_idx
            rank_cpu[layer_idx, r_idx] = count

            # Update count and push back with new score
            new_count = count + 1
            logcnt_cpu[layer_idx, expert_idx] = new_count
            new_score_neg = -w_row[expert_idx] / new_count
            heapq.heappush(pq, (new_score_neg, expert_idx, new_count))

    return phy2log_cpu.to(device), rank_cpu.to(device), logcnt_cpu.to(device)
>>>>>>> REPLACE

</DIFF>