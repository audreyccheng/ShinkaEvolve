<NAME>
polish_lns_heuristic
</NAME>

<DESCRIPTION>
1. Increase `NUM_RESTARTS` to 10 and `MAX_LNS_STEPS` to 250 to utilize the available time budget for better exploration, as the current speed score is perfect (1.0).
2. Enhance the Large Neighborhood Search (LNS) "Recreate" phase. After the randomized greedy filling of the subset of packs, a new "Polish" step is introduced. This step iteratively identifies the heaviest and lightest packs within the subset and attempts to perform 1-vs-1 item swaps to reduce the load difference. This allows the algorithm to overcome the limitations of pure greedy construction (which cannot easily undo a bad early assignment) by locally refining the subset packing using pairwise exchanges, which is computationally cheap for small subsets but effective for balance.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Number of restarts for the randomized heuristic
    NUM_RESTARTS = 5

    for i in range(num_layers):
=======
    # Number of restarts for the randomized heuristic
    NUM_RESTARTS = 10

    for i in range(num_layers):
>>>>>>> REPLACE
<<<<<<< SEARCH
            # 3. Refinement: Large Neighborhood Search (LNS)
            MAX_LNS_STEPS = 100 if num_packs > 1 else 0

            for step in range(MAX_LNS_STEPS):
=======
            # 3. Refinement: Large Neighborhood Search (LNS)
            MAX_LNS_STEPS = 250 if num_packs > 1 else 0

            for step in range(MAX_LNS_STEPS):
>>>>>>> REPLACE
<<<<<<< SEARCH
                SUB_RESTARTS = 20
                for sub_attempt in range(SUB_RESTARTS):
                    if sub_attempt == 0:
                        current_items = items_sorted
                    else:
                        # Perturb weights slightly to change sort order
                        noise_sub = torch.rand(len(items))
                        # Efficient perturbed sort
                        # We use a list of tuples (perturbed_weight, index)
                        weighted_items = []
                        for idx, item in enumerate(items):
                            pw = layer_w_list[item] * (0.8 + 0.4 * noise_sub[idx].item())
                            weighted_items.append((pw, item))
                        weighted_items.sort(key=lambda x: x[0], reverse=True)
                        current_items = [x[1] for x in weighted_items]

                    # Greedy Fill (Best Fit)
                    temp_weights = {p: 0.0 for p in cand_list}
                    temp_packs = {p: [] for p in cand_list}
                    temp_counts = {p: 0 for p in cand_list}

                    possible = True
                    for item_idx in current_items:
                        w = layer_w_list[item_idx]

                        best_local_p = -1
                        min_local_w = float('inf')

                        for p in cand_list:
                            if temp_counts[p] < groups_per_pack:
                                if temp_weights[p] < min_local_w:
                                    min_local_w = temp_weights[p]
                                    best_local_p = p

                        if best_local_p == -1:
                            possible = False
                            break

                        temp_packs[best_local_p].append(item_idx)
                        temp_weights[best_local_p] += w
                        temp_counts[best_local_p] += 1

                    if possible:
                        c_max = max(temp_weights.values())
                        c_ss = sum(v*v for v in temp_weights.values())

                        # Check improvement
                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):
                            best_sub_max = c_max
                            best_sub_ss = c_ss
                            best_sub_weights = [temp_weights[p] for p in cand_list]
                            best_sub_packs = [temp_packs[p] for p in cand_list]
                            improved_sub = True
=======
                SUB_RESTARTS = 20
                for sub_attempt in range(SUB_RESTARTS):
                    if sub_attempt == 0:
                        current_items = items_sorted
                    else:
                        # Perturb weights slightly to change sort order
                        noise_sub = torch.rand(len(items))
                        # Efficient perturbed sort
                        weighted_items = []
                        for idx, item in enumerate(items):
                            pw = layer_w_list[item] * (0.85 + 0.3 * noise_sub[idx].item())
                            weighted_items.append((pw, item))
                        weighted_items.sort(key=lambda x: x[0], reverse=True)
                        current_items = [x[1] for x in weighted_items]

                    # Greedy Fill (Best Fit)
                    temp_weights = {p: 0.0 for p in cand_list}
                    temp_packs = {p: [] for p in cand_list}
                    temp_counts = {p: 0 for p in cand_list}

                    possible = True
                    for item_idx in current_items:
                        w = layer_w_list[item_idx]

                        best_local_p = -1
                        min_local_w = float('inf')

                        for p in cand_list:
                            if temp_counts[p] < groups_per_pack:
                                if temp_weights[p] < min_local_w:
                                    min_local_w = temp_weights[p]
                                    best_local_p = p

                        if best_local_p == -1:
                            possible = False
                            break

                        temp_packs[best_local_p].append(item_idx)
                        temp_weights[best_local_p] += w
                        temp_counts[best_local_p] += 1

                    if possible:
                        # Polish: Attempt pairwise swaps within subset
                        s_keys = list(temp_weights.keys())
                        for _ in range(5):
                            p_max = max(s_keys, key=temp_weights.get)
                            p_min = min(s_keys, key=temp_weights.get)
                            w_max = temp_weights[p_max]
                            w_min = temp_weights[p_min]
                            if w_max - w_min < 1e-6:
                                break

                            best_swap = None
                            best_gain = -1.0

                            for i_idx, u in enumerate(temp_packs[p_max]):
                                wu = layer_w_list[u]
                                for j_idx, v in enumerate(temp_packs[p_min]):
                                    wv = layer_w_list[v]
                                    delta = wu - wv
                                    diff = w_max - w_min
                                    if delta > 1e-6 and delta < diff:
                                        gain = delta * (diff - delta)
                                        if gain > best_gain:
                                            best_gain = gain
                                            best_swap = (i_idx, j_idx, delta)

                            if best_swap:
                                i_idx, j_idx, delta = best_swap
                                u = temp_packs[p_max][i_idx]
                                v = temp_packs[p_min][j_idx]
                                temp_packs[p_max][i_idx] = v
                                temp_packs[p_min][j_idx] = u
                                temp_weights[p_max] -= delta
                                temp_weights[p_min] += delta
                            else:
                                break

                        c_max = max(temp_weights.values())
                        c_ss = sum(v*v for v in temp_weights.values())

                        # Check improvement
                        if c_max < best_sub_max - 1e-6 or (abs(c_max - best_sub_max) < 1e-6 and c_ss < best_sub_ss - 1e-6):
                            best_sub_max = c_max
                            best_sub_ss = c_ss
                            best_sub_weights = [temp_weights[p] for p in cand_list]
                            best_sub_packs = [temp_packs[p] for p in cand_list]
                            improved_sub = True
>>>>>>> REPLACE
</DIFF>