<NAME>
dynamic_eff_and_deep_polish
</NAME>

<DESCRIPTION>
1.  **Dynamic Efficiency Scaling in Beam Search**: Introduces a decaying efficiency factor (`4.0` -> `1.0`) alongside the Gamma decay. This encourages establishing a highly parallel skeleton early in the construction phase (high reward for parallelism), while allowing for tighter, less "bonus-driven" packing in the final stages. This dynamic weighting is more sophisticated than the previous static `3.0` factor.
2.  **Optimized Gamma Range**: Adjusts Gamma decay to `2.0` -> `0.8` (from `1.8` -> `1.0`) to stronger emphasize "Big Rocks First" (accepting sequential work for large items) initially, and minimizing cost increase strictly at the end.
3.  **Deep Convergent Polish**: Increases `MAX_PASSES` in the ILS Polish phase (up to 50) and lifts the sort operation out of the loop. This leverages the "Early Exit" optimization to allow the schedule to fully settle into a local optimum without premature cutoff, maximizing the benefits of the LPT Gap Repair.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    BEAM_WIDTH = max(16, int(num_seqs * 2.5))
    GAMMA_START = 1.8
    GAMMA_END = 1.0

    # Seed beam
=======
    BEAM_WIDTH = max(16, int(num_seqs * 2.5))
    GAMMA_START = 2.0
    GAMMA_END = 0.8
    EFF_START = 4.0
    EFF_END = 1.0

    # Seed beam
>>>>>>> REPLACE
<<<<<<< SEARCH
    # Construction Loop
    for step in range(num_txns - 1):
        # Linear Gamma Decay
        progress = (step + 1) / max(1, num_txns - 1)
        current_gamma = GAMMA_START - (progress * (GAMMA_START - GAMMA_END))

        candidates = []
        for parent in beam:
            rem_list = list(parent['rem'])
            if not rem_list: continue

            # Candidate Selection: Smart LPT + Random
            to_eval = set()

            # Top LPT available
            lpt_count = 0
            for t in lpt_indices:
                if t in parent['rem']:
                    to_eval.add(t)
                    lpt_count += 1
                    if lpt_count >= 5: break

            # Random diversity
            if len(rem_list) > len(to_eval):
                pool = [x for x in rem_list if x not in to_eval]
                count = min(len(pool), 5)
                to_eval.update(random.sample(pool, count))

            parent_cost = parent['cost']
            parent_work = parent['work']

            for t in to_eval:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)
                new_work = parent_work + txn_lengths[t]

                # Base Score
                new_score = new_cost - (current_gamma * new_work)

                # Continuous Efficiency Bonus
                delta = new_cost - parent_cost
                t_len = txn_lengths[t]

                if t_len > 1e-6:
                    # efficiency 1.0 = perfect parallel (delta=0)
                    # efficiency 0.0 = sequential (delta=t_len)
                    efficiency = max(0.0, (t_len - delta) / t_len)

                    # Apply quadratic bonus for high efficiency
                    if efficiency > 0.01:
                        bonus = t_len * 3.0 * (efficiency ** 2)
                        new_score -= bonus

                new_rem = parent['rem'].copy()
                new_rem.remove(t)

                candidates.append({
                    'seq': new_seq,
                    'cost': new_cost,
                    'score': new_score,
                    'work': new_work,
                    'rem': new_rem
                })
=======
    # Construction Loop
    for step in range(num_txns - 1):
        # Linear Decay for Gamma and Efficiency Factor
        progress = (step + 1) / max(1, num_txns - 1)
        current_gamma = GAMMA_START - (progress * (GAMMA_START - GAMMA_END))
        current_eff = EFF_START - (progress * (EFF_START - EFF_END))

        candidates = []
        for parent in beam:
            rem_list = list(parent['rem'])
            if not rem_list: continue

            # Candidate Selection: Smart LPT + Random
            to_eval = set()

            # Top LPT available
            lpt_count = 0
            for t in lpt_indices:
                if t in parent['rem']:
                    to_eval.add(t)
                    lpt_count += 1
                    if lpt_count >= 5: break

            # Random diversity
            if len(rem_list) > len(to_eval):
                pool = [x for x in rem_list if x not in to_eval]
                count = min(len(pool), 5)
                to_eval.update(random.sample(pool, count))

            parent_cost = parent['cost']
            parent_work = parent['work']

            for t in to_eval:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)
                new_work = parent_work + txn_lengths[t]

                # Base Score
                new_score = new_cost - (current_gamma * new_work)

                # Continuous Efficiency Bonus
                delta = new_cost - parent_cost
                t_len = txn_lengths[t]

                if t_len > 1e-6:
                    # efficiency 1.0 = perfect parallel (delta=0)
                    # efficiency 0.0 = sequential (delta=t_len)
                    efficiency = max(0.0, (t_len - delta) / t_len)

                    # Apply dynamic quadratic bonus for high efficiency
                    if efficiency > 0.01:
                        bonus = t_len * current_eff * (efficiency ** 2)
                        new_score -= bonus

                new_rem = parent['rem'].copy()
                new_rem.remove(t)

                candidates.append({
                    'seq': new_seq,
                    'cost': new_cost,
                    'score': new_score,
                    'work': new_work,
                    'rem': new_rem
                })
>>>>>>> REPLACE
<<<<<<< SEARCH
        # D. Polish: Convergent LPT Gap Repair
        should_polish = (current_cost <= best_cost * 1.05) or (random.random() < 0.25)

        if should_polish and num_txns > 1:
            improved = True
            passes = 0
            # Significantly increased passes for full convergence
            MAX_PASSES = 12
            if num_txns < 50: MAX_PASSES = 20

            while improved and passes < MAX_PASSES:
                improved = False
                passes += 1

                # Check every transaction in LPT order
                txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

                for txn in txns_to_check:
=======
        # D. Polish: Convergent LPT Gap Repair
        should_polish = (current_cost <= best_cost * 1.05) or (random.random() < 0.25)

        if should_polish and num_txns > 1:
            improved = True
            passes = 0
            # Unbounded/High passes for maximum convergence allowed by Early Exit
            MAX_PASSES = 25
            if num_txns < 50: MAX_PASSES = 50

            # Precompute LPT check order (constant set of txns)
            txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

            while improved and passes < MAX_PASSES:
                improved = False
                passes += 1

                for txn in txns_to_check:
>>>>>>> REPLACE
</DIFF>