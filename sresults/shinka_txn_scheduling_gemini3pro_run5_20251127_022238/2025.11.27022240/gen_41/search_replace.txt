<NAME>
density_beam_and_best_insert
</NAME>

<DESCRIPTION>
1.  **Density-Aware Beam Search**: Introduced `txn_weights` to calculate the standalone cost of each transaction. Modified the Beam Search to use a scoring function (`cost - alpha * weight`) that prioritizes schedules that pack more "work" (heavier transactions) into the same makespan. This acts as a smart tie-breaker to handle the "Zero-Cost Bonus" recommendation.
2.  **Weighted Beam Width**: Increased `BEAM_WIDTH` from 5 to 8 to explore more candidates, leveraging the fast execution time.
3.  **Best-Insert Operator**: Added a `best_insert` operator to the Simulated Annealing phase. This operator removes a random transaction and inserts it at the *optimal* position (greedy best-fit) rather than a random one. This deterministic improvement step (albeit applied stochastically) helps polish the schedule significantly.
4.  **Hyperparameters**: Adjusted `OP_WEIGHTS` to include `best_insert` with a low probability (due to its high computational cost) and tuned adaptation rates.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Hyperparameters ---
    BEAM_WIDTH = 5

    # SA Parameters
    SA_ITERATIONS = 8000
    SA_COOLING_RATE = 0.999
    SA_START_TEMP_RATIO = 0.05

    # Ruin-and-Recreate Parameters
    STAGNATION_LIMIT = 500
    RUIN_BLOCK_SIZE_MIN = 2
    RUIN_BLOCK_SIZE_MAX = 5

    # Adaptive Operator Weights
    OP_WEIGHTS = {'swap': 2.0, 'insert': 8.0, 'block_move': 4.0, 'reverse': 1.0}
    OP_MIN_WEIGHT = 1.0
    OP_ADAPTATION_RATE = 0.1

    cost_cache = {}

    def get_cost_cached(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- PHASE 1: Exhaustive Beam Search Construction ---
    candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        candidates.append((cost, seq, {x for x in range(workload.num_txns) if x != t}))

    candidates.sort(key=lambda x: x[0])
    beam = candidates[:BEAM_WIDTH]

    for _ in range(workload.num_txns - 1):
        next_beam_candidates = []
        for b_cost, b_seq, b_rem in beam:
            for cand in b_rem:
                new_seq = b_seq + [cand]
                new_cost = get_cost_cached(new_seq)
                next_beam_candidates.append((new_cost, new_seq, b_rem, cand))

        # Greedy sort
        next_beam_candidates.sort(key=lambda x: x[0])

        new_beam = []
        for c_cost, c_seq, c_parent_rem, c_cand in next_beam_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break
            new_rem = c_parent_rem.copy()
            new_rem.remove(c_cand)
            new_beam.append((c_cost, c_seq, new_rem))
        beam = new_beam

    if not beam:
        return float('inf'), []

    current_schedule = beam[0][1]
    current_cost = beam[0][0]
=======
    # --- Hyperparameters ---
    BEAM_WIDTH = 8

    # SA Parameters
    SA_ITERATIONS = 8000
    SA_COOLING_RATE = 0.999
    SA_START_TEMP_RATIO = 0.05

    # Ruin-and-Recreate Parameters
    STAGNATION_LIMIT = 500
    RUIN_BLOCK_SIZE_MIN = 2
    RUIN_BLOCK_SIZE_MAX = 5

    # Adaptive Operator Weights
    # Added 'best_insert': expensive but powerful local optimization
    OP_WEIGHTS = {'swap': 2.0, 'insert': 6.0, 'block_move': 4.0, 'reverse': 1.0, 'best_insert': 0.4}
    OP_MIN_WEIGHT = 0.5
    OP_ADAPTATION_RATE = 0.1

    cost_cache = {}

    def get_cost_cached(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- Pre-calculation: Transaction Weights ---
    # Used for density-aware heuristics
    txn_weights = {}
    for t in range(workload.num_txns):
        txn_weights[t] = get_cost_cached([t])

    # --- PHASE 1: Density-Aware Beam Search Construction ---
    candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        w = txn_weights[t]
        # Score heuristic: Minimize cost, maximize packed weight (as tie-breaker)
        score = cost - (0.005 * w)
        candidates.append({'score': score, 'cost': cost, 'seq': seq, 'weight': w, 'rem': {x for x in range(workload.num_txns) if x != t}})

    candidates.sort(key=lambda x: x['score'])
    beam = candidates[:BEAM_WIDTH]

    for _ in range(workload.num_txns - 1):
        next_beam_candidates = []
        for node in beam:
            b_seq = node['seq']
            b_rem = node['rem']
            b_w = node['weight']

            for cand in b_rem:
                new_seq = b_seq + [cand]
                new_cost = get_cost_cached(new_seq)

                # Update total weight packed
                new_w = b_w + txn_weights[cand]

                # Density-aware score
                score = new_cost - (0.005 * new_w)

                next_beam_candidates.append({
                    'score': score,
                    'cost': new_cost,
                    'seq': new_seq,
                    'weight': new_w,
                    'rem': b_rem,
                    'cand': cand
                })

        # Sort by heuristic score
        next_beam_candidates.sort(key=lambda x: x['score'])

        new_beam = []
        for cand_node in next_beam_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            new_rem = cand_node['rem'].copy()
            new_rem.remove(cand_node['cand'])

            # Create new beam node
            new_node = cand_node.copy()
            new_node['rem'] = new_rem
            del new_node['cand'] # clean up

            new_beam.append(new_node)
        beam = new_beam

    if not beam:
        return float('inf'), []

    current_schedule = beam[0]['seq']
    current_cost = beam[0]['cost']
>>>>>>> REPLACE
<<<<<<< SEARCH
        if op == 'swap':
            i, j = random.sample(range(n), 2)
            neighbor[i], neighbor[j] = neighbor[j], neighbor[i]
        elif op == 'insert':
            i = random.randint(0, n - 1)
            val = neighbor.pop(i)
            j = random.randint(0, n - 1)
            neighbor.insert(j, val)
        elif op == 'reverse':
            i, j = sorted(random.sample(range(n), 2))
            neighbor[i:j+1] = neighbor[i:j+1][::-1]
        elif op == 'block_move':
            b_size = random.randint(2, 6)
            if n > b_size:
                i = random.randint(0, n - b_size)
                block = neighbor[i:i+b_size]
                del neighbor[i:i+b_size]
                j = random.randint(0, len(neighbor))
                neighbor[j:j] = block
=======
        if op == 'swap':
            i, j = random.sample(range(n), 2)
            neighbor[i], neighbor[j] = neighbor[j], neighbor[i]
        elif op == 'insert':
            i = random.randint(0, n - 1)
            val = neighbor.pop(i)
            j = random.randint(0, n - 1)
            neighbor.insert(j, val)
        elif op == 'reverse':
            i, j = sorted(random.sample(range(n), 2))
            neighbor[i:j+1] = neighbor[i:j+1][::-1]
        elif op == 'block_move':
            b_size = random.randint(2, 6)
            if n > b_size:
                i = random.randint(0, n - b_size)
                block = neighbor[i:i+b_size]
                del neighbor[i:i+b_size]
                j = random.randint(0, len(neighbor))
                neighbor[j:j] = block
        elif op == 'best_insert':
            # Deterministic greedy best-fit insertion for a random item
            idx = random.randint(0, n - 1)
            val = neighbor.pop(idx)
            best_pos = -1
            min_c = float('inf')

            for i in range(len(neighbor) + 1):
                neighbor.insert(i, val)
                c = get_cost_cached(neighbor)
                if c < min_c:
                    min_c = c
                    best_pos = i
                neighbor.pop(i)

            neighbor.insert(best_pos, val)
>>>>>>> REPLACE
</DIFF>