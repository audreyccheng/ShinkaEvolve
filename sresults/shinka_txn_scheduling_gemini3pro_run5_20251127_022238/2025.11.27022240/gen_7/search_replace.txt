<NAME>
exhaustive_beam_search
</NAME>

<DESCRIPTION>
Replace the multi-restart stochastic Beam Search with a single-pass, exhaustive Beam Search followed by extended Simulated Annealing.

Rationale:
1. **Exhaustive Candidate Evaluation**: The previous approach sampled only ~12 candidates (12%) per step. This high probability of missing the optimal 'next transaction' severely limits the quality of the greedy construction. By evaluating *all* remaining transactions at each step, we ensure the local greedy decision is optimal.
2. **Computational Budget Reallocation**: Instead of 3 random restarts with poor sampling, we invest the budget into one high-quality construction (Width=4, All Samples). The complexity is roughly $W \times N^2/2 \approx 20,000$ operations, which matches the previous budget.
3. **Improved SA**: With a better starting schedule, we run SA for more iterations (4000) with a tuned cooling schedule to refine local optima.
4. **Deterministic Tie-breaking**: Reduces variance in results.

This approach exploits the monotonic nature of the cost function more effectively by finding a much superior "backbone" schedule before refining.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Beam Search construction followed by Simulated Annealing.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting the computational budget (number of restarts)

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Hyperparameters
    # Scale restarts based on input request, but keep reasonable bounds
    NUM_RESTARTS = max(2, int(num_seqs / 3))

    # Beam Search Parameters
    BEAM_WIDTH = 4
    BEAM_SAMPLES = 12  # Number of candidates to sample for each beam path

    # Simulated Annealing Parameters
    SA_ITERATIONS = 2000
    SA_COOLING_RATE = 0.992

    best_global_cost = float('inf')
    best_global_schedule = []

    # Cache for costs to avoid re-simulating identical schedules during SA
    cost_cache = {}

    def get_cost_cached(seq):
        # Convert to tuple for hashing
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]

        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    for _ in range(NUM_RESTARTS):
        # --- PHASE 1: Beam Search Construction ---
        # Initialize beam with random start transactions for diversity
        initial_candidates = random.sample(range(workload.num_txns), min(workload.num_txns, BEAM_WIDTH * 2))
        beam = [] # List of tuples: (cost, sequence_list, remaining_set_list)

        for start_txn in initial_candidates:
            seq = [start_txn]
            rem = list(range(workload.num_txns))
            rem.remove(start_txn)
            # Use cached cost
            cost = get_cost_cached(seq)
            beam.append((cost, seq, rem))

        # Select best initial starts
        beam.sort(key=lambda x: x[0])
        beam = beam[:BEAM_WIDTH]

        # Iteratively build the schedule
        # We need to add (num_txns - 1) more transactions
        for _ in range(workload.num_txns - 1):
            next_beam_candidates = []

            for b_cost, b_seq, b_rem in beam:
                # Sample a subset of remaining transactions to evaluate
                sample_size = min(len(b_rem), BEAM_SAMPLES)
                candidates = random.sample(b_rem, sample_size)

                for cand in candidates:
                    new_seq = b_seq + [cand]
                    new_cost = get_cost_cached(new_seq)

                    # Store candidate info. We reconstruct remaining list later for survivors only
                    next_beam_candidates.append((new_cost, new_seq, b_rem, cand))

            # Prune: Sort by cost and keep top BEAM_WIDTH
            next_beam_candidates.sort(key=lambda x: x[0])

            new_beam = []
            for c_cost, c_seq, c_parent_rem, c_cand in next_beam_candidates:
                if len(new_beam) >= BEAM_WIDTH:
                    break

                # Construct the new remaining list for the survivor
                new_rem = list(c_parent_rem)
                new_rem.remove(c_cand)
                new_beam.append((c_cost, c_seq, new_rem))

            beam = new_beam

        # Best result from Beam Search
        current_schedule = beam[0][1]
        current_cost = beam[0][0]

        # --- PHASE 2: Simulated Annealing Refinement ---
        # Start temperature proportional to cost (e.g., 5%)
        T = current_cost * 0.05

        best_run_schedule = list(current_schedule)
        best_run_cost = current_cost

        for k in range(SA_ITERATIONS):
            # Create neighbor by perturbing the schedule
            neighbor = list(current_schedule)
            idx1 = random.randint(0, len(neighbor) - 1)
            idx2 = random.randint(0, len(neighbor) - 1)

            if idx1 == idx2:
                continue

            # Randomly choose perturbation type: Swap vs Insert
            # Insert is generally better for scheduling (shifting jobs), Swap for sorting
            if random.random() < 0.5:
                # Swap
                neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]
            else:
                # Insert (Move item at idx1 to idx2)
                val = neighbor.pop(idx1)
                neighbor.insert(idx2, val)

            new_cost = get_cost_cached(neighbor)
            delta = new_cost - current_cost

            # Acceptance Probability
            accept = False
            if delta < 0:
                accept = True
            elif T > 1e-9:
                # Metropolis criterion
                p = math.exp(-delta / T)
                if random.random() < p:
                    accept = True

            if accept:
                current_schedule = neighbor
                current_cost = new_cost
                if current_cost < best_run_cost:
                    best_run_cost = current_cost
                    best_run_schedule = list(current_schedule)

            # Cool down
            T *= SA_COOLING_RATE
            if T < 0.1: T = 0.1

        # Update global best if this run found a better schedule
        if best_run_cost < best_global_cost:
            best_global_cost = best_run_cost
            best_global_schedule = best_run_schedule

    return best_global_cost, best_global_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Exhaustive Beam Search construction followed by Simulated Annealing.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting the computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Hyperparameters
    # Use budget for one high-quality construction instead of multiple restarts
    # Width 4 allows maintaining diversity while exhaustive search ensures local optimality
    BEAM_WIDTH = 4

    # Simulated Annealing Parameters
    # Increased iterations as we only run once
    SA_ITERATIONS = 4000
    SA_COOLING_RATE = 0.9985

    best_global_cost = float('inf')
    best_global_schedule = []

    # Cache for costs to avoid re-simulating identical schedules
    cost_cache = {}

    def get_cost_cached(seq):
        # Convert to tuple for hashing
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]

        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- PHASE 1: Exhaustive Beam Search Construction ---
    # Step 1: Initialize beam by evaluating ALL possible start transactions
    initial_candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        initial_candidates.append((cost, seq, [x for x in range(workload.num_txns) if x != t]))

    # Sort and take top BEAM_WIDTH
    initial_candidates.sort(key=lambda x: x[0])
    beam = initial_candidates[:BEAM_WIDTH]

    # Iteratively build the schedule
    # We need to add (num_txns - 1) more transactions
    for _ in range(workload.num_txns - 1):
        next_beam_candidates = []

        for b_cost, b_seq, b_rem in beam:
            # Evaluate ALL remaining transactions
            # Exhaustive search ensures we pick the absolute best local moves
            for cand in b_rem:
                new_seq = b_seq + [cand]
                new_cost = get_cost_cached(new_seq)

                # Store candidate info
                next_beam_candidates.append((new_cost, new_seq, b_rem, cand))

        # Prune: Sort by cost and keep top BEAM_WIDTH
        # This keeps the best paths found so far
        next_beam_candidates.sort(key=lambda x: x[0])

        new_beam = []
        # Filter to ensure we don't pick duplicates (though unlikely with different parents)
        # and limit to BEAM_WIDTH
        for c_cost, c_seq, c_parent_rem, c_cand in next_beam_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            # Construct the new remaining list for the survivor
            new_rem = list(c_parent_rem)
            new_rem.remove(c_cand)
            new_beam.append((c_cost, c_seq, new_rem))

        beam = new_beam

    # Best result from Beam Search
    if not beam:
        # Fallback if beam empty (should not happen)
        return float('inf'), []

    current_schedule = beam[0][1]
    current_cost = beam[0][0]

    # --- PHASE 2: Simulated Annealing Refinement ---
    # Start temperature proportional to cost
    T = current_cost * 0.05

    best_run_schedule = list(current_schedule)
    best_run_cost = current_cost

    for k in range(SA_ITERATIONS):
        # Create neighbor by perturbing the schedule
        neighbor = list(current_schedule)
        idx1 = random.randint(0, len(neighbor) - 1)
        idx2 = random.randint(0, len(neighbor) - 1)

        if idx1 == idx2:
            continue

        # Randomly choose perturbation type
        if random.random() < 0.5:
            # Swap
            neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]
        else:
            # Insert (Move item at idx1 to idx2)
            val = neighbor.pop(idx1)
            neighbor.insert(idx2, val)

        new_cost = get_cost_cached(neighbor)
        delta = new_cost - current_cost

        # Acceptance Probability
        accept = False
        if delta < 0:
            accept = True
        elif T > 1e-9:
            # Metropolis criterion
            p = math.exp(-delta / T)
            if random.random() < p:
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost
            if current_cost < best_run_cost:
                best_run_cost = current_cost
                best_run_schedule = list(current_schedule)

        # Cool down
        T *= SA_COOLING_RATE
        if T < 0.1: T = 0.1

    return best_run_cost, best_run_schedule
>>>>>>> REPLACE

</DIFF>