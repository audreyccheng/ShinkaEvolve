<NAME>
optimize_polish_and_adaptive_ruin
</NAME>
<DESCRIPTION>
1.  **Adaptive Ruin:** Introduces a `stagnation` counter. If the global best solution isn't updated for consecutive cycles, the size of the removed blocks (perturbation strength) increases. This helps escape local optima when the search gets stuck.
2.  **Optimized Deep Polish (Gap Repair):**
    *   Increases `MAX_PASSES` to 3 to allow the algorithm to converge closer to a local optimum.
    *   Adds an **Early Exit** condition: During the scan for the best position of a transaction, if a position is found where the makespan equals the makespan *without* that transaction (perfect parallelism/hiding), the scan stops immediately. This significantly reduces the number of expensive evaluations, allowing for more passes within the time budget.
    *   Re-calculates `base_cost_no_txn` (cost without the transaction) to enable the Early Exit check.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    # --- 2. Refinement Phase: Deterministic Gap-Repair ILS ---

    best_schedule = list(current_schedule)
    best_cost = current_cost

    # Adjust cycles based on workload size
    ILS_CYCLES = 5
    if num_txns < 20: ILS_CYCLES = 2
    if num_txns > 80: ILS_CYCLES = 4 # slightly less cycles for very large workloads to save time for polish

    for cycle in range(ILS_CYCLES):

        # A. Restart Strategy
        if cycle > 0 and current_cost > best_cost:
            # Revert to best to focus search (intensification)
            if random.random() < 0.4:
                current_schedule = list(best_schedule)
                current_cost = best_cost

        # B. Multi-Mode Ruin
        work_seq = list(current_schedule)
        removed_txns = []

        r_mode = random.random()

        if r_mode < 0.25:
            # Mode 1: Tail Ruin (Target critical path end)
            bs = max(4, int(num_txns * 0.25))
            if len(work_seq) > bs:
                start = len(work_seq) - bs
                removed_txns = work_seq[start:]
                del work_seq[start:]

        elif r_mode < 0.55:
            # Mode 2: Single Large Block (Locality)
            bs = max(2, int(num_txns * 0.2))
            if len(work_seq) > bs:
                start = random.randint(0, len(work_seq) - bs)
                removed_txns = work_seq[start : start + bs]
                del work_seq[start : start + bs]

        elif r_mode < 0.85:
            # Mode 3: Two Disjoint Blocks (Global shuffle)
            total_rem = max(4, int(num_txns * 0.20))
            b1 = total_rem // 2
            b2 = total_rem - b1

            if len(work_seq) > b1:
                s1 = random.randint(0, len(work_seq) - b1)
                removed_txns.extend(work_seq[s1 : s1 + b1])
                del work_seq[s1 : s1 + b1]
            if len(work_seq) > b2:
                s2 = random.randint(0, len(work_seq) - b2)
                removed_txns.extend(work_seq[s2 : s2 + b2])
                del work_seq[s2 : s2 + b2]

        else:
            # Mode 4: Random Scatter (Dependency chains)
            cnt = max(3, int(num_txns * 0.15))
            indices = sorted(random.sample(range(len(work_seq)), min(len(work_seq), cnt)), reverse=True)
            for idx in indices:
                removed_txns.append(work_seq.pop(idx))

        # Sort removed transactions by LPT (Longest Processing Time)
        # Re-inserting big items first (Big Rocks principle)
        removed_txns.sort(key=lambda t: txn_lengths.get(t, 0), reverse=True)

        # C. Recreate (Greedy Best-Fit)
        for txn in removed_txns:
            best_pos = -1
            best_incr = float('inf')

            for pos in range(len(work_seq) + 1):
                work_seq.insert(pos, txn)
                c = workload.get_opt_seq_cost(work_seq)
                if c < best_incr:
                    best_incr = c
                    best_pos = pos
                del work_seq[pos]

            work_seq.insert(best_pos, txn)

        current_schedule = work_seq
        current_cost = best_incr

        if current_cost < best_cost:
            best_cost = current_cost
            best_schedule = list(current_schedule)

        # D. Polish: Deterministic Iterative Improvement (Gap Repair)
        # Scan entire schedule, try to move each transaction to its optimal position.

        # Heuristic to decide if polish is needed
        # Always polish if we are near the best solution to try and break through
        # Or randomly to explore
        should_polish = (current_cost <= best_cost * 1.05) or (random.random() < 0.3)

        if should_polish and num_txns > 1:
            improved = True
            passes = 0
            MAX_PASSES = 1
            if num_txns < 50: MAX_PASSES = 2 # Allow more passes for small workloads

            while improved and passes < MAX_PASSES:
                improved = False
                passes += 1

                # Check every transaction
                # Processing in LPT order can sometimes help settle major blocks first
                txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

                for txn in txns_to_check:
                    # Find current location
                    try:
                        current_idx = current_schedule.index(txn)
                    except ValueError:
                        continue

                    # Cost without txn
                    del current_schedule[current_idx]

                    # Find best insertion point
                    best_pos = -1
                    best_val = float('inf')

                    # Scan all positions
                    for pos in range(len(current_schedule) + 1):
                        current_schedule.insert(pos, txn)
                        c = workload.get_opt_seq_cost(current_schedule)
                        if c < best_val:
                            best_val = c
                            best_pos = pos
                        del current_schedule[pos]

                    # Re-insert at best position
                    current_schedule.insert(best_pos, txn)

                    # Update if improved
                    if best_val < current_cost - 1e-6:
                        current_cost = best_val
                        improved = True
                        if current_cost < best_cost:
                            best_cost = current_cost
                            best_schedule = list(current_schedule)
=======
    # --- 2. Refinement Phase: Adaptive ILS + Optimized Gap Repair ---

    best_schedule = list(current_schedule)
    best_cost = current_cost

    stagnation = 0

    # Adjust cycles based on workload size
    ILS_CYCLES = 5
    if num_txns < 20: ILS_CYCLES = 3
    if num_txns > 80: ILS_CYCLES = 4

    for cycle in range(ILS_CYCLES):

        # A. Restart Strategy
        # If stagnated or drifted too far, restart from best
        if cycle > 0 and current_cost > best_cost:
            prob_restart = 0.4 + (0.1 * stagnation)
            if random.random() < prob_restart:
                current_schedule = list(best_schedule)
                current_cost = best_cost
                stagnation = 0

        # B. Adaptive Multi-Mode Ruin
        work_seq = list(current_schedule)
        removed_txns = []

        # Ruin Intensity increases with stagnation
        intensity_mult = 1.0 + (0.2 * stagnation)

        r_mode = random.random()

        if r_mode < 0.25:
            # Mode 1: Tail Ruin
            base_size = 0.25 * intensity_mult
            bs = max(4, int(num_txns * min(0.5, base_size)))
            if len(work_seq) > bs:
                start = len(work_seq) - bs
                removed_txns = work_seq[start:]
                del work_seq[start:]

        elif r_mode < 0.55:
            # Mode 2: Single Large Block
            base_size = 0.2 * intensity_mult
            bs = max(2, int(num_txns * min(0.4, base_size)))
            if len(work_seq) > bs:
                start = random.randint(0, len(work_seq) - bs)
                removed_txns = work_seq[start : start + bs]
                del work_seq[start : start + bs]

        elif r_mode < 0.85:
            # Mode 3: Two Disjoint Blocks
            base_size = 0.20 * intensity_mult
            total_rem = max(4, int(num_txns * min(0.4, base_size)))
            b1 = total_rem // 2
            b2 = total_rem - b1

            if len(work_seq) > b1:
                s1 = random.randint(0, len(work_seq) - b1)
                removed_txns.extend(work_seq[s1 : s1 + b1])
                del work_seq[s1 : s1 + b1]
            if len(work_seq) > b2:
                s2 = random.randint(0, len(work_seq) - b2)
                removed_txns.extend(work_seq[s2 : s2 + b2])
                del work_seq[s2 : s2 + b2]

        else:
            # Mode 4: Scatter
            cnt = max(3, int(num_txns * 0.15 * intensity_mult))
            indices = sorted(random.sample(range(len(work_seq)), min(len(work_seq), cnt)), reverse=True)
            for idx in indices:
                removed_txns.append(work_seq.pop(idx))

        # Re-inserting big items first
        removed_txns.sort(key=lambda t: txn_lengths.get(t, 0), reverse=True)

        # C. Recreate (Greedy Best-Fit)
        for txn in removed_txns:
            best_pos = -1
            best_incr = float('inf')

            for pos in range(len(work_seq) + 1):
                work_seq.insert(pos, txn)
                c = workload.get_opt_seq_cost(work_seq)
                if c < best_incr:
                    best_incr = c
                    best_pos = pos
                del work_seq[pos]

            work_seq.insert(best_pos, txn)

        current_schedule = work_seq
        current_cost = best_incr

        if current_cost < best_cost:
            best_cost = current_cost
            best_schedule = list(current_schedule)
            stagnation = 0
        else:
            stagnation += 1

        # D. Polish: Optimized Gap Repair with Early Exit
        should_polish = (current_cost <= best_cost * 1.05) or (stagnation > 2) or (random.random() < 0.2)

        if should_polish and num_txns > 1:
            improved = True
            passes = 0
            # Increase passes but rely on Early Exit to save time
            MAX_PASSES = 3

            while improved and passes < MAX_PASSES:
                improved = False
                passes += 1

                txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

                for txn in txns_to_check:
                    try:
                        current_idx = current_schedule.index(txn)
                    except ValueError: continue

                    # Temporarily remove txn
                    del current_schedule[current_idx]

                    # Calculate baseline cost (cost without this txn)
                    # This allows detecting "Perfect Hiding"
                    base_cost_no_txn = workload.get_opt_seq_cost(current_schedule)

                    best_pos = -1
                    best_val = float('inf')

                    # Scan all positions
                    for pos in range(len(current_schedule) + 1):
                        current_schedule.insert(pos, txn)
                        c = workload.get_opt_seq_cost(current_schedule)

                        # Optimization: Undo immediately
                        del current_schedule[pos]

                        if c < best_val:
                            best_val = c
                            best_pos = pos

                        # EARLY EXIT: Perfect Parallelism
                        # If adding the transaction doesn't increase makespan relative to
                        # the schedule without it, we can't do better. Stop scanning.
                        if c <= base_cost_no_txn + 1e-9:
                            break

                    # Re-insert at best position
                    current_schedule.insert(best_pos, txn)

                    # Update global if improved
                    if best_val < current_cost - 1e-6:
                        current_cost = best_val
                        improved = True
                        if current_cost < best_cost:
                            best_cost = current_cost
                            best_schedule = list(current_schedule)
                            stagnation = 0
>>>>>>> REPLACE
</DIFF>

<NAME>
tune_beam_search
</NAME>
<DESCRIPTION>
Adjusts the Beam Search parameters:
- Increases the number of LPT candidates considered during expansion (from 5 to 7) to ensure high-work transactions are not missed early on.
- Adjusts the Gamma decay to end at 0.8 instead of 1.0. A value < 1.0 at the end encourages "overpacking" or finding slots where the marginal cost is less than the work added, effectively smoothing the transition into the refinement phase.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    beam = []
    GAMMA_START = 1.8
    GAMMA_END = 1.0

    for t in seeds:
=======
    beam = []
    GAMMA_START = 1.8
    GAMMA_END = 0.8

    for t in seeds:
>>>>>>> REPLACE
<<<<<<< SEARCH
            # Smart LPT Selection
            lpt_count = 0
            for t in lpt_indices:
                if t in parent['rem']:
                    to_eval.add(t)
                    lpt_count += 1
                    if lpt_count >= 5: break
=======
            # Smart LPT Selection
            lpt_count = 0
            for t in lpt_indices:
                if t in parent['rem']:
                    to_eval.add(t)
                    lpt_count += 1
                    if lpt_count >= 7: break
>>>>>>> REPLACE
</DIFF>