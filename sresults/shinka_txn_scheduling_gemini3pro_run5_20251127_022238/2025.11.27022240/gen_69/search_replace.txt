<NAME>
optimize_polish_phase
</NAME>

<DESCRIPTION>
Significantly enhance the refinement phase (ILS and Polish) to improve schedule quality and convergence.
1.  **Early Exit Optimization**: In both the Recreate and Polish phases, if a transaction insertion results in zero makespan increase (perfect parallelism), stop scanning immediately. This drastically reduces computation time.
2.  **Increased Polish Passes**: With the time saved by early exit, increase `MAX_PASSES` in the Polish phase (from 1 to 3-5). This allows the "Gap Repair" strategy to converge deeper into local optima.
3.  **Adaptive ILS Cycles**: Slightly tuned ILS cycle counts to balance exploration with the more intensive exploitation of the improved Polish phase.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- 2. Refinement Phase: Deterministic ILS ---

    best_schedule = list(current_schedule)
    best_cost = current_cost

    ILS_CYCLES = 5
    if num_txns < 20: ILS_CYCLES = 2

    for cycle in range(ILS_CYCLES):

        # A. Restart Strategy
        if cycle > 0 and current_cost > best_cost:
            # Periodically revert to best to focus search
            if random.random() < 0.4:
                current_schedule = list(best_schedule)
                current_cost = best_cost

        # B. Multi-Mode Ruin
        work_seq = list(current_schedule)
        removed_txns = []

        r_mode = random.random()

        if r_mode < 0.25:
            # Mode 1: Tail Ruin (Target critical path end)
            bs = max(4, int(num_txns * 0.25))
            if len(work_seq) > bs:
                start = len(work_seq) - bs
                removed_txns = work_seq[start:]
                del work_seq[start:]

        elif r_mode < 0.55:
            # Mode 2: Single Large Block (Locality)
            bs = max(2, int(num_txns * 0.2))
            if len(work_seq) > bs:
                start = random.randint(0, len(work_seq) - bs)
                removed_txns = work_seq[start : start + bs]
                del work_seq[start : start + bs]

        elif r_mode < 0.85:
            # Mode 3: Two Disjoint Blocks (Global shuffle)
            total_rem = max(4, int(num_txns * 0.20))
            b1 = total_rem // 2
            b2 = total_rem - b1

            if len(work_seq) > b1:
                s1 = random.randint(0, len(work_seq) - b1)
                removed_txns.extend(work_seq[s1 : s1 + b1])
                del work_seq[s1 : s1 + b1]
            if len(work_seq) > b2:
                s2 = random.randint(0, len(work_seq) - b2)
                removed_txns.extend(work_seq[s2 : s2 + b2])
                del work_seq[s2 : s2 + b2]

        else:
            # Mode 4: Random Scatter (Dependency chains)
            cnt = max(3, int(num_txns * 0.15))
            indices = sorted(random.sample(range(len(work_seq)), min(len(work_seq), cnt)), reverse=True)
            for idx in indices:
                removed_txns.append(work_seq.pop(idx))

        # Sort removed transactions by LPT (Longest Processing Time)
        # Placing difficult/long transactions first improves packing efficiency
        removed_txns.sort(key=lambda t: txn_lengths.get(t, 0), reverse=True)

        # C. Recreate (Greedy Best-Fit)
        for txn in removed_txns:
            best_pos = -1
            best_incr = float('inf')

            for pos in range(len(work_seq) + 1):
                work_seq.insert(pos, txn)
                c = workload.get_opt_seq_cost(work_seq)
                if c < best_incr:
                    best_incr = c
                    best_pos = pos
                del work_seq[pos]

            work_seq.insert(best_pos, txn)

        current_schedule = work_seq
        current_cost = best_incr # Update cost

        # Save if improved
        if current_cost < best_cost:
            best_cost = current_cost
            best_schedule = list(current_schedule)

        # D. Polish: Deterministic Iterative Improvement (Gap Repair)
        # Scan entire schedule, try to move each transaction to its optimal position.
        # This is expensive but powerful.

        # Optimization: Only perform if we are close to best or randomly
        # to save compute on bad candidates.
        should_polish = (current_cost <= best_cost * 1.05) or (random.random() < 0.3)

        if should_polish and num_txns > 1:
            improved = True
            passes = 0
            MAX_PASSES = 1

            while improved and passes < MAX_PASSES:
                improved = False
                passes += 1

                # Check every transaction
                # Iterate over a snapshot so indices don't get messed up by moves
                # Sort by LPT: Try to optimize placement of large blocks first
                txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

                for txn in txns_to_check:
                    # Find current location
                    try:
                        current_idx = current_schedule.index(txn)
                    except ValueError:
                        continue # Should not happen

                    # Temporarily remove
                    del current_schedule[current_idx]

                    # Find best insertion point
                    best_pos = -1
                    best_val = float('inf')

                    # Full scan
                    for pos in range(len(current_schedule) + 1):
                        current_schedule.insert(pos, txn)
                        c = workload.get_opt_seq_cost(current_schedule)
                        if c < best_val:
                            best_val = c
                            best_pos = pos
                        del current_schedule[pos]

                    # Re-insert at best position
                    current_schedule.insert(best_pos, txn)

                    # If we found a better position that improves the global cost
                    if best_val < current_cost - 1e-6:
                        current_cost = best_val
                        improved = True
                        if current_cost < best_cost:
                            best_cost = current_cost
                            best_schedule = list(current_schedule)
=======
    # --- 2. Refinement Phase: Deterministic ILS ---

    best_schedule = list(current_schedule)
    best_cost = current_cost

    # Adaptive cycles based on problem size
    ILS_CYCLES = 6
    if num_txns < 20: ILS_CYCLES = 3

    for cycle in range(ILS_CYCLES):

        # A. Restart Strategy
        # Periodically revert to best to focus search
        if cycle > 0 and current_cost > best_cost:
            if random.random() < 0.4:
                current_schedule = list(best_schedule)
                current_cost = best_cost

        # B. Multi-Mode Ruin
        work_seq = list(current_schedule)
        removed_txns = []

        r_mode = random.random()

        if r_mode < 0.25:
            # Mode 1: Tail Ruin (Critical Path)
            bs = max(4, int(num_txns * 0.25))
            if len(work_seq) > bs:
                start = len(work_seq) - bs
                removed_txns = work_seq[start:]
                del work_seq[start:]

        elif r_mode < 0.55:
            # Mode 2: Single Large Block (Locality)
            bs = max(2, int(num_txns * 0.2))
            if len(work_seq) > bs:
                start = random.randint(0, len(work_seq) - bs)
                removed_txns = work_seq[start : start + bs]
                del work_seq[start : start + bs]

        elif r_mode < 0.85:
            # Mode 3: Two Disjoint Blocks (Global shuffle)
            total_rem = max(4, int(num_txns * 0.20))
            b1 = total_rem // 2
            b2 = total_rem - b1

            if len(work_seq) > b1:
                s1 = random.randint(0, len(work_seq) - b1)
                removed_txns.extend(work_seq[s1 : s1 + b1])
                del work_seq[s1 : s1 + b1]
            if len(work_seq) > b2:
                s2 = random.randint(0, len(work_seq) - b2)
                removed_txns.extend(work_seq[s2 : s2 + b2])
                del work_seq[s2 : s2 + b2]

        else:
            # Mode 4: Random Scatter (Dependency chains)
            cnt = max(3, int(num_txns * 0.15))
            indices = sorted(random.sample(range(len(work_seq)), min(len(work_seq), cnt)), reverse=True)
            for idx in indices:
                removed_txns.append(work_seq.pop(idx))

        # Sort removed transactions by LPT (Longest Processing Time)
        # Placing difficult/long transactions first improves packing efficiency
        removed_txns.sort(key=lambda t: txn_lengths.get(t, 0), reverse=True)

        # C. Recreate (Greedy Best-Fit with Early Exit)
        for txn in removed_txns:
            base_cost = workload.get_opt_seq_cost(work_seq)
            best_pos = -1
            best_incr = float('inf')

            for pos in range(len(work_seq) + 1):
                work_seq.insert(pos, txn)
                c = workload.get_opt_seq_cost(work_seq)

                if c < best_incr:
                    best_incr = c
                    best_pos = pos

                del work_seq[pos]

                # Early Exit: Perfect packing (no cost increase)
                if abs(c - base_cost) < 1e-9:
                    break

            work_seq.insert(best_pos, txn)

        current_schedule = work_seq
        current_cost = workload.get_opt_seq_cost(work_seq)

        # Save if improved
        if current_cost < best_cost:
            best_cost = current_cost
            best_schedule = list(current_schedule)

        # D. Polish: Deterministic Iterative Improvement (Gap Repair)
        # Scan entire schedule, try to move each transaction to its optimal position.

        # Heuristic: Polish if we are near the best solution or randomly
        should_polish = (current_cost <= best_cost * 1.05) or (random.random() < 0.2)

        if should_polish and num_txns > 1:
            improved = True
            passes = 0
            # Increase passes for convergence
            MAX_PASSES = 3
            if num_txns < 50: MAX_PASSES = 5

            while improved and passes < MAX_PASSES:
                improved = False
                passes += 1

                # Check every transaction
                # Processing in LPT order (Big Rocks first) helps settle structure
                txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

                for txn in txns_to_check:
                    try:
                        current_idx = current_schedule.index(txn)
                    except ValueError: continue

                    # Cost without txn
                    del current_schedule[current_idx]

                    # Baseline cost without this transaction
                    base_val = workload.get_opt_seq_cost(current_schedule)

                    best_pos = -1
                    best_val = float('inf')

                    # Scan all positions
                    for pos in range(len(current_schedule) + 1):
                        current_schedule.insert(pos, txn)
                        c = workload.get_opt_seq_cost(current_schedule)

                        # Check improvement
                        if c < best_val:
                            best_val = c
                            best_pos = pos

                        del current_schedule[pos]

                        # Early Exit: Perfect hidden latency
                        if abs(c - base_val) < 1e-9:
                            best_pos = pos
                            best_val = c
                            break

                    # Re-insert at best position
                    current_schedule.insert(best_pos, txn)

                    # Update if improved
                    if best_val < current_cost - 1e-6:
                        current_cost = best_val
                        improved = True
                        if current_cost < best_cost:
                            best_cost = current_cost
                            best_schedule = list(current_schedule)
>>>>>>> REPLACE
</DIFF>