<NAME>
ILS_tail_ruin_and_lpt_strategies
</NAME>

<DESCRIPTION>
Implements three key improvements to the ILS refinement phase based on successful heuristics:
1.  **Tail Ruin Mode**: Adds a specific ruin mode that targets the end of the schedule (the last 25% of transactions). This directly attacks the critical path/makespan definition, allowing the algorithm to repack the often sparse tail of the schedule.
2.  **LPT Reinsertion**: In the 'Recreate' phase, removed transactions are now sorted by length (Longest Processing Time) before reinsertion. This standard bin-packing heuristic ensures that large, difficult-to-fit transactions are placed in the best available gaps first, before smaller transactions clutter the schedule.
3.  **LPT Polish**: In the 'Gap Repair' (Polish) phase, transactions are checked and moved in LPT order rather than schedule order. This prioritizes finding optimal homes for the most impactful transactions first.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # B. Multi-Mode Ruin
        work_seq = list(current_schedule)
        removed_txns = []

        r_mode = random.random()

        if r_mode < 0.4:
            # Mode 1: Single Large Block (Locality)
            bs = max(2, int(num_txns * 0.2))
            if len(work_seq) > bs:
                start = random.randint(0, len(work_seq) - bs)
                removed_txns = work_seq[start : start + bs]
                del work_seq[start : start + bs]

        elif r_mode < 0.8:
            # Mode 2: Two Disjoint Blocks (Global shuffle)
            total_rem = max(4, int(num_txns * 0.15))
            b1 = total_rem // 2
            b2 = total_rem - b1

            if len(work_seq) > b1:
                s1 = random.randint(0, len(work_seq) - b1)
                removed_txns.extend(work_seq[s1 : s1 + b1])
                del work_seq[s1 : s1 + b1]

            if len(work_seq) > b2:
                s2 = random.randint(0, len(work_seq) - b2)
                removed_txns.extend(work_seq[s2 : s2 + b2])
                del work_seq[s2 : s2 + b2]

        else:
            # Mode 3: Random Scatter (Dependency chains)
            cnt = max(3, int(num_txns * 0.1))
            indices = sorted(random.sample(range(len(work_seq)), min(len(work_seq), cnt)), reverse=True)
            for idx in indices:
                removed_txns.append(work_seq.pop(idx))

        random.shuffle(removed_txns)

        # C. Recreate (Greedy Best-Fit)
        for txn in removed_txns:
=======
        # B. Multi-Mode Ruin
        work_seq = list(current_schedule)
        removed_txns = []

        r_mode = random.random()

        if r_mode < 0.25:
            # Mode 1: Tail Ruin (Target critical path end)
            # The end of the schedule often has gaps; repacking it can reduce makespan directly.
            bs = max(4, int(num_txns * 0.25))
            if len(work_seq) > bs:
                start = len(work_seq) - bs
                removed_txns = work_seq[start:]
                del work_seq[start:]

        elif r_mode < 0.55:
            # Mode 2: Single Large Block (Locality)
            bs = max(2, int(num_txns * 0.2))
            if len(work_seq) > bs:
                start = random.randint(0, len(work_seq) - bs)
                removed_txns = work_seq[start : start + bs]
                del work_seq[start : start + bs]

        elif r_mode < 0.85:
            # Mode 3: Two Disjoint Blocks (Global shuffle)
            total_rem = max(4, int(num_txns * 0.20))
            b1 = total_rem // 2
            b2 = total_rem - b1

            if len(work_seq) > b1:
                s1 = random.randint(0, len(work_seq) - b1)
                removed_txns.extend(work_seq[s1 : s1 + b1])
                del work_seq[s1 : s1 + b1]
            if len(work_seq) > b2:
                s2 = random.randint(0, len(work_seq) - b2)
                removed_txns.extend(work_seq[s2 : s2 + b2])
                del work_seq[s2 : s2 + b2]

        else:
            # Mode 4: Random Scatter (Dependency chains)
            cnt = max(3, int(num_txns * 0.15))
            indices = sorted(random.sample(range(len(work_seq)), min(len(work_seq), cnt)), reverse=True)
            for idx in indices:
                removed_txns.append(work_seq.pop(idx))

        # Sort removed transactions by LPT (Longest Processing Time)
        # Placing difficult/long transactions first improves packing efficiency
        removed_txns.sort(key=lambda t: txn_lengths.get(t, 0), reverse=True)

        # C. Recreate (Greedy Best-Fit)
        for txn in removed_txns:
>>>>>>> REPLACE
<<<<<<< SEARCH
                # Check every transaction
                # Iterate over a snapshot so indices don't get messed up by moves
                txns_to_check = list(current_schedule)

                for txn in txns_to_check:
=======
                # Check every transaction
                # Iterate over a snapshot so indices don't get messed up by moves
                # Sort by LPT: Try to optimize placement of large blocks first
                txns_to_check = sorted(current_schedule, key=lambda t: txn_lengths.get(t, 0), reverse=True)

                for txn in txns_to_check:
>>>>>>> REPLACE
</DIFF>