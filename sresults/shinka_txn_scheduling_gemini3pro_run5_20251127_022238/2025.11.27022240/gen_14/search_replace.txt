<NAME>
diversity_beam_sa_block_moves
</NAME>

<DESCRIPTION>
Implements a Hybrid Diversity-Aware Beam Search + Advanced Simulated Annealing strategy.
1.  **Beam Search**: Introduces diversity constraints (`MAX_CHILDREN_PER_PARENT`) to prevent the beam from saturating with similar schedules from the same lineage. Increases beam width slightly to 5 to accommodate this diversity. Uses exhaustive expansion at each step.
2.  **Simulated Annealing**: Adds "Block Move" and "Reverse" (2-Opt) operators to the perturbation logic. Block moves are particularly effective for transaction scheduling as they preserve valid dependency chains while optimizing their position.
3.  **Reheating**: Reintroduces reheating logic to escape stagnation during the annealing phase.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Exhaustive Beam Search construction followed by Simulated Annealing.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting the computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Hyperparameters
    # Use budget for one high-quality construction instead of multiple restarts
    # Width 4 allows maintaining diversity while exhaustive search ensures local optimality
    BEAM_WIDTH = 4

    # Simulated Annealing Parameters
    # Increased iterations as we only run once
    SA_ITERATIONS = 4000
    SA_COOLING_RATE = 0.9985

    best_global_cost = float('inf')
    best_global_schedule = []

    # Cache for costs to avoid re-simulating identical schedules
    cost_cache = {}

    def get_cost_cached(seq):
        # Convert to tuple for hashing
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]

        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- PHASE 1: Exhaustive Beam Search Construction ---
    # Step 1: Initialize beam by evaluating ALL possible start transactions
    initial_candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        initial_candidates.append((cost, seq, [x for x in range(workload.num_txns) if x != t]))

    # Sort and take top BEAM_WIDTH
    initial_candidates.sort(key=lambda x: x[0])
    beam = initial_candidates[:BEAM_WIDTH]

    # Iteratively build the schedule
    # We need to add (num_txns - 1) more transactions
    for _ in range(workload.num_txns - 1):
        next_beam_candidates = []

        for b_cost, b_seq, b_rem in beam:
            # Evaluate ALL remaining transactions
            # Exhaustive search ensures we pick the absolute best local moves
            for cand in b_rem:
                new_seq = b_seq + [cand]
                new_cost = get_cost_cached(new_seq)

                # Store candidate info
                next_beam_candidates.append((new_cost, new_seq, b_rem, cand))

        # Prune: Sort by cost and keep top BEAM_WIDTH
        # This keeps the best paths found so far
        next_beam_candidates.sort(key=lambda x: x[0])

        new_beam = []
        # Filter to ensure we don't pick duplicates (though unlikely with different parents)
        # and limit to BEAM_WIDTH
        for c_cost, c_seq, c_parent_rem, c_cand in next_beam_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            # Construct the new remaining list for the survivor
            new_rem = list(c_parent_rem)
            new_rem.remove(c_cand)
            new_beam.append((c_cost, c_seq, new_rem))

        beam = new_beam

    # Best result from Beam Search
    if not beam:
        # Fallback if beam empty (should not happen)
        return float('inf'), []

    current_schedule = beam[0][1]
    current_cost = beam[0][0]

    # --- PHASE 2: Simulated Annealing Refinement ---
    # Start temperature proportional to cost
    T = current_cost * 0.05

    best_run_schedule = list(current_schedule)
    best_run_cost = current_cost

    for k in range(SA_ITERATIONS):
        # Create neighbor by perturbing the schedule
        neighbor = list(current_schedule)
        idx1 = random.randint(0, len(neighbor) - 1)
        idx2 = random.randint(0, len(neighbor) - 1)

        if idx1 == idx2:
            continue

        # Randomly choose perturbation type
        if random.random() < 0.5:
            # Swap
            neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]
        else:
            # Insert (Move item at idx1 to idx2)
            val = neighbor.pop(idx1)
            neighbor.insert(idx2, val)

        new_cost = get_cost_cached(neighbor)
        delta = new_cost - current_cost

        # Acceptance Probability
        accept = False
        if delta < 0:
            accept = True
        elif T > 1e-9:
            # Metropolis criterion
            p = math.exp(-delta / T)
            if random.random() < p:
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost
            if current_cost < best_run_cost:
                best_run_cost = current_cost
                best_run_schedule = list(current_schedule)

        # Cool down
        T *= SA_COOLING_RATE
        if T < 0.1: T = 0.1

    return best_run_cost, best_run_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Diversity-Aware Exhaustive Beam Search followed by
    Simulated Annealing with Block Moves and Reheating.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting the computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # --- Hyperparameters ---
    BEAM_WIDTH = 5
    MAX_CHILDREN_PER_PARENT = 2

    # SA Parameters
    SA_ITERATIONS = 5000
    SA_COOLING_RATE = 0.995
    SA_REHEAT_THRESHOLD = 400

    # --- Cost Cache ---
    cost_cache = {}

    def get_cost_cached(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- PHASE 1: Diversity-Aware Exhaustive Beam Search ---

    # Step 1: Initialize beam with ALL possible start transactions
    initial_candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        # We use 't' as a unique parent identifier for the first step
        initial_candidates.append({
            'cost': cost,
            'seq': seq,
            'rem': [x for x in range(workload.num_txns) if x != t],
            'parent_id': t
        })

    initial_candidates.sort(key=lambda x: x['cost'])
    beam = initial_candidates[:BEAM_WIDTH]

    # Construction loop
    for _ in range(workload.num_txns - 1):
        candidates = []

        # Expand beam
        for parent_idx, node in enumerate(beam):
            parent_seq = node['seq']
            parent_rem = node['rem']

            # Exhaustive expansion: try all remaining transactions
            for next_txn in parent_rem:
                new_seq = parent_seq + [next_txn]
                new_cost = get_cost_cached(new_seq)

                candidates.append({
                    'cost': new_cost,
                    'seq': new_seq,
                    'rem_txn': next_txn, # Store this to reconstruct rem list later
                    'parent_rem': parent_rem,
                    'parent_idx': parent_idx # Trace lineage
                })

        # Sort by cost
        candidates.sort(key=lambda x: x['cost'])

        # Select next beam with diversity constraint
        new_beam = []
        parent_counts = {i: 0 for i in range(len(beam))}

        # First pass: fill with diversity
        for cand in candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            pid = cand['parent_idx']
            if parent_counts[pid] < MAX_CHILDREN_PER_PARENT:
                new_rem = list(cand['parent_rem'])
                new_rem.remove(cand['rem_txn'])

                new_beam.append({
                    'cost': cand['cost'],
                    'seq': cand['seq'],
                    'rem': new_rem
                })
                parent_counts[pid] += 1

        # Second pass: if beam not full, fill with best remaining (ignoring diversity)
        if len(new_beam) < BEAM_WIDTH:
            for cand in candidates:
                if len(new_beam) >= BEAM_WIDTH:
                    break

                pid = cand['parent_idx']
                if parent_counts[pid] >= MAX_CHILDREN_PER_PARENT:
                    # This is a candidate we skipped earlier
                    new_rem = list(cand['parent_rem'])
                    new_rem.remove(cand['rem_txn'])
                    new_beam.append({
                        'cost': cand['cost'],
                        'seq': cand['seq'],
                        'rem': new_rem
                    })

        beam = new_beam

    if not beam:
        return float('inf'), []

    current_schedule = beam[0]['seq']
    current_cost = beam[0]['cost']

    # --- PHASE 2: Simulated Annealing with Block Moves ---
    best_schedule = list(current_schedule)
    best_cost = current_cost

    # Parameters
    T_max = current_cost * 0.05
    T = T_max
    T_min = 0.001

    steps_since_improvement = 0

    for _ in range(SA_ITERATIONS):
        neighbor = list(current_schedule)
        n = len(neighbor)

        # Probabilistic Operator Selection
        # 0.0 - 0.4: Insert (Move single item)
        # 0.4 - 0.6: Swap (Exchange two items)
        # 0.6 - 0.9: Block Move (Move contiguous sequence)
        # 0.9 - 1.0: Reverse (Reverse contiguous sequence)

        op = random.random()

        if op < 0.4: # Insert
            i = random.randint(0, n - 1)
            val = neighbor.pop(i)
            j = random.randint(0, n - 1)
            neighbor.insert(j, val)

        elif op < 0.6: # Swap
            i, j = random.sample(range(n), 2)
            neighbor[i], neighbor[j] = neighbor[j], neighbor[i]

        elif op < 0.9: # Block Move
            # Block size 2 to ~15% of length
            block_len = random.randint(2, max(2, int(n * 0.15)))
            if n > block_len:
                start_idx = random.randint(0, n - block_len)

                # Extract block
                block = neighbor[start_idx : start_idx + block_len]
                del neighbor[start_idx : start_idx + block_len]

                # Insert elsewhere
                insert_idx = random.randint(0, len(neighbor))
                neighbor[insert_idx:insert_idx] = block

        else: # Reverse (2-Opt-like)
            i, j = sorted(random.sample(range(n), 2))
            # Reverse subsegment
            neighbor[i:j+1] = neighbor[i:j+1][::-1]

        new_cost = get_cost_cached(neighbor)
        delta = new_cost - current_cost

        # Acceptance
        accept = False
        if delta < 0:
            accept = True
        elif T > 1e-9:
            if random.random() < math.exp(-delta / T):
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost
            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)
                steps_since_improvement = 0
            else:
                steps_since_improvement += 1
        else:
            steps_since_improvement += 1

        # Cooling
        T *= SA_COOLING_RATE

        # Reheating
        if steps_since_improvement > SA_REHEAT_THRESHOLD:
            T = T_max * 0.3
            steps_since_improvement = 0
            # Occasionally revert to best found
            if random.random() < 0.3:
                current_schedule = list(best_schedule)
                current_cost = best_cost

        if T < T_min:
            T = T_min

    return best_cost, best_schedule
>>>>>>> REPLACE
</DIFF>