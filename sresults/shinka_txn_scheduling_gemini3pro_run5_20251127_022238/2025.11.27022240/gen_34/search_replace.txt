<NAME>
ILS_MultiSegment_Adaptive
</NAME>

<DESCRIPTION>
Replaces the simple Simulated Annealing refinement phase with an Adaptive Simulated Annealing that incorporates a Multi-Segment Ruin-and-Recreate (Iterated Local Search) mechanism. When the search stagnates, this mechanism removes two disjoint blocks of transactions from the best found schedule and greedily re-inserts them, allowing for larger structural rearrangements to escape local optima. Additionally, it reintroduces adaptive operator weights to dynamically favor effective move types (insert, swap, block_move, reverse).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Exhaustive Beam Search and SA with Block Moves.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting the computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Hyperparameters
    # Width 5 provides good coverage without exploding computation
    BEAM_WIDTH = 5

    # Simulated Annealing Parameters
    # High iteration count as we only run one construction
    SA_ITERATIONS = 8000
    SA_COOLING_RATE = 0.999

    cost_cache = {}

    def get_cost_cached(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]

        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- PHASE 1: Exhaustive Beam Search Construction ---
    # Step 1: Initialize beam with all possible start transactions
    # This finds the best "headers" for the schedule
    candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        # Use set for easier handling, though list is fine too
        candidates.append((cost, seq, {x for x in range(workload.num_txns) if x != t}))

    candidates.sort(key=lambda x: x[0])
    beam = candidates[:BEAM_WIDTH]

    # Iteratively build the schedule
    for _ in range(workload.num_txns - 1):
        next_beam_candidates = []

        for b_cost, b_seq, b_rem in beam:
            # Exhaustive expansion: Try ALL remaining transactions
            # This is critical for finding the correct dependency ordering
            for cand in b_rem:
                new_seq = b_seq + [cand]
                new_cost = get_cost_cached(new_seq)
                next_beam_candidates.append((new_cost, new_seq, b_rem, cand))

        # Prune: Keep top BEAM_WIDTH
        # We sort by cost.
        next_beam_candidates.sort(key=lambda x: x[0])

        new_beam = []
        # Selection
        for c_cost, c_seq, c_parent_rem, c_cand in next_beam_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            # Create new remaining set
            new_rem = c_parent_rem.copy()
            new_rem.remove(c_cand)
            new_beam.append((c_cost, c_seq, new_rem))

        beam = new_beam

    # Best result from Beam Search
    if not beam:
        return float('inf'), []

    current_schedule = beam[0][1]
    current_cost = beam[0][0]

    # --- PHASE 2: Simulated Annealing with Block Moves ---
    # Start temperature
    T = current_cost * 0.05

    best_schedule = list(current_schedule)
    best_cost = current_cost

    for k in range(SA_ITERATIONS):
        neighbor = list(current_schedule)
        n = len(neighbor)

        r = random.random()

        if r < 0.4:
            # Insert Operator (Single item move) - 40%
            # Good for fine-tuning dependencies
            i = random.randint(0, n - 1)
            val = neighbor.pop(i)
            j = random.randint(0, n - 1)
            neighbor.insert(j, val)

        elif r < 0.7:
            # Swap Operator - 30%
            # Good for reordering locally
            i = random.randint(0, n - 1)
            j = random.randint(0, n - 1)
            if i != j:
                neighbor[i], neighbor[j] = neighbor[j], neighbor[i]

        else:
            # Block Move Operator - 30%
            # Moves a contiguous subsequence to a new location
            # Preserves local structures that are already optimized
            block_size = random.randint(2, 6)
            if n > block_size:
                i = random.randint(0, n - block_size)
                block = neighbor[i:i+block_size]
                del neighbor[i:i+block_size]

                # Insert elsewhere
                j = random.randint(0, len(neighbor))
                neighbor[j:j] = block

        new_cost = get_cost_cached(neighbor)
        delta = new_cost - current_cost

        accept = False
        if delta < 0:
            accept = True
        elif T > 1e-9:
            p = math.exp(-delta / T)
            if random.random() < p:
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost
            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)

        # Cooling
        T *= SA_COOLING_RATE
        # Reheat if stuck at bottom to escape local optima
        if T < 0.005:
            T = current_cost * 0.01

    return best_cost, best_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Exhaustive Beam Search followed by
    Adaptive Simulated Annealing with Multi-Segment Ruin-and-Recreate.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting the computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # --- Hyperparameters ---
    BEAM_WIDTH = 5

    # SA Parameters
    SA_ITERATIONS = 8000
    SA_COOLING_RATE = 0.999
    SA_START_TEMP_RATIO = 0.05

    # Ruin-and-Recreate Parameters
    STAGNATION_LIMIT = 500
    RUIN_BLOCK_SIZE_MIN = 2
    RUIN_BLOCK_SIZE_MAX = 5

    # Adaptive Operator Weights
    OP_WEIGHTS = {'swap': 2.0, 'insert': 8.0, 'block_move': 4.0, 'reverse': 1.0}
    OP_MIN_WEIGHT = 1.0
    OP_ADAPTATION_RATE = 0.1

    cost_cache = {}

    def get_cost_cached(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- PHASE 1: Exhaustive Beam Search Construction ---
    candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost_cached(seq)
        candidates.append((cost, seq, {x for x in range(workload.num_txns) if x != t}))

    candidates.sort(key=lambda x: x[0])
    beam = candidates[:BEAM_WIDTH]

    for _ in range(workload.num_txns - 1):
        next_beam_candidates = []
        for b_cost, b_seq, b_rem in beam:
            for cand in b_rem:
                new_seq = b_seq + [cand]
                new_cost = get_cost_cached(new_seq)
                next_beam_candidates.append((new_cost, new_seq, b_rem, cand))

        # Greedy sort
        next_beam_candidates.sort(key=lambda x: x[0])

        new_beam = []
        for c_cost, c_seq, c_parent_rem, c_cand in next_beam_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break
            new_rem = c_parent_rem.copy()
            new_rem.remove(c_cand)
            new_beam.append((c_cost, c_seq, new_rem))
        beam = new_beam

    if not beam:
        return float('inf'), []

    current_schedule = beam[0][1]
    current_cost = beam[0][0]

    # --- PHASE 2: Adaptive SA with Multi-Segment Ruin-and-Recreate ---
    best_schedule = list(current_schedule)
    best_cost = current_cost

    T = current_cost * SA_START_TEMP_RATIO
    ops = list(OP_WEIGHTS.keys())
    steps_since_imp = 0

    for k in range(SA_ITERATIONS):
        # 1. Ruin-and-Recreate (Kick) on Stagnation
        if steps_since_imp > STAGNATION_LIMIT:
            # Intensification: restart from best known
            kick_seq = list(best_schedule)
            removed_items = []

            # Multi-Segment Ruin: Remove 2 disjoint blocks
            # We do this by removing a block, then removing another from the remaining seq
            for _ in range(2):
                if len(kick_seq) > RUIN_BLOCK_SIZE_MIN:
                    sz = random.randint(RUIN_BLOCK_SIZE_MIN, min(len(kick_seq), RUIN_BLOCK_SIZE_MAX))
                    if len(kick_seq) > sz:
                        start = random.randint(0, len(kick_seq) - sz)
                        removed_items.extend(kick_seq[start : start + sz])
                        del kick_seq[start : start + sz]

            # Recreate: Greedy Best-Fit Insertion
            # Shuffling removed items prevents bias from original order
            random.shuffle(removed_items)

            for item in removed_items:
                best_pos = -1
                min_c = float('inf')

                # Check all positions
                for i in range(len(kick_seq) + 1):
                    kick_seq.insert(i, item)
                    c = get_cost_cached(kick_seq)
                    if c < min_c:
                        min_c = c
                        best_pos = i
                    kick_seq.pop(i)

                kick_seq.insert(best_pos, item)

            current_schedule = kick_seq
            current_cost = min_c

            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)
                steps_since_imp = 0
            else:
                steps_since_imp = 0 # Reset anyway to explore new neighborhood

            # Reset Temp slightly
            T = max(T, current_cost * 0.02)
            continue

        # 2. Operator Selection
        total_w = sum(OP_WEIGHTS.values())
        r = random.uniform(0, total_w)
        cum = 0
        op = ops[0]
        for o in ops:
            cum += OP_WEIGHTS[o]
            if r <= cum:
                op = o
                break

        neighbor = list(current_schedule)
        n = len(neighbor)

        if op == 'swap':
            i, j = random.sample(range(n), 2)
            neighbor[i], neighbor[j] = neighbor[j], neighbor[i]
        elif op == 'insert':
            i = random.randint(0, n - 1)
            val = neighbor.pop(i)
            j = random.randint(0, n - 1)
            neighbor.insert(j, val)
        elif op == 'reverse':
            i, j = sorted(random.sample(range(n), 2))
            neighbor[i:j+1] = neighbor[i:j+1][::-1]
        elif op == 'block_move':
            b_size = random.randint(2, 6)
            if n > b_size:
                i = random.randint(0, n - b_size)
                block = neighbor[i:i+b_size]
                del neighbor[i:i+b_size]
                j = random.randint(0, len(neighbor))
                neighbor[j:j] = block

        new_cost = get_cost_cached(neighbor)
        delta = new_cost - current_cost

        # 3. Acceptance
        accept = False
        if delta < 0:
            accept = True
            if new_cost < best_cost:
                best_cost = new_cost
                best_schedule = list(neighbor)
                steps_since_imp = 0
            else:
                steps_since_imp += 1
        else:
            steps_since_imp += 1
            if T > 1e-9 and random.random() < math.exp(-delta / T):
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost

        # 4. Adapt Weights
        reward = 0.1
        if delta < 0:
            reward = 1.0 if new_cost >= best_cost else 2.0

        OP_WEIGHTS[op] = (1 - OP_ADAPTATION_RATE) * OP_WEIGHTS[op] + OP_ADAPTATION_RATE * (OP_MIN_WEIGHT + reward)

        # 5. Cooling
        T *= SA_COOLING_RATE

    return best_cost, best_schedule
>>>>>>> REPLACE
</DIFF>