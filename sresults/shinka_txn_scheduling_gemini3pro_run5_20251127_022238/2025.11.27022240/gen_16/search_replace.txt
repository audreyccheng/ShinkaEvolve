<NAME>
enhanced_hybrid_beam_sa
</NAME>

<DESCRIPTION>
Improves the scheduling algorithm by enhancing both the constructive and refinement phases.
1. The Beam Search construction is strengthened by increasing the beam width and introducing diversity-aware pruning (selecting some candidates randomly from a pool rather than just the top scorers), preventing early convergence to local optima.
2. The Simulated Annealing refinement is upgraded with a "Block Move" operator, allowing the algorithm to move clusters of transactions together, which preserves beneficial local structures while optimizing global placement.
3. Tuning parameters (Gamma, Sample Size) are adjusted based on prior successful generations.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Hybrid Scheduling Algorithm:
    1. Constructive Phase: Beam Search with Work-Density scoring to build a high-quality initial schedule.
    2. Refinement Phase: Simulated Annealing to perform local search (swaps/inserts) on the constructed schedule.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Hint for computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """

    # --- 0. Helper & Precomputation ---
    num_txns = workload.num_txns

    # Extract transaction costs (lengths) for heuristics
    # Structure: workload.txns[i][0] is metadata, index 3 is usually length
    txn_lengths = {}
    for i in range(num_txns):
        try:
            txn_lengths[i] = workload.txns[i][0][3]
        except (IndexError, TypeError, AttributeError):
            txn_lengths[i] = 1.0

    # Sort indices by length descending (LPT - Longest Processing Time)
    lpt_sorted_indices = sorted(txn_lengths.keys(), key=lambda k: txn_lengths[k], reverse=True)

    # --- 1. Constructive Phase: Beam Search ---
    # Parameters
    # We use a narrower beam than pure beam search to save time for the annealing phase
    BEAM_WIDTH = 4
    SAMPLE_SIZE = 8       # Candidates to evaluate per expansion
    GAMMA = 1.5           # Work-density bias: favors schedules that complete "heavy" work early

    # Initial Beam Seeding
    # Start with a mix of longest transactions and random ones for diversity
    seeds = set(lpt_sorted_indices[:BEAM_WIDTH])
    if len(seeds) < BEAM_WIDTH:
        remaining_slots = BEAM_WIDTH - len(seeds)
        seeds.update(random.sample(range(num_txns), min(num_txns - len(seeds), remaining_slots)))

    beam = []
    for t in seeds:
        seq = [t]
        cost = workload.get_opt_seq_cost(seq)
        acc_work = txn_lengths[t]
        # Scoring Metric: Cost (Makespan) penalized by Work Done
        # Lower score is better. We subtract Work Done to "reward" progress.
        score = cost - (GAMMA * acc_work)

        remaining = set(range(num_txns))
        remaining.remove(t)

        beam.append({
            'seq': seq,
            'cost': cost,
            'score': score,
            'acc_work': acc_work,
            'rem': remaining
        })

    # Sort by score and trim to beam width
    beam.sort(key=lambda x: x['score'])
    beam = beam[:BEAM_WIDTH]

    # Construction Loop (Greedy Extension)
    for _ in range(num_txns - 1):
        candidates = []

        for parent in beam:
            rem_set = parent['rem']
            if not rem_set:
                continue

            # Candidate Selection: LPT + Random
            to_eval = set()

            # A) Add heuristic candidates (Longest remaining)
            added = 0
            for t in lpt_sorted_indices:
                if t in rem_set:
                    to_eval.add(t)
                    added += 1
                    if added >= (SAMPLE_SIZE // 2):
                        break

            # B) Add random candidates to maintain diversity
            needed = SAMPLE_SIZE - len(to_eval)
            rem_list = list(rem_set)
            if needed > 0 and rem_list:
                if len(rem_list) <= needed:
                    to_eval.update(rem_list)
                else:
                    to_eval.update(random.sample(rem_list, needed))

            # Evaluate candidates
            base_seq = parent['seq']
            base_work = parent['acc_work']

            for t in to_eval:
                new_seq = base_seq + [t]

                # Run simulation to get makespan
                new_cost = workload.get_opt_seq_cost(new_seq)

                new_work = base_work + txn_lengths[t]
                new_score = new_cost - (GAMMA * new_work)

                new_rem = rem_set.copy()
                new_rem.remove(t)

                candidates.append({
                    'seq': new_seq,
                    'cost': new_cost,
                    'score': new_score,
                    'acc_work': new_work,
                    'rem': new_rem
                })

        if not candidates:
            break

        # Beam Pruning: Sort by Work-Density Score
        candidates.sort(key=lambda x: x['score'])
        beam = candidates[:BEAM_WIDTH]

    # Select best result from construction phase based on actual Cost
    beam.sort(key=lambda x: x['cost'])
    best_candidate = beam[0]

    current_schedule = best_candidate['seq']
    current_cost = best_candidate['cost']

    # --- 2. Refinement Phase: Simulated Annealing ---
    # Attempt to improve the constructed schedule by local perturbation

    MAX_ITER = 600
    # Start temp relative to cost to allow some uphill moves initially
    INITIAL_TEMP = max(1.0, current_cost * 0.05)
    COOLING_RATE = 0.99

    best_schedule = list(current_schedule)
    best_cost = current_cost

    temp = INITIAL_TEMP

    for i in range(MAX_ITER):
        # Create neighbor
        neighbor = list(current_schedule)

        # Mutation Strategy: 50% Swap, 50% Insert (Block Move)
        mutation_type = random.random()
        idx1 = random.randint(0, num_txns - 1)

        if mutation_type < 0.5:
            # Swap two transactions
            idx2 = random.randint(0, num_txns - 1)
            while idx1 == idx2:
                idx2 = random.randint(0, num_txns - 1)
            neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]
        else:
            # Insert: Remove txn at idx1 and insert at idx2
            val = neighbor.pop(idx1)
            # Insert range is 0 to len(neighbor) inclusive (append)
            idx2 = random.randint(0, len(neighbor))
            neighbor.insert(idx2, val)

        # Evaluate neighbor
        neighbor_cost = workload.get_opt_seq_cost(neighbor)
        delta = neighbor_cost - current_cost

        # Metropolis Acceptance Criterion
        accept = False
        if delta < 0:
            accept = True
        else:
            # Probabilistic acceptance of worse solutions
            if temp > 0.001:
                prob = math.exp(-delta / temp)
                if random.random() < prob:
                    accept = True

        if accept:
            current_schedule = neighbor
            current_cost = neighbor_cost

            # Keep track of global best found
            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)

        # Cool down
        temp *= COOLING_RATE
        if temp < 0.001:
            break

    return best_cost, best_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Hybrid Scheduling Algorithm:
    1. Constructive Phase: Wide Beam Search with diversity pruning to build a robust initial schedule.
    2. Refinement Phase: Simulated Annealing with advanced operators (Block Moves) to optimize clusters.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Hint for computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """

    # --- 0. Helper & Precomputation ---
    num_txns = workload.num_txns

    # Extract transaction costs
    txn_lengths = {}
    for i in range(num_txns):
        try:
            txn_lengths[i] = workload.txns[i][0][3]
        except (IndexError, TypeError, AttributeError):
            txn_lengths[i] = 1.0

    lpt_sorted_indices = sorted(txn_lengths.keys(), key=lambda k: txn_lengths[k], reverse=True)

    # --- 1. Constructive Phase: Enhanced Beam Search ---
    # Increased beam width and sampling for better initial quality
    BEAM_WIDTH = max(8, int(num_seqs))
    SAMPLE_SIZE = 12
    GAMMA = 1.4

    # Initial Beam Seeding
    seeds = set(lpt_sorted_indices[:BEAM_WIDTH])
    if len(seeds) < BEAM_WIDTH:
        remaining_slots = BEAM_WIDTH - len(seeds)
        seeds.update(random.sample(range(num_txns), min(num_txns - len(seeds), remaining_slots)))

    beam = []
    for t in seeds:
        seq = [t]
        cost = workload.get_opt_seq_cost(seq)
        acc_work = txn_lengths[t]
        score = cost - (GAMMA * acc_work)

        remaining = set(range(num_txns))
        remaining.remove(t)

        beam.append({
            'seq': seq,
            'cost': cost,
            'score': score,
            'acc_work': acc_work,
            'rem': remaining
        })

    beam.sort(key=lambda x: x['score'])
    beam = beam[:BEAM_WIDTH]

    # Construction Loop
    for _ in range(num_txns - 1):
        candidates = []

        for parent in beam:
            rem_set = parent['rem']
            if not rem_set:
                continue

            to_eval = set()

            # A) Heuristic candidates
            added = 0
            for t in lpt_sorted_indices:
                if t in rem_set:
                    to_eval.add(t)
                    added += 1
                    if added >= 4: # Constant check of top remaining
                        break

            # B) Random candidates
            needed = SAMPLE_SIZE - len(to_eval)
            rem_list = list(rem_set)
            if needed > 0 and rem_list:
                if len(rem_list) <= needed:
                    to_eval.update(rem_list)
                else:
                    to_eval.update(random.sample(rem_list, needed))

            base_seq = parent['seq']
            base_work = parent['acc_work']

            for t in to_eval:
                new_seq = base_seq + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)
                new_work = base_work + txn_lengths[t]
                new_score = new_cost - (GAMMA * new_work)

                new_rem = rem_set.copy()
                new_rem.remove(t)

                candidates.append({
                    'seq': new_seq,
                    'cost': new_cost,
                    'score': new_score,
                    'acc_work': new_work,
                    'rem': new_rem
                })

        if not candidates:
            break

        # Diversity-Aware Pruning
        candidates.sort(key=lambda x: x['score'])

        k_best = int(BEAM_WIDTH * 0.7)
        next_beam = candidates[:k_best]

        remaining_needed = BEAM_WIDTH - len(next_beam)
        if remaining_needed > 0:
            # Sample from a wider pool of good candidates to maintain diversity
            pool_size = min(len(candidates), BEAM_WIDTH * 3)
            pool = candidates[k_best : pool_size]
            if len(pool) <= remaining_needed:
                next_beam.extend(pool)
            else:
                next_beam.extend(random.sample(pool, remaining_needed))

        beam = next_beam

    # Select best from construction
    beam.sort(key=lambda x: x['cost'])
    best_candidate = beam[0]

    current_schedule = best_candidate['seq']
    current_cost = best_candidate['cost']

    # --- 2. Refinement Phase: SA with Block Moves ---

    MAX_ITER = 750 # Slightly increased iterations
    INITIAL_TEMP = max(1.0, current_cost * 0.05)
    COOLING_RATE = 0.99

    best_schedule = list(current_schedule)
    best_cost = current_cost

    temp = INITIAL_TEMP

    for i in range(MAX_ITER):
        neighbor = list(current_schedule)
        r = random.random()

        if r < 0.35:
            # Swap
            idx1, idx2 = random.sample(range(num_txns), 2)
            neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]
        elif r < 0.7:
            # Insert (Single Move)
            idx1 = random.randint(0, num_txns - 1)
            val = neighbor.pop(idx1)
            idx2 = random.randint(0, num_txns - 1)
            neighbor.insert(idx2, val)
        else:
            # Block Move: Move a contiguous chunk
            if num_txns > 4:
                block_size = random.randint(2, max(3, num_txns // 8))
                start_idx = random.randint(0, num_txns - block_size)

                # Extract block
                block = neighbor[start_idx : start_idx + block_size]
                del neighbor[start_idx : start_idx + block_size]

                # Insert block
                insert_idx = random.randint(0, len(neighbor))
                neighbor[insert_idx:insert_idx] = block
            else:
                # Fallback for very small workloads
                idx1, idx2 = random.sample(range(num_txns), 2)
                neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]

        # Evaluate neighbor
        neighbor_cost = workload.get_opt_seq_cost(neighbor)
        delta = neighbor_cost - current_cost

        accept = False
        if delta < 0:
            accept = True
        elif temp > 0.001:
            prob = math.exp(-delta / temp)
            if random.random() < prob:
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = neighbor_cost
            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)

        temp *= COOLING_RATE
        if temp < 0.001:
            break

    return best_cost, best_schedule
>>>>>>> REPLACE
</DIFF>