<NAME>
ils_multi_segment_ruin
</NAME>

<DESCRIPTION>
Implement Iterated Local Search (ILS) with Multi-Segment Ruin-and-Recreate.
- Replaces the simple SA refinement with an ILS approach.
- The Ruin phase removes two disjoint random blocks of transactions.
- The Recreate phase re-inserts these transactions using a Greedy Best-Fit strategy (checking all positions).
- This allows the algorithm to overcome structural dependencies that simple swaps/inserts cannot resolve.
- Also integrates Adaptive Operator Selection during the local search phase.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Exhaustive Beam Search followed by Simulated Annealing with Reheating.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting computational budget (used to scale beam width)

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Hyperparameters
    # Beam width: scale with budget but keep manageable.
    # Exhaustive search at each beam step is expensive, so width is smaller than random sampling approaches.
    BEAM_WIDTH = max(4, int(num_seqs * 0.6))

    # SA Parameters
    SA_ITERATIONS = 5000
    SA_COOLING_RATE = 0.995
    SA_REHEAT_THRESHOLD = 300  # Iterations without improvement

    # Cost Cache
    cost_cache = {}

    def get_cost(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- Phase 1: Exhaustive Beam Search ---
    # Initialize beam with ALL transactions to find best starts
    beam = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost(seq)
        beam.append({
            'cost': cost,
            'seq': seq,
            'rem': set(range(workload.num_txns)) - {t}
        })

    # Prune to width
    beam.sort(key=lambda x: x['cost'])
    beam = beam[:BEAM_WIDTH]

    # Construction loop
    for _ in range(workload.num_txns - 1):
        candidates = []

        # Expand each beam node
        for node in beam:
            parent_seq = node['seq']
            parent_rem = node['rem']

            # Exhaustively evaluate all valid next transactions
            for t in parent_rem:
                new_seq = parent_seq + [t]
                cost = get_cost(new_seq)
                candidates.append((cost, new_seq, parent_rem, t))

        # Select best global candidates
        candidates.sort(key=lambda x: x[0])

        new_beam = []
        for cost, seq, parent_rem, t in candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            # Create new node
            new_rem = parent_rem.copy()
            new_rem.remove(t)
            new_beam.append({
                'cost': cost,
                'seq': seq,
                'rem': new_rem
            })

        beam = new_beam

    # Best schedule from construction
    if not beam:
        return float('inf'), []

    current_schedule = list(beam[0]['seq'])
    current_cost = beam[0]['cost']

    # --- Phase 2: Simulated Annealing with Reheating ---
    best_schedule = list(current_schedule)
    best_cost = current_cost

    # Initial temperature
    T_max = current_cost * 0.1
    T = T_max
    T_min = 0.001

    stagnant_steps = 0

    for _ in range(SA_ITERATIONS):
        # Generate neighbor
        neighbor = list(current_schedule)
        n = len(neighbor)

        op = random.random()
        idx1 = random.randint(0, n - 1)
        idx2 = random.randint(0, n - 1)

        if op < 0.4: # Swap
            neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]
        elif op < 0.8: # Insert
            if idx1 != idx2:
                val = neighbor.pop(idx1)
                neighbor.insert(idx2, val)
        else: # Reverse
            start, end = sorted((idx1, idx2))
            if start < end:
                neighbor[start:end+1] = neighbor[start:end+1][::-1]

        new_cost = get_cost(neighbor)
        delta = new_cost - current_cost

        # Acceptance
        accept = False
        if delta < 0:
            accept = True
        elif T > 1e-9:
            if random.random() < math.exp(-delta / T):
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost
            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)
                stagnant_steps = 0
            else:
                stagnant_steps += 1
        else:
            stagnant_steps += 1

        # Cooling
        T *= SA_COOLING_RATE

        # Reheating
        if stagnant_steps > SA_REHEAT_THRESHOLD or T < T_min:
            T = T_max * 0.5
            T_max *= 0.9 # Decay reheat ceiling
            stagnant_steps = 0
            # Occasionally jump back to best known to explore its neighborhood again
            if random.random() < 0.4:
                current_schedule = list(best_schedule)
                current_cost = best_cost

    return best_cost, best_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Exhaustive Beam Search followed by
    Adaptive Simulated Annealing with Multi-Segment Ruin-and-Recreate.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Parameter affecting computational budget

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # --- Hyperparameters ---
    BEAM_WIDTH = 4  # Focused beam for construction

    # SA / ILS Parameters
    SA_ITERATIONS = 5000
    SA_COOLING_RATE = 0.998
    SA_START_TEMP_RATIO = 0.05

    # Ruin-and-Recreate Parameters
    # Trigger ruin when search stagnates
    STAGNATION_LIMIT = 300
    RUIN_BLOCK_SIZE_MIN = 2
    RUIN_BLOCK_SIZE_MAX = 4

    # Adaptive Operator Weights
    # 'insert' and 'block_move' are structural operators, given higher initial weight
    OP_WEIGHTS = {'swap': 2.0, 'insert': 8.0, 'reverse': 1.0, 'block_move': 4.0}
    OP_MIN_WEIGHT = 1.0
    OP_ADAPTATION_RATE = 0.2

    # --- Cost Cache ---
    cost_cache = {}

    def get_cost(seq):
        t_seq = tuple(seq)
        if t_seq in cost_cache:
            return cost_cache[t_seq]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[t_seq] = c
        return c

    # --- Phase 1: Exhaustive Beam Search ---
    # Initialize beam
    candidates = []
    for t in range(workload.num_txns):
        seq = [t]
        cost = get_cost(seq)
        candidates.append({'cost': cost, 'seq': seq, 'rem': {x for x in range(workload.num_txns) if x != t}})

    candidates.sort(key=lambda x: x['cost'])
    beam = candidates[:BEAM_WIDTH]

    # Iteratively build schedule
    for _ in range(workload.num_txns - 1):
        next_candidates = []

        for node in beam:
            p_seq = node['seq']
            p_rem = node['rem']

            # Exhaustive expansion for quality
            for cand in p_rem:
                new_seq = p_seq + [cand]
                new_cost = get_cost(new_seq)
                next_candidates.append((new_cost, new_seq, p_rem, cand))

        # Sort by cost (Greedy)
        next_candidates.sort(key=lambda x: x[0])

        new_beam = []
        for c_cost, c_seq, c_parent_rem, c_cand in next_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            new_rem = c_parent_rem.copy()
            new_rem.remove(c_cand)
            new_beam.append({'cost': c_cost, 'seq': c_seq, 'rem': new_rem})

        beam = new_beam

    if not beam:
        return float('inf'), []

    current_schedule = beam[0]['seq']
    current_cost = beam[0]['cost']

    # --- Phase 2: Adaptive SA with Ruin-and-Recreate ---
    best_schedule = list(current_schedule)
    best_cost = current_cost

    T = current_cost * SA_START_TEMP_RATIO
    ops = list(OP_WEIGHTS.keys())

    steps_since_imp = 0

    for it in range(SA_ITERATIONS):
        # 1. Stagnation Check -> Ruin-and-Recreate (Kick)
        if steps_since_imp > STAGNATION_LIMIT:
            # Intensification: Start from best known
            kick_seq = list(best_schedule)
            removed_items = []

            # Multi-Segment Ruin: Remove 2 disjoint blocks
            for _ in range(2):
                if len(kick_seq) > RUIN_BLOCK_SIZE_MIN:
                    sz = random.randint(RUIN_BLOCK_SIZE_MIN, min(len(kick_seq), RUIN_BLOCK_SIZE_MAX))
                    # Pick random start
                    start = random.randint(0, len(kick_seq) - sz)
                    removed_items.extend(kick_seq[start : start + sz])
                    del kick_seq[start : start + sz]

            # Shuffle removed items to reduce bias
            random.shuffle(removed_items)

            # Recreate: Greedy Best-Fit Insertion
            # For each item, find optimal position in current partial schedule
            for item in removed_items:
                best_pos = -1
                min_c = float('inf')

                # Check all possible insertion points
                for i in range(len(kick_seq) + 1):
                    kick_seq.insert(i, item)
                    c = get_cost(kick_seq)
                    if c < min_c:
                        min_c = c
                        best_pos = i
                    kick_seq.pop(i)

                # Insert at best found position
                kick_seq.insert(best_pos, item)

            # Update current state
            current_schedule = kick_seq
            current_cost = min_c

            # Check global improvement
            if current_cost < best_cost:
                best_cost = current_cost
                best_schedule = list(current_schedule)
                steps_since_imp = 0
            else:
                steps_since_imp = 0 # Reset counter

            # Reheat slightly
            T = max(T, current_cost * 0.02)
            continue

        # 2. Select Operator (Adaptive)
        total_w = sum(OP_WEIGHTS.values())
        r = random.uniform(0, total_w)
        cum = 0
        op = ops[0]
        for o in ops:
            cum += OP_WEIGHTS[o]
            if r <= cum:
                op = o
                break

        neighbor = list(current_schedule)
        n = len(neighbor)

        if op == 'swap':
            i, j = random.sample(range(n), 2)
            neighbor[i], neighbor[j] = neighbor[j], neighbor[i]
        elif op == 'insert':
            i = random.randint(0, n - 1)
            val = neighbor.pop(i)
            j = random.randint(0, n - 1)
            neighbor.insert(j, val)
        elif op == 'reverse':
            i, j = sorted(random.sample(range(n), 2))
            neighbor[i:j+1] = neighbor[i:j+1][::-1]
        elif op == 'block_move':
            b_size = random.randint(2, 6)
            if n > b_size:
                i = random.randint(0, n - b_size)
                block = neighbor[i:i+b_size]
                del neighbor[i:i+b_size]
                j = random.randint(0, len(neighbor))
                neighbor[j:j] = block

        new_cost = get_cost(neighbor)
        delta = new_cost - current_cost

        # 3. Acceptance Criteria
        accept = False
        if delta < 0:
            accept = True
            if new_cost < best_cost:
                best_cost = new_cost
                best_schedule = list(neighbor)
                steps_since_imp = 0
            else:
                steps_since_imp += 1
        else:
            steps_since_imp += 1
            if T > 1e-9 and random.random() < math.exp(-delta / T):
                accept = True

        if accept:
            current_schedule = neighbor
            current_cost = new_cost

        # 4. Adapt Operator Weights
        reward = 0.1
        if delta < 0:
            # Higher reward for finding a new global best
            reward = 2.0 if new_cost < best_cost else 1.0

        OP_WEIGHTS[op] = (1 - OP_ADAPTATION_RATE) * OP_WEIGHTS[op] + OP_ADAPTATION_RATE * (OP_MIN_WEIGHT + reward)

        # 5. Cooling
        T *= SA_COOLING_RATE

    return best_cost, best_schedule
>>>>>>> REPLACE
</DIFF>