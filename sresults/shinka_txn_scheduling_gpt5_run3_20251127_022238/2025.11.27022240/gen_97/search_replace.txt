<prefix_dominance_mcts_lns>
Introduce prefix-dominance pruning shared across MCTS and greedy rollout, integrate LB/dominance filtering into candidate generation and expansion, and add conflict-targeted 2.5-opt moves to local search. This reduces exploration of dominated prefixes and focuses refinement on worst conflicts, yielding lower makespan within the same time budget.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    buddies = build_buddies(max_buddies=8)
=======
    buddies = build_buddies(max_buddies=8)

    # Shared prefix-dominance map to prune equivalent states across MCTS
    # Keyed by (frozenset(remaining), suffix of last k txns) -> best known prefix cost
    prefix_dom = {}
    def dom_sig(rem_set, seq, k):
        if k <= 0:
            return (frozenset(rem_set), ())
        tail = tuple(seq[-k:]) if len(seq) >= k else tuple(seq)
        return (frozenset(rem_set), tail)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def make_candidates(prefix, rem, k_base=14):
        # Build a ranked candidate pool without scanning full rem
        rem_list = list(rem)
        if not rem_list:
            return []
        pool = []
        if prefix:
            last = prefix[-1]
            pool.extend([u for u in buddies.get(last, []) if u in rem])
        # add top low-singleton from rem
        low_single = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(6, len(rem_list))]
        for u in low_single:
            if u not in pool:
                pool.append(u)
        # add random for diversity
        need = max(0, 2 * k_base - len(pool))
        if need > 0:
            others = [x for x in rem_list if x not in pool]
            if others:
                pool.extend(rng.sample(others, min(need, len(others))))
        if not pool:
            return []

        # Rank by immediate extension and shallow lookahead with anti-buddy gating
        pt = tuple(prefix)
        last = prefix[-1] if prefix else None
        tmp = []
        best_immediate = float('inf')
        for u in pool:
            ec = eval_ext_cost(pt, u)
            tmp.append((ec, u))
            if ec < best_immediate:
                best_immediate = ec

        tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
        scored = []
        for ec, u in tmp:
            # incumbent pruning on immediate extension
            if ec >= incumbent_cost:
                continue
            if last is not None and is_antibuddy(last, u) and ec > tol:
                continue
            # shallow lookahead: try a few buddies of u or random next
            la_best = ec
            new_rem = set(rem)
            if u in new_rem:
                new_rem.remove(u)
            la_pool = [v for v in buddies.get(u, []) if v in new_rem]
            if not la_pool:
                la_pool = list(new_rem)
            if len(la_pool) > 4:
                la_pool = rng.sample(la_pool, 4)
            new_pt = tuple(list(prefix) + [u])
            for nxt in la_pool:
                c2 = eval_ext_cost(new_pt, nxt)
                if c2 < la_best:
                    la_best = c2
            scored.append((ec, la_best, u))

        if not scored:
            # fallback to original pool order if all pruned
            scored = [(ec, ec, u) for ec, u in tmp]

        scored.sort(key=lambda x: (x[0], x[1]))
        ranked = [u for _ec, _la, u in scored]
        # trim to k_base*2 for widening use
        return ranked[:min(len(ranked), 2 * k_base)]
=======
    def make_candidates(prefix, rem, k_base=14):
        # Build a ranked candidate pool without scanning full rem
        rem_list = list(rem)
        if not rem_list:
            return []
        pool = []
        if prefix:
            last = prefix[-1]
            pool.extend([u for u in buddies.get(last, []) if u in rem])
        # add top low-singleton from rem
        low_single = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(6, len(rem_list))]
        for u in low_single:
            if u not in pool:
                pool.append(u)
        # add random for diversity
        need = max(0, 2 * k_base - len(pool))
        if need > 0:
            others = [x for x in rem_list if x not in pool]
            if others:
                pool.extend(rng.sample(others, min(need, len(others))))
        if not pool:
            return []

        # Rank by immediate extension and shallow lookahead with anti-buddy gating
        pt = tuple(prefix)
        last = prefix[-1] if prefix else None
        tmp = []
        best_immediate = float('inf')
        for u in pool:
            ec = eval_ext_cost(pt, u)
            tmp.append((ec, u))
            if ec < best_immediate:
                best_immediate = ec

        tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
        scored = []
        for ec, u in tmp:
            # incumbent pruning on immediate extension
            if ec >= incumbent_cost:
                continue
            if last is not None and is_antibuddy(last, u) and ec > tol:
                continue
            # LB and prefix-dominance pruning on child state
            new_rem = set(rem)
            if u in new_rem:
                new_rem.remove(u)
            if lb_singleton(ec, new_rem) >= incumbent_cost:
                continue
            sig_child = dom_sig(new_rem, list(prefix) + [u], 3)
            prev = prefix_dom.get(sig_child)
            if prev is not None and ec >= prev:
                continue
            # shallow lookahead: try a few buddies of u or random next
            la_best = ec
            la_pool = [v for v in buddies.get(u, []) if v in new_rem]
            if not la_pool:
                la_pool = list(new_rem)
            if len(la_pool) > 4:
                la_pool = rng.sample(la_pool, 4)
            new_pt = tuple(list(prefix) + [u])
            for nxt in la_pool:
                c2 = eval_ext_cost(new_pt, nxt)
                if c2 < la_best:
                    la_best = c2
            # Update dominance with the child prefix cost
            if prev is None or ec < prev:
                prefix_dom[sig_child] = ec
            scored.append((ec, la_best, u))

        if not scored:
            # fallback to original pool order if all pruned
            scored = [(ec, ec, u) for ec, u in tmp]

        scored.sort(key=lambda x: (x[0], x[1]))
        ranked = [u for _ec, _la, u in scored]
        # trim to k_base*2 for widening use
        return ranked[:min(len(ranked), 2 * k_base)]
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        while True:
            # Terminate at full sequence
            if not rem:
                break
            # Progressive widening
            limit = progressive_widen_limit(node.visits, alpha=0.5, base=1)
            # Expand if we can and there are untried candidates
            if len(node.children) < limit and node.untried:
                # Expand: pick the best untried by ext cost
                cand = node.untried.pop(0)
                # Create child
                new_prefix = prefix + [cand]
                new_rem = rem.copy()
                new_rem.remove(cand)
                child = get_node(new_prefix, new_rem)
                node.children[cand] = child
                path.append(node)
                node = child
                prefix = new_prefix
                rem = new_rem
                break  # move to simulation
            else:
                # Select child by UCB
                if not node.children:
                    break
                best_child = None
                best_val = -float('inf')
                for cand, child in node.children.items():
                    val = ucb_value(node.visits, child)
                    if val > best_val:
                        best_val = val
                        best_child = (cand, child)
                cand, child = best_child
                path.append(node)
                # Advance
                prefix = prefix + [cand]
                rem = rem - {cand}
                node = child

            # Safety time check
            if not time_left():
                break
=======
        while True:
            # Terminate at full sequence
            if not rem:
                break
            # Progressive widening
            limit = progressive_widen_limit(node.visits, alpha=0.5, base=1)
            # Expand if we can and there are untried candidates
            if len(node.children) < limit and node.untried:
                expanded = False
                # Try untried candidates in order, skipping dominated/LB-pruned children
                while node.untried and not expanded:
                    cand = node.untried.pop(0)
                    new_prefix = prefix + [cand]
                    new_rem = rem.copy()
                    new_rem.remove(cand)
                    ec = eval_seq_cost(new_prefix)
                    # Prefix-dominance and LB pruning on child
                    sig_child = dom_sig(new_rem, new_prefix, 3)
                    prev = prefix_dom.get(sig_child)
                    if prev is not None and ec >= prev:
                        continue
                    if lb_singleton(ec, new_rem) >= incumbent_cost:
                        continue
                    # Update dominance
                    if prev is None or ec < prev:
                        prefix_dom[sig_child] = ec
                    # Create child
                    child = get_node(new_prefix, new_rem)
                    node.children[cand] = child
                    path.append(node)
                    node = child
                    prefix = new_prefix
                    rem = new_rem
                    expanded = True
                if expanded:
                    break  # move to simulation
                # If nothing could be expanded, fall through to selection among existing children
            # Select child by UCB
            if not node.children:
                break
            best_child = None
            best_val = -float('inf')
            for cand, child in node.children.items():
                val = ucb_value(node.visits, child)
                if val > best_val:
                    best_val = val
                    best_child = (cand, child)
            cand, child = best_child
            path.append(node)
            # Advance
            prefix = prefix + [cand]
            rem = rem - {cand}
            node = child

            # Safety time check
            if not time_left():
                break
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        while rem and time_left():
            if incumbent is not None and lb_singleton(cur_cost, rem) >= incumbent:
                # Abort rollout if it's already worse than incumbent
                break
            last = seq_out[-1] if seq_out else None
            rem_list = list(rem)
=======
        while rem and time_left():
            if incumbent is not None and lb_singleton(cur_cost, rem) >= incumbent:
                # Abort rollout if it's already worse than incumbent
                break
            # Prefix-dominance update and prune for rollout state
            ds = dom_sig(rem, seq_out, 3)
            prevd = prefix_dom.get(ds)
            if prevd is not None and cur_cost >= prevd:
                break
            if prevd is None or cur_cost < prevd:
                prefix_dom[ds] = cur_cost

            last = seq_out[-1] if seq_out else None
            rem_list = list(rem)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        # Limited non-adjacent swap (2-opt style without reversal), gated by surrogate
        swap_tries = 60
        while swap_tries > 0 and time_left():
            swap_tries -= 1
            i = rng.randrange(0, n - 2)
            j = rng.randrange(i + 2, n)
            # Surrogate gating: only attempt if both boundaries are weak
            bad_i = pair_pref(best_seq[i], best_seq[i + 1]) > 0
            bad_j = pair_pref(best_seq[j - 1], best_seq[j]) > 0 if j < n else True
            if not (bad_i or bad_j):
                if rng.random() < 0.6:
                    continue
            cand = best_seq[:]
            cand[i], cand[j] = cand[j], cand[i]
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        return best_cost, best_seq
=======
        # Limited non-adjacent swap (2-opt style without reversal), gated by surrogate
        swap_tries = 60
        while swap_tries > 0 and time_left():
            swap_tries -= 1
            i = rng.randrange(0, n - 2)
            j = rng.randrange(i + 2, n)
            # Surrogate gating: only attempt if both boundaries are weak
            bad_i = pair_pref(best_seq[i], best_seq[i + 1]) > 0
            bad_j = pair_pref(best_seq[j - 1], best_seq[j]) > 0 if j < n else True
            if not (bad_i or bad_j):
                if rng.random() < 0.6:
                    continue
            cand = best_seq[:]
            cand[i], cand[j] = cand[j], cand[i]
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                n = len(best_seq)

        # Conflict-targeted 2.5-opt sampling around worst adjacencies
        if time_left() and n >= 6:
            viols = []
            for i in range(n - 1):
                viols.append((pair_pref(best_seq[i], best_seq[i + 1]), i))
            viols.sort(reverse=True, key=lambda x: x[0])
            cap = min(20, max(4, n // 8))
            cands = []
            for v, i in viols[:cap]:
                # pick j relatively far for diversity
                j = rng.randrange(0, n - 1)
                if abs(j - i) <= 2:
                    continue
                cands.append((v, i, j))
            if cands:
                cands.sort(reverse=True, key=lambda x: x[0])
                eval_list = cands[:max(1, int(0.4 * len(cands)))]
                # add 10% random
                extra = max(1, len(cands) // 10)
                for _ in range(extra):
                    eval_list.append(rng.choice(cands))
                budget = 60
                tried = 0
                for _v, i, j in eval_list:
                    if tried >= budget or not time_left():
                        break
                    # 2-opt style swap endpoints
                    cand = best_seq[:]
                    cand[i], cand[j] = cand[j], cand[i]
                    c = eval_seq_cost(cand); tried += 1
                    if c < best_cost:
                        best_cost, best_seq = c, cand
                        n = len(best_seq)
                        continue
                    if tried >= budget or not time_left():
                        break
                    # 2.5-opt: move small block around boundary after i before i
                    s = min(4, max(3, n // 40))
                    b_start = max(0, min(i + 1, n - s))
                    block = best_seq[b_start:b_start + s]
                    remain = best_seq[:b_start] + best_seq[b_start + s:]
                    pos = max(0, min(i, len(remain)))
                    cand2 = remain[:]
                    blk = block if rng.random() < 0.5 else block[::-1]
                    for off, x in enumerate(blk):
                        cand2.insert(pos + off, x)
                    c2 = eval_seq_cost(cand2); tried += 1
                    if c2 < best_cost:
                        best_cost, best_seq = c2, cand2
                        n = len(best_seq)

        return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>