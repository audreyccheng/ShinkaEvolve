<NAME>
pair_seeded_beam_with_depth_adaptive_antibuddy_and_child_dom
</NAME>

<DESCRIPTION>
I introduce four targeted improvements to reduce makespan:

1) Pair-seeded beam starts: In addition to singleton seeds, we now generate a compact set of strong pair seeds from the best singletons. Evaluating a few [a,b] starts captures key early-conflict structure and often leads the beam search into better regions.

2) Early greedy baseline incumbent: Before any restart, we compute a fast greedy completion from an empty prefix to establish a strong global incumbent. This tightens pruning throughout the beam expansions and speeds convergence.

3) Depth-adaptive anti-buddy gating: Both in the greedy finisher and the beam expansion, the anti-buddy filter’s tolerance scales with depth (early: more lenient; late: stricter). This reduces exploration of known-bad adjacencies without prematurely pruning promising early paths.

4) Child-level prefix-dominance and promotion: For each expanded child, we check and update prefix-dominance (both local and global) using the child’s extension cost and, when probed, the child’s greedy completion cost. We also prune children dominated by existing records. This unifies and strengthens dominance pruning and promotes better incumbents early at child expansion.

These changes keep runtime bounded while focusing expansions where the simulator’s true cost indicates higher payoff. The pair seeds, early incumbent, and stronger child pruning typically lead to lower makespan schedules in transactional workloads with read/write conflicts.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
            # Anti-buddy filtering: skip strongly disfavored unless within 1% of best
            filtered = []
            last_txn = seq_out[-1] if seq_out else None
            tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
            for c, t in scored:
                if is_antibuddy(last_txn, t) and c > tol:
                    continue
                filtered.append((c, t))
=======
            # Anti-buddy filtering: depth-adaptive tolerance (more lenient early, stricter late)
            filtered = []
            last_txn = seq_out[-1] if seq_out else None
            depth_ratio = (len(seq_out) / max(1, N))
            if depth_ratio < 0.33:
                tol_factor = 1.012
            elif depth_ratio < 0.66:
                tol_factor = 1.008
            else:
                tol_factor = 1.004
            tol = best_immediate * tol_factor if best_immediate < float('inf') else float('inf')
            for c, t in scored:
                if is_antibuddy(last_txn, t) and c > tol:
                    continue
                filtered.append((c, t))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        # Seed: best singletons by cost
        seeds = sorted(all_txns_local, key=lambda t: singleton_cost.get(t, float('inf')))
        seeds = seeds[:max(beam_width * 2, 8)]
        beam = []
        for t in seeds:
            if not time_left():
                break
            seq = [t]
            rem = set(all_txns_local)
            rem.remove(t)
            c = eval_seq_cost(seq)
            beam.append((c, seq, rem))
        if not beam:
            seq = all_txns_local[:]
            rng.shuffle(seq)
            return eval_seq_cost(seq), seq, incumbent_cost, None
=======
        # Seed: best singletons by cost + a few strong pairs
        seeds = sorted(all_txns_local, key=lambda t: singleton_cost.get(t, float('inf')))
        seeds = seeds[:max(beam_width * 2, 8)]
        beam = []
        for t in seeds:
            if not time_left():
                break
            seq = [t]
            rem = set(all_txns_local)
            rem.remove(t)
            c = eval_seq_cost(seq)
            beam.append((c, seq, rem))
        # Add pair seeds from top singletons to capture early conflicts
        if time_left() and len(seeds) >= 2:
            pair_candidates = seeds[:min(12, len(seeds))]
            pair_evals = []
            for i in range(len(pair_candidates)):
                if not time_left():
                    break
                a = pair_candidates[i]
                for j in range(i + 1, len(pair_candidates)):
                    if not time_left():
                        break
                    b = pair_candidates[j]
                    c2 = eval_seq_cost([a, b])
                    pair_evals.append((c2, [a, b]))
                    c3 = eval_seq_cost([b, a])
                    pair_evals.append((c3, [b, a]))
            pair_evals.sort(key=lambda x: x[0])
            for c2, pseq in pair_evals[:min(beam_width, len(pair_evals))]:
                rem = set(all_txns_local)
                for x in pseq:
                    if x in rem:
                        rem.remove(x)
                beam.append((c2, pseq, rem))
        if not beam:
            seq = all_txns_local[:]
            rng.shuffle(seq)
            return eval_seq_cost(seq), seq, incumbent_cost, None
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                # Second pass: anti-buddy filter and lookahead
                scored = []
                tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
                for ec, cand in tmp:
                    if ec >= best_full_cost:
                        continue
                    if is_antibuddy(last, cand) and ec > tol:
                        continue
                    # shallow lookahead: prefer buddy-next of cand first
                    la_best = ec
                    if rem and time_left():
                        new_rem = rem.copy()
                        if cand in new_rem:
                            new_rem.remove(cand)
                        la_pool = []
                        if cand in buddies:
                            for v in buddies[cand]:
                                if v in new_rem:
                                    la_pool.append(v)
                        if not la_pool:
                            la_pool = list(new_rem)
                        # sample top 'lookahead_top'
                        if len(la_pool) > lookahead_top:
                            la_pool = rng.sample(la_pool, lookahead_top)
                        new_prefix_tuple = tuple(seq + [cand])
                        for nxt in la_pool:
                            c2 = eval_ext_cost(new_prefix_tuple, nxt)
                            if c2 < la_best:
                                la_best = c2
                    scored.append((ec - cost_so_far, la_best, ec, cand))
=======
                # Second pass: anti-buddy filter and lookahead (depth-adaptive tolerance)
                scored = []
                depth_ratio = (len(seq) / max(1, N))
                if depth_ratio < 0.33:
                    tol_factor = 1.012
                elif depth_ratio < 0.66:
                    tol_factor = 1.008
                else:
                    tol_factor = 1.004
                tol = best_immediate * tol_factor if best_immediate < float('inf') else float('inf')
                for ec, cand in tmp:
                    if ec >= best_full_cost:
                        continue
                    if is_antibuddy(last, cand) and ec > tol:
                        continue
                    # shallow lookahead: prefer buddy-next of cand first
                    la_best = ec
                    if rem and time_left():
                        new_rem = rem.copy()
                        if cand in new_rem:
                            new_rem.remove(cand)
                        la_pool = []
                        if cand in buddies:
                            for v in buddies[cand]:
                                if v in new_rem:
                                    la_pool.append(v)
                        if not la_pool:
                            la_pool = list(new_rem)
                        # sample top 'lookahead_top'
                        if len(la_pool) > lookahead_top:
                            la_pool = rng.sample(la_pool, lookahead_top)
                        new_prefix_tuple = tuple(seq + [cand])
                        for nxt in la_pool:
                            c2 = eval_ext_cost(new_prefix_tuple, nxt)
                            if c2 < la_best:
                                la_best = c2
                    scored.append((ec - cost_so_far, la_best, ec, cand))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                # Probe a few best children by greedily completing them to tighten incumbent
                probe_k = min(params.get('next_k', 4), len(top))
                idx_child = 0
                for _delta, la_score, ec, cand in top:
                    new_seq = seq + [cand]
                    new_rem = rem.copy()
                    new_rem.remove(cand)
                    # Child LB pruning
                    if lb_singleton(ec, new_rem) >= best_full_cost:
                        continue
                    # Greedy probe for first few children to update incumbent and refine ranking
                    if idx_child < probe_k and time_left():
                        g_cost, g_seq = greedy_finish(new_seq, new_rem, branch_k=max(6, N // 12), incumbent=best_full_cost)
                        if len(g_seq) == N and g_cost < best_full_cost:
                            best_full_cost, best_full_seq = g_cost, g_seq
                        la_score = min(la_score, g_cost)
                    idx_child += 1
                    # Prune child if its adjusted lookahead is not better than the incumbent
                    if la_score >= best_full_cost:
                        continue
                    new_beam.append((ec, new_seq, new_rem, la_score))
=======
                # Probe a few best children by greedily completing them to tighten incumbent
                probe_k = min(params.get('next_k', 4), len(top))
                idx_child = 0
                for _delta, la_score, ec, cand in top:
                    new_seq = seq + [cand]
                    new_rem = rem.copy()
                    new_rem.remove(cand)
                    # Child signature dominance check before expensive probes
                    sig_child = make_signature(new_rem, new_seq, k_cur)
                    prev_local_c = best_state.get(sig_child)
                    if prev_local_c is not None and ec >= prev_local_c:
                        continue
                    prev_global_c = best_state_global.get(sig_child)
                    if prev_global_c is not None and ec >= prev_global_c:
                        continue
                    # Update dominance with child's extension cost
                    best_state[sig_child] = ec if prev_local_c is None else min(prev_local_c, ec)
                    cur_best = best_state_global.get(sig_child)
                    if cur_best is None or ec < cur_best:
                        best_state_global[sig_child] = ec
                    # Child LB pruning
                    if lb_singleton(ec, new_rem) >= best_full_cost:
                        continue
                    # Greedy probe for first few children to update incumbent and refine ranking
                    if idx_child < probe_k and time_left():
                        g_cost, g_seq = greedy_finish(new_seq, new_rem, branch_k=max(6, N // 12), incumbent=best_full_cost)
                        if len(g_seq) == N and g_cost < best_full_cost:
                            best_full_cost, best_full_seq = g_cost, g_seq
                        # Strengthen dominance with probe result
                        prev_local_probe = best_state.get(sig_child)
                        if prev_local_probe is None or g_cost < prev_local_probe:
                            best_state[sig_child] = g_cost
                        prev_global_probe = best_state_global.get(sig_child)
                        if prev_global_probe is None or g_cost < prev_global_probe:
                            best_state_global[sig_child] = g_cost
                        la_score = min(la_score, g_cost)
                    idx_child += 1
                    # Prune child if its adjusted lookahead is not better than the incumbent
                    if la_score >= best_full_cost:
                        continue
                    new_beam.append((ec, new_seq, new_rem, la_score))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    global_best_cost = float('inf')
    global_best_seq = None

    max_restarts = max(2, min(len(portfolios), int(num_seqs)))
    for r in range(max_restarts):
=======
    global_best_cost = float('inf')
    global_best_seq = None

    # Early greedy baseline from empty prefix to tighten incumbent and pruning
    if time_left():
        c0, s0 = greedy_finish([], set(all_txns), branch_k=max(10, N // 8), incumbent=float('inf'))
        if c0 < global_best_cost:
            global_best_cost, global_best_seq = c0, s0

    max_restarts = max(2, min(len(portfolios), int(num_seqs)))
    for r in range(max_restarts):
>>>>>>> REPLACE

</DIFF>