<NAME>
beam_memo_local_refine
</NAME>

<DESCRIPTION>
I replace the purely greedy, random-sampled construction with a memoized, beam-guided construction plus a short local refinement. The new get_best_schedule uses:

- Prefix cost memoization and extension cache to drastically reduce repeated simulator calls.
- A modest beam search guided by marginal cost and a one-step lookahead to pick promising prefixes without exploding runtime.
- Greedy completion from the best prefixes to tighten an incumbent quickly and prune weaker branches implicitly.
- A lightweight local search (adjacent swaps and a few insertions) to fix residual high-impact conflicts cheaply.
- Multiple restarts under a small time budget per workload for robustness.

This yields schedules with significantly lower makespan by evaluating real prefix costs rather than relying on heuristics like transaction length or random picks, while keeping runtime competitive thanks to caching and bounded branching.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using greedy cost sampling strategy.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    def get_greedy_cost_sampled(num_samples, sample_rate):
        # greedy with random starting point
        start_txn = random.randint(0, workload.num_txns - 1)
        txn_seq = [start_txn]
        remaining_txns = [x for x in range(0, workload.num_txns)]
        remaining_txns.remove(start_txn)
        running_cost = workload.txns[start_txn][0][3]

        for i in range(0, workload.num_txns - 1):
            min_cost = 100000  # MAX
            min_relative_cost = 10
            min_txn = -1
            holdout_txns = []
            done = False
            key_maps = []

            sample = random.random()
            if sample > sample_rate:
                idx = random.randint(0, len(remaining_txns) - 1)
                t = remaining_txns[idx]
                txn_seq.append(t)
                remaining_txns.pop(idx)
                continue

            for j in range(0, num_samples):
                idx = 0
                if len(remaining_txns) > 1:
                    idx = random.randint(0, len(remaining_txns) - 1)
                else:
                    done = True
                t = remaining_txns[idx]
                holdout_txns.append(remaining_txns.pop(idx))

                txn_len = workload.txns[t][0][3]
                test_seq = txn_seq.copy()
                test_seq.append(t)
                cost = 0
                cost = workload.get_opt_seq_cost(test_seq)
                if cost < min_cost:
                    min_cost = cost
                    min_txn = t
                if done:
                    break
            assert(min_txn != -1)
            running_cost = min_cost
            txn_seq.append(min_txn)
            holdout_txns.remove(min_txn)
            remaining_txns.extend(holdout_txns)

        assert len(set(txn_seq)) == workload.num_txns

        overall_cost = workload.get_opt_seq_cost(txn_seq)
        return overall_cost, txn_seq

    return get_greedy_cost_sampled(10, 1.0)
=======
def get_best_schedule(workload, num_seqs):
    """
    Beam-guided schedule construction with memoized prefix costs, marginal-cost ordering,
    shallow lookahead, greedy completion, short local refinement, and multiple restarts.
    """
    N = workload.num_txns
    start_time = time.time()
    # Keep a modest per-workload time budget to balance quality and speed
    time_budget_sec = 0.65

    def time_left():
        return (time.time() - start_time) < time_budget_sec

    # Memoization caches
    cost_cache = {}
    ext_cache = {}

    def eval_cost(seq):
        key = tuple(seq)
        c = cost_cache.get(key)
        if c is None:
            c = workload.get_opt_seq_cost(seq)
            cost_cache[key] = c
        return c

    def eval_ext(prefix_tuple, cand):
        key = (prefix_tuple, cand)
        c = ext_cache.get(key)
        if c is None:
            c = eval_cost(list(prefix_tuple) + [cand])
            ext_cache[key] = c
        return c

    def greedy_finish(seq, rem):
        seq_out = list(seq)
        rem_set = set(rem)
        cur_cost = eval_cost(seq_out)
        # Finish by repeatedly appending the least-cost extension from a small pool
        while rem_set and time_left():
            rem_list = list(rem_set)
            k = min(12, max(4, N // 12))
            pool = rem_list if len(rem_list) <= k else random.sample(rem_list, k)
            prefix_tuple = tuple(seq_out)
            best_t = None
            best_c = float('inf')
            for t in pool:
                c = eval_ext(prefix_tuple, t)
                if c < best_c:
                    best_c = c
                    best_t = t
            if best_t is None:
                best_t = rem_list[0]
                best_c = eval_ext(prefix_tuple, best_t)
            seq_out.append(best_t)
            rem_set.remove(best_t)
            cur_cost = best_c
        if rem_set:
            # Append any leftovers if time ran out
            for t in list(rem_set):
                seq_out.append(t)
            cur_cost = eval_cost(seq_out)
        return cur_cost, seq_out

    def beam_search():
        # Modest beam and branching, scaled by N
        beam_width = min(32, max(8, N // 7))
        branch = min(20, max(6, N // 10))
        lookahead_k = 2

        all_txns = list(range(N))
        # Seed beam with best singletons from a small random pool
        init_pool = min(N, max(beam_width * 2, 12))
        init_candidates = random.sample(all_txns, init_pool) if init_pool < N else all_txns[:]
        beam = []
        for t in init_candidates:
            if not time_left():
                break
            seq = [t]
            rem = set(all_txns)
            rem.remove(t)
            c = eval_cost(seq)
            beam.append((c, seq, rem))
        if not beam:
            seq = all_txns[:]
            random.shuffle(seq)
            return eval_cost(seq), seq
        beam.sort(key=lambda x: x[0])
        beam = beam[:beam_width]

        incumbent = float('inf')
        inc_seq = None

        steps = N - 1
        for _ in range(steps):
            if not time_left():
                break
            new_beam = []

            # Tighten incumbent early by greedily completing the best prefix
            if beam and time_left():
                pref = min(beam, key=lambda x: x[0])
                c_try, s_try = greedy_finish(pref[1], pref[2])
                if len(s_try) == N and c_try < incumbent:
                    incumbent, inc_seq = c_try, s_try

            for cost_so_far, seq, rem in beam:
                if not rem:
                    new_beam.append((cost_so_far, seq, rem))
                    if cost_so_far < incumbent:
                        incumbent, inc_seq = cost_so_far, seq[:]
                    continue
                if cost_so_far >= incumbent:
                    continue

                rem_list = list(rem)
                pool_size = min(len(rem_list), branch * 3)
                cand_pool = random.sample(rem_list, pool_size) if len(rem_list) > pool_size else rem_list

                prefix_tuple = tuple(seq)
                scored = []
                for cand in cand_pool:
                    if not time_left():
                        break
                    ec = eval_ext(prefix_tuple, cand)
                    scored.append((ec, cand))
                if not scored:
                    continue
                scored.sort(key=lambda x: x[0])
                top = scored[:min(branch, len(scored))]

                for ec, cand in top:
                    if not time_left():
                        break
                    new_seq = seq + [cand]
                    new_rem = rem.copy()
                    new_rem.remove(cand)

                    # One-step lookahead to refine ranking
                    la_score = ec
                    if new_rem and time_left():
                        la_pool = list(new_rem)
                        la_sample = la_pool if len(la_pool) <= lookahead_k else random.sample(la_pool, lookahead_k)
                        best_la = float('inf')
                        new_prefix = tuple(new_seq)
                        for nx in la_sample:
                            c2 = eval_ext(new_prefix, nx)
                            if c2 < best_la:
                                best_la = c2
                        la_score = min(la_score, best_la)

                    new_beam.append((ec, new_seq, new_rem, la_score))

            if not new_beam:
                break

            # Keep top unique prefixes by lookahead score
            new_beam.sort(key=lambda x: x[3])
            unique = []
            seen = set()
            for ent in new_beam:
                key = tuple(ent[1])
                if key in seen:
                    continue
                seen.add(key)
                unique.append((ent[0], ent[1], ent[2]))
                if len(unique) >= beam_width:
                    break
            beam = unique

        # Finalize by greedy completion of remaining prefixes
        best_cost = incumbent
        best_seq = inc_seq
        for cost_so_far, seq, rem in beam:
            if not time_left():
                break
            c_fin, s_fin = greedy_finish(seq, rem)
            if len(s_fin) == N and c_fin < best_cost:
                best_cost, best_seq = c_fin, s_fin

        if best_seq is None:
            seq = all_txns[:]
            random.shuffle(seq)
            best_seq = seq
            best_cost = eval_cost(seq)
        return best_cost, best_seq

    def local_refine(seq, cost0):
        best_seq = seq[:]
        best_cost = cost0
        # One pass of adjacent swaps
        for i in range(N - 1):
            if not time_left():
                break
            cand = best_seq[:]
            cand[i], cand[i + 1] = cand[i + 1], cand[i]
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        # A few random insertion moves
        trials = min(40, max(10, 4 * N // 10))
        while trials > 0 and time_left():
            trials -= 1
            i, j = random.sample(range(N), 2)
            if i == j:
                continue
            cand = best_seq[:]
            v = cand.pop(i)
            cand.insert(j, v)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        return best_cost, best_seq

    global_best = float('inf')
    global_seq = None
    restarts = max(1, int(num_seqs))
    for _ in range(restarts):
        if not time_left():
            break
        c, s = beam_search()
        if time_left():
            c, s = local_refine(s, c)
        if c < global_best:
            global_best, global_seq = c, s

    if global_seq is None:
        seq = list(range(N))
        random.shuffle(seq)
        global_seq = seq
        global_best = eval_cost(seq)

    return global_best, global_seq
>>>>>>> REPLACE
</DIFF>