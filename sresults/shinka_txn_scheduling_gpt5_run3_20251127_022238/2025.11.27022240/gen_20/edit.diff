--- a/original.py
+++ b/original.py
@@ -1,424 +1,499 @@
 # EVOLVE-BLOCK-START
 """Transaction scheduling algorithm for optimizing makespan across multiple workloads"""
 
 import time
 import random
 import sys
 import os
+from math import sqrt, log
 
 # Add the openevolve_examples directory to the path to import txn_simulator and workloads
-# Find the repository root by looking for the openevolve_examples directory
+# Find the repository root by looking for openevolve_examples directory
 def find_repo_root(start_path):
     """Find the repository root by looking for openevolve_examples directory."""
     current = os.path.abspath(start_path)
     # Search up the directory tree
     while current != os.path.dirname(current):  # Stop at filesystem root
         candidate = os.path.join(current, 'openevolve_examples', 'txn_scheduling')
         if os.path.exists(candidate):
             return current
         current = os.path.dirname(current)
 
     # If not found by searching up, try common locations relative to known paths
     # This handles when the program is copied to a results directory
     script_dir = os.path.dirname(os.path.abspath(__file__))
     possible_roots = [
         script_dir,  # Current directory
         os.path.dirname(script_dir),  # Parent
         os.path.dirname(os.path.dirname(script_dir)),  # Grandparent
         '/home/ubuntu/ShinkaEvolve',  # Absolute path fallback for Ubuntu
         '/Users/audreycc/Documents/Work/LLMTxn/ADRS-Exps/ShinkaEvolve',  # Absolute path fallback for macOS
     ]
     for root in possible_roots:
         candidate = os.path.join(root, 'openevolve_examples', 'txn_scheduling')
         if os.path.exists(candidate):
             return root
 
     raise RuntimeError(f"Could not find openevolve_examples directory. Searched from: {start_path}")
 
 repo_root = find_repo_root(os.path.dirname(__file__))
 sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'txn_scheduling'))
 
 from txn_simulator import Workload
 from workloads import WORKLOAD_1, WORKLOAD_2, WORKLOAD_3
 
 
 def get_best_schedule(workload, num_seqs):
     """
-    Beam search with A*-style lower-bound pruning, marginal-cost ordering,
-    shallow lookahead, shared memoized caches across restarts, multi-prefix
-    greedy completion, and a stronger sliding-window local refinement.
+    Monte Carlo Tree Search (MCTS) constructor with conflict-aware rollouts,
+    followed by Large Neighborhood Search (LNS) ruin-and-recreate refinement.
+    Shared memoized caches are used across all phases to minimize simulator calls.
 
     Args:
         workload: Workload object containing transaction data
-        num_seqs: Number of random restarts for the beam search
+        num_seqs: Intensity parameter; used to scale search effort slightly
 
     Returns:
         Tuple of (lowest makespan, corresponding schedule)
     """
     N = workload.num_txns
-    # Time budget per workload to balance quality and speed
-    time_budget_sec = 0.55
+
+    # Overall per-workload time budget (seconds)
+    # Scaled lightly by num_seqs but bounded to keep runtime reasonable
+    base_budget = 0.70
+    time_budget_sec = min(1.00, base_budget + 0.03 * max(0, int(num_seqs) - 5))
     start_time = time.time()
 
     def time_left():
         return (time.time() - start_time) < time_budget_sec
 
-    # Shared caches across all restarts
+    # ----------------------
+    # Shared memoized caches
+    # ----------------------
     cost_cache = {}
-    ext_cache = {}
-
-    def eval_seq_cost(seq):
+    ext_cache = {}   # (prefix_tuple, cand) -> cost
+    pair_cost_cache = {}  # (i, j) -> cost([i, j])
+    singleton_cost = {}
+
+    def eval_cost(seq):
         key = tuple(seq)
-        cached = cost_cache.get(key)
-        if cached is not None:
-            return cached
+        c = cost_cache.get(key)
+        if c is not None:
+            return c
         c = workload.get_opt_seq_cost(seq)
         cost_cache[key] = c
         return c
 
-    def eval_ext_cost(prefix_tuple, cand):
+    def eval_ext(prefix_tuple, cand):
         key = (prefix_tuple, cand)
-        cached = ext_cache.get(key)
-        if cached is not None:
-            return cached
-        c = eval_seq_cost(list(prefix_tuple) + [cand])
+        c = ext_cache.get(key)
+        if c is not None:
+            return c
+        c = eval_cost(list(prefix_tuple) + [cand])
         ext_cache[key] = c
         return c
 
-    # Precompute singleton costs for lower bounds and seeding
-    singleton_cost = {}
+    def eval_pair(i, j):
+        key = (i, j)
+        c = pair_cost_cache.get(key)
+        if c is not None:
+            return c
+        c = eval_cost([i, j])
+        pair_cost_cache[key] = c
+        return c
+
+    # Precompute singleton costs
     for t in range(N):
         if not time_left():
             break
-        singleton_cost[t] = eval_seq_cost([t])
-
-    def max_singleton_rem(rem_set):
-        if not rem_set:
-            return 0
-        # Compute max singleton among remaining; small overhead given beam widths
-        m = 0
-        for t in rem_set:
-            c = singleton_cost.get(t)
-            if c is None:
-                c = eval_seq_cost([t])
-                singleton_cost[t] = c
-            if c > m:
-                m = c
-        return m
-
-    def greedy_finish(seq, rem_set, branch_factor, incumbent=None):
-        seq_out = list(seq)
-        rem = set(rem_set)
-        cur_cost = eval_seq_cost(seq_out)
+        singleton_cost[t] = eval_cost([t])
+
+    # ----------------------
+    # Conflict estimation
+    # ----------------------
+    # Sampled symmetric conflict weight between i and j approximated as
+    # min(cost([i, j]), cost([j, i])) - max(singleton[i], singleton[j])
+    # Larger means more interference if they are adjacent.
+    conflict_weight = {}
+    def add_conflict(i, j):
+        if i == j:
+            return
+        a = singleton_cost.get(i, eval_cost([i]))
+        b = singleton_cost.get(j, eval_cost([j]))
+        cij = eval_pair(i, j)
+        cji = eval_pair(j, i)
+        w = min(cij, cji) - max(a, b)
+        if w < 0:
+            w = 0.0
+        conflict_weight[(i, j)] = w
+        conflict_weight[(j, i)] = w
+
+    # Limit estimation time
+    if time_left():
+        # per txn, sample k others
+        sample_k = min(14, max(6, N // 10))
+        all_txns = list(range(N))
+        for i in all_txns:
+            if not time_left():
+                break
+            others = [x for x in all_txns if x != i]
+            k = min(sample_k, len(others))
+            if k > 0:
+                for j in random.sample(others, k):
+                    if not time_left():
+                        break
+                    if (i, j) not in conflict_weight:
+                        add_conflict(i, j)
+
+    def pair_penalty(a, b):
+        # Fallback to zero if not sampled; this keeps LNS conservative
+        return conflict_weight.get((a, b), 0.0)
+
+    # ----------------------
+    # Rollout policy (used by MCTS)
+    # ----------------------
+    def greedy_rollout(prefix, remaining_set, sample_branch=10, epsilon=0.05):
+        seq = list(prefix)
+        rem = set(remaining_set)
+        cur_cost = eval_cost(seq)
         while rem and time_left():
-            # Early prune if LB already worse than incumbent
-            if incumbent is not None:
-                lb_here = max(cur_cost, max_singleton_rem(rem))
-                if lb_here >= incumbent:
-                    break
             rem_list = list(rem)
-            k = min(branch_factor, len(rem_list))
-            cand_pool = random.sample(rem_list, k) if len(rem_list) > k else rem_list
+            # Epsilon-greedy exploration in rollout
+            if random.random() < epsilon:
+                t = random.choice(rem_list)
+                seq.append(t)
+                rem.remove(t)
+                cur_cost = eval_cost(seq)
+                continue
+            k = min(sample_branch, len(rem_list))
+            cand_pool = rem_list if len(rem_list) <= k else random.sample(rem_list, k)
             best_t = None
-            best_c = float('inf')
-            prefix_tuple = tuple(seq_out)
+            best_val = float('inf')
+            pfx = tuple(seq)
             for t in cand_pool:
-                c = eval_ext_cost(prefix_tuple, t)
-                if c < best_c:
-                    best_c = c
+                c = eval_ext(pfx, t)
+                # Use slight penalty by expected conflicts with remaining (bias away from "hot" txns)
+                # Estimate future penalty as average pair penalty vs a small sample of rem
+                if len(rem) > 1:
+                    samp = random.sample(rem - {t}, min(4, len(rem) - 1))
+                    conf_bias = sum(pair_penalty(t, u) for u in samp) / max(1, len(samp))
+                else:
+                    conf_bias = 0.0
+                val = c + 0.15 * conf_bias
+                if val < best_val:
+                    best_val = val
                     best_t = t
             if best_t is None:
                 best_t = rem_list[0]
-                best_c = eval_ext_cost(prefix_tuple, best_t)
-            seq_out.append(best_t)
+                best_val = eval_ext(pfx, best_t)
+            seq.append(best_t)
             rem.remove(best_t)
-            cur_cost = best_c
-        if rem:
-            # If time ran out or pruned, append the rest arbitrarily
-            for t in list(rem):
-                seq_out.append(t)
-            cur_cost = eval_seq_cost(seq_out)
-        return cur_cost, seq_out
-
-    def run_beam_search():
-        # Dynamically size the beam and branching according to problem size
-        beam_width = min(max(8, N // 7), 40)
-        branch_factor = min(max(8, N // 9), 28)
-        lookahead_k = 3
-
+            cur_cost = best_val if isinstance(best_val, (int, float)) else eval_cost(seq)
+        return eval_cost(seq), seq
+
+    # ----------------------
+    # MCTS constructor
+    # ----------------------
+    class MCTSNode:
+        __slots__ = ("prefix", "rem", "children", "untried", "visits", "value_sum", "best_seen_cost", "best_seen_seq")
+        def __init__(self, prefix, rem):
+            self.prefix = tuple(prefix)
+            self.rem = frozenset(rem)
+            self.children = {}  # action t -> node
+            self.untried = set(rem)  # actions yet to expand
+            self.visits = 0
+            self.value_sum = 0.0  # sum of rollout costs (we minimize)
+            self.best_seen_cost = float('inf')
+            self.best_seen_seq = None
+
+    node_table = {}
+
+    def get_node(prefix, rem_set):
+        key = (tuple(prefix), frozenset(rem_set))
+        n = node_table.get(key)
+        if n is None:
+            n = MCTSNode(prefix, rem_set)
+            node_table[key] = n
+        return n
+
+    def mcts_search(time_budget_frac=0.55):
+        # Reserve fraction of total time for MCTS
+        end_time = start_time + time_budget_sec * time_budget_frac
+        # UCB exploration constant; tuned to balance exploration vs exploitation
+        C = 1.25
+
+        # Root initialization
         all_txns = list(range(N))
-        # Precompute a few singleton costs to seed
-        init_pool_size = min(len(all_txns), max(beam_width * 2, 8))
-        init_candidates = random.sample(all_txns, init_pool_size) if init_pool_size > 0 else all_txns[:]
-        beam = []
-        for t in init_candidates:
-            if not time_left():
-                break
-            seq = [t]
-            rem = set(all_txns)
-            rem.remove(t)
-            cost = eval_seq_cost(seq)
-            beam.append((cost, seq, rem))
-        if not beam:
-            seq = all_txns[:]
+        root = get_node([], set(all_txns))
+
+        global_best_cost = float('inf')
+        global_best_seq = None
+
+        # Warm-start: try a couple of greedy starts from different seeds
+        if time_left():
+            seeds = random.sample(all_txns, min(6, N))
+            for s in seeds:
+                if not time_left() or (time.time() > end_time):
+                    break
+                c0, seq0 = greedy_rollout([s], set(all_txns) - {s}, sample_branch=12)
+                if c0 < global_best_cost:
+                    global_best_cost, global_best_seq = c0, seq0
+
+        iterations = 0
+        while time_left() and (time.time() < end_time):
+            iterations += 1
+            node = root
+            path = [node]
+            # Selection
+            while node.untried == set() and node.children and node.rem:
+                # UCB on children: maximize -mean_cost + C * sqrt(log(Np)/Nc)
+                best_score = -1e18
+                best_action = None
+                for a, child in node.children.items():
+                    if child.visits == 0:
+                        score = 1e9  # force exploration
+                    else:
+                        mean = child.value_sum / child.visits
+                        score = (-mean) + C * sqrt(max(0.0, log(max(1.0, node.visits)) / child.visits))
+                    if score > best_score:
+                        best_score = score
+                        best_action = a
+                if best_action is None:
+                    break
+                # Move to child
+                new_prefix = list(node.prefix) + [best_action]
+                new_rem = set(node.rem)
+                if best_action in new_rem:
+                    new_rem.remove(best_action)
+                node = get_node(new_prefix, new_rem)
+                path.append(node)
+
+            # Expansion
+            if node.rem and node.untried:
+                # Choose action to expand: prioritize low marginal ext cost among a sample
+                cand_pool = list(node.untried)
+                if len(cand_pool) > 12:
+                    cand_pool = random.sample(cand_pool, 12)
+                pfx = tuple(node.prefix)
+                best_a = None
+                best_val = float('inf')
+                for a in cand_pool:
+                    c = eval_ext(pfx, a)
+                    # tie-break by singleton cost a bit
+                    val = c + 0.05 * singleton_cost.get(a, eval_cost([a]))
+                    if val < best_val:
+                        best_val = val
+                        best_a = a
+                if best_a is None:
+                    best_a = random.choice(list(node.untried))
+                node.untried.discard(best_a)
+                new_prefix = list(node.prefix) + [best_a]
+                new_rem = set(node.rem)
+                if best_a in new_rem:
+                    new_rem.remove(best_a)
+                child = get_node(new_prefix, new_rem)
+                node.children[best_a] = child
+                node = child
+                path.append(node)
+
+            # Rollout
+            rem_set = set(node.rem)
+            if rem_set:
+                rollout_branch = 10 if len(rem_set) > 30 else 14
+                cost_final, seq_final = greedy_rollout(list(node.prefix), rem_set, sample_branch=rollout_branch)
+            else:
+                cost_final = eval_cost(list(node.prefix))
+                seq_final = list(node.prefix)
+
+            # Backpropagation
+            for nd in path:
+                nd.visits += 1
+                nd.value_sum += cost_final
+                if cost_final < nd.best_seen_cost:
+                    nd.best_seen_cost = cost_final
+                    nd.best_seen_seq = seq_final
+
+            if cost_final < global_best_cost:
+                global_best_cost, global_best_seq = cost_final, seq_final
+
+        # Fallback
+        if global_best_seq is None:
+            seq = list(range(N))
             random.shuffle(seq)
-            return eval_seq_cost(seq), seq
-
-        # Keep best initial seeds
-        beam.sort(key=lambda x: x[0])
-        beam = beam[:max(1, min(beam_width, len(beam)))]
-
-        incumbent_cost = float('inf')
-        incumbent_seq = None
-
-        # Expand the beam until full sequences are built or time elapses
-        steps = N - 1
-        for _ in range(steps):
-            if not time_left():
-                break
-            new_beam = []
-            # Tighten incumbent early by greedily completing top prefixes
-            if beam and time_left():
-                # Try top-K by current prefix cost
-                beam_sorted_for_finish = sorted(beam, key=lambda x: x[0])[:min(3, len(beam))]
-                for cost_so_far, seq_b, rem_b in beam_sorted_for_finish:
-                    if not time_left():
-                        break
-                    c_try, s_try = greedy_finish(seq_b, rem_b, branch_factor, incumbent_cost)
-                    if len(s_try) == N and c_try < incumbent_cost:
-                        incumbent_cost, incumbent_seq = c_try, s_try
-
-            for cost_so_far, seq, rem in beam:
-                # If no remaining, update incumbent and carry forward
-                if not rem:
-                    new_beam.append((cost_so_far, seq, rem))
-                    if cost_so_far < incumbent_cost:
-                        incumbent_cost, incumbent_seq = cost_so_far, seq[:]
-                    continue
-
-                # A*-style prefix lower bound prune
-                if cost_so_far >= incumbent_cost:
-                    continue
-                lb_prefix = max(cost_so_far, max_singleton_rem(rem))
-                if lb_prefix >= incumbent_cost:
-                    continue
-
-                rem_list = list(rem)
-                # Create a candidate pool and sort by marginal delta
-                pool_size = min(len(rem_list), branch_factor * 3)
-                cand_pool = random.sample(rem_list, pool_size) if len(rem_list) > pool_size else rem_list
-
-                scored = []
-                prefix_tuple = tuple(seq)
-                for cand in cand_pool:
-                    if not time_left():
-                        break
-                    ext_cost = eval_ext_cost(prefix_tuple, cand)
-                    delta = ext_cost - cost_so_far
-                    scored.append((delta, ext_cost, cand))
-                if not scored:
-                    continue
-                scored.sort(key=lambda x: x[0])
-                top_cands = scored[:min(branch_factor, len(scored))]
-
-                # Append candidates; use LB + shallow lookahead to rank
-                for _, ext_cost, cand in top_cands:
-                    if not time_left():
-                        break
-                    new_seq = seq + [cand]
-                    new_rem = rem.copy()
-                    new_rem.remove(cand)
-
-                    # Child lower bound for pruning
-                    lb_child = max(ext_cost, max_singleton_rem(new_rem))
-                    if lb_child >= incumbent_cost:
-                        continue
-
-                    # Shallow lookahead ranking
-                    rank_score = lb_child
-                    if new_rem and time_left():
-                        la_pool = list(new_rem)
-                        la_sample = la_pool if len(la_pool) <= lookahead_k else random.sample(la_pool, lookahead_k)
-                        best_la = float('inf')
-                        new_prefix_tuple = tuple(new_seq)
-                        for nxt in la_sample:
-                            c2 = eval_ext_cost(new_prefix_tuple, nxt)
-                            if c2 < best_la:
-                                best_la = c2
-                        # Use the better of LB and lookahead cost for ranking
-                        rank_score = min(rank_score, best_la)
-
-                    new_beam.append((ext_cost, new_seq, new_rem, rank_score))
-
-            if not new_beam:
-                break
-
-            # Keep only the top beam_width unique prefixes by rank_score
-            new_beam.sort(key=lambda x: x[3])
-            unique = []
-            seen = set()
-            for entry in new_beam:
-                key = tuple(entry[1])
-                if key in seen:
-                    continue
-                seen.add(key)
-                # store actual prefix cost ext_cost for further expansion
-                unique.append((entry[0], entry[1], entry[2]))
-                if len(unique) >= beam_width:
+            global_best_seq = seq
+            global_best_cost = eval_cost(seq)
+        return global_best_cost, global_best_seq
+
+    # ----------------------
+    # LNS Refinement
+    # ----------------------
+    def lns_refine(seq, start_cost, time_budget_frac=0.35):
+        end_time = start_time + time_budget_sec * (1.0)  # up to total budget
+        best_seq = list(seq)
+        best_cost = start_cost
+
+        if N <= 2 or not time_left():
+            return best_cost, best_seq
+
+        # Helper: compute adjacency penalties along sequence (approx)
+        def adjacency_penalties(s):
+            pens = []
+            for i in range(len(s) - 1):
+                a, b = s[i], s[i + 1]
+                pens.append((pair_penalty(a, b), i))
+            pens.sort(key=lambda x: -x[0])
+            return pens
+
+        def reinsert_sequence(base_seq, removed):
+            # Greedy reinsertion of removed items into base_seq using sampled positions
+            seq_local = list(base_seq)
+            for t in removed:
+                if not time_left() or time.time() > end_time:
                     break
-            beam = unique
-
-        # Complete remaining prefixes greedily and pick the best
-        best_cost = incumbent_cost
-        best_seq_local = incumbent_seq
-        for cost_so_far, seq, rem in beam:
-            if not time_left():
-                break
-            c_fin, s_fin = greedy_finish(seq, rem, branch_factor, incumbent_cost)
-            if len(s_fin) == N and c_fin < best_cost:
-                best_cost, best_seq_local = c_fin, s_fin
-
-        if best_seq_local is None:
-            # Fallback to a random permutation
-            seq = all_txns[:]
-            random.shuffle(seq)
-            best_seq_local = seq
-            best_cost = eval_seq_cost(seq)
-        return best_cost, best_seq_local
-
-    def local_improve(seq, current_cost):
-        # Adjacent swaps, sliding-window insertions, and limited random insertions
-        best_seq = seq[:]
-        best_cost = current_cost
-
-        # Adjacent swap hill climbing (single pass)
-        for i in range(len(best_seq) - 1):
-            if not time_left():
-                break
-            cand = best_seq[:]
-            cand[i], cand[i + 1] = cand[i + 1], cand[i]
-            c = eval_seq_cost(cand)
-            if c < best_cost:
-                best_cost = c
-                best_seq = cand
-
-        # Sliding-window insertion refinement
-        Nloc = len(best_seq)
-        for w in (7, 9):
-            if not time_left():
-                break
-            step = max(1, w // 2)
-            start_idx = 0
-            while start_idx < Nloc and time_left():
-                end_idx = min(Nloc, start_idx + w)
-                improved_window = True
-                # Iterate until no improvement within this window or time runs out
-                iter_guard = 0
-                while improved_window and time_left() and iter_guard < 2:
-                    improved_window = False
-                    iter_guard += 1
-                    for i in range(start_idx, end_idx):
-                        if not time_left():
-                            break
-                        for j in range(start_idx, end_idx):
-                            if i == j:
-                                continue
-                            cand = best_seq[:]
-                            val = cand.pop(i)
-                            cand.insert(j, val)
-                            c = eval_seq_cost(cand)
-                            if c < best_cost:
-                                best_cost = c
-                                best_seq = cand
-                                # Update positions after change
-                                Nloc = len(best_seq)
-                                improved_window = True
-                start_idx += step
-
-        # Random insertion moves (bounded)
-        trials = 50
-        while trials > 0 and time_left():
-            trials -= 1
-            i, j = random.sample(range(len(best_seq)), 2)
-            if i == j:
-                continue
-            cand = best_seq[:]
-            val = cand.pop(i)
-            cand.insert(j, val)
-            c = eval_seq_cost(cand)
-            if c < best_cost:
-                best_cost = c
-                best_seq = cand
+                best_c = float('inf')
+                best_pos = None
+                # Candidate positions: endpoints + a few random positions + near high-penalty edges
+                positions = {0, len(seq_local)}
+                if len(seq_local) > 1:
+                    positions.update(random.sample(range(1, len(seq_local)), min(8, len(seq_local) - 1)))
+                # Try to bias by adjacency penalties: try around a few worst edges
+                ap = adjacency_penalties(seq_local)[:4]
+                for _, idx in ap:
+                    positions.add(idx + 1)
+                for pos in positions:
+                    cand = seq_local[:]
+                    cand.insert(pos, t)
+                    c = eval_cost(cand)
+                    if c < best_c:
+                        best_c = c
+                        best_pos = pos
+                if best_pos is None:
+                    best_pos = len(seq_local)
+                seq_local.insert(best_pos, t)
+            return eval_cost(seq_local), seq_local
+
+        # Run multiple LNS iterations until out of time
+        iterations = 0
+        while time_left() and (time.time() < end_time):
+            iterations += 1
+            cur_seq = list(best_seq)
+            cur_cost = best_cost
+            # Choose removal size
+            rem_size = max(4, min(18, N // 8))
+            # Strategy selection
+            strat_roll = random.random()
+            removed_idx = set()
+
+            if strat_roll < 0.40:
+                # Conflict-guided removal: remove transactions around top-K high-penalty edges
+                ap = adjacency_penalties(cur_seq)
+                k_edges = min(max(2, rem_size // 3), len(ap))
+                chosen_edges = ap[:k_edges]
+                for _, idx in chosen_edges:
+                    removed_idx.add(idx)
+                    removed_idx.add(idx + 1)
+                # Top up randomly to reach target size
+                while len(removed_idx) < rem_size:
+                    removed_idx.add(random.randrange(len(cur_seq)))
+            elif strat_roll < 0.75:
+                # Random removal
+                candidates = list(range(len(cur_seq)))
+                removed_idx = set(random.sample(candidates, min(rem_size, len(candidates))))
+            else:
+                # Contiguous block removal
+                if len(cur_seq) > rem_size:
+                    start = random.randrange(0, len(cur_seq) - rem_size + 1)
+                    removed_idx = set(range(start, start + rem_size))
+                else:
+                    removed_idx = set(range(len(cur_seq)))
+
+            removed_idx = sorted(list(removed_idx))
+            removed_items = [cur_seq[i] for i in removed_idx]
+            base_seq = [cur_seq[i] for i in range(len(cur_seq)) if i not in removed_idx]
+
+            # Reinsert
+            new_cost, new_seq = reinsert_sequence(base_seq, removed_items)
+
+            # Accept if improved
+            if new_cost < best_cost:
+                best_cost, best_seq = new_cost, new_seq
+            else:
+                # Occasionally accept equal-cost to escape plateaus
+                if new_cost == best_cost and random.random() < 0.1:
+                    best_cost, best_seq = new_cost, new_seq
+
+            # Small adjacent-swap polish on occasion
+            if iterations % 3 == 0 and time_left():
+                for i in range(min(8, len(best_seq) - 1)):
+                    idx = random.randrange(0, len(best_seq) - 1)
+                    cand = best_seq[:]
+                    cand[idx], cand[idx + 1] = cand[idx + 1], cand[idx]
+                    c = eval_cost(cand)
+                    if c < best_cost:
+                        best_cost, best_seq = c, cand
 
         return best_cost, best_seq
 
-    global_best_cost = float('inf')
-    global_best_seq = None
-
-    # Multiple random restarts for robustness, bounded by time
-    restarts = max(1, int(num_seqs))
-    r = 0
-    while r < restarts and time_left():
-        cost, seq = run_beam_search()
-        if time_left():
-            cost, seq = local_improve(seq, cost)
-        if cost < global_best_cost:
-            global_best_cost, global_best_seq = cost, seq
-        r += 1
-
-    if global_best_seq is None:
-        # Fallback to a random permutation
+    # ----------------------
+    # Orchestrate phases
+    # ----------------------
+    # Use MCTS to construct a strong schedule, then refine via LNS
+    mcts_cost, mcts_seq = mcts_search(time_budget_frac=0.55)
+    final_cost, final_seq = lns_refine(mcts_seq, mcts_cost, time_budget_frac=0.35)
+
+    # Fallback if something failed
+    if not final_seq or len(final_seq) != N:
         seq = list(range(N))
         random.shuffle(seq)
-        global_best_seq = seq
-        global_best_cost = eval_seq_cost(seq)
-
-    return global_best_cost, global_best_seq
+        final_seq = seq
+        final_cost = eval_cost(seq)
+
+    return final_cost, final_seq
 
 
 def get_random_costs():
     """
     Evaluate scheduling algorithm on three different workloads.
 
     Returns:
         Tuple of (total_makespan, list_of_schedules, execution_time)
     """
     start_time = time.time()
     workload_size = 100
 
     # Workload 1: Complex mixed read/write transactions
     workload = Workload(WORKLOAD_1)
     makespan1, schedule1 = get_best_schedule(workload, 10)
     cost1 = workload.get_opt_seq_cost(schedule1)
 
     # Workload 2: Simple read-then-write pattern
     workload2 = Workload(WORKLOAD_2)
     makespan2, schedule2 = get_best_schedule(workload2, 10)
     cost2 = workload2.get_opt_seq_cost(schedule2)
 
     # Workload 3: Minimal read/write operations
     workload3 = Workload(WORKLOAD_3)
     makespan3, schedule3 = get_best_schedule(workload3, 10)
     cost3 = workload3.get_opt_seq_cost(schedule3)
 
     total_makespan = cost1 + cost2 + cost3
     schedules = [schedule1, schedule2, schedule3]
     execution_time = time.time() - start_time
 
     return total_makespan, schedules, execution_time
 
 
 # EVOLVE-BLOCK-END
 
 
 # This part remains fixed (not evolved)
 def run_scheduling():
     """Run the transaction scheduling algorithm for all workloads"""
     total_makespan, schedules, execution_time = get_random_costs()
     return total_makespan, schedules, execution_time
 
 
 if __name__ == "__main__":
     total_makespan, schedules, execution_time = run_scheduling()
     print(f"Total makespan: {total_makespan}, Execution time: {execution_time:.4f}s")
     print(f"Individual workload costs: {[workload.get_opt_seq_cost(schedule) for workload, schedule in zip([Workload(WORKLOAD_1), Workload(WORKLOAD_2), Workload(WORKLOAD_3)], schedules)]}")