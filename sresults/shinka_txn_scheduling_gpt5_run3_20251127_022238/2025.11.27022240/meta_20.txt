# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy sampled transaction scheduler**
- **Implementation**: Implements a greedy cost-sampling scheduler: start at a random transaction, then at each step evaluate up to 10 randomly selected candidates via workload.get_opt_seq_cost and pick the minimum; sample_rate is fixed at 1.0 so only the greedy path runs. Includes robust repo-root path discovery; num_seqs and workload_size are unused, costs are recomputed redundantly, and randomness is unseeded.
- **Performance**: Combined score 2.65 across 3 workloads (300 transactions); correct and passes all validation tests with execution time recorded.
- **Feedback**: Greedy sampling trades optimality for speed; unseeded randomness can cause variability—seeding or multi-start runs could stabilize/improve scores. Removing redundant cost recomputations and honoring num_seqs/sample_rate would reduce overhead and enable broader exploration.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Beam-search transaction scheduler with memoized costs**
- **Implementation**: Uses beam search with dynamic beam/branch sizing, memoized prefix cost evaluation, and multiple random restarts. Initializes the beam from sampled singletons and prunes to top unique prefixes at each depth to control breadth.
- **Performance**: Combined score 3.40; produced valid schedules for all three workloads (300 transactions) and passed all validation tests.
- **Feedback**: Dynamic sizing and memoization reduced search overhead, while random restarts improved robustness; capped beam (≤32) and branch (≤24) factors kept runtime reasonable but can miss global optima due to stochastic pruning. Re-evaluating final schedules confirmed consistency of reported makespans.
**Program Identifier:** Generation 1 - Patch Name beam_search_with_memoized_costs - Correct Program: True

**Program Name: Beam + local search transaction scheduler**
- **Implementation**: Uses a beam search with memoized partial-cost evaluations (Workload.get_opt_seq_cost) and adaptive beam width (from num_seqs) plus sampled candidate expansions, followed by local improvements via adjacent swaps and sampled insertion. Includes robust repository path discovery to import simulator/workloads reliably.
- **Performance**: Achieved a combined score of 3.19 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Memoization and controlled branching reduce simulator calls and help meet the time budget, while local improvements further lower makespan beyond the beam result. Randomized starts and sampling introduce run-to-run variance without a fixed seed.
**Program Identifier:** Generation 2 - Patch Name beam_search_local_improve - Correct Program: True

**Program Name: Multi-start Greedy Scheduler with Lookahead and Local Search**
- **Implementation**: Uses a multi-start greedy constructor with full candidate evaluation, limited two-step lookahead, and a memoized cost cache. Final schedules are refined via adjacent-swap hill climbing and accept-if-better random insertions, with starts seeded from lowest-cost singletons.
- **Performance**: Combined score 3.40 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Memoization and lookahead improve selection quality and reduce redundant cost calls, while local search finds additional improvements after greedy construction. Runtime is mitigated by sampling and bounded local moves, though full candidate evaluation per step remains a potential bottleneck on larger instances.
**Program Identifier:** Generation 3 - Patch Name greedy_full_eval_beam_local - Correct Program: True

**Program Name: Tournament-ILS Transaction Scheduler**
- **Implementation**: Builds a pairwise preference matrix from O(n^2) length-1/2 simulations to score transactions and locally sort via tournament comparisons, then applies memoized true-cost refinement with one adjacent-swap pass, limited ruin-and-recreate (sampled insert positions), and sampled insertion moves; refinement budget scales with num_seqs. A cached evaluator avoids redundant simulator calls across candidates.
- **Performance**: Combined score 2.87 on 3 workloads (300 transactions); all validation tests passed.
- **Feedback**: Pairwise surrogate costs provided strong ordering signals and reduced expensive evaluations, with memoization further decreasing simulator calls. The constrained ILS budget (single true-cost pass and up to two ruin-and-recreate tries) likely caps peak optimality while keeping runtime controlled.
**Program Identifier:** Generation 4 - Patch Name pairwise_tournament_rank_ils - Correct Program: True

**Program Name: MCTS + VND Transaction Scheduler**
- **Implementation**: UCT-based MCTS over partial schedules with progressive widening, greedy-biased expansion, cost caching, and a transposition table; rollouts use limited lookahead with pruning and are followed by VND local search (adjacent swaps, insertions, small block moves). The final schedule is extracted via most-visited children with greedy fallback, and evaluated across three workloads.
- **Performance**: Combined score: 0.0; did not pass validation.
- **Feedback**: Failures likely stem from nondeterminism (no fixed RNG seed), heavy iteration budgets causing timeouts, and brittle repo path discovery; partial-cost reliance may also mismatch the simulator API. Seed the RNG, cap/scale iteration budgets, simplify imports to avoid filesystem probing, and verify partial-cost calls against the provided Workload interface.
**Program Identifier:** Generation 5 - Patch Name uct_mcts_vnd_scheduler - Correct Program: False

**Program Name: Hybrid Beam-GRASP Transaction Scheduler**
- **Implementation**: Alternates a beam search with shallow lookahead and a GRASP constructor, using adaptive beam/branch sizes scaled by N and a shared memoized cost cache under a 0.35s per-workload time budget. A local search phase (adjacent swaps, random swaps, sampled insertions) refines each constructed sequence.
- **Performance**: Achieved combined score 1.56 on 3 workloads (300 transactions) within the time budget, and passed all validation tests.
- **Feedback**: The hybrid construction plus local improvement consistently finds low-makespan schedules under tight time constraints, aided by caching and adaptive sampling. Beam truncation with greedy completion can occur when the budget is tight, but outputs remain valid.
**Program Identifier:** Generation 6 - Patch Name beam_grasp_ils_hybrid - Correct Program: True

**Program Name: Multi-start Greedy VNS Transaction Scheduler**
- **Implementation**: Uses a memoized partial-sequence evaluator with multi-start greedy construction (limited lookahead) and Variable Neighborhood Search combining adjacent swaps, sampled relocations, and light ruin-and-recreate; seeding is diversified via singleton-cost rankings and budgets adapt to problem size. Includes adaptive candidate sampling and restart strategies to control simulator calls and runtime.
- **Performance**: Combined score 3.24 across three workloads (300 transactions); produced valid schedules and passed all validation tests.
- **Feedback**: Memoization significantly cuts simulator evaluations, enabling stronger local search within the given budget, while adaptive sampling and restrained ruin-and-recreate maintain good makespan-quality/runtime trade-offs. Time-based RNG seeding yields non-deterministic results across runs.
**Program Identifier:** Generation 7 - Patch Name greedy_lookahead_rr_vns - Correct Program: True

**Program Name: Marginal-Cost LNS Transaction Scheduler**
- **Implementation**: Employs a marginal-cost-guided LNS: a lazy candidate-pool greedy constructor with limited lookahead builds seeds, a global cost cache accelerates evals, adjacent-swap hill-climb cleans up, and hot windows (chosen via prefix marginals) are reordered using budgeted permutation enumeration/sampling; targeted relocate moves, multi-start seeding, and final random insertions provide additional refinement.
- **Performance**: Achieved a combined score of 3.18 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Evaluation indicates robust correctness and effective heuristic improvements from caching and windowed LNS/relocate moves; the score suggests remaining headroom, potentially addressable via adaptive pool/window sizes or dynamic permutation budgets.
**Program Identifier:** Generation 8 - Patch Name marginal_lns_pool - Correct Program: True

**Program Name: Tournament-Guided Greedy VNS Scheduler**
- **Implementation**: Uses pairwise-tournament-guided greedy construction with limited lookahead and a global memoized cost cache. Precomputes singleton/pairwise costs to form preference margins, applies multi-start seeding, and refines schedules via VNS (tournament bubble cleanup, adjacent swaps, relocations, non-adjacent swaps, and ruin-and-recreate).
- **Performance**: Achieved combined score 3.12 across 3 workloads (300 transactions), passing all validation tests.
- **Feedback**: Precomputing pairwise preferences and caching partial evaluations effectively cut simulator calls and guided the search toward low-conflict orderings. Multi-start plus VNS consistently improved makespan, and size-aware budgeting maintained stable performance across varying workload complexities.
**Program Identifier:** Generation 9 - Patch Name pairwise_guided_greedy_vns - Correct Program: True

**Program Name: Preference-Guided Beam Search Scheduler**
- **Implementation**: Uses a memoized cost oracle and a sampled pairwise preference model to compute soft precedence weights, guiding a time-bounded beam search scored by true cost plus penalty with shallow lookahead and adaptive beam/branch sizes. A multi-pass LocalRefiner fixes high-weight violations, then performs adjacent swaps, random insertions, and long swaps, with a SchedulerEngine allocating time across preference building, construction, and refinement per workload size.
- **Performance**: Achieved a combined score of 2.04 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests within the ~0.75s/workload budget.
- **Feedback**: Preference sampling and cost memoization effectively reduce search overhead, while lookahead and violation-guided refinement yield consistent makespan improvements. Dynamic scaling and ALNS-style moves aid solution quality, though the modest score indicates potential gains from deeper lookahead or broader restart strategies under the same time budget.
**Program Identifier:** Generation 10 - Patch Name pref_beam_alns - Correct Program: True

**Program Name: Beam search scheduler with caching and refinement**
- **Implementation**: Time-bounded beam search using marginal-cost ordering and shallow lookahead, with shared memoization caches (cost/delta), incumbent-based pruning, greedy completion, and a local improvement pass (adjacent swaps plus random insertions). Beam/branch widths scale with workload size and multiple restarts run within the budget.
- **Performance**: Achieved combined score 1.93 across 3 workloads (300 transactions) and passed all validation tests.
- **Feedback**: Caching and marginal-cost ordering reduce redundant evaluations and focus exploration, while shallow lookahead and greedy completion tighten pruning against the incumbent. The lightweight local refinement yields incremental gains without exceeding the per-workload time budget.
**Program Identifier:** Generation 11 - Patch Name beam_astar_delta_local - Correct Program: True

**Program Name: A*-beam scheduler with memoized delta costs**
- **Implementation**: Uses an A*-guided beam search with delta-based candidate ordering, greedy two-step lookahead completion, and local polishing (adjacent swaps and sampled insertions). A shared CostOracle memoizes cost and marginal deltas with FIFO-bounded caches, plus multi-profile restarts and adaptive beam/branching from num_seqs.
- **Performance**: Combined score to maximize: 0.0; failed all validation tests.
- **Feedback**: Time-salted RNG seeds and brittle repository path discovery undermine determinism and portability, likely contributing to test failures. The max-singleton lower bound used as f=max(g,h) is not clearly admissible for the remaining cost, risking incorrect pruning and invalid results; additionally, the “partial sampling” branches are no-ops, reducing intended speedups.
**Program Identifier:** Generation 12 - Patch Name astar_beam_lns_scheduler - Correct Program: False

**Program Name: A*-guided Beam + Local Search Scheduler**
- **Implementation**: Uses an A*-guided beam search with cached sequence costs and marginal deltas, a singleton-cost lower bound, diversified seeding, candidate sampling, two-step lookahead, periodic greedy completions, and multi-restart local search (adjacent swaps and relocations) with shared caches and deterministic RNG. Includes repo-root probing to import external simulator/workloads and aggregates makespan across three workloads.
- **Performance**: Combined score 0.0; the program failed validation tests.
- **Feedback**: Likely failure stems from brittle external path discovery/imports and/or oversized beam/branch settings causing timeouts; the singleton-based lower bound may be too weak to prune effectively. Additionally, ‘workload_size’ is unused and restarts share the same RNG stream, reducing diversity and potential solution quality.
**Program Identifier:** Generation 13 - Patch Name beam_astar_delta_vns - Correct Program: False

**Program Name: A*-guided beam scheduler with local refinement**
- **Implementation**: Uses an A*-style marginal-cost beam search with shared cost/delta caches, lightweight lookahead, incumbent pruning, greedy completion, and a bounded local improvement phase (adjacent swaps and limited insertions) under a 0.60s per-workload time budget and deterministic multi-mode restarts. It also includes custom repository path discovery and sys.path injection to import the simulator and workloads.
- **Performance**: Combined score 0.0; the program is marked incorrect and fails validation tests.
- **Feedback**: Fragile import path discovery and strict time budgeting likely caused failures or fallback to low-quality/random schedules, leading to validation failure. The heuristic (max singleton as lower bound) and non-additive g-cost may misguide the beam/A* scoring, further hurting solution quality under tight time limits.
**Program Identifier:** Generation 14 - Patch Name astar_marginal_beam - Correct Program: False

**Program Name: Memoized Beam Search Transaction Scheduler**
- **Implementation**: Implements a time-bounded, dynamic-width beam search that ranks candidates by marginal cost with shallow lookahead, periodically greedily completes prefixes to tighten the incumbent, and deduplicates prefixes. Shared memoized cost caches span restarts, and a local improvement pass (adjacent swaps plus random insertions) refines the final sequence.
- **Performance**: Achieved a combined score of 2.48 across 3 workloads (300 transactions), passing all validation tests within the per-workload 0.55s budget.
- **Feedback**: Cache reuse and greedy completion reduce redundant evaluations and enable effective pruning under the tight time cap, improving schedule quality. Dynamic beam sizing and local refinement balance exploration and exploitation, though the strict 0.55s budget can limit the number of effective restarts on larger instances.
**Program Identifier:** Generation 15 - Patch Name precedence_guided_beam_with_lookahead_and_local_refine - Correct Program: True

**Program Name: Time-bounded memoized beam scheduler with local search**
- **Implementation**: Combines adaptive beam search with memoized marginal-cost evaluation and shallow lookahead under a strict time budget. Prefixes are greedily completed with incumbency pruning, then refined by adjacent swaps and sampled insertions across restarts.
- **Performance**: Achieved combined score 1.83 across 3 workloads (300 transactions); schedules are valid and all validation tests pass.
- **Feedback**: Caching of full sequence costs and prefix-extension pairs reduces simulator calls and enables near real-time search, yielding strong makespan within tight budgets. Randomized candidate sampling and restarts introduce variability but help escape local minima; ext_cost recomputes full costs rather than true deltas, which may cap scalability on larger N.
**Program Identifier:** Generation 16 - Patch Name beam_marginal_memo - Correct Program: True

**Program Name: Beam A*-guided Transaction Scheduler**
- **Implementation**: Implements beam search with A*-style lower bounds, marginal-cost ordering, shallow lookahead, and greedy multi-prefix completion; shared memoized cost/extension caches across restarts and precomputed singleton costs reduce evaluation overhead. A post-beam local-improvement phase (adjacent swaps, sliding-window insertions, bounded random insertions) refines schedules, with dynamic beam/branch sizing and a 0.55s/workload time budget.
- **Performance**: Combined score to maximize: 2.28; produced valid schedules for 3 workloads (300 transactions) within the time budget and passed all validation tests.
- **Feedback**: Lower-bound pruning plus memoization cut redundant evaluations and accelerate convergence, while sliding-window refinement improves makespan beyond greedy completion. Time-bounded restarts and incumbent tightening via greedy finishes yield robust results, with minor variability due to randomized sampling.
**Program Identifier:** Generation 17 - Patch Name a_star_lb_beam_and_window_local - Correct Program: True

**Program Name: Tournament-Guided Beam Search with VNS for Scheduling**
- **Implementation**: Builds a tournament preference matrix from memoized singleton/pairwise costs and runs a beam search with lookahead, tournament-based candidate preselection, diverse starts, and state deduplication. A VNS post-optimizer applies tournament bubble passes, adjacent swaps, sampled 2-opt, relocations, and ruin-and-recreate, leveraging caching to limit simulator calls.
- **Performance**: Achieved a combined score of 3.41 across 3 workloads (300 transactions), passing all validation tests.
- **Feedback**: Memoization and tournament-guided pruning effectively balance exploration and evaluation cost, yielding strong schedules with a modest beam width. Local VNS refinements reliably improve beam outputs; tuning beam and candidate parameters may further boost results on conflict-heavy workloads.
**Program Identifier:** Generation 18 - Patch Name tournament_guided_beam_vns - Correct Program: True

**Program Name: A*-Guided Beam Scheduler with Greedy Refinement**
- **Implementation**: Implements a time-budgeted A*-guided beam search using marginal-cost ordering, singleton lower-bound pruning, shallow lookahead, and shared memoized cost caches across restarts with dynamic beam/branch sizing. Beam prefixes are greedily completed to tighten the incumbent and then locally refined via adjacent swaps, insertions, and sparse long swaps.
- **Performance**: Achieved combined score 2.07 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Shared caches and LB pruning reduce cost evaluations and help maintain quality under the 0.55s/workload budget; dynamic beam/branching and periodic greedy completion quickly establish strong incumbents. Local refinement yields modest extra gains, but results remain somewhat sensitive to randomness and tight time limits.
**Program Identifier:** Generation 19 - Patch Name a_star_lb_prune_and_multi_finish - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

## Successful Algorithmic Patterns
- Tournament-guided candidate selection plus VNS refinement delivered the top score. Tournament-Guided Beam Search with VNS for Scheduling (3.41) precomputes singleton/pairwise true costs (M[i][j]) to form a preference matrix W and guides beam expansions with tournament preselection, then applies a VNS post-optimizer (tournament bubble, adjacent swaps, sampled 2-opt, relocations, ruin-and-recreate) using the same memoized evaluator. This outperformed prior memoized beam-only approaches (e.g., Memoized Beam Search Transaction Scheduler at 2.48).
- Memoized partial-cost evaluation remains the core enabler. The best program caches get_opt_seq_cost for all tested subsequences and reuses it across construction and local search. Similar memoization drove strong results in other correct programs: Memoized Beam Search Transaction Scheduler (2.48), A*-Guided Beam Scheduler with Greedy Refinement (2.07), and Time-bounded memoized beam scheduler with local search (1.83).
- Lightweight, bounded lookahead helps prune cheaply. The best program uses shallow lookahead over a small candidate pool (lookahead_top ~3, next_k ~5) to rank expansions, consistent with other successful implementations that combine shallow lookahead with greedy completion/pruning (e.g., A*-LB beam and window local at 2.28; Memoized Beam Search Transaction Scheduler at 2.48).
- Adaptive, diversity-aware beam construction. The best program seeds beam starts via tournament-best, a good singleton, and randomized distinct starts, prunes duplicate states using (prefix, remaining) keys, and uses moderate beam/candidate caps. This mirrors prior successful adaptive breadth patterns seen in correct, mid-to-high scorers (e.g., Preference-Guided Beam Search Scheduler at 2.04; Beam search scheduler with caching and refinement at 1.93).

## Ineffective Approaches
- Misapplied A* lower bounds and scoring led to failures. Several A*-guided beams were marked incorrect with 0.0 scores: A*-beam scheduler with memoized delta costs (Gen 12), A*-guided Beam + Local Search Scheduler (Gen 13), and A*-guided beam scheduler with local refinement (Gen 14). Feedback cites non-admissible/weak lower bounds (max-singleton LB, f=max(g,h)) and non-additive g-costs that misguide pruning.
- Brittle environment handling and nondeterminism broke correctness. The failing A*-guided programs included fragile repository path discovery/imports and time-salted RNG seeds, undermining determinism and portability, resulting in validation failures (0.0).
- Overly tight or misallocated compute can cap quality. Programs with stricter budgets or insufficient search depth/width underperformed relative to the best: Time-bounded memoized beam scheduler with local search (1.83) recomputes full costs on extensions instead of true deltas; Preference-Guided Beam Search Scheduler (2.04) hints deeper lookahead or broader restarts could help under the same time cap.

## Implementation Insights
- What makes the current best effective:
  - True-cost tournament guidance: It precomputes a full pairwise cost table M and derives W[i][j] = M[i][j] − M[j][i], using it to preselect candidates and drive a cheap tournament-bubble cleanup. This yields stronger and cheaper guidance than sampled/learned surrogates (cf. Preference-Guided Beam Search Scheduler at 2.04).
  - Unified memoized evaluator across phases: A single evaluate_seq cache serves beam expansion, lookahead scoring, and all local VNS moves, minimizing simulator calls and enabling a richer local neighborhood without blowing the time budget.
  - Bounded, diversified search: Uses modest beam widths (≈6–16), candidate-per-expand caps (≈6–14), shallow lookahead, and multiple diverse starts (tournament-best, good singleton, random). State deduplication with (prefix, remaining) keys focuses effort on unique partial schedules.
  - Structured VNS that scales with N: Starts with low-cost moves (adjacent swaps), then sampled 2-opt and relocations, and selectively applies ruin-and-recreate with bounded block sizes and tries. This layered design reliably improves the beam output (feedback: “Local VNS refinements reliably improve beam outputs”) without overwhelming the budget.
- Cross-program patterns with impact:
  - Shared caches across restarts/phases improve pruning and throughput (2.48, 2.07, 1.83), while recomputing full costs instead of deltas (1.83) limits scalability on larger N.
  - Lightweight lookahead and greedy/periodic completions tighten incumbents and reduce futile expansions (2.48, 2.28, 2.07).
  - Surrogate/precedence guidance is useful but peaks lower unless combined with true-cost search and post-optimization (2.04 vs 3.41).

## Performance Analysis
- The new best score (3.41) surpasses the prior top-tier memoized beam baseline (previously 3.40) by integrating tournament-guided preselection and a richer VNS. Compared to Memoized Beam Search Transaction Scheduler (2.48), the uplift underscores the value of combining surrogate pairwise guidance and deeper local neighborhoods with memoized true-cost evaluation.
- A*-guided variants that were correct scored lower than the best: A*-LB beam and window local (2.28) and A*-Guided Beam Scheduler with Greedy Refinement (2.07). This suggests the singleton-based LBs and A*-style scoring provided limited pruning benefit under tight budgets relative to tournament-guided beam with VNS, and heavier A* logic introduced overhead without commensurate gains.
- Preference/surrogate approaches improve over naive greedy but trail the best when not tightly coupled with true-cost exploration and refinement: Preference-Guided Beam Search Scheduler (2.04) and Beam search scheduler with caching and refinement (1.93) are clearly below the tournament-guided VNS (3.41).
- Failures cluster around A*-guided designs with brittle infrastructure and heuristic misuse (0.0 scores for Gens 12–14), reinforcing that stability and correctness safeguards are prerequisites. Correct programs consistently share memoization, bounded lookahead, adaptive beam widths, and either greedy completion or local improvement, achieving 1.83–3.41 within ~0.55–0.75s/workload.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

1. Add deterministic, multi-restart beam runs with a shared memoized cache across restarts
   - Run 2–3 short restarts of beam_search per workload, varying beam_width and cand_per_expand (e.g., [beam=16,cand=10], [12,14], [8,18]), then pick the best full schedule. Seed deterministically per workload (e.g., rng = random.Random(1729 + workload.num_txns)) and move cost_cache outside beam_search so it’s reused across restarts; optionally wrap it in an LRU with ~200k entries. Evidence: shared caches and structured restarts consistently improved breadth and robustness in top performers; nondeterminism hurt A*-style attempts.

2. Use W-guided surrogate prefiltering in VNS to expand neighborhoods without extra simulator calls
   - Before evaluating a swap or relocate, score the move with a cheap surrogate: estimate ΔW as the change in pairwise violation margins around the edited indices (using W). Only pass the top-k% (e.g., top 30–40%) surrogate-ranked moves in each VNS phase to evaluate_seq; keep a small random sample for diversity. Evidence: the best program’s tournament guidance (W) excelled during construction—extending it to filter local moves lets you try more candidates within the same budget.

3. Tighten incumbents early with periodic greedy completions and lightweight incumbent-based pruning
   - At each beam depth, greedily complete the top-1–2 prefixes using tournament_bubble_pass and W-ranked insertions to produce full sequences, update a global incumbent, and cache these costs. During expansion, skip adding child states whose immediate cost (evaluate_seq(seq+[t])) is already ≥ incumbent (monotone in this setting), keeping a safe fallback path if all candidates are pruned. Evidence: early incumbents reduced wasted exploration in multiple correct programs; cheap greedy completions plus safe pruning lift effective beam quality without A*-style fragility.

4. Introduce conflict-clustered blocks and block-aware moves guided by strong W edges
   - Build a precedence DAG from W with edges i→j when W[i][j] < −τ (e.g., τ = percentile 70 of |W|), extract clusters via connected components, and initialize beam starts with cluster-respecting orders. Add block-level moves to VNS: swap two small clusters, or relocate a contiguous block centered on the most violated boundary (where prefer_before fails with large |W|). Evidence: leveraging strong pairwise preferences as soft constraints improves both construction and local refinement and scales better than random block choices.

5. Depth- and conflict-adaptive lookahead with precomputed “buddy lists” from M/W
   - Precompute for each t a small buddy list B[t] of 5–8 transactions that pair best with t (e.g., smallest M[t][u] and/or most negative W[t][u]). In lookahead, expand L dynamically: L = 4–6 early (high branching) and shrink to 2 later, and choose u from B[t] ∩ remaining first before falling back to preselect_by_tournament. Evidence: lightweight, bounded lookahead helped prune cheaply; biasing the second step to high-synergy pairs from M/W should improve ranking accuracy without many extra simulator calls.