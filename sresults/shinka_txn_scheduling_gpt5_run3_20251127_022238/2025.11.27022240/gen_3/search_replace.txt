<NAME>
greedy_full_eval_beam_local
</NAME>
<DESCRIPTION>
I replaced the random-sampled greedy builder with a stronger multi-start approach that evaluates all remaining candidates at each step, adds a small lookahead tie-break to better anticipate conflicts, and then applies local improvement (adjacent swaps and random insertions). I also added memoization for sequence costs to avoid recomputing costs for identical partial schedules. This directly optimizes the makespan using workload.get_opt_seq_cost on partial and full sequences instead of relying on weak proxies like transaction length or sampling noise. The net effect is:
- Better construction: full evaluation ensures the next choice is the globally best immediate extension, with lookahead to mitigate myopic decisions.
- Diversification: multiple randomized restarts using good singleton starts.
- Intensification: local search refinements to escape construction-order biases.
- Efficiency: caching reduces redundant cost evaluations.

These changes remain within the original interface, respect performance constraints by limiting lookahead and local search attempts, and should yield lower makespan schedules across workloads without introducing new dependencies.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using greedy cost sampling strategy.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    def get_greedy_cost_sampled(num_samples, sample_rate):
        # greedy with random starting point
        start_txn = random.randint(0, workload.num_txns - 1)
        txn_seq = [start_txn]
        remaining_txns = [x for x in range(0, workload.num_txns)]
        remaining_txns.remove(start_txn)
        running_cost = workload.txns[start_txn][0][3]

        for i in range(0, workload.num_txns - 1):
            min_cost = 100000  # MAX
            min_relative_cost = 10
            min_txn = -1
            holdout_txns = []
            done = False
            key_maps = []

            sample = random.random()
            if sample > sample_rate:
                idx = random.randint(0, len(remaining_txns) - 1)
                t = remaining_txns[idx]
                txn_seq.append(t)
                remaining_txns.pop(idx)
                continue

            for j in range(0, num_samples):
                idx = 0
                if len(remaining_txns) > 1:
                    idx = random.randint(0, len(remaining_txns) - 1)
                else:
                    done = True
                t = remaining_txns[idx]
                holdout_txns.append(remaining_txns.pop(idx))

                txn_len = workload.txns[t][0][3]
                test_seq = txn_seq.copy()
                test_seq.append(t)
                cost = 0
                cost = workload.get_opt_seq_cost(test_seq)
                if cost < min_cost:
                    min_cost = cost
                    min_txn = t
                if done:
                    break
            assert(min_txn != -1)
            running_cost = min_cost
            txn_seq.append(min_txn)
            holdout_txns.remove(min_txn)
            remaining_txns.extend(holdout_txns)

        assert len(set(txn_seq)) == workload.num_txns

        overall_cost = workload.get_opt_seq_cost(txn_seq)
        return overall_cost, txn_seq

    return get_greedy_cost_sampled(10, 1.0)
=======
def get_best_schedule(workload, num_seqs):
    """
    Enhanced multi-start greedy with full-evaluation, limited lookahead, and local improvement.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of randomized restarts to attempt

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    n = workload.num_txns
    best_cost = float('inf')
    best_seq = None

    # Memoization for sequence costs to avoid recomputation
    cost_cache = {}

    def seq_cost(seq):
        key = tuple(seq)
        if key in cost_cache:
            return cost_cache[key]
        c = workload.get_opt_seq_cost(seq)
        cost_cache[key] = c
        return c

    # Precompute singleton costs to seed better starting points
    singleton_costs = [(t, seq_cost([t])) for t in range(n)]
    singleton_costs.sort(key=lambda x: x[1])

    restarts = max(1, int(num_seqs))

    for r in range(restarts):
        # Diversify starts: use a good singleton with randomness, then random fallback
        if r < min(5, n):
            k = min(10, n)
            t0 = random.choice([t for t, _ in singleton_costs[:k]])
        else:
            t0 = random.randint(0, n - 1)

        seq = [t0]
        remaining = [t for t in range(n) if t != t0]

        # Greedy build: evaluate all candidates and use small lookahead to break ties
        while remaining:
            cand_costs = []
            base = seq
            for t in remaining:
                c = seq_cost(base + [t])
                cand_costs.append((t, c))
            cand_costs.sort(key=lambda x: x[1])

            # Consider top L candidates for lookahead
            L = min(3, len(cand_costs))
            top_cands = cand_costs[:L]

            chosen_t = top_cands[0][0]
            best_pair_cost = None
            lookahead_samples = 6 if n <= 60 else 4
            for t, immediate_c in top_cands:
                if len(remaining) == 1:
                    la_cost = immediate_c
                else:
                    next_pool = [x for x in remaining if x != t]
                    if len(next_pool) <= lookahead_samples:
                        sampled_next = next_pool
                    else:
                        sampled_next = random.sample(next_pool, lookahead_samples)
                    la_cost = min(seq_cost(base + [t, u]) for u in sampled_next)
                if best_pair_cost is None or la_cost < best_pair_cost:
                    best_pair_cost = la_cost
                    chosen_t = t

            seq.append(chosen_t)
            remaining.remove(chosen_t)

        # Local improvement phase
        current_cost = seq_cost(seq)

        # 1) Adjacent swap hill-climb passes
        for _ in range(2):
            any_improve = False
            for i in range(n - 1):
                seq[i], seq[i + 1] = seq[i + 1], seq[i]
                c = seq_cost(seq)
                if c < current_cost:
                    current_cost = c
                    any_improve = True
                else:
                    # revert if no improvement
                    seq[i], seq[i + 1] = seq[i + 1], seq[i]
            if not any_improve:
                break

        # 2) Random insertion improvements with accept-if-better
        attempts = min(150, 3 * n)
        for _ in range(attempts):
            i = random.randint(0, n - 1)
            j = random.randint(0, n - 1)
            if i == j:
                continue
            t = seq.pop(i)
            seq.insert(j, t)
            c = seq_cost(seq)
            if c < current_cost:
                current_cost = c
            else:
                # revert
                seq.pop(j)
                seq.insert(i, t)

        if current_cost < best_cost:
            best_cost = current_cost
            best_seq = seq[:]

    return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>