<NAME>
two_phase_beam_domlns
</NAME>

<DESCRIPTION>
I introduce three targeted enhancements to reduce makespan by aligning search with true conflict-induced delays while keeping evaluations bounded:

1) Global prefix-dominance across constructors (dom_global):
   - Maintain a shared dominance map dom_global[(frozenset(remaining), tuple(prefix[-3:]))] → best partial cost seen. Skip expansions that cannot beat the best known for the same signature in both the greedy builder and the beam search. This prevents redundant exploration of dominated prefixes and reduces simulator calls.

2) Safe, incumbent-pruned two-phase beam:
   - Phase A (broad): similar to current beam but with shared dominance and tournament/buddy guidance to depth ~0.4n, updating a global incumbent via greedy completions.
   - Phase B (focused): narrow beam for 2–3 more steps; for each expanded child, greedily complete and prune any child whose full cost ≥ incumbent, yet keep the best child per parent to guarantee progress. This finds higher-quality prefixes with safe pruning guided by full sequence bounds.

3) Strengthened LNS with block neighborhoods and anti-buddy filtering:
   - Add block-swap and block-reinsert neighborhoods centered on worst violated adjacencies (by M[a][b]-M[b][a]). Rank candidates cheaply and evaluate only a capped subset per iteration.
   - In the greedy constructor, apply anti-buddy filtering: deprioritize candidates that the last placed transaction strongly “dislikes” (top-quartile W[last][t]), unless they are clearly best. This reduces placing harmful adjacencies that inflate conflicts.

Together these changes improve schedule quality with minimal overhead by steering the search away from dominated prefixes, safely pruning with a strong incumbent, and applying focused non-local moves where conflicts hurt most.

</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Global cache for sequence costs
    cost_cache = {}

    def eval_seq(seq):
=======
    # Global cache for sequence costs
    cost_cache = {}
    # Global prefix-dominance map shared across constructors
    dom_global = {}

    def sig_key(seq, remaining, suffix=3):
        suf = tuple(seq[-suffix:]) if len(seq) >= suffix else tuple(seq)
        return (frozenset(remaining), suf)

    def eval_seq(seq):
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def build_initial_sequence():
        pool_size = max(10, min(16, 3 + n // 8))
        reevaluate_every = 10  # refresh pool globally at intervals

        # Seed starting txn: choose among tournament-best and good singletons
        candidate_seeds = set()
        candidate_seeds.add(tournament_order[0])
        topk = min(10, n)
        for t, _ in sorted(enumerate(c1), key=lambda x: x[1])[:topk]:
            candidate_seeds.add(t)
        if len(candidate_seeds) < 3:
            candidate_seeds.update(rng.sample(range(n), min(3, n)))
        best_seed = min(candidate_seeds, key=lambda s: eval_seq([s]))

        seq = [best_seed]
        remaining = set(range(n))
        remaining.remove(best_seed)

        pool = set()

        def refresh_pool_full():
            nonlocal pool
            if len(remaining) <= pool_size * 2:
                cand_list = [(t, eval_seq(seq + [t])) for t in remaining]
                cand_list.sort(key=lambda x: x[1])
                pool = set([t for t, _ in cand_list[:pool_size]])
            else:
                # Tournament-guided preselection using W against recent prefix
                pre = preselect_by_tournament(seq, list(remaining), min(pool_size * 2, len(remaining)))
                cand_list = [(t, eval_seq(seq + [t])) for t in pre]
                cand_list.sort(key=lambda x: x[1])
                pool = set([t for t, _ in cand_list[:pool_size]])

        def top_pool_candidates():
            cand_list = [(t, eval_seq(seq + [t])) for t in list(pool)]
            cand_list.sort(key=lambda x: x[1])
            return cand_list

        # Initialize pool
        refresh_pool_full()

        step = 0
        while remaining:
            # Incumbent pruning against best seed so far (if available)
            try:
                if seed_best_cost < float('inf'):
                    base_cost = eval_seq(seq)
                    if base_cost >= seed_best_cost:
                        # Complete cheaply by immediate best to terminate early
                        rest = list(remaining)
                        rest.sort(key=lambda t: eval_seq(seq + [t]))
                        seq.extend(rest)
                        remaining.clear()
                        break
            except NameError:
                # seed_best_cost not yet defined in first call
                pass

            if step % reevaluate_every == 0:
                refresh_pool_full()
            else:
                while len(pool) < pool_size and remaining:
                    choices = list(remaining - pool)
                    if not choices:
                        break
                    # bias by tournament preference for diversity with guidance
                    add = preselect_by_tournament(seq, choices, 1) or [rng.choice(choices)]
                    pool.add(add[0])

            cand_list = top_pool_candidates()
            if not cand_list:
                pick = rng.choice(list(remaining))
                seq.append(pick)
                remaining.remove(pick)
                step += 1
                continue

            # Lookahead over top few with buddy-prioritized second step
            L = min(4, len(cand_list))
            best_t = cand_list[0][0]
            best_metric = cand_list[0][1]
            for t, immediate_c in cand_list[:L]:
                nexts = list(remaining - {t})
                if not nexts:
                    metric = immediate_c
                else:
                    # build la_pool = buddies ∩ nexts, then fill by tournament preference
                    buddy_pref = [u for u in buddies[t] if u in nexts]
                    need = 6 if n > 60 else 8
                    la_pool = buddy_pref[:need]
                    if len(la_pool) < need:
                        extra = preselect_by_tournament(seq + [t], [u for u in nexts if u not in la_pool], need - len(la_pool), recent_k=3)
                        la_pool.extend(extra)
                    if not la_pool:
                        la_pool = nexts[:min(need, len(nexts))]
                    metric = min(eval_seq(seq + [t, u]) for u in la_pool)
                if metric < best_metric:
                    best_metric = metric
                    best_t = t

            seq.append(best_t)
            remaining.remove(best_t)
            if best_t in pool:
                pool.remove(best_t)
            step += 1

        return seq
=======
    def build_initial_sequence():
        pool_size = max(10, min(16, 3 + n // 8))
        reevaluate_every = 10  # refresh pool globally at intervals

        # Seed starting txn: choose among tournament-best and good singletons
        candidate_seeds = set()
        candidate_seeds.add(tournament_order[0])
        topk = min(10, n)
        for t, _ in sorted(enumerate(c1), key=lambda x: x[1])[:topk]:
            candidate_seeds.add(t)
        if len(candidate_seeds) < 3:
            candidate_seeds.update(rng.sample(range(n), min(3, n)))
        best_seed = min(candidate_seeds, key=lambda s: eval_seq([s]))

        seq = [best_seed]
        remaining = set(range(n))
        remaining.remove(best_seed)
        # Register initial signature in dominance map
        dom_global[sig_key(seq, remaining)] = eval_seq(seq)

        pool = set()

        def refresh_pool_full():
            nonlocal pool
            new_pool = []
            if len(remaining) <= pool_size * 2:
                cand = list(remaining)
            else:
                # Tournament-guided preselection using W against recent prefix
                cand = preselect_by_tournament(seq, list(remaining), min(pool_size * 2, len(remaining)))
            for t in cand:
                rem_after = set(remaining)
                rem_after.remove(t)
                c_im = eval_seq(seq + [t])
                sig = sig_key(seq + [t], rem_after)
                # Dominance pruning
                if sig in dom_global and c_im >= dom_global[sig]:
                    continue
                new_pool.append((t, c_im, rem_after, sig))
            new_pool.sort(key=lambda x: x[1])
            pool = set([t for t, _, _, _ in new_pool[:pool_size]])

        def top_pool_candidates():
            # Return sorted immediate candidates; anti-buddy filter applied later
            cand_list = []
            for t in list(pool):
                rem_after = set(remaining)
                if t not in rem_after:
                    continue
                rem_after.remove(t)
                c_im = eval_seq(seq + [t])
                cand_list.append((t, c_im, rem_after))
            cand_list.sort(key=lambda x: x[1])
            return cand_list

        # Initialize pool
        refresh_pool_full()

        step = 0
        while remaining:
            # Incumbent pruning against best seed so far (if available)
            if inc['cost'] < float('inf'):
                base_cost = eval_seq(seq)
                if base_cost >= inc['cost']:
                    # Complete cheaply by immediate best to terminate early
                    rest = list(remaining)
                    rest.sort(key=lambda t: eval_seq(seq + [t]))
                    seq.extend(rest)
                    remaining.clear()
                    break

            if step % reevaluate_every == 0:
                refresh_pool_full()
            else:
                while len(pool) < pool_size and remaining:
                    choices = list(remaining - pool)
                    if not choices:
                        break
                    # bias by tournament preference with dominance guard
                    guided = preselect_by_tournament(seq, choices, 1)
                    t_add = guided[0] if guided else rng.choice(choices)
                    rem_after = set(remaining)
                    rem_after.remove(t_add)
                    c_im = eval_seq(seq + [t_add])
                    if (sig_key(seq + [t_add], rem_after) in dom_global and
                        c_im >= dom_global[sig_key(seq + [t_add], rem_after)]):
                        # skip dominated candidate
                        # try one random alternative
                        alt_choices = [x for x in choices if x != t_add]
                        if alt_choices:
                            t_add = rng.choice(alt_choices)
                    pool.add(t_add)

            cand_list = top_pool_candidates()
            if not cand_list:
                pick = rng.choice(list(remaining))
                seq.append(pick)
                remaining.remove(pick)
                dom_global[sig_key(seq, remaining)] = eval_seq(seq)
                step += 1
                continue

            # Anti-buddy filtering: penalize strongly disliked next txns by last placed
            last = seq[-1]
            row = [(t, W[last][t]) for t, _, _ in cand_list if t != last]
            pos_sorted = sorted([t for t, w in row if w > 0], key=lambda t: W[last][t], reverse=True)
            q = max(1, len(pos_sorted) // 4)
            disliked = set(pos_sorted[:q])

            best_immediate = cand_list[0][1]
            adjusted = []
            for t, c_im, rem_after in cand_list:
                penalized = c_im
                if t in disliked and c_im > best_immediate * 0.99:
                    penalized = c_im * 1.02  # mild penalty unless clearly best
                adjusted.append((penalized, c_im, t, rem_after))
            adjusted.sort(key=lambda z: (z[0], z[1], z[2]))

            # Lookahead over top few with buddy-prioritized second step
            L = min(4, len(adjusted))
            best_t = adjusted[0][2]
            best_metric = adjusted[0][1]
            for k_idx in range(L):
                t = adjusted[k_idx][2]
                immediate_c = adjusted[k_idx][1]
                nexts = list(remaining - {t})
                if not nexts:
                    metric = immediate_c
                else:
                    # build la_pool = buddies ∩ nexts, then fill by tournament preference
                    buddy_pref = [u for u in buddies[t] if u in nexts]
                    need = 6 if n > 60 else 8
                    la_pool = buddy_pref[:need]
                    if len(la_pool) < need:
                        extra = preselect_by_tournament(seq + [t], [u for u in nexts if u not in la_pool], need - len(la_pool), recent_k=3)
                        la_pool.extend(extra)
                    if not la_pool:
                        la_pool = nexts[:min(need, len(nexts))]
                    metric = min(eval_seq(seq + [t, u]) for u in la_pool)
                if metric < best_metric:
                    best_metric = metric
                    best_t = t

            seq.append(best_t)
            remaining.remove(best_t)
            # Update dominance info for the new prefix
            dom_global[sig_key(seq, remaining)] = eval_seq(seq)
            if best_t in pool:
                pool.remove(best_t)
            step += 1

        return seq
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def lns_improve(seq, base_cost, budget_factor):
        best_seq = seq[:]
        best_cost = base_cost
        n_local = len(best_seq)

        # Iterations scale mildly with budget_factor and n
        iters = max(4, min(10, 2 + int(budget_factor) + n_local // 40))
        max_k = 7 if n_local >= 40 else 6

        for it in range(iters):
            # Compute marginals to locate hot regions
            _, marg = prefix_marginals(best_seq)

            # Choose window size
            k = max_k if it < 2 else rng.randint(4, max_k)
            if n_local <= k:
                break

            # Find top windows by marginal sum (sliding window)
            sums = []
            window_sum = sum(marg[0:k])
            sums.append((0, window_sum))
            for s in range(1, n_local - k + 1):
                window_sum += marg[s + k - 1] - marg[s - 1]
                sums.append((s, window_sum))
            sums.sort(key=lambda x: -x[1])

            # Also consider windows around worst violated adjacencies
            viol_starts = worst_violation_boundaries(best_seq, topm=3)
            candidate_starts = []
            for v in viol_starts:
                start = max(0, min(v - (k // 2), n_local - k))
                candidate_starts.append(start)
            candidate_starts.extend([start for start, _ in sums[:2]])
            # Deduplicate while preserving order
            seen_starts = set()
            ordered_starts = []
            for st in candidate_starts:
                if st not in seen_starts:
                    seen_starts.add(st)
                    ordered_starts.append(st)

            tried_any = False
            for start in ordered_starts:
                block = best_seq[start : start + k]
                base = best_seq[:start] + best_seq[start + k :]

                # Determine permutation budget
                factorial = 1
                for i in range(2, k + 1):
                    factorial *= i
                # Cap permutations to keep time in check
                if k <= 6:
                    perm_budget = min(720, factorial)
                else:
                    perm_budget = 2000  # sample for k=7

                perm_best_seq = None
                perm_best_cost = best_cost

                if factorial <= perm_budget:
                    for p in itertools.permutations(block):
                        cand_seq = base[:start] + list(p) + base[start:]
                        c = eval_seq(cand_seq)
                        if c < perm_best_cost:
                            perm_best_cost = c
                            perm_best_seq = cand_seq
                else:
                    seenp = set()
                    attempts = 0
                    while attempts < perm_budget:
                        p = tuple(rng.sample(block, k))
                        if p in seenp:
                            continue
                        seenp.add(p)
                        cand_seq = base[:start] + list(p) + base[start:]
                        c = eval_seq(cand_seq)
                        if c < perm_best_cost:
                            perm_best_cost = c
                            perm_best_seq = cand_seq
                        attempts += 1

                if perm_best_seq is not None and perm_best_cost < best_cost:
                    best_seq = perm_best_seq
                    best_cost = perm_best_cost
                    tried_any = True
                    break  # accept first improving window

            # Targeted relocate moves for top-blame transactions
            _, marg = prefix_marginals(best_seq)
            positions = sorted(range(n_local), key=lambda i: marg[i], reverse=True)[:3]
            for pos in positions:
                if pos >= len(best_seq):
                    continue
                t = best_seq[pos]
                base = best_seq[:pos] + best_seq[pos + 1 :]
                best_pos_cost = best_cost
                best_pos_idx = None
                positions_try = set([0, len(base)])
                for _ in range(8):
                    positions_try.add(rng.randint(0, len(base)))
                for j in positions_try:
                    cand = base[:j] + [t] + base[j:]
                    c = eval_seq(cand)
                    if c < best_pos_cost:
                        best_pos_cost = c
                        best_pos_idx = j
                if best_pos_idx is not None and best_pos_cost < best_cost:
                    best_seq = base[:best_pos_idx] + [t] + base[best_pos_idx:]
                    best_cost = best_pos_cost

            if not tried_any:
                continue

        return best_seq, best_cost
=======
    def lns_improve(seq, base_cost, budget_factor):
        best_seq = seq[:]
        best_cost = base_cost
        n_local = len(best_seq)

        # Iterations scale mildly with budget_factor and n
        iters = max(4, min(10, 2 + int(budget_factor) + n_local // 40))
        max_k = 7 if n_local >= 40 else 6

        def boundary_penalty(arr, i):
            a, b = arr[i], arr[i + 1]
            return M[a][b] - M[b][a]

        for it in range(iters):
            # Compute marginals to locate hot regions
            _, marg = prefix_marginals(best_seq)

            # Choose window size
            k = max_k if it < 2 else rng.randint(4, max_k)
            if n_local <= k:
                break

            # Find top windows by marginal sum (sliding window)
            sums = []
            window_sum = sum(marg[0:k])
            sums.append((0, window_sum))
            for s in range(1, n_local - k + 1):
                window_sum += marg[s + k - 1] - marg[s - 1]
                sums.append((s, window_sum))
            sums.sort(key=lambda x: -x[1])

            # Also consider windows around worst violated adjacencies
            viol_starts = worst_violation_boundaries(best_seq, topm=3)
            candidate_starts = []
            for v in viol_starts:
                start = max(0, min(v - (k // 2), n_local - k))
                candidate_starts.append(start)
            candidate_starts.extend([start for start, _ in sums[:2]])
            # Deduplicate while preserving order
            seen_starts = set()
            ordered_starts = []
            for st in candidate_starts:
                if st not in seen_starts:
                    seen_starts.add(st)
                    ordered_starts.append(st)

            tried_any = False
            for start in ordered_starts:
                block = best_seq[start : start + k]
                base = best_seq[:start] + best_seq[start + k :]

                # Determine permutation budget
                factorial = 1
                for i in range(2, k + 1):
                    factorial *= i
                # Cap permutations to keep time in check
                if k <= 6:
                    perm_budget = min(720, factorial)
                else:
                    perm_budget = 2000  # sample for k=7

                perm_best_seq = None
                perm_best_cost = best_cost

                if factorial <= perm_budget:
                    for p in itertools.permutations(block):
                        cand_seq = base[:start] + list(p) + base[start:]
                        c = eval_seq(cand_seq)
                        if c < perm_best_cost:
                            perm_best_cost = c
                            perm_best_seq = cand_seq
                else:
                    seenp = set()
                    attempts = 0
                    while attempts < perm_budget:
                        p = tuple(rng.sample(block, k))
                        if p in seenp:
                            continue
                        seenp.add(p)
                        cand_seq = base[:start] + list(p) + base[start:]
                        c = eval_seq(cand_seq)
                        if c < perm_best_cost:
                            perm_best_cost = c
                            perm_best_seq = cand_seq
                        attempts += 1

                if perm_best_seq is not None and perm_best_cost < best_cost:
                    best_seq = perm_best_seq
                    best_cost = perm_best_cost
                    tried_any = True
                    break  # accept first improving window

            # Targeted relocate moves for top-blame transactions
            _, marg = prefix_marginals(best_seq)
            positions = sorted(range(n_local), key=lambda i: marg[i], reverse=True)[:3]
            for pos in positions:
                if pos >= len(best_seq):
                    continue
                t = best_seq[pos]
                base = best_seq[:pos] + best_seq[pos + 1 :]
                best_pos_cost = best_cost
                best_pos_idx = None
                positions_try = set([0, len(base)])
                for _ in range(8):
                    positions_try.add(rng.randint(0, len(base)))
                for j in positions_try:
                    cand = base[:j] + [t] + base[j:]
                    c = eval_seq(cand)
                    if c < best_pos_cost:
                        best_pos_cost = c
                        best_pos_idx = j
                if best_pos_idx is not None and best_pos_cost < best_cost:
                    best_seq = base[:best_pos_idx] + [t] + base[best_pos_idx:]
                    best_cost = best_pos_cost

            # Additional neighborhoods: block-swap and block-reinsert around bad boundaries
            eval_budget = 200  # cap evals per iteration for these neighborhoods
            evals_used = 0

            # Identify worst boundaries
            boundary_idxs = worst_violation_boundaries(best_seq, topm=2)
            # Block-swap: try swapping two blocks near worst boundaries
            if len(boundary_idxs) >= 1 and evals_used < eval_budget:
                bs_candidates = []
                for b in boundary_idxs:
                    size1 = rng.randint(3, min(6, max(3, n_local // 10)))
                    start1 = max(0, min(b - size1 // 2, n_local - size1))
                    end1 = start1 + size1
                    # choose second block
                    for _ in range(2):
                        b2 = boundary_idxs[-1] if len(boundary_idxs) > 1 else rng.randint(0, n_local - 2)
                        size2 = size1
                        start2 = max(0, min(b2 - size2 // 2, n_local - size2))
                        end2 = start2 + size2
                        if end1 <= start2 or end2 <= start1:
                            bs_candidates.append((start1, end1, start2, end2))
                # Dedup and limit
                seen_bs = set()
                pruned = []
                for cnd in bs_candidates:
                    if cnd not in seen_bs:
                        seen_bs.add(cnd)
                        pruned.append(cnd)
                pruned = pruned[:6]
                for start1, end1, start2, end2 in pruned:
                    cand = best_seq[:]
                    block1 = cand[start1:end1]
                    block2 = cand[start2:end2]
                    # place block2 at start1, block1 at start2 (adjust indices if start2 > start1)
                    if start2 > start1:
                        cand = cand[:start1] + block2 + cand[end1:start2] + block1 + cand[end2:]
                    else:
                        cand = cand[:start2] + block1 + cand[end2:start1] + block2 + cand[end1:]
                    c = eval_seq(cand)
                    evals_used += 1
                    if c < best_cost:
                        best_seq, best_cost = cand, c
                        tried_any = True
                        break
                if tried_any:
                    pass

            # Block-reinsert: remove a hot block and reinsert at strategic positions
            if evals_used < eval_budget and n_local > 12:
                size = rng.randint(4, min(6, max(4, n_local // 12)))
                if boundary_idxs:
                    center = boundary_idxs[0]
                else:
                    center = rng.randint(0, n_local - 2)
                start = max(0, min(center - size // 2, n_local - size))
                end = start + size
                block = best_seq[start:end]
                base = best_seq[:start] + best_seq[end:]
                # Try ends and few random positions
                positions_try = {0, len(base)}
                while len(positions_try) < 6:
                    positions_try.add(rng.randint(0, len(base)))
                # Rank by surrogate: sum of boundary penalties at insertion boundaries
                scored_pos = []
                for pos in positions_try:
                    left = base[pos - 1] if pos - 1 >= 0 else None
                    right = base[pos] if pos < len(base) else None
                    # crude surrogate using M's margins
                    sur = 0
                    if left is not None:
                        sur += sum(M[left][x] - M[x][left] for x in block) / len(block)
                    if right is not None:
                        sur += sum(M[x][right] - M[right][x] for x in block) / len(block)
                    scored_pos.append((sur, pos))
                scored_pos.sort(key=lambda x: x[0])
                for _, pos in scored_pos[:4]:
                    cand = base[:pos] + block + base[pos:]
                    c = eval_seq(cand)
                    evals_used += 1
                    if c < best_cost:
                        best_seq, best_cost = cand, c
                        tried_any = True
                        break

            if not tried_any:
                continue

        return best_seq, best_cost
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def beam_seed(inc=None):
        beam_width = max(6, min(16, int(num_seqs)))
        cand_per_expand = max(6, min(12, n // 7 + 6))
        lookahead_top = 3
        next_k = 5
        depth_limit = max(3, int(0.4 * n))

        # Starts: tournament-best, a good singleton, then randoms
        starts = []
        starts.append(tournament_order[0])
        topk = min(10, n)
        singles_sorted = sorted(range(n), key=lambda t: c1[t])[:topk]
        starts.append(rng.choice(singles_sorted))
        remcands = [t for t in range(n) if t not in starts]
        rng.shuffle(remcands)
        starts.extend(remcands[:max(0, beam_width - len(starts))])

        beam = []
        dom = {}  # prefix-dominance: (remaining_fset, suffix<=3) -> best cost
        for t in starts:
            seq = [t]
            rem = frozenset(set(range(n)) - {t})
            cost = eval_seq(seq)
            sig = (rem, tuple(seq[-1:]))
            if sig in dom and cost >= dom[sig]:
                continue
            dom[sig] = cost
            beam.append((cost, seq, rem))

        incumbent_cost = inc if inc is not None else float('inf')
        incumbent_seq = None

        depth = 1
        while depth < min(depth_limit, n) and beam:
            next_beam = []
            local_seen = set()
            for cost, seq, rem in beam:
                rem_list = list(rem)
                if not rem_list:
                    next_beam.append((cost, seq, rem))
                    continue

                # Tournament-guided preselection
                if len(rem_list) > cand_per_expand * 2:
                    pre = preselect_by_tournament(seq, rem_list, cand_per_expand * 2)
                else:
                    pre = rem_list

                # Immediate costs
                imm = [(t, eval_seq(seq + [t])) for t in pre]
                imm.sort(key=lambda z: z[1])

                # Buddy-biased lookahead on top-L
                L = min(lookahead_top, len(imm))
                scored = []
                for t, imc in imm[:L]:
                    nexts = [u for u in rem_list if u != t]
                    if not nexts:
                        la = imc
                    else:
                        buddy_pref = [u for u in buddies[t] if u in nexts]
                        pool = buddy_pref[:next_k]
                        if len(pool) < next_k:
                            extra = preselect_by_tournament(seq + [t], [u for u in nexts if u not in pool], next_k - len(pool), recent_k=3)
                            pool.extend(extra)
                        if not pool:
                            pool = nexts[:min(next_k, len(nexts))]
                        la = min(eval_seq(seq + [t, u]) for u in pool)
                    scored.append((t, min(imc, la)))

                # Add a few immediate-best without lookahead for diversity
                diversity = min(max(2, cand_per_expand // 3), len(imm))
                for t, imc in imm[:diversity]:
                    scored.append((t, imc))

                # Unique by child and keep best-k
                uniq = {}
                for t, m in scored:
                    if (t not in uniq) or (m < uniq[t]):
                        uniq[t] = m
                items = sorted(uniq.items(), key=lambda z: z[1])
                take = min(cand_per_expand, len(items))
                for t, _ in items[:take]:
                    new_seq = seq + [t]
                    new_rem = rem - {t}
                    new_cost = eval_seq(new_seq)
                    sig = (new_rem, tuple(new_seq[-3:]) if len(new_seq) >= 3 else tuple(new_seq))
                    if sig in dom and new_cost >= dom[sig]:
                        continue
                    dom[sig] = new_cost
                    key = (tuple(new_seq), new_rem)
                    if key in local_seen:
                        continue
                    local_seen.add(key)
                    next_beam.append((new_cost, new_seq, new_rem))

            if not next_beam:
                break

            # Update incumbent by greedily completing top prefixes
            next_beam.sort(key=lambda x: x[0])
            for bc, bseq, brem in next_beam[:2]:
                if incumbent_cost < float('inf') and bc >= incumbent_cost:
                    continue
                full, fc = greedy_complete(bseq)
                if fc < incumbent_cost:
                    incumbent_cost = fc
                    incumbent_seq = full

            # Keep the beam
            beam = next_beam[:beam_width]
            depth += 1

        # Choose best prefix and complete greedily
        if not beam:
            t = rng.randint(0, n - 1)
            full, fc = greedy_complete([t])
            return full, fc
        beam.sort(key=lambda x: x[0])
        _, bseq, _ = beam[0]
        full, fc = greedy_complete(bseq)
        if incumbent_seq is not None and incumbent_cost < fc:
            return incumbent_seq, incumbent_cost
        return full, fc
=======
    def beam_seed(inc=None):
        # Phase A (broad): explore to ~0.4n with tournament/buddy guidance
        beam_width = max(6, min(16, int(num_seqs)))
        cand_per_expand = max(6, min(12, n // 7 + 6))
        lookahead_top = 3
        next_k = 5
        depth_limit_a = max(3, int(0.4 * n))

        # Starts: tournament-best, a good singleton, then randoms
        starts = []
        starts.append(tournament_order[0])
        topk = min(10, n)
        singles_sorted = sorted(range(n), key=lambda t: c1[t])[:topk]
        starts.append(rng.choice(singles_sorted))
        remcands = [t for t in range(n) if t not in starts]
        rng.shuffle(remcands)
        starts.extend(remcands[:max(0, beam_width - len(starts))])

        beam = []
        dom_local = {}  # local dominance: (remaining_fset, suffix<=3) -> best cost
        for t in starts:
            seq = [t]
            rem = frozenset(set(range(n)) - {t})
            cost = eval_seq(seq)
            sig = (rem, tuple(seq[-1:]))
            if sig in dom_local and cost >= dom_local[sig]:
                continue
            dom_local[sig] = cost
            # consult global dominance too
            gsig = sig_key(seq, rem)
            if gsig in dom_global and cost >= dom_global[gsig]:
                continue
            dom_global[gsig] = cost
            beam.append((cost, seq, rem))

        incumbent_cost = inc['cost'] if (inc is not None and inc.get('cost', float('inf')) < float('inf')) else float('inf')
        incumbent_seq = inc.get('seq') if inc is not None else None

        depth = 1
        while depth < min(depth_limit_a, n) and beam:
            next_beam = []
            local_seen = set()
            for cost, seq, rem in beam:
                rem_list = list(rem)
                if not rem_list:
                    next_beam.append((cost, seq, rem))
                    continue

                # Tournament-guided preselection
                if len(rem_list) > cand_per_expand * 2:
                    pre = preselect_by_tournament(seq, rem_list, cand_per_expand * 2)
                else:
                    pre = rem_list

                # Immediate costs
                imm = [(t, eval_seq(seq + [t])) for t in pre]
                imm.sort(key=lambda z: z[1])

                # Buddy-biased lookahead on top-L
                L = min(lookahead_top, len(imm))
                scored = []
                for t, imc in imm[:L]:
                    nexts = [u for u in rem_list if u != t]
                    if not nexts:
                        la = imc
                    else:
                        buddy_pref = [u for u in buddies[t] if u in nexts]
                        pool = buddy_pref[:next_k]
                        if len(pool) < next_k:
                            extra = preselect_by_tournament(seq + [t], [u for u in nexts if u not in pool], next_k - len(pool), recent_k=3)
                            pool.extend(extra)
                        if not pool:
                            pool = nexts[:min(next_k, len(nexts))]
                        la = min(eval_seq(seq + [t, u]) for u in pool)
                    scored.append((t, min(imc, la)))

                # Also add a few immediate-best without lookahead for diversity
                diversity = min(max(2, cand_per_expand // 3), len(imm))
                for t, imc in imm[:diversity]:
                    scored.append((t, imc))

                # Unique by child and keep best-k
                uniq = {}
                for t, m in scored:
                    if (t not in uniq) or (m < uniq[t]):
                        uniq[t] = m
                items = sorted(uniq.items(), key=lambda z: z[1])
                take = min(cand_per_expand, len(items))
                for t, _ in items[:take]:
                    new_seq = seq + [t]
                    new_rem = rem - {t}
                    new_cost = eval_seq(new_seq)
                    sig = (new_rem, tuple(new_seq[-3:]) if len(new_seq) >= 3 else tuple(new_seq))
                    if sig in dom_local and new_cost >= dom_local[sig]:
                        continue
                    dom_local[sig] = new_cost
                    gsig = sig_key(new_seq, new_rem)
                    if gsig in dom_global and new_cost >= dom_global[gsig]:
                        continue
                    dom_global[gsig] = new_cost
                    key = (tuple(new_seq), new_rem)
                    if key in local_seen:
                        continue
                    local_seen.add(key)
                    next_beam.append((new_cost, new_seq, new_rem))

            if not next_beam:
                break

            # Update incumbent by greedily completing top prefixes
            next_beam.sort(key=lambda x: x[0])
            for bc, bseq, brem in next_beam[:2]:
                if incumbent_cost < float('inf') and bc >= incumbent_cost:
                    continue
                full, fc = greedy_complete(bseq)
                if fc < incumbent_cost:
                    incumbent_cost = fc
                    incumbent_seq = full

            # Keep the beam
            beam = next_beam[:beam_width]
            depth += 1

        # Phase B (focused): a few more steps with incumbent-pruned children
        if beam:
            beam_width_b = min(10, len(beam))
            cand_expand_b = 8
            steps_b = min(3, max(1, n // 50))
            for _ in range(steps_b):
                next_beam_b = []
                for cost, seq, rem in beam[:beam_width_b]:
                    rem_list = list(rem)
                    if not rem_list:
                        next_beam_b.append((cost, seq, rem))
                        continue
                    # Rank children by immediate + light lookahead
                    imm = [(t, eval_seq(seq + [t])) for t in rem_list]
                    imm.sort(key=lambda z: z[1])
                    take_children = min(cand_expand_b, len(imm))
                    kept_any = False
                    for t, _ in imm[:take_children]:
                        new_seq = seq + [t]
                        new_rem = rem - {t}
                        # Greedily complete child for safe pruning
                        full, fc = greedy_complete(new_seq)
                        if fc < incumbent_cost:
                            incumbent_cost = fc
                            incumbent_seq = full
                        # prune children whose full completion not better than incumbent
                        if fc >= incumbent_cost and kept_any:
                            continue
                        kept_any = True
                        new_cost = eval_seq(new_seq)
                        # dominance checks
                        gsig = sig_key(new_seq, new_rem)
                        if gsig in dom_global and new_cost >= dom_global[gsig]:
                            continue
                        dom_global[gsig] = new_cost
                        next_beam_b.append((new_cost, new_seq, new_rem))
                if not next_beam_b:
                    break
                next_beam_b.sort(key=lambda x: x[0])
                beam = next_beam_b[:beam_width_b]

        # Choose best prefix and complete greedily
        if not beam:
            t = rng.randint(0, n - 1)
            full, fc = greedy_complete([t])
            # update inc if provided
            if inc is not None and fc < inc.get('cost', float('inf')):
                inc['cost'] = fc
                inc['seq'] = full
            return full, fc
        beam.sort(key=lambda x: x[0])
        _, bseq, _ = beam[0]
        full, fc = greedy_complete(bseq)
        # Compare with incumbent from Phase B
        if incumbent_seq is not None and incumbent_cost < fc:
            if inc is not None and incumbent_cost < inc.get('cost', float('inf')):
                inc['cost'] = incumbent_cost
                inc['seq'] = incumbent_seq
            return incumbent_seq, incumbent_cost
        if inc is not None and fc < inc.get('cost', float('inf')):
            inc['cost'] = fc
            inc['seq'] = full
        return full, fc
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    bseq, bcost = beam_seed()
    bseq, bcost = adjacent_pass(bseq, bcost)
    seed_best_seq, seed_best_cost = bseq, bcost
=======
    bseq, bcost = beam_seed(inc)
    bseq, bcost = adjacent_pass(bseq, bcost)
    seed_best_seq, seed_best_cost = bseq, bcost
    inc['seq'] = seed_best_seq
    inc['cost'] = seed_best_cost
>>>>>>> REPLACE

</DIFF>