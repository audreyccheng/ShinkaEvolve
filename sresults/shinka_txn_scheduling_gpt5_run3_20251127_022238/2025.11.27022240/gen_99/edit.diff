--- a/original.py
+++ b/original.py
@@ -1,829 +1,1106 @@
 # EVOLVE-BLOCK-START
 """Transaction scheduling algorithm for optimizing makespan across multiple workloads"""
 
 import time
 import random
 import sys
 import os
+import itertools
 from collections import defaultdict, deque
 
 # Add the openevolve_examples directory to the path to import txn_simulator and workloads
 # Find the repository root by looking for openevolve_examples directory
 def find_repo_root(start_path):
     """Find the repository root by looking for openevolve_examples directory."""
     current = os.path.abspath(start_path)
     # Search up the directory tree
     while current != os.path.dirname(current):  # Stop at filesystem root
         candidate = os.path.join(current, 'openevolve_examples', 'txn_scheduling')
         if os.path.exists(candidate):
             return current
         current = os.path.dirname(current)
 
     # If not found by searching up, try common locations relative to known paths
     # This handles when the program is copied to a results directory
     script_dir = os.path.dirname(os.path.abspath(__file__))
     possible_roots = [
         script_dir,  # Current directory
         os.path.dirname(script_dir),  # Parent
         os.path.dirname(os.path.dirname(script_dir)),  # Grandparent
         '/home/ubuntu/ShinkaEvolve',  # Absolute path fallback for Ubuntu
         '/Users/audreycc/Documents/Work/LLMTxn/ADRS-Exps/ShinkaEvolve',  # Absolute path fallback for macOS
     ]
     for root in possible_roots:
         candidate = os.path.join(root, 'openevolve_examples', 'txn_scheduling')
         if os.path.exists(candidate):
             return root
 
     raise RuntimeError(f"Could not find openevolve_examples directory. Searched from: {start_path}")
 
 repo_root = find_repo_root(os.path.dirname(__file__))
 sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'txn_scheduling'))
 
 from txn_simulator import Workload
 from workloads import WORKLOAD_1, WORKLOAD_2, WORKLOAD_3
 
 
 def get_best_schedule(workload, num_seqs):
     """
     Buddy-guided, dominance-pruned beam search with greedy lookahead probes,
     conflict-aware GRASP diversification, and VNS/ILS refinement to minimize makespan.
 
     Args:
         workload: Workload object containing transaction data
         num_seqs: Number of random restarts (used as an upper bound; also time-bounded)
 
     Returns:
         Tuple of (lowest makespan, corresponding schedule)
     """
     N = workload.num_txns
     start_time = time.time()
     # Budget chosen to balance quality and runtime for combined score
     time_budget_sec = 0.56 if N >= 90 else 0.48
 
     def time_left():
         return (time.time() - start_time) < time_budget_sec
 
     rng = random.Random(1337 + 31 * N)
 
     # Shared caches across all phases/restarts
     cost_cache = {}
     ext_cache = {}
 
     def eval_seq_cost(seq):
         key = tuple(seq)
         cached = cost_cache.get(key)
         if cached is not None:
             return cached
         c = workload.get_opt_seq_cost(seq)
         cost_cache[key] = c
         return c
 
     def eval_ext_cost(prefix_tuple, cand):
         key = (prefix_tuple, cand)
         cached = ext_cache.get(key)
         if cached is not None:
             return cached
         c = eval_seq_cost(list(prefix_tuple) + [cand])
         ext_cache[key] = c
         return c
 
     all_txns = list(range(N))
 
     # Precompute singleton costs to seed and for lower bounds
     singleton_cost = {}
     for t in all_txns:
         if not time_left():
             break
         singleton_cost[t] = eval_seq_cost([t])
 
     # Build buddy lists B[t]: top partners minimizing cost([t,u]).
     # Keep small lists (6â€“8) for speed/focus. Sample candidates to bound cost.
     def build_buddies(max_buddies=8):
         buddies = {t: [] for t in all_txns}
         anti_thresh = {t: float('inf') for t in all_txns}
         # Candidate pools per t
         singles_sorted = sorted(all_txns, key=lambda x: singleton_cost.get(x, float('inf')))
         for t in all_txns:
             if not time_left():
                 break
             # Candidate sample: mix of top by singleton and random
             cand_pool = []
             top_slice = singles_sorted[:min(20, max(8, N // 6))]
             cand_pool.extend(top_slice)
             if N > 1:
                 extra = min(24, N - 1)
                 cand_pool.extend(rng.sample([x for x in all_txns if x != t], min(extra, max(10, N // 5))))
             # Deduplicate and remove t
             pool = []
             seen_l = set()
             for u in cand_pool:
                 if u == t or u in seen_l:
                     continue
                 seen_l.add(u)
                 pool.append(u)
             scored = []
             pos_deltas = []
             base = singleton_cost.get(t)
             prefix_tuple = (t,)  # singleton prefix
             for u in pool:
                 if not time_left():
                     break
                 c2 = eval_ext_cost(prefix_tuple, u)
                 delta = c2 - base
                 scored.append((delta, u))  # delta over singleton
                 if delta > 0:
                     pos_deltas.append(delta)
             scored.sort(key=lambda x: x[0])
             buddies[t] = [u for _d, u in scored[:max_buddies]]
             # 75th percentile threshold among positive deltas (if any)
             if pos_deltas:
                 pos_deltas.sort()
                 idx = int(0.75 * (len(pos_deltas) - 1))
                 anti_thresh[t] = pos_deltas[idx]
         return buddies, anti_thresh
 
     buddies, anti_buddy_thresh = build_buddies(max_buddies=8)
 
     # Pairwise adjacency surrogate using true two-step marginal delta
     pair_cost_cache = {}
     def pair_cost(a, b):
         key = (a, b)
         c = pair_cost_cache.get(key)
         if c is not None:
             return c
         base = singleton_cost.get(a)
         if base is None:
             base = eval_seq_cost([a])
             singleton_cost[a] = base
         ec = eval_ext_cost((a,), b)
         delta = ec - base
         pair_cost_cache[key] = delta
         return delta
 
     # Anti-buddy gate using learned threshold per 'last'
     def is_antibuddy(last, cand):
         if last is None:
             return False
         thr = anti_buddy_thresh.get(last, float('inf'))
         if thr == float('inf'):
             return False
         pc = pair_cost(last, cand)
         return pc > 0 and pc >= thr
 
     # Global prefix-dominance map shared across restarts/phases
     best_state_global = {}
     # Shared prefix-dominance cache for pruning across beam/greedy
     prefix_dom = {}
 
     # Lower bound using max remaining singleton cost
     def lb_singleton(cur_cost, rem_set):
         if not rem_set:
             return cur_cost
         m = 0
         for t in rem_set:
             c = singleton_cost.get(t)
             if c is None:
                 c = eval_seq_cost([t])
                 singleton_cost[t] = c
             if c > m:
                 m = c
         return max(cur_cost, m)
 
     # Greedy completion guided by buddies and extension costs
     def greedy_finish(seq, rem_set, branch_k=10, incumbent=None):
         seq_out = list(seq)
         rem = set(rem_set)
         cur_cost = eval_seq_cost(seq_out) if seq_out else 0
         while rem and time_left():
             if incumbent is not None:
                 if lb_singleton(cur_cost, rem) >= incumbent:
                     break
             # Shared prefix-dominance update and optional prune
             k_upd = 3 if len(seq_out) < int(0.7 * N) else 4
             sig_g = make_signature(rem, seq_out, k_upd)
             prev_g = prefix_dom.get(sig_g)
             if prev_g is not None and cur_cost >= prev_g - 1e-9:
                 break
             if prev_g is None or cur_cost < prev_g:
                 prefix_dom[sig_g] = cur_cost
             last = seq_out[-1] if seq_out else None
             rem_list = list(rem)
             cand_pool = []
 
             # Prefer buddies of last
             if last is not None and last in buddies:
                 for u in buddies[last]:
                     if u in rem:
                         cand_pool.append(u)
 
             # Fill with random sample for diversity
             need = max(0, branch_k - len(cand_pool))
             if need > 0:
                 others = [x for x in rem_list if x not in cand_pool]
                 if len(others) > need:
                     cand_pool.extend(rng.sample(others, need))
                 else:
                     cand_pool.extend(others)
 
             if not cand_pool:
                 cand_pool = rem_list if len(rem_list) <= branch_k else rng.sample(rem_list, branch_k)
 
             prefix_tuple = tuple(seq_out)
             scored = []
             best_immediate = float('inf')
             for t in cand_pool:
                 c = eval_ext_cost(prefix_tuple, t)
                 scored.append((c, t))
                 if c < best_immediate:
                     best_immediate = c
             if not scored:
                 # Time exhausted; append remaining arbitrarily
                 seq_out.extend(rem)
                 cur_cost = eval_seq_cost(seq_out)
                 return cur_cost, seq_out
             # Anti-buddy filtering: skip strongly disfavored unless near-best
             tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
             filtered = []
             last_txn = seq_out[-1] if seq_out else None
             for c, t in scored:
                 if is_antibuddy(last_txn, t) and c > tol:
                     continue
                 filtered.append((c, t))
             if not filtered:
                 filtered = scored
             filtered.sort(key=lambda x: x[0])
             best_c, best_t = filtered[0]
             seq_out.append(best_t)
             rem.remove(best_t)
             cur_cost = best_c
         if rem:
             seq_out.extend(list(rem))
             cur_cost = eval_seq_cost(seq_out)
         return cur_cost, seq_out
 
     # Prefix-dominance pruning state
     def make_signature(rem_set, seq, k_suffix):
         if k_suffix <= 0:
             return (frozenset(rem_set), ())
         tail = tuple(seq[-k_suffix:]) if len(seq) >= k_suffix else tuple(seq)
         return (frozenset(rem_set), tail)
 
     # Core beam runner with params and incumbent-based pruning
     def run_beam(params, incumbent_cost=float('inf'), k_suffix=3):
         beam_width = params['beam']
         branch_factor = params['branch']
         lookahead_top = params['lookahead_top']
 
         all_txns_local = all_txns
         # Seed: best singletons by cost plus a few randoms for diversity
         seeds_sorted = sorted(all_txns_local, key=lambda t: singleton_cost.get(t, float('inf')))
         seed_pool = seeds_sorted[:max(beam_width * 2, 8)]
         # add a few random seeds
         if len(all_txns_local) > len(seed_pool):
             extra = min(6, len(all_txns_local) - len(seed_pool))
             seed_pool.extend(rng.sample([x for x in all_txns_local if x not in seed_pool], extra))
 
         beam = []
         for t in seed_pool:
             if not time_left():
                 break
             seq = [t]
             rem = set(all_txns_local)
             rem.remove(t)
             c = eval_seq_cost(seq)
             beam.append((c, seq, rem))
         if not beam:
             seq = all_txns_local[:]
             rng.shuffle(seq)
             return eval_seq_cost(seq), seq, incumbent_cost, None
 
         beam.sort(key=lambda x: x[0])
         beam = beam[:beam_width]
 
         # Prefix-dominance map (local) and track best full
         best_state = {}
 
         best_full_cost = incumbent_cost
         best_full_seq = None
 
         steps = N - 1
         depth = 0
         while depth < steps and time_left():
             depth += 1
             new_beam = []
 
             # Depth-adaptive suffix length for dominance (more context later)
             if depth < int(0.7 * N):
                 k_cur = max(3, k_suffix)
             else:
                 k_cur = max(4, k_suffix)
 
             for cost_so_far, seq, rem in beam:
                 if not rem:
                     # complete sequence
                     if cost_so_far < best_full_cost:
                         best_full_cost, best_full_seq = cost_so_far, seq[:]
                     continue
 
                 # incumbent pruning
                 if cost_so_far >= best_full_cost:
                     continue
 
                 # prefix-dominance pruning (local and global)
                 sig = make_signature(rem, seq, k_cur)
                 prev_local = best_state.get(sig)
                 if prev_local is not None and cost_so_far >= prev_local:
                     continue
                 prev_global = best_state_global.get(sig)
                 if prev_global is not None and cost_so_far >= prev_global:
                     continue
                 # Update both
                 best_state[sig] = cost_so_far
                 cur_best = best_state_global.get(sig)
                 if cur_best is None or cost_so_far < cur_best:
                     best_state_global[sig] = cost_so_far
 
                 # Candidate pool: buddies of last + random sample
                 last = seq[-1]
                 rem_list = list(rem)
                 cand_pool = []
                 if last in buddies:
                     for u in buddies[last]:
                         if u in rem:
                             cand_pool.append(u)
                 # supplement with random to reach 2*branch
                 need = max(0, branch_factor * 2 - len(cand_pool))
                 if need > 0:
                     others = [x for x in rem_list if x not in cand_pool]
                     add = min(len(others), need)
                     if add > 0:
                         cand_pool.extend(rng.sample(others, add))
 
                 if not cand_pool:
                     cand_pool = rem_list if len(rem_list) <= branch_factor * 2 else rng.sample(rem_list, branch_factor * 2)
 
                 # Score by marginal delta and shallow lookahead biased by buddies with anti-buddy gating
                 prefix_tuple = tuple(seq)
                 tmp = []
                 best_immediate = float('inf')
                 for cand in cand_pool:
                     if not time_left():
                         break
                     ec = eval_ext_cost(prefix_tuple, cand)
                     tmp.append((ec, cand))
                     if ec < best_immediate:
                         best_immediate = ec
                 scored = []
                 tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
                 for ec, cand in tmp:
                     if ec >= best_full_cost:
                         # immediate prune by incumbent
                         continue
                     if is_antibuddy(last, cand) and ec > tol:
                         continue
                     # shallow lookahead: prefer buddy-next of cand first
                     la_best = ec
                     if rem and time_left():
                         new_rem = rem.copy()
                         if cand in new_rem:
                             new_rem.remove(cand)
                         la_pool = [v for v in buddies.get(cand, []) if v in new_rem]
                         if not la_pool:
                             la_pool = list(new_rem)
                         # sample top 'lookahead_top'
                         if len(la_pool) > lookahead_top:
                             la_pool = rng.sample(la_pool, lookahead_top)
                         new_prefix_tuple = tuple(seq + [cand])
                         for nxt in la_pool:
                             c2 = eval_ext_cost(new_prefix_tuple, nxt)
                             if c2 < la_best:
                                 la_best = c2
                     scored.append((ec - cost_so_far, la_best, ec, cand))
 
                 if not scored:
                     continue
                 # rank by marginal delta then lookahead score
                 scored.sort(key=lambda x: (x[0], x[1]))
                 top = scored[:min(branch_factor, len(scored))]
                 # Promote top children via greedy completion and prune by incumbent/prefix-dom
                 probe_k = min(len(top), 2 if depth < int(0.7 * N) else 1)
                 idx_child = 0
                 for _delta, la_score, ec, cand in top:
                     new_seq = seq + [cand]
                     new_rem = rem.copy()
                     new_rem.remove(cand)
                     # Child LB pruning
                     if lb_singleton(ec, new_rem) >= best_full_cost:
                         continue
                     # Prefix-dominance prune on child state
                     sig_child = make_signature(new_rem, new_seq, k_cur)
                     prev_pd = prefix_dom.get(sig_child)
                     if prev_pd is not None and ec >= prev_pd - 1e-9:
                         continue
                     # Greedy probe for first few children to update incumbent and refine ranking
                     if idx_child < probe_k and time_left():
                         g_cost, g_seq = greedy_finish(new_seq, new_rem, branch_k=max(6, N // 12), incumbent=best_full_cost)
                         if len(g_seq) == N and g_cost < best_full_cost:
                             best_full_cost, best_full_seq = g_cost, g_seq
                         la_score = min(la_score, g_cost)
                     idx_child += 1
                     # Prune child if lookahead is not better than incumbent
                     if la_score >= best_full_cost:
                         continue
                     # Update shared prefix-dominance with best known prefix cost
                     if prev_pd is None or ec < prev_pd:
                         prefix_dom[sig_child] = ec
                     new_beam.append((ec, new_seq, new_rem, la_score))
 
             if not new_beam:
                 break
 
             # Select next beam by lookahead score; keep unique prefixes
             new_beam.sort(key=lambda x: x[3])
             unique = []
             seen = set()
             for entry in new_beam:
                 key = tuple(entry[1])
                 if key in seen:
                     continue
                 seen.add(key)
                 unique.append((entry[0], entry[1], entry[2]))
                 if len(unique) >= beam_width:
                     break
             beam = unique
 
             # Periodically greedily complete top-2 prefixes
             if beam and time_left():
                 for c_pref, s_pref, r_pref in beam[:min(2, len(beam))]:
                     c_try, s_try = greedy_finish(s_pref, r_pref, branch_k=max(8, N // 10), incumbent=best_full_cost)
                     if len(s_try) == N and c_try < best_full_cost:
                         best_full_cost, best_full_seq = c_try, s_try
 
         # Finalize: greedily finish remaining prefixes
         for c_pref, s_pref, r_pref in beam:
             if not time_left():
                 break
             c_fin, s_fin = greedy_finish(s_pref, r_pref, branch_k=max(8, N // 10), incumbent=best_full_cost)
             if len(s_fin) == N and c_fin < best_full_cost:
                 best_full_cost, best_full_seq = c_fin, s_fin
 
         if best_full_seq is None:
             seq = all_txns_local[:]
             rng.shuffle(seq)
             best_full_seq = seq
             best_full_cost = eval_seq_cost(seq)
         return best_full_cost, best_full_seq, best_full_cost, beam[:]
 
     # Conflict-aware GRASP constructive heuristic (diversified)
     def run_grasp():
         seq = []
         rem = set(all_txns)
         # Seed from best among a small random pool of singletons
         seed_pool = rng.sample(all_txns, min(12, len(all_txns)))
         seed_best = None
         seed_best_cost = float('inf')
         for t in seed_pool:
             if not time_left():
                 break
             c = eval_seq_cost([t])
             if c < seed_best_cost:
                 seed_best_cost = c
                 seed_best = t
         if seed_best is None:
             seed_best = rng.choice(all_txns)
             seed_best_cost = eval_seq_cost([seed_best])
         seq.append(seed_best)
         rem.remove(seed_best)
         cur_cost = seed_best_cost
 
         # GRASP loop: build using RCL over extension costs, guided by buddies
         grasp_top_k = 6
         while rem and time_left():
             last = seq[-1]
             rem_list = list(rem)
             # Candidate pool: buddies of last plus random fill
             cand_pool = [u for u in buddies.get(last, []) if u in rem]
             need = max(0, min(16, max(6, N // 12)) - len(cand_pool))
             if need > 0:
                 others = [x for x in rem_list if x not in cand_pool]
                 if others:
                     cand_pool.extend(rng.sample(others, min(need, len(others))))
             if not cand_pool:
                 cand_pool = rem_list
 
             scored = []
             pt = tuple(seq)
             best_immediate = float('inf')
             for t in cand_pool:
                 if not time_left():
                     break
                 c = eval_ext_cost(pt, t)
                 scored.append((c, t))
                 if c < best_immediate:
                     best_immediate = c
             if not scored:
                 # fallback append random
                 t = rng.choice(rem_list)
                 seq.append(t)
                 rem.remove(t)
                 cur_cost = eval_seq_cost(seq)
                 continue
             # Anti-buddy filter: skip strongly disfavored unless near-best
             tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
             filtered = []
             last_txn = seq[-1]
             for c, t in scored:
                 if is_antibuddy(last_txn, t) and c > tol:
                     continue
                 filtered.append((c, t))
             if not filtered:
                 filtered = scored
             filtered.sort(key=lambda x: x[0])
             top_k = min(grasp_top_k, len(filtered))
             chosen_cost, chosen_t = rng.choice(filtered[:top_k])
             seq.append(chosen_t)
             rem.remove(chosen_t)
             cur_cost = chosen_cost
 
         if rem:
             seq.extend(list(rem))
         final_cost = eval_seq_cost(seq)
         return final_cost, seq
 
     # Lightweight VNS refinement: adjacent swaps, relocations and boundary repair
     def local_improve(seq, current_cost):
         best_seq = seq[:]
         best_cost = current_cost
 
-        # Multiple adjacent-swap passes until no improvement or time
+        # Local evaluation budget to cap expensive evals inside local search
+        eval_budget = 700 if N >= 90 else 600
+        eval_count = 0
+
+        def eval_local(s):
+            nonlocal eval_count
+            if not time_left() or eval_count >= eval_budget:
+                return float('inf')
+            eval_count += 1
+            return eval_seq_cost(s)
+
+        # Small adjacent bubble pass around [L,R]
+        def bubble_pass(cur_seq, cur_cost, L, R, passes=1):
+            n = len(cur_seq)
+            L = max(0, L)
+            R = min(n - 1, R)
+            best_s = cur_seq[:]
+            best_c = cur_cost
+            for _ in range(passes):
+                improved = False
+                for i in range(L, R):
+                    cand = best_s[:]
+                    cand[i], cand[i + 1] = cand[i + 1], cand[i]
+                    c = eval_local(cand)
+                    if c < best_c:
+                        best_c = c
+                        best_s = cand
+                        improved = True
+                        # Narrow follow-up around the changed area
+                        if not time_left() or eval_count >= eval_budget:
+                            break
+                if not improved or not time_left() or eval_count >= eval_budget:
+                    break
+            return best_c, best_s
+
+        # Multiple adjacent-swap passes until no improvement or time/budget
         for _ in range(2):
             improved = False
             for i in range(len(best_seq) - 1):
-                if not time_left():
+                if not time_left() or eval_count >= eval_budget:
                     break
                 cand = best_seq[:]
                 cand[i], cand[i + 1] = cand[i + 1], cand[i]
-                c = eval_seq_cost(cand)
+                c = eval_local(cand)
                 if c < best_cost:
                     best_cost = c
                     best_seq = cand
                     improved = True
-            if not improved or not time_left():
+            if not improved or not time_left() or eval_count >= eval_budget:
                 break
 
         # Boundary-focused ruin-and-recreate around the worst adjacency
         def boundary_repair_once(cur_seq, cur_cost):
             n = len(cur_seq)
-            if n < 6 or not time_left():
+            if n < 6 or not time_left() or eval_count >= eval_budget:
                 return cur_cost, cur_seq
             # Find worst adjacency by surrogate pair_cost
             worst_idx = -1
             worst_val = -float('inf')
             for i in range(n - 1):
                 if not time_left():
                     break
                 v = pair_cost(cur_seq[i], cur_seq[i + 1])
                 if v > worst_val:
                     worst_val = v
                     worst_idx = i
             if worst_idx < 0:
                 return cur_cost, cur_seq
             # Remove a small block centered at worst_idx
             block_size = min(5, max(3, n // 30))
             start = max(0, min(worst_idx - block_size // 2, n - block_size))
             block = cur_seq[start:start + block_size]
             remaining = cur_seq[:start] + cur_seq[start + block_size:]
             seq_build = remaining[:]
             # Greedily reinsert block elements at best positions using true cost
             for x in block:
-                if not time_left():
+                if not time_left() or eval_count >= eval_budget:
                     break
                 positions = list(range(max(0, start - 3), min(len(seq_build) + 1, start + 4)))
                 # add a few random positions for diversity
                 extra = set()
                 limit = min(8, len(seq_build) + 1)
                 while len(extra) < limit and time_left():
                     extra.add(rng.randrange(len(seq_build) + 1))
                 for p in extra:
                     if p not in positions:
                         positions.append(p)
                 best_local_cost = float('inf')
                 best_pos = 0
                 for p in positions:
                     cand = seq_build[:]
                     cand.insert(p, x)
-                    c = eval_seq_cost(cand)
+                    c = eval_local(cand)
                     if c < best_local_cost:
                         best_local_cost = c
                         best_pos = p
+                    if eval_count >= eval_budget or not time_left():
+                        break
                 seq_build.insert(best_pos, x)
             if len(seq_build) == n:
-                c_new = eval_seq_cost(seq_build)
+                c_new = eval_local(seq_build)
                 if c_new < cur_cost:
+                    # Bubble clean-up nearby
+                    c_new, seq_build = bubble_pass(seq_build, c_new, max(0, start - 3), min(n - 2, start + block_size + 3), passes=1)
                     return c_new, seq_build
             return cur_cost, cur_seq
 
         # Attempt a couple of boundary repairs
         for _ in range(2):
-            if not time_left():
+            if not time_left() or eval_count >= eval_budget:
                 break
             c_try, s_try = boundary_repair_once(best_seq, best_cost)
             if c_try < best_cost:
                 best_cost, best_seq = c_try, s_try
 
+        # Anchored window optimization around worst adjacency (permute interior)
+        def anchored_window_improve(cur_seq, cur_cost):
+            if not time_left() or eval_count >= eval_budget:
+                return cur_cost, cur_seq
+            n = len(cur_seq)
+            if n < 8:
+                return cur_cost, cur_seq
+            # find worst adjacency
+            worst_i = 0
+            worst_val = -float('inf')
+            for i in range(n - 1):
+                v = pair_cost(cur_seq[i], cur_seq[i + 1])
+                if v > worst_val:
+                    worst_val = v
+                    worst_i = i
+            # choose window size
+            k = 7 if n >= 80 else 6
+            best_local_c = cur_cost
+            best_local_s = cur_seq[:]
+
+            def score_window(order, left_out, right_out):
+                # surrogate score: sum pair_cost inside window plus edges to context
+                s = 0.0
+                for i in range(len(order) - 1):
+                    s += pair_cost(order[i], order[i + 1])
+                if left_out is not None:
+                    s += pair_cost(left_out, order[0])
+                if right_out is not None:
+                    s += pair_cost(order[-1], right_out)
+                return s
+
+            def try_anchor(anchor_side):
+                nonlocal best_local_c, best_local_s
+                if anchor_side == 'left':
+                    # Anchor at worst_i (left of boundary)
+                    start = max(0, min(worst_i, n - k))
+                    win = cur_seq[start:start + k]
+                    if len(win) < 2:
+                        return
+                    anchor = win[0]
+                    interior = win[1:]
+                    left_out = cur_seq[start - 1] if start - 1 >= 0 else None
+                    right_out = cur_seq[start + k] if start + k < n else None
+                else:
+                    # Anchor at worst_i+1 (right of boundary)
+                    start = max(0, min(worst_i - (k - 2), n - k))
+                    win = cur_seq[start:start + k]
+                    if len(win) < 2:
+                        return
+                    anchor = win[-1]
+                    interior = win[:-1]
+                    left_out = cur_seq[start - 1] if start - 1 >= 0 else None
+                    right_out = cur_seq[start + k] if start + k < n else None
+
+                m = len(interior)
+                # Enumerate permutations surrogate-ranked; evaluate top 40% + 10% random within cap
+                perms = itertools.permutations(interior, m)
+                # We cannot iterate all perms twice; collect surrogate scores first (limited)
+                cand_scored = []
+                # limit number of perms to avoid excessive memory; for m<=6 ok
+                max_collect = 720 if m >= 6 else 120
+                cnt = 0
+                for perm in perms:
+                    if cnt >= max_collect:
+                        break
+                    if anchor_side == 'left':
+                        order = [anchor] + list(perm)
+                    else:
+                        order = list(perm) + [anchor]
+                    sc = score_window(order, left_out, right_out)
+                    cand_scored.append((sc, order))
+                    cnt += 1
+                if not cand_scored:
+                    return
+                cand_scored.sort(key=lambda x: x[0])
+                top_count = max(1, int(0.4 * len(cand_scored)))
+                eval_list = cand_scored[:top_count]
+                # add 10% random
+                extra = max(1, int(0.1 * len(cand_scored)))
+                for _ in range(extra):
+                    eval_list.append(rng.choice(cand_scored))
+                # Strict per-anchor eval cap
+                cap = min(250, max(150, 40 * m))
+                tried = 0
+                for _sc, order in eval_list:
+                    if tried >= cap or not time_left() or eval_count >= eval_budget:
+                        break
+                    # Build candidate sequence
+                    if anchor_side == 'left':
+                        new_win = order
+                    else:
+                        new_win = order
+                    cand = cur_seq[:start] + new_win + cur_seq[start + k:]
+                    c = eval_local(cand); tried += 1
+                    if c < best_local_c:
+                        best_local_c, best_local_s = c, cand
+                        # local bubble near window
+                        L = max(0, start - 3)
+                        R = min(n - 2, start + k + 3)
+                        best_local_c, best_local_s = bubble_pass(best_local_s, best_local_c, L, R, passes=1)
+
+            try_anchor('left')
+            if not time_left() or eval_count >= eval_budget:
+                return best_local_c, best_local_s
+            try_anchor('right')
+            return best_local_c, best_local_s
+
+        if time_left() and eval_count < eval_budget:
+            c_try, s_try = anchored_window_improve(best_seq, best_cost)
+            if c_try < best_cost:
+                best_cost, best_seq = c_try, s_try
+
+        # Bridge move: take a block around right-side of worst boundary and insert before left
+        def bridge_move(cur_seq, cur_cost):
+            if not time_left() or eval_count >= eval_budget:
+                return cur_cost, cur_seq
+            n = len(cur_seq)
+            if n < 8:
+                return cur_cost, cur_seq
+            # worst adjacency
+            worst_i = 0
+            worst_val = -float('inf')
+            for i in range(n - 1):
+                v = pair_cost(cur_seq[i], cur_seq[i + 1])
+                if v > worst_val:
+                    worst_val = v
+                    worst_i = i
+            a = cur_seq[worst_i]
+            # try a few block sizes around b
+            best_c, best_s = cur_cost, cur_seq[:]
+            for s in [3, 4, 5]:
+                if not time_left() or eval_count >= eval_budget:
+                    break
+                if n <= s + 2:
+                    continue
+                b_idx = worst_i + 1
+                start = max(0, min(b_idx - s // 2, n - s))
+                block = cur_seq[start:start + s]
+                remain = cur_seq[:start] + cur_seq[start + s:]
+                # position before 'a' in remain
+                try:
+                    pos_a = remain.index(a)
+                except ValueError:
+                    pos_a = min(worst_i, len(remain))
+                for rev in [False, True]:
+                    if not time_left() or eval_count >= eval_budget:
+                        break
+                    blk = block if not rev else block[::-1]
+                    cand = remain[:]
+                    for off, x in enumerate(blk):
+                        cand.insert(pos_a + off, x)
+                    c = eval_local(cand)
+                    if c < best_c:
+                        best_c, best_s = c, cand
+                        # bubble cleanup near a area
+                        L = max(0, pos_a - 3)
+                        R = min(len(cand) - 2, pos_a + s + 3)
+                        best_c, best_s = bubble_pass(best_s, best_c, L, R, passes=1)
+            return best_c, best_s
+
+        if time_left() and eval_count < eval_budget:
+            c_try, s_try = bridge_move(best_seq, best_cost)
+            if c_try < best_cost:
+                best_cost, best_seq = c_try, s_try
+
         # Block-swap neighborhood around top-2 worst adjacencies (limited tries)
-        if time_left():
+        if time_left() and eval_count < eval_budget:
             n = len(best_seq)
             if n >= 8:
                 worst = []
                 for i in range(n - 1):
                     if not time_left():
                         break
                     worst.append((pair_cost(best_seq[i], best_seq[i + 1]), i))
                 worst.sort(key=lambda x: x[0], reverse=True)
                 tries = 0
                 for a in range(min(2, len(worst))):
-                    if not time_left():
+                    if not time_left() or eval_count >= eval_budget:
                         break
                     for b in range(a + 1, min(4, len(worst))):
-                        if not time_left():
+                        if not time_left() or eval_count >= eval_budget:
                             break
                         i = worst[a][1]
                         j = worst[b][1]
                         block = min(6, max(3, n // 40))
                         si = max(0, min(i - block // 2, n - block))
                         sj = max(0, min(j - block // 2, n - block))
                         # ensure non-overlap
                         if abs(si - sj) < block:
                             continue
                         cand = best_seq[:]
                         # ensure si < sj
                         if si > sj:
                             si, sj = sj, si
                         block_i = cand[si:si + block]
                         block_j = cand[sj:sj + block]
                         mid = cand[si + block:sj]
                         cand2 = cand[:si] + block_j + mid + block_i + cand[sj + block:]
-                        c = eval_seq_cost(cand2)
+                        c = eval_local(cand2)
                         tries += 1
                         if c < best_cost:
                             best_cost = c
                             best_seq = cand2
-                    if tries >= 4:
-                        break
+                            # bubble around swapped blocks
+                            L = max(0, si - 3)
+                            R = min(n - 2, sj + block + 3)
+                            best_cost, best_seq = bubble_pass(best_seq, best_cost, L, R, passes=1)
+                        if tries >= 4:
+                            break
 
         # Targeted relocations with small window (reduced trials, keep diversity)
-        trials = 45
+        trials = 36
         n = len(best_seq)
-        while trials > 0 and time_left():
+        while trials > 0 and time_left() and eval_count < eval_budget:
             trials -= 1
             i = rng.randrange(n)
             j = rng.randrange(n)
             if i == j:
                 continue
             cand = best_seq[:]
             val = cand.pop(i)
             cand.insert(j, val)
-            c = eval_seq_cost(cand)
+            c = eval_local(cand)
             if c < best_cost:
                 best_cost = c
                 best_seq = cand
+                # bubble around min(i,j)
+                L = max(0, min(i, j) - 2)
+                R = min(n - 2, max(i, j) + 2)
+                best_cost, best_seq = bubble_pass(best_seq, best_cost, L, R, passes=1)
+
+        # Conflict-targeted 2.5-opt sampling focused on worst adjacencies
+        if time_left() and eval_count < eval_budget and n >= 6:
+            viols = []
+            for i in range(n - 1):
+                viols.append((pair_cost(best_seq[i], best_seq[i + 1]), i))
+            viols.sort(reverse=True, key=lambda x: x[0])
+            cap = min(20, max(4, n // 8))
+            cands = []
+            for v, i in viols[:cap]:
+                j = rng.randrange(0, n - 1)
+                if abs(j - i) <= 2:
+                    continue
+                cands.append((v, i, j))
+            if cands:
+                cands.sort(reverse=True, key=lambda x: x[0])
+                eval_list = cands[:max(1, int(0.4 * len(cands)))]
+                # add 10% random
+                extra = max(1, len(cands) // 10)
+                for _ in range(extra):
+                    eval_list.append(rng.choice(cands))
+                budget = 60
+                tried = 0
+                for _v, i, j in eval_list:
+                    if tried >= budget or not time_left() or eval_count >= eval_budget:
+                        break
+                    # 2-opt style swap endpoints
+                    cand = best_seq[:]
+                    cand[i], cand[j] = cand[j], cand[i]
+                    c = eval_local(cand); tried += 1
+                    if c < best_cost:
+                        best_cost, best_seq = c, cand
+                        n = len(best_seq)
+                        # bubble near endpoints
+                        L = max(0, min(i, j) - 2)
+                        R = min(n - 2, max(i, j) + 2)
+                        best_cost, best_seq = bubble_pass(best_seq, best_cost, L, R, passes=1)
+                        continue
+                    if tried >= budget or not time_left() or eval_count >= eval_budget:
+                        break
+                    # 2.5-opt: move small block after i before i
+                    s = min(4, max(3, n // 40))
+                    b_start = max(0, min(i + 1, n - s))
+                    block = best_seq[b_start:b_start + s]
+                    remain = best_seq[:b_start] + best_seq[b_start + s:]
+                    pos = max(0, min(i, len(remain)))
+                    cand2 = remain[:]
+                    blk = block if rng.random() < 0.5 else block[::-1]
+                    for off, x in enumerate(blk):
+                        cand2.insert(pos + off, x)
+                    c2 = eval_local(cand2); tried += 1
+                    if c2 < best_cost:
+                        best_cost, best_seq = c2, cand2
+                        n = len(best_seq)
+                        L = max(0, pos - 2)
+                        R = min(n - 2, pos + s + 2)
+                        best_cost, best_seq = bubble_pass(best_seq, best_cost, L, R, passes=1)
 
         return best_cost, best_seq
 
     # Simple perturbation for ILS: shuffle a small window around a bad boundary
     def perturb(seq):
         n = len(seq)
         if n < 6:
             return seq[:]
-        # pick a center index
-        i = rng.randrange(1, n - 2)
+        # pick a center index biased to worst adjacency
+        worst_i = rng.randrange(1, n - 2)
+        worst_val = -float('inf')
+        for i in range(n - 1):
+            v = pair_cost(seq[i], seq[i + 1])
+            if v > worst_val:
+                worst_val = v
+                worst_i = i
+        i = worst_i
         w = min(6, max(3, n // 40))
         s = max(0, min(i - w // 2, n - w))
         block = seq[s:s + w]
         middle = block[:]
         rng.shuffle(middle)
         return seq[:s] + middle + seq[s + w:]
 
     # Portfolio of parameter settings (deterministic seeds)
     portfolios = [
         {'beam': 16, 'branch': 12, 'lookahead_top': 4, 'next_k': 6, 'k_suffix': 3},
         {'beam': 12, 'branch': 14, 'lookahead_top': 3, 'next_k': 5, 'k_suffix': 3},
         {'beam': 10, 'branch': 10, 'lookahead_top': 3, 'next_k': 4, 'k_suffix': 4},
     ]
 
     global_best_cost = float('inf')
     global_best_seq = None
 
     # Alternate portfolio beams and GRASP within time budget
     max_restarts = max(2, min(len(portfolios) + 1, int(num_seqs)))
     r = 0
     while r < max_restarts and time_left():
         # Beam restart
         params_A = portfolios[r % len(portfolios)].copy()
         cA, sA, incumbent_cost, _beam_frontier = run_beam(params_A, incumbent_cost=global_best_cost, k_suffix=params_A['k_suffix'])
         # Tighter beam follow-up
         if time_left():
             params_B = {'beam': max(8, params_A['beam'] - 4),
                         'branch': max(8, params_A['branch'] - 4),
                         'lookahead_top': max(2, params_A['lookahead_top'] - 1),
                         'next_k': max(3, params_A['next_k'] - 1),
                         'k_suffix': params_A['k_suffix']}
             cB, sB, _, _ = run_beam(params_B, incumbent_cost=min(global_best_cost, incumbent_cost), k_suffix=params_B['k_suffix'])
             if cB < cA:
                 cA, sA = cB, sB
 
-        # Local refinement
+        # Local refinement with budget
         if time_left():
             cA, sA = local_improve(sA, cA)
 
         if cA < global_best_cost:
             global_best_cost, global_best_seq = cA, sA
 
         # GRASP diversification restart
         if time_left():
             cg, sg = run_grasp()
             if time_left():
                 cg, sg = local_improve(sg, cg)
             if cg < global_best_cost:
                 global_best_cost, global_best_seq = cg, sg
 
         r += 1
 
     # Iterated Local Search while time remains
     ils_iters = 0
-    while time_left() and ils_iters < 3 and global_best_seq is not None:
+    while time_left() and ils_iters < 2 and global_best_seq is not None:
         ils_iters += 1
         cand = perturb(global_best_seq)
         cc = eval_seq_cost(cand)
         cc, cand = local_improve(cand, cc)
         if cc < global_best_cost:
             global_best_cost, global_best_seq = cc, cand
 
     # Safety: ensure permutation validity
     if global_best_seq is None or len(global_best_seq) != N or len(set(global_best_seq)) != N:
         if global_best_seq is None:
             seq = list(range(N))
             rng.shuffle(seq)
             global_best_seq = seq
         seen = set()
         repaired = []
         for t in global_best_seq:
             if 0 <= t < N and t not in seen:
                 repaired.append(t)
                 seen.add(t)
         for t in range(N):
             if t not in seen:
                 repaired.append(t)
         global_best_seq = repaired[:N]
         global_best_cost = eval_seq_cost(global_best_seq)
 
     return global_best_cost, global_best_seq
 
 
 def get_random_costs():
     """
     Evaluate scheduling algorithm on three different workloads.
 
     Returns:
         Tuple of (total_makespan, list_of_schedules, execution_time)
     """
     start_time = time.time()
     workload_size = 100
 
     # Workload 1: Complex mixed read/write transactions
     workload = Workload(WORKLOAD_1)
     makespan1, schedule1 = get_best_schedule(workload, 10)
     cost1 = workload.get_opt_seq_cost(schedule1)
 
     # Workload 2: Simple read-then-write pattern
     workload2 = Workload(WORKLOAD_2)
     makespan2, schedule2 = get_best_schedule(workload2, 10)
     cost2 = workload2.get_opt_seq_cost(schedule2)
 
     # Workload 3: Minimal read/write operations
     workload3 = Workload(WORKLOAD_3)
     makespan3, schedule3 = get_best_schedule(workload3, 10)
     cost3 = workload3.get_opt_seq_cost(schedule3)
 
     total_makespan = cost1 + cost2 + cost3
     schedules = [schedule1, schedule2, schedule3]
     execution_time = time.time() - start_time
 
     return total_makespan, schedules, execution_time
 
 
 # EVOLVE-BLOCK-END
 
 
 # This part remains fixed (not evolved)
 def run_scheduling():
     """Run the transaction scheduling algorithm for all workloads"""
     total_makespan, schedules, execution_time = get_random_costs()
     return total_makespan, schedules, execution_time
 
 
 if __name__ == "__main__":
     total_makespan, schedules, execution_time = run_scheduling()
     print(f"Total makespan: {total_makespan}, Execution time: {execution_time:.4f}s")
     print(f"Individual workload costs: {[workload.get_opt_seq_cost(schedule) for workload, schedule in zip([Workload(WORKLOAD_1), Workload(WORKLOAD_2), Workload(WORKLOAD_3)], schedules)]}")