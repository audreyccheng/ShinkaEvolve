# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy sampled transaction scheduler**
- **Implementation**: Implements a greedy cost-sampling scheduler: start at a random transaction, then at each step evaluate up to 10 randomly selected candidates via workload.get_opt_seq_cost and pick the minimum; sample_rate is fixed at 1.0 so only the greedy path runs. Includes robust repo-root path discovery; num_seqs and workload_size are unused, costs are recomputed redundantly, and randomness is unseeded.
- **Performance**: Combined score 2.65 across 3 workloads (300 transactions); correct and passes all validation tests with execution time recorded.
- **Feedback**: Greedy sampling trades optimality for speed; unseeded randomness can cause variability—seeding or multi-start runs could stabilize/improve scores. Removing redundant cost recomputations and honoring num_seqs/sample_rate would reduce overhead and enable broader exploration.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Beam-search transaction scheduler with memoized costs**
- **Implementation**: Uses beam search with dynamic beam/branch sizing, memoized prefix cost evaluation, and multiple random restarts. Initializes the beam from sampled singletons and prunes to top unique prefixes at each depth to control breadth.
- **Performance**: Combined score 3.40; produced valid schedules for all three workloads (300 transactions) and passed all validation tests.
- **Feedback**: Dynamic sizing and memoization reduced search overhead, while random restarts improved robustness; capped beam (≤32) and branch (≤24) factors kept runtime reasonable but can miss global optima due to stochastic pruning. Re-evaluating final schedules confirmed consistency of reported makespans.
**Program Identifier:** Generation 1 - Patch Name beam_search_with_memoized_costs - Correct Program: True

**Program Name: Beam + local search transaction scheduler**
- **Implementation**: Uses a beam search with memoized partial-cost evaluations (Workload.get_opt_seq_cost) and adaptive beam width (from num_seqs) plus sampled candidate expansions, followed by local improvements via adjacent swaps and sampled insertion. Includes robust repository path discovery to import simulator/workloads reliably.
- **Performance**: Achieved a combined score of 3.19 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Memoization and controlled branching reduce simulator calls and help meet the time budget, while local improvements further lower makespan beyond the beam result. Randomized starts and sampling introduce run-to-run variance without a fixed seed.
**Program Identifier:** Generation 2 - Patch Name beam_search_local_improve - Correct Program: True

**Program Name: Multi-start Greedy Scheduler with Lookahead and Local Search**
- **Implementation**: Uses a multi-start greedy constructor with full candidate evaluation, limited two-step lookahead, and a memoized cost cache. Final schedules are refined via adjacent-swap hill climbing and accept-if-better random insertions, with starts seeded from lowest-cost singletons.
- **Performance**: Combined score 3.40 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Memoization and lookahead improve selection quality and reduce redundant cost calls, while local search finds additional improvements after greedy construction. Runtime is mitigated by sampling and bounded local moves, though full candidate evaluation per step remains a potential bottleneck on larger instances.
**Program Identifier:** Generation 3 - Patch Name greedy_full_eval_beam_local - Correct Program: True

**Program Name: Tournament-ILS Transaction Scheduler**
- **Implementation**: Builds a pairwise preference matrix from O(n^2) length-1/2 simulations to score transactions and locally sort via tournament comparisons, then applies memoized true-cost refinement with one adjacent-swap pass, limited ruin-and-recreate (sampled insert positions), and sampled insertion moves; refinement budget scales with num_seqs. A cached evaluator avoids redundant simulator calls across candidates.
- **Performance**: Combined score 2.87 on 3 workloads (300 transactions); all validation tests passed.
- **Feedback**: Pairwise surrogate costs provided strong ordering signals and reduced expensive evaluations, with memoization further decreasing simulator calls. The constrained ILS budget (single true-cost pass and up to two ruin-and-recreate tries) likely caps peak optimality while keeping runtime controlled.
**Program Identifier:** Generation 4 - Patch Name pairwise_tournament_rank_ils - Correct Program: True

**Program Name: MCTS + VND Transaction Scheduler**
- **Implementation**: UCT-based MCTS over partial schedules with progressive widening, greedy-biased expansion, cost caching, and a transposition table; rollouts use limited lookahead with pruning and are followed by VND local search (adjacent swaps, insertions, small block moves). The final schedule is extracted via most-visited children with greedy fallback, and evaluated across three workloads.
- **Performance**: Combined score: 0.0; did not pass validation.
- **Feedback**: Failures likely stem from nondeterminism (no fixed RNG seed), heavy iteration budgets causing timeouts, and brittle repo path discovery; partial-cost reliance may also mismatch the simulator API. Seed the RNG, cap/scale iteration budgets, simplify imports to avoid filesystem probing, and verify partial-cost calls against the provided Workload interface.
**Program Identifier:** Generation 5 - Patch Name uct_mcts_vnd_scheduler - Correct Program: False

**Program Name: Hybrid Beam-GRASP Transaction Scheduler**
- **Implementation**: Alternates a beam search with shallow lookahead and a GRASP constructor, using adaptive beam/branch sizes scaled by N and a shared memoized cost cache under a 0.35s per-workload time budget. A local search phase (adjacent swaps, random swaps, sampled insertions) refines each constructed sequence.
- **Performance**: Achieved combined score 1.56 on 3 workloads (300 transactions) within the time budget, and passed all validation tests.
- **Feedback**: The hybrid construction plus local improvement consistently finds low-makespan schedules under tight time constraints, aided by caching and adaptive sampling. Beam truncation with greedy completion can occur when the budget is tight, but outputs remain valid.
**Program Identifier:** Generation 6 - Patch Name beam_grasp_ils_hybrid - Correct Program: True

**Program Name: Multi-start Greedy VNS Transaction Scheduler**
- **Implementation**: Uses a memoized partial-sequence evaluator with multi-start greedy construction (limited lookahead) and Variable Neighborhood Search combining adjacent swaps, sampled relocations, and light ruin-and-recreate; seeding is diversified via singleton-cost rankings and budgets adapt to problem size. Includes adaptive candidate sampling and restart strategies to control simulator calls and runtime.
- **Performance**: Combined score 3.24 across three workloads (300 transactions); produced valid schedules and passed all validation tests.
- **Feedback**: Memoization significantly cuts simulator evaluations, enabling stronger local search within the given budget, while adaptive sampling and restrained ruin-and-recreate maintain good makespan-quality/runtime trade-offs. Time-based RNG seeding yields non-deterministic results across runs.
**Program Identifier:** Generation 7 - Patch Name greedy_lookahead_rr_vns - Correct Program: True

**Program Name: Marginal-Cost LNS Transaction Scheduler**
- **Implementation**: Employs a marginal-cost-guided LNS: a lazy candidate-pool greedy constructor with limited lookahead builds seeds, a global cost cache accelerates evals, adjacent-swap hill-climb cleans up, and hot windows (chosen via prefix marginals) are reordered using budgeted permutation enumeration/sampling; targeted relocate moves, multi-start seeding, and final random insertions provide additional refinement.
- **Performance**: Achieved a combined score of 3.18 across 3 workloads (300 transactions), producing valid schedules and passing all validation tests.
- **Feedback**: Evaluation indicates robust correctness and effective heuristic improvements from caching and windowed LNS/relocate moves; the score suggests remaining headroom, potentially addressable via adaptive pool/window sizes or dynamic permutation budgets.
**Program Identifier:** Generation 8 - Patch Name marginal_lns_pool - Correct Program: True

**Program Name: Tournament-Guided Greedy VNS Scheduler**
- **Implementation**: Uses pairwise-tournament-guided greedy construction with limited lookahead and a global memoized cost cache. Precomputes singleton/pairwise costs to form preference margins, applies multi-start seeding, and refines schedules via VNS (tournament bubble cleanup, adjacent swaps, relocations, non-adjacent swaps, and ruin-and-recreate).
- **Performance**: Achieved combined score 3.12 across 3 workloads (300 transactions), passing all validation tests.
- **Feedback**: Precomputing pairwise preferences and caching partial evaluations effectively cut simulator calls and guided the search toward low-conflict orderings. Multi-start plus VNS consistently improved makespan, and size-aware budgeting maintained stable performance across varying workload complexities.
**Program Identifier:** Generation 9 - Patch Name pairwise_guided_greedy_vns - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

## Successful Algorithmic Patterns
- Memoized partial-cost evaluation drove the biggest gains. The current best program, Beam-search transaction scheduler with memoized costs (score 3.40), caches prefix costs and reuses them throughout beam expansion. Similar caching appears in other high scorers (Beam + local search: 3.19; Multi-start Greedy VNS: 3.24; Marginal-Cost LNS: 3.18; Tournament-Guided Greedy VNS: 3.12), consistently reducing simulator calls and enabling deeper/broader search.
- Structured search with adaptive breadth outperformed naive greedy. The best program’s dynamic beam/branch sizing (beam ≤32, branch ≤24) plus uniqueness pruning maintained strong exploration within time budgets, significantly improving over the Greedy sampled scheduler (2.65).
- Random restarts increased robustness. The best program uses multiple restarts (num_seqs=10 in evaluation) and prunes to top unique prefixes per depth, which stabilized performance and helped reach the top score while keeping stochastic pruning under control.
- Lightweight local search is helpful but not necessary to reach top score. Programs combining constructive heuristics plus local improvement (e.g., Multi-start Greedy Scheduler with Lookahead and Local Search at 3.40; Greedy VNS at 3.24; Beam + local search at 3.19) show consistent gains, but the best beam-only approach already achieved 3.40 through strong construction quality and caching.

## Ineffective Approaches
- Overly heavy/planned search without safeguards led to failures. The MCTS + VND scheduler (0.0) suffered from nondeterminism (no fixed RNG seed), large iteration budgets causing timeouts, and brittle path discovery. Reliance on partial-costs without tight integration to the simulator API contributed to instability.
- Tight global time caps degraded solution quality. The Hybrid Beam-GRASP scheduler (1.56) enforced a ~0.35s per-workload budget, triggering beam truncation and greedy completion, which hurt makespan quality despite correctness.
- Full candidate evaluation at every construction step can become a bottleneck. The Multi-start Greedy Scheduler with Lookahead and Local Search tied the top score (3.40) but feedback notes full-step evaluation as a latent scalability risk. Where not offset by strong caching and bounded local moves, this pattern can throttle performance on larger instances.
- Unseeded randomness induced variance and potential instability. Multiple programs note unseeded RNG as a source of variability (Greedy sampled scheduler: 2.65; Beam + local search: 3.19; Greedy VNS: 3.24), which can undermine reproducibility even when average quality is good.

## Implementation Insights
- What makes the current best program effective:
  - Memoized prefix-cost cache keyed by tuple(seq) in the beam greatly reduces redundant Workload.get_opt_seq_cost calls, directly improving runtime and enabling wider beam/branch factors.
  - Dynamic beam/branch sizing (beam_width = min(max(4, N // 8), 32); branch_factor = min(max(6, N // 10), 24)) scales exploration to problem size while bounding cost, outperforming fixed-parameter greedy (2.65) and budget-constrained hybrids (1.56).
  - Unique-prefix pruning at each depth (seen set over tuple(prefix)) avoids duplicate states and focuses evaluation on genuinely distinct partial schedules.
  - Multiple random restarts with re-evaluation of final schedules ensure consistency of reported makespans, increasing robustness relative to single-start greedy approaches.
- Cross-program coding patterns tied to performance:
  - Global/shared caches across phases (e.g., Marginal-Cost LNS at 3.18; Multi-start Greedy VNS at 3.24; Tournament-Guided Greedy VNS at 3.12) amortize expensive evaluations better than per-run caches, enabling more aggressive local search or broader construction.
  - Controlled local search neighborhoods (adjacent swaps, sampled insertions, small block moves) consistently provide post-construction improvements without overwhelming budgets (seen in 3.40, 3.24, 3.19, 3.18 programs).
  - Pairwise/surrogate precomputations (Tournament-ILS: 2.87; Tournament-Guided Greedy VNS: 3.12) cut simulator calls and offer good initial orderings, but can cap peak optimality without sufficient true-cost refinement.

## Performance Analysis
- Clear uplift from structured search with caching: moving from Greedy sampled (2.65) to memoized beam search (3.40) demonstrates the value of systematic exploration and prefix-cost reuse (+0.75 score).
- Two top-tier paths emerged:
  - Beam search with memoization and restarts (3.40, current best) achieved top performance purely via strong construction quality and efficient pruning.
  - Multi-start greedy with lookahead plus bounded local search (also 3.40) matched the top score, trading heavier per-step evaluation for post-processing improvements.
- Post-construction local search generally helps but may trade off with construction breadth under tight time budgets. Beam + local search (3.19) underperformed the best beam-only (3.40), suggesting local refinement overhead reduced beam effectiveness; by contrast, when construction is greedy, local search is crucial to close the gap (Greedy VNS: 3.24; Marginal-Cost LNS: 3.18).
- Surrogate-guided methods delivered mid-to-high performance with reduced evaluation cost but fell short of the best. Pairwise-guided strategies scored 2.87–3.12, indicating strong guidance but a ceiling without more extensive true-cost exploration/refinement.
- Aggressive or brittle strategies suffer: MCTS + VND failed entirely (0.0) due to nondeterminism, misaligned budgets, and API/path issues; heavily time-capped hybrids (1.56) validated correctness but sacrificed solution quality through premature truncation.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

1. Add a shared cross-restart memoized cache (plus marginal Δ-cache) for prefix costs
   - Move cost_cache outside run_beam_search and reuse it across all restarts for the same workload; optionally bound it with an LRU of, e.g., 200k entries. Also cache marginal deltas Δ(seq, cand) = cost(seq+[cand]) - cost(seq) keyed by (tuple(seq), cand) to avoid recomputing differences repeatedly during expansion. Evidence: global/shared caches consistently lifted performance in other top programs and will let you push wider beams/branches with the same budget.

2. Order and limit branching by marginal cost with a light two-step lookahead
   - Within each expansion, compute Δ for all candidates and sort by Δ; only expand the top_k = min(branch_factor, 12) cheapest deltas. For the final cut line, use a cheap two-step lookahead for the best few candidates (e.g., try best next-next transaction greedily using cached Δ) to refine ranking without many simulator calls. Evidence: marginal-cost guidance and bounded local lookahead improved constructive quality in high scorers, and your cache makes Δ nearly free.

3. Introduce A*-style scoring and pruning with incumbent-based cuts and a cheap lower bound
   - Maintain the best full cost found so far (incumbent) and prune any prefix where cost(prefix) ≥ incumbent. Score beam entries by f = g(prefix) + h(remaining), where h is a fast lower bound such as h = max(singleton_cost[i] for i in remaining), with singleton_cost[i] = get_opt_seq_cost([i]) precomputed and cached; use f for beam ranking and as a secondary tie-breaker even if h is imperfect. Periodically greedily complete the current best beam prefix to refresh a strong incumbent early, tightening pruning. Evidence: structured search with better pruning enabled wider effective exploration and faster convergence in top programs.

4. Add a bounded, cache-aware local search pass on the returned schedule
   - After beam search returns a full sequence, run a small neighborhood search using cached evaluations: adjacent swaps over a sliding window plus sampled insertions (e.g., 20–50 total moves, accept-if-improves, stop on 5 consecutive non-improves). Reuse the same cost_cache/Δ-cache so most checks are incremental. Evidence: lightweight local improvement reliably adds gains without derailing runtime when construction is already strong.

5. Make restarts deterministic and diversity-driven with structured seeding and adaptive widths
   - Seed RNG deterministically per workload (e.g., seed = 1729 + workload.num_txns) for reproducibility, then ensure diversity by mixing initial beam seeds: include the k cheapest singletons, k largest singletons, and k random picks (k ≈ beam_width/3 each). Vary beam_width/branch_factor across restarts to trade breadth vs. depth (e.g., first restart: beam=1.25× default, branch=0.8×; second: default; third: beam=0.8×, branch=1.25×), keeping within the current min/max bounds. Evidence: random restarts helped robustness; controlling diversity and breadth adaptively should stabilize and occasionally surpass current best runs.