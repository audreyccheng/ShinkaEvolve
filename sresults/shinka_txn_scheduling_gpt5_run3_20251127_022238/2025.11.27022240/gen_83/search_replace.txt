<mcts_widen_lookahead_antibuddy>
Enhance MCTS candidate generation and greedy rollouts with anti-buddy filtering and shallow lookahead, add elite crossover polishing, and extend local refinement with limited non-adjacent swaps. This concentrates exploration on low-conflict adjacencies and prunes poor branches using incumbent-aware checks, improving makespan without heavy runtime cost.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    # Buddy lists derived from sampled adjacencies; fallback to low-singleton
    def build_buddies(max_buddies=8):
        buddies = {t: [] for t in all_txns}
        for t in all_txns:
            row = P.get(t, {})
            if row:
                scored = sorted([(row[u], u) for u in row.keys() if u != t], key=lambda x: x[0])
                buddies[t] = [u for _d, u in scored[:max_buddies]]
            else:
                buddies[t] = [u for u in singles_sorted if u != t][:max_buddies]
        return buddies

    buddies = build_buddies(max_buddies=8)
=======
    # Anti-buddy thresholds from P (75th percentile of positive margins per last)
    anti_buddy_thresh = {}
    for t in all_txns:
        row = P.get(t, {})
        pos_vals = [v for v in row.values() if v > 0]
        if pos_vals:
            pos_vals.sort()
            idx = int(0.75 * (len(pos_vals) - 1))
            anti_buddy_thresh[t] = pos_vals[idx]
        else:
            anti_buddy_thresh[t] = float('inf')

    def is_antibuddy(last, cand):
        if last is None:
            return False
        v = P.get(last, {}).get(cand, 0.0)
        thr = anti_buddy_thresh.get(last, float('inf'))
        return v > 0 and v >= thr

    # Buddy lists derived from sampled adjacencies; fallback to low-singleton
    def build_buddies(max_buddies=8):
        buddies = {t: [] for t in all_txns}
        for t in all_txns:
            row = P.get(t, {})
            if row:
                scored = sorted([(row[u], u) for u in row.keys() if u != t], key=lambda x: x[0])
                buddies[t] = [u for _d, u in scored[:max_buddies]]
            else:
                buddies[t] = [u for u in singles_sorted if u != t][:max_buddies]
        return buddies

    buddies = build_buddies(max_buddies=8)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def greedy_rollout(seq, rem_set, branch_k=12, incumbent=None):
        seq_out = list(seq)
        rem = set(rem_set)
        cur_cost = eval_seq_cost(seq_out) if seq_out else 0
        while rem and time_left():
            if incumbent is not None and lb_singleton(cur_cost, rem) >= incumbent:
                # Abort rollout if it's already worse than incumbent
                break
            last = seq_out[-1] if seq_out else None
            rem_list = list(rem)
            pool = []
            if last is not None:
                pool.extend([u for u in buddies.get(last, []) if u in rem])
            # add top few by singleton
            low_single = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(4, len(rem_list))]
            for u in low_single:
                if u not in pool:
                    pool.append(u)
            # add random to fill
            need = max(0, branch_k - len(pool))
            if need > 0:
                others = [x for x in rem_list if x not in pool]
                if others:
                    pool.extend(rng.sample(others, min(need, len(others))))
            if not pool:
                pool = rem_list if len(rem_list) <= branch_k else rng.sample(rem_list, branch_k)
            prefix_tuple = tuple(seq_out)
            best_t = None
            best_c = float('inf')
            for t in pool:
                c = eval_ext_cost(prefix_tuple, t)
                if c < best_c:
                    best_c = c
                    best_t = t
            if best_t is None:
                # Fallback
                t = rem_list[0]
                best_t = t
                best_c = eval_ext_cost(prefix_tuple, t)
            seq_out.append(best_t)
            rem.remove(best_t)
            cur_cost = best_c
        if rem:
            seq_out.extend(list(rem))
            cur_cost = eval_seq_cost(seq_out)
        return cur_cost, seq_out
=======
    def greedy_rollout(seq, rem_set, branch_k=12, incumbent=None):
        seq_out = list(seq)
        rem = set(rem_set)
        cur_cost = eval_seq_cost(seq_out) if seq_out else 0
        while rem and time_left():
            if incumbent is not None and lb_singleton(cur_cost, rem) >= incumbent:
                # Abort rollout if it's already worse than incumbent
                break
            last = seq_out[-1] if seq_out else None
            rem_list = list(rem)
            pool = []
            if last is not None:
                pool.extend([u for u in buddies.get(last, []) if u in rem])
            # add top few by singleton
            low_single = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(4, len(rem_list))]
            for u in low_single:
                if u not in pool:
                    pool.append(u)
            # add random to fill
            need = max(0, branch_k - len(pool))
            if need > 0:
                others = [x for x in rem_list if x not in pool]
                if others:
                    pool.extend(rng.sample(others, min(need, len(others))))
            if not pool:
                pool = rem_list if len(rem_list) <= branch_k else rng.sample(rem_list, branch_k)

            # Evaluate immediate extension costs and apply anti-buddy filtering
            prefix_tuple = tuple(seq_out)
            scored = []
            best_immediate = float('inf')
            for t in pool:
                c = eval_ext_cost(prefix_tuple, t)
                scored.append((c, t))
                if c < best_immediate:
                    best_immediate = c
            # 1% tolerance for anti-buddy skip
            tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
            filtered = []
            for c, t in scored:
                if last is not None and is_antibuddy(last, t) and c > tol:
                    continue
                filtered.append((c, t))
            if not filtered:
                filtered = scored

            filtered.sort(key=lambda x: x[0])
            best_c, best_t = filtered[0]
            if best_t is None:
                # Fallback
                t = rem_list[0]
                best_t = t
                best_c = eval_ext_cost(prefix_tuple, t)
            seq_out.append(best_t)
            rem.remove(best_t)
            cur_cost = best_c
        if rem:
            seq_out.extend(list(rem))
            cur_cost = eval_seq_cost(seq_out)
        return cur_cost, seq_out
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def make_candidates(prefix, rem, k_base=14):
        # Build a ranked candidate pool without scanning full rem
        rem_list = list(rem)
        if not rem_list:
            return []
        pool = []
        if prefix:
            last = prefix[-1]
            pool.extend([u for u in buddies.get(last, []) if u in rem])
        # add top low-singleton from rem
        low_single = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(6, len(rem_list))]
        for u in low_single:
            if u not in pool:
                pool.append(u)
        # add random for diversity
        need = max(0, 2 * k_base - len(pool))
        if need > 0:
            others = [x for x in rem_list if x not in pool]
            if others:
                pool.extend(rng.sample(others, min(need, len(others))))
        # Rank by extension cost
        pt = tuple(prefix)
        scored = []
        for u in pool:
            c = eval_ext_cost(pt, u)
            scored.append((c, u))
        scored.sort(key=lambda x: x[0])
        ranked = [u for _c, u in scored]
        # trim to k_base*2 for widening use
        return ranked[:min(len(ranked), 2 * k_base)]
=======
    def make_candidates(prefix, rem, k_base=14):
        # Build a ranked candidate pool without scanning full rem
        rem_list = list(rem)
        if not rem_list:
            return []
        pool = []
        if prefix:
            last = prefix[-1]
            pool.extend([u for u in buddies.get(last, []) if u in rem])
        # add top low-singleton from rem
        low_single = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(6, len(rem_list))]
        for u in low_single:
            if u not in pool:
                pool.append(u)
        # add random for diversity
        need = max(0, 2 * k_base - len(pool))
        if need > 0:
            others = [x for x in rem_list if x not in pool]
            if others:
                pool.extend(rng.sample(others, min(need, len(others))))
        if not pool:
            return []

        # Rank by immediate extension and shallow lookahead with anti-buddy gating
        pt = tuple(prefix)
        last = prefix[-1] if prefix else None
        tmp = []
        best_immediate = float('inf')
        for u in pool:
            ec = eval_ext_cost(pt, u)
            tmp.append((ec, u))
            if ec < best_immediate:
                best_immediate = ec

        tol = best_immediate * 1.01 if best_immediate < float('inf') else float('inf')
        scored = []
        for ec, u in tmp:
            # incumbent pruning on immediate extension
            if ec >= incumbent_cost:
                continue
            if last is not None and is_antibuddy(last, u) and ec > tol:
                continue
            # shallow lookahead: try a few buddies of u or random next
            la_best = ec
            new_rem = set(rem)
            if u in new_rem:
                new_rem.remove(u)
            la_pool = [v for v in buddies.get(u, []) if v in new_rem]
            if not la_pool:
                la_pool = list(new_rem)
            if len(la_pool) > 4:
                la_pool = rng.sample(la_pool, 4)
            new_pt = tuple(list(prefix) + [u])
            for nxt in la_pool:
                c2 = eval_ext_cost(new_pt, nxt)
                if c2 < la_best:
                    la_best = c2
            scored.append((ec, la_best, u))

        if not scored:
            # fallback to original pool order if all pruned
            scored = [(ec, ec, u) for ec, u in tmp]

        scored.sort(key=lambda x: (x[0], x[1]))
        ranked = [u for _ec, _la, u in scored]
        # trim to k_base*2 for widening use
        return ranked[:min(len(ranked), 2 * k_base)]
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        # Occasionally perform elite crossover exploration
        if iterations % 30 == 0 and len(elite) >= 2 and time_left():
            p1 = elite[0][1]
            p2 = elite[min(1, len(elite) - 1)][1] if rng.random() < 0.5 else elite[rng.randrange(len(elite))][1]
            child_seq = ox_crossover(p1, p2)
            # Greedy polishing from child prefix: re-evaluate true cost or short rollout tweak
            c_child = eval_seq_cost(child_seq)
            if c_child < incumbent_cost:
                incumbent_cost, incumbent_seq = c_child, child_seq
                add_elite(incumbent_cost, incumbent_seq)
=======
        # Occasionally perform elite crossover exploration
        if iterations % 30 == 0 and len(elite) >= 2 and time_left():
            p1 = elite[0][1]
            p2 = elite[min(1, len(elite) - 1)][1] if rng.random() < 0.5 else elite[rng.randrange(len(elite))][1]
            child_seq = ox_crossover(p1, p2)
            # Quick adjacent bubble improvement guided by pairwise margins
            c_child = eval_seq_cost(child_seq)
            if time_left():
                improved = True
                passes = 0
                while improved and passes < 1 and time_left():
                    improved = False
                    passes += 1
                    upto = min(len(child_seq) - 1, 14)
                    for i in range(upto):
                        a, b = child_seq[i], child_seq[i + 1]
                        # Skip if adjacency already preferred
                        if P.get(a, {}).get(b, 0.0) <= 0 and rng.random() < 0.5:
                            continue
                        cand = child_seq[:]
                        cand[i], cand[i + 1] = cand[i + 1], cand[i]
                        c_try = eval_seq_cost(cand)
                        if c_try < c_child:
                            child_seq, c_child = cand, c_try
                            improved = True
            if c_child < incumbent_cost:
                incumbent_cost, incumbent_seq = c_child, child_seq
                add_elite(incumbent_cost, incumbent_seq)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def local_refine(seq, cur_cost):
        best_seq = seq[:]
        best_cost = cur_cost
        n = len(best_seq)
        if n <= 2 or not time_left():
            return best_cost, best_seq

        # Adjacent swap hill-climb (one pass)
        improved = True
        passes = 0
        while improved and passes < 2 and time_left():
            improved = False
            passes += 1
            for i in range(n - 1):
                if not time_left():
                    break
                cand = best_seq[:]
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_seq_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True

        # Identify worst boundaries as surrogate targets
        margins = []
        for k in range(n - 1):
            if not time_left():
                break
            margins.append((pair_pref(best_seq[k], best_seq[k + 1]), k))
        margins.sort(reverse=True, key=lambda x: x[0])
        focus = [k for _, k in margins[:max(8, n // 10)]]

        # Relocation moves with bias toward focus
        tries = 0
        max_tries = 120
        while tries < max_tries and time_left():
            tries += 1
            if focus and rng.random() < 0.7:
                k = rng.choice(focus)
                i = k if rng.random() < 0.5 else k + 1
                j = rng.randrange(n)
            else:
                i, j = rng.randrange(n), rng.randrange(n)
            if i == j:
                continue
            cand = best_seq[:]
            v = cand.pop(i)
            cand.insert(j, v)
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        # Small block reinsert around worst boundary
        if n >= 6 and time_left():
            if focus:
                k = focus[0]
                start = max(0, min(k - 1, n - 4))
                w = min(4, n - start)
            else:
                start = rng.randrange(0, max(1, n - 4))
                w = min(4, n - start)
            block = best_seq[start:start + w]
            remain = best_seq[:start] + best_seq[start + w:]
            best_local = best_cost
            best_candidate = None
            for pos in range(max(0, start - 3), min(len(remain) + 1, start + 4)):
                cand = remain[:]
                for offset, x in enumerate(block):
                    cand.insert(pos + offset, x)
                c = eval_seq_cost(cand)
                if c < best_local:
                    best_local = c
                    best_candidate = cand
            if best_candidate is not None:
                best_cost, best_seq = best_local, best_candidate

        return best_cost, best_seq
=======
    def local_refine(seq, cur_cost):
        best_seq = seq[:]
        best_cost = cur_cost
        n = len(best_seq)
        if n <= 2 or not time_left():
            return best_cost, best_seq

        # Adjacent swap hill-climb (up to 2 passes)
        improved = True
        passes = 0
        while improved and passes < 2 and time_left():
            improved = False
            passes += 1
            for i in range(n - 1):
                if not time_left():
                    break
                cand = best_seq[:]
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_seq_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True

        # Identify worst boundaries as surrogate targets
        margins = []
        for k in range(n - 1):
            if not time_left():
                break
            margins.append((pair_pref(best_seq[k], best_seq[k + 1]), k))
        margins.sort(reverse=True, key=lambda x: x[0])
        focus = [k for _, k in margins[:max(8, n // 10)]]

        # Relocation moves with bias toward focus
        tries = 0
        max_tries = 120
        while tries < max_tries and time_left():
            tries += 1
            if focus and rng.random() < 0.7:
                k = rng.choice(focus)
                i = k if rng.random() < 0.5 else k + 1
                j = rng.randrange(n)
            else:
                i, j = rng.randrange(n), rng.randrange(n)
            if i == j:
                continue
            cand = best_seq[:]
            v = cand.pop(i)
            cand.insert(j, v)
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        # Small block reinsert around worst boundary
        if n >= 6 and time_left():
            if focus:
                k = focus[0]
                start = max(0, min(k - 1, n - 4))
                w = min(4, n - start)
            else:
                start = rng.randrange(0, max(1, n - 4))
                w = min(4, n - start)
            block = best_seq[start:start + w]
            remain = best_seq[:start] + best_seq[start + w:]
            best_local = best_cost
            best_candidate = None
            for pos in range(max(0, start - 3), min(len(remain) + 1, start + 4)):
                cand = remain[:]
                for offset, x in enumerate(block):
                    cand.insert(pos + offset, x)
                c = eval_seq_cost(cand)
                if c < best_local:
                    best_local = c
                    best_candidate = cand
            if best_candidate is not None:
                best_cost, best_seq = best_local, best_candidate

        # Limited non-adjacent swap (2-opt style without reversal), gated by surrogate
        swap_tries = 60
        while swap_tries > 0 and time_left():
            swap_tries -= 1
            i = rng.randrange(0, n - 2)
            j = rng.randrange(i + 2, n)
            # Surrogate gating: only attempt if both boundaries are weak
            bad_i = pair_pref(best_seq[i], best_seq[i + 1]) > 0
            bad_j = pair_pref(best_seq[j - 1], best_seq[j]) > 0 if j < n else True
            if not (bad_i or bad_j):
                if rng.random() < 0.6:
                    continue
            cand = best_seq[:]
            cand[i], cand[j] = cand[j], cand[i]
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>