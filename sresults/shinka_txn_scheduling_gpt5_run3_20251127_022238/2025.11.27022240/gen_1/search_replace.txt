<NAME>
beam_search_with_memoized_costs
</NAME>

<DESCRIPTION>
I replace the purely greedy sampler with a beam search that uses multiple random restarts, limited branching, and memoization of partial schedule costs. The new approach explores multiple promising partial schedules at each step (beam width) and expands each with a limited number of randomly sampled candidates (branch factor). Costs for partial prefixes are cached to avoid recomputation across expansions within a restart. This balances exploration and exploitation, reducing the chance of getting stuck in a poor greedy path while keeping runtime reasonable. By directly optimizing on workload.get_opt_seq_cost for partial prefixes, the search makes decisions aligned with actual makespan, not proxies. Multiple restarts further improve robustness. This should lower the makespan across workloads and increase the combined score.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using greedy cost sampling strategy.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    def get_greedy_cost_sampled(num_samples, sample_rate):
        # greedy with random starting point
        start_txn = random.randint(0, workload.num_txns - 1)
        txn_seq = [start_txn]
        remaining_txns = [x for x in range(0, workload.num_txns)]
        remaining_txns.remove(start_txn)
        running_cost = workload.txns[start_txn][0][3]

        for i in range(0, workload.num_txns - 1):
            min_cost = 100000  # MAX
            min_relative_cost = 10
            min_txn = -1
            holdout_txns = []
            done = False
            key_maps = []

            sample = random.random()
            if sample > sample_rate:
                idx = random.randint(0, len(remaining_txns) - 1)
                t = remaining_txns[idx]
                txn_seq.append(t)
                remaining_txns.pop(idx)
                continue

            for j in range(0, num_samples):
                idx = 0
                if len(remaining_txns) > 1:
                    idx = random.randint(0, len(remaining_txns) - 1)
                else:
                    done = True
                t = remaining_txns[idx]
                holdout_txns.append(remaining_txns.pop(idx))

                txn_len = workload.txns[t][0][3]
                test_seq = txn_seq.copy()
                test_seq.append(t)
                cost = 0
                cost = workload.get_opt_seq_cost(test_seq)
                if cost < min_cost:
                    min_cost = cost
                    min_txn = t
                if done:
                    break
            assert(min_txn != -1)
            running_cost = min_cost
            txn_seq.append(min_txn)
            holdout_txns.remove(min_txn)
            remaining_txns.extend(holdout_txns)

        assert len(set(txn_seq)) == workload.num_txns

        overall_cost = workload.get_opt_seq_cost(txn_seq)
        return overall_cost, txn_seq

    return get_greedy_cost_sampled(10, 1.0)
=======
def get_best_schedule(workload, num_seqs):
    """
    Find a near-optimal schedule using beam search with memoized partial costs
    and multiple random restarts.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of random restarts for the beam search

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """

    def run_beam_search():
        N = workload.num_txns
        # Dynamically size the beam and branching according to problem size
        beam_width = min(max(4, N // 8), 32)
        branch_factor = min(max(6, N // 10), 24)

        all_txns = list(range(N))
        # Memoize costs for partial prefixes to avoid recomputation
        cost_cache = {}

        def eval_seq_cost(seq):
            key = tuple(seq)
            cached = cost_cache.get(key)
            if cached is not None:
                return cached
            c = workload.get_opt_seq_cost(seq)
            cost_cache[key] = c
            return c

        # Initialize beam with the best singletons from a random pool
        init_pool_size = min(len(all_txns), beam_width * 2)
        init_candidates = random.sample(all_txns, init_pool_size) if init_pool_size > 0 else all_txns[:]
        beam = []
        for t in init_candidates:
            seq = [t]
            rem = set(all_txns)
            rem.remove(t)
            cost = eval_seq_cost(seq)
            beam.append((cost, seq, rem))
        beam.sort(key=lambda x: x[0])
        beam = beam[:max(1, min(beam_width, len(beam)))]

        # Expand the beam until full sequences are built
        steps = N - 1
        for _ in range(steps):
            new_beam = []
            for cost, seq, rem in beam:
                if not rem:
                    # Already complete; keep as-is
                    new_beam.append((cost, seq, rem))
                    continue

                rem_list = list(rem)
                # Limit branching to keep runtime reasonable
                if len(rem_list) <= branch_factor:
                    candidates = rem_list
                else:
                    candidates = random.sample(rem_list, branch_factor)

                for cand in candidates:
                    new_seq = seq + [cand]
                    new_rem = rem.copy()
                    new_rem.remove(cand)
                    new_cost = eval_seq_cost(new_seq)
                    new_beam.append((new_cost, new_seq, new_rem))

            if not new_beam:
                break

            # Keep only the top beam_width unique prefixes by current cost
            new_beam.sort(key=lambda x: x[0])
            unique = []
            seen = set()
            for entry in new_beam:
                key = tuple(entry[1])
                if key in seen:
                    continue
                seen.add(key)
                unique.append(entry)
                if len(unique) >= beam_width:
                    break
            beam = unique

        # Return the best full sequence from the beam
        best_entry = min(beam, key=lambda x: x[0])
        return best_entry[0], best_entry[1]

    best_cost = float('inf')
    best_seq = None

    # Multiple random restarts for robustness
    restarts = max(1, int(num_seqs))
    for _ in range(restarts):
        cost, seq = run_beam_search()
        if cost < best_cost:
            best_cost, best_seq = cost, seq

    return best_cost, best_seq
>>>>>>> REPLACE

</DIFF>