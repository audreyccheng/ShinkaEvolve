<prefix_dom_lookahead_pruning>
Introduce prefix-dominance pruning with shared map across restarts, add shallow lookahead ranking and child greedy probes, and make beam search incumbent-aware globally to cut expensive branches and drive toward lower makespan schedules. Also strengthen local search with boundary-focused ruin-recreate and multi-pass adjacent swaps.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    # Core beam search with incumbent tightening, guided candidate pools
    def run_beam_once():
        beam_width = min(28, max(6, N // 8))
        branch_factor = min(20, max(6, N // 10))

        # Seed beam with best singletons and a few randoms for diversity
        seeds = []
        top_seeds = singles_sorted[:max(beam_width * 2, 6)]
        for t in top_seeds:
            seq = [t]
            rem = set(all_txns)
            rem.remove(t)
            c = eval_seq_cost(seq)
            seeds.append((c, seq, rem))
        others = [x for x in all_txns if x not in top_seeds]
        if others:
            for t in rng.sample(others, min(4, len(others))):
                seq = [t]
                rem = set(all_txns) - {t}
                c = eval_seq_cost(seq)
                seeds.append((c, seq, rem))

        seeds.sort(key=lambda x: x[0])
        beam = seeds[:beam_width] if seeds else []

        if not beam:
            seq = all_txns[:]
            rng.shuffle(seq)
            return eval_seq_cost(seq), seq

        incumbent_cost = float('inf')
        incumbent_seq = None

        # Early incumbent via greedy finish of best prefix
        if time_left():
            c_try, s_try = greedy_finish(beam[0][1], beam[0][2], branch_factor=max(8, branch_factor), incumbent=incumbent_cost)
            if len(s_try) == N and c_try < incumbent_cost:
                incumbent_cost, incumbent_seq = c_try, s_try

        steps = N - 1
        for _ in range(steps):
            if not time_left():
                break
            new_beam = []

            # Periodically tighten incumbent by completing top-k prefixes
            for (cost_so_far, seq, rem) in beam[:min(2, len(beam))]:
                if not time_left():
                    break
                c_try, s_try = greedy_finish(seq, rem, branch_factor=max(8, branch_factor), incumbent=incumbent_cost)
                if len(s_try) == N and c_try < incumbent_cost:
                    incumbent_cost, incumbent_seq = c_try, s_try

            for cost_so_far, seq, rem in beam:
                if not rem:
                    # full sequence
                    if cost_so_far < incumbent_cost:
                        incumbent_cost, incumbent_seq = cost_so_far, seq[:]
                    new_beam.append((cost_so_far, seq, rem, cost_so_far))
                    continue

                # incumbent pruning on prefix and simple LB
                if cost_so_far >= incumbent_cost:
                    continue
                if lb_singleton(cost_so_far, rem) >= incumbent_cost:
                    continue

                rem_list = list(rem)
                # Build candidate pool: buddies of last + low-singleton + random fill (limit to 2*branch)
                cand_pool = []
                if seq:
                    last = seq[-1]
                    cand_pool.extend([x for x in buddies.get(last, []) if x in rem])
                low_s = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(5, len(rem_list))]
                for u in low_s:
                    if u not in cand_pool:
                        cand_pool.append(u)
                need = max(0, 2 * branch_factor - len(cand_pool))
                if need > 0:
                    others = [x for x in rem_list if x not in cand_pool]
                    if others:
                        cand_pool.extend(rng.sample(others, min(need, len(others))))
                if not cand_pool:
                    cand_pool = rem_list if len(rem_list) <= 2 * branch_factor else rng.sample(rem_list, 2 * branch_factor)

                prefix_tuple = tuple(seq)
                scored = []
                for t in cand_pool:
                    if not time_left():
                        break
                    ec = eval_ext_cost(prefix_tuple, t)
                    if ec >= incumbent_cost:
                        continue
                    # Rank primarily by extension cost; add slight bias for delta smoothness
                    delta = ec - cost_so_far
                    rank = (ec, delta)
                    scored.append((rank, ec, t))
                if not scored:
                    continue
                scored.sort(key=lambda x: (x[0][0], x[0][1]))
                top = scored[:min(branch_factor, len(scored))]

                for _rank, ec, t in top:
                    new_seq = seq + [t]
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    # child LB prune
                    if lb_singleton(ec, new_rem) >= incumbent_cost:
                        continue
                    new_beam.append((ec, new_seq, new_rem, ec))

            if not new_beam:
                break

            # Keep top unique prefixes by current cost surrogate
            new_beam.sort(key=lambda x: x[3])
            unique = []
            seen = set()
            for entry in new_beam:
                key = tuple(entry[1])
                if key in seen:
                    continue
                seen.add(key)
                unique.append((entry[0], entry[1], entry[2]))
                if len(unique) >= beam_width:
                    break
            beam = unique

        # Final greedy completion of remaining prefixes
        best_cost = incumbent_cost
        best_seq = incumbent_seq
        for cost_so_far, seq, rem in beam:
            if not time_left():
                break
            c_fin, s_fin = greedy_finish(seq, rem, branch_factor=max(8, branch_factor), incumbent=incumbent_cost)
            if len(s_fin) == N and c_fin < best_cost:
                best_cost, best_seq = c_fin, s_fin

        if best_seq is None:
            seq = all_txns[:]
            rng.shuffle(seq)
            best_seq = seq
            best_cost = eval_seq_cost(seq)
        return best_cost, best_seq
=======
    # Shared prefix-dominance and global incumbent across restarts
    prefix_dom = {}
    global_inc_cost = float('inf')
    global_inc_seq = None

    def make_signature(rem_set, seq, k_suffix=3):
        tail = tuple(seq[-k_suffix:]) if len(seq) >= k_suffix else tuple(seq)
        return (frozenset(rem_set), tail)

    # Simple wrapper to use pair_delta as adjacency surrogate
    def pair_cost(a, b):
        return pair_delta(a, b)

    # Core beam search with prefix-dominance, shallow lookahead, and child greedy probes
    def run_beam_once():
        nonlocal global_inc_cost, global_inc_seq

        beam_width = min(28, max(6, N // 8))
        branch_factor = min(20, max(6, N // 10))
        lookahead_top = 3
        probe_children = 4
        k_suffix = 3

        # Seed beam with best singletons and a few randoms for diversity
        seeds = []
        top_seeds = singles_sorted[:max(beam_width * 2, 6)]
        for t in top_seeds:
            seq = [t]
            rem = set(all_txns)
            rem.remove(t)
            c = eval_seq_cost(seq)
            # prefix-dominance record
            sig = make_signature(rem, seq, k_suffix)
            prev = prefix_dom.get(sig)
            if prev is None or c < prev:
                prefix_dom[sig] = c
            seeds.append((c, seq, rem))
        others = [x for x in all_txns if x not in top_seeds]
        if others:
            for t in rng.sample(others, min(4, len(others))):
                seq = [t]
                rem = set(all_txns) - {t}
                c = eval_seq_cost(seq)
                sig = make_signature(rem, seq, k_suffix)
                prev = prefix_dom.get(sig)
                if prev is None or c < prev:
                    prefix_dom[sig] = c
                seeds.append((c, seq, rem))

        seeds.sort(key=lambda x: x[0])
        beam = seeds[:beam_width] if seeds else []

        if not beam:
            seq = all_txns[:]
            rng.shuffle(seq)
            return eval_seq_cost(seq), seq

        # Incumbent shared with restarts; tighten early via greedy finish of best prefix
        if time_left():
            c_try, s_try = greedy_finish(beam[0][1], beam[0][2], branch_factor=max(8, branch_factor), incumbent=global_inc_cost)
            if len(s_try) == N and c_try < global_inc_cost:
                global_inc_cost, global_inc_seq = c_try, s_try

        steps = N - 1
        for _ in range(steps):
            if not time_left():
                break
            new_beam = []

            # Periodically tighten incumbent by completing top-2 prefixes
            for (cost_so_far, seq, rem) in beam[:min(2, len(beam))]:
                if not time_left():
                    break
                c_try, s_try = greedy_finish(seq, rem, branch_factor=max(8, branch_factor), incumbent=global_inc_cost)
                if len(s_try) == N and c_try < global_inc_cost:
                    global_inc_cost, global_inc_seq = c_try, s_try

            for cost_so_far, seq, rem in beam:
                if not rem:
                    # full sequence; propagate
                    if cost_so_far < global_inc_cost:
                        global_inc_cost, global_inc_seq = cost_so_far, seq[:]
                    new_beam.append((cost_so_far, seq, rem, cost_so_far))
                    continue

                # incumbent pruning on prefix and singleton-LB
                if cost_so_far >= global_inc_cost:
                    continue
                if lb_singleton(cost_so_far, rem) >= global_inc_cost:
                    continue

                # prefix-dominance pruning for current prefix
                sig_cur = make_signature(rem, seq, k_suffix)
                prev_best = prefix_dom.get(sig_cur)
                if prev_best is not None and cost_so_far >= prev_best:
                    continue
                # record/update
                if prev_best is None or cost_so_far < prev_best:
                    prefix_dom[sig_cur] = cost_so_far

                rem_list = list(rem)
                # Build candidate pool: buddies of last + low-singleton + random fill (limit to 2*branch)
                cand_pool = []
                if seq:
                    last = seq[-1]
                    cand_pool.extend([x for x in buddies.get(last, []) if x in rem])
                low_s = sorted(rem_list, key=lambda t: singleton_cost.get(t, float('inf')))[:min(5, len(rem_list))]
                for u in low_s:
                    if u not in cand_pool:
                        cand_pool.append(u)
                need = max(0, 2 * branch_factor - len(cand_pool))
                if need > 0:
                    others = [x for x in rem_list if x not in cand_pool]
                    if others:
                        cand_pool.extend(rng.sample(others, min(need, len(others))))
                if not cand_pool:
                    cand_pool = rem_list if len(rem_list) <= 2 * branch_factor else rng.sample(rem_list, 2 * branch_factor)

                prefix_tuple = tuple(seq)
                scored = []
                for t in cand_pool:
                    if not time_left():
                        break
                    ec = eval_ext_cost(prefix_tuple, t)
                    if ec >= global_inc_cost:
                        continue
                    # Child LB
                    # Evaluate shallow lookahead from child using buddies-first pool
                    new_seq = seq + [t]
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    lb_child = lb_singleton(ec, new_rem)
                    if lb_child >= global_inc_cost:
                        continue

                    la_best = float('inf')
                    if new_rem and time_left():
                        la_pool = [u for u in buddies.get(t, []) if u in new_rem]
                        if not la_pool:
                            la_pool = list(new_rem)
                        if len(la_pool) > lookahead_top:
                            la_pool = rng.sample(la_pool, lookahead_top)
                        new_prefix_tuple = tuple(new_seq)
                        for nxt in la_pool:
                            c2 = eval_ext_cost(new_prefix_tuple, nxt)
                            if c2 < la_best:
                                la_best = c2
                    # rank by a conservative score combining LB and lookahead
                    rank_score = min(la_best, lb_child) if la_best != float('inf') else lb_child
                    if rank_score == float('inf'):
                        rank_score = ec
                    delta = ec - cost_so_far
                    scored.append(((rank_score, delta), ec, t, new_seq, new_rem))

                if not scored:
                    continue
                scored.sort(key=lambda x: (x[0][0], x[0][1]))
                top = scored[:min(branch_factor, len(scored))]

                # For a few best children, do greedy probes and update/prune
                idx_child = 0
                for (_rank, ec, t, new_seq, new_rem) in [(x[0], x[1], x[2], x[3], x[4]) for x in top]:
                    if not time_left():
                        break
                    sig_child = make_signature(new_rem, new_seq, k_suffix)
                    prev = prefix_dom.get(sig_child)
                    if prev is not None and ec >= prev:
                        continue
                    # Optional greedy probe for first few children
                    rank_score = ec
                    if idx_child < probe_children and time_left():
                        g_cost, g_seq = greedy_finish(new_seq, new_rem, branch_factor=max(6, N // 12), incumbent=global_inc_cost)
                        if len(g_seq) == N and g_cost < global_inc_cost:
                            global_inc_cost, global_inc_seq = g_cost, g_seq
                        # prune dominated children by probe
                        if g_cost >= global_inc_cost:
                            idx_child += 1
                            continue
                        rank_score = min(rank_score, g_cost)
                    idx_child += 1
                    # update dominance table
                    if prev is None or ec < prev:
                        prefix_dom[sig_child] = ec
                    new_beam.append((ec, new_seq, new_rem, rank_score))

            if not new_beam:
                break

            # Keep top unique prefixes by rank_score
            new_beam.sort(key=lambda x: x[3])
            unique = []
            seen = set()
            for entry in new_beam:
                key = tuple(entry[1])
                if key in seen:
                    continue
                seen.add(key)
                unique.append((entry[0], entry[1], entry[2]))
                if len(unique) >= beam_width:
                    break
            beam = unique

        # Final greedy completion of remaining prefixes
        best_cost = global_inc_cost
        best_seq = global_inc_seq
        for cost_so_far, seq, rem in beam:
            if not time_left():
                break
            c_fin, s_fin = greedy_finish(seq, rem, branch_factor=max(8, branch_factor), incumbent=global_inc_cost)
            if len(s_fin) == N and c_fin < best_cost:
                best_cost, best_seq = c_fin, s_fin

        if best_seq is None:
            seq = all_txns[:]
            rng.shuffle(seq)
            best_seq = seq
            best_cost = eval_seq_cost(seq)
        return best_cost, best_seq
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Lightweight local improvement: adjacent swaps and limited relocations
    def local_improve(seq, cur_cost):
        best_seq = seq[:]
        best_cost = cur_cost
        n = len(best_seq)

        # One pass of adjacent swaps as hill climb
        for i in range(n - 1):
            if not time_left():
                break
            cand = best_seq[:]
            cand[i], cand[i + 1] = cand[i + 1], cand[i]
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        # A handful of relocations for diversity
        trials = 30
        while trials > 0 and time_left():
            trials -= 1
            i, j = rng.sample(range(n), 2)
            if i == j:
                continue
            cand = best_seq[:]
            v = cand.pop(i)
            cand.insert(j, v)
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        return best_cost, best_seq
=======
    # Lightweight but stronger local improvement: multi-pass adjacent swaps, boundary repair, and relocations
    def local_improve(seq, cur_cost):
        best_seq = seq[:]
        best_cost = cur_cost
        n = len(best_seq)

        if n <= 2:
            return best_cost, best_seq

        # Multiple adjacent-swap passes until no improvement or time cap
        for _ in range(2):
            improved = False
            for i in range(n - 1):
                if not time_left():
                    break
                cand = best_seq[:]
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_seq_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True
            if not improved or not time_left():
                break

        # Boundary-focused ruin-and-recreate around worst adjacency by pair_cost surrogate
        def boundary_repair_once(cur_seq, cur_c):
            m = len(cur_seq)
            if m < 6 or not time_left():
                return cur_c, cur_seq
            worst_idx = -1
            worst_val = -float('inf')
            for i in range(m - 1):
                if not time_left():
                    break
                v = pair_cost(cur_seq[i], cur_seq[i + 1])
                if v > worst_val:
                    worst_val = v
                    worst_idx = i
            if worst_idx < 0:
                return cur_c, cur_seq
            block_size = min(5, max(3, m // 30))
            start = max(0, min(worst_idx - block_size // 2, m - block_size))
            block = cur_seq[start:start + block_size]
            remain = cur_seq[:start] + cur_seq[start + block_size:]
            seq_build = remain[:]
            # Greedy reinsert block elements near start and a few random spots
            for x in block:
                if not time_left():
                    break
                positions = list(range(max(0, start - 3), min(len(seq_build) + 1, start + 4)))
                # add a few random positions
                extra = set()
                limit = min(6, len(seq_build) + 1)
                while len(extra) < limit and time_left():
                    extra.add(rng.randrange(len(seq_build) + 1))
                for p in extra:
                    if p not in positions:
                        positions.append(p)
                best_local = float('inf')
                best_pos = 0
                for p in positions:
                    cand = seq_build[:]
                    cand.insert(p, x)
                    c = eval_seq_cost(cand)
                    if c < best_local:
                        best_local = c
                        best_pos = p
                seq_build.insert(best_pos, x)
            if len(seq_build) == m:
                c_new = eval_seq_cost(seq_build)
                if c_new < cur_c:
                    return c_new, seq_build
            return cur_c, cur_seq

        # Attempt one or two boundary repairs
        for _ in range(2):
            if not time_left():
                break
            c_try, s_try = boundary_repair_once(best_seq, best_cost)
            if c_try < best_cost:
                best_cost, best_seq = c_try, s_try

        # A handful of relocations for diversity
        trials = 36
        while trials > 0 and time_left():
            trials -= 1
            i, j = rng.sample(range(n), 2)
            if i == j:
                continue
            cand = best_seq[:]
            v = cand.pop(i)
            cand.insert(j, v)
            c = eval_seq_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand

        return best_cost, best_seq
>>>>>>> REPLACE