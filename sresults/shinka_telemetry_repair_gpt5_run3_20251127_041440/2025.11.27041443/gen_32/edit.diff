--- a/original.py
+++ b/original.py
@@ -1,446 +1,611 @@
 # EVOLVE-BLOCK-START
 """
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+Weighted least-squares projection with link hardening and re-sync.
+
+Core ideas:
+- Robust link fusion (R3) with adaptive tolerance and soft-zero snapping.
+- Exact per-router flow conservation via closed-form weighted least-squares projection.
+- Dominance cap to avoid over-reliance on one interface during correction.
+- Bundle-aware intra-group smoothing and confidence-gap re-sync.
+- Residual-based confidence calibration with peer smoothing and scaling penalties.
+
+Maintains the original function signature and outputs.
 """
-from typing import Dict, Any, Tuple, List
+from typing import Dict, Any, Tuple, List, Optional
+import math
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
-    """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-
-    Strategy inspired by Hodor:
-    1) Signal Collection: use redundant bilateral measurements on links.
-    2) Signal Hardening: pair-wise hardening via link symmetry (R3) with 2% tolerance.
-    3) Dynamic Checking: router-level flow conservation (R1) with guarded, capped scaling.
-    Additionally, enforce interface consistency for rates when status is down.
-
-    Confidence calibration:
-    - High confidence when redundant signals agree and small/zero corrections.
-    - Confidence reduced proportionally to symmetry deviations and applied router-level adjustments.
-
-    Note: We intentionally do not flip interface statuses to preserve status accuracy,
-    but we reduce status confidence when peers disagree.
-    """
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
-    ZERO_EPS = 1e-3
-    # Soft-zero threshold for Mbps-scale counters
-    ZERO_THRESH = 1.0
+    # Hyperparameters
+    TAU_H_BASE = 0.02           # ~2% hardening threshold
+    TAU_H_HIGH = 0.015          # tighter tolerance for high-rate pairs
+    TAU_H_LOW = 0.03            # looser tolerance for low/near-zero pairs
+    ZERO_THRESH = 1.0           # Mbps soft-zero threshold
+    ZERO_EPS = 1e-6
+    DAMP_ROUTER = 0.60          # router projection damping on lambda
+    DOMINANCE_CAP = 0.50        # ≤ 50% share cap for any single interface correction
+    PEER_SMOOTH = 0.10          # confidence peer smoothing fraction
+    STRONG_SCALE_GUARD = 0.08   # guard threshold for re-sync skipping
+    RESYNC_MAX_F = 0.40         # max fraction for one-sided nudge toward mean
+    BUNDLE_DOM_FRAC = 0.60      # bundle dominance threshold on a side’s traffic
+    INTRA_BUNDLE_CLIP = 0.05    # ±5% intra-bundle smoothing cap
+    UNTOUCHED_BOOST = 0.02      # confidence boost for untouched well-synced counters
+    CLIP_HIT_PENALTY = 0.95     # multiplicative penalty when strong scaling/clipping hit
 
     def clamp01(x: float) -> float:
         return max(0.0, min(1.0, x))
 
     def rel_diff(a: float, b: float) -> float:
         return abs(a - b) / max(1.0, abs(a), abs(b))
 
-    def compute_tau_h(v1: float, v2: float) -> float:
-        """
-        Adaptive symmetry tolerance:
-        - 0.015 for high-rate pairs (>=100 Mbps both sides)
-        - 0.03 for near-zero/low-rate (either side < 1 Mbps)
-        - 0.02 baseline otherwise
-        """
+    def adaptive_tau(v1: float, v2: float) -> float:
         if v1 >= 100.0 and v2 >= 100.0:
-            return 0.015
+            return TAU_H_HIGH
         if v1 < ZERO_THRESH or v2 < ZERO_THRESH:
-            return 0.03
-        return HARDENING_THRESHOLD
-
-    # Precompute originals and peers
+            return TAU_H_LOW
+        return TAU_H_BASE
+
+    def is_near_zero_link(vals: List[float]) -> bool:
+        return max(vals) < 2.0 * ZERO_THRESH
+
+    # Collect maps
     orig_rx: Dict[str, float] = {}
     orig_tx: Dict[str, float] = {}
     status: Dict[str, str] = {}
-    peer_of: Dict[str, str] = {}
-
-    for if_id, data in telemetry.items():
-        orig_rx[if_id] = float(data.get('rx_rate', 0.0))
-        orig_tx[if_id] = float(data.get('tx_rate', 0.0))
-        status[if_id] = data.get('interface_status', 'unknown')
-        ct = data.get('connected_to')
-        peer_of[if_id] = ct if ct in telemetry else None
-
-    # Initialize hardened values with originals
-    hardened_rx: Dict[str, float] = {i: v for i, v in orig_rx.items()}
-    hardened_tx: Dict[str, float] = {i: v for i, v in orig_tx.items()}
-    conf_rx: Dict[str, float] = {i: 0.7 for i in telemetry}
-    conf_tx: Dict[str, float] = {i: 0.7 for i in telemetry}
-
-    processed_pairs = set()
-
-    # Pairwise hardening using link symmetry (R3)
-    for a, data in telemetry.items():
-        b = peer_of.get(a)
-        if not b or (b, a) in processed_pairs or a == b:
-            continue
-        processed_pairs.add((a, b))
-
-        a_stat = status.get(a, 'unknown')
-        b_stat = status.get(b, 'unknown')
-        a_up = (a_stat == 'up')
-        b_up = (b_stat == 'up')
-
-        a_rx = orig_rx[a]
-        a_tx = orig_tx[a]
-        b_rx = orig_rx[b]
-        b_tx = orig_tx[b]
-
-        # If either side is down: enforce zero on both link directions with high confidence
-        if not a_up or not b_up:
-            hardened_rx[a] = 0.0
-            hardened_tx[a] = 0.0
-            hardened_rx[b] = 0.0
-            hardened_tx[b] = 0.0
-            conf_rx[a] = max(conf_rx[a], 0.85)
-            conf_tx[a] = max(conf_tx[a], 0.85)
-            conf_rx[b] = max(conf_rx[b], 0.85)
-            conf_tx[b] = max(conf_tx[b], 0.85)
-            continue
-
-        # Soft-zero stabilization: both ends up and all four directions near zero
-        if max(a_rx, a_tx, b_rx, b_tx) < 2.0 * ZERO_THRESH:
-            hardened_rx[a] = 0.0
-            hardened_tx[a] = 0.0
-            hardened_rx[b] = 0.0
-            hardened_tx[b] = 0.0
-            conf_rx[a] = max(conf_rx[a], 0.95)
-            conf_tx[a] = max(conf_tx[a], 0.95)
-            conf_rx[b] = max(conf_rx[b], 0.95)
-            conf_tx[b] = max(conf_tx[b], 0.95)
-            continue
-
-        # Direction 1: a.tx should match b.rx (adaptive tolerance)
-        d1 = rel_diff(a_tx, b_rx)
-        tau1 = compute_tau_h(a_tx, b_rx)
-        if d1 <= tau1:
-            v1 = 0.5 * (a_tx + b_rx)
-            hardened_tx[a] = max(0.0, v1)
-            hardened_rx[b] = max(0.0, v1)
-            c1 = clamp01(0.9 + 0.1 * (1.0 - d1 / max(tau1, 1e-12)))
-            conf_tx[a] = max(conf_tx[a], c1)
-            conf_rx[b] = max(conf_rx[b], c1)
-        else:
-            # Snap to peer's measurement for strong symmetry
-            hardened_tx[a] = max(0.0, b_rx)
-            hardened_rx[b] = max(0.0, b_rx)
-            c1 = clamp01(1.0 - d1)
-            conf_tx[a] = max(conf_tx[a], c1)
-            conf_rx[b] = max(conf_rx[b], c1)
-
-        # Direction 2: a.rx should match b.tx (adaptive tolerance)
-        d2 = rel_diff(a_rx, b_tx)
-        tau2 = compute_tau_h(a_rx, b_tx)
-        if d2 <= tau2:
-            v2 = 0.5 * (a_rx + b_tx)
-            hardened_rx[a] = max(0.0, v2)
-            hardened_tx[b] = max(0.0, v2)
-            c2 = clamp01(0.9 + 0.1 * (1.0 - d2 / max(tau2, 1e-12)))
-            conf_rx[a] = max(conf_rx[a], c2)
-            conf_tx[b] = max(conf_tx[b], c2)
-        else:
-            hardened_rx[a] = max(0.0, b_tx)
-            hardened_tx[b] = max(0.0, b_tx)
-            c2 = clamp01(1.0 - d2)
-            conf_rx[a] = max(conf_rx[a], c2)
-            conf_tx[b] = max(conf_tx[b], c2)
-
-    # Unpaired interfaces: keep own values with moderate confidence
-    for i, d in telemetry.items():
-        if i not in [x for pair in processed_pairs for x in pair]:
-            # If interface is down, enforce zero with strong confidence
-            if status.get(i) == 'down':
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.85)
-                conf_tx[i] = max(conf_tx[i], 0.85)
-            else:
-                # Keep local but acknowledge weaker redundancy
-                hardened_rx[i] = max(0.0, orig_rx[i])
-                hardened_tx[i] = max(0.0, orig_tx[i])
-                conf_rx[i] = max(conf_rx[i], 0.6)
-                conf_tx[i] = max(conf_tx[i], 0.6)
-
-    # Track per-direction scaled factors from router adjustments (for later guards)
-    scaled_rx_factor = {i: 1.0 for i in telemetry}
-    scaled_tx_factor = {i: 1.0 for i in telemetry}
-
-    # Build router membership using provided topology (preferred)
+    peer_of: Dict[str, Optional[str]] = {}
+    local_router_of: Dict[str, Any] = {}
+    remote_router_of: Dict[str, Any] = {}
+
+    for iid, d in telemetry.items():
+        orig_rx[iid] = float(d.get('rx_rate', 0.0))
+        orig_tx[iid] = float(d.get('tx_rate', 0.0))
+        status[iid] = d.get('interface_status', 'unknown')
+        peer = d.get('connected_to')
+        peer_of[iid] = peer if peer in telemetry else None
+        local_router_of[iid] = d.get('local_router')
+        remote_router_of[iid] = d.get('remote_router')
+
+    # Derive missing remote_router via peer's local_router if needed
+    for iid in telemetry:
+        if not remote_router_of.get(iid):
+            p = peer_of.get(iid)
+            if p and p in telemetry:
+                remote_router_of[iid] = telemetry[p].get('local_router')
+
+    # Router->interfaces mapping (use topology if provided, else fallback to local_router)
     router_ifaces: Dict[str, List[str]] = {}
     if topology:
         for r, ifs in topology.items():
             router_ifaces[r] = [i for i in ifs if i in telemetry]
     else:
-        # Fallback to local_router if topology not supplied (still useful for R1)
+        # Fallback: still useful to enforce R1
         for iid, d in telemetry.items():
             r = d.get('local_router')
-            router_ifaces.setdefault(r, []).append(iid)
-
-    # Guarded router-level flow conservation (R1)
-    # Targeted adjustment: adjust only the lower-confidence side, distribute by weights,
-    # clip per-interface relative change to +/-10%, and damp the total correction by 60%.
+            if r is not None:
+                router_ifaces.setdefault(r, []).append(iid)
+
+    # Build unique link pairs
+    link_pairs: List[Tuple[str, str]] = []
+    seen = set()
+    for a in telemetry:
+        b = peer_of.get(a)
+        if not b or a == b or b not in telemetry:
+            continue
+        if (b, a) in seen or (a, b) in seen:
+            continue
+        seen.add((a, b))
+        link_pairs.append((a, b))
+    in_pairs = {x for ab in link_pairs for x in ab}
+
+    # Initialize hardened with originals (non-negative)
+    rx: Dict[str, float] = {i: max(0.0, v) for i, v in orig_rx.items()}
+    tx: Dict[str, float] = {i: max(0.0, v) for i, v in orig_tx.items()}
+
+    # Directional confidences initialized; refined later
+    conf_rx: Dict[str, float] = {i: 0.7 for i in telemetry}
+    conf_tx: Dict[str, float] = {i: 0.7 for i in telemetry}
+
+    # Track scale factors applied later (for confidence, re-sync guard)
+    scaled_rx_factor: Dict[str, float] = {i: 1.0 for i in telemetry}
+    scaled_tx_factor: Dict[str, float] = {i: 1.0 for i in telemetry}
+    clip_hit: Dict[str, bool] = {i: False for i in telemetry}
+
+    # Stage 1: Link hardening with adaptive tolerance and soft-zero
+    for a, b in link_pairs:
+        a_up = (status.get(a) == 'up')
+        b_up = (status.get(b) == 'up')
+
+        a_rx0, a_tx0 = rx[a], tx[a]
+        b_rx0, b_tx0 = rx[b], tx[b]
+
+        # If either side down: force zeros with high confidence
+        if not a_up or not b_up:
+            rx[a] = tx[a] = 0.0
+            rx[b] = tx[b] = 0.0
+            conf_rx[a] = max(conf_rx[a], 0.85)
+            conf_tx[a] = max(conf_tx[a], 0.85)
+            conf_rx[b] = max(conf_rx[b], 0.85)
+            conf_tx[b] = max(conf_tx[b], 0.85)
+            continue
+
+        # Soft-zero if all four directions tiny
+        if is_near_zero_link([a_rx0, a_tx0, b_rx0, b_tx0]):
+            rx[a] = tx[a] = rx[b] = tx[b] = 0.0
+            conf_rx[a] = max(conf_rx[a], 0.95)
+            conf_tx[a] = max(conf_tx[a], 0.95)
+            conf_rx[b] = max(conf_rx[b], 0.95)
+            conf_tx[b] = max(conf_tx[b], 0.95)
+            continue
+
+        # Direction 1: a.tx vs b.rx
+        d1 = rel_diff(a_tx0, b_rx0)
+        tau1 = adaptive_tau(a_tx0, b_rx0)
+        if d1 <= tau1:
+            v1 = 0.5 * (a_tx0 + b_rx0)
+        else:
+            # Favor the farther-from-zero redundant observation to avoid under-report outliers
+            v1 = b_rx0 if abs(b_rx0) >= abs(a_tx0) else a_tx0
+        tx[a] = max(0.0, v1)
+        rx[b] = max(0.0, v1)
+        c1 = clamp01(0.9 + 0.1 * (1.0 - min(1.0, d1 / max(tau1, 1e-12)))) if d1 <= tau1 else clamp01(1.0 - d1)
+        conf_tx[a] = max(conf_tx[a], c1)
+        conf_rx[b] = max(conf_rx[b], c1)
+
+        # Direction 2: a.rx vs b.tx
+        d2 = rel_diff(a_rx0, b_tx0)
+        tau2 = adaptive_tau(a_rx0, b_tx0)
+        if d2 <= tau2:
+            v2 = 0.5 * (a_rx0 + b_tx0)
+        else:
+            v2 = b_tx0 if abs(b_tx0) >= abs(a_rx0) else a_rx0
+        rx[a] = max(0.0, v2)
+        tx[b] = max(0.0, v2)
+        c2 = clamp01(0.9 + 0.1 * (1.0 - min(1.0, d2 / max(tau2, 1e-12)))) if d2 <= tau2 else clamp01(1.0 - d2)
+        conf_rx[a] = max(conf_rx[a], c2)
+        conf_tx[b] = max(conf_tx[b], c2)
+
+    # Unpaired interfaces: keep local; zero if down
+    for i in telemetry:
+        if i not in in_pairs:
+            if status.get(i) != 'up':
+                rx[i] = tx[i] = 0.0
+                conf_rx[i] = max(conf_rx[i], 0.85)
+                conf_tx[i] = max(conf_tx[i], 0.85)
+            else:
+                rx[i] = max(0.0, orig_rx[i])
+                tx[i] = max(0.0, orig_tx[i])
+                conf_rx[i] = max(conf_rx[i], 0.6)
+                conf_tx[i] = max(conf_tx[i], 0.6)
+
+    # Helper: compute router residuals (for later attenuation/soft-zero rule)
+    def compute_router_residuals(vals_rx: Dict[str, float], vals_tx: Dict[str, float]) -> Dict[str, float]:
+        residuals: Dict[str, float] = {}
+        for r, ifs in router_ifaces.items():
+            ups = [i for i in ifs if status.get(i) == 'up']
+            if not ups:
+                residuals[r] = 0.0
+                continue
+            srx = sum(vals_rx[i] for i in ups)
+            stx = sum(vals_tx[i] for i in ups)
+            denom = max(1.0, srx, stx)
+            residuals[r] = abs(srx - stx) / denom
+        return residuals
+
+    # Stage 2: Exact per-router WLS projection onto Σ(in)=Σ(out)
+    router_residual_pre = compute_router_residuals(rx, tx)
+
     for r, ifs in router_ifaces.items():
-        # Consider only interfaces that are up to avoid double-penalizing down links
         up_ifs = [i for i in ifs if status.get(i) == 'up']
         if len(up_ifs) < 2:
             continue
 
-        sum_rx = sum(hardened_rx[i] for i in up_ifs)
-        sum_tx = sum(hardened_tx[i] for i in up_ifs)
-        denom = max(1.0, sum_rx, sum_tx)
-        imbalance = abs(sum_rx - sum_tx) / denom
-
-        # Adaptive router tolerance depending on number of active links
-        n_active = len(up_ifs)
-        tau_router = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active)) ** 0.5))
-        if imbalance <= tau_router:
-            continue
-
-        # Aggregate confidences per side
-        avg_rx_conf = sum(conf_rx[i] for i in up_ifs) / len(up_ifs)
-        avg_tx_conf = sum(conf_tx[i] for i in up_ifs) / len(up_ifs)
-
-        # Choose side with lower aggregate confidence to adjust
-        adjust_side = 'rx' if avg_rx_conf < avg_tx_conf else 'tx'
-        delta = sum_rx - sum_tx  # positive: rx larger than tx
-        # We aim to reduce the gap; compute total additive adjustment with damping
-        total_adjust = (-delta) if adjust_side == 'rx' else (delta)
-        total_adjust *= 0.6  # damping to avoid over-correction
-
-        # Build weights: favor larger links and lower-confidence signals
-        vals = []
-        confs = []
-        if adjust_side == 'rx':
-            vals = [hardened_rx[i] for i in up_ifs]
-            confs = [conf_rx[i] for i in up_ifs]
-        else:
-            vals = [hardened_tx[i] for i in up_ifs]
-            confs = [conf_tx[i] for i in up_ifs]
-
-        weights = []
-        for v, c in zip(vals, confs):
-            w = (max(v, 0.0) + 1e-6) * (1.0 - clamp01(c)) + 1e-6
+        # Build variable vectors
+        vals: List[float] = []
+        signs: List[int] = []  # +1 for rx, -1 for tx
+        idx_map: List[Tuple[str, str]] = []  # (interface_id, 'rx'/'tx')
+        weights: List[float] = []
+
+        # Compose rx variables
+        for i in up_ifs:
+            v = rx[i]
+            vals.append(v)
+            signs.append(+1)
+            idx_map.append((i, 'rx'))
+            # Trust weight: higher for confident and high-rate counters
+            c = clamp01(conf_rx.get(i, 0.7))
+            # Two-tier adjustment (low and mid confidence make smaller weights => larger correction)
+            tier = 1.0
+            if c < 0.70:
+                tier = 0.6
+            elif c < 0.85:
+                tier = 0.8
+            # Weight proportional to confidence^2 and inversely to magnitude (to make relative changes)
+            w = max(1e-6, (c**2) * tier / max(v, ZERO_THRESH))
+            # Protect near-zero from taking huge absolute correction
+            if v < ZERO_THRESH:
+                w *= 3.0
             weights.append(w)
-        total_w = sum(weights)
-        if total_w <= 0:
-            continue
-
-        # Apply distributed adjustments with per-interface clipping (+/-10%)
-        for idx, i in enumerate(up_ifs):
-            v_old = vals[idx]
-            w_i = weights[idx] / total_w
-            adj = total_adjust * w_i
-            # Clip per-interface relative change to +/-10%
-            cap = 0.10 * v_old
-            adj_clipped = min(max(adj, -cap), cap)
-            v_new = max(0.0, v_old + adj_clipped)
-
-            # Update hardened values and track effective scale factor for re-sync guard
-            if adjust_side == 'rx':
-                prev = hardened_rx[i]
-                hardened_rx[i] = v_new
-                if prev > ZERO_EPS:
-                    scaled_rx_factor[i] *= (v_new / prev)
-                # Moderate confidence penalty proportional to applied change
-                rel = abs(adj_clipped) / max(1.0, abs(prev))
-                conf_rx[i] = clamp01(conf_rx[i] * (1.0 - 0.6 * rel))
+
+        # Compose tx variables
+        for i in up_ifs:
+            v = tx[i]
+            vals.append(v)
+            signs.append(-1)
+            idx_map.append((i, 'tx'))
+            c = clamp01(conf_tx.get(i, 0.7))
+            tier = 1.0
+            if c < 0.70:
+                tier = 0.6
+            elif c < 0.85:
+                tier = 0.8
+            w = max(1e-6, (c**2) * tier / max(v, ZERO_THRESH))
+            if v < ZERO_THRESH:
+                w *= 3.0
+            weights.append(w)
+
+        # Compute lambda for weighted projection
+        # a^T x0 = sum(signs[i] * vals[i])
+        ax0 = 0.0
+        denom = 0.0  # a^T W^{-1} a = sum( (sign^2)/w_i ) = sum(1/w_i)
+        inv_weights = [1.0 / max(1e-12, w) for w in weights]
+        for sgn, v, invw in zip(signs, vals, inv_weights):
+            ax0 += sgn * v
+            denom += invw  # since sgn^2 = 1
+
+        if denom <= 1e-12:
+            continue
+
+        # Damped Lagrange multiplier
+        lam = 2.0 * ax0 / denom
+        lam *= DAMP_ROUTER
+
+        # Initial deltas
+        deltas = [-(invw) * sgn * lam * 0.5 for sgn, invw in zip(signs, inv_weights)]
+        # Note: derived from x* = x0 - 0.5 W^{-1} λ a, with λ as above (post damping)
+
+        # Dominance cap iteration: avoid one interface taking >50% of correction
+        def apply_dominance_cap(deltas_in: List[float], invw_in: List[float]) -> List[float]:
+            # Compute shares by absolute delta proportional to invw (since all deltas share same lam)
+            for _ in range(3):
+                absd = [abs(d) for d in deltas_in]
+                total = sum(absd) + 1e-12
+                shares = [d / total for d in absd]
+                max_share = max(shares)
+                if max_share <= DOMINANCE_CAP + 1e-6:
+                    break
+                k = shares.index(max_share)
+                # Increase weight (decrease inv weight) for offender
+                invw_in[k] *= (max_share / DOMINANCE_CAP)  # reduce its share
+                # Recompute deltas with modified inverse weights
+                denom_new = sum(invw_in)
+                if denom_new <= 1e-12:
+                    break
+                lam_new = 2.0 * ax0 / denom_new
+                lam_new *= DAMP_ROUTER
+                deltas_in = [-(invw) * sgn * lam_new * 0.5 for sgn, invw in zip(signs, invw_in)]
+            return deltas_in
+
+        deltas = apply_dominance_cap(deltas, inv_weights[:])
+
+        # Apply deltas
+        for (i, side), dv, v_old in zip(idx_map, deltas, vals):
+            v_new = max(0.0, v_old + dv)
+            if side == 'rx':
+                prev = rx[i]
+                rx[i] = v_new
+                if prev > ZERO_EPS and v_new >= 0.0:
+                    scl = v_new / prev if prev > 0 else 1.0
+                    scaled_rx_factor[i] *= scl
+                    if abs(scl - 1.0) >= 0.10:
+                        clip_hit[i] = True
             else:
-                prev = hardened_tx[i]
-                hardened_tx[i] = v_new
-                if prev > ZERO_EPS:
-                    scaled_tx_factor[i] *= (v_new / prev)
-                rel = abs(adj_clipped) / max(1.0, abs(prev))
-                conf_tx[i] = clamp01(conf_tx[i] * (1.0 - 0.6 * rel))
-
-    # Final symmetry touch-up (R3) with one-sided, confidence-gap-proportional nudge
-    for a, b in list(processed_pairs):
-        if a not in telemetry or b not in telemetry:
-            continue
-        # Skip if either side is down (already zeroed)
+                prev = tx[i]
+                tx[i] = v_new
+                if prev > ZERO_EPS and v_new >= 0.0:
+                    scl = v_new / prev if prev > 0 else 1.0
+                    scaled_tx_factor[i] *= scl
+                    if abs(scl - 1.0) >= 0.10:
+                        clip_hit[i] = True
+
+    # Stage 2.1: Bundle-aware intra-group smoothing (small ±5% pass)
+    # Group by (local_router, remote_router)
+    for r, ifs in router_ifaces.items():
+        up_ifs = [i for i in ifs if status.get(i) == 'up']
+        if not up_ifs:
+            continue
+        # Side totals
+        sum_rx_side = sum(rx[i] for i in up_ifs)
+        sum_tx_side = sum(tx[i] for i in up_ifs)
+        # Build bundles
+        bundles: Dict[Tuple[Any, Any], List[str]] = {}
+        for i in up_ifs:
+            key = (local_router_of.get(i), remote_router_of.get(i))
+            bundles.setdefault(key, []).append(i)
+
+        # RX side smoothing
+        for key, members in bundles.items():
+            if len(members) < 2:
+                continue
+            group_sum = sum(rx[i] for i in members)
+            if sum_rx_side > ZERO_EPS and (group_sum / sum_rx_side) >= BUNDLE_DOM_FRAC:
+                # Relative scales (post-router vs pre-router using orig_rx as loose anchor)
+                rels = []
+                for i in members:
+                    base = max(ZERO_THRESH, orig_rx.get(i, 0.0))
+                    rels.append(rx[i] / base)
+                s_group = sum(rels) / len(rels)
+                # Clip to ±5%
+                s_group = max(1.0 - INTRA_BUNDLE_CLIP, min(1.0 + INTRA_BUNDLE_CLIP, s_group))
+                for i in members:
+                    base = max(ZERO_THRESH, orig_rx.get(i, 0.0))
+                    new_v = max(0.0, base * s_group)
+                    if rx[i] > ZERO_EPS:
+                        scl = new_v / rx[i]
+                        if abs(scl - 1.0) >= 0.10:
+                            clip_hit[i] = True
+                    rx[i] = new_v
+
+        # TX side smoothing
+        for key, members in bundles.items():
+            if len(members) < 2:
+                continue
+            group_sum = sum(tx[i] for i in members)
+            if sum_tx_side > ZERO_EPS and (group_sum / sum_tx_side) >= BUNDLE_DOM_FRAC:
+                rels = []
+                for i in members:
+                    base = max(ZERO_THRESH, orig_tx.get(i, 0.0))
+                    rels.append(tx[i] / base)
+                s_group = sum(rels) / len(rels)
+                s_group = max(1.0 - INTRA_BUNDLE_CLIP, min(1.0 + INTRA_BUNDLE_CLIP, s_group))
+                for i in members:
+                    base = max(ZERO_THRESH, orig_tx.get(i, 0.0))
+                    new_v = max(0.0, base * s_group)
+                    if tx[i] > ZERO_EPS:
+                        scl = new_v / tx[i]
+                        if abs(scl - 1.0) >= 0.10:
+                            clip_hit[i] = True
+                    tx[i] = new_v
+
+    # Stage 2.2: Soft-zero stabilization on hardened links if routers balanced
+    router_residual_post = compute_router_residuals(rx, tx)
+    for a, b in link_pairs:
         if status.get(a) != 'up' or status.get(b) != 'up':
             continue
-
-        # Helper to perform one-sided nudge toward mean
-        def nudge_one_side(val_lo: float, val_hi: float, f: float) -> float:
-            target = 0.5 * (val_lo + val_hi)
-            return val_lo + f * (target - val_lo)
+        # If link tiny and adjacent routers close to balanced, snap to zero
+        if is_near_zero_link([rx[a], tx[a], rx[b], tx[b]]):
+            ra = local_router_of.get(a)
+            rb = local_router_of.get(b)
+            imba = router_residual_post.get(ra, 0.0)
+            imbb = router_residual_post.get(rb, 0.0)
+            # Adaptive router tolerance based on active links
+            n_active_a = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
+            n_active_b = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
+            tau_ra = min(0.07, max(0.03, 0.05 * math.sqrt(2.0 / max(2, n_active_a))))
+            tau_rb = min(0.07, max(0.03, 0.05 * math.sqrt(2.0 / max(2, n_active_b))))
+            if imba <= tau_ra and imbb <= tau_rb:
+                rx[a] = tx[a] = rx[b] = tx[b] = 0.0
+                conf_rx[a] = max(conf_rx[a], 0.95)
+                conf_tx[a] = max(conf_tx[a], 0.95)
+                conf_rx[b] = max(conf_rx[b], 0.95)
+                conf_tx[b] = max(conf_tx[b], 0.95)
+
+    # Stage 3: Confidence-gap re-sync with scaling guard and router attenuation
+    def nudge_toward_mean(val_lo: float, val_hi: float, frac: float) -> float:
+        target = 0.5 * (val_lo + val_hi)
+        return val_lo + frac * (target - val_lo)
+
+    # Recompute router residuals for attenuation
+    router_residual_final = compute_router_residuals(rx, tx)
+
+    for a, b in link_pairs:
+        if status.get(a) != 'up' or status.get(b) != 'up':
+            continue
+
+        # Attenuation from local router imbalances
+        ra = local_router_of.get(a)
+        rb = local_router_of.get(b)
+        att = 1.0 - max(router_residual_final.get(ra, 0.0), router_residual_final.get(rb, 0.0))
+        att = clamp01(att)
 
         # Direction 1: a.tx vs b.rx
-        a_tx = hardened_tx.get(a, 0.0)
-        b_rx = hardened_rx.get(b, 0.0)
+        a_tx, b_rx = tx[a], rx[b]
         if max(a_tx, b_rx) > ZERO_EPS:
             d1 = rel_diff(a_tx, b_rx)
-            tau1 = compute_tau_h(a_tx, b_rx)
+            tau1 = adaptive_tau(a_tx, b_rx)
             if d1 > tau1:
-                conf_a_tx = conf_tx.get(a, 0.6)
-                conf_b_rx = conf_rx.get(b, 0.6)
-                if conf_a_tx >= conf_b_rx:
-                    # Nudge lower-confidence side (b.rx) unless it had strong router scaling
-                    if abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= 0.08:
-                        f = min(0.4, max(0.0, conf_a_tx - conf_b_rx))
-                        if f > 0.0:
-                            old = b_rx
-                            new = nudge_one_side(old, a_tx, f)
-                            hardened_rx[b] = max(0.0, new)
-                            relc = abs(new - old) / max(1.0, abs(old), abs(new))
-                            conf_rx[b] = clamp01(conf_rx.get(b, 0.6) * (1.0 - 0.3 * relc))
-                else:
-                    # Nudge lower-confidence side (a.tx) unless it had strong router scaling
-                    if abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= 0.08:
-                        f = min(0.4, max(0.0, conf_b_rx - conf_a_tx))
-                        if f > 0.0:
-                            old = a_tx
-                            new = nudge_one_side(old, b_rx, f)
-                            hardened_tx[a] = max(0.0, new)
-                            relc = abs(new - old) / max(1.0, abs(old), abs(new))
-                            conf_tx[a] = clamp01(conf_tx.get(a, 0.6) * (1.0 - 0.3 * relc))
+                ca, cb = conf_tx.get(a, 0.7), conf_rx.get(b, 0.7)
+                if ca >= cb and abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
+                    f = min(RESYNC_MAX_F, max(0.0, ca - cb)) * att
+                    if f > 0.0:
+                        old = b_rx
+                        new = max(0.0, nudge_toward_mean(old, a_tx, f))
+                        rx[b] = new
+                        # confidence penalty proportional to relative movement
+                        move_rel = rel_diff(new, old)
+                        conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.3 * move_rel))
+                elif cb > ca and abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
+                    f = min(RESYNC_MAX_F, max(0.0, cb - ca)) * att
+                    if f > 0.0:
+                        old = a_tx
+                        new = max(0.0, nudge_toward_mean(old, b_rx, f))
+                        tx[a] = new
+                        move_rel = rel_diff(new, old)
+                        conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.3 * move_rel))
 
         # Direction 2: a.rx vs b.tx
-        a_rx = hardened_rx.get(a, 0.0)
-        b_tx = hardened_tx.get(b, 0.0)
+        a_rx, b_tx = rx[a], tx[b]
         if max(a_rx, b_tx) > ZERO_EPS:
             d2 = rel_diff(a_rx, b_tx)
-            tau2 = compute_tau_h(a_rx, b_tx)
+            tau2 = adaptive_tau(a_rx, b_tx)
             if d2 > tau2:
-                conf_a_rx = conf_rx.get(a, 0.6)
-                conf_b_tx = conf_tx.get(b, 0.6)
-                if conf_a_rx >= conf_b_tx:
-                    # Nudge lower-confidence side (b.tx) unless it had strong router scaling
-                    if abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= 0.08:
-                        f = min(0.4, max(0.0, conf_a_rx - conf_b_tx))
-                        if f > 0.0:
-                            old = b_tx
-                            new = nudge_one_side(old, a_rx, f)
-                            hardened_tx[b] = max(0.0, new)
-                            relc = abs(new - old) / max(1.0, abs(old), abs(new))
-                            conf_tx[b] = clamp01(conf_tx.get(b, 0.6) * (1.0 - 0.3 * relc))
-                else:
-                    # Nudge lower-confidence side (a.rx) unless it had strong router scaling
-                    if abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= 0.08:
-                        f = min(0.4, max(0.0, conf_b_tx - conf_a_rx))
-                        if f > 0.0:
-                            old = a_rx
-                            new = nudge_one_side(old, b_tx, f)
-                            hardened_rx[a] = max(0.0, new)
-                            relc = abs(new - old) / max(1.0, abs(old), abs(new))
-                            conf_rx[a] = clamp01(conf_rx.get(a, 0.6) * (1.0 - 0.3 * relc))
-
-    # Confidence peer smoothing: softly harmonize per-direction confidences across peers
-    # Apply only when both ends are up
-    new_conf_rx = dict(conf_rx)
-    new_conf_tx = dict(conf_tx)
-    for a, b in list(processed_pairs):
-        if a not in telemetry or b not in telemetry:
-            continue
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        # Blend 10% from peer opposite direction
-        new_conf_tx[a] = clamp01(0.9 * conf_tx.get(a, 0.6) + 0.1 * conf_rx.get(b, 0.6))
-        new_conf_rx[b] = clamp01(0.9 * conf_rx.get(b, 0.6) + 0.1 * conf_tx.get(a, 0.6))
-        new_conf_rx[a] = clamp01(0.9 * conf_rx.get(a, 0.6) + 0.1 * conf_tx.get(b, 0.6))
-        new_conf_tx[b] = clamp01(0.9 * conf_tx.get(b, 0.6) + 0.1 * conf_rx.get(a, 0.6))
-    conf_rx = new_conf_rx
-    conf_tx = new_conf_tx
-
-    # Enforce interface down => zero traffic (final safeguard)
+                ca, cb = conf_rx.get(a, 0.7), conf_tx.get(b, 0.7)
+                if ca >= cb and abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
+                    f = min(RESYNC_MAX_F, max(0.0, ca - cb)) * att
+                    if f > 0.0:
+                        old = b_tx
+                        new = max(0.0, nudge_toward_mean(old, a_rx, f))
+                        tx[b] = new
+                        move_rel = rel_diff(new, old)
+                        conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.3 * move_rel))
+                elif cb > ca and abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
+                    f = min(RESYNC_MAX_F, max(0.0, cb - ca)) * att
+                    if f > 0.0:
+                        old = a_rx
+                        new = max(0.0, nudge_toward_mean(old, b_tx, f))
+                        rx[a] = new
+                        move_rel = rel_diff(new, old)
+                        conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.3 * move_rel))
+
+    # Final safety: enforce down => zero
     for i in telemetry:
-        if status.get(i) == 'down':
-            hardened_rx[i] = 0.0
-            hardened_tx[i] = 0.0
+        if status.get(i) != 'up':
+            rx[i] = 0.0
+            tx[i] = 0.0
             conf_rx[i] = max(conf_rx[i], 0.85)
             conf_tx[i] = max(conf_tx[i], 0.85)
 
-    # Assemble result with confidence calibration
-    result: Dict[str, Dict[str, Tuple]] = {}
-    for i, data in telemetry.items():
-        interface_status = status.get(i, 'unknown')
-        connected_to = data.get('connected_to')
-
-        # Status confidence: penalize when peer status inconsistent or traffic present while down
-        status_confidence = 1.0
-        if connected_to and connected_to in telemetry:
-            peer_status = telemetry[connected_to].get('interface_status', 'unknown')
-            if interface_status != peer_status:
-                status_confidence = 0.6
-        if interface_status == 'down' and (orig_rx.get(i, 0.0) > ZERO_EPS or orig_tx.get(i, 0.0) > ZERO_EPS):
-            status_confidence = min(status_confidence, 0.6)
-
-        rx_c_base = clamp01(conf_rx.get(i, 0.6))
-        tx_c_base = clamp01(conf_tx.get(i, 0.6))
-        # Include a small (10%) confidence component tied to the magnitude of router scaling
+    # Confidence calibration
+    # Router residuals after all adjustments
+    router_resid_end = compute_router_residuals(rx, tx)
+
+    # Compute raw confidence components and combine
+    conf_final_rx: Dict[str, float] = {}
+    conf_final_tx: Dict[str, float] = {}
+    for i in telemetry:
+        # Measurement residuals
+        r_meas_rx = rel_diff(rx[i], orig_rx[i])
+        r_meas_tx = rel_diff(tx[i], orig_tx[i])
+
+        # Link residuals
+        p = peer_of.get(i)
+        if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
+            r_link_rx = rel_diff(rx[i], tx[p])
+            r_link_tx = rel_diff(tx[i], rx[p])
+        else:
+            r_link_rx = 0.2
+            r_link_tx = 0.2
+
+        # Router residual
+        rtr = router_resid_end.get(local_router_of.get(i), 0.0)
+
+        base_rx = clamp01(1.0 - (0.55 * r_meas_rx + 0.35 * r_link_rx + 0.10 * rtr))
+        base_tx = clamp01(1.0 - (0.55 * r_meas_tx + 0.35 * r_link_tx + 0.10 * rtr))
+
+        # Scaling penalties
         alpha_rx = abs(scaled_rx_factor.get(i, 1.0) - 1.0)
         alpha_tx = abs(scaled_tx_factor.get(i, 1.0) - 1.0)
         scale_term_rx = clamp01(1.0 - min(0.5, alpha_rx))
         scale_term_tx = clamp01(1.0 - min(0.5, alpha_tx))
-        rx_c = clamp01(0.9 * rx_c_base + 0.1 * scale_term_rx)
-        tx_c = clamp01(0.9 * tx_c_base + 0.1 * scale_term_tx)
+
+        c_rx = clamp01(0.90 * base_rx + 0.10 * scale_term_rx)
+        c_tx = clamp01(0.90 * base_tx + 0.10 * scale_term_tx)
+
+        # Clip-hit penalty and untouched boost
+        if clip_hit.get(i, False) or alpha_rx >= 0.10:
+            c_rx *= CLIP_HIT_PENALTY
+        if clip_hit.get(i, False) or alpha_tx >= 0.10:
+            c_tx *= CLIP_HIT_PENALTY
+
+        # Untouched small-change and good symmetry boost
+        if r_meas_rx < 0.01 and r_link_rx <= adaptive_tau(rx[i], tx.get(p, rx[i]) if p else rx[i]):
+            c_rx = min(0.98, c_rx + UNTOUCHED_BOOST)
+        if r_meas_tx < 0.01 and r_link_tx <= adaptive_tau(tx[i], rx.get(p, tx[i]) if p else tx[i]):
+            c_tx = min(0.98, c_tx + UNTOUCHED_BOOST)
+
+        # Floor for down interfaces
+        if status.get(i) != 'up':
+            c_rx = max(c_rx, 0.85)
+            c_tx = max(c_tx, 0.85)
+
+        conf_final_rx[i] = c_rx
+        conf_final_tx[i] = c_tx
+
+    # Peer smoothing
+    for a, b in link_pairs:
+        if status.get(a) == 'up' and status.get(b) == 'up':
+            # a.tx with b.rx and a.rx with b.tx
+            conf_final_tx[a] = clamp01((1.0 - PEER_SMOOTH) * conf_final_tx[a] + PEER_SMOOTH * conf_final_rx[b])
+            conf_final_rx[a] = clamp01((1.0 - PEER_SMOOTH) * conf_final_rx[a] + PEER_SMOOTH * conf_final_tx[b])
+            conf_final_tx[b] = clamp01((1.0 - PEER_SMOOTH) * conf_final_tx[b] + PEER_SMOOTH * conf_final_rx[a])
+            conf_final_rx[b] = clamp01((1.0 - PEER_SMOOTH) * conf_final_rx[b] + PEER_SMOOTH * conf_final_tx[a])
+
+    # Assemble final result
+    result: Dict[str, Dict[str, Tuple]] = {}
+    for i, data in telemetry.items():
+        my_status = status.get(i, 'unknown')
+        peer_id = data.get('connected_to')
+
+        # Status confidence: penalize if peer status mismatched or traffic on down
+        status_conf = 1.0
+        if peer_id and peer_id in telemetry:
+            if my_status != telemetry[peer_id].get('interface_status', 'unknown'):
+                status_conf = 0.6
+        if my_status == 'down' and (orig_rx.get(i, 0.0) > ZERO_EPS or orig_tx.get(i, 0.0) > ZERO_EPS):
+            status_conf = min(status_conf, 0.6)
 
         repaired: Dict[str, Any] = {}
-        repaired['rx_rate'] = (orig_rx.get(i, 0.0), hardened_rx.get(i, 0.0), rx_c)
-        repaired['tx_rate'] = (orig_tx.get(i, 0.0), hardened_tx.get(i, 0.0), tx_c)
-        repaired['interface_status'] = (interface_status, interface_status, status_confidence)
+        repaired['rx_rate'] = (orig_rx.get(i, 0.0), max(0.0, rx.get(i, 0.0)), clamp01(conf_final_rx.get(i, 0.6)))
+        repaired['tx_rate'] = (orig_tx.get(i, 0.0), max(0.0, tx.get(i, 0.0)), clamp01(conf_final_tx.get(i, 0.6)))
+        repaired['interface_status'] = (my_status, my_status, status_conf)
 
         # Copy metadata unchanged
-        repaired['connected_to'] = connected_to
+        repaired['connected_to'] = data.get('connected_to')
         repaired['local_router'] = data.get('local_router')
         repaired['remote_router'] = data.get('remote_router')
 
         result[i] = repaired
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")