--- a/original.py
+++ b/original.py
@@ -1,416 +1,666 @@
 # EVOLVE-BLOCK-START
 """
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+Targeted-bundle router sync: robust link fusion, targeted router projection with bundle awareness,
+confidence-gap re-sync, adaptive tolerances, and calibrated confidence.
+
+This algorithm:
+1) Harden links using redundant peer signals with adaptive tolerance.
+2) Enforce router flow conservation by targeted scaling of low-confidence, active interfaces
+   (per-interface damped factors, clipped), with bundle-aware scaling for parallel links.
+3) Perform confidence-gap proportional re-sync on links (one-sided nudge), skipping directions
+   that already received strong router scaling.
+4) Apply adaptive tolerances and a soft-zero rule to stabilize near-zero noise.
+5) Calibrate confidence with scale penalties, final invariant satisfaction, and peer smoothing.
 """
 from typing import Dict, Any, Tuple, List
+import math
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
-    """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-
-    Core principle: Use network invariants to validate and repair telemetry:
-    1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
-    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
-    3. Interface Consistency: Status should be consistent across connected pairs
-
-    Args:
-        telemetry: Dictionary where key is interface_id and value contains:
-            - interface_status: "up" or "down"
-            - rx_rate: receive rate in Mbps
-            - tx_rate: transmit rate in Mbps
-            - connected_to: interface_id this interface connects to
-            - local_router: router_id this interface belongs to
-            - remote_router: router_id on the other side
-        topology: Dictionary where key is router_id and value contains a list of interface_ids
-
-    Returns:
-        Dictionary with same structure but telemetry values become tuples of:
-        (original_value, repaired_value, confidence_score)
-        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
-    """
-
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
-    # Router-level imbalance tolerance (slightly looser)
-    ROUTER_TOL = 0.05
-    # Near-zero threshold to stabilize tiny rates
-    ZERO_THRESH = 0.1
+    # Base thresholds
+    ZERO_THRESH = 0.1  # Mbps considered near-zero
     EPS = 1e-9
 
+    # Helper functions
     def safe_rate(x: Any) -> float:
         try:
             v = float(x)
-            if v < 0:
+            if not math.isfinite(v) or v < 0:
                 return 0.0
             return v
         except Exception:
             return 0.0
 
     def rel_diff(a: float, b: float) -> float:
         m = max(abs(a), abs(b), 1.0)
         return abs(a - b) / m
 
     def clamp01(x: float) -> float:
         if x < 0.0: return 0.0
         if x > 1.0: return 1.0
         return x
 
-    result = {}
-
-    # First pass: collect all measurements and check link symmetry
-    link_symmetry_violations = {}
-
-    for interface_id, data in telemetry.items():
-        interface_status = data.get('interface_status', 'unknown')
-        rx_rate = safe_rate(data.get('rx_rate', 0.0))
-        tx_rate = safe_rate(data.get('tx_rate', 0.0))
-        connected_to = data.get('connected_to')
-
-        # Check link symmetry if connected interface exists
-        if connected_to and connected_to in telemetry:
-            peer_data = telemetry[connected_to]
-            peer_rx = safe_rate(peer_data.get('rx_rate', 0.0))
-            peer_tx = safe_rate(peer_data.get('tx_rate', 0.0))
-
-            # My TX should match their RX (within tolerance)
-            tx_rx_diff = rel_diff(tx_rate, peer_rx)
-            # My RX should match their TX (within tolerance)
-            rx_tx_diff = rel_diff(rx_rate, peer_tx)
-
-            link_symmetry_violations[interface_id] = {
-                'tx_rx_diff': tx_rx_diff,
-                'rx_tx_diff': rx_tx_diff,
-                'peer_rx': peer_rx,
-                'peer_tx': peer_tx,
-                'peer_status': peer_data.get('interface_status', 'unknown'),
-            }
-
-    # Second pass: repair using redundant signals with small-mismatch and near-zero handling
-    for interface_id, data in telemetry.items():
-        repaired_data = {}
-
-        interface_status = data.get('interface_status', 'unknown')
-        rx_rate = safe_rate(data.get('rx_rate', 0.0))
-        tx_rate = safe_rate(data.get('tx_rate', 0.0))
-        connected_to = data.get('connected_to')
-
-        # Default: no repair, conservative high confidence
-        repaired_rx = rx_rate
-        repaired_tx = tx_rate
-        repaired_status = interface_status
-        rx_confidence = 0.95
-        tx_confidence = 0.95
-        status_confidence = 0.95
-
-        # Check for issues and attempt repair
-        if interface_id in link_symmetry_violations:
-            violations = link_symmetry_violations[interface_id]
-            peer_tx = violations['peer_tx']
-            peer_rx = violations['peer_rx']
-            peer_status = violations['peer_status']
-            tx_rx_diff = violations['tx_rx_diff']
-            rx_tx_diff = violations['rx_tx_diff']
-
-            # If both ends down, snap to zero with high confidence
-            if interface_status == 'down' and peer_status == 'down':
-                repaired_rx, repaired_tx = 0.0, 0.0
-                rx_confidence, tx_confidence = 0.98, 0.98
-            else:
-                # Near-zero stabilization: if both sides are ~0 in a direction, set to 0
-                if max(tx_rate, peer_rx) < ZERO_THRESH:
-                    repaired_tx = 0.0
-                    tx_confidence = 0.95
-                if max(rx_rate, peer_tx) < ZERO_THRESH:
-                    repaired_rx = 0.0
-                    rx_confidence = 0.95
-
-                # RX repair from peer TX
-                if rx_tx_diff <= HARDENING_THRESHOLD:
-                    # within tolerance: keep local, reinforce confidence
-                    rx_confidence = max(rx_confidence, 0.95)
-                elif rx_tx_diff <= 0.10:
-                    # moderate mismatch: average
-                    fused = 0.5 * rx_rate + 0.5 * peer_tx
-                    repaired_rx = fused
-                    rx_confidence = max(0.6, clamp01(1.0 - rx_tx_diff))
-                else:
-                    # large mismatch: prefer plausible side
-                    if rx_rate < ZERO_THRESH and peer_tx >= ZERO_THRESH:
-                        repaired_rx = peer_tx
-                    elif peer_tx < ZERO_THRESH and rx_rate >= ZERO_THRESH:
-                        repaired_rx = rx_rate
-                    else:
-                        # bias to peer if peer is up and local is down
-                        if interface_status == 'down' and peer_status == 'up':
-                            repaired_rx = peer_tx
-                        elif peer_status == 'down' and interface_status == 'up':
-                            repaired_rx = rx_rate
-                        else:
-                            # default to weighted toward peer
-                            repaired_rx = 0.3 * rx_rate + 0.7 * peer_tx
-                    rx_confidence = max(0.4, clamp01(1.0 - rx_tx_diff))
-
-                # TX repair from peer RX
-                if tx_rx_diff <= HARDENING_THRESHOLD:
-                    tx_confidence = max(tx_confidence, 0.95)
-                elif tx_rx_diff <= 0.10:
-                    fused = 0.5 * tx_rate + 0.5 * peer_rx
-                    repaired_tx = fused
-                    tx_confidence = max(0.6, clamp01(1.0 - tx_rx_diff))
-                else:
-                    if tx_rate < ZERO_THRESH and peer_rx >= ZERO_THRESH:
-                        repaired_tx = peer_rx
-                    elif peer_rx < ZERO_THRESH and tx_rate >= ZERO_THRESH:
-                        repaired_tx = tx_rate
-                    else:
-                        if interface_status == 'down' and peer_status == 'up':
-                            repaired_tx = peer_rx
-                        elif peer_status == 'down' and interface_status == 'up':
-                            repaired_tx = tx_rate
-                        else:
-                            repaired_tx = 0.3 * tx_rate + 0.7 * peer_rx
-                    tx_confidence = max(0.4, clamp01(1.0 - tx_rx_diff))
-
-        # Check status consistency
-        if connected_to and connected_to in telemetry:
-            peer_status = telemetry[connected_to].get('interface_status', 'unknown')
-            # If statuses don't match, lower confidence
-            if interface_status != peer_status:
-                status_confidence = 0.6
-                # If interface is down but has non-zero rates, that's suspicious -> enforce zeros
-                if interface_status == 'down' and (rx_rate > ZERO_THRESH or tx_rate > ZERO_THRESH):
-                    repaired_rx = 0.0
-                    repaired_tx = 0.0
-                    rx_confidence = min(rx_confidence, 0.5)
-                    tx_confidence = min(tx_confidence, 0.5)
-
-        # Store repaired values with confidence scores
-        repaired_data['rx_rate'] = (rx_rate, repaired_rx, clamp01(rx_confidence))
-        repaired_data['tx_rate'] = (tx_rate, repaired_tx, clamp01(tx_confidence))
-        repaired_data['interface_status'] = (interface_status, repaired_status, clamp01(status_confidence))
-
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = connected_to
-        repaired_data['local_router'] = data.get('local_router')
-        repaired_data['remote_router'] = data.get('remote_router')
-
-        result[interface_id] = repaired_data
-
-    # Third pass: Router-level flow conservation projection (uses topology)
-    # Build router->interfaces from topology with fallback to local_router fields.
+    def tau_h_dir(v1: float, v2: float, c1: float = None, c2: float = None) -> float:
+        # Adaptive hardening tolerance:
+        # - Stricter (1.5%) when both > 100 Mbps and confidences (if provided) are high
+        # - Looser (3%) when either < 1 Mbps or any low confidence
+        # - Baseline 2% otherwise
+        high = (v1 > 100.0 and v2 > 100.0)
+        low = (v1 < 1.0 or v2 < 1.0)
+        if c1 is not None and c2 is not None:
+            high_conf = (c1 >= 0.8 and c2 >= 0.8)
+            low_conf = (c1 < 0.7 or c2 < 0.7)
+        else:
+            high_conf = False
+            low_conf = False
+        if high and high_conf:
+            return 0.015
+        if low or low_conf:
+            return 0.03
+        return 0.02
+
+    def tau_router(n_active: int) -> float:
+        # Adaptive router tolerance based on active interfaces
+        # Clamp in [0.03, 0.07]
+        base = 0.05 * math.sqrt(2.0 / max(2, n_active))
+        return max(0.03, min(0.07, base))
+
+    # Build peers mapping
+    peers: Dict[str, str] = {}
+    for if_id, data in telemetry.items():
+        peer = data.get("connected_to")
+        if isinstance(peer, str) and peer in telemetry:
+            peers[if_id] = peer
+
+    # Build router->interfaces from topology; also record router_of for each interface
     router_ifaces: Dict[str, List[str]] = {}
     for r, if_list in topology.items():
         router_ifaces.setdefault(r, [])
         for i in if_list:
             if i in telemetry:
                 router_ifaces[r].append(i)
+    router_of: Dict[str, str] = {}
     for if_id, data in telemetry.items():
-        r = data.get('local_router')
+        r = data.get("local_router")
         if r is None:
             r = f"unknown_router::{if_id}"
         router_ifaces.setdefault(r, [])
         if if_id not in router_ifaces[r]:
             router_ifaces[r].append(if_id)
-
-    # For each router, scale the less-trustworthy aggregate (tx or rx) toward the other
+        router_of[if_id] = r
+
+    # Prepare originals and statuses
+    orig_tx: Dict[str, float] = {}
+    orig_rx: Dict[str, float] = {}
+    status_raw: Dict[str, str] = {}
+    for if_id, data in telemetry.items():
+        orig_tx[if_id] = safe_rate(data.get("tx_rate", 0.0))
+        orig_rx[if_id] = safe_rate(data.get("rx_rate", 0.0))
+        s = data.get("interface_status", "unknown")
+        status_raw[if_id] = s if s in ("up", "down") else "unknown"
+
+    # Stage 1: Link hardening with adaptive fusion
+    hard_tx: Dict[str, float] = {}
+    hard_rx: Dict[str, float] = {}
+    conf_tx_link: Dict[str, float] = {}
+    conf_rx_link: Dict[str, float] = {}
+    pre_mismatch_tx: Dict[str, float] = {}
+    pre_mismatch_rx: Dict[str, float] = {}
+
+    visited = set()
+
+    def fuse_direction(v_local: float, v_peer: float, s_local: str, s_peer: str) -> Tuple[float, float]:
+        mismatch = rel_diff(v_local, v_peer)
+        th = tau_h_dir(v_local, v_peer)
+
+        # Both near-zero => stabilize at 0 with high confidence
+        if max(v_local, v_peer) < ZERO_THRESH:
+            return 0.0, 0.95
+
+        # Within tolerance: trust local
+        if mismatch <= th:
+            return v_local, 0.95
+
+        # Moderate mismatch: average
+        if mismatch <= 0.10:
+            fused = 0.5 * v_local + 0.5 * v_peer
+            return fused, clamp01(1.0 - mismatch)
+
+        # Large mismatch: decide by plausibility
+        if v_local < ZERO_THRESH and v_peer >= ZERO_THRESH:
+            return v_peer, clamp01(1.0 - mismatch)
+        if v_peer < ZERO_THRESH and v_local >= ZERO_THRESH:
+            return v_local, clamp01(1.0 - mismatch)
+
+        # Status-aware: prefer side that is up
+        if s_local == "down" and s_peer == "up":
+            return v_peer, clamp01(1.0 - mismatch)
+        if s_peer == "down" and s_local == "up":
+            return v_local, clamp01(1.0 - mismatch)
+
+        # Default: lean toward peer to reconcile asymmetry
+        fused = 0.3 * v_local + 0.7 * v_peer
+        return fused, clamp01(1.0 - mismatch)
+
+    for if_id, data in telemetry.items():
+        if if_id in visited:
+            continue
+        peer = peers.get(if_id)
+        if not peer:
+            # Isolated interface: keep as-is with conservative confidence
+            hard_tx[if_id] = orig_tx[if_id]
+            hard_rx[if_id] = orig_rx[if_id]
+            conf_tx_link[if_id] = 0.6
+            conf_rx_link[if_id] = 0.6
+            pre_mismatch_tx[if_id] = 0.4
+            pre_mismatch_rx[if_id] = 0.4
+            visited.add(if_id)
+            continue
+
+        visited.add(if_id)
+        visited.add(peer)
+
+        a, b = if_id, peer
+        a_tx, a_rx = orig_tx[a], orig_rx[a]
+        b_tx, b_rx = orig_tx[b], orig_rx[b]
+        sa, sb = status_raw[a], status_raw[b]
+
+        # Both ends down: force zeros strongly
+        if sa == "down" and sb == "down":
+            for i in (a, b):
+                hard_tx[i] = 0.0
+                hard_rx[i] = 0.0
+                conf_tx_link[i] = 0.98
+                conf_rx_link[i] = 0.98
+            pre_mismatch_tx[a] = rel_diff(a_tx, b_rx)
+            pre_mismatch_rx[a] = rel_diff(a_rx, b_tx)
+            pre_mismatch_tx[b] = rel_diff(b_tx, a_rx)
+            pre_mismatch_rx[b] = rel_diff(b_rx, a_tx)
+            continue
+
+        # Directional mismatches
+        diff_ab = rel_diff(a_tx, b_rx)
+        diff_ba = rel_diff(b_tx, a_rx)
+        pre_mismatch_tx[a] = diff_ab
+        pre_mismatch_rx[b] = diff_ab
+        pre_mismatch_tx[b] = diff_ba
+        pre_mismatch_rx[a] = diff_ba
+
+        fused_ab, c_ab = fuse_direction(a_tx, b_rx, sa, sb)
+        fused_ba, c_ba = fuse_direction(b_tx, a_rx, sb, sa)
+
+        # Map fused directions to both ends
+        hard_tx[a] = fused_ab
+        hard_rx[b] = fused_ab
+        hard_tx[b] = fused_ba
+        hard_rx[a] = fused_ba
+
+        conf_tx_link[a] = c_ab
+        conf_rx_link[b] = c_ab
+        conf_tx_link[b] = c_ba
+        conf_rx_link[a] = c_ba
+
+    # Ensure all interfaces have values
+    for if_id in telemetry.keys():
+        if if_id not in hard_tx:
+            hard_tx[if_id] = orig_tx[if_id]
+            conf_tx_link[if_id] = 0.6
+        if if_id not in hard_rx:
+            hard_rx[if_id] = orig_rx[if_id]
+            conf_rx_link[if_id] = 0.6
+        if if_id not in pre_mismatch_tx:
+            pre_mismatch_tx[if_id] = 0.4
+        if if_id not in pre_mismatch_rx:
+            pre_mismatch_rx[if_id] = 0.4
+
+    # Stage 2: Targeted router-level flow projection with bundle awareness
+    scaled_tx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
+    scaled_rx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
+    strong_scaled_tx: Dict[str, bool] = {if_id: False for if_id in telemetry}
+    strong_scaled_rx: Dict[str, bool] = {if_id: False for if_id in telemetry}
+
     for router, if_list in router_ifaces.items():
-        if not if_list:
-            continue
-        sum_tx = 0.0
-        sum_rx = 0.0
-        sum_tx_conf = 0.0
-        sum_rx_conf = 0.0
-        for i in if_list:
-            if i not in result:
-                continue
-            sum_tx += safe_rate(result[i]['tx_rate'][1])
-            sum_rx += safe_rate(result[i]['rx_rate'][1])
-            sum_tx_conf += clamp01(result[i]['tx_rate'][2])
-            sum_rx_conf += clamp01(result[i]['rx_rate'][2])
+        if len(if_list) <= 1:
+            continue
+
+        sum_tx = sum(hard_tx.get(i, 0.0) for i in if_list)
+        sum_rx = sum(hard_rx.get(i, 0.0) for i in if_list)
+        n_active_tx = sum(1 for i in if_list if hard_tx.get(i, 0.0) >= ZERO_THRESH)
+        n_active_rx = sum(1 for i in if_list if hard_rx.get(i, 0.0) >= ZERO_THRESH)
+        n_active = max(n_active_tx, n_active_rx)
         if max(sum_tx, sum_rx) < EPS:
             continue
         mismatch = rel_diff(sum_tx, sum_rx)
-        if mismatch > ROUTER_TOL:
-            # choose the side with lower aggregate confidence to adjust
-            adjust_side = 'tx' if sum_tx_conf < sum_rx_conf else 'rx'
-            if adjust_side == 'tx' and sum_tx > 0:
-                alpha = sum_rx / max(sum_tx, EPS)
-                # clip and damp scaling
-                alpha = max(0.85, min(1.15, alpha))
+        TAU_ROUTER = tau_router(n_active)
+        if mismatch <= TAU_ROUTER:
+            continue
+
+        # Decide side by aggregate confidence
+        c_tx_total = sum(conf_tx_link.get(i, 0.6) for i in if_list)
+        c_rx_total = sum(conf_rx_link.get(i, 0.6) for i in if_list)
+        adjust_side = "tx" if c_tx_total < c_rx_total else "rx"
+
+        # Build per-interface values, confidences, and bundle groups by remote router
+        def group_key(iid: str) -> str:
+            rr = telemetry.get(iid, {}).get("remote_router")
+            return f"{rr}" if rr is not None else f"unknown_remote::{iid}"
+
+        if adjust_side == "tx" and sum_tx > 0:
+            vals = {i: hard_tx.get(i, 0.0) for i in if_list}
+            confs = {i: clamp01(conf_tx_link.get(i, 0.6)) for i in if_list}
+            weights = {}
+            for i, v in vals.items():
+                w = (1.0 - confs[i]) * (v if v >= ZERO_THRESH else 0.0)
+                weights[i] = max(0.0, w)
+            denom = sum(weights.values())
+            target, current = sum_rx, sum_tx
+
+            if denom < EPS:
+                # Fallback: uniform damped scaling
+                alpha = target / max(current, EPS)
+                alpha = max(0.90, min(1.10, alpha))
                 alpha_eff = 1.0 + 0.6 * (alpha - 1.0)
-                penalty = abs(alpha_eff - 1.0)
                 for i in if_list:
-                    if i not in result:
+                    hard_tx[i] = vals[i] * alpha_eff
+                    scaled_tx_factor[i] *= alpha_eff
+                    penalty = abs(alpha_eff - 1.0)
+                    if penalty > 0.08:
+                        strong_scaled_tx[i] = True
+                    conf_tx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
+            else:
+                k = (target - current) / denom
+
+                # Compute group-major bundles
+                total_side = sum(vals.values())
+                bundles: Dict[str, List[str]] = {}
+                for i in if_list:
+                    bundles.setdefault(group_key(i), []).append(i)
+                bundle_share: Dict[str, float] = {}
+                for g, members in bundles.items():
+                    share = sum(vals[m] for m in members) / max(total_side, EPS)
+                    bundle_share[g] = share
+
+                # Precompute group-level ratio for dominant bundles
+                group_alpha_raw: Dict[str, float] = {}
+                for g, members in bundles.items():
+                    if bundle_share[g] >= 0.55:
+                        sum_w = sum(weights[m] for m in members)
+                        sum_v = sum(vals[m] for m in members)
+                        if sum_v > EPS:
+                            alpha_raw_g = 1.0 + k * (sum_w / sum_v)
+                        else:
+                            alpha_raw_g = 1.0
+                        group_alpha_raw[g] = alpha_raw_g
+
+                # Apply per-interface or bundle-shared scaling
+                for i, v in vals.items():
+                    if v < EPS:
                         continue
-                    cur_tx = safe_rate(result[i]['tx_rate'][1])
-                    new_tx = cur_tx * alpha_eff
-                    result[i]['tx_rate'] = (
-                        result[i]['tx_rate'][0],
-                        new_tx,
-                        clamp01(result[i]['tx_rate'][2] * (1.0 - 0.4 * clamp01(penalty)))
-                    )
-            elif adjust_side == 'rx' and sum_rx > 0:
-                alpha = sum_tx / max(sum_rx, EPS)
-                alpha = max(0.85, min(1.15, alpha))
+                    g = group_key(i)
+                    if g in group_alpha_raw:
+                        alpha_raw = group_alpha_raw[g]
+                    else:
+                        alpha_raw = 1.0 + k * (weights[i] / max(v, EPS))
+                    # Damped and clipped
+                    alpha_eff = 1.0 + 0.6 * (alpha_raw - 1.0)
+                    alpha_eff = max(0.90, min(1.10, alpha_eff))
+                    hard_tx[i] = v * alpha_eff
+                    scaled_tx_factor[i] *= alpha_eff
+                    penalty = abs(alpha_eff - 1.0)
+                    if penalty > 0.08:
+                        strong_scaled_tx[i] = True
+                    conf_tx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
+
+        elif adjust_side == "rx" and sum_rx > 0:
+            vals = {i: hard_rx.get(i, 0.0) for i in if_list}
+            confs = {i: clamp01(conf_rx_link.get(i, 0.6)) for i in if_list}
+            weights = {}
+            for i, v in vals.items():
+                w = (1.0 - confs[i]) * (v if v >= ZERO_THRESH else 0.0)
+                weights[i] = max(0.0, w)
+            denom = sum(weights.values())
+            target, current = sum_tx, sum_rx
+
+            if denom < EPS:
+                alpha = target / max(current, EPS)
+                alpha = max(0.90, min(1.10, alpha))
                 alpha_eff = 1.0 + 0.6 * (alpha - 1.0)
-                penalty = abs(alpha_eff - 1.0)
                 for i in if_list:
-                    if i not in result:
+                    hard_rx[i] = vals[i] * alpha_eff
+                    scaled_rx_factor[i] *= alpha_eff
+                    penalty = abs(alpha_eff - 1.0)
+                    if penalty > 0.08:
+                        strong_scaled_rx[i] = True
+                    conf_rx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
+            else:
+                k = (target - current) / denom
+
+                total_side = sum(vals.values())
+                bundles: Dict[str, List[str]] = {}
+                for i in if_list:
+                    bundles.setdefault(group_key(i), []).append(i)
+                bundle_share: Dict[str, float] = {}
+                for g, members in bundles.items():
+                    share = sum(vals[m] for m in members) / max(total_side, EPS)
+                    bundle_share[g] = share
+
+                group_alpha_raw: Dict[str, float] = {}
+                for g, members in bundles.items():
+                    if bundle_share[g] >= 0.55:
+                        sum_w = sum(weights[m] for m in members)
+                        sum_v = sum(vals[m] for m in members)
+                        if sum_v > EPS:
+                            alpha_raw_g = 1.0 + k * (sum_w / sum_v)
+                        else:
+                            alpha_raw_g = 1.0
+                        group_alpha_raw[g] = alpha_raw_g
+
+                for i, v in vals.items():
+                    if v < EPS:
                         continue
-                    cur_rx = safe_rate(result[i]['rx_rate'][1])
-                    new_rx = cur_rx * alpha_eff
-                    result[i]['rx_rate'] = (
-                        result[i]['rx_rate'][0],
-                        new_rx,
-                        clamp01(result[i]['rx_rate'][2] * (1.0 - 0.4 * clamp01(penalty)))
-                    )
-
-    # Stage 2.5: Post-projection gentle link re-sync and confidence calibration
+                    g = group_key(i)
+                    if g in group_alpha_raw:
+                        alpha_raw = group_alpha_raw[g]
+                    else:
+                        alpha_raw = 1.0 + k * (weights[i] / max(v, EPS))
+                    alpha_eff = 1.0 + 0.6 * (alpha_raw - 1.0)
+                    alpha_eff = max(0.90, min(1.10, alpha_eff))
+                    hard_rx[i] = v * alpha_eff
+                    scaled_rx_factor[i] *= alpha_eff
+                    penalty = abs(alpha_eff - 1.0)
+                    if penalty > 0.08:
+                        strong_scaled_rx[i] = True
+                    conf_rx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
+
+    # Stage 2.5: Confidence-gap proportional link re-sync (skip directions with strong scaling)
     processed_pairs = set()
     for a, data_a in telemetry.items():
         b = data_a.get('connected_to')
         if not isinstance(b, str) or b not in telemetry:
             continue
         key = tuple(sorted([a, b]))
         if key in processed_pairs:
             continue
         processed_pairs.add(key)
 
-        # a->b direction: my_tx[a] vs their_rx[b]
-        if a in result and b in result:
-            tx_a = safe_rate(result[a]['tx_rate'][1])
-            rx_b = safe_rate(result[b]['rx_rate'][1])
-            diff_ab = rel_diff(tx_a, rx_b)
-            if diff_ab > HARDENING_THRESHOLD and max(tx_a, rx_b) >= ZERO_THRESH:
-                ca = clamp01(result[a]['tx_rate'][2])
-                cb = clamp01(result[b]['rx_rate'][2])
+        # a->b direction
+        tx_a = hard_tx.get(a, 0.0)
+        rx_b = hard_rx.get(b, 0.0)
+        ca = clamp01(conf_tx_link.get(a, 0.6))
+        cb = clamp01(conf_rx_link.get(b, 0.6))
+        th_ab = tau_h_dir(tx_a, rx_b, ca, cb)
+        if rel_diff(tx_a, rx_b) > th_ab and max(tx_a, rx_b) >= ZERO_THRESH:
+            if not (strong_scaled_tx.get(a, False) or strong_scaled_rx.get(b, False)):
                 mean_ab = 0.5 * (tx_a + rx_b)
-                if ca < cb:
-                    # Nudge lower-confidence side toward mean
-                    new_tx_a = 0.5 * mean_ab + 0.5 * tx_a
-                    result[a]['tx_rate'] = (result[a]['tx_rate'][0], new_tx_a, clamp01(ca * 0.95))
-                elif cb < ca:
-                    new_rx_b = 0.5 * mean_ab + 0.5 * rx_b
-                    result[b]['rx_rate'] = (result[b]['rx_rate'][0], new_rx_b, clamp01(cb * 0.95))
-                else:
-                    # Both similar and low confidence: cautiously set both to mean
-                    if ca < 0.7:
-                        result[a]['tx_rate'] = (result[a]['tx_rate'][0], mean_ab, clamp01(ca * 0.93))
-                        result[b]['rx_rate'] = (result[b]['rx_rate'][0], mean_ab, clamp01(cb * 0.93))
-
-        # b->a direction: my_tx[b] vs their_rx[a]
-        if a in result and b in result:
-            tx_b = safe_rate(result[b]['tx_rate'][1])
-            rx_a = safe_rate(result[a]['rx_rate'][1])
-            diff_ba = rel_diff(tx_b, rx_a)
-            if diff_ba > HARDENING_THRESHOLD and max(tx_b, rx_a) >= ZERO_THRESH:
-                cb_tx = clamp01(result[b]['tx_rate'][2])
-                ca_rx = clamp01(result[a]['rx_rate'][2])
+                high, low = (ca, 'a'), (cb, 'b')
+                if cb > ca:
+                    high, low = (cb, 'b'), (ca, 'a')
+                f = min(0.4, max(0.0, high[0] - low[0]))
+                if f > 0.0:
+                    if low[1] == 'a':
+                        hard_tx[a] = (1.0 - f) * tx_a + f * mean_ab
+                        conf_tx_link[a] *= 0.97
+                    else:
+                        hard_rx[b] = (1.0 - f) * rx_b + f * mean_ab
+                        conf_rx_link[b] *= 0.97
+
+        # b->a direction
+        tx_b = hard_tx.get(b, 0.0)
+        rx_a = hard_rx.get(a, 0.0)
+        cb_tx = clamp01(conf_tx_link.get(b, 0.6))
+        ca_rx = clamp01(conf_rx_link.get(a, 0.6))
+        th_ba = tau_h_dir(tx_b, rx_a, cb_tx, ca_rx)
+        if rel_diff(tx_b, rx_a) > th_ba and max(tx_b, rx_a) >= ZERO_THRESH:
+            if not (strong_scaled_tx.get(b, False) or strong_scaled_rx.get(a, False)):
                 mean_ba = 0.5 * (tx_b + rx_a)
-                if cb_tx < ca_rx:
-                    new_tx_b = 0.5 * mean_ba + 0.5 * tx_b
-                    result[b]['tx_rate'] = (result[b]['tx_rate'][0], new_tx_b, clamp01(cb_tx * 0.95))
-                elif ca_rx < cb_tx:
-                    new_rx_a = 0.5 * mean_ba + 0.5 * rx_a
-                    result[a]['rx_rate'] = (result[a]['rx_rate'][0], new_rx_a, clamp01(ca_rx * 0.95))
-                else:
-                    if cb_tx < 0.7:
-                        result[b]['tx_rate'] = (result[b]['tx_rate'][0], mean_ba, clamp01(cb_tx * 0.93))
-                        result[a]['rx_rate'] = (result[a]['rx_rate'][0], mean_ba, clamp01(ca_rx * 0.93))
-
-    # Final confidence touch-up: incorporate final symmetry residuals
+                high, low = (cb_tx, 'b'), (ca_rx, 'a')
+                if ca_rx > cb_tx:
+                    high, low = (ca_rx, 'a'), (cb_tx, 'b')
+                f = min(0.4, max(0.0, high[0] - low[0]))
+                if f > 0.0:
+                    if low[1] == 'b':
+                        hard_tx[b] = (1.0 - f) * tx_b + f * mean_ba
+                        conf_tx_link[b] *= 0.97
+                    else:
+                        hard_rx[a] = (1.0 - f) * rx_a + f * mean_ba
+                        conf_rx_link[a] *= 0.97
+
+    # Soft-zero rule: stabilize tiny bidirectional links
+    processed_pairs = set()
+    for a, data_a in telemetry.items():
+        b = data_a.get('connected_to')
+        if not isinstance(b, str) or b not in telemetry:
+            continue
+        key = tuple(sorted([a, b]))
+        if key in processed_pairs:
+            continue
+        processed_pairs.add(key)
+        tx_a = hard_tx.get(a, 0.0)
+        rx_b = hard_rx.get(b, 0.0)
+        tx_b = hard_tx.get(b, 0.0)
+        rx_a = hard_rx.get(a, 0.0)
+        if max(tx_a, rx_b, tx_b, rx_a) < 2.0 * ZERO_THRESH:
+            hard_tx[a] = 0.0
+            hard_rx[b] = 0.0
+            hard_tx[b] = 0.0
+            hard_rx[a] = 0.0
+            conf_tx_link[a] = max(conf_tx_link.get(a, 0.6), 0.95)
+            conf_rx_link[b] = max(conf_rx_link.get(b, 0.6), 0.95)
+            conf_tx_link[b] = max(conf_tx_link.get(b, 0.6), 0.95)
+            conf_rx_link[a] = max(conf_rx_link.get(a, 0.6), 0.95)
+
+    # Status repair (symmetry-aware)
+    repaired_status: Dict[str, str] = {}
+    status_conf: Dict[str, float] = {}
+    handled = set()
+    for a, data_a in telemetry.items():
+        if a in handled:
+            continue
+        b = data_a.get('connected_to')
+        sa = status_raw.get(a, "unknown")
+        if not isinstance(b, str) or b not in telemetry:
+            repaired_status[a] = sa
+            status_conf[a] = 0.95
+            handled.add(a)
+            continue
+        sb = status_raw.get(b, "unknown")
+        # Traffic-based consistency
+        any_traffic = (hard_tx.get(a, 0.0) >= ZERO_THRESH or hard_rx.get(a, 0.0) >= ZERO_THRESH or
+                       hard_tx.get(b, 0.0) >= ZERO_THRESH or hard_rx.get(b, 0.0) >= ZERO_THRESH)
+        if sa == "down" and sb == "down":
+            repaired_status[a] = "down"
+            repaired_status[b] = "down"
+            status_conf[a] = 0.98
+            status_conf[b] = 0.98
+        elif sa != sb:
+            if any_traffic:
+                repaired_status[a] = "up"
+                repaired_status[b] = "up"
+                status_conf[a] = 0.70
+                status_conf[b] = 0.70
+            else:
+                # ambiguous; keep as-is with lower confidence
+                repaired_status[a] = sa
+                repaired_status[b] = sb
+                status_conf[a] = 0.6
+                status_conf[b] = 0.6
+        else:
+            repaired_status[a] = sa
+            repaired_status[b] = sb
+            status_conf[a] = 0.95
+            status_conf[b] = 0.95
+        handled.add(a)
+        handled.add(b)
+
+    # Prepare final invariant metrics for confidence calibration
+    # Router imbalance AFTER projection
+    router_imbalance_after: Dict[str, float] = {}
+    for r, if_list in router_ifaces.items():
+        sum_tx_a = sum(hard_tx.get(i, 0.0) for i in if_list)
+        sum_rx_a = sum(hard_rx.get(i, 0.0) for i in if_list)
+        router_imbalance_after[r] = rel_diff(sum_tx_a, sum_rx_a)
+
+    # Final per-direction symmetry residuals
+    post_mismatch_tx_dir: Dict[str, float] = {}
+    post_mismatch_rx_dir: Dict[str, float] = {}
     for i, data in telemetry.items():
-        peer = data.get('connected_to')
-        if not isinstance(peer, str) or peer not in telemetry or i not in result or peer not in result:
-            continue
-        mis_tx = rel_diff(safe_rate(result[i]['tx_rate'][1]), safe_rate(result[peer]['rx_rate'][1]))
-        mis_rx = rel_diff(safe_rate(result[i]['rx_rate'][1]), safe_rate(result[peer]['tx_rate'][1]))
-        result[i]['tx_rate'] = (
-            result[i]['tx_rate'][0],
-            result[i]['tx_rate'][1],
-            clamp01(0.7 * clamp01(result[i]['tx_rate'][2]) + 0.3 * clamp01(1.0 - mis_tx))
+        p = data.get("connected_to")
+        if isinstance(p, str) and p in telemetry:
+            post_mismatch_tx_dir[i] = rel_diff(hard_tx.get(i, 0.0), hard_rx.get(p, 0.0))
+            post_mismatch_rx_dir[i] = rel_diff(hard_rx.get(i, 0.0), hard_tx.get(p, 0.0))
+        else:
+            post_mismatch_tx_dir[i] = 0.4
+            post_mismatch_rx_dir[i] = 0.4
+
+    # Compose results with confidence calibration
+    result: Dict[str, Dict[str, Tuple]] = {}
+    for if_id, data in telemetry.items():
+        rep_tx = hard_tx.get(if_id, orig_tx[if_id])
+        rep_rx = hard_rx.get(if_id, orig_rx[if_id])
+
+        # Change magnitude relative to original
+        change_tx = rel_diff(orig_tx[if_id], rep_tx)
+        change_rx = rel_diff(orig_rx[if_id], rep_rx)
+
+        # Redundancy (pre-fusion mismatch)
+        pre_tx = pre_mismatch_tx.get(if_id, 0.4)
+        pre_rx = pre_mismatch_rx.get(if_id, 0.4)
+
+        # Final symmetry agreement
+        fin_sym_tx = clamp01(1.0 - post_mismatch_tx_dir.get(if_id, 0.4))
+        fin_sym_rx = clamp01(1.0 - post_mismatch_rx_dir.get(if_id, 0.4))
+
+        # Router factor AFTER projection
+        r = router_of.get(if_id, None)
+        router_penalty_after = router_imbalance_after.get(r, 0.0) if r is not None else 0.0
+        router_factor_after = clamp01(1.0 - min(0.5, router_penalty_after))
+
+        base_tx_conf = clamp01(conf_tx_link.get(if_id, 0.6))
+        base_rx_conf = clamp01(conf_rx_link.get(if_id, 0.6))
+
+        red_tx = clamp01(1.0 - pre_tx)
+        red_rx = clamp01(1.0 - pre_rx)
+
+        ch_tx = clamp01(1.0 - change_tx)
+        ch_rx = clamp01(1.0 - change_rx)
+
+        # Scale penalty term (larger scaling => lower confidence)
+        scale_term_tx = clamp01(1.0 - min(0.5, abs(scaled_tx_factor.get(if_id, 1.0) - 1.0)))
+        scale_term_rx = clamp01(1.0 - min(0.5, abs(scaled_rx_factor.get(if_id, 1.0) - 1.0)))
+
+        conf_tx_final = clamp01(
+            0.22 * base_tx_conf +
+            0.18 * red_tx +
+            0.28 * fin_sym_tx +
+            0.12 * ch_tx +
+            0.10 * router_factor_after +
+            0.10 * scale_term_tx
         )
-        result[i]['rx_rate'] = (
-            result[i]['rx_rate'][0],
-            result[i]['rx_rate'][1],
-            clamp01(0.7 * clamp01(result[i]['rx_rate'][2]) + 0.3 * clamp01(1.0 - mis_rx))
+        conf_rx_final = clamp01(
+            0.22 * base_rx_conf +
+            0.18 * red_rx +
+            0.28 * fin_sym_rx +
+            0.12 * ch_rx +
+            0.10 * router_factor_after +
+            0.10 * scale_term_rx
         )
 
-    # Final pass: status enforcement - down implies zero counters with calibrated confidence
+        # Status enforcement: down implies zero counters
+        rep_status = repaired_status.get(if_id, status_raw.get(if_id, "unknown"))
+        conf_status = status_conf.get(if_id, 0.9)
+        if rep_status == "down":
+            rep_tx = 0.0
+            rep_rx = 0.0
+            if orig_tx[if_id] >= ZERO_THRESH or orig_rx[if_id] >= ZERO_THRESH:
+                conf_tx_final = min(conf_tx_final, 0.7)
+                conf_rx_final = min(conf_rx_final, 0.7)
+            else:
+                conf_tx_final = max(conf_tx_final, 0.9)
+                conf_rx_final = max(conf_rx_final, 0.9)
+
+        # Assemble output
+        out = {}
+        out["rx_rate"] = (orig_rx[if_id], rep_rx, conf_rx_final)
+        out["tx_rate"] = (orig_tx[if_id], rep_tx, conf_tx_final)
+        out["interface_status"] = (status_raw[if_id], rep_status, conf_status)
+
+        # Copy metadata unchanged
+        out["connected_to"] = data.get("connected_to")
+        out["local_router"] = data.get("local_router")
+        out["remote_router"] = data.get("remote_router")
+
+        result[if_id] = out
+
+    # Peer confidence smoothing (10%) when both ends are up
     for i, data in telemetry.items():
-        status = data.get('interface_status', 'unknown')
-        if i not in result:
-            continue
-        if status == 'down':
-            orig_tx = safe_rate(result[i]['tx_rate'][0])
-            orig_rx = safe_rate(result[i]['rx_rate'][0])
-            result[i]['tx_rate'] = (
-                result[i]['tx_rate'][0],
-                0.0,
-                0.9 if (orig_tx < ZERO_THRESH and orig_rx < ZERO_THRESH) else min(result[i]['tx_rate'][2], 0.7)
-            )
-            result[i]['rx_rate'] = (
-                result[i]['rx_rate'][0],
-                0.0,
-                0.9 if (orig_tx < ZERO_THRESH and orig_rx < ZERO_THRESH) else min(result[i]['rx_rate'][2], 0.7)
-            )
+        p = data.get("connected_to")
+        if not isinstance(p, str) or p not in telemetry:
+            continue
+        if i not in result or p not in result:
+            continue
+        if result[i]["interface_status"][1] != "up" or result[p]["interface_status"][1] != "up":
+            continue
+        # Blend my confidence with peer opposite by 10%
+        my_tx_c = clamp01(result[i]["tx_rate"][2])
+        my_rx_c = clamp01(result[i]["rx_rate"][2])
+        peer_rx_c = clamp01(result[p]["rx_rate"][2])
+        peer_tx_c = clamp01(result[p]["tx_rate"][2])
+        result[i]["tx_rate"] = (result[i]["tx_rate"][0], result[i]["tx_rate"][1],
+                                clamp01(0.90 * my_tx_c + 0.10 * peer_rx_c))
+        result[i]["rx_rate"] = (result[i]["rx_rate"][0], result[i]["rx_rate"][1],
+                                clamp01(0.90 * my_rx_c + 0.10 * peer_tx_c))
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")