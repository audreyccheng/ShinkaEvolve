<NAME>
adaptive_tau_guard_softzero
</NAME>

<DESCRIPTION>
I propose three targeted improvements that should increase counter repair accuracy and keep confidence calibration strong:

1) Adaptive hardening tolerance: Replace the fixed 2% link symmetry tolerance with a dynamic tau_h_dir that tightens to 1.5% for high-rate/high-confidence cases and relaxes to 3% for low-rate/low-confidence cases. This reduces unnecessary changes on stable high-throughput links and avoids noise-driven adjustments near zero.

2) Re-sync scaling guard and adaptive threshold: Introduce strong_scaled flags during router-level projection and skip Stage 2.5 re-sync on directions that received strong scaling (|scale − 1| > 0.08). Also use the new adaptive threshold in Stage 2.5 with confidence-aware tau_h_dir. This prevents double-adjustment after significant router corrections and further aligns with the Hodor dynamic checking principle.

3) Soft-zero stabilization: Before status repair, if both directions of a link are tiny (< 2 × ZERO_THRESH), snap all four counters on the link to zero with high confidence. This reduces jitter and improves near-zero accuracy without harming calibration.

The changes are localized: we add a helper tau_h_dir, adjust fuse_direction to use it, add strong scaling flags in projection, adapt re-sync conditions, and add a soft-zero pass. No external interfaces change.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def clamp01(x: float) -> float:
        if x < 0.0: return 0.0
        if x > 1.0: return 1.0
        return x
=======
    def clamp01(x: float) -> float:
        if x < 0.0: return 0.0
        if x > 1.0: return 1.0
        return x

    def tau_h_dir(v1: float, v2: float, c1: float = None, c2: float = None) -> float:
        """
        Adaptive hardening tolerance:
        - 1.5% when both directions are high-rate (>100 Mbps) and confidences (if provided) are high (>=0.8)
        - 3% when either direction is low-rate (<1 Mbps) or any confidence is low (<0.7)
        - 2% baseline otherwise
        """
        high = (v1 > 100.0 and v2 > 100.0)
        low = (v1 < 1.0 or v2 < 1.0)
        high_conf = (c1 is not None and c2 is not None and c1 >= 0.8 and c2 >= 0.8)
        low_conf = (c1 is not None and c2 is not None and (c1 < 0.7 or c2 < 0.7))
        if high and high_conf:
            return 0.015
        if low or low_conf:
            return 0.03
        return 0.02
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def fuse_direction(v_local: float, v_peer: float, s_local: str, s_peer: str) -> Tuple[float, float]:
        mismatch = rel_diff(v_local, v_peer)

        # Both near-zero => zero with high confidence
        if max(v_local, v_peer) < ZERO_THRESH:
            return 0.0, 0.95

        # If within hardening tolerance, keep local reading (minimal change)
        if mismatch <= TAU_H:
            return v_local, 0.95

        # Moderate mismatch: average
        if mismatch <= 0.10:
            fused = 0.5 * v_local + 0.5 * v_peer
            return fused, clamp01(1.0 - mismatch)

        # Large mismatch: prefer the more plausible side
        # If one is near-zero and the other is not, take the non-zero
        if v_local < ZERO_THRESH and v_peer >= ZERO_THRESH:
            return v_peer, clamp01(1.0 - mismatch)
        if v_peer < ZERO_THRESH and v_local >= ZERO_THRESH:
            return v_local, clamp01(1.0 - mismatch)

        # Status-aware bias
        if s_local == "down" and s_peer == "up":
            return v_peer, clamp01(1.0 - mismatch)
        if s_peer == "down" and s_local == "up":
            return v_local, clamp01(1.0 - mismatch)

        # Otherwise, snap mostly to peer to resolve asymmetry decisively
        fused = 0.3 * v_local + 0.7 * v_peer
        return fused, clamp01(1.0 - mismatch)
=======
    def fuse_direction(v_local: float, v_peer: float, s_local: str, s_peer: str) -> Tuple[float, float]:
        mismatch = rel_diff(v_local, v_peer)
        th = tau_h_dir(v_local, v_peer)

        # Both near-zero => zero with high confidence
        if max(v_local, v_peer) < ZERO_THRESH:
            return 0.0, 0.95

        # If within adaptive hardening tolerance, keep local reading (minimal change)
        if mismatch <= th:
            return v_local, 0.95

        # Moderate mismatch: average
        if mismatch <= 0.10:
            fused = 0.5 * v_local + 0.5 * v_peer
            return fused, clamp01(1.0 - mismatch)

        # Large mismatch: prefer the more plausible side
        # If one is near-zero and the other is not, take the non-zero
        if v_local < ZERO_THRESH and v_peer >= ZERO_THRESH:
            return v_peer, clamp01(1.0 - mismatch)
        if v_peer < ZERO_THRESH and v_local >= ZERO_THRESH:
            return v_local, clamp01(1.0 - mismatch)

        # Status-aware bias
        if s_local == "down" and s_peer == "up":
            return v_peer, clamp01(1.0 - mismatch)
        if s_peer == "down" and s_local == "up":
            return v_local, clamp01(1.0 - mismatch)

        # Otherwise, snap mostly to peer to resolve asymmetry decisively
        fused = 0.3 * v_local + 0.7 * v_peer
        return fused, clamp01(1.0 - mismatch)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    router_imbalance_before: Dict[str, float] = {}
    scaled_tx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    scaled_rx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
=======
    router_imbalance_before: Dict[str, float] = {}
    scaled_tx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    scaled_rx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    # Track directions that received strong scaling to guard against double-adjustment in Stage 2.5
    strong_scaled_tx: Dict[str, bool] = {if_id: False for if_id in telemetry}
    strong_scaled_rx: Dict[str, bool] = {if_id: False for if_id in telemetry}
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                    for i in if_list:
                        hard_tx[i] *= alpha_eff
                        scaled_tx_factor[i] *= alpha_eff
                        penalty = clamp01(abs(alpha_eff - 1.0))
                        conf_tx_link[i] *= clamp01(1.0 - 0.4 * penalty)
=======
                    for i in if_list:
                        hard_tx[i] *= alpha_eff
                        scaled_tx_factor[i] *= alpha_eff
                        penalty = clamp01(abs(alpha_eff - 1.0))
                        conf_tx_link[i] *= clamp01(1.0 - 0.4 * penalty)
                        if penalty > 0.08:
                            strong_scaled_tx[i] = True
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                        hard_tx[i] = v * scale_i
                        scaled_tx_factor[i] *= scale_i
                        penalty = clamp01(abs(scale_i - 1.0))
                        conf_tx_link[i] *= clamp01(1.0 - 0.4 * penalty)
=======
                        hard_tx[i] = v * scale_i
                        scaled_tx_factor[i] *= scale_i
                        penalty = clamp01(abs(scale_i - 1.0))
                        conf_tx_link[i] *= clamp01(1.0 - 0.4 * penalty)
                        if penalty > 0.08:
                            strong_scaled_tx[i] = True
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                    for i in if_list:
                        hard_rx[i] *= alpha_eff
                        scaled_rx_factor[i] *= alpha_eff
                        penalty = clamp01(abs(alpha_eff - 1.0))
                        conf_rx_link[i] *= clamp01(1.0 - 0.4 * penalty)
=======
                    for i in if_list:
                        hard_rx[i] *= alpha_eff
                        scaled_rx_factor[i] *= alpha_eff
                        penalty = clamp01(abs(alpha_eff - 1.0))
                        conf_rx_link[i] *= clamp01(1.0 - 0.4 * penalty)
                        if penalty > 0.08:
                            strong_scaled_rx[i] = True
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                        hard_rx[i] = v * scale_i
                        scaled_rx_factor[i] *= scale_i
                        penalty = clamp01(abs(scale_i - 1.0))
                        conf_rx_link[i] *= clamp01(1.0 - 0.4 * penalty)
=======
                        hard_rx[i] = v * scale_i
                        scaled_rx_factor[i] *= scale_i
                        penalty = clamp01(abs(scale_i - 1.0))
                        conf_rx_link[i] *= clamp01(1.0 - 0.4 * penalty)
                        if penalty > 0.08:
                            strong_scaled_rx[i] = True
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        diff_ab = rel_diff(tx_a, rx_b)
        if diff_ab > TAU_H and max(tx_a, rx_b) >= ZERO_THRESH:
            mean_ab = 0.5 * (tx_a + rx_b)
            ca = conf_tx_link.get(a, 0.6)
            cb = conf_rx_link.get(b, 0.6)
=======
        diff_ab = rel_diff(tx_a, rx_b)
        ca = conf_tx_link.get(a, 0.6)
        cb = conf_rx_link.get(b, 0.6)
        th_ab = tau_h_dir(tx_a, rx_b, ca, cb)
        if diff_ab > th_ab and max(tx_a, rx_b) >= ZERO_THRESH and not (strong_scaled_tx.get(a, False) or strong_scaled_rx.get(b, False)):
            mean_ab = 0.5 * (tx_a + rx_b)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        diff_ba = rel_diff(tx_b, rx_a)
        if diff_ba > TAU_H and max(tx_b, rx_a) >= ZERO_THRESH:
            mean_ba = 0.5 * (tx_b + rx_a)
            cb_tx = conf_tx_link.get(b, 0.6)
            ca_rx = conf_rx_link.get(a, 0.6)
=======
        diff_ba = rel_diff(tx_b, rx_a)
        cb_tx = conf_tx_link.get(b, 0.6)
        ca_rx = conf_rx_link.get(a, 0.6)
        th_ba = tau_h_dir(tx_b, rx_a, cb_tx, ca_rx)
        if diff_ba > th_ba and max(tx_b, rx_a) >= ZERO_THRESH and not (strong_scaled_tx.get(b, False) or strong_scaled_rx.get(a, False)):
            mean_ba = 0.5 * (tx_b + rx_a)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Status repair (conservative and symmetry-aware)
=======
    # Soft-zero rule: if both directions on a link are tiny, snap all four to 0 with high confidence
    processed_pairs = set()
    for a, data_a in telemetry.items():
        b = data_a.get('connected_to')
        if not isinstance(b, str) or b not in telemetry:
            continue
        key = tuple(sorted([a, b]))
        if key in processed_pairs:
            continue
        processed_pairs.add(key)
        tx_a = hard_tx.get(a, 0.0)
        rx_b = hard_rx.get(b, 0.0)
        tx_b = hard_tx.get(b, 0.0)
        rx_a = hard_rx.get(a, 0.0)
        if max(tx_a, rx_b, tx_b, rx_a) < 2.0 * ZERO_THRESH:
            hard_tx[a] = 0.0
            hard_rx[b] = 0.0
            hard_tx[b] = 0.0
            hard_rx[a] = 0.0
            conf_tx_link[a] = max(conf_tx_link.get(a, 0.6), 0.95)
            conf_rx_link[b] = max(conf_rx_link.get(b, 0.6), 0.95)
            conf_tx_link[b] = max(conf_tx_link.get(b, 0.6), 0.95)
            conf_rx_link[a] = max(conf_rx_link.get(a, 0.6), 0.95)

    # Status repair (conservative and symmetry-aware)
>>>>>>> REPLACE

</DIFF>