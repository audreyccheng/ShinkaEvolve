--- a/original.py
+++ b/original.py
@@ -1,1104 +1,603 @@
 # EVOLVE-BLOCK-START
 """
-Bundle-aware consensus projection for network telemetry repair.
-
-Algorithm summary:
-1) Robust link hardening with adaptive tolerance and soft-zero snapping.
-2) Router flow conservation via targeted, confidence-weighted corrections.
-   - Expected-penalty router-side selection with dominance awareness.
-   - Bundle-aware scaling for parallel links (shared factor).
-   - Adaptive per-interface clipping with dominance-aware caps and micro-tier.
-3) Confidence-gap-proportional re-sync on links with scaling guard and absolute-per-dir caps.
-4) Dispersion-aware bundle finishing with per-router zero-sum enforcement.
-5) Confidence calibrated from measurement residuals, link residuals, router residuals,
-   plus stability, bundle-consistency, scale-factor term, and peer/router smoothing.
-
-Maintains inputs/outputs of the original function.
+Global weighted POCS for network telemetry repair.
+
+Core idea:
+- Alternate projections onto two convex invariant sets:
+  (1) Link symmetry: a.tx = b.rx and a.rx = b.tx.
+  (2) Router conservation: Σ_tx(router) = Σ_rx(router).
+- Projections are minimum-change under dominance- and confidence-aware weights,
+  with per-interface, share/HHI-adaptive move caps to avoid overcorrections.
+- Includes soft-zero stabilization, non-negativity, and early stopping.
+
+Confidence is calibrated from measurement/link/router residuals and move scales,
+with peer smoothing and "untouched" boosts.
 """
 from typing import Dict, Any, Tuple, List
 import math
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     # Hyperparameters
-    TAU_H_BASE = 0.02        # ~2% hardening threshold
-    ZERO_EPS = 1e-6
-    ZERO_THRESH = 1.0        # Mbps near-zero threshold
-    DAMP_ROUTER = 0.60       # router damping factor
-    PER_LINK_CLIP_BASE = 0.10     # baseline per-interface relative change cap (±10%)
-    BUNDLE_CLIP = 0.15       # bundle shared factor cap (±15%)
-    STRONG_SCALE_GUARD = 0.08  # guard for re-sync when strong router scaling applied
-    RESYNC_MAX_F = 0.40      # max one-sided nudge toward mean
-    RESYNC_PER_DIR_CAP = 0.02  # per-direction absolute move cap as fraction of max value
-    PEER_SMOOTH = 0.10       # 10% peer smoothing
-    WEIGHT_FOCUS = 0.70      # focus router correction on lowest-confidence 70% weight
-    DOMINANCE_CAP = 0.50     # cap any single interface's weight share to ≤50% in a pass
-    CLIP_HIT_PENALTY = 0.95  # confidence penalty multiplier when clipping/strong scaling hit
-    UNTOUCHED_BOOST = 0.02   # confidence boost for untouched, well-synced counters
-    # Second micro re-sync pass parameters
-    RESYNC2_CAP_FRAC = 0.01  # per-move absolute cap as fraction of local reference (±1%)
-    RESYNC2_GAIN = 0.50      # halved gain relative to Stage 3
-
-    # Bundle finishing parameters
-    FINISH_GAMMA_MAX = 0.30
-    FINISH_C_LOW = 0.02
-    FINISH_C_HIGH = 0.04
+    TAU_H = 0.02                 # ~2% link hardening tolerance
+    ZERO_THRESH = 1.0            # Mbps near-zero threshold
+    ZERO_EPS = 1e-9
+    MAX_ITERS = 15               # POCS iterations
+    EARLY_STOP_LINK = 0.012      # stop when max link residual below ~1.2%
+    EARLY_STOP_ROUTER = 0.025    # stop when router residual below ~2.5%
+    WEIGHT_FLOOR = 0.40          # minimum direction weight
+    WEIGHT_CEIL = 2.50           # maximum direction weight
+    SHARE_PROTECT = 0.50         # additional weight factor for dominant share
+    CAP_REL_BASE = 0.10          # base per-iteration relative cap 10%
+    CAP_REL_MIN = 0.03           # min per-iteration relative cap 3%
+    CAP_REL_MAX = 0.15           # max per-iteration relative cap 15%
+    SOFT_ZERO_FACTOR = 2.0       # if all four sides < 2*ZERO_THRESH -> zero
+    PEER_SMOOTH = 0.10           # confidence peer smoothing
+    UNTOUCHED_BOOST = 0.02       # slight boost for untouched, well-synced counters
+    CLIP_HIT_PENALTY = 0.95      # confidence penalty if caps hit
 
     def clamp01(x: float) -> float:
         return max(0.0, min(1.0, x))
 
     def rel_diff(a: float, b: float) -> float:
         return abs(a - b) / max(1.0, abs(a), abs(b))
 
     def adaptive_tau(v1: float, v2: float) -> float:
-        # Adaptive symmetry tolerance:
-        # tighter for high rates, looser for low/near-zero or low confidence regions.
+        # Slightly tighter for large rates, looser for low.
         if v1 >= 100.0 and v2 >= 100.0:
             return 0.015
         if v1 < ZERO_THRESH or v2 < ZERO_THRESH:
             return 0.03
-        return TAU_H_BASE
+        return TAU_H
 
     def median(vals: List[float]) -> float:
-        n = len(vals)
-        if n == 0:
+        if not vals:
             return 0.0
         s = sorted(vals)
-        m = n // 2
+        n = len(s)
         if n % 2 == 1:
-            return s[m]
-        return 0.5 * (s[m - 1] + s[m])
-
-    # Build basic maps
+            return s[n // 2]
+        return 0.5 * (s[n // 2 - 1] + s[n // 2 - 2])
+
+    # Extract base data
     orig_rx: Dict[str, float] = {}
     orig_tx: Dict[str, float] = {}
     status: Dict[str, str] = {}
     peer_of: Dict[str, str] = {}
     local_router_of: Dict[str, Any] = {}
     remote_router_of: Dict[str, Any] = {}
 
     for iid, d in telemetry.items():
         orig_rx[iid] = float(d.get('rx_rate', 0.0))
         orig_tx[iid] = float(d.get('tx_rate', 0.0))
         status[iid] = d.get('interface_status', 'unknown')
         ct = d.get('connected_to')
         peer_of[iid] = ct if ct in telemetry else None
         local_router_of[iid] = d.get('local_router')
         remote_router_of[iid] = d.get('remote_router')
 
-    # Build router->interfaces mapping, prefer provided topology
+    # Build router_ifaces from topology when possible
     router_ifaces: Dict[str, List[str]] = {}
     if topology:
         for r, ifs in topology.items():
             router_ifaces[r] = [i for i in ifs if i in telemetry]
     else:
-        # Fallback to local_router fields
+        # Fallback to local_router fields if topology missing
         for iid, d in telemetry.items():
             r = d.get('local_router')
             if r is not None:
                 router_ifaces.setdefault(r, []).append(iid)
 
-    # Derive missing remote_router via peer's local_router if needed
+    # Fill missing remote_router via peer's local_router if available
     for iid in telemetry:
         if not remote_router_of.get(iid):
             p = peer_of.get(iid)
             if p and p in telemetry:
                 remote_router_of[iid] = telemetry[p].get('local_router')
 
-    # Build link pairs (unique, undirected)
+    # Build link pairs (unique undirected)
     link_pairs: List[Tuple[str, str]] = []
     seen = set()
     for a in telemetry:
         b = peer_of.get(a)
         if not b or b not in telemetry or a == b:
             continue
         if (b, a) in seen or (a, b) in seen:
             continue
         seen.add((a, b))
         link_pairs.append((a, b))
 
-    # Initialize hardened values with originals
-    hardened_rx: Dict[str, float] = {i: max(0.0, orig_rx[i]) for i in telemetry}
-    hardened_tx: Dict[str, float] = {i: max(0.0, orig_tx[i]) for i in telemetry}
-    # Initialize confidences (will be calibrated later)
-    conf_rx: Dict[str, float] = {i: 0.7 for i in telemetry}
-    conf_tx: Dict[str, float] = {i: 0.7 for i in telemetry}
-
-    # Track cumulative router scaling factors for re-sync guard and confidence
-    scaled_rx_factor: Dict[str, float] = {i: 1.0 for i in telemetry}
-    scaled_tx_factor: Dict[str, float] = {i: 1.0 for i in telemetry}
-    # Track if a direction hit clipping (±10% per-pass cap or strong scaling)
-    clip_hit_rx: Dict[str, bool] = {i: False for i in telemetry}
-    clip_hit_tx: Dict[str, bool] = {i: False for i in telemetry}
-
-    # Stage 1: Robust link hardening with adaptive tolerance and soft-zero
+    # Initialize working values
+    x_rx: Dict[str, float] = {i: max(0.0, orig_rx[i]) for i in telemetry}
+    x_tx: Dict[str, float] = {i: max(0.0, orig_tx[i]) for i in telemetry}
+
+    # Initial weights per direction (confidence-aware, dominance-aware)
+    w_rx: Dict[str, float] = {}
+    w_tx: Dict[str, float] = {}
+
+    def init_weights() -> None:
+        # Link-mismatch confidence for directions
+        for i in telemetry:
+            if status.get(i) != 'up':
+                w_rx[i] = WEIGHT_CEIL
+                w_tx[i] = WEIGHT_CEIL
+                continue
+            p = peer_of.get(i)
+            # Use original values for initialization to avoid bias
+            if p and p in telemetry and status.get(p) == 'up':
+                c_tx = clamp01(1.0 - rel_diff(orig_tx[i], orig_rx[p]))
+                c_rx = clamp01(1.0 - rel_diff(orig_rx[i], orig_tx[p]))
+            else:
+                c_tx = 0.6
+                c_rx = 0.6
+            wtx = max(WEIGHT_FLOOR, 0.5 + 0.5 * c_tx)
+            wrx = max(WEIGHT_FLOOR, 0.5 + 0.5 * c_rx)
+            w_tx[i] = min(WEIGHT_CEIL, wtx)
+            w_rx[i] = min(WEIGHT_CEIL, wrx)
+        # Share protection: amplify weights for dominant shares to move less
+        for r, ifs in router_ifaces.items():
+            ups = [i for i in ifs if status.get(i) == 'up']
+            if not ups:
+                continue
+            sum_tx = sum(max(x_tx[i], 0.0) for i in ups) + ZERO_EPS
+            sum_rx = sum(max(x_rx[i], 0.0) for i in ups) + ZERO_EPS
+            # HHI per direction (for later caps)
+            for i in ups:
+                share_t = max(x_tx[i], 0.0) / sum_tx
+                share_r = max(x_rx[i], 0.0) / sum_rx
+                w_tx[i] = min(WEIGHT_CEIL, w_tx[i] * (1.0 + SHARE_PROTECT * share_t))
+                w_rx[i] = min(WEIGHT_CEIL, w_rx[i] * (1.0 + SHARE_PROTECT * share_r))
+
+    init_weights()
+
+    # Track cap hits for confidence penalties
+    cap_hit_rx: Dict[str, bool] = {i: False for i in telemetry}
+    cap_hit_tx: Dict[str, bool] = {i: False for i in telemetry}
+
+    # Helper: compute router residuals
+    def router_residuals(curr_rx: Dict[str, float], curr_tx: Dict[str, float]) -> Dict[str, float]:
+        res: Dict[str, float] = {}
+        for r, ifs in router_ifaces.items():
+            ups = [i for i in ifs if status.get(i) == 'up']
+            if not ups:
+                res[r] = 0.0
+                continue
+            srx = sum(curr_rx[i] for i in ups)
+            stx = sum(curr_tx[i] for i in ups)
+            denom = max(1.0, srx, stx)
+            res[r] = abs(stx - srx) / denom
+        return res
+
+    # Helper: compute link residuals (max over both directions)
+    def max_link_residual() -> float:
+        m = 0.0
+        for a, b in link_pairs:
+            if status.get(a) != 'up' or status.get(b) != 'up':
+                continue
+            r1 = rel_diff(x_tx[a], x_rx[b])
+            r2 = rel_diff(x_rx[a], x_tx[b])
+            # only consider residuals above tolerance
+            tau1 = adaptive_tau(x_tx[a], x_rx[b])
+            tau2 = adaptive_tau(x_rx[a], x_tx[b])
+            m = max(m, max(max(0.0, r1 - tau1), max(0.0, r2 - tau2)))
+        return m
+
+    # Soft-zero helper for a link
+    def soft_zero_link(a: str, b: str) -> bool:
+        if status.get(a) != 'up' or status.get(b) != 'up':
+            return False
+        if max(x_rx[a], x_tx[a], x_rx[b], x_tx[b]) < SOFT_ZERO_FACTOR * ZERO_THRESH:
+            x_rx[a] = x_tx[a] = 0.0
+            x_rx[b] = x_tx[b] = 0.0
+            return True
+        return False
+
+    # Link projection: weighted averaging on each direction
+    def project_links() -> None:
+        for a, b in link_pairs:
+            a_up = (status.get(a) == 'up')
+            b_up = (status.get(b) == 'up')
+            if not a_up or not b_up:
+                # Down link: force zeros already in status handling later
+                continue
+
+            # Near-zero stabilization
+            if soft_zero_link(a, b):
+                continue
+
+            # a.tx vs b.rx
+            v1, v2 = x_tx[a], x_rx[b]
+            tau1 = adaptive_tau(v1, v2)
+            w1, w2 = max(WEIGHT_FLOOR, w_tx.get(a, 1.0)), max(WEIGHT_FLOOR, w_rx.get(b, 1.0))
+            # Weighted projection (exact). Keep even within tau to reduce noise symmetrically.
+            v = (w1 * v1 + w2 * v2) / max(ZERO_EPS, w1 + w2)
+            x_tx[a] = max(0.0, v)
+            x_rx[b] = max(0.0, v)
+
+            # a.rx vs b.tx
+            v1b, v2b = x_rx[a], x_tx[b]
+            tau2 = adaptive_tau(v1b, v2b)
+            w1b, w2b = max(WEIGHT_FLOOR, w_rx.get(a, 1.0)), max(WEIGHT_FLOOR, w_tx.get(b, 1.0))
+            vb = (w1b * v1b + w2b * v2b) / max(ZERO_EPS, w1b + w2b)
+            x_rx[a] = max(0.0, vb)
+            x_tx[b] = max(0.0, vb)
+
+    # Router projection: exact weighted projection with cap saturation (one equality per router)
+    def project_routers() -> None:
+        nonlocal cap_hit_rx, cap_hit_tx
+        for r, ifs in router_ifaces.items():
+            ups = [i for i in ifs if status.get(i) == 'up']
+            if len(ups) == 0:
+                continue
+
+            sum_tx_r = sum(x_tx[i] for i in ups)
+            sum_rx_r = sum(x_rx[i] for i in ups)
+            gap = sum_tx_r - sum_rx_r  # want gap -> 0
+
+            denom = max(1.0, sum_tx_r, sum_rx_r)
+            # Adaptive skip if gap is within tolerance
+            n_active = len(ups)
+            tau_router = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active)) ** 0.5))
+            if abs(gap) / denom <= tau_router:
+                continue
+
+            # Compute shares and HHI per direction for caps
+            sum_tx_pos = sum(max(x_tx[i], 0.0) for i in ups) + ZERO_EPS
+            sum_rx_pos = sum(max(x_rx[i], 0.0) for i in ups) + ZERO_EPS
+            shares_tx = {i: max(x_tx[i], 0.0) / sum_tx_pos for i in ups}
+            shares_rx = {i: max(x_rx[i], 0.0) / sum_rx_pos for i in ups}
+            hhi_tx = sum(shares_tx[i] ** 2 for i in ups)
+            hhi_rx = sum(shares_rx[i] ** 2 for i in ups)
+            hhi = 0.5 * (hhi_tx + hhi_rx)
+
+            # Cap per-interface relative change (share/HHI aware)
+            cap_tx_abs: Dict[str, float] = {}
+            cap_rx_abs: Dict[str, float] = {}
+            for i in ups:
+                share_t = shares_tx[i]
+                share_r = shares_rx[i]
+                # stiffer when HHI and share are high
+                cap_rel_t = CAP_REL_BASE * (1.0 - 0.5 * math.sqrt(max(0.0, hhi))) * (1.0 - 0.4 * share_t)
+                cap_rel_r = CAP_REL_BASE * (1.0 - 0.5 * math.sqrt(max(0.0, hhi))) * (1.0 - 0.4 * share_r)
+                cap_rel_t = min(CAP_REL_MAX, max(CAP_REL_MIN, cap_rel_t))
+                cap_rel_r = min(CAP_REL_MAX, max(CAP_REL_MIN, cap_rel_r))
+                cap_tx_abs[i] = cap_rel_t * max(1.0, x_tx[i])
+                cap_rx_abs[i] = cap_rel_r * max(1.0, x_rx[i])
+
+            # Active sets for saturation algorithm
+            U_tx = set(ups)
+            U_rx = set(ups)
+            fixed_tx: Dict[str, float] = {i: 0.0 for i in ups}
+            fixed_rx: Dict[str, float] = {i: 0.0 for i in ups}
+
+            # Precompute inverse weights to avoid division by zero
+            inv_w_tx = {i: 1.0 / max(ZERO_EPS, w_tx.get(i, 1.0)) for i in ups}
+            inv_w_rx = {i: 1.0 / max(ZERO_EPS, w_rx.get(i, 1.0)) for i in ups}
+
+            # Saturation loop
+            remaining = 10 * len(ups) + 10  # safety bound
+            while remaining > 0:
+                remaining -= 1
+                sum_inv_tx = sum(inv_w_tx[i] for i in U_tx) if U_tx else 0.0
+                sum_inv_rx = sum(inv_w_rx[i] for i in U_rx) if U_rx else 0.0
+                S = sum_inv_tx + sum_inv_rx
+                S_fixed = sum(fixed_tx[i] for i in ups) - sum(fixed_rx[i] for i in ups)
+                # If no degrees of freedom remain, break
+                if S <= ZERO_EPS:
+                    break
+                # Compute Lagrange multiplier to close remaining gap (subject to fixed contributions)
+                lam = 2.0 * (gap + S_fixed) / S
+                # Candidate deltas
+                violate = False
+                cand_tx: Dict[str, float] = {}
+                cand_rx: Dict[str, float] = {}
+                for i in list(U_tx):
+                    dti = -lam * 0.5 * inv_w_tx[i]
+                    # Saturate check
+                    if abs(dti) > cap_tx_abs[i] + 1e-12:
+                        # Fix at cap
+                        dti_clip = cap_tx_abs[i] if dti > 0 else -cap_tx_abs[i]
+                        fixed_tx[i] += dti_clip
+                        U_tx.remove(i)
+                        violate = True
+                    else:
+                        cand_tx[i] = dti
+                for i in list(U_rx):
+                    dri = +lam * 0.5 * inv_w_rx[i]
+                    if abs(dri) > cap_rx_abs[i] + 1e-12:
+                        dri_clip = cap_rx_abs[i] if dri > 0 else -cap_rx_abs[i]
+                        fixed_rx[i] += dri_clip
+                        U_rx.remove(i)
+                        violate = True
+                    else:
+                        cand_rx[i] = dri
+                if not violate:
+                    # Apply candidates and fixed deltas
+                    for i, dti in cand_tx.items():
+                        x_tx[i] = max(0.0, x_tx[i] + dti)
+                        if abs(dti) >= cap_tx_abs[i] - 1e-12:
+                            cap_hit_tx[i] = True
+                    for i, dri in cand_rx.items():
+                        x_rx[i] = max(0.0, x_rx[i] + dri)
+                        if abs(dri) >= cap_rx_abs[i] - 1e-12:
+                            cap_hit_rx[i] = True
+                    # Apply fixed contributions to those already clipped (no-op here, as we accumulated in fixed arrays)
+                    for i in fixed_tx:
+                        if i not in cand_tx and abs(fixed_tx[i]) > 0.0 and i not in U_tx:
+                            # Already accounted in fixed set; apply at end
+                            pass
+                    for i in fixed_rx:
+                        if i not in cand_rx and abs(fixed_rx[i]) > 0.0 and i not in U_rx:
+                            pass
+                    # Now apply fixed deltas
+                    for i in ups:
+                        if i not in cand_tx and i not in U_tx and abs(fixed_tx[i]) > 0.0:
+                            x_tx[i] = max(0.0, x_tx[i] + fixed_tx[i])
+                            cap_hit_tx[i] = True
+                            fixed_tx[i] = 0.0
+                        if i not in cand_rx and i not in U_rx and abs(fixed_rx[i]) > 0.0:
+                            x_rx[i] = max(0.0, x_rx[i] + fixed_rx[i])
+                            cap_hit_rx[i] = True
+                            fixed_rx[i] = 0.0
+                    break  # finished projection for this router
+
+            # If we exit due to no degrees left, we've applied partial closure only.
+            # Non-negativity will be enforced below.
+
+    # Enforce status down -> zero (hard constraint)
+    def enforce_status_zero() -> None:
+        for i in telemetry:
+            if status.get(i) != 'up':
+                x_rx[i] = 0.0
+                x_tx[i] = 0.0
+
+    # Non-negativity clamp (safety)
+    def clamp_nonneg() -> None:
+        for i in telemetry:
+            x_rx[i] = max(0.0, x_rx[i])
+            x_tx[i] = max(0.0, x_tx[i])
+
+    # Iterative POCS loop
+    for it in range(MAX_ITERS):
+        # Link projection
+        project_links()
+        # Router projection
+        project_routers()
+        # Status and non-negativity
+        enforce_status_zero()
+        clamp_nonneg()
+
+        # Optional: refresh weights once midway based on current residuals to focus on remaining mismatches
+        if it == (MAX_ITERS // 2):
+            # Update weights using current link mismatches; keep share protection
+            for i in telemetry:
+                if status.get(i) != 'up':
+                    w_rx[i] = WEIGHT_CEIL
+                    w_tx[i] = WEIGHT_CEIL
+                    continue
+                p = peer_of.get(i)
+                if p and p in telemetry and status.get(p) == 'up':
+                    c_tx = clamp01(1.0 - rel_diff(x_tx[i], x_rx[p]))
+                    c_rx = clamp01(1.0 - rel_diff(x_rx[i], x_tx[p]))
+                else:
+                    c_tx = 0.6
+                    c_rx = 0.6
+                w_tx[i] = min(WEIGHT_CEIL, max(WEIGHT_FLOOR, 0.5 + 0.5 * c_tx))
+                w_rx[i] = min(WEIGHT_CEIL, max(WEIGHT_FLOOR, 0.5 + 0.5 * c_rx))
+            # Re-apply share protection
+            for r, ifs in router_ifaces.items():
+                ups = [i for i in ifs if status.get(i) == 'up']
+                if not ups:
+                    continue
+                sum_tx = sum(max(x_tx[i], 0.0) for i in ups) + ZERO_EPS
+                sum_rx = sum(max(x_rx[i], 0.0) for i in ups) + ZERO_EPS
+                for i in ups:
+                    share_t = max(x_tx[i], 0.0) / sum_tx
+                    share_r = max(x_rx[i], 0.0) / sum_rx
+                    w_tx[i] = min(WEIGHT_CEIL, w_tx[i] * (1.0 + SHARE_PROTECT * share_t))
+                    w_rx[i] = min(WEIGHT_CEIL, w_rx[i] * (1.0 + SHARE_PROTECT * share_r))
+
+        # Early stopping if residuals small
+        rr = router_residuals(x_rx, x_tx)
+        max_rtr = max(rr.values()) if rr else 0.0
+        max_link = max_link_residual()
+        if max_link <= EARLY_STOP_LINK and max_rtr <= EARLY_STOP_ROUTER:
+            break
+
+    # Final soft-zero stabilization on near-zero links
     for a, b in link_pairs:
-        a_up = (status.get(a) == 'up')
-        b_up = (status.get(b) == 'up')
-        a_rx, a_tx = orig_rx[a], orig_tx[a]
-        b_rx, b_tx = orig_rx[b], orig_tx[b]
-
-        # If either side is down: force both to zero on the link with high confidence
-        if not a_up or not b_up:
-            for i in (a, b):
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.85)
-                conf_tx[i] = max(conf_tx[i], 0.85)
-            continue
-
-        # Soft-zero stabilization for near-zero links
-        if max(a_rx, a_tx, b_rx, b_tx) < 2.0 * ZERO_THRESH:
-            for i in (a, b):
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.95)
-                conf_tx[i] = max(conf_tx[i], 0.95)
-            continue
-
-        # Direction 1: a.tx vs b.rx
-        d1 = rel_diff(a_tx, b_rx)
-        tau1 = adaptive_tau(a_tx, b_rx)
-        if d1 <= tau1:
-            v1 = 0.5 * (a_tx + b_rx)
-            hardened_tx[a] = v1
-            hardened_rx[b] = v1
-            c1 = clamp01(0.9 + 0.1 * (1.0 - d1 / max(tau1, 1e-12)))
-            conf_tx[a] = max(conf_tx[a], c1)
-            conf_rx[b] = max(conf_rx[b], c1)
-        else:
-            # Choose the more reliable of the two readings (farther from zero), rely on redundancy
-            choice = b_rx if abs(b_rx) >= abs(a_tx) else a_tx
-            hardened_tx[a] = max(0.0, choice)
-            hardened_rx[b] = max(0.0, choice)
-            c1 = clamp01(1.0 - d1)
-            conf_tx[a] = max(conf_tx[a], c1)
-            conf_rx[b] = max(conf_rx[b], c1)
-
-        # Direction 2: a.rx vs b.tx
-        d2 = rel_diff(a_rx, b_tx)
-        tau2 = adaptive_tau(a_rx, b_tx)
-        if d2 <= tau2:
-            v2 = 0.5 * (a_rx + b_tx)
-            hardened_rx[a] = v2
-            hardened_tx[b] = v2
-            c2 = clamp01(0.9 + 0.1 * (1.0 - d2 / max(tau2, 1e-12)))
-            conf_rx[a] = max(conf_rx[a], c2)
-            conf_tx[b] = max(conf_tx[b], c2)
-        else:
-            choice = b_tx if abs(b_tx) >= abs(a_rx) else a_rx
-            hardened_rx[a] = max(0.0, choice)
-            hardened_tx[b] = max(0.0, choice)
-            c2 = clamp01(1.0 - d2)
-            conf_rx[a] = max(conf_rx[a], c2)
-            conf_tx[b] = max(conf_tx[b], c2)
-
-    # Unpaired interfaces: trust local with moderate confidence; zero if down
-    in_pairs = {x for pair in link_pairs for x in pair}
-    for i in telemetry:
-        if i not in in_pairs:
-            if status.get(i) != 'up':
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.85)
-                conf_tx[i] = max(conf_tx[i], 0.85)
-            else:
-                hardened_rx[i] = max(0.0, orig_rx[i])
-                hardened_tx[i] = max(0.0, orig_tx[i])
-                conf_rx[i] = max(conf_rx[i], 0.6)
-                conf_tx[i] = max(conf_tx[i], 0.6)
-
-    # Stage 2: Router flow conservation with targeted, bundle-aware corrections
-    for r, ifs in router_ifaces.items():
-        if not ifs:
-            continue
-        up_ifs = [i for i in ifs if status.get(i) == 'up']
-        if len(up_ifs) < 2:
-            continue
-
-        sum_rx = sum(hardened_rx[i] for i in up_ifs)
-        sum_tx = sum(hardened_tx[i] for i in up_ifs)
-        denom = max(1.0, sum_rx, sum_tx)
-        imbalance = (sum_rx - sum_tx)  # positive means rx > tx
-        rel_gap = abs(imbalance) / denom
-
-        # Adaptive router tolerance based on number of active interfaces
-        n_active = len(up_ifs)
-        tau_router = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active)) ** 0.5))
-        if rel_gap <= tau_router:
-            continue
-
-        # Expected-penalty router-side selection with dominance awareness
-        def side_penalty(side: str) -> float:
-            vals = [(i, (hardened_rx[i] if side == 'rx' else hardened_tx[i]),
-                     clamp01(conf_rx[i] if side == 'rx' else conf_tx[i]))
-                    for i in up_ifs]
-            # weights w_i = (1 - conf_i) * rate_i
-            w = {i: (1.0 - c) * max(v, ZERO_THRESH) for (i, v, c) in vals}
-            total_w = sum(w.values()) or 1.0
-            # Focus subset covering WEIGHT_FOCUS
-            order = sorted(up_ifs, key=lambda x: w[x], reverse=True)
-            focus: List[str] = []
-            acc_w = 0.0
-            for i2 in order:
-                if acc_w / total_w >= WEIGHT_FOCUS:
-                    break
-                focus.append(i2)
-                acc_w += w[i2]
-            if not focus:
-                focus = list(up_ifs)
-                acc_w = total_w
-            # dominance cap in focus
-            cap_per = DOMINANCE_CAP * acc_w
-            eff_w = {i3: min(w[i3], cap_per) for i3 in focus}
-            eff_total = sum(eff_w.values()) or 1.0
-            # HHI for focus
-            hhi = sum((eff_w[i4] / eff_total) ** 2 for i4 in focus)
-
-            # Simulate two-tier scaling using current weights
-            delta = (-imbalance if side == 'rx' else imbalance)
-            # Per spec: k = delta/(0.6·Σ(rate_i·w_i))
-            denom_k = 0.0
-            for i5 in focus:
-                vi = hardened_rx[i5] if side == 'rx' else hardened_tx[i5]
-                denom_k += vi * eff_w[i5]
-            k = 0.0 if denom_k == 0.0 else delta / (0.6 * denom_k)
-            penalty = 0.0
-            for i6 in focus:
-                vi = hardened_rx[i6] if side == 'rx' else hardened_tx[i6]
-                ci = clamp01(conf_rx[i6] if side == 'rx' else conf_tx[i6])
-                # clip_hi(conf_i) = 1.12 for conf < 0.70 else 1.10
-                clip_hi = 1.12 if ci < 0.70 else 1.10
-                scale_sim = 1.0 + 0.6 * k * eff_w[i6]
-                scale_sim = max(0.90, min(clip_hi, scale_sim))
-                penalty += abs(scale_sim - 1.0) + 0.5 * (1.0 - ci)
-            penalty += 0.05 * hhi
-            return penalty
-
-        pen_rx = side_penalty('rx')
-        pen_tx = side_penalty('tx')
-        if pen_rx + 1e-9 < 0.95 * (pen_tx + 1e-9):
-            adjust_side = 'rx'
-        elif pen_tx + 1e-9 < 0.95 * (pen_rx + 1e-9):
-            adjust_side = 'tx'
-        else:
-            # Fallback to lower aggregate confidence
-            avg_rx_conf = sum(conf_rx[i] for i in up_ifs) / len(up_ifs)
-            avg_tx_conf = sum(conf_tx[i] for i in up_ifs) / len(up_ifs)
-            adjust_side = 'rx' if avg_rx_conf < avg_tx_conf else 'tx'
-        total_adjust = (-imbalance if adjust_side == 'rx' else imbalance) * DAMP_ROUTER
-
-        # Build per-interface values and confidences for the chosen side
-        side_vals = {i: (hardened_rx[i] if adjust_side == 'rx' else hardened_tx[i]) for i in up_ifs}
-        side_confs = {i: (conf_rx[i] if adjust_side == 'rx' else conf_tx[i]) for i in up_ifs}
-
-        # Group interfaces into bundles by (local_router, remote_router)
-        bundle_map: Dict[Tuple[Any, Any], List[str]] = {}
-        for i in up_ifs:
-            lr = local_router_of.get(i)
-            rr = remote_router_of.get(i)
-            if not rr:
-                p = peer_of.get(i)
-                if p:
-                    rr = local_router_of.get(p)
-            key = (lr, rr)
-            bundle_map.setdefault(key, []).append(i)
-
-        side_total = sum(side_vals.values())
-        # Identify majority bundles (>=50% of side traffic)
-        majority_bundles = []
-        for key, members in bundle_map.items():
-            s = sum(side_vals[m] for m in members)
-            if side_total > ZERO_EPS and s >= 0.5 * side_total:
-                majority_bundles.append((key, members, s))
-
-        # Build weights for distribution: w_i = (1 - conf) * max(val, ZERO_THRESH)
-        weights = {i: (1.0 - clamp01(side_confs[i])) * max(side_vals[i], ZERO_THRESH) + 1e-9 for i in up_ifs}
-        total_w = sum(weights.values())
-        if total_w <= 0:
-            weights = {i: 1.0 for i in up_ifs}
-            total_w = float(len(up_ifs))
-
-        # Focus adjustments on the lowest-confidence subset covering WEIGHT_FOCUS of total weight
-        sorted_ifs = sorted(up_ifs, key=lambda x: weights[x], reverse=True)
-        focus_set = []
-        acc = 0.0
-        for i in sorted_ifs:
-            if acc / max(total_w, 1e-12) >= WEIGHT_FOCUS:
-                break
-            focus_set.append(i)
-            acc += weights[i]
-        # Fallback: if empty due to zeros, use all
-        if not focus_set:
-            focus_set = list(up_ifs)
-            acc = total_w
-        focus_total_w = max(acc, 1e-9)
-
-        # Dominance-aware HHI on focus
-        sum_w_focus = sum(weights[i] for i in focus_set) or 1.0
-        shares = [(weights[i] / sum_w_focus) for i in focus_set]
-        hhi_focus = sum(s * s for s in shares)
-
-        # Helper: adaptive per-interface clip ceilings
-        def clip_hi_for_conf(ci: float) -> float:
-            if ci < 0.50:
-                return 1.15
-            if ci < 0.70:
-                # 1 + min(0.15, 0.10 + 0.05*(0.70 - ci))
-                return 1.0 + min(0.15, 0.10 + 0.05 * max(0.0, 0.70 - ci))
-            return 1.10
-
-        # Absolute dominance-aware cap for per-interface move
-        def abs_cap_for_delta(delta_total: float) -> float:
-            # (0.5 − 0.2·sqrt(HHI))·|delta|
-            return max(0.0, (0.5 - 0.2 * math.sqrt(max(0.0, hhi_focus)))) * abs(delta_total)
-
-        # Apply bundle-aware scaling if there is a majority bundle; else per-interface adjustments
-        if majority_bundles:
-            # Compute per-bundle weight from focused members only
-            bundle_weights: Dict[Tuple[Any, Any], float] = {}
-            bundle_members_focused: Dict[Tuple[Any, Any], List[str]] = {}
-            for key, members, _ in majority_bundles:
-                focused_members = [m for m in members if m in focus_set]
-                if not focused_members:
-                    continue
-                bundle_members_focused[key] = focused_members
-                bundle_weights[key] = sum(weights[m] for m in focused_members)
-
-            # First, scale majority bundles with a shared factor per bundle on focused members only
-            for key, members, _ in majority_bundles:
-                focused_members = bundle_members_focused.get(key, [])
-                if not focused_members:
-                    continue
-                w_g = bundle_weights.get(key, 0.0)
-                if w_g <= 0.0:
-                    continue
-                # Portion of total adjust to this bundle proportional to its focused weight
-                adj_g = total_adjust * (w_g / focus_total_w)
-                s_sum_focus = sum(side_vals[m] for m in focused_members)
-                if s_sum_focus <= ZERO_EPS:
-                    continue
-                target_sum = max(0.0, s_sum_focus + adj_g)
-                scale_g = target_sum / s_sum_focus
-                # Clip group scale to [1-BUNDLE_CLIP, 1+BUNDLE_CLIP]
-                clipped = False
-                if scale_g > 1.0 + BUNDLE_CLIP:
-                    scale_g = 1.0 + BUNDLE_CLIP
-                    clipped = True
-                elif scale_g < 1.0 - BUNDLE_CLIP:
-                    scale_g = 1.0 - BUNDLE_CLIP
-                    clipped = True
-                for m in focused_members:
-                    old = side_vals[m]
-                    new = max(0.0, scale_g * old)
-                    if adjust_side == 'rx':
-                        prev = hardened_rx[m]
-                        if prev > ZERO_EPS:
-                            scaled_rx_factor[m] *= (new / prev)
-                        hardened_rx[m] = new
-                        relc = abs(new - old) / max(1.0, abs(old))
-                        conf_rx[m] = clamp01(conf_rx[m] * (1.0 - 0.6 * relc))
-                        if clipped:
-                            clip_hit_rx[m] = True
-                    else:
-                        prev = hardened_tx[m]
-                        if prev > ZERO_EPS:
-                            scaled_tx_factor[m] *= (new / prev)
-                        hardened_tx[m] = new
-                        relc = abs(new - old) / max(1.0, abs(old))
-                        conf_tx[m] = clamp01(conf_tx[m] * (1.0 - 0.6 * relc))
-                        if clipped:
-                            clip_hit_tx[m] = True
-
-            # Then, adjust remaining non-majority interfaces individually using focused leftover weights
-            all_major_members = [m for _, members, _ in majority_bundles for m in members]
-            non_majority_all = [i for i in up_ifs if i not in all_major_members]
-            non_majority = [i for i in non_majority_all if i in focus_set]
-            nm_total_w = sum(weights[i] for i in non_majority)
-            if nm_total_w > 0:
-                # Dominance cap on per-interface share within this subset
-                cap_per = DOMINANCE_CAP * nm_total_w
-                eff_weights = {i: min(weights[i], cap_per) for i in non_majority}
-                eff_total_w = max(1e-9, sum(eff_weights.values()))
-                adj_nm = total_adjust * (nm_total_w / focus_total_w)
-                cap_abs_global = abs_cap_for_delta(adj_nm)
-                for i in non_majority:
-                    v_old = side_vals[i]
-                    ci = clamp01(side_confs[i])
-                    w_i = eff_weights[i] / eff_total_w
-                    adj_i_raw = adj_nm * w_i
-                    # Adaptive clip ceiling per-interface
-                    clip_hi = clip_hi_for_conf(ci)
-                    # decrease clip ceiling when dominated by few links
-                    clip_hi = 1.0 + (clip_hi - 1.0) * (1.0 - math.sqrt(max(0.0, hhi_focus)))
-                    cap_rel = (clip_hi - 1.0) * v_old
-                    adj_i = min(max(adj_i_raw, -cap_rel), cap_rel)
-                    # micro-tier absolute cap when conf < 0.50
-                    if ci < 0.50:
-                        adj_i = max(-0.35 * abs(adj_nm), min(0.35 * abs(adj_nm), adj_i))
-                    # dominance-aware absolute cap
-                    adj_i = max(-cap_abs_global, min(cap_abs_global, adj_i))
-                    v_new = max(0.0, v_old + adj_i)
-                    if adjust_side == 'rx':
-                        prev = hardened_rx[i]
-                        if prev > ZERO_EPS:
-                            scl = (v_new / prev)
-                            scaled_rx_factor[i] *= scl
-                            if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                                clip_hit_rx[i] = True
-                        hardened_rx[i] = v_new
-                        relc = abs(adj_i) / max(1.0, abs(v_old))
-                        conf_rx[i] = clamp01(conf_rx[i] * (1.0 - 0.6 * relc))
-                    else:
-                        prev = hardened_tx[i]
-                        if prev > ZERO_EPS:
-                            scl = (v_new / prev)
-                            scaled_tx_factor[i] *= scl
-                            if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                                clip_hit_tx[i] = True
-                        hardened_tx[i] = v_new
-                        relc = abs(adj_i) / max(1.0, abs(v_old))
-                        conf_tx[i] = clamp01(conf_tx[i] * (1.0 - 0.6 * relc))
-        else:
-            # No dominant bundle: targeted per-interface corrections only over focus_set
-            cap_per = DOMINANCE_CAP * focus_total_w
-            eff_weights = {i: min(weights[i], cap_per) for i in focus_set}
-            eff_total_w = max(1e-9, sum(eff_weights.values()))
-            cap_abs_global = abs_cap_for_delta(total_adjust)
-            for i in focus_set:
-                v_old = side_vals[i]
-                ci = clamp01(side_confs[i])
-                w_i = eff_weights[i] / eff_total_w
-                adj_i_raw = total_adjust * w_i
-                clip_hi = clip_hi_for_conf(ci)
-                clip_hi = 1.0 + (clip_hi - 1.0) * (1.0 - math.sqrt(max(0.0, hhi_focus)))
-                cap_rel = (clip_hi - 1.0) * v_old
-                adj_i = min(max(adj_i_raw, -cap_rel), cap_rel)
-                if ci < 0.50:
-                    adj_i = max(-0.35 * abs(total_adjust), min(0.35 * abs(total_adjust), adj_i))
-                adj_i = max(-cap_abs_global, min(cap_abs_global, adj_i))
-                v_new = max(0.0, v_old + adj_i)
-                if adjust_side == 'rx':
-                    prev = hardened_rx[i]
-                    if prev > ZERO_EPS:
-                        scl = (v_new / prev)
-                        scaled_rx_factor[i] *= scl
-                        if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                            clip_hit_rx[i] = True
-                    hardened_rx[i] = v_new
-                    relc = abs(adj_i) / max(1.0, abs(v_old))
-                    conf_rx[i] = clamp01(conf_rx[i] * (1.0 - 0.6 * relc))
-                else:
-                    prev = hardened_tx[i]
-                    if prev > ZERO_EPS:
-                        scl = (v_new / prev)
-                        scaled_tx_factor[i] *= scl
-                        if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                            clip_hit_tx[i] = True
-                    hardened_tx[i] = v_new
-                    relc = abs(adj_i) / max(1.0, abs(v_old))
-                    conf_tx[i] = clamp01(conf_tx[i] * (1.0 - 0.6 * relc))
-
-    # Stage 2.5: Post-router soft-zero stabilization and residual computation for re-sync attenuation
-    router_residual_mid: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        ups = [i for i in ifs if status.get(i) == 'up']
-        if not ups:
-            router_residual_mid[r] = 0.0
-            continue
-        srx = sum(hardened_rx[i] for i in ups)
-        stx = sum(hardened_tx[i] for i in ups)
-        denomr = max(1.0, srx, stx)
-        router_residual_mid[r] = abs(srx - stx) / denomr
-
-    # Soft-zero stabilization: if link tiny and adjacent routers close to balanced, snap to zero
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        if max(hardened_rx[a], hardened_tx[a], hardened_rx[b], hardened_tx[b]) < 2.0 * ZERO_THRESH:
-            ra = local_router_of.get(a)
-            rb = local_router_of.get(b)
-            n_active_a = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-            n_active_b = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-            tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active_a)) ** 0.5))
-            tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active_b)) ** 0.5))
-            if router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb:
-                hardened_rx[a] = hardened_tx[a] = hardened_rx[b] = hardened_tx[b] = 0.0
-                conf_rx[a] = max(conf_rx[a], 0.95)
-                conf_tx[a] = max(conf_tx[a], 0.95)
-                conf_rx[b] = max(conf_rx[b], 0.95)
-                conf_tx[b] = max(conf_tx[b], 0.95)
-
-    # Stage 3: Confidence-gap-proportional re-sync with scaling guard and router-imbalance attenuation
-    def nudge_toward_mean(val_lo: float, val_hi: float, frac: float) -> float:
-        target = 0.5 * (val_lo + val_hi)
-        return val_lo + frac * (target - val_lo)
-
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-
-        # Attenuation from local router imbalances
-        ra = local_router_of.get(a)
-        rb = local_router_of.get(b)
-        att = clamp01(1.0 - max(router_residual_mid.get(ra, 0.0), router_residual_mid.get(rb, 0.0)))
-
-        # Direction 1: a.tx vs b.rx
-        a_tx, b_rx = hardened_tx[a], hardened_rx[b]
-        if max(a_tx, b_rx) > ZERO_EPS:
-            d1 = rel_diff(a_tx, b_rx)
-            tau1 = adaptive_tau(a_tx, b_rx)
-            if d1 > tau1:
-                ca, cb = conf_tx.get(a, 0.6), conf_rx.get(b, 0.6)
-                gap_norm = clamp01((d1 - tau1) / max(tau1, 1e-9))
-                # Saturating mismatch-proportional gain
-                f_base = 0.4 * (1.0 / (1.0 + math.exp(-5.0 * (gap_norm - 0.5))))
-                f_base *= att
-                moved = False
-                # Prefer moving the higher-confidence peer whose target dir hasn't been strongly scaled
-                if ca >= cb and abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = b_rx
-                        target = a_tx
-                        step = nudge_toward_mean(old, target, f)
-                        # cap absolute move per direction
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_rx[b] = new
-                        relc = rel_diff(new, old)
-                        conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.3 * relc))
-                        moved = True
-                elif cb > ca and abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = a_tx
-                        target = b_rx
-                        step = nudge_toward_mean(old, target, f)
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_tx[a] = new
-                        relc = rel_diff(new, old)
-                        conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.3 * relc))
-                        moved = True
-                # bilateral micro-step when both sides low-confidence and routers within tolerance
-                if not moved and ca < 0.70 and cb < 0.70:
-                    na = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-                    nb = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-                    tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, na)) ** 0.5))
-                    tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, nb)) ** 0.5))
-                    if router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb:
-                        f_bi = min(0.10, 0.5 * gap_norm) * att
-                        if f_bi > 0.0:
-                            old_a = a_tx; old_b = b_rx
-                            tgt = 0.5 * (old_a + old_b)
-                            cap_a = RESYNC_PER_DIR_CAP * max(old_a, tgt, 1.0)
-                            cap_b = RESYNC_PER_DIR_CAP * max(old_b, tgt, 1.0)
-                            new_a = old_a + clamp01(f_bi) * (tgt - old_a)
-                            new_b = old_b + clamp01(f_bi) * (tgt - old_b)
-                            new_a = max(0.0, min(old_a + cap_a, max(old_a - cap_a, new_a)))
-                            new_b = max(0.0, min(old_b + cap_b, max(old_b - cap_b, new_b)))
-                            hardened_tx[a] = new_a
-                            hardened_rx[b] = new_b
-                            conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.2 * rel_diff(new_a, old_a)))
-                            conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.2 * rel_diff(new_b, old_b)))
-
-        # Direction 2: a.rx vs b.tx
-        a_rx, b_tx = hardened_rx[a], hardened_tx[b]
-        if max(a_rx, b_tx) > ZERO_EPS:
-            d2 = rel_diff(a_rx, b_tx)
-            tau2 = adaptive_tau(a_rx, b_tx)
-            if d2 > tau2:
-                ca, cb = conf_rx.get(a, 0.6), conf_tx.get(b, 0.6)
-                gap_norm = clamp01((d2 - tau2) / max(tau2, 1e-9))
-                f_base = 0.4 * (1.0 / (1.0 + math.exp(-5.0 * (gap_norm - 0.5))))
-                f_base *= clamp01(1.0 - max(router_residual_mid.get(ra, 0.0), router_residual_mid.get(rb, 0.0)))
-                moved = False
-                if ca >= cb and abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = b_tx
-                        target = a_rx
-                        step = nudge_toward_mean(old, target, f)
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_tx[b] = new
-                        relc = rel_diff(new, old)
-                        conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.3 * relc))
-                        moved = True
-                elif cb > ca and abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = a_rx
-                        target = b_tx
-                        step = nudge_toward_mean(old, target, f)
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_rx[a] = new
-                        relc = rel_diff(new, old)
-                        conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.3 * relc))
-                        moved = True
-                if not moved and ca < 0.70 and cb < 0.70:
-                    na = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-                    nb = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-                    tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, na)) ** 0.5))
-                    tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, nb)) ** 0.5))
-                    if router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb:
-                        f_bi = min(0.10, 0.5 * gap_norm) * clamp01(1.0 - max(router_residual_mid.get(ra, 0.0), router_residual_mid.get(rb, 0.0)))
-                        if f_bi > 0.0:
-                            old_a = a_rx; old_b = b_tx
-                            tgt = 0.5 * (old_a + old_b)
-                            cap_a = RESYNC_PER_DIR_CAP * max(old_a, tgt, 1.0)
-                            cap_b = RESYNC_PER_DIR_CAP * max(old_b, tgt, 1.0)
-                            new_a = old_a + clamp01(f_bi) * (tgt - old_a)
-                            new_b = old_b + clamp01(f_bi) * (tgt - old_b)
-                            new_a = max(0.0, min(old_a + cap_a, max(old_a - cap_a, new_a)))
-                            new_b = max(0.0, min(old_b + cap_b, max(old_b - cap_b, new_b)))
-                            hardened_rx[a] = new_a
-                            hardened_tx[b] = new_b
-                            conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.2 * rel_diff(new_a, old_a)))
-                            conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.2 * rel_diff(new_b, old_b)))
-
-    # Stage 3.6: Two-pass, saturating micro re-sync for stubborn residuals
-    # Only when both adjacent routers are within tolerance; adjust lower-confidence side,
-    # skip any interface flagged strong_scaled or clip-hit in Stage 2, and cap per-move to ±1% of local ref.
-    def routers_balanced(i_a: str, i_b: str) -> bool:
-        ra = local_router_of.get(i_a)
-        rb = local_router_of.get(i_b)
-        na = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-        nb = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-        tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, na)) ** 0.5))
-        tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, nb)) ** 0.5))
-        return router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb
-
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        if not routers_balanced(a, b):
-            continue
-
-        # Direction 1: a.tx vs b.rx
-        a_tx, b_rx = hardened_tx[a], hardened_rx[b]
-        if max(a_tx, b_rx) > ZERO_EPS:
-            d1 = rel_diff(a_tx, b_rx)
-            tau1 = adaptive_tau(a_tx, b_rx)
-            if d1 > 1.5 * tau1:
-                ca, cb = conf_tx.get(a, 0.6), conf_rx.get(b, 0.6)
-                # choose lower-confidence side that didn't hit clip/strong scaling
-                can_move_b = (not clip_hit_rx.get(b, False)) and (abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                can_move_a = (not clip_hit_tx.get(a, False)) and (abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                move_b = (cb <= ca) and can_move_b
-                move_a = (ca < cb) and can_move_a
-                # fallback: if preferred side blocked, try the other if allowed
-                if not move_b and not move_a:
-                    move_b = can_move_b
-                    move_a = (not move_b) and can_move_a
-                gap_norm = clamp01((d1 - tau1) / max(tau1, 1e-9))
-                f2 = RESYNC2_GAIN * min(0.20, gap_norm)
-                if move_b and f2 > 0.0:
-                    old = b_rx
-                    target = a_tx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_rx[b] = new
-                    # modest confidence attenuation
-                    conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.15 * rel_diff(new, old)))
-                elif move_a and f2 > 0.0:
-                    old = a_tx
-                    target = b_rx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_tx[a] = new
-                    conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.15 * rel_diff(new, old)))
-
-        # Direction 2: a.rx vs b.tx
-        a_rx, b_tx = hardened_rx[a], hardened_tx[b]
-        if max(a_rx, b_tx) > ZERO_EPS:
-            d2 = rel_diff(a_rx, b_tx)
-            tau2 = adaptive_tau(a_rx, b_tx)
-            if d2 > 1.5 * tau2:
-                ca, cb = conf_rx.get(a, 0.6), conf_tx.get(b, 0.6)
-                can_move_b = (not clip_hit_tx.get(b, False)) and (abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                can_move_a = (not clip_hit_rx.get(a, False)) and (abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                move_b = (cb <= ca) and can_move_b
-                move_a = (ca < cb) and can_move_a
-                if not move_b and not move_a:
-                    move_b = can_move_b
-                    move_a = (not move_b) and can_move_a
-                gap_norm = clamp01((d2 - tau2) / max(tau2, 1e-9))
-                f2 = RESYNC2_GAIN * min(0.20, gap_norm)
-                if move_b and f2 > 0.0:
-                    old = b_tx
-                    target = a_rx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_tx[b] = new
-                    conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.15 * rel_diff(new, old)))
-                elif move_a and f2 > 0.0:
-                    old = a_rx
-                    target = b_tx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_rx[a] = new
-                    conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.15 * rel_diff(new, old)))
-
-    # Stage 3.8: Dispersion-aware bundle finishing with per-router zero-sum enforcement
-    # Build direction-aware bundles: group by (local_router, remote_router)
-    dir1_groups: Dict[Tuple[Any, Any], List[Tuple[str, str]]] = {}
-    dir2_groups: Dict[Tuple[Any, Any], List[Tuple[str, str]]] = {}
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        ra = local_router_of.get(a)
-        rb = local_router_of.get(b)
-        dir1_groups.setdefault((ra, rb), []).append((a, b))   # a.tx vs b.rx
-        dir2_groups.setdefault((rb, ra), []).append((b, a))   # b.tx vs a.rx
-
-    def huber_weight(e_vals: List[float]) -> List[float]:
-        if not e_vals:
-            return []
-        med = median(e_vals)
-        mad = median([abs(x - med) for x in e_vals]) + 1e-12
-        k = 1.5 * mad
-        w = []
-        for e in e_vals:
-            ae = abs(e - med)
-            if ae <= k:
-                w.append(1.0)
-            else:
-                w.append(k / ae)
-        return w
-
-    def bundle_finish(groups: Dict[Tuple[Any, Any], List[Tuple[str, str]]]) -> None:
-        for (ra, rb), items in groups.items():
-            usable_idx = []
-            e_vals: List[float] = []
-            rels: List[float] = []
-            rates: List[float] = []
-            for idx, (x, y) in enumerate(items):
-                if status.get(x) != 'up' or status.get(y) != 'up':
-                    continue
-                vtx = hardened_tx.get(x, 0.0)
-                vrx = hardened_rx.get(y, 0.0)
-                if max(vtx, vrx) < ZERO_THRESH:
-                    continue
-                e = vtx - vrx
-                usable_idx.append(idx)
-                e_vals.append(e)
-                rels.append(rel_diff(vtx, vrx))
-                rates.append(max(vtx, vrx))
-            m = len(usable_idx)
-            if m < 2:
-                continue
-            # Robust center
-            e_med = median(e_vals)
-            # Gamma scaled by dispersion
-            rel_med = median(rels)
-            tau = TAU_H_BASE
-            if rel_med <= ZERO_EPS:
-                continue
-            gamma = min(FINISH_GAMMA_MAX, 0.5 * tau / max(rel_med, 1e-9))
-            # Huber weights
-            w_h = huber_weight(e_vals)
-            # Per-link clipping factor
-            c_clip = FINISH_C_LOW + (FINISH_C_HIGH - FINISH_C_LOW) * clamp01((m - 2) / 6.0)
-
-            # Compute deltas (zero-sum will be enforced per-router)
-            deltas = []
-            keys = []
-            for j, idx in enumerate(usable_idx):
-                a, b = items[idx]
-                rate = rates[j]
-                delta = -gamma * (e_vals[j] - e_med) * w_h[j]
-                cap = c_clip * max(rate, 1.0)
-                delta = max(-cap, min(cap, delta))
-                deltas.append(delta)
-                keys.append((a, b))
-            # Enforce per-router zero-sum: subtract mean delta per local router in this direction
-            # Compute per-router means (here only ra is local router for all in this group)
-            mean_delta = sum(deltas) / len(deltas)
-            deltas = [d - mean_delta for d in deltas]
-
-            # Apply
-            for (a, b), delta in zip(keys, deltas):
-                if abs(delta) <= ZERO_EPS:
-                    continue
-                prev_tx = hardened_tx[a]
-                prev_rx = hardened_rx[b]
-                new_tx = max(0.0, prev_tx + delta)
-                new_rx = max(0.0, prev_rx - delta)
-                if prev_tx > ZERO_EPS:
-                    scaled_tx_factor[a] *= (new_tx / prev_tx)
-                if prev_rx > ZERO_EPS:
-                    scaled_rx_factor[b] *= (new_rx / prev_rx)
-                hardened_tx[a] = new_tx
-                hardened_rx[b] = new_rx
-                # Light confidence adjustment
-                relc_tx = rel_diff(new_tx, prev_tx)
-                relc_rx = rel_diff(new_rx, prev_rx)
-                conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.2 * relc_tx))
-                conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.2 * relc_rx))
-
-    bundle_finish(dir1_groups)
-    bundle_finish(dir2_groups)
-
-    # Enforce status down => zero as a final safety
-    for i in telemetry:
-        if status.get(i) != 'up':
-            hardened_rx[i] = 0.0
-            hardened_tx[i] = 0.0
-            conf_rx[i] = max(conf_rx[i], 0.85)
-            conf_tx[i] = max(conf_tx[i], 0.85)
-
-    # Compute router residuals after all adjustments (for confidence calibration)
-    router_residual: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        up_ifs = [i for i in ifs if status.get(i) == 'up']
-        if not up_ifs:
-            router_residual[r] = 0.0
-            continue
-        sum_rx = sum(hardened_rx[i] for i in up_ifs)
-        sum_tx = sum(hardened_tx[i] for i in up_ifs)
-        denom = max(1.0, sum_rx, sum_tx)
-        router_residual[r] = abs(sum_rx - sum_tx) / denom
-
-    # Stage 4: Confidence calibration with stability, bundle-consistency, scale penalty, and peer smoothing
-    # Pre-compute router totals per direction for stability term
-    router_sum_rx: Dict[str, float] = {}
-    router_sum_tx: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        ups = [i for i in ifs if status.get(i) == 'up']
-        router_sum_rx[r] = sum(hardened_rx.get(i, 0.0) for i in ups)
-        router_sum_tx[r] = sum(hardened_tx.get(i, 0.0) for i in ups)
-
-    # Pre-compute bundle median residual per link for bundle-consistency
-    bundle_e_median_tx: Dict[str, float] = {}
-    bundle_e_median_rx: Dict[str, float] = {}
-    # For each link pair, residual e = tx - peer.rx
-    # Build per-bundle arrays (local->remote for tx direction)
+        if status.get(a) == 'up' and status.get(b) == 'up':
+            soft_zero_link(a, b)
+
+    # Final router residuals for confidence
+    final_router_res = router_residuals(x_rx, x_tx)
+
+    # Confidence calibration
+    conf_rx: Dict[str, float] = {}
+    conf_tx: Dict[str, float] = {}
+
+    # Precompute bundle residual medians for optional bundle consistency signal
     bundle_e_map_tx: Dict[Tuple[Any, Any], List[float]] = {}
     bundle_e_map_rx: Dict[Tuple[Any, Any], List[float]] = {}
     for a, b in link_pairs:
         if status.get(a) != 'up' or status.get(b) != 'up':
             continue
         ra = local_router_of.get(a)
         rb = local_router_of.get(b)
-        e1 = hardened_tx[a] - hardened_rx[b]
-        e2 = hardened_tx[b] - hardened_rx[a]
-        bundle_e_map_tx.setdefault((ra, rb), []).append(e1)
-        bundle_e_map_rx.setdefault((rb, ra), []).append(e2)
+        bundle_e_map_tx.setdefault((ra, rb), []).append(x_tx[a] - x_rx[b])
+        bundle_e_map_rx.setdefault((rb, ra), []).append(x_tx[b] - x_rx[a])
     bundle_e_med_tx: Dict[Tuple[Any, Any], float] = {k: median(v) for k, v in bundle_e_map_tx.items()}
     bundle_e_med_rx: Dict[Tuple[Any, Any], float] = {k: median(v) for k, v in bundle_e_map_rx.items()}
 
-    def compute_conf(i: str) -> Tuple[float, float]:
+    # Router totals for share-based stability
+    router_sum_rx: Dict[str, float] = {}
+    router_sum_tx: Dict[str, float] = {}
+    for r, ifs in router_ifaces.items():
+        ups = [i for i in ifs if status.get(i) == 'up']
+        router_sum_rx[r] = sum(x_rx.get(i, 0.0) for i in ups)
+        router_sum_tx[r] = sum(x_tx.get(i, 0.0) for i in ups)
+
+    for i in telemetry:
         p = peer_of.get(i)
         # Measurement residuals
-        r_meas_rx = rel_diff(hardened_rx[i], orig_rx[i])
-        r_meas_tx = rel_diff(hardened_tx[i], orig_tx[i])
+        r_meas_rx = rel_diff(x_rx[i], orig_rx[i])
+        r_meas_tx = rel_diff(x_tx[i], orig_tx[i])
+
         # Link residuals
         if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
-            r_link_rx = rel_diff(hardened_rx[i], hardened_tx[p])
-            r_link_tx = rel_diff(hardened_tx[i], hardened_rx[p])
+            r_link_rx = rel_diff(x_rx[i], x_tx[p])
+            r_link_tx = rel_diff(x_tx[i], x_rx[p])
         else:
             r_link_rx = 0.2
             r_link_tx = 0.2
+
         # Router residual
-        rtr = router_residual.get(local_router_of.get(i), 0.0)
+        rtr = final_router_res.get(local_router_of.get(i), 0.0)
+
+        # Bundle consistency (distance to median residual within direction)
+        bcons_rx = 0.0
+        bcons_tx = 0.0
+        if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
+            lr = local_router_of.get(i)
+            rr = local_router_of.get(p)
+            e_tx = x_tx[i] - x_rx[p]
+            e_rx = x_rx[i] - x_tx[p]
+            med_tx = bundle_e_med_tx.get((lr, rr), 0.0)
+            med_rx = bundle_e_med_rx.get((lr, rr), 0.0)
+            # closeness factor in [0,1]
+            bcons_tx = clamp01(1.0 - abs(e_tx - med_tx) / (abs(med_tx) + max(x_tx[i], 1.0)))
+            bcons_rx = clamp01(1.0 - abs(e_rx - med_rx) / (abs(med_rx) + max(x_rx[i], 1.0)))
+
         # Base confidence blend
-        base_rx = 1.0 - (0.53 * r_meas_rx + 0.33 * r_link_rx + 0.14 * rtr)
-        base_tx = 1.0 - (0.53 * r_meas_tx + 0.33 * r_link_tx + 0.14 * rtr)
+        base_rx = 1.0 - (0.55 * r_meas_rx + 0.30 * r_link_rx + 0.15 * rtr)
+        base_tx = 1.0 - (0.55 * r_meas_tx + 0.30 * r_link_tx + 0.15 * rtr)
         base_rx = clamp01(base_rx)
         base_tx = clamp01(base_tx)
 
-        # Scale-factor term (penalize big routed adjustments)
-        alpha_rx = abs(scaled_rx_factor.get(i, 1.0) - 1.0)
-        alpha_tx = abs(scaled_tx_factor.get(i, 1.0) - 1.0)
-        scale_term_rx = clamp01(1.0 - min(0.5, alpha_rx))
-        scale_term_tx = clamp01(1.0 - min(0.5, alpha_tx))
-
-        c_rx = clamp01(0.90 * base_rx + 0.10 * scale_term_rx)
-        c_tx = clamp01(0.90 * base_tx + 0.10 * scale_term_tx)
-
-        # Stability term: interfaces that dominate router totals get a reduction
+        # Dominance stability: downweight confidence for dominant shares
         r_id = local_router_of.get(i)
         sum_r_rx = max(1.0, router_sum_rx.get(r_id, 1.0))
         sum_r_tx = max(1.0, router_sum_tx.get(r_id, 1.0))
-        share_rx = hardened_rx[i] / sum_r_rx
-        share_tx = hardened_tx[i] / sum_r_tx
-        stab_rx = clamp01(1.0 - 0.5 * share_rx)
-        stab_tx = clamp01(1.0 - 0.5 * share_tx)
-        c_rx = clamp01(c_rx + 0.05 * stab_rx)
-        c_tx = clamp01(c_tx + 0.05 * stab_tx)
-
-        # Bundle-consistency term: distance from bundle median residual
-        p = peer_of.get(i)
-        if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
-            lr = local_router_of.get(i)
-            rr = local_router_of.get(p)
-            e_tx = hardened_tx[i] - hardened_rx[p]
-            e_rx = hardened_rx[i] - hardened_tx[p]
-            med_tx = bundle_e_med_tx.get((lr, rr), 0.0)
-            med_rx = bundle_e_med_rx.get((lr, rr), 0.0)
-            bcons_tx = clamp01(1.0 - abs(e_tx - med_tx) / (abs(med_tx) + max(hardened_tx[i], 1.0)))
-            bcons_rx = clamp01(1.0 - abs(e_rx - med_rx) / (abs(med_rx) + max(hardened_rx[i], 1.0)))
-            c_tx = clamp01(c_tx + 0.06 * bcons_tx)
-            c_rx = clamp01(c_rx + 0.06 * bcons_rx)
-
-        # If interface is down, zero is a strong invariant; raise confidence floor
+        share_r = x_rx[i] / sum_r_rx
+        share_t = x_tx[i] / sum_r_tx
+        stab_rx = clamp01(1.0 - 0.5 * share_r)
+        stab_tx = clamp01(1.0 - 0.5 * share_t)
+
+        # Clip/move penalty
+        pen_rx = CLIP_HIT_PENALTY if cap_hit_rx.get(i, False) else 1.0
+        pen_tx = CLIP_HIT_PENALTY if cap_hit_tx.get(i, False) else 1.0
+
+        c_rx = clamp01(0.85 * base_rx + 0.05 * bcons_rx + 0.10 * stab_rx) * pen_rx
+        c_tx = clamp01(0.85 * base_tx + 0.05 * bcons_tx + 0.10 * stab_tx) * pen_tx
+
+        # Down interface -> zero is strong invariant; raise floor
         if status.get(i) != 'up':
             c_rx = max(c_rx, 0.85)
             c_tx = max(c_tx, 0.85)
-        return c_rx, c_tx
-
-    # Preliminary confidences
-    for i in telemetry:
-        cr, ct = compute_conf(i)
-        conf_rx[i], conf_tx[i] = cr, ct
-
-    # Apply penalties for clip/strong scaling and check if router imbalance worsened
-    for i in telemetry:
-        r_id = local_router_of.get(i)
-        # If anyone hit clip or strong scaling, small penalty
-        if abs(scaled_rx_factor.get(i, 1.0) - 1.0) >= PER_LINK_CLIP_BASE or clip_hit_rx.get(i, False):
-            conf_rx[i] = clamp01(conf_rx[i] * CLIP_HIT_PENALTY)
-        if abs(scaled_tx_factor.get(i, 1.0) - 1.0) >= PER_LINK_CLIP_BASE or clip_hit_tx.get(i, False):
-            conf_tx[i] = clamp01(conf_tx[i] * CLIP_HIT_PENALTY)
-        # Extra tiny penalty if both clip and router got worse (mid to final)
-        # Compute local notion: if final router residual > mid residual
-        if router_residual.get(r_id, 0.0) > router_residual_mid.get(r_id, 0.0):
-            if clip_hit_rx.get(i, False):
-                conf_rx[i] = clamp01(conf_rx[i] * 0.97)
-            if clip_hit_tx.get(i, False):
-                conf_tx[i] = clamp01(conf_tx[i] * 0.97)
-
-    # Router-aware smoothing when |scale - 1| < 0.05
-    router_mean_conf_rx: Dict[str, float] = {}
-    router_mean_conf_tx: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        ups = [i for i in ifs if i in telemetry and status.get(i) == 'up']
-        if ups:
-            router_mean_conf_rx[r] = sum(conf_rx[i] for i in ups) / len(ups)
-            router_mean_conf_tx[r] = sum(conf_tx[i] for i in ups) / len(ups)
-    for i in telemetry:
-        r = local_router_of.get(i)
-        if abs(scaled_rx_factor.get(i, 1.0) - 1.0) < 0.05 and r in router_mean_conf_rx:
-            conf_rx[i] = clamp01(0.85 * conf_rx[i] + 0.15 * router_mean_conf_rx[r])
-        if abs(scaled_tx_factor.get(i, 1.0) - 1.0) < 0.05 and r in router_mean_conf_tx:
-            conf_tx[i] = clamp01(0.85 * conf_tx[i] + 0.15 * router_mean_conf_tx[r])
-
-    # Peer smoothing (order-independent via staged update)
+
+        conf_rx[i] = clamp01(c_rx)
+        conf_tx[i] = clamp01(c_tx)
+
+    # Peer smoothing
     new_conf_rx = dict(conf_rx)
     new_conf_tx = dict(conf_tx)
     for a, b in link_pairs:
         if status.get(a) == 'up' and status.get(b) == 'up':
             new_conf_tx[a] = clamp01((1.0 - PEER_SMOOTH) * conf_tx[a] + PEER_SMOOTH * conf_rx[b])
             new_conf_rx[b] = clamp01((1.0 - PEER_SMOOTH) * conf_rx[b] + PEER_SMOOTH * conf_tx[a])
             new_conf_rx[a] = clamp01((1.0 - PEER_SMOOTH) * conf_rx[a] + PEER_SMOOTH * conf_tx[b])
             new_conf_tx[b] = clamp01((1.0 - PEER_SMOOTH) * conf_tx[b] + PEER_SMOOTH * conf_rx[a])
     conf_rx, conf_tx = new_conf_rx, new_conf_tx
 
-    # Untouched boost: minimal change (<1%) and good final symmetry on link
+    # Untouched boost (minimal change and good link symmetry)
     for i in telemetry:
         p = peer_of.get(i)
-        if not p or p not in telemetry or status.get(i) != 'up' or status.get(p) != 'up':
-            continue
-        # RX direction
-        if rel_diff(hardened_rx[i], orig_rx[i]) < 0.01:
-            if rel_diff(hardened_rx[i], hardened_tx[p]) <= adaptive_tau(hardened_rx[i], hardened_tx[p]):
-                conf_rx[i] = min(0.98, conf_rx[i] + UNTOUCHED_BOOST)
-        # TX direction
-        if rel_diff(hardened_tx[i], orig_tx[i]) < 0.01:
-            if rel_diff(hardened_tx[i], hardened_rx[p]) <= adaptive_tau(hardened_tx[i], hardened_rx[p]):
-                conf_tx[i] = min(0.98, conf_tx[i] + UNTOUCHED_BOOST)
+        if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
+            # RX
+            if rel_diff(x_rx[i], orig_rx[i]) < 0.01:
+                if rel_diff(x_rx[i], x_tx[p]) <= adaptive_tau(x_rx[i], x_tx[p]):
+                    conf_rx[i] = min(0.98, conf_rx[i] + UNTOUCHED_BOOST)
+            # TX
+            if rel_diff(x_tx[i], orig_tx[i]) < 0.01:
+                if rel_diff(x_tx[i], x_rx[p]) <= adaptive_tau(x_tx[i], x_rx[p]):
+                    conf_tx[i] = min(0.98, conf_tx[i] + UNTOUCHED_BOOST)
 
     # Assemble final result
     result: Dict[str, Dict[str, Tuple]] = {}
     for i, data in telemetry.items():
         my_status = status.get(i, 'unknown')
         peer_id = peer_of.get(i)
         # Status confidence: do not flip, but penalize inconsistent peer or down+nonzero readings
         status_conf = 1.0
         if peer_id and peer_id in telemetry:
             if telemetry[peer_id].get('interface_status', 'unknown') != my_status:
                 status_conf = 0.6
         if my_status == 'down' and (orig_rx.get(i, 0.0) > ZERO_EPS or orig_tx.get(i, 0.0) > ZERO_EPS):
             status_conf = min(status_conf, 0.6)
 
         repaired: Dict[str, Any] = {}
-        repaired['rx_rate'] = (orig_rx.get(i, 0.0), max(0.0, hardened_rx.get(i, 0.0)), clamp01(conf_rx.get(i, 0.6)))
-        repaired['tx_rate'] = (orig_tx.get(i, 0.0), max(0.0, hardened_tx.get(i, 0.0)), clamp01(conf_tx.get(i, 0.6)))
+        repaired['rx_rate'] = (orig_rx.get(i, 0.0), max(0.0, x_rx.get(i, 0.0)), clamp01(conf_rx.get(i, 0.6)))
+        repaired['tx_rate'] = (orig_tx.get(i, 0.0), max(0.0, x_tx.get(i, 0.0)), clamp01(conf_tx.get(i, 0.6)))
         repaired['interface_status'] = (my_status, my_status, status_conf)
 
         # Copy metadata unchanged
         repaired['connected_to'] = data.get('connected_to')
         repaired['local_router'] = data.get('local_router')
         repaired['remote_router'] = data.get('remote_router')
 
         result[i] = repaired
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")