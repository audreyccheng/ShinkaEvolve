<NAME>
two_tier_scaling_clip_penalty_router_attn
</NAME>

<DESCRIPTION>
I propose three targeted improvements aimed at increasing counter-repair accuracy while tightening confidence calibration:

1) Dominance-capped, targeted per-interface scaling:
   - In router-level projection, when using weighted per-interface scaling, cap any single interface’s share of the total correction to ≤50% of the absolute router delta, but only when at least two interfaces are adjustable. This prevents over-reliance on one link and reduces overcorrection, improving both counter accuracy and calibration. I also set flags when per-interface scaling clips to bounds to inform confidence penalties.

2) Router-imbalance attenuation in link re-sync:
   - In the post-projection re-sync step, attenuate the one-sided nudge by the local router’s current imbalance. This preserves router conservation and prevents re-sync from undoing router projections on imbalanced nodes, improving flow-conservation fidelity.

3) Confidence calibration refinements:
   - Add a clip-hit penalty (0.95) when a direction was clipped or scaled ≥10%.
   - Add an untouched boost (+0.02 up to 0.98) if a direction changed <1% and final symmetry residual ≤2%.
   - Adjust final smoothing to a two-step approach: first do a 70/30 residual blend, then a 10% peer smoothing. This sharpens calibration and reduces overconfidence.

These changes are minimal, cohesive, and leverage the topology and invariants more precisely, aiming to raise combined score by improving counters and aligning confidence with actual repair quality.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def tau_router(n_active: int) -> float:
        # Adaptive router tolerance based on active interfaces
        # Clamp in [0.03, 0.07]
        base = 0.05 * math.sqrt(2.0 / max(2, n_active))
        return max(0.03, min(0.07, base))
=======
    def tau_router(n_active: int) -> float:
        # Adaptive router tolerance based on active interfaces
        # Clamp in [0.03, 0.07]
        base = 0.05 * math.sqrt(2.0 / max(2, n_active))
        return max(0.03, min(0.07, base))

    def router_imbalance_now(router_id: str) -> float:
        # Compute current router imbalance from hardened counters
        if router_id is None or router_id not in router_ifaces:
            return 0.0
        ifs = router_ifaces.get(router_id, [])
        sum_tx = sum(hard_tx.get(i, 0.0) for i in ifs)
        sum_rx = sum(hard_rx.get(i, 0.0) for i in ifs)
        return rel_diff(sum_tx, sum_rx)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    scaled_tx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    scaled_rx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    strong_scaled_tx: Dict[str, bool] = {if_id: False for if_id in telemetry}
    strong_scaled_rx: Dict[str, bool] = {if_id: False for if_id in telemetry}
=======
    scaled_tx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    scaled_rx_factor: Dict[str, float] = {if_id: 1.0 for if_id in telemetry}
    strong_scaled_tx: Dict[str, bool] = {if_id: False for if_id in telemetry}
    strong_scaled_rx: Dict[str, bool] = {if_id: False for if_id in telemetry}
    # Track if any per-direction scaling hit clipping bounds to inform confidence penalties
    clip_hit_tx: Dict[str, bool] = {if_id: False for if_id in telemetry}
    clip_hit_rx: Dict[str, bool] = {if_id: False for if_id in telemetry}
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
            else:
                k = (target - current) / denom

                # Compute group-major bundles
                total_side = sum(vals.values())
                bundles: Dict[str, List[str]] = {}
                for i in if_list:
                    bundles.setdefault(group_key(i), []).append(i)
                bundle_share: Dict[str, float] = {}
                for g, members in bundles.items():
                    share = sum(vals[m] for m in members) / max(total_side, EPS)
                    bundle_share[g] = share

                # Precompute group-level ratio for dominant bundles
                group_alpha_raw: Dict[str, float] = {}
                for g, members in bundles.items():
                    if bundle_share[g] >= 0.55:
                        sum_w = sum(weights[m] for m in members)
                        sum_v = sum(vals[m] for m in members)
                        if sum_v > EPS:
                            alpha_raw_g = 1.0 + k * (sum_w / sum_v)
                        else:
                            alpha_raw_g = 1.0
                        group_alpha_raw[g] = alpha_raw_g

                # Apply per-interface or bundle-shared scaling
                for i, v in vals.items():
                    if v < EPS:
                        continue
                    g = group_key(i)
                    if g in group_alpha_raw:
                        alpha_raw = group_alpha_raw[g]
                    else:
                        alpha_raw = 1.0 + k * (weights[i] / max(v, EPS))
                    # Damped and clipped
                    alpha_eff = 1.0 + 0.6 * (alpha_raw - 1.0)
                    alpha_eff = max(0.90, min(1.10, alpha_eff))
                    hard_tx[i] = v * alpha_eff
                    scaled_tx_factor[i] *= alpha_eff
                    penalty = abs(alpha_eff - 1.0)
                    if penalty > 0.08:
                        strong_scaled_tx[i] = True
                    conf_tx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
=======
            else:
                delta = (target - current)
                k = delta / denom

                # Compute group-major bundles
                total_side = sum(vals.values())
                bundles: Dict[str, List[str]] = {}
                for i in if_list:
                    bundles.setdefault(group_key(i), []).append(i)
                bundle_share: Dict[str, float] = {}
                for g, members in bundles.items():
                    share = sum(vals[m] for m in members) / max(total_side, EPS)
                    bundle_share[g] = share

                # Precompute group-level ratio for dominant bundles
                group_alpha_raw: Dict[str, float] = {}
                for g, members in bundles.items():
                    if bundle_share[g] >= 0.55:
                        sum_w = sum(weights[m] for m in members)
                        sum_v = sum(vals[m] for m in members)
                        if sum_v > EPS:
                            alpha_raw_g = 1.0 + k * (sum_w / sum_v)
                        else:
                            alpha_raw_g = 1.0
                        group_alpha_raw[g] = alpha_raw_g

                # Dominance cap: prevent any single interface from absorbing >50% of total delta
                n_weighted = sum(1 for i in if_list if weights.get(i, 0.0) > 0.0 and vals.get(i, 0.0) >= EPS)
                cap_abs = 0.5 * abs(delta) if n_weighted >= 2 else None

                # Apply per-interface or bundle-shared scaling
                for i, v in vals.items():
                    if v < EPS:
                        continue
                    g = group_key(i)
                    if g in group_alpha_raw:
                        alpha_raw = group_alpha_raw[g]
                    else:
                        alpha_raw = 1.0 + k * (weights[i] / max(v, EPS))
                    # Damped and clipped
                    alpha_eff = 1.0 + 0.6 * (alpha_raw - 1.0)
                    alpha_eff = max(0.90, min(1.10, alpha_eff))
                    # Dominance cap on absolute change if applicable
                    if cap_abs is not None:
                        change_i = v * (alpha_eff - 1.0)
                        if abs(change_i) > cap_abs:
                            alpha_eff = 1.0 + math.copysign(cap_abs, change_i) / max(v, EPS)
                    # Mark clip-hit when hitting bounds
                    if abs(alpha_eff - 0.90) < 1e-12 or abs(alpha_eff - 1.10) < 1e-12:
                        clip_hit_tx[i] = True
                    hard_tx[i] = v * alpha_eff
                    scaled_tx_factor[i] *= alpha_eff
                    penalty = abs(alpha_eff - 1.0)
                    if penalty > 0.08:
                        strong_scaled_tx[i] = True
                    conf_tx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
            else:
                k = (target - current) / denom

                total_side = sum(vals.values())
                bundles: Dict[str, List[str]] = {}
                for i in if_list:
                    bundles.setdefault(group_key(i), []).append(i)
                bundle_share: Dict[str, float] = {}
                for g, members in bundles.items():
                    share = sum(vals[m] for m in members) / max(total_side, EPS)
                    bundle_share[g] = share

                group_alpha_raw: Dict[str, float] = {}
                for g, members in bundles.items():
                    if bundle_share[g] >= 0.55:
                        sum_w = sum(weights[m] for m in members)
                        sum_v = sum(vals[m] for m in members)
                        if sum_v > EPS:
                            alpha_raw_g = 1.0 + k * (sum_w / sum_v)
                        else:
                            alpha_raw_g = 1.0
                        group_alpha_raw[g] = alpha_raw_g

                for i, v in vals.items():
                    if v < EPS:
                        continue
                    g = group_key(i)
                    if g in group_alpha_raw:
                        alpha_raw = group_alpha_raw[g]
                    else:
                        alpha_raw = 1.0 + k * (weights[i] / max(v, EPS))
                    alpha_eff = 1.0 + 0.6 * (alpha_raw - 1.0)
                    alpha_eff = max(0.90, min(1.10, alpha_eff))
                    hard_rx[i] = v * alpha_eff
                    scaled_rx_factor[i] *= alpha_eff
                    penalty = abs(alpha_eff - 1.0)
                    if penalty > 0.08:
                        strong_scaled_rx[i] = True
                    conf_rx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
=======
            else:
                delta = (target - current)
                k = delta / denom

                total_side = sum(vals.values())
                bundles: Dict[str, List[str]] = {}
                for i in if_list:
                    bundles.setdefault(group_key(i), []).append(i)
                bundle_share: Dict[str, float] = {}
                for g, members in bundles.items():
                    share = sum(vals[m] for m in members) / max(total_side, EPS)
                    bundle_share[g] = share

                group_alpha_raw: Dict[str, float] = {}
                for g, members in bundles.items():
                    if bundle_share[g] >= 0.55:
                        sum_w = sum(weights[m] for m in members)
                        sum_v = sum(vals[m] for m in members)
                        if sum_v > EPS:
                            alpha_raw_g = 1.0 + k * (sum_w / sum_v)
                        else:
                            alpha_raw_g = 1.0
                        group_alpha_raw[g] = alpha_raw_g

                # Dominance cap: prevent any single interface from absorbing >50% of total delta
                n_weighted = sum(1 for i in if_list if weights.get(i, 0.0) > 0.0 and vals.get(i, 0.0) >= EPS)
                cap_abs = 0.5 * abs(delta) if n_weighted >= 2 else None

                for i, v in vals.items():
                    if v < EPS:
                        continue
                    g = group_key(i)
                    if g in group_alpha_raw:
                        alpha_raw = group_alpha_raw[g]
                    else:
                        alpha_raw = 1.0 + k * (weights[i] / max(v, EPS))
                    alpha_eff = 1.0 + 0.6 * (alpha_raw - 1.0)
                    alpha_eff = max(0.90, min(1.10, alpha_eff))
                    if cap_abs is not None:
                        change_i = v * (alpha_eff - 1.0)
                        if abs(change_i) > cap_abs:
                            alpha_eff = 1.0 + math.copysign(cap_abs, change_i) / max(v, EPS)
                    if abs(alpha_eff - 0.90) < 1e-12 or abs(alpha_eff - 1.10) < 1e-12:
                        clip_hit_rx[i] = True
                    hard_rx[i] = v * alpha_eff
                    scaled_rx_factor[i] *= alpha_eff
                    penalty = abs(alpha_eff - 1.0)
                    if penalty > 0.08:
                        strong_scaled_rx[i] = True
                    conf_rx_link[i] *= clamp01(1.0 - 0.4 * clamp01(penalty))
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
                f = min(0.4, max(0.0, high[0] - low[0])) * sev_ab
                if f > 0.0:
                    if low[1] == 'a':
                        hard_tx[a] = (1.0 - f) * tx_a + f * mean_ab
                        conf_tx_link[a] *= 0.97
                    else:
                        hard_rx[b] = (1.0 - f) * rx_b + f * mean_ab
                        conf_rx_link[b] *= 0.97
=======
                base_f = min(0.4, max(0.0, high[0] - low[0])) * sev_ab
                if base_f > 0.0:
                    if low[1] == 'a':
                        # Attenuate by local router imbalance on the side being adjusted
                        att = clamp01(1.0 - router_imbalance_now(router_of.get(a)))
                        f = base_f * att
                        hard_tx[a] = (1.0 - f) * tx_a + f * mean_ab
                        conf_tx_link[a] *= 0.97
                    else:
                        att = clamp01(1.0 - router_imbalance_now(router_of.get(b)))
                        f = base_f * att
                        hard_rx[b] = (1.0 - f) * rx_b + f * mean_ab
                        conf_rx_link[b] *= 0.97
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
                f = min(0.4, max(0.0, high[0] - low[0])) * sev_ba
                if f > 0.0:
                    if low[1] == 'b':
                        hard_tx[b] = (1.0 - f) * tx_b + f * mean_ba
                        conf_tx_link[b] *= 0.97
                    else:
                        hard_rx[a] = (1.0 - f) * rx_a + f * mean_ba
                        conf_rx_link[a] *= 0.97
=======
                base_f = min(0.4, max(0.0, high[0] - low[0])) * sev_ba
                if base_f > 0.0:
                    if low[1] == 'b':
                        att = clamp01(1.0 - router_imbalance_now(router_of.get(b)))
                        f = base_f * att
                        hard_tx[b] = (1.0 - f) * tx_b + f * mean_ba
                        conf_tx_link[b] *= 0.97
                    else:
                        att = clamp01(1.0 - router_imbalance_now(router_of.get(a)))
                        f = base_f * att
                        hard_rx[a] = (1.0 - f) * rx_a + f * mean_ba
                        conf_rx_link[a] *= 0.97
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        conf_tx_final = clamp01(
            0.22 * base_tx_conf +
            0.18 * red_tx +
            0.28 * fin_sym_tx +
            0.12 * ch_tx +
            0.10 * router_factor_after +
            0.10 * scale_term_tx
        )
        conf_rx_final = clamp01(
            0.22 * base_rx_conf +
            0.18 * red_rx +
            0.28 * fin_sym_rx +
            0.12 * ch_rx +
            0.10 * router_factor_after +
            0.10 * scale_term_rx
        )
=======
        conf_tx_final = clamp01(
            0.22 * base_tx_conf +
            0.18 * red_tx +
            0.28 * fin_sym_tx +
            0.12 * ch_tx +
            0.10 * router_factor_after +
            0.10 * scale_term_tx
        )
        conf_rx_final = clamp01(
            0.22 * base_rx_conf +
            0.18 * red_rx +
            0.28 * fin_sym_rx +
            0.12 * ch_rx +
            0.10 * router_factor_after +
            0.10 * scale_term_rx
        )

        # Confidence refinements: clip-hit penalty and untouched boost
        if clip_hit_tx.get(if_id, False) or abs(scaled_tx_factor.get(if_id, 1.0) - 1.0) >= 0.10:
            conf_tx_final *= 0.95
        if clip_hit_rx.get(if_id, False) or abs(scaled_rx_factor.get(if_id, 1.0) - 1.0) >= 0.10:
            conf_rx_final *= 0.95
        if change_tx < 0.01 and post_mismatch_tx_dir.get(if_id, 0.4) <= 0.02:
            conf_tx_final = min(0.98, conf_tx_final + 0.02)
        if change_rx < 0.01 and post_mismatch_rx_dir.get(if_id, 0.4) <= 0.02:
            conf_rx_final = min(0.98, conf_rx_final + 0.02)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    # Peer confidence smoothing with residual-informed touch (when both ends are up)
    for i, data in telemetry.items():
        p = data.get("connected_to")
        if not isinstance(p, str) or p not in telemetry:
            continue
        if i not in result or p not in result:
            continue
        if result[i]["interface_status"][1] != "up" or result[p]["interface_status"][1] != "up":
            continue
        # Compute final symmetry residuals
        tx_i = safe_rate(result[i]["tx_rate"][1])
        rx_p = safe_rate(result[p]["rx_rate"][1])
        rx_i = safe_rate(result[i]["rx_rate"][1])
        tx_p = safe_rate(result[p]["tx_rate"][1])
        mis_tx = rel_diff(tx_i, rx_p)
        mis_rx = rel_diff(rx_i, tx_p)
        # Blend my confidence with 10% peer opposite and 10% residual agreement
        my_tx_c = clamp01(result[i]["tx_rate"][2])
        my_rx_c = clamp01(result[i]["rx_rate"][2])
        peer_rx_c = clamp01(result[p]["rx_rate"][2])
        peer_tx_c = clamp01(result[p]["tx_rate"][2])
        result[i]["tx_rate"] = (
            result[i]["tx_rate"][0],
            result[i]["tx_rate"][1],
            clamp01(0.80 * my_tx_c + 0.10 * peer_rx_c + 0.10 * clamp01(1.0 - mis_tx))
        )
        result[i]["rx_rate"] = (
            result[i]["rx_rate"][0],
            result[i]["rx_rate"][1],
            clamp01(0.80 * my_rx_c + 0.10 * peer_tx_c + 0.10 * clamp01(1.0 - mis_rx))
        )
=======
    # Peer confidence smoothing (first 70/30 residual blend, then 10% peer smoothing) when both ends are up
    for i, data in telemetry.items():
        p = data.get("connected_to")
        if not isinstance(p, str) or p not in telemetry:
            continue
        if i not in result or p not in result:
            continue
        if result[i]["interface_status"][1] != "up" or result[p]["interface_status"][1] != "up":
            continue
        # Compute final symmetry residuals
        tx_i = safe_rate(result[i]["tx_rate"][1])
        rx_p = safe_rate(result[p]["rx_rate"][1])
        rx_i = safe_rate(result[i]["rx_rate"][1])
        tx_p = safe_rate(result[p]["tx_rate"][1])
        mis_tx = rel_diff(tx_i, rx_p)
        mis_rx = rel_diff(rx_i, tx_p)
        # 70/30 residual blend
        old_tx_c = clamp01(result[i]["tx_rate"][2])
        old_rx_c = clamp01(result[i]["rx_rate"][2])
        base_tx_c = clamp01(0.70 * old_tx_c + 0.30 * clamp01(1.0 - mis_tx))
        base_rx_c = clamp01(0.70 * old_rx_c + 0.30 * clamp01(1.0 - mis_rx))
        # 10% peer smoothing
        peer_rx_c = clamp01(result[p]["rx_rate"][2])
        peer_tx_c = clamp01(result[p]["tx_rate"][2])
        final_tx_c = clamp01(0.90 * base_tx_c + 0.10 * peer_rx_c)
        final_rx_c = clamp01(0.90 * base_rx_c + 0.10 * peer_tx_c)
        result[i]["tx_rate"] = (
            result[i]["tx_rate"][0],
            result[i]["tx_rate"][1],
            final_tx_c
        )
        result[i]["rx_rate"] = (
            result[i]["rx_rate"][0],
            result[i]["rx_rate"][1],
            final_rx_c
        )
>>>>>>> REPLACE
</DIFF>