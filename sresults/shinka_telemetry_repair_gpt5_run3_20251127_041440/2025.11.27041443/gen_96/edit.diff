--- a/original.py
+++ b/original.py
@@ -1,1104 +1,408 @@
 # EVOLVE-BLOCK-START
 """
-Bundle-aware consensus projection for network telemetry repair.
-
-Algorithm summary:
-1) Robust link hardening with adaptive tolerance and soft-zero snapping.
-2) Router flow conservation via targeted, confidence-weighted corrections.
-   - Expected-penalty router-side selection with dominance awareness.
-   - Bundle-aware scaling for parallel links (shared factor).
-   - Adaptive per-interface clipping with dominance-aware caps and micro-tier.
-3) Confidence-gap-proportional re-sync on links with scaling guard and absolute-per-dir caps.
-4) Dispersion-aware bundle finishing with per-router zero-sum enforcement.
-5) Confidence calibrated from measurement residuals, link residuals, router residuals,
-   plus stability, bundle-consistency, scale-factor term, and peer/router smoothing.
-
-Maintains inputs/outputs of the original function.
+Global POCS-based projection for network telemetry repair.
+
+Approach:
+- Formulate telemetry repair as a weighted least-squares projection onto convex
+  sets encoding network invariants.
+- Iteratively project current telemetry onto:
+  1) Link symmetry sets: a.tx = b.rx and b.tx = a.rx (weighted averaging)
+  2) Router conservation hyperplanes: Σrx = Σtx per router (weighted L2 projection)
+- Enforce non-negativity and "down => zero" constraints throughout.
+- Use share-aware and near-zero-aware weights so dominant links and tiny links
+  are more stable; low-share links absorb more of the corrections safely.
+- Confidence calibrated from: measurement deviation, final link residuals,
+  and final router residuals, with light peer smoothing.
+
+Maintains inputs/outputs of the original function signature.
 """
 from typing import Dict, Any, Tuple, List
 import math
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     # Hyperparameters
-    TAU_H_BASE = 0.02        # ~2% hardening threshold
-    ZERO_EPS = 1e-6
-    ZERO_THRESH = 1.0        # Mbps near-zero threshold
-    DAMP_ROUTER = 0.60       # router damping factor
-    PER_LINK_CLIP_BASE = 0.10     # baseline per-interface relative change cap (±10%)
-    BUNDLE_CLIP = 0.15       # bundle shared factor cap (±15%)
-    STRONG_SCALE_GUARD = 0.08  # guard for re-sync when strong router scaling applied
-    RESYNC_MAX_F = 0.40      # max one-sided nudge toward mean
-    RESYNC_PER_DIR_CAP = 0.02  # per-direction absolute move cap as fraction of max value
-    PEER_SMOOTH = 0.10       # 10% peer smoothing
-    WEIGHT_FOCUS = 0.70      # focus router correction on lowest-confidence 70% weight
-    DOMINANCE_CAP = 0.50     # cap any single interface's weight share to ≤50% in a pass
-    CLIP_HIT_PENALTY = 0.95  # confidence penalty multiplier when clipping/strong scaling hit
-    UNTOUCHED_BOOST = 0.02   # confidence boost for untouched, well-synced counters
-    # Second micro re-sync pass parameters
-    RESYNC2_CAP_FRAC = 0.01  # per-move absolute cap as fraction of local reference (±1%)
-    RESYNC2_GAIN = 0.50      # halved gain relative to Stage 3
-
-    # Bundle finishing parameters
-    FINISH_GAMMA_MAX = 0.30
-    FINISH_C_LOW = 0.02
-    FINISH_C_HIGH = 0.04
+    TAU_H = 0.02            # ~2% hardening tolerance
+    ZERO_EPS = 1e-9
+    ZERO_THRESH = 1.0       # Mbps near-zero threshold
+    N_ITER = 6              # number of POCS outer iterations
+    LINK_ZERO_SNAP = 2.0    # soft-zero snap when link max < 2*ZERO_THRESH and routers balanced
+    PEER_SMOOTH = 0.10      # peer confidence smoothing
+    ROUTER_BAL_TAU_MIN = 0.03
+    ROUTER_BAL_TAU_MAX = 0.07
+
+    # Weighting parameters
+    W_SHARE_K = 2.0         # added weight proportional to share within router side
+    W_ZERO_K = 2.0          # extra weight when variable is near zero
+    W_MIN = 0.15            # minimal weight to avoid division issues
 
     def clamp01(x: float) -> float:
         return max(0.0, min(1.0, x))
 
     def rel_diff(a: float, b: float) -> float:
         return abs(a - b) / max(1.0, abs(a), abs(b))
 
-    def adaptive_tau(v1: float, v2: float) -> float:
-        # Adaptive symmetry tolerance:
-        # tighter for high rates, looser for low/near-zero or low confidence regions.
-        if v1 >= 100.0 and v2 >= 100.0:
-            return 0.015
-        if v1 < ZERO_THRESH or v2 < ZERO_THRESH:
-            return 0.03
-        return TAU_H_BASE
-
-    def median(vals: List[float]) -> float:
-        n = len(vals)
-        if n == 0:
-            return 0.0
-        s = sorted(vals)
-        m = n // 2
-        if n % 2 == 1:
-            return s[m]
-        return 0.5 * (s[m - 1] + s[m])
+    def router_tau(n_active: int) -> float:
+        # Adaptive router tolerance by active interface count
+        return min(ROUTER_BAL_TAU_MAX, max(ROUTER_BAL_TAU_MIN, 0.05 * (2.0 / max(2, n_active)) ** 0.5))
 
     # Build basic maps
     orig_rx: Dict[str, float] = {}
     orig_tx: Dict[str, float] = {}
     status: Dict[str, str] = {}
     peer_of: Dict[str, str] = {}
     local_router_of: Dict[str, Any] = {}
     remote_router_of: Dict[str, Any] = {}
 
     for iid, d in telemetry.items():
         orig_rx[iid] = float(d.get('rx_rate', 0.0))
         orig_tx[iid] = float(d.get('tx_rate', 0.0))
         status[iid] = d.get('interface_status', 'unknown')
         ct = d.get('connected_to')
         peer_of[iid] = ct if ct in telemetry else None
         local_router_of[iid] = d.get('local_router')
         remote_router_of[iid] = d.get('remote_router')
 
-    # Build router->interfaces mapping, prefer provided topology
+    # Build router->interfaces mapping; prefer provided topology
     router_ifaces: Dict[str, List[str]] = {}
     if topology:
         for r, ifs in topology.items():
             router_ifaces[r] = [i for i in ifs if i in telemetry]
     else:
-        # Fallback to local_router fields
+        # Fallback to local_router fields if topology not provided
         for iid, d in telemetry.items():
             r = d.get('local_router')
             if r is not None:
                 router_ifaces.setdefault(r, []).append(iid)
 
     # Derive missing remote_router via peer's local_router if needed
     for iid in telemetry:
         if not remote_router_of.get(iid):
             p = peer_of.get(iid)
             if p and p in telemetry:
                 remote_router_of[iid] = telemetry[p].get('local_router')
 
     # Build link pairs (unique, undirected)
     link_pairs: List[Tuple[str, str]] = []
     seen = set()
     for a in telemetry:
         b = peer_of.get(a)
         if not b or b not in telemetry or a == b:
             continue
         if (b, a) in seen or (a, b) in seen:
             continue
         seen.add((a, b))
         link_pairs.append((a, b))
 
-    # Initialize hardened values with originals
-    hardened_rx: Dict[str, float] = {i: max(0.0, orig_rx[i]) for i in telemetry}
-    hardened_tx: Dict[str, float] = {i: max(0.0, orig_tx[i]) for i in telemetry}
-    # Initialize confidences (will be calibrated later)
-    conf_rx: Dict[str, float] = {i: 0.7 for i in telemetry}
-    conf_tx: Dict[str, float] = {i: 0.7 for i in telemetry}
-
-    # Track cumulative router scaling factors for re-sync guard and confidence
-    scaled_rx_factor: Dict[str, float] = {i: 1.0 for i in telemetry}
-    scaled_tx_factor: Dict[str, float] = {i: 1.0 for i in telemetry}
-    # Track if a direction hit clipping (±10% per-pass cap or strong scaling)
-    clip_hit_rx: Dict[str, bool] = {i: False for i in telemetry}
-    clip_hit_tx: Dict[str, bool] = {i: False for i in telemetry}
-
-    # Stage 1: Robust link hardening with adaptive tolerance and soft-zero
-    for a, b in link_pairs:
-        a_up = (status.get(a) == 'up')
-        b_up = (status.get(b) == 'up')
-        a_rx, a_tx = orig_rx[a], orig_tx[a]
-        b_rx, b_tx = orig_rx[b], orig_tx[b]
-
-        # If either side is down: force both to zero on the link with high confidence
-        if not a_up or not b_up:
-            for i in (a, b):
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.85)
-                conf_tx[i] = max(conf_tx[i], 0.85)
-            continue
-
-        # Soft-zero stabilization for near-zero links
-        if max(a_rx, a_tx, b_rx, b_tx) < 2.0 * ZERO_THRESH:
-            for i in (a, b):
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.95)
-                conf_tx[i] = max(conf_tx[i], 0.95)
-            continue
-
-        # Direction 1: a.tx vs b.rx
-        d1 = rel_diff(a_tx, b_rx)
-        tau1 = adaptive_tau(a_tx, b_rx)
-        if d1 <= tau1:
-            v1 = 0.5 * (a_tx + b_rx)
-            hardened_tx[a] = v1
-            hardened_rx[b] = v1
-            c1 = clamp01(0.9 + 0.1 * (1.0 - d1 / max(tau1, 1e-12)))
-            conf_tx[a] = max(conf_tx[a], c1)
-            conf_rx[b] = max(conf_rx[b], c1)
-        else:
-            # Choose the more reliable of the two readings (farther from zero), rely on redundancy
-            choice = b_rx if abs(b_rx) >= abs(a_tx) else a_tx
-            hardened_tx[a] = max(0.0, choice)
-            hardened_rx[b] = max(0.0, choice)
-            c1 = clamp01(1.0 - d1)
-            conf_tx[a] = max(conf_tx[a], c1)
-            conf_rx[b] = max(conf_rx[b], c1)
-
-        # Direction 2: a.rx vs b.tx
-        d2 = rel_diff(a_rx, b_tx)
-        tau2 = adaptive_tau(a_rx, b_tx)
-        if d2 <= tau2:
-            v2 = 0.5 * (a_rx + b_tx)
-            hardened_rx[a] = v2
-            hardened_tx[b] = v2
-            c2 = clamp01(0.9 + 0.1 * (1.0 - d2 / max(tau2, 1e-12)))
-            conf_rx[a] = max(conf_rx[a], c2)
-            conf_tx[b] = max(conf_tx[b], c2)
-        else:
-            choice = b_tx if abs(b_tx) >= abs(a_rx) else a_rx
-            hardened_rx[a] = max(0.0, choice)
-            hardened_tx[b] = max(0.0, choice)
-            c2 = clamp01(1.0 - d2)
-            conf_rx[a] = max(conf_rx[a], c2)
-            conf_tx[b] = max(conf_tx[b], c2)
-
-    # Unpaired interfaces: trust local with moderate confidence; zero if down
-    in_pairs = {x for pair in link_pairs for x in pair}
+    # Initialize working values
+    rx: Dict[str, float] = {i: max(0.0, orig_rx[i]) for i in telemetry}
+    tx: Dict[str, float] = {i: max(0.0, orig_tx[i]) for i in telemetry}
+
+    # Enforce down interfaces -> zero
     for i in telemetry:
-        if i not in in_pairs:
+        if status.get(i) != 'up':
+            rx[i] = 0.0
+            tx[i] = 0.0
+
+    # Quick helper: compute router sums
+    def router_sums() -> Dict[str, Tuple[float, float, int]]:
+        sums: Dict[str, Tuple[float, float, int]] = {}
+        for r, ifs in router_ifaces.items():
+            ups = [i for i in ifs if status.get(i) == 'up']
+            srx = sum(rx[i] for i in ups)
+            stx = sum(tx[i] for i in ups)
+            sums[r] = (srx, stx, len(ups))
+        return sums
+
+    # Helper: compute share per interface for a given direction (rx or tx)
+    def side_shares() -> Tuple[Dict[str, float], Dict[str, float]]:
+        # tx_share[i]: share of tx[i] in local router's total TX; rx_share likewise
+        tx_share: Dict[str, float] = {}
+        rx_share: Dict[str, float] = {}
+        # Precompute sums per router side
+        sum_tx_r: Dict[str, float] = {}
+        sum_rx_r: Dict[str, float] = {}
+        for r, ifs in router_ifaces.items():
+            ups = [i for i in ifs if status.get(i) == 'up']
+            sum_tx_r[r] = sum(tx[i] for i in ups)
+            sum_rx_r[r] = sum(rx[i] for i in ups)
+        for i in telemetry:
+            r = local_router_of.get(i)
+            if r is None:
+                tx_share[i] = 0.0
+                rx_share[i] = 0.0
+                continue
+            st = sum_tx_r.get(r, 0.0)
+            sr = sum_rx_r.get(r, 0.0)
+            tx_share[i] = 0.0 if st <= ZERO_EPS else tx[i] / st
+            rx_share[i] = 0.0 if sr <= ZERO_EPS else rx[i] / sr
+        return tx_share, rx_share
+
+    # Weighted averaging projection onto x = y constraint
+    def project_pair_equal(x_val: float, y_val: float, wx: float, wy: float) -> float:
+        wx = max(W_MIN, wx)
+        wy = max(W_MIN, wy)
+        return (wx * x_val + wy * y_val) / (wx + wy)
+
+    # Weighted projection of router onto Σrx = Σtx hyperplane
+    # Minimize Σ w_i * delta_i^2 s.t. Σ s_i * delta_i = -d, where s_i = +1 for rx, -1 for tx
+    def project_router_balance(r: str) -> None:
+        ifs = [i for i in router_ifaces.get(r, []) if status.get(i) == 'up']
+        if len(ifs) < 2:
+            return
+        # Build variable lists
+        z_vals: List[float] = []
+        s_signs: List[int] = []
+        weights: List[float] = []
+        # Shares to bias weights
+        tx_sh, rx_sh = shares_tx.get, shares_rx.get
+        for i in ifs:
+            # rx direction entry
+            vi_rx = rx[i]
+            si_rx = +1
+            wi_rx = 1.0 + W_SHARE_K * max(0.0, rx_sh(i)) + (W_ZERO_K if vi_rx < 2.0 * ZERO_THRESH else 0.0)
+            z_vals.append(vi_rx); s_signs.append(si_rx); weights.append(max(W_MIN, wi_rx))
+            # tx direction entry
+            vi_tx = tx[i]
+            si_tx = -1
+            wi_tx = 1.0 + W_SHARE_K * max(0.0, tx_sh(i)) + (W_ZERO_K if vi_tx < 2.0 * ZERO_THRESH else 0.0)
+            z_vals.append(vi_tx); s_signs.append(si_tx); weights.append(max(W_MIN, wi_tx))
+
+        # Compute imbalance d = Σ s_i * z_i
+        d = 0.0
+        for zi, si in zip(z_vals, s_signs):
+            d += si * zi
+
+        # Skip if within tolerance
+        srx, stx, nup = router_totals.get(r, (0.0, 0.0, 0))
+        denom = max(1.0, srx, stx)
+        if abs(d) / denom <= router_tau(nup):
+            return
+
+        # Weighted solution: delta_i = -d * s_i / w_i / Σ (1/w_j)
+        invw_sum = sum(1.0 / wi for wi in weights)
+        if invw_sum <= ZERO_EPS:
+            return
+        deltas = [(-d) * si / wi / invw_sum for si, wi in zip(s_signs, weights)]
+
+        # Determine maximal step to keep variables non-negative (damped if needed)
+        lam_max = 1.0
+        for zi, di in zip(z_vals, deltas):
+            if di < 0.0:
+                lam_max = min(lam_max, (zi / (-di)) if (-di) > ZERO_EPS else lam_max)
+        lam = max(0.0, min(1.0, lam_max))
+
+        # Apply updates
+        idx = 0
+        for i in ifs:
+            d_rx = lam * deltas[idx]; d_tx = lam * deltas[idx + 1]
+            rx[i] = max(0.0, rx[i] + d_rx)
+            tx[i] = max(0.0, tx[i] + d_tx)
+            idx += 2
+
+    # POCS outer iterations
+    for _ in range(N_ITER):
+        # Refresh router totals and shares
+        router_totals = router_sums()
+        shares_tx, shares_rx = side_shares()
+
+        # 1) Project onto link symmetry for each connected pair (two directions)
+        for a, b in link_pairs:
+            a_up = (status.get(a) == 'up')
+            b_up = (status.get(b) == 'up')
+
+            if not a_up or not b_up:
+                # Down -> zero already enforced; force both sides of the link to zero
+                rx[a] = tx[a] = 0.0
+                rx[b] = tx[b] = 0.0
+                continue
+
+            # Soft-zero stabilization for near-zero links
+            if max(rx[a], tx[a], rx[b], tx[b]) < LINK_ZERO_SNAP * ZERO_THRESH:
+                rx[a] = tx[a] = 0.0
+                rx[b] = tx[b] = 0.0
+                continue
+
+            # Direction 1: a.tx == b.rx
+            x = tx[a]; y = rx[b]
+            # Weights prefer large-share and non-near-zero to remain more stable
+            wx = 1.0 + W_SHARE_K * max(0.0, shares_tx.get(a, 0.0)) + (W_ZERO_K if x < 2.0 * ZERO_THRESH else 0.0)
+            wy = 1.0 + W_SHARE_K * max(0.0, shares_rx.get(b, 0.0)) + (W_ZERO_K if y < 2.0 * ZERO_THRESH else 0.0)
+            v = project_pair_equal(x, y, wx, wy)
+            tx[a] = max(0.0, v)
+            rx[b] = max(0.0, v)
+
+            # Direction 2: a.rx == b.tx
+            x2 = rx[a]; y2 = tx[b]
+            wx2 = 1.0 + W_SHARE_K * max(0.0, shares_rx.get(a, 0.0)) + (W_ZERO_K if x2 < 2.0 * ZERO_THRESH else 0.0)
+            wy2 = 1.0 + W_SHARE_K * max(0.0, shares_tx.get(b, 0.0)) + (W_ZERO_K if y2 < 2.0 * ZERO_THRESH else 0.0)
+            v2 = project_pair_equal(x2, y2, wx2, wy2)
+            rx[a] = max(0.0, v2)
+            tx[b] = max(0.0, v2)
+
+        # 2) Project per-router onto Σrx = Σtx hyperplane (weighted, non-negativity aware)
+        router_totals = router_sums()
+        shares_tx, shares_rx = side_shares()
+        for r in router_ifaces.keys():
+            project_router_balance(r)
+
+        # 3) Re-apply hard down constraint
+        for i in telemetry:
             if status.get(i) != 'up':
-                hardened_rx[i] = 0.0
-                hardened_tx[i] = 0.0
-                conf_rx[i] = max(conf_rx[i], 0.85)
-                conf_tx[i] = max(conf_tx[i], 0.85)
-            else:
-                hardened_rx[i] = max(0.0, orig_rx[i])
-                hardened_tx[i] = max(0.0, orig_tx[i])
-                conf_rx[i] = max(conf_rx[i], 0.6)
-                conf_tx[i] = max(conf_tx[i], 0.6)
-
-    # Stage 2: Router flow conservation with targeted, bundle-aware corrections
-    for r, ifs in router_ifaces.items():
-        if not ifs:
-            continue
-        up_ifs = [i for i in ifs if status.get(i) == 'up']
-        if len(up_ifs) < 2:
-            continue
-
-        sum_rx = sum(hardened_rx[i] for i in up_ifs)
-        sum_tx = sum(hardened_tx[i] for i in up_ifs)
-        denom = max(1.0, sum_rx, sum_tx)
-        imbalance = (sum_rx - sum_tx)  # positive means rx > tx
-        rel_gap = abs(imbalance) / denom
-
-        # Adaptive router tolerance based on number of active interfaces
-        n_active = len(up_ifs)
-        tau_router = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active)) ** 0.5))
-        if rel_gap <= tau_router:
-            continue
-
-        # Expected-penalty router-side selection with dominance awareness
-        def side_penalty(side: str) -> float:
-            vals = [(i, (hardened_rx[i] if side == 'rx' else hardened_tx[i]),
-                     clamp01(conf_rx[i] if side == 'rx' else conf_tx[i]))
-                    for i in up_ifs]
-            # weights w_i = (1 - conf_i) * rate_i
-            w = {i: (1.0 - c) * max(v, ZERO_THRESH) for (i, v, c) in vals}
-            total_w = sum(w.values()) or 1.0
-            # Focus subset covering WEIGHT_FOCUS
-            order = sorted(up_ifs, key=lambda x: w[x], reverse=True)
-            focus: List[str] = []
-            acc_w = 0.0
-            for i2 in order:
-                if acc_w / total_w >= WEIGHT_FOCUS:
-                    break
-                focus.append(i2)
-                acc_w += w[i2]
-            if not focus:
-                focus = list(up_ifs)
-                acc_w = total_w
-            # dominance cap in focus
-            cap_per = DOMINANCE_CAP * acc_w
-            eff_w = {i3: min(w[i3], cap_per) for i3 in focus}
-            eff_total = sum(eff_w.values()) or 1.0
-            # HHI for focus
-            hhi = sum((eff_w[i4] / eff_total) ** 2 for i4 in focus)
-
-            # Simulate two-tier scaling using current weights
-            delta = (-imbalance if side == 'rx' else imbalance)
-            # Per spec: k = delta/(0.6·Σ(rate_i·w_i))
-            denom_k = 0.0
-            for i5 in focus:
-                vi = hardened_rx[i5] if side == 'rx' else hardened_tx[i5]
-                denom_k += vi * eff_w[i5]
-            k = 0.0 if denom_k == 0.0 else delta / (0.6 * denom_k)
-            penalty = 0.0
-            for i6 in focus:
-                vi = hardened_rx[i6] if side == 'rx' else hardened_tx[i6]
-                ci = clamp01(conf_rx[i6] if side == 'rx' else conf_tx[i6])
-                # clip_hi(conf_i) = 1.12 for conf < 0.70 else 1.10
-                clip_hi = 1.12 if ci < 0.70 else 1.10
-                scale_sim = 1.0 + 0.6 * k * eff_w[i6]
-                scale_sim = max(0.90, min(clip_hi, scale_sim))
-                penalty += abs(scale_sim - 1.0) + 0.5 * (1.0 - ci)
-            penalty += 0.05 * hhi
-            return penalty
-
-        pen_rx = side_penalty('rx')
-        pen_tx = side_penalty('tx')
-        if pen_rx + 1e-9 < 0.95 * (pen_tx + 1e-9):
-            adjust_side = 'rx'
-        elif pen_tx + 1e-9 < 0.95 * (pen_rx + 1e-9):
-            adjust_side = 'tx'
-        else:
-            # Fallback to lower aggregate confidence
-            avg_rx_conf = sum(conf_rx[i] for i in up_ifs) / len(up_ifs)
-            avg_tx_conf = sum(conf_tx[i] for i in up_ifs) / len(up_ifs)
-            adjust_side = 'rx' if avg_rx_conf < avg_tx_conf else 'tx'
-        total_adjust = (-imbalance if adjust_side == 'rx' else imbalance) * DAMP_ROUTER
-
-        # Build per-interface values and confidences for the chosen side
-        side_vals = {i: (hardened_rx[i] if adjust_side == 'rx' else hardened_tx[i]) for i in up_ifs}
-        side_confs = {i: (conf_rx[i] if adjust_side == 'rx' else conf_tx[i]) for i in up_ifs}
-
-        # Group interfaces into bundles by (local_router, remote_router)
-        bundle_map: Dict[Tuple[Any, Any], List[str]] = {}
-        for i in up_ifs:
-            lr = local_router_of.get(i)
-            rr = remote_router_of.get(i)
-            if not rr:
-                p = peer_of.get(i)
-                if p:
-                    rr = local_router_of.get(p)
-            key = (lr, rr)
-            bundle_map.setdefault(key, []).append(i)
-
-        side_total = sum(side_vals.values())
-        # Identify majority bundles (>=50% of side traffic)
-        majority_bundles = []
-        for key, members in bundle_map.items():
-            s = sum(side_vals[m] for m in members)
-            if side_total > ZERO_EPS and s >= 0.5 * side_total:
-                majority_bundles.append((key, members, s))
-
-        # Build weights for distribution: w_i = (1 - conf) * max(val, ZERO_THRESH)
-        weights = {i: (1.0 - clamp01(side_confs[i])) * max(side_vals[i], ZERO_THRESH) + 1e-9 for i in up_ifs}
-        total_w = sum(weights.values())
-        if total_w <= 0:
-            weights = {i: 1.0 for i in up_ifs}
-            total_w = float(len(up_ifs))
-
-        # Focus adjustments on the lowest-confidence subset covering WEIGHT_FOCUS of total weight
-        sorted_ifs = sorted(up_ifs, key=lambda x: weights[x], reverse=True)
-        focus_set = []
-        acc = 0.0
-        for i in sorted_ifs:
-            if acc / max(total_w, 1e-12) >= WEIGHT_FOCUS:
-                break
-            focus_set.append(i)
-            acc += weights[i]
-        # Fallback: if empty due to zeros, use all
-        if not focus_set:
-            focus_set = list(up_ifs)
-            acc = total_w
-        focus_total_w = max(acc, 1e-9)
-
-        # Dominance-aware HHI on focus
-        sum_w_focus = sum(weights[i] for i in focus_set) or 1.0
-        shares = [(weights[i] / sum_w_focus) for i in focus_set]
-        hhi_focus = sum(s * s for s in shares)
-
-        # Helper: adaptive per-interface clip ceilings
-        def clip_hi_for_conf(ci: float) -> float:
-            if ci < 0.50:
-                return 1.15
-            if ci < 0.70:
-                # 1 + min(0.15, 0.10 + 0.05*(0.70 - ci))
-                return 1.0 + min(0.15, 0.10 + 0.05 * max(0.0, 0.70 - ci))
-            return 1.10
-
-        # Absolute dominance-aware cap for per-interface move
-        def abs_cap_for_delta(delta_total: float) -> float:
-            # (0.5 − 0.2·sqrt(HHI))·|delta|
-            return max(0.0, (0.5 - 0.2 * math.sqrt(max(0.0, hhi_focus)))) * abs(delta_total)
-
-        # Apply bundle-aware scaling if there is a majority bundle; else per-interface adjustments
-        if majority_bundles:
-            # Compute per-bundle weight from focused members only
-            bundle_weights: Dict[Tuple[Any, Any], float] = {}
-            bundle_members_focused: Dict[Tuple[Any, Any], List[str]] = {}
-            for key, members, _ in majority_bundles:
-                focused_members = [m for m in members if m in focus_set]
-                if not focused_members:
-                    continue
-                bundle_members_focused[key] = focused_members
-                bundle_weights[key] = sum(weights[m] for m in focused_members)
-
-            # First, scale majority bundles with a shared factor per bundle on focused members only
-            for key, members, _ in majority_bundles:
-                focused_members = bundle_members_focused.get(key, [])
-                if not focused_members:
-                    continue
-                w_g = bundle_weights.get(key, 0.0)
-                if w_g <= 0.0:
-                    continue
-                # Portion of total adjust to this bundle proportional to its focused weight
-                adj_g = total_adjust * (w_g / focus_total_w)
-                s_sum_focus = sum(side_vals[m] for m in focused_members)
-                if s_sum_focus <= ZERO_EPS:
-                    continue
-                target_sum = max(0.0, s_sum_focus + adj_g)
-                scale_g = target_sum / s_sum_focus
-                # Clip group scale to [1-BUNDLE_CLIP, 1+BUNDLE_CLIP]
-                clipped = False
-                if scale_g > 1.0 + BUNDLE_CLIP:
-                    scale_g = 1.0 + BUNDLE_CLIP
-                    clipped = True
-                elif scale_g < 1.0 - BUNDLE_CLIP:
-                    scale_g = 1.0 - BUNDLE_CLIP
-                    clipped = True
-                for m in focused_members:
-                    old = side_vals[m]
-                    new = max(0.0, scale_g * old)
-                    if adjust_side == 'rx':
-                        prev = hardened_rx[m]
-                        if prev > ZERO_EPS:
-                            scaled_rx_factor[m] *= (new / prev)
-                        hardened_rx[m] = new
-                        relc = abs(new - old) / max(1.0, abs(old))
-                        conf_rx[m] = clamp01(conf_rx[m] * (1.0 - 0.6 * relc))
-                        if clipped:
-                            clip_hit_rx[m] = True
-                    else:
-                        prev = hardened_tx[m]
-                        if prev > ZERO_EPS:
-                            scaled_tx_factor[m] *= (new / prev)
-                        hardened_tx[m] = new
-                        relc = abs(new - old) / max(1.0, abs(old))
-                        conf_tx[m] = clamp01(conf_tx[m] * (1.0 - 0.6 * relc))
-                        if clipped:
-                            clip_hit_tx[m] = True
-
-            # Then, adjust remaining non-majority interfaces individually using focused leftover weights
-            all_major_members = [m for _, members, _ in majority_bundles for m in members]
-            non_majority_all = [i for i in up_ifs if i not in all_major_members]
-            non_majority = [i for i in non_majority_all if i in focus_set]
-            nm_total_w = sum(weights[i] for i in non_majority)
-            if nm_total_w > 0:
-                # Dominance cap on per-interface share within this subset
-                cap_per = DOMINANCE_CAP * nm_total_w
-                eff_weights = {i: min(weights[i], cap_per) for i in non_majority}
-                eff_total_w = max(1e-9, sum(eff_weights.values()))
-                adj_nm = total_adjust * (nm_total_w / focus_total_w)
-                cap_abs_global = abs_cap_for_delta(adj_nm)
-                for i in non_majority:
-                    v_old = side_vals[i]
-                    ci = clamp01(side_confs[i])
-                    w_i = eff_weights[i] / eff_total_w
-                    adj_i_raw = adj_nm * w_i
-                    # Adaptive clip ceiling per-interface
-                    clip_hi = clip_hi_for_conf(ci)
-                    # decrease clip ceiling when dominated by few links
-                    clip_hi = 1.0 + (clip_hi - 1.0) * (1.0 - math.sqrt(max(0.0, hhi_focus)))
-                    cap_rel = (clip_hi - 1.0) * v_old
-                    adj_i = min(max(adj_i_raw, -cap_rel), cap_rel)
-                    # micro-tier absolute cap when conf < 0.50
-                    if ci < 0.50:
-                        adj_i = max(-0.35 * abs(adj_nm), min(0.35 * abs(adj_nm), adj_i))
-                    # dominance-aware absolute cap
-                    adj_i = max(-cap_abs_global, min(cap_abs_global, adj_i))
-                    v_new = max(0.0, v_old + adj_i)
-                    if adjust_side == 'rx':
-                        prev = hardened_rx[i]
-                        if prev > ZERO_EPS:
-                            scl = (v_new / prev)
-                            scaled_rx_factor[i] *= scl
-                            if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                                clip_hit_rx[i] = True
-                        hardened_rx[i] = v_new
-                        relc = abs(adj_i) / max(1.0, abs(v_old))
-                        conf_rx[i] = clamp01(conf_rx[i] * (1.0 - 0.6 * relc))
-                    else:
-                        prev = hardened_tx[i]
-                        if prev > ZERO_EPS:
-                            scl = (v_new / prev)
-                            scaled_tx_factor[i] *= scl
-                            if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                                clip_hit_tx[i] = True
-                        hardened_tx[i] = v_new
-                        relc = abs(adj_i) / max(1.0, abs(v_old))
-                        conf_tx[i] = clamp01(conf_tx[i] * (1.0 - 0.6 * relc))
-        else:
-            # No dominant bundle: targeted per-interface corrections only over focus_set
-            cap_per = DOMINANCE_CAP * focus_total_w
-            eff_weights = {i: min(weights[i], cap_per) for i in focus_set}
-            eff_total_w = max(1e-9, sum(eff_weights.values()))
-            cap_abs_global = abs_cap_for_delta(total_adjust)
-            for i in focus_set:
-                v_old = side_vals[i]
-                ci = clamp01(side_confs[i])
-                w_i = eff_weights[i] / eff_total_w
-                adj_i_raw = total_adjust * w_i
-                clip_hi = clip_hi_for_conf(ci)
-                clip_hi = 1.0 + (clip_hi - 1.0) * (1.0 - math.sqrt(max(0.0, hhi_focus)))
-                cap_rel = (clip_hi - 1.0) * v_old
-                adj_i = min(max(adj_i_raw, -cap_rel), cap_rel)
-                if ci < 0.50:
-                    adj_i = max(-0.35 * abs(total_adjust), min(0.35 * abs(total_adjust), adj_i))
-                adj_i = max(-cap_abs_global, min(cap_abs_global, adj_i))
-                v_new = max(0.0, v_old + adj_i)
-                if adjust_side == 'rx':
-                    prev = hardened_rx[i]
-                    if prev > ZERO_EPS:
-                        scl = (v_new / prev)
-                        scaled_rx_factor[i] *= scl
-                        if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                            clip_hit_rx[i] = True
-                    hardened_rx[i] = v_new
-                    relc = abs(adj_i) / max(1.0, abs(v_old))
-                    conf_rx[i] = clamp01(conf_rx[i] * (1.0 - 0.6 * relc))
-                else:
-                    prev = hardened_tx[i]
-                    if prev > ZERO_EPS:
-                        scl = (v_new / prev)
-                        scaled_tx_factor[i] *= scl
-                        if abs(scl - 1.0) >= PER_LINK_CLIP_BASE:
-                            clip_hit_tx[i] = True
-                    hardened_tx[i] = v_new
-                    relc = abs(adj_i) / max(1.0, abs(v_old))
-                    conf_tx[i] = clamp01(conf_tx[i] * (1.0 - 0.6 * relc))
-
-    # Stage 2.5: Post-router soft-zero stabilization and residual computation for re-sync attenuation
-    router_residual_mid: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        ups = [i for i in ifs if status.get(i) == 'up']
-        if not ups:
-            router_residual_mid[r] = 0.0
-            continue
-        srx = sum(hardened_rx[i] for i in ups)
-        stx = sum(hardened_tx[i] for i in ups)
-        denomr = max(1.0, srx, stx)
-        router_residual_mid[r] = abs(srx - stx) / denomr
-
-    # Soft-zero stabilization: if link tiny and adjacent routers close to balanced, snap to zero
+                rx[i] = 0.0
+                tx[i] = 0.0
+
+    # Final soft-zero snap for tiny links when both adjacent routers are balanced
+    router_totals = router_sums()
     for a, b in link_pairs:
         if status.get(a) != 'up' or status.get(b) != 'up':
+            rx[a] = tx[a] = 0.0
+            rx[b] = tx[b] = 0.0
             continue
-        if max(hardened_rx[a], hardened_tx[a], hardened_rx[b], hardened_tx[b]) < 2.0 * ZERO_THRESH:
-            ra = local_router_of.get(a)
-            rb = local_router_of.get(b)
-            n_active_a = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-            n_active_b = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-            tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active_a)) ** 0.5))
-            tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, n_active_b)) ** 0.5))
-            if router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb:
-                hardened_rx[a] = hardened_tx[a] = hardened_rx[b] = hardened_tx[b] = 0.0
-                conf_rx[a] = max(conf_rx[a], 0.95)
-                conf_tx[a] = max(conf_tx[a], 0.95)
-                conf_rx[b] = max(conf_rx[b], 0.95)
-                conf_tx[b] = max(conf_tx[b], 0.95)
-
-    # Stage 3: Confidence-gap-proportional re-sync with scaling guard and router-imbalance attenuation
-    def nudge_toward_mean(val_lo: float, val_hi: float, frac: float) -> float:
-        target = 0.5 * (val_lo + val_hi)
-        return val_lo + frac * (target - val_lo)
-
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-
-        # Attenuation from local router imbalances
+
         ra = local_router_of.get(a)
         rb = local_router_of.get(b)
-        att = clamp01(1.0 - max(router_residual_mid.get(ra, 0.0), router_residual_mid.get(rb, 0.0)))
-
-        # Direction 1: a.tx vs b.rx
-        a_tx, b_rx = hardened_tx[a], hardened_rx[b]
-        if max(a_tx, b_rx) > ZERO_EPS:
-            d1 = rel_diff(a_tx, b_rx)
-            tau1 = adaptive_tau(a_tx, b_rx)
-            if d1 > tau1:
-                ca, cb = conf_tx.get(a, 0.6), conf_rx.get(b, 0.6)
-                gap_norm = clamp01((d1 - tau1) / max(tau1, 1e-9))
-                # Saturating mismatch-proportional gain
-                f_base = 0.4 * (1.0 / (1.0 + math.exp(-5.0 * (gap_norm - 0.5))))
-                f_base *= att
-                moved = False
-                # Prefer moving the higher-confidence peer whose target dir hasn't been strongly scaled
-                if ca >= cb and abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = b_rx
-                        target = a_tx
-                        step = nudge_toward_mean(old, target, f)
-                        # cap absolute move per direction
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_rx[b] = new
-                        relc = rel_diff(new, old)
-                        conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.3 * relc))
-                        moved = True
-                elif cb > ca and abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = a_tx
-                        target = b_rx
-                        step = nudge_toward_mean(old, target, f)
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_tx[a] = new
-                        relc = rel_diff(new, old)
-                        conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.3 * relc))
-                        moved = True
-                # bilateral micro-step when both sides low-confidence and routers within tolerance
-                if not moved and ca < 0.70 and cb < 0.70:
-                    na = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-                    nb = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-                    tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, na)) ** 0.5))
-                    tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, nb)) ** 0.5))
-                    if router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb:
-                        f_bi = min(0.10, 0.5 * gap_norm) * att
-                        if f_bi > 0.0:
-                            old_a = a_tx; old_b = b_rx
-                            tgt = 0.5 * (old_a + old_b)
-                            cap_a = RESYNC_PER_DIR_CAP * max(old_a, tgt, 1.0)
-                            cap_b = RESYNC_PER_DIR_CAP * max(old_b, tgt, 1.0)
-                            new_a = old_a + clamp01(f_bi) * (tgt - old_a)
-                            new_b = old_b + clamp01(f_bi) * (tgt - old_b)
-                            new_a = max(0.0, min(old_a + cap_a, max(old_a - cap_a, new_a)))
-                            new_b = max(0.0, min(old_b + cap_b, max(old_b - cap_b, new_b)))
-                            hardened_tx[a] = new_a
-                            hardened_rx[b] = new_b
-                            conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.2 * rel_diff(new_a, old_a)))
-                            conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.2 * rel_diff(new_b, old_b)))
-
-        # Direction 2: a.rx vs b.tx
-        a_rx, b_tx = hardened_rx[a], hardened_tx[b]
-        if max(a_rx, b_tx) > ZERO_EPS:
-            d2 = rel_diff(a_rx, b_tx)
-            tau2 = adaptive_tau(a_rx, b_tx)
-            if d2 > tau2:
-                ca, cb = conf_rx.get(a, 0.6), conf_tx.get(b, 0.6)
-                gap_norm = clamp01((d2 - tau2) / max(tau2, 1e-9))
-                f_base = 0.4 * (1.0 / (1.0 + math.exp(-5.0 * (gap_norm - 0.5))))
-                f_base *= clamp01(1.0 - max(router_residual_mid.get(ra, 0.0), router_residual_mid.get(rb, 0.0)))
-                moved = False
-                if ca >= cb and abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = b_tx
-                        target = a_rx
-                        step = nudge_toward_mean(old, target, f)
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_tx[b] = new
-                        relc = rel_diff(new, old)
-                        conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.3 * relc))
-                        moved = True
-                elif cb > ca and abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
-                    f = min(RESYNC_MAX_F, f_base)
-                    if f > 0.0:
-                        old = a_rx
-                        target = b_tx
-                        step = nudge_toward_mean(old, target, f)
-                        cap_abs = RESYNC_PER_DIR_CAP * max(target, old, 1.0)
-                        step = max(0.0, min(old + cap_abs, max(0.0, step)))
-                        step = max(0.0, max(old - cap_abs, step))
-                        new = step
-                        hardened_rx[a] = new
-                        relc = rel_diff(new, old)
-                        conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.3 * relc))
-                        moved = True
-                if not moved and ca < 0.70 and cb < 0.70:
-                    na = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-                    nb = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-                    tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, na)) ** 0.5))
-                    tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, nb)) ** 0.5))
-                    if router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb:
-                        f_bi = min(0.10, 0.5 * gap_norm) * clamp01(1.0 - max(router_residual_mid.get(ra, 0.0), router_residual_mid.get(rb, 0.0)))
-                        if f_bi > 0.0:
-                            old_a = a_rx; old_b = b_tx
-                            tgt = 0.5 * (old_a + old_b)
-                            cap_a = RESYNC_PER_DIR_CAP * max(old_a, tgt, 1.0)
-                            cap_b = RESYNC_PER_DIR_CAP * max(old_b, tgt, 1.0)
-                            new_a = old_a + clamp01(f_bi) * (tgt - old_a)
-                            new_b = old_b + clamp01(f_bi) * (tgt - old_b)
-                            new_a = max(0.0, min(old_a + cap_a, max(old_a - cap_a, new_a)))
-                            new_b = max(0.0, min(old_b + cap_b, max(old_b - cap_b, new_b)))
-                            hardened_rx[a] = new_a
-                            hardened_tx[b] = new_b
-                            conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.2 * rel_diff(new_a, old_a)))
-                            conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.2 * rel_diff(new_b, old_b)))
-
-    # Stage 3.6: Two-pass, saturating micro re-sync for stubborn residuals
-    # Only when both adjacent routers are within tolerance; adjust lower-confidence side,
-    # skip any interface flagged strong_scaled or clip-hit in Stage 2, and cap per-move to ±1% of local ref.
-    def routers_balanced(i_a: str, i_b: str) -> bool:
-        ra = local_router_of.get(i_a)
-        rb = local_router_of.get(i_b)
-        na = len([i for i in router_ifaces.get(ra, []) if status.get(i) == 'up'])
-        nb = len([i for i in router_ifaces.get(rb, []) if status.get(i) == 'up'])
-        tau_ra = min(0.07, max(0.03, 0.05 * (2.0 / max(2, na)) ** 0.5))
-        tau_rb = min(0.07, max(0.03, 0.05 * (2.0 / max(2, nb)) ** 0.5))
-        return router_residual_mid.get(ra, 0.0) <= tau_ra and router_residual_mid.get(rb, 0.0) <= tau_rb
-
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        if not routers_balanced(a, b):
-            continue
-
-        # Direction 1: a.tx vs b.rx
-        a_tx, b_rx = hardened_tx[a], hardened_rx[b]
-        if max(a_tx, b_rx) > ZERO_EPS:
-            d1 = rel_diff(a_tx, b_rx)
-            tau1 = adaptive_tau(a_tx, b_rx)
-            if d1 > 1.5 * tau1:
-                ca, cb = conf_tx.get(a, 0.6), conf_rx.get(b, 0.6)
-                # choose lower-confidence side that didn't hit clip/strong scaling
-                can_move_b = (not clip_hit_rx.get(b, False)) and (abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                can_move_a = (not clip_hit_tx.get(a, False)) and (abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                move_b = (cb <= ca) and can_move_b
-                move_a = (ca < cb) and can_move_a
-                # fallback: if preferred side blocked, try the other if allowed
-                if not move_b and not move_a:
-                    move_b = can_move_b
-                    move_a = (not move_b) and can_move_a
-                gap_norm = clamp01((d1 - tau1) / max(tau1, 1e-9))
-                f2 = RESYNC2_GAIN * min(0.20, gap_norm)
-                if move_b and f2 > 0.0:
-                    old = b_rx
-                    target = a_tx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_rx[b] = new
-                    # modest confidence attenuation
-                    conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.15 * rel_diff(new, old)))
-                elif move_a and f2 > 0.0:
-                    old = a_tx
-                    target = b_rx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_tx[a] = new
-                    conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.15 * rel_diff(new, old)))
-
-        # Direction 2: a.rx vs b.tx
-        a_rx, b_tx = hardened_rx[a], hardened_tx[b]
-        if max(a_rx, b_tx) > ZERO_EPS:
-            d2 = rel_diff(a_rx, b_tx)
-            tau2 = adaptive_tau(a_rx, b_tx)
-            if d2 > 1.5 * tau2:
-                ca, cb = conf_rx.get(a, 0.6), conf_tx.get(b, 0.6)
-                can_move_b = (not clip_hit_tx.get(b, False)) and (abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                can_move_a = (not clip_hit_rx.get(a, False)) and (abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD)
-                move_b = (cb <= ca) and can_move_b
-                move_a = (ca < cb) and can_move_a
-                if not move_b and not move_a:
-                    move_b = can_move_b
-                    move_a = (not move_b) and can_move_a
-                gap_norm = clamp01((d2 - tau2) / max(tau2, 1e-9))
-                f2 = RESYNC2_GAIN * min(0.20, gap_norm)
-                if move_b and f2 > 0.0:
-                    old = b_tx
-                    target = a_rx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_tx[b] = new
-                    conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.15 * rel_diff(new, old)))
-                elif move_a and f2 > 0.0:
-                    old = a_rx
-                    target = b_tx
-                    step = nudge_toward_mean(old, target, f2)
-                    cap_abs2 = RESYNC2_CAP_FRAC * max(old, 1.0)
-                    new = max(0.0, min(old + cap_abs2, max(old - cap_abs2, step)))
-                    hardened_rx[a] = new
-                    conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.15 * rel_diff(new, old)))
-
-    # Stage 3.8: Dispersion-aware bundle finishing with per-router zero-sum enforcement
-    # Build direction-aware bundles: group by (local_router, remote_router)
-    dir1_groups: Dict[Tuple[Any, Any], List[Tuple[str, str]]] = {}
-    dir2_groups: Dict[Tuple[Any, Any], List[Tuple[str, str]]] = {}
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        ra = local_router_of.get(a)
-        rb = local_router_of.get(b)
-        dir1_groups.setdefault((ra, rb), []).append((a, b))   # a.tx vs b.rx
-        dir2_groups.setdefault((rb, ra), []).append((b, a))   # b.tx vs a.rx
-
-    def huber_weight(e_vals: List[float]) -> List[float]:
-        if not e_vals:
-            return []
-        med = median(e_vals)
-        mad = median([abs(x - med) for x in e_vals]) + 1e-12
-        k = 1.5 * mad
-        w = []
-        for e in e_vals:
-            ae = abs(e - med)
-            if ae <= k:
-                w.append(1.0)
-            else:
-                w.append(k / ae)
-        return w
-
-    def bundle_finish(groups: Dict[Tuple[Any, Any], List[Tuple[str, str]]]) -> None:
-        for (ra, rb), items in groups.items():
-            usable_idx = []
-            e_vals: List[float] = []
-            rels: List[float] = []
-            rates: List[float] = []
-            for idx, (x, y) in enumerate(items):
-                if status.get(x) != 'up' or status.get(y) != 'up':
-                    continue
-                vtx = hardened_tx.get(x, 0.0)
-                vrx = hardened_rx.get(y, 0.0)
-                if max(vtx, vrx) < ZERO_THRESH:
-                    continue
-                e = vtx - vrx
-                usable_idx.append(idx)
-                e_vals.append(e)
-                rels.append(rel_diff(vtx, vrx))
-                rates.append(max(vtx, vrx))
-            m = len(usable_idx)
-            if m < 2:
-                continue
-            # Robust center
-            e_med = median(e_vals)
-            # Gamma scaled by dispersion
-            rel_med = median(rels)
-            tau = TAU_H_BASE
-            if rel_med <= ZERO_EPS:
-                continue
-            gamma = min(FINISH_GAMMA_MAX, 0.5 * tau / max(rel_med, 1e-9))
-            # Huber weights
-            w_h = huber_weight(e_vals)
-            # Per-link clipping factor
-            c_clip = FINISH_C_LOW + (FINISH_C_HIGH - FINISH_C_LOW) * clamp01((m - 2) / 6.0)
-
-            # Compute deltas (zero-sum will be enforced per-router)
-            deltas = []
-            keys = []
-            for j, idx in enumerate(usable_idx):
-                a, b = items[idx]
-                rate = rates[j]
-                delta = -gamma * (e_vals[j] - e_med) * w_h[j]
-                cap = c_clip * max(rate, 1.0)
-                delta = max(-cap, min(cap, delta))
-                deltas.append(delta)
-                keys.append((a, b))
-            # Enforce per-router zero-sum: subtract mean delta per local router in this direction
-            # Compute per-router means (here only ra is local router for all in this group)
-            mean_delta = sum(deltas) / len(deltas)
-            deltas = [d - mean_delta for d in deltas]
-
-            # Apply
-            for (a, b), delta in zip(keys, deltas):
-                if abs(delta) <= ZERO_EPS:
-                    continue
-                prev_tx = hardened_tx[a]
-                prev_rx = hardened_rx[b]
-                new_tx = max(0.0, prev_tx + delta)
-                new_rx = max(0.0, prev_rx - delta)
-                if prev_tx > ZERO_EPS:
-                    scaled_tx_factor[a] *= (new_tx / prev_tx)
-                if prev_rx > ZERO_EPS:
-                    scaled_rx_factor[b] *= (new_rx / prev_rx)
-                hardened_tx[a] = new_tx
-                hardened_rx[b] = new_rx
-                # Light confidence adjustment
-                relc_tx = rel_diff(new_tx, prev_tx)
-                relc_rx = rel_diff(new_rx, prev_rx)
-                conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.2 * relc_tx))
-                conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.2 * relc_rx))
-
-    bundle_finish(dir1_groups)
-    bundle_finish(dir2_groups)
-
-    # Enforce status down => zero as a final safety
+        srx_a, stx_a, na = router_totals.get(ra, (0.0, 0.0, 0))
+        srx_b, stx_b, nb = router_totals.get(rb, (0.0, 0.0, 0))
+        bal_a = abs(srx_a - stx_a) / max(1.0, srx_a, stx_a) <= router_tau(na)
+        bal_b = abs(srx_b - stx_b) / max(1.0, srx_b, stx_b) <= router_tau(nb)
+
+        if bal_a and bal_b and max(rx[a], tx[a], rx[b], tx[b]) < LINK_ZERO_SNAP * ZERO_THRESH:
+            rx[a] = tx[a] = 0.0
+            rx[b] = tx[b] = 0.0
+
+    # Confidence computation
+    # Router residuals after all adjustments
+    router_residual: Dict[str, float] = {}
+    for r, (srx, stx, nup) in router_totals.items():
+        denom = max(1.0, srx, stx)
+        router_residual[r] = abs(srx - stx) / denom if denom > 0 else 0.0
+
+    # Base confidences per direction from three terms:
+    #  - measurement change
+    #  - link residual (vs. peer opposite dir)
+    #  - router residual
+    conf_rx: Dict[str, float] = {}
+    conf_tx: Dict[str, float] = {}
+
     for i in telemetry:
-        if status.get(i) != 'up':
-            hardened_rx[i] = 0.0
-            hardened_tx[i] = 0.0
-            conf_rx[i] = max(conf_rx[i], 0.85)
-            conf_tx[i] = max(conf_tx[i], 0.85)
-
-    # Compute router residuals after all adjustments (for confidence calibration)
-    router_residual: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        up_ifs = [i for i in ifs if status.get(i) == 'up']
-        if not up_ifs:
-            router_residual[r] = 0.0
-            continue
-        sum_rx = sum(hardened_rx[i] for i in up_ifs)
-        sum_tx = sum(hardened_tx[i] for i in up_ifs)
-        denom = max(1.0, sum_rx, sum_tx)
-        router_residual[r] = abs(sum_rx - sum_tx) / denom
-
-    # Stage 4: Confidence calibration with stability, bundle-consistency, scale penalty, and peer smoothing
-    # Pre-compute router totals per direction for stability term
-    router_sum_rx: Dict[str, float] = {}
-    router_sum_tx: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        ups = [i for i in ifs if status.get(i) == 'up']
-        router_sum_rx[r] = sum(hardened_rx.get(i, 0.0) for i in ups)
-        router_sum_tx[r] = sum(hardened_tx.get(i, 0.0) for i in ups)
-
-    # Pre-compute bundle median residual per link for bundle-consistency
-    bundle_e_median_tx: Dict[str, float] = {}
-    bundle_e_median_rx: Dict[str, float] = {}
-    # For each link pair, residual e = tx - peer.rx
-    # Build per-bundle arrays (local->remote for tx direction)
-    bundle_e_map_tx: Dict[Tuple[Any, Any], List[float]] = {}
-    bundle_e_map_rx: Dict[Tuple[Any, Any], List[float]] = {}
-    for a, b in link_pairs:
-        if status.get(a) != 'up' or status.get(b) != 'up':
-            continue
-        ra = local_router_of.get(a)
-        rb = local_router_of.get(b)
-        e1 = hardened_tx[a] - hardened_rx[b]
-        e2 = hardened_tx[b] - hardened_rx[a]
-        bundle_e_map_tx.setdefault((ra, rb), []).append(e1)
-        bundle_e_map_rx.setdefault((rb, ra), []).append(e2)
-    bundle_e_med_tx: Dict[Tuple[Any, Any], float] = {k: median(v) for k, v in bundle_e_map_tx.items()}
-    bundle_e_med_rx: Dict[Tuple[Any, Any], float] = {k: median(v) for k, v in bundle_e_map_rx.items()}
-
-    def compute_conf(i: str) -> Tuple[float, float]:
+        # Measurement residuals
+        r_meas_rx = rel_diff(rx[i], orig_rx[i])
+        r_meas_tx = rel_diff(tx[i], orig_tx[i])
+
+        # Link residuals
         p = peer_of.get(i)
-        # Measurement residuals
-        r_meas_rx = rel_diff(hardened_rx[i], orig_rx[i])
-        r_meas_tx = rel_diff(hardened_tx[i], orig_tx[i])
-        # Link residuals
         if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
-            r_link_rx = rel_diff(hardened_rx[i], hardened_tx[p])
-            r_link_tx = rel_diff(hardened_tx[i], hardened_rx[p])
+            r_link_rx = rel_diff(rx[i], tx[p])  # my rx vs peer tx
+            r_link_tx = rel_diff(tx[i], rx[p])  # my tx vs peer rx
         else:
             r_link_rx = 0.2
             r_link_tx = 0.2
+
         # Router residual
         rtr = router_residual.get(local_router_of.get(i), 0.0)
-        # Base confidence blend
-        base_rx = 1.0 - (0.53 * r_meas_rx + 0.33 * r_link_rx + 0.14 * rtr)
-        base_tx = 1.0 - (0.53 * r_meas_tx + 0.33 * r_link_tx + 0.14 * rtr)
-        base_rx = clamp01(base_rx)
-        base_tx = clamp01(base_tx)
-
-        # Scale-factor term (penalize big routed adjustments)
-        alpha_rx = abs(scaled_rx_factor.get(i, 1.0) - 1.0)
-        alpha_tx = abs(scaled_tx_factor.get(i, 1.0) - 1.0)
-        scale_term_rx = clamp01(1.0 - min(0.5, alpha_rx))
-        scale_term_tx = clamp01(1.0 - min(0.5, alpha_tx))
-
-        c_rx = clamp01(0.90 * base_rx + 0.10 * scale_term_rx)
-        c_tx = clamp01(0.90 * base_tx + 0.10 * scale_term_tx)
-
-        # Stability term: interfaces that dominate router totals get a reduction
-        r_id = local_router_of.get(i)
-        sum_r_rx = max(1.0, router_sum_rx.get(r_id, 1.0))
-        sum_r_tx = max(1.0, router_sum_tx.get(r_id, 1.0))
-        share_rx = hardened_rx[i] / sum_r_rx
-        share_tx = hardened_tx[i] / sum_r_tx
-        stab_rx = clamp01(1.0 - 0.5 * share_rx)
-        stab_tx = clamp01(1.0 - 0.5 * share_tx)
-        c_rx = clamp01(c_rx + 0.05 * stab_rx)
-        c_tx = clamp01(c_tx + 0.05 * stab_tx)
-
-        # Bundle-consistency term: distance from bundle median residual
-        p = peer_of.get(i)
-        if p and p in telemetry and status.get(i) == 'up' and status.get(p) == 'up':
-            lr = local_router_of.get(i)
-            rr = local_router_of.get(p)
-            e_tx = hardened_tx[i] - hardened_rx[p]
-            e_rx = hardened_rx[i] - hardened_tx[p]
-            med_tx = bundle_e_med_tx.get((lr, rr), 0.0)
-            med_rx = bundle_e_med_rx.get((lr, rr), 0.0)
-            bcons_tx = clamp01(1.0 - abs(e_tx - med_tx) / (abs(med_tx) + max(hardened_tx[i], 1.0)))
-            bcons_rx = clamp01(1.0 - abs(e_rx - med_rx) / (abs(med_rx) + max(hardened_rx[i], 1.0)))
-            c_tx = clamp01(c_tx + 0.06 * bcons_tx)
-            c_rx = clamp01(c_rx + 0.06 * bcons_rx)
+
+        # Confidence as 1 − weighted residual blend
+        c_rx = 1.0 - (0.52 * r_meas_rx + 0.33 * r_link_rx + 0.15 * rtr)
+        c_tx = 1.0 - (0.52 * r_meas_tx + 0.33 * r_link_tx + 0.15 * rtr)
+        # Enforce floors/ceilings
+        conf_rx[i] = clamp01(c_rx)
+        conf_tx[i] = clamp01(c_tx)
 
         # If interface is down, zero is a strong invariant; raise confidence floor
         if status.get(i) != 'up':
-            c_rx = max(c_rx, 0.85)
-            c_tx = max(c_tx, 0.85)
-        return c_rx, c_tx
-
-    # Preliminary confidences
-    for i in telemetry:
-        cr, ct = compute_conf(i)
-        conf_rx[i], conf_tx[i] = cr, ct
-
-    # Apply penalties for clip/strong scaling and check if router imbalance worsened
-    for i in telemetry:
-        r_id = local_router_of.get(i)
-        # If anyone hit clip or strong scaling, small penalty
-        if abs(scaled_rx_factor.get(i, 1.0) - 1.0) >= PER_LINK_CLIP_BASE or clip_hit_rx.get(i, False):
-            conf_rx[i] = clamp01(conf_rx[i] * CLIP_HIT_PENALTY)
-        if abs(scaled_tx_factor.get(i, 1.0) - 1.0) >= PER_LINK_CLIP_BASE or clip_hit_tx.get(i, False):
-            conf_tx[i] = clamp01(conf_tx[i] * CLIP_HIT_PENALTY)
-        # Extra tiny penalty if both clip and router got worse (mid to final)
-        # Compute local notion: if final router residual > mid residual
-        if router_residual.get(r_id, 0.0) > router_residual_mid.get(r_id, 0.0):
-            if clip_hit_rx.get(i, False):
-                conf_rx[i] = clamp01(conf_rx[i] * 0.97)
-            if clip_hit_tx.get(i, False):
-                conf_tx[i] = clamp01(conf_tx[i] * 0.97)
-
-    # Router-aware smoothing when |scale - 1| < 0.05
-    router_mean_conf_rx: Dict[str, float] = {}
-    router_mean_conf_tx: Dict[str, float] = {}
-    for r, ifs in router_ifaces.items():
-        ups = [i for i in ifs if i in telemetry and status.get(i) == 'up']
-        if ups:
-            router_mean_conf_rx[r] = sum(conf_rx[i] for i in ups) / len(ups)
-            router_mean_conf_tx[r] = sum(conf_tx[i] for i in ups) / len(ups)
-    for i in telemetry:
-        r = local_router_of.get(i)
-        if abs(scaled_rx_factor.get(i, 1.0) - 1.0) < 0.05 and r in router_mean_conf_rx:
-            conf_rx[i] = clamp01(0.85 * conf_rx[i] + 0.15 * router_mean_conf_rx[r])
-        if abs(scaled_tx_factor.get(i, 1.0) - 1.0) < 0.05 and r in router_mean_conf_tx:
-            conf_tx[i] = clamp01(0.85 * conf_tx[i] + 0.15 * router_mean_conf_tx[r])
-
-    # Peer smoothing (order-independent via staged update)
+            conf_rx[i] = max(conf_rx[i], 0.85)
+            conf_tx[i] = max(conf_tx[i], 0.85)
+
+    # Peer smoothing for confidences (order-independent staging)
     new_conf_rx = dict(conf_rx)
     new_conf_tx = dict(conf_tx)
     for a, b in link_pairs:
         if status.get(a) == 'up' and status.get(b) == 'up':
             new_conf_tx[a] = clamp01((1.0 - PEER_SMOOTH) * conf_tx[a] + PEER_SMOOTH * conf_rx[b])
             new_conf_rx[b] = clamp01((1.0 - PEER_SMOOTH) * conf_rx[b] + PEER_SMOOTH * conf_tx[a])
+
             new_conf_rx[a] = clamp01((1.0 - PEER_SMOOTH) * conf_rx[a] + PEER_SMOOTH * conf_tx[b])
             new_conf_tx[b] = clamp01((1.0 - PEER_SMOOTH) * conf_tx[b] + PEER_SMOOTH * conf_rx[a])
-    conf_rx, conf_tx = new_conf_rx, new_conf_tx
-
-    # Untouched boost: minimal change (<1%) and good final symmetry on link
-    for i in telemetry:
-        p = peer_of.get(i)
-        if not p or p not in telemetry or status.get(i) != 'up' or status.get(p) != 'up':
-            continue
-        # RX direction
-        if rel_diff(hardened_rx[i], orig_rx[i]) < 0.01:
-            if rel_diff(hardened_rx[i], hardened_tx[p]) <= adaptive_tau(hardened_rx[i], hardened_tx[p]):
-                conf_rx[i] = min(0.98, conf_rx[i] + UNTOUCHED_BOOST)
-        # TX direction
-        if rel_diff(hardened_tx[i], orig_tx[i]) < 0.01:
-            if rel_diff(hardened_tx[i], hardened_rx[p]) <= adaptive_tau(hardened_tx[i], hardened_rx[p]):
-                conf_tx[i] = min(0.98, conf_tx[i] + UNTOUCHED_BOOST)
-
-    # Assemble final result
+    conf_rx = new_conf_rx
+    conf_tx = new_conf_tx
+
+    # Assemble final result in required tuple format
     result: Dict[str, Dict[str, Tuple]] = {}
     for i, data in telemetry.items():
         my_status = status.get(i, 'unknown')
         peer_id = peer_of.get(i)
-        # Status confidence: do not flip, but penalize inconsistent peer or down+nonzero readings
+        # Status confidence: do not flip, penalize inconsistent peer or down+nonzero readings
         status_conf = 1.0
         if peer_id and peer_id in telemetry:
             if telemetry[peer_id].get('interface_status', 'unknown') != my_status:
                 status_conf = 0.6
         if my_status == 'down' and (orig_rx.get(i, 0.0) > ZERO_EPS or orig_tx.get(i, 0.0) > ZERO_EPS):
             status_conf = min(status_conf, 0.6)
 
         repaired: Dict[str, Any] = {}
-        repaired['rx_rate'] = (orig_rx.get(i, 0.0), max(0.0, hardened_rx.get(i, 0.0)), clamp01(conf_rx.get(i, 0.6)))
-        repaired['tx_rate'] = (orig_tx.get(i, 0.0), max(0.0, hardened_tx.get(i, 0.0)), clamp01(conf_tx.get(i, 0.6)))
+        repaired['rx_rate'] = (orig_rx.get(i, 0.0), max(0.0, rx.get(i, 0.0)), clamp01(conf_rx.get(i, 0.6)))
+        repaired['tx_rate'] = (orig_tx.get(i, 0.0), max(0.0, tx.get(i, 0.0)), clamp01(conf_tx.get(i, 0.6)))
         repaired['interface_status'] = (my_status, my_status, status_conf)
 
         # Copy metadata unchanged
         repaired['connected_to'] = data.get('connected_to')
         repaired['local_router'] = data.get('local_router')
         repaired['remote_router'] = data.get('remote_router')
 
         result[i] = repaired
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")