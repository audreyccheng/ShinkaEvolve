<NAME>
dominance_fix_confadaptive_resync
</NAME>

<DESCRIPTION>
I propose three targeted improvements aimed at increasing counter repair accuracy and confidence calibration while preserving robustness:

1) Fix dominance cap logic in the router WLS projection. The current implementation mistakenly increases inverse weight for an over-dominant variable, which actually increases its share of the correction. By reducing the inverse weight instead, we properly cap any single variable’s contribution. This should improve the distribution of corrections across interfaces, reducing over-corrections and improving both accuracy and calibration.

2) Add a symmetric low-confidence re-sync option. When both sides of a link direction have low confidence (<0.7) and the link remains mismatched, apply a cautious symmetric nudge toward the mean (default 12%), attenuated by router imbalance. This helps reduce persistent mismatches where neither side is trustworthy, improving repair accuracy without overstating confidence.

3) Use confidence-adaptive tolerances in re-sync. We adopt a tau that tightens when both sides are high-rate and high-confidence, and loosens when either side is low-rate or low-confidence. This reduces unnecessary nudging when already well-supported, and allows more tolerance to jitter in weak signals, improving calibration.

A small hyperparameter (SYM_RESYNC_F) is added for the symmetric re-sync magnitude. All changes are minimal and consistent with the current code structure.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    RESYNC_MAX_F = 0.40         # max fraction for one-sided nudge toward mean
    BUNDLE_DOM_FRAC = 0.60      # bundle dominance threshold on a side’s traffic
=======
    RESYNC_MAX_F = 0.40         # max fraction for one-sided nudge toward mean
    SYM_RESYNC_F = 0.12         # symmetric nudge when both sides have low confidence
    BUNDLE_DOM_FRAC = 0.60      # bundle dominance threshold on a side’s traffic
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        def apply_dominance_cap(deltas_in: List[float], invw_in: List[float]) -> List[float]:
            # Compute shares by absolute delta proportional to invw (since all deltas share same lam)
            for _ in range(3):
                absd = [abs(d) for d in deltas_in]
                total = sum(absd) + 1e-12
                shares = [d / total for d in absd]
                max_share = max(shares)
                if max_share <= DOMINANCE_CAP + 1e-6:
                    break
                k = shares.index(max_share)
                # Increase weight (decrease inv weight) for offender
                invw_in[k] *= (max_share / DOMINANCE_CAP)  # reduce its share
                # Recompute deltas with modified inverse weights
                denom_new = sum(invw_in)
                if denom_new <= 1e-12:
                    break
                lam_new = 2.0 * ax0 / denom_new
                lam_new *= DAMP_ROUTER
                deltas_in = [-(invw) * sgn * lam_new * 0.5 for sgn, invw in zip(signs, invw_in)]
            return deltas_in
=======
        def apply_dominance_cap(deltas_in: List[float], invw_in: List[float]) -> List[float]:
            # Compute shares by absolute delta proportional to invw (since all deltas share same lam)
            for _ in range(3):
                absd = [abs(d) for d in deltas_in]
                total = sum(absd) + 1e-12
                shares = [d / total for d in absd]
                max_share = max(shares)
                if max_share <= DOMINANCE_CAP + 1e-6:
                    break
                k = shares.index(max_share)
                # Shrink inverse weight for offender to reduce its share
                invw_in[k] *= max(0.5, DOMINANCE_CAP / max_share)
                # Recompute deltas with modified inverse weights
                denom_new = sum(invw_in)
                if denom_new <= 1e-12:
                    break
                lam_new = 2.0 * ax0 / denom_new
                lam_new *= DAMP_ROUTER
                deltas_in = [-(invw) * sgn * lam_new * 0.5 for sgn, invw in zip(signs, invw_in)]
            return deltas_in
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def nudge_toward_mean(val_lo: float, val_hi: float, frac: float) -> float:
        target = 0.5 * (val_lo + val_hi)
        return val_lo + frac * (target - val_lo)

    # Recompute router residuals for attenuation
    router_residual_final = compute_router_residuals(rx, tx)
=======
    def nudge_toward_mean(val_lo: float, val_hi: float, frac: float) -> float:
        target = 0.5 * (val_lo + val_hi)
        return val_lo + frac * (target - val_lo)

    def adaptive_tau_conf(v1: float, v2: float, c1: float, c2: float) -> float:
        # Confidence-aware tolerance: tighten when both sides are strong, loosen when weak
        if v1 >= 100.0 and v2 >= 100.0 and min(c1, c2) >= 0.80:
            return TAU_H_HIGH
        if v1 < ZERO_THRESH or v2 < ZERO_THRESH or min(c1, c2) < 0.70:
            return TAU_H_LOW
        return TAU_H_BASE

    # Recompute router residuals for attenuation
    router_residual_final = compute_router_residuals(rx, tx)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        # Direction 1: a.tx vs b.rx
        a_tx, b_rx = tx[a], rx[b]
        if max(a_tx, b_rx) > ZERO_EPS:
            d1 = rel_diff(a_tx, b_rx)
            tau1 = adaptive_tau(a_tx, b_rx)
            if d1 > tau1:
                ca, cb = conf_tx.get(a, 0.7), conf_rx.get(b, 0.7)
                if ca >= cb and abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, ca - cb)) * att
                    if f > 0.0:
                        old = b_rx
                        new = max(0.0, nudge_toward_mean(old, a_tx, f))
                        rx[b] = new
                        # confidence penalty proportional to relative movement
                        move_rel = rel_diff(new, old)
                        conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.3 * move_rel))
                elif cb > ca and abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, cb - ca)) * att
                    if f > 0.0:
                        old = a_tx
                        new = max(0.0, nudge_toward_mean(old, b_rx, f))
                        tx[a] = new
                        move_rel = rel_diff(new, old)
                        conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.3 * move_rel))
=======
        # Direction 1: a.tx vs b.rx
        a_tx, b_rx = tx[a], rx[b]
        if max(a_tx, b_rx) > ZERO_EPS:
            ca, cb = conf_tx.get(a, 0.7), conf_rx.get(b, 0.7)
            d1 = rel_diff(a_tx, b_rx)
            tau1 = adaptive_tau_conf(a_tx, b_rx, ca, cb)
            if d1 > tau1:
                if ca >= cb and abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, ca - cb)) * att
                    if f > 0.0:
                        old = b_rx
                        new = max(0.0, nudge_toward_mean(old, a_tx, f))
                        rx[b] = new
                        # confidence penalty proportional to relative movement
                        move_rel = rel_diff(new, old)
                        conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.3 * move_rel))
                elif cb > ca and abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, cb - ca)) * att
                    if f > 0.0:
                        old = a_tx
                        new = max(0.0, nudge_toward_mean(old, b_rx, f))
                        tx[a] = new
                        move_rel = rel_diff(new, old)
                        conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.3 * move_rel))
                else:
                    # Symmetric cautious nudge when both confidences are low
                    if ca < 0.70 and cb < 0.70 and \
                       abs(scaled_rx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD and \
                       abs(scaled_tx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                        f_sym = SYM_RESYNC_F * att
                        target = 0.5 * (a_tx + b_rx)
                        new_a_tx = max(0.0, a_tx + f_sym * (target - a_tx))
                        new_b_rx = max(0.0, b_rx + f_sym * (target - b_rx))
                        tx[a] = new_a_tx
                        rx[b] = new_b_rx
                        pen_a = rel_diff(new_a_tx, a_tx)
                        pen_b = rel_diff(new_b_rx, b_rx)
                        conf_tx[a] = clamp01(conf_tx[a] * (1.0 - 0.3 * pen_a))
                        conf_rx[b] = clamp01(conf_rx[b] * (1.0 - 0.3 * pen_b))
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
        # Direction 2: a.rx vs b.tx
        a_rx, b_tx = rx[a], tx[b]
        if max(a_rx, b_tx) > ZERO_EPS:
            d2 = rel_diff(a_rx, b_tx)
            tau2 = adaptive_tau(a_rx, b_tx)
            if d2 > tau2:
                ca, cb = conf_rx.get(a, 0.7), conf_tx.get(b, 0.7)
                if ca >= cb and abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, ca - cb)) * att
                    if f > 0.0:
                        old = b_tx
                        new = max(0.0, nudge_toward_mean(old, a_rx, f))
                        tx[b] = new
                        move_rel = rel_diff(new, old)
                        conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.3 * move_rel))
                elif cb > ca and abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, cb - ca)) * att
                    if f > 0.0:
                        old = a_rx
                        new = max(0.0, nudge_toward_mean(old, b_tx, f))
                        rx[a] = new
                        move_rel = rel_diff(new, old)
                        conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.3 * move_rel))
=======
        # Direction 2: a.rx vs b.tx
        a_rx, b_tx = rx[a], tx[b]
        if max(a_rx, b_tx) > ZERO_EPS:
            ca, cb = conf_rx.get(a, 0.7), conf_tx.get(b, 0.7)
            d2 = rel_diff(a_rx, b_tx)
            tau2 = adaptive_tau_conf(a_rx, b_tx, ca, cb)
            if d2 > tau2:
                if ca >= cb and abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, ca - cb)) * att
                    if f > 0.0:
                        old = b_tx
                        new = max(0.0, nudge_toward_mean(old, a_rx, f))
                        tx[b] = new
                        move_rel = rel_diff(new, old)
                        conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.3 * move_rel))
                elif cb > ca and abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                    f = min(RESYNC_MAX_F, max(0.0, cb - ca)) * att
                    if f > 0.0:
                        old = a_rx
                        new = max(0.0, nudge_toward_mean(old, b_tx, f))
                        rx[a] = new
                        move_rel = rel_diff(new, old)
                        conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.3 * move_rel))
                else:
                    # Symmetric cautious nudge when both confidences are low
                    if ca < 0.70 and cb < 0.70 and \
                       abs(scaled_tx_factor.get(b, 1.0) - 1.0) <= STRONG_SCALE_GUARD and \
                       abs(scaled_rx_factor.get(a, 1.0) - 1.0) <= STRONG_SCALE_GUARD:
                        f_sym = SYM_RESYNC_F * att
                        target = 0.5 * (a_rx + b_tx)
                        new_a_rx = max(0.0, a_rx + f_sym * (target - a_rx))
                        new_b_tx = max(0.0, b_tx + f_sym * (target - b_tx))
                        rx[a] = new_a_rx
                        tx[b] = new_b_tx
                        pen_a = rel_diff(new_a_rx, a_rx)
                        pen_b = rel_diff(new_b_tx, b_tx)
                        conf_rx[a] = clamp01(conf_rx[a] * (1.0 - 0.3 * pen_a))
                        conf_tx[b] = clamp01(conf_tx[b] * (1.0 - 0.3 * pen_b))
>>>>>>> REPLACE