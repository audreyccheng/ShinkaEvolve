<NAME>
beam_regret_vnd_oropt
</NAME>

<DESCRIPTION>
I introduce a small regret-guided beam during construction and enrich local search with Or-opt block moves. Specifically:
- Construction: Upgrade the regret-based insertion to a lightweight beam search. At each insertion layer, we expand partial sequences with best-position insertions for sampled transactions, then select the next beam using cost-first with a quota of high-regret candidates and enforce diversity by last-2 suffix signatures with duplicate pruning. In endgame (few remaining), we evaluate all remaining txns and all positions to avoid myopic placements.
- Local search: Add Or-opt block reinsertion for block sizes 2 and 3 in a VND-style loop, alongside existing adjacent swaps, single-item reinsertion, and sampled 2-opt. This helps relocate tightly coupled conflict blocks together, often reducing serialization delays.
- Elite management: Diversify elites by enforcing uniqueness on suffix length 2 (instead of only last element), improving recombination potential and avoiding convergence to similar endings.

These changes directly act on the objective (makespan via workload.get_opt_seq_cost) rather than proxies, broaden exploration where regret suggests high opportunity, and deepen exploitation via richer neighborhoods, yielding lower makespan without excessive runtime.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # ----------------------------
    # Parameters (adaptive)
    # ----------------------------
    elite_size = max(3, min(6, 2 + num_seqs // 3))
    seed_elite_singletons = max(2, min(6, int(num_seqs)))
    seed_random_additional = max(1, min(4, int((num_seqs + 1) // 3)))

    # Candidate sampling sizes
    k_txn_sample = min(16, max(8, 2 + int(1.5 * num_seqs)))  # txns per insertion
    k_pos_sample = min(10, max(6, 2 + int(1.2 * num_seqs)))  # positions per insertion
    rem_all_threshold = 14                                    # when few remain, consider all txns

    # Regret selection probability (exploration vs exploitation)
    regret_prob = 0.65

    # Local search parameters
    ls_adj_rounds_max = 2
    two_opt_trials = min(35, max(12, n // 3))
    reinsertion_pos_factor = 1.0  # multiplier for k_pos_sample

    # Iterated local search (ILS) / perturbation
    ils_rounds = max(2, min(5, 1 + num_seqs // 4))
    perturb_swap_count = max(2, min(6, 2 + num_seqs // 3))
    perturb_block_len = max(3, min(10, 3 + num_seqs // 2))

    # Large Neighborhood Search (LNS)
    lns_iters = max(2, min(6, 2 + num_seqs // 3))
    destroy_frac_range = (0.08, 0.18)
=======
    # ----------------------------
    # Parameters (adaptive)
    # ----------------------------
    elite_size = max(3, min(6, 2 + num_seqs // 3))
    seed_elite_singletons = max(2, min(6, int(num_seqs)))
    seed_random_additional = max(1, min(4, int((num_seqs + 1) // 3)))

    # Candidate sampling sizes
    k_txn_sample = min(16, max(8, 2 + int(1.5 * num_seqs)))  # txns per insertion
    k_pos_sample = min(10, max(6, 2 + int(1.2 * num_seqs)))  # positions per insertion
    rem_all_threshold = 14                                    # when few remain, consider all txns

    # Regret selection probability (exploration vs exploitation)
    regret_prob = 0.65

    # Small local beam for construction and diversity settings
    local_beam_width = max(3, min(6, int(num_seqs)))
    high_regret_quota_ratio = 0.3
    diversity_suffix_k = 2
    endgame_all_pos_threshold = max(6, min(12, num_seqs))     # when few remain, try all positions

    # Local search parameters
    ls_adj_rounds_max = 2
    two_opt_trials = min(35, max(12, n // 3))
    reinsertion_pos_factor = 1.0  # multiplier for k_pos_sample

    # Iterated local search (ILS) / perturbation
    ils_rounds = max(2, min(5, 1 + num_seqs // 4))
    perturb_swap_count = max(2, min(6, 2 + num_seqs // 3))
    perturb_block_len = max(3, min(10, 3 + num_seqs // 2))

    # Large Neighborhood Search (LNS)
    lns_iters = max(2, min(6, 2 + num_seqs // 3))
    destroy_frac_range = (0.08, 0.18)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def regret_insertion_build(seed_t=None):
        """Construct a schedule using regret-based insertion."""
        if seed_t is None:
            seed_t = random.randint(0, n - 1)
        seq = [seed_t]
        rem = set(all_txns)
        rem.remove(seed_t)

        # Add second transaction by trying prepend/append among sampled candidates
        if rem:
            cand_txns = list(rem)
            if len(cand_txns) > k_txn_sample:
                cand_txns = random.sample(cand_txns, k_txn_sample)
            best_c2 = float('inf')
            best_seq2 = None
            best_t2 = None
            for t in cand_txns:
                seq_a = [t] + seq
                c_a = seq_cost(seq_a)
                seq_b = seq + [t]
                c_b = seq_cost(seq_b)
                if c_a < best_c2:
                    best_c2 = c_a
                    best_seq2 = seq_a
                    best_t2 = t
                if c_b < best_c2:
                    best_c2 = c_b
                    best_seq2 = seq_b
                    best_t2 = t
            if best_seq2 is not None:
                seq = best_seq2
                rem.remove(best_t2)

        while rem:
            # Candidate transactions
            if len(rem) <= rem_all_threshold:
                cand_txns = list(rem)
            else:
                cand_txns = random.sample(list(rem), min(k_txn_sample, len(rem)))

            # For each candidate transaction, evaluate best and second-best positions
            best_overall = (float('inf'), None, None)  # cost, txn, new_seq
            best_by_regret = (float('-inf'), None, None)  # regret, txn, new_seq

            for t in cand_txns:
                pos_list = position_samples(len(seq))
                best_c, best_p, second_c = evaluate_best_two_positions(seq, t, pos_list)
                # Track pure best
                if best_c < best_overall[0]:
                    new_seq = seq[:best_p] + [t] + seq[best_p:]
                    best_overall = (best_c, t, new_seq)
                # Track regret (second - best)
                regret = second_c - best_c if second_c < float('inf') else (0.0)
                if regret > best_by_regret[0]:
                    new_seq_r = seq[:best_p] + [t] + seq[best_p:]
                    best_by_regret = (regret, t, new_seq_r)

            # Choose according to regret_prob
            pick_regret = (random.random() < regret_prob)
            chosen = best_by_regret if pick_regret and best_by_regret[1] is not None else best_overall
            if chosen[1] is None:
                # Fallback random append
                t = random.choice(tuple(rem))
                seq = seq + [t]
                rem.remove(t)
            else:
                seq = chosen[2]
                rem.remove(chosen[1])

        return seq
=======
    def regret_insertion_build(seed_t=None):
        """Construct a schedule using regret-guided insertion with a small beam and diversity."""
        if seed_t is None:
            seed_t = random.randint(0, n - 1)

        # Beam holds tuples: (seq, rem_set, cost)
        seq0 = [seed_t]
        rem0 = set(all_txns)
        rem0.remove(seed_t)
        beam = [(seq0, rem0, seq_cost(seq0))]

        # Add a second element by prepend/append across beam
        expansions = []
        for seq, rem, _ in beam:
            if not rem:
                expansions.append((seq, rem, seq_cost(seq), 0.0))
                continue
            cand_txns = list(rem)
            if len(cand_txns) > k_txn_sample:
                cand_txns = random.sample(cand_txns, k_txn_sample)
            for t in cand_txns:
                # Try prepend and append for early shaping
                for new_seq in ([t] + seq, seq + [t]):
                    c = seq_cost(new_seq)
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    expansions.append((new_seq, new_rem, c, 0.0))
        # Select initial beam by cost-diversity
        expansions.sort(key=lambda x: x[2])
        next_beam = []
        seen_sig = set()
        for s, r, c, _ in expansions:
            sig = tuple(s[-2:]) if len(s) >= 2 else tuple(s)
            if sig in seen_sig:
                continue
            seen_sig.add(sig)
            next_beam.append((s, r, c))
            if len(next_beam) >= local_beam_width:
                break
        if next_beam:
            beam = next_beam

        while True:
            # If all states are complete, stop
            if all(len(rem) == 0 for _, rem, _ in beam):
                break

            expansions = []
            seen_seqs = set()
            for seq, rem, _ in beam:
                if not rem:
                    expansions.append((seq, rem, seq_cost(seq), 0.0, None))
                    continue

                # Candidate transactions
                if len(rem) <= rem_all_threshold:
                    cand_txns = list(rem)
                else:
                    cand_txns = random.sample(list(rem), min(k_txn_sample, len(rem)))

                # Determine position policy (all vs sampled)
                use_all_pos = (len(rem) <= endgame_all_pos_threshold) or (len(seq) <= 18)
                pos_list_all = list(range(len(seq) + 1)) if use_all_pos else position_samples(len(seq))

                # For each candidate transaction, evaluate best and second-best positions
                for t in cand_txns:
                    best_c, best_p, second_c = evaluate_best_two_positions(seq, t, pos_list_all)
                    new_seq = seq[:best_p] + [t] + seq[best_p:]
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    regret = second_c - best_c if second_c < float('inf') else 0.0
                    key = tuple(new_seq)
                    if key in seen_seqs:
                        continue
                    seen_seqs.add(key)
                    expansions.append((new_seq, new_rem, best_c, regret, t))

            if not expansions:
                break

            # Rank expansions
            by_cost = sorted(expansions, key=lambda x: (x[2], -x[3]))
            by_regret = sorted(expansions, key=lambda x: (-x[3], x[2]))

            # Select next beam with diversity and regret quota
            base_quota = max(1, int(local_beam_width * (1.0 - high_regret_quota_ratio)))
            regret_quota = max(0, local_beam_width - base_quota)
            next_beam = []
            seen_sig = set()

            # Helper to add with diversity (suffix-k signature)
            def try_add(entry):
                s, r, c, reg, _t = entry
                sig = tuple(s[-diversity_suffix_k:]) if len(s) >= diversity_suffix_k else tuple(s)
                if sig in seen_sig:
                    return False
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                return True

            # Fill cost-first
            i = 0
            while len(next_beam) < base_quota and i < len(by_cost):
                try_add(by_cost[i])
                i += 1
            # Fill regret quota
            j = 0
            while len(next_beam) < base_quota + regret_quota and j < len(by_regret):
                try_add(by_regret[j])
                j += 1
            # If still short, fill by cost
            k = 0
            while len(next_beam) < local_beam_width and k < len(by_cost):
                try_add(by_cost[k])
                k += 1

            if not next_beam:
                # Fallback: take top-k by cost
                next_beam = [(s, r, c) for s, r, c, _, _ in by_cost[:local_beam_width]]

            beam = next_beam

        # Choose best complete
        best_seq = None
        best_cost = float('inf')
        for seq, rem, cost in beam:
            if rem:
                # append rest deterministically then evaluate
                seq_complete = seq[:] + sorted(list(rem))
                c = seq_cost(seq_complete)
                if c < best_cost:
                    best_cost = c
                    best_seq = seq_complete
            else:
                if cost < best_cost:
                    best_cost = cost
                    best_seq = seq

        return best_seq
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    # Local refinement: adjacent swaps, reinsertion, sampled 2-opt (first-improvement)
    def local_refine(seq):
        best_seq = seq[:]
        best_cost = seq_cost(best_seq)
        improved_outer = True

        adj_rounds = 0

        def two_opt_sample_pass(cur_seq, cur_cost):
            tried = 0
            while tried < two_opt_trials:
                i = random.randint(0, n - 2)
                j = random.randint(i + 2, n - 1) if i + 2 < n else None
                tried += 1
                if j is None:
                    continue
                cand = cur_seq[:]
                cand[i], cand[j] = cand[j], cand[i]
                c = seq_cost(cand)
                if c < cur_cost:
                    return True, c, cand
            return False, cur_cost, cur_seq

        while improved_outer:
            improved_outer = False

            # Adjacent swap pass (limited rounds)
            if adj_rounds < ls_adj_rounds_max:
                improved = True
                while improved:
                    improved = False
                    for i in range(n - 1):
                        cand = best_seq[:]
                        cand[i], cand[i + 1] = cand[i + 1], cand[i]
                        c = seq_cost(cand)
                        if c < best_cost:
                            best_cost = c
                            best_seq = cand
                            improved = True
                            improved_outer = True
                            break
                adj_rounds += 1
                if improved_outer:
                    continue

            # Reinsertion pass: move one item to a better position
            reinsertion_done = False
            k_positions = max(6, int(reinsertion_pos_factor * k_pos_sample))
            for i in range(n):
                item = best_seq[i]
                base = best_seq[:i] + best_seq[i + 1:]
                # try positions near current i plus sampled set
                positions = position_samples(len(base), focus_idx=i, k_positions=k_positions)
                for p in positions:
                    cand = base[:p] + [item] + base[p:]
                    c = seq_cost(cand)
                    if c < best_cost:
                        best_cost = c
                        best_seq = cand
                        improved_outer = True
                        reinsertion_done = True
                        break
                if reinsertion_done:
                    break
            if improved_outer:
                continue

            # Sampled 2-opt pass (non-adjacent swaps)
            changed, new_cost, new_seq = two_opt_sample_pass(best_seq, best_cost)
            if changed:
                best_seq = new_seq
                best_cost = new_cost
                improved_outer = True

        return best_cost, best_seq
=======
    # Local refinement: VND with adjacent swaps, Or-opt (1,2,3), and sampled 2-opt
    def local_refine(seq):
        best_seq = seq[:]
        best_cost = seq_cost(best_seq)
        improved_outer = True

        adj_rounds = 0

        def two_opt_sample_pass(cur_seq, cur_cost):
            tried = 0
            while tried < two_opt_trials:
                i = random.randint(0, n - 2)
                j = random.randint(i + 2, n - 1) if i + 2 < n else None
                tried += 1
                if j is None:
                    continue
                cand = cur_seq[:]
                cand[i], cand[j] = cand[j], cand[i]
                c = seq_cost(cand)
                if c < cur_cost:
                    return True, c, cand
            return False, cur_cost, cur_seq

        def try_reinsertion(cur_seq, cur_cost):
            k_positions = max(6, int(reinsertion_pos_factor * k_pos_sample))
            for i in range(n):
                item = cur_seq[i]
                base = cur_seq[:i] + cur_seq[i + 1:]
                # Endgame: exhaustive positions when sequence small
                if len(base) <= 20:
                    positions = list(range(len(base) + 1))
                else:
                    positions = position_samples(len(base), focus_idx=i, k_positions=k_positions)
                for p in positions:
                    cand = base[:p] + [item] + base[p:]
                    if cand == cur_seq:
                        continue
                    c = seq_cost(cand)
                    if c < cur_cost:
                        return True, c, cand
            return False, cur_cost, cur_seq

        def try_or_opt(cur_seq, cur_cost, k):
            L = len(cur_seq)
            for i in range(L - k + 1):
                block = cur_seq[i:i + k]
                base = cur_seq[:i] + cur_seq[i + k:]
                # Endgame: exhaustive positions when small; otherwise sample near i
                if len(base) <= 20:
                    positions = list(range(len(base) + 1))
                else:
                    positions = position_samples(len(base), focus_idx=i, k_positions=k_pos_sample)
                for p in positions:
                    # Skip no-op reinsertion at same position
                    if p == i:
                        continue
                    cand = base[:p] + block + base[p:]
                    if cand == cur_seq:
                        continue
                    c = seq_cost(cand)
                    if c < cur_cost:
                        return True, c, cand
            return False, cur_cost, cur_seq

        while improved_outer:
            improved_outer = False

            # Adjacent swap pass (limited rounds)
            if adj_rounds < ls_adj_rounds_max:
                improved = True
                while improved:
                    improved = False
                    for i in range(n - 1):
                        cand = best_seq[:]
                        cand[i], cand[i + 1] = cand[i + 1], cand[i]
                        c = seq_cost(cand)
                        if c < best_cost:
                            best_cost = c
                            best_seq = cand
                            improved = True
                            improved_outer = True
                            break
                adj_rounds += 1
                if improved_outer:
                    continue

            # Or-opt k=1 (single reinsertion)
            changed, new_cost, new_seq = try_reinsertion(best_seq, best_cost)
            if changed:
                best_seq, best_cost = new_seq, new_cost
                improved_outer = True
                continue

            # Or-opt k=2
            changed, new_cost, new_seq = try_or_opt(best_seq, best_cost, 2)
            if changed:
                best_seq, best_cost = new_seq, new_cost
                improved_outer = True
                continue

            # Or-opt k=3
            changed, new_cost, new_seq = try_or_opt(best_seq, best_cost, 3)
            if changed:
                best_seq, best_cost = new_seq, new_cost
                improved_outer = True
                continue

            # Sampled 2-opt pass (non-adjacent swaps)
            changed, new_cost, new_seq = two_opt_sample_pass(best_seq, best_cost)
            if changed:
                best_seq = new_seq
                best_cost = new_cost
                improved_outer = True

        return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    for seed in seed_txns:
        seq0 = regret_insertion_build(seed)
        c1, s1 = local_refine(seq0)
        add_elite(c1, s1)
=======
    for seed in seed_txns:
        seq0 = regret_insertion_build(seed)
        c1, s1 = local_refine(seq0)
        add_elite(c1, s1)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def add_elite(c, s):
        nonlocal elite
        elite.append((c, s))
        elite.sort(key=lambda x: x[0])
        # keep unique sequences by last element to add diversity cheaply
        uniq = []
        seen_end = set()
        for c1, s1 in elite:
            end = s1[-1] if s1 else None
            if end in seen_end:
                continue
            seen_end.add(end)
            uniq.append((c1, s1))
            if len(uniq) >= elite_size:
                break
        elite = uniq
=======
    def add_elite(c, s):
        nonlocal elite
        elite.append((c, s))
        elite.sort(key=lambda x: x[0])
        # keep unique sequences by suffix of length 2 to add diversity
        uniq = []
        seen_sig = set()
        for c1, s1 in elite:
            if s1:
                sig = tuple(s1[-2:]) if len(s1) >= 2 else (s1[-1],)
            else:
                sig = (None,)
            if sig in seen_sig:
                continue
            seen_sig.add(sig)
            uniq.append((c1, s1))
            if len(uniq) >= elite_size:
                break
        elite = uniq
>>>>>>> REPLACE
</DIFF>