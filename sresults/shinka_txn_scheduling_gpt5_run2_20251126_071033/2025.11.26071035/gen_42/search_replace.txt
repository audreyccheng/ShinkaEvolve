<NAME>
regret_cached_insertion_and_pair_swaps
</NAME>

<DESCRIPTION>
I propose three synergistic improvements that directly target makespan reduction by better handling conflict-sensitive placements and stronger local refinement without excessive overhead:

1) Deterministic, stratified insertion positions + best-two insertion caching
- Replace random position sampling with deterministic, evenly spaced positions (always including ends). This makes insertion evaluations repeatable and cacheable.
- Add a best_two_cache keyed by (tuple(seq), txn) that stores (best_cost, best_pos, second_best_cost) for reuse across construction, LNS, and local search. This reduces repeated simulator calls and allows effective regret-based selection.

2) Regret-guided reinsertion in LNS
- Instead of greedily reinserting items one-by-one, at each step score a small candidate set by (best, second-best) insertion and pick the highest-regret item to place next. This prioritizes conflict-critical placements, reducing downstream contention.

3) Add sampled non-adjacent pair swaps to VND
- Implement a lightweight sampled pair-swap move to complement Or-opt and adjacent swaps. It finds larger structural improvements (e.g., resolving distant conflicts) that adjacent swaps and single-block reinsertions may miss.

These changes are minimal, cohesive, and leverage the real makespan objective via cached, repeated evaluations. They should improve solution quality (lower makespan) while keeping runtime practical due to caching and deterministic sampling.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Cost cache for partial prefixes to reduce repeated evaluations
    cost_cache = {}

    def eval_cost(prefix):
        """Evaluate and cache the cost for a (possibly partial) prefix sequence."""
        key = tuple(prefix)
        if key in cost_cache:
            return cost_cache[key]
        c = workload.get_opt_seq_cost(list(prefix))
        cost_cache[key] = c
        return c
=======
    # Cost cache for partial prefixes to reduce repeated evaluations
    cost_cache = {}

    def eval_cost(prefix):
        """Evaluate and cache the cost for a (possibly partial) prefix sequence."""
        key = tuple(prefix)
        if key in cost_cache:
            return cost_cache[key]
        c = workload.get_opt_seq_cost(list(prefix))
        cost_cache[key] = c
        return c

    # Cache best and second-best insertion results per (seq, txn)
    # Keyed by (tuple(seq), txn) to ensure validity
    best_two_cache = {}
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def sample_positions(seq_len):
        """Return list of positions [0..seq_len] where insertion can occur, with optional sampling."""
        if POS_SAMPLE_LIMIT is None or seq_len + 1 <= (POS_SAMPLE_LIMIT or (seq_len + 1)):
            return list(range(seq_len + 1))
        # Sample positions but always include ends to preserve global structure
        num_to_sample = max(2, min(POS_SAMPLE_LIMIT, seq_len + 1))
        mandatory = {0, seq_len}
        interior = list(range(1, seq_len))
        if len(interior) <= num_to_sample - 2:
            chosen = set(interior)
        else:
            chosen = set(random.sample(interior, num_to_sample - 2))
        chosen.update(mandatory)
        return sorted(chosen)
=======
    def sample_positions(seq_len):
        """
        Deterministic stratified positions: always include ends and evenly spaced anchors.
        This makes insertion evaluations repeatable and compatible with caching.
        """
        total = seq_len + 1
        if POS_SAMPLE_LIMIT is None or total <= POS_SAMPLE_LIMIT:
            return list(range(total))
        # Evenly spaced positions including both ends
        k = max(2, min(POS_SAMPLE_LIMIT - 1, total - 1))
        # Generate k+1 anchors from 0..seq_len inclusive
        anchors = {0, seq_len}
        if k > 0:
            for i in range(1, k):
                pos = round(i * seq_len / k)
                pos = max(0, min(seq_len, pos))
                anchors.add(pos)
        return sorted(anchors)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def best_insertion_for_txn(current_seq, txn):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos, second_best_cost) to enable regret-based selection.
        """
        seq_len = len(current_seq)
        best_cost = float('inf')
        second_best = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        # Evaluate each possible position, track the two best costs
        for pos in positions:
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                second_best = best_cost
                best_cost = cost
                best_pos = pos
            elif cost < second_best:
                second_best = cost
        # In case we only had one position, second_best may remain inf; normalize
        if second_best == float('inf'):
            second_best = best_cost
        return best_cost, best_pos, second_best
=======
    def best_insertion_for_txn(current_seq, txn):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos, second_best_cost) to enable regret-based selection.
        Uses deterministic positions and caches results per (seq, txn).
        """
        key = (tuple(current_seq), txn)
        cached = best_two_cache.get(key)
        if cached is not None:
            return cached

        seq_len = len(current_seq)
        best_cost = float('inf')
        second_best = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        # Evaluate each possible position, track the two best costs
        for pos in positions:
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                second_best = best_cost
                best_cost = cost
                best_pos = pos
            elif cost < second_best:
                second_best = cost
        # Normalize second_best in degenerate case
        if second_best == float('inf'):
            second_best = best_cost

        result = (best_cost, best_pos, second_best)
        best_two_cache[key] = result
        return result
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def local_search_relocations(seq, curr_cost, tries=RELOC_TRIES):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        Accepts first improving move and continues until no improvement across budgeted tries.
        """
        best_seq = list(seq)
        best_cost = curr_cost

        if len(best_seq) <= 2:
            return best_seq, best_cost

        trials = 0
        while trials < tries:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                trials = 0  # reset upon improvement
            else:
                trials += 1
        return best_seq, best_cost
=======
    def local_search_relocations(seq, curr_cost, tries=RELOC_TRIES):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        Accepts first improving move and continues until no improvement across budgeted tries.
        """
        best_seq = list(seq)
        best_cost = curr_cost

        if len(best_seq) <= 2:
            return best_seq, best_cost

        trials = 0
        while trials < tries:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                trials = 0  # reset upon improvement
            else:
                trials += 1
        return best_seq, best_cost

    def local_search_pair_swaps(seq, curr_cost, tries=None):
        """
        Sampled non-adjacent pair swaps: explore up to 'tries' random pairs and apply the best improving swap.
        Complements Or-opt and adjacent swaps to resolve distant conflicts.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        L = len(best_seq)
        if L <= 3:
            return best_seq, best_cost
        if tries is None:
            tries = min(200, max(60, n))

        best_delta = 0.0
        best_pair = None
        for _ in range(tries):
            i = random.randint(0, L - 1)
            j = random.randint(0, L - 1)
            if i == j or abs(i - j) <= 1:
                continue
            cand = best_seq[:]
            cand[i], cand[j] = cand[j], cand[i]
            c = eval_cost(cand)
            delta = best_cost - c
            if delta > best_delta:
                best_delta = delta
                best_pair = (i, j)
        if best_pair is not None and best_delta > 0:
            i, j = best_pair
            best_seq[i], best_seq[j] = best_seq[j], best_seq[i]
            best_cost = eval_cost(best_seq)
        return best_seq, best_cost
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def vnd_local_search(seq, curr_cost):
        """
        Variable Neighborhood Descent:
        Or-opt blocks k=3,2,1 (best-improving), then adjacent swaps, then light relocations.
        Repeat cycle until no further improvement.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        changed = True
        while changed:
            changed = False
            for k in (3, 2, 1):
                s, c = or_opt_block(best_seq, best_cost, k)
                if c < best_cost:
                    best_seq, best_cost = s, c
                    changed = True
            s, c = local_search_adjacent_swaps(best_seq, best_cost, max_passes=1)
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
            s, c = local_search_relocations(best_seq, best_cost, tries=max(8, RELOC_TRIES // 2))
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
        return best_seq, best_cost
=======
    def vnd_local_search(seq, curr_cost):
        """
        Variable Neighborhood Descent:
        Or-opt blocks k=3,2,1 (best-improving), then adjacent swaps, then sampled pair swaps,
        then light relocations. Repeat cycle until no further improvement.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        changed = True
        while changed:
            changed = False
            for k in (3, 2, 1):
                s, c = or_opt_block(best_seq, best_cost, k)
                if c < best_cost:
                    best_seq, best_cost = s, c
                    changed = True
            s, c = local_search_adjacent_swaps(best_seq, best_cost, max_passes=1)
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
            s, c = local_search_pair_swaps(best_seq, best_cost, tries=min(200, max(60, n)))
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
            s, c = local_search_relocations(best_seq, best_cost, tries=max(8, RELOC_TRIES // 2))
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
        return best_seq, best_cost
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def lns_ruin_recreate(seq, curr_cost, rounds=2):
        """
        Ruin-and-recreate LNS: remove a contiguous block (plus a few random extras) and reinsert greedily.
        Accept only improving reconstructions; repeat for a few rounds.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        for _ in range(max(1, rounds)):
            L = len(best_seq)
            if L < 6:
                break
            # Choose block to remove
            base_len = max(4, L // 10)
            block_len = min(L - 2, base_len + random.randint(0, 3))
            start = random.randint(0, L - block_len)
            removed = best_seq[start:start + block_len]
            skeleton = best_seq[:start] + best_seq[start + block_len:]
            # Optionally remove a few extras for diversification
            extra_count = min(3, max(0, L // 30))
            extras_idx = sorted(random.sample(range(len(skeleton)), extra_count)) if extra_count and len(skeleton) > extra_count else []
            extras = []
            offset = 0
            for idx in extras_idx:
                idx_adj = idx - offset
                extras.append(skeleton.pop(idx_adj))
                offset += 1
            to_insert = removed + extras

            # Reinsert removed items using best insertion positions
            rebuilt = list(skeleton)
            for t in to_insert:
                best_c = float('inf')
                best_p = 0
                positions = sample_positions(len(rebuilt))
                for pos in positions:
                    cand = rebuilt[:]
                    cand.insert(pos, t)
                    c = eval_cost(cand)
                    if c < best_c:
                        best_c = c
                        best_p = pos
                rebuilt.insert(best_p, t)

            c_final = eval_cost(rebuilt)
            if c_final < best_cost:
                best_cost = c_final
                best_seq = rebuilt
        return best_seq, best_cost
=======
    def lns_ruin_recreate(seq, curr_cost, rounds=2):
        """
        Ruin-and-recreate LNS: remove a contiguous block (plus a few random extras) and rebuild
        via regret-guided reinsertion using cached best-two insertions.
        Accept only improving reconstructions; repeat for a few rounds.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        for _ in range(max(1, rounds)):
            L = len(best_seq)
            if L < 6:
                break
            # Choose block to remove
            base_len = max(4, L // 10)
            block_len = min(L - 2, base_len + random.randint(0, 3))
            start = random.randint(0, L - block_len)
            removed = best_seq[start:start + block_len]
            skeleton = best_seq[:start] + best_seq[start + block_len:]
            # Optionally remove a few extras for diversification
            extra_count = min(3, max(0, L // 30))
            extras_idx = sorted(random.sample(range(len(skeleton)), extra_count)) if extra_count and len(skeleton) > extra_count else []
            extras = []
            offset = 0
            for idx in extras_idx:
                idx_adj = idx - offset
                extras.append(skeleton.pop(idx_adj))
                offset += 1
            to_insert = removed + extras

            # Regret-guided reinsertion with small candidate sampling per step
            rebuilt = list(skeleton)
            remaining = list(to_insert)
            while remaining:
                k_t = min(len(remaining), max(4, len(remaining) // 2))
                cand_txns = remaining if len(remaining) <= k_t else random.sample(remaining, k_t)
                scored = []
                for t in cand_txns:
                    best_c, best_p, second_c = best_insertion_for_txn(rebuilt, t)
                    regret = max(0.0, second_c - best_c)
                    scored.append((regret, best_c, best_p, t))
                if not scored:
                    # fallback: append any remaining
                    t = remaining.pop()
                    rebuilt.append(t)
                    continue
                # Choose highest regret; tie-break on best cost
                scored.sort(key=lambda x: (-x[0], x[1]))
                regret, best_c, best_p, t = scored[0]
                rebuilt.insert(best_p, t)
                remaining.remove(t)

            c_final = eval_cost(rebuilt)
            if c_final < best_cost:
                best_cost = c_final
                best_seq = rebuilt
        return best_seq, best_cost
>>>>>>> REPLACE
</DIFF>