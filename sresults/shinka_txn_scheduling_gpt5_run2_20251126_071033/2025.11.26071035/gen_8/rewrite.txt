# EVOLVE-BLOCK-START
"""Transaction scheduling algorithm for optimizing makespan across multiple workloads
Monte Carlo Tree Search with progressive widening and LNS refinement.
"""

import time
import random
import math
import sys
import os

# Add the openevolve_examples directory to the path to import txn_simulator and workloads
# Find the repository root by looking for the openevolve_examples directory
def find_repo_root(start_path):
    """Find the repository root by looking for openevolve_examples directory."""
    current = os.path.abspath(start_path)
    # Search up the directory tree
    while current != os.path.dirname(current):  # Stop at filesystem root
        candidate = os.path.join(current, 'openevolve_examples', 'txn_scheduling')
        if os.path.exists(candidate):
            return current
        current = os.path.dirname(current)
    
    # If not found by searching up, try common locations relative to known paths
    # This handles when the program is copied to a results directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    possible_roots = [
        script_dir,  # Current directory
        os.path.dirname(script_dir),  # Parent
        os.path.dirname(os.path.dirname(script_dir)),  # Grandparent
        '/home/ubuntu/ShinkaEvolve',  # Absolute path fallback for Ubuntu
        '/Users/audreycc/Documents/Work/LLMTxn/ADRS-Exps/ShinkaEvolve',  # Absolute path fallback for macOS
    ]
    for root in possible_roots:
        candidate = os.path.join(root, 'openevolve_examples', 'txn_scheduling')
        if os.path.exists(candidate):
            return root
    
    raise RuntimeError(f"Could not find openevolve_examples directory. Searched from: {start_path}")

repo_root = find_repo_root(os.path.dirname(__file__))
sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'txn_scheduling'))

from txn_simulator import Workload
from workloads import WORKLOAD_1, WORKLOAD_2, WORKLOAD_3


def get_best_schedule(workload, num_seqs):
    """
    Monte Carlo Tree Search with progressive widening + Large Neighborhood Search refinement.
    
    Args:
        workload: Workload object containing transaction data
        num_seqs: Effort parameter
    
    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    n = workload.num_txns

    # Cost cache for partial prefixes to reduce repeated evaluations
    cost_cache = {}

    def eval_cost(prefix):
        """Evaluate and cache the cost for a prefix sequence."""
        key = tuple(prefix)
        cached = cost_cache.get(key)
        if cached is not None:
            return cached
        c = workload.get_opt_seq_cost(list(prefix))
        cost_cache[key] = c
        return c

    class MCTSNode:
        __slots__ = (
            "prefix", "remaining", "visits", "value_sum", "best_reward", "best_seq",
            "children", "candidates", "cand_scores"
        )
        def __init__(self, prefix, remaining):
            self.prefix = tuple(prefix)
            self.remaining = tuple(sorted(remaining))  # deterministic ordering
            self.visits = 0
            self.value_sum = 0.0
            self.best_reward = float("-inf")
            self.best_seq = None  # best full sequence discovered through this node
            self.children = {}  # action (txn) -> child node
            self.candidates = None  # cached candidate txn list
            self.cand_scores = None  # txn -> partial cost when appended

        def is_terminal(self):
            return len(self.remaining) == 0

        def expand_candidates(self, sample_cap, keep_top):
            """Compute candidate next transactions: sample from remaining and keep top by minimal partial cost."""
            if self.candidates is not None:
                return

            rem_list = list(self.remaining)
            if len(rem_list) <= sample_cap:
                sample = rem_list
            else:
                sample = random.sample(rem_list, sample_cap)

            scores = {}
            base = list(self.prefix)
            best = []
            for t in sample:
                c = eval_cost(base + [t])
                scores[t] = c
                best.append((c, t))
            best.sort(key=lambda x: x[0])
            # Keep the top-K by partial projected cost
            top_k = [t for _, t in best[:min(keep_top, len(best))]]
            self.candidates = top_k
            self.cand_scores = scores

        def select_child(self, c_ucb):
            """Select a child using UCB1 on rewards."""
            total_visits = max(1, self.visits)
            best_score = float("-inf")
            best_child = None
            best_action = None
            for a, child in self.children.items():
                if child.visits == 0:
                    ucb = float("inf")
                else:
                    mean = child.value_sum / child.visits
                    ucb = mean + c_ucb * math.sqrt(math.log(total_visits) / child.visits)
                if ucb > best_score:
                    best_score = ucb
                    best_child = child
                    best_action = a
            return best_action, best_child

    # Rollout policy: greedy among small random subset with epsilon exploration
    def rollout_from(prefix, remaining, pick_k=5, epsilon=0.1):
        seq = list(prefix)
        rem = list(remaining)
        while rem:
            if len(rem) <= pick_k:
                candidates = rem
            else:
                candidates = random.sample(rem, pick_k)
            # evaluate append cost for each candidate
            best_t = None
            best_cost = float("inf")
            for t in candidates:
                c = eval_cost(seq + [t])
                if c < best_cost:
                    best_cost = c
                    best_t = t
            # epsilon-greedy exploration
            if random.random() < epsilon and len(rem) > 1:
                # pick a random other candidate
                explore_set = [t for t in candidates if t != best_t]
                if explore_set:
                    best_t = random.choice(explore_set)
            seq.append(best_t)
            rem.remove(best_t)
        final_cost = eval_cost(seq)
        return -final_cost, final_cost, seq  # reward, cost, sequence

    # Local search refinement: adjacent swaps, relocations, and 2-opt reversal
    def local_search(seq, start_cost, max_adj_passes, reloc_tries, two_opt_tries):
        best_seq = list(seq)
        best_cost = start_cost

        # Adjacent swaps first (hill climbing)
        for _ in range(max_adj_passes):
            improved = False
            i = 0
            while i < len(best_seq) - 1:
                cand = best_seq[:]
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True
                i += 1
            if not improved:
                break

        # Random block relocation
        if len(best_seq) > 3:
            no_improve = 0
            tries = 0
            while tries < reloc_tries and no_improve < reloc_tries // 3:
                i = random.randint(0, len(best_seq) - 2)
                j = random.randint(i + 1, len(best_seq) - 1)
                # pick destination position k outside [i, j]
                possible_positions = list(range(0, i)) + list(range(j + 1, len(best_seq) + 1))
                if not possible_positions:
                    tries += 1
                    continue
                k = random.choice(possible_positions)

                block = best_seq[i:j + 1]
                rest = best_seq[:i] + best_seq[j + 1:]
                if k <= i:
                    cand = rest[:k] + block + rest[k:]
                else:
                    # adjust k since block removed before j+1
                    k_adj = k - (j - i + 1)
                    cand = rest[:k_adj] + block + rest[k_adj:]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    no_improve = 0
                else:
                    no_improve += 1
                tries += 1

        # 2-opt segment reversal
        if len(best_seq) > 3:
            tries = 0
            while tries < two_opt_tries:
                i = random.randint(0, len(best_seq) - 3)
                j = random.randint(i + 2, len(best_seq) - 1)
                cand = best_seq[:i] + list(reversed(best_seq[i:j + 1])) + best_seq[j + 1:]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                tries += 1

        return best_cost, best_seq

    # MCTS configuration
    # Scale iterations with problem size and effort; keep practical ceiling
    iter_budget = min(1200, max(300, 5 * n + 80 * max(1, num_seqs)))
    c_ucb = 1.2  # exploration constant
    # Candidate sampling per node for expansion
    sample_cap = 14 if n > 40 else 18
    keep_top = 8 if n > 40 else 10
    # Rollout candidate choices
    rollout_k = 5 if n > 40 else 6
    epsilon = 0.08

    # LNS parameters
    max_adj_passes = 2 if n > 40 else 3
    reloc_tries = 120 if n > 40 else 80
    two_opt_tries = 120 if n > 40 else 80

    root = MCTSNode(prefix=[], remaining=list(range(n)))
    best_global_cost = float('inf')
    best_global_seq = list(range(n))

    # Seed to diversify but deterministic per call
    random.seed((n * 977 + num_seqs * 131) % (2**32 - 1))

    for it in range(iter_budget):
        node = root
        path = [node]

        # Selection + Progressive Widening + Expansion
        while not node.is_terminal():
            # Generate candidate actions if needed
            node.expand_candidates(sample_cap=sample_cap, keep_top=keep_top)

            # Progressive widening: allow more children as visits grow
            allow_children = min(len(node.candidates), 1 + int(math.sqrt(node.visits + 1)))
            # Expand an untried action if allowed
            unexpanded = [a for a in node.candidates if a not in node.children]
            if len(node.children) < allow_children and unexpanded:
                # Choose the best-scored unexpanded action first (by partial cost)
                best_a = min(unexpanded, key=lambda a: node.cand_scores.get(a, float('inf')))
                action = best_a
                new_prefix = list(node.prefix) + [action]
                new_remaining = [x for x in node.remaining if x != action]
                child = MCTSNode(prefix=new_prefix, remaining=new_remaining)
                node.children[action] = child
                node = child
                path.append(node)
                break
            else:
                # Select an existing child with UCB
                a, child = node.select_child(c_ucb=c_ucb)
                if child is None:
                    # No children yet; expand one candidate randomly
                    action = random.choice(node.candidates) if node.candidates else random.choice(list(node.remaining))
                    new_prefix = list(node.prefix) + [action]
                    new_remaining = [x for x in node.remaining if x != action]
                    child = MCTSNode(prefix=new_prefix, remaining=new_remaining)
                    node.children[action] = child
                    node = child
                    path.append(node)
                    break
                else:
                    node = child
                    path.append(node)

        # Rollout from current node
        if node.is_terminal():
            final_prefix = list(node.prefix)
            final_cost = eval_cost(final_prefix)
            reward = -final_cost
            final_seq = final_prefix
        else:
            reward, final_cost, final_seq = rollout_from(node.prefix, node.remaining, pick_k=rollout_k, epsilon=epsilon)

        # Keep global incumbent; refine occasionally
        if final_cost < best_global_cost:
            best_global_cost = final_cost
            best_global_seq = final_seq

        # Backpropagation
        for p in path:
            p.visits += 1
            p.value_sum += reward
            if reward > p.best_reward:
                p.best_reward = reward
                p.best_seq = final_seq

        # Light periodic local improvement on the current best
        if (it + 1) % max(50, n // 2) == 0:
            lc, ls = local_search(best_global_seq, best_global_cost, max_adj_passes=1, reloc_tries=40, two_opt_tries=40)
            if lc < best_global_cost:
                best_global_cost, best_global_seq = lc, ls

    # Final local refinement
    best_global_cost, best_global_seq = local_search(
        best_global_seq, best_global_cost,
        max_adj_passes=max_adj_passes,
        reloc_tries=reloc_tries,
        two_opt_tries=two_opt_tries
    )

    # Safety check
    assert len(set(best_global_seq)) == n, "Schedule must include each transaction exactly once"

    return best_global_cost, best_global_seq


def get_random_costs():
    """
    Evaluate scheduling algorithm on three different workloads.
    
    Returns:
        Tuple of (total_makespan, list_of_schedules, execution_time)
    """
    start_time = time.time()
    workload_size = 100
    
    # Workload 1: Complex mixed read/write transactions
    workload = Workload(WORKLOAD_1)
    makespan1, schedule1 = get_best_schedule(workload, 10)
    cost1 = workload.get_opt_seq_cost(schedule1)

    # Workload 2: Simple read-then-write pattern
    workload2 = Workload(WORKLOAD_2)
    makespan2, schedule2 = get_best_schedule(workload2, 10)
    cost2 = workload2.get_opt_seq_cost(schedule2)

    # Workload 3: Minimal read/write operations
    workload3 = Workload(WORKLOAD_3)
    makespan3, schedule3 = get_best_schedule(workload3, 10)
    cost3 = workload3.get_opt_seq_cost(schedule3)
    
    total_makespan = cost1 + cost2 + cost3
    schedules = [schedule1, schedule2, schedule3]
    execution_time = time.time() - start_time
    
    return total_makespan, schedules, execution_time


# EVOLVE-BLOCK-END


# This part remains fixed (not evolved)
def run_scheduling():
    """Run the transaction scheduling algorithm for all workloads"""
    total_makespan, schedules, execution_time = get_random_costs()
    return total_makespan, schedules, execution_time


if __name__ == "__main__":
    total_makespan, schedules, execution_time = run_scheduling()
    print(f"Total makespan: {total_makespan}, Execution time: {execution_time:.4f}s")
    print(f"Individual workload costs: {[workload.get_opt_seq_cost(schedule) for workload, schedule in zip([Workload(WORKLOAD_1), Workload(WORKLOAD_2), Workload(WORKLOAD_3)], schedules)]}")