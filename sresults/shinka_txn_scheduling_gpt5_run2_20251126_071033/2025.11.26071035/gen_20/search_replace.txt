<NAME>
grasp_regret_vnd_lns
</NAME>

<DESCRIPTION>
I introduce three synergistic upgrades to the GRASP-based scheduler to reduce makespan more effectively:

1) Cached evaluations via LRU: Replace the raw evaluator with a tuple-keyed LRU cache to avoid repeated cost computations for identical prefixes. This speeds up construction and local search, allowing more effective exploration within the same time.

2) Regret-guided insertion in construction: Upgrade best-insertion to return both best and second-best insertion costs, and use a regret-based Restricted Candidate List policy. We bias selection toward candidates with larger regret among the top by cost (indicating high opportunity), which empirically improves schedules by better resolving conflicts early.

3) Stronger local search: Add Or-opt (block reinsertion of sizes 1â€“3) with best-improvement passes to escape local minima that adjacent swaps miss. Add a small ruin-and-recreate LNS step that removes a subset (mix of contiguous and random items) and reinserts greedily using the same insertion evaluator, followed by quick polishing.

Together, these changes maintain runtime practicality while deepening search quality and producing lower makespan schedules.

</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
import time
import random
import sys
import os
=======
import time
from functools import lru_cache
import random
import sys
import os
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def eval_cost(seq):
        return workload.get_opt_seq_cost(seq)
=======
    @lru_cache(maxsize=50000)
    def _eval_cost_tuple(seq_tuple):
        # Cached evaluation for sequences (or prefixes) represented as tuples
        return workload.get_opt_seq_cost(list(seq_tuple))

    def eval_cost(seq):
        # Wrapper accepting list; converts to tuple key for caching
        return _eval_cost_tuple(tuple(seq))
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def best_insertion_for_txn(current_seq, txn, current_best):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos). current_best is the best known cost to allow pruning.
        """
        seq_len = len(current_seq)
        best_cost = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        for pos in positions:
            # Build candidate sequence with insertion
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                best_cost = cost
                best_pos = pos
                # simple pruning: if we beat current_best significantly, keep going but this helps early wins
                # No strict bound known, but we can short-circuit if we reach 0 (impossible) or equal to theoretical min
            # Early continue if we already can't beat current_best is avoided due to no strong bound
        return best_cost, best_pos
=======
    def best_insertion_for_txn(current_seq, txn, current_best):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos, second_best_cost). current_best is kept for potential pruning.
        """
        seq_len = len(current_seq)
        best_cost = float('inf')
        second_best = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        for pos in positions:
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                second_best = best_cost
                best_cost = cost
                best_pos = pos
            elif cost < second_best:
                second_best = cost
        if second_best == float('inf'):
            second_best = best_cost
        return best_cost, best_pos, second_best
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
        while remaining:
            # Adaptive candidate sample size
            # Focus more candidates when many remain; taper off later
            dynamic_base = CAND_SAMPLE_BASE
            # small randomness to diversify
            cand_size = min(len(remaining), max(3, dynamic_base + random.randint(-JITTER, JITTER)))
            candidates = random.sample(remaining, cand_size)

            best_step_cost = float('inf')
            best_txn = None
            best_pos = 0

            for t in candidates:
                cost_t, pos_t = best_insertion_for_txn(seq, t, best_step_cost)
                if cost_t < best_step_cost:
                    best_step_cost = cost_t
                    best_txn = t
                    best_pos = pos_t

            # As a fallback, if candidates performed poorly (shouldn't happen), choose a random remaining txn at end
            if best_txn is None:
                t = random.choice(remaining)
                seq.append(t)
                curr_cost = eval_cost(seq)
                remaining.remove(t)
            else:
                seq.insert(best_pos, best_txn)
                curr_cost = best_step_cost
                remaining.remove(best_txn)
=======
        while remaining:
            # Adaptive candidate sample size
            # Focus more candidates when many remain; taper off later
            dynamic_base = CAND_SAMPLE_BASE
            # small randomness to diversify
            cand_size = min(len(remaining), max(3, dynamic_base + random.randint(-JITTER, JITTER)))
            # In the endgame, evaluate all remaining to avoid myopia
            if len(remaining) <= dynamic_base + 2:
                candidates = list(remaining)
            else:
                candidates = random.sample(remaining, cand_size)

            # Score candidates by best insertion, along with regret (second-best - best)
            scored = []
            for t in candidates:
                cost_t, pos_t, second_best = best_insertion_for_txn(seq, t, float('inf'))
                regret = max(0.0, second_best - cost_t)
                scored.append((cost_t, regret, t, pos_t))

            # Choose with regret-biased RCL among top by cost
            if scored:
                scored.sort(key=lambda x: x[0])  # ascending by cost
                rcl_size = max(1, min(3, len(scored)//2 if len(scored) > 3 else len(scored)))
                rcl = scored[:rcl_size]
                # With probability 0.6, pick the highest regret in RCL; else random among RCL
                if random.random() < 0.6:
                    best_step_cost, _, best_txn, best_pos = max(rcl, key=lambda x: x[1])
                else:
                    best_step_cost, _, best_txn, best_pos = random.choice(rcl)

                seq.insert(best_pos, best_txn)
                curr_cost = best_step_cost
                remaining.remove(best_txn)
            else:
                # Fallback: append a random remaining txn
                t = random.choice(remaining)
                seq.append(t)
                curr_cost = eval_cost(seq)
                remaining.remove(t)
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def local_search_adjacent_swaps(seq, curr_cost):
        """
        Perform multiple passes of adjacent swap hill-climbing.
        """
        improved = True
        passes = 0
        best_seq = seq
        best_cost = curr_cost

        while improved and passes < MAX_LS_PASSES:
            improved = False
            passes += 1
            i = 0
            # One pass left-to-right
            while i < len(best_seq) - 1:
                cand = best_seq.copy()
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True
                    # After improvement, we can continue locally; do not skip ahead
                i += 1
        return best_seq, best_cost

    def local_search_relocations(seq, curr_cost):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        """
=======
    def local_search_adjacent_swaps(seq, curr_cost):
        """
        Perform multiple passes of adjacent swap hill-climbing.
        """
        improved = True
        passes = 0
        best_seq = seq
        best_cost = curr_cost

        while improved and passes < MAX_LS_PASSES:
            improved = False
            passes += 1
            i = 0
            # One pass left-to-right
            while i < len(best_seq) - 1:
                cand = best_seq.copy()
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True
                    # After improvement, we can continue locally; do not skip ahead
                i += 1
        return best_seq, best_cost

    def local_search_oropt(seq, curr_cost, max_rounds=1):
        """
        Or-opt block reinsertion (block sizes 1..3), best-improvement per round.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        if len(best_seq) <= 2:
            return best_seq, best_cost

        rounds = 0
        while rounds < max_rounds:
            rounds += 1
            improved = False
            # Try larger blocks first
            for blk in (3, 2, 1):
                if blk > len(best_seq):
                    continue
                move_best_delta = 0.0
                move_best_i = None
                move_best_pos = None
                move_best_block = None
                # Enumerate block start indices
                for i in range(0, len(best_seq) - blk + 1):
                    block = best_seq[i:i + blk]
                    base = best_seq[:i] + best_seq[i + blk:]
                    # Candidate insertion positions (respect ends; sample if long)
                    m = len(base) + 1
                    if POS_SAMPLE_LIMIT is None or m <= (POS_SAMPLE_LIMIT or m) + 1:
                        positions = list(range(m))
                    else:
                        k = min(POS_SAMPLE_LIMIT, m - 1)
                        interior = list(range(1, m - 1))
                        sampled = set(random.sample(interior, k)) if interior else set()
                        sampled.update({0, m - 1})
                        positions = sorted(sampled)
                    for pos in positions:
                        cand = base[:]
                        cand[pos:pos] = block
                        c = eval_cost(cand)
                        if c < best_cost - 1e-12:
                            # Best-improvement tracking
                            delta = best_cost - c
                            if delta > move_best_delta:
                                move_best_delta = delta
                                move_best_i = i
                                move_best_pos = pos
                                move_best_block = block
                if move_best_i is not None:
                    # Apply best move for this block size
                    base = best_seq[:move_best_i] + best_seq[move_best_i + len(move_best_block):]
                    base[move_best_pos:move_best_pos] = move_best_block
                    best_seq = base
                    best_cost = eval_cost(best_seq)
                    improved = True
                    break  # restart at largest block after improvement
            if not improved:
                break

        return best_seq, best_cost

    def local_search_relocations(seq, curr_cost):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        """
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    def local_search_relocations(seq, curr_cost):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        """
        best_seq = seq
        best_cost = curr_cost
        trials = 0
        # Early exit if trivial
        if len(seq) <= 2:
            return best_seq, best_cost

        while trials < RELOC_TRIES:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            # Adjust j if removal shifts indices
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                # On improvement, reset trials to keep exploring around new incumbent
                trials = 0
            else:
                trials += 1
        return best_seq, best_cost
=======
    def local_search_relocations(seq, curr_cost):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        """
        best_seq = seq
        best_cost = curr_cost
        trials = 0
        # Early exit if trivial
        if len(seq) <= 2:
            return best_seq, best_cost

        while trials < RELOC_TRIES:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            # Adjust j if removal shifts indices
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                # On improvement, reset trials to keep exploring around new incumbent
                trials = 0
            else:
                trials += 1
        return best_seq, best_cost

    def ruin_and_recreate(seq, curr_cost, rounds=2):
        """
        Ruin-and-recreate LNS: remove k transactions (contiguous + random) and greedily reinsert.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        if len(best_seq) <= 4:
            return best_seq, best_cost

        for _ in range(rounds):
            k = min(max(8, int(0.1 * n)), len(best_seq) - 1)
            # Select a contiguous segment (half of k) and a few random removals
            k_contig = max(2, k // 2)
            start = random.randint(0, len(best_seq) - k_contig)
            remove_idx = set(range(start, start + k_contig))
            # Add random indices
            while len(remove_idx) < k:
                remove_idx.add(random.randint(0, len(best_seq) - 1))
            remove_idx = sorted(remove_idx)

            removed = [best_seq[i] for i in remove_idx]
            base = [best_seq[i] for i in range(len(best_seq)) if i not in remove_idx]

            # Greedy reinsertion of removed items using best insertion positions
            cur = list(base)
            for t in removed:
                ins_cost, ins_pos, _ = best_insertion_for_txn(cur, t, float('inf'))
                cur.insert(ins_pos, t)
            c_new = eval_cost(cur)
            if c_new < best_cost:
                best_cost = c_new
                best_seq = cur

        return best_seq, best_cost
>>>>>>> REPLACE

</DIFF>

<DIFF>
<<<<<<< SEARCH
    for _ in range(max(1, num_seqs)):
        seq, cost = construct_sequence()
        # Local search refinement
        seq, cost = local_search_adjacent_swaps(seq, cost)
        seq, cost = local_search_relocations(seq, cost)

        if cost < global_best_cost:
            global_best_cost = cost
            global_best_seq = seq
=======
    for _ in range(max(1, num_seqs)):
        seq, cost = construct_sequence()
        # Local search refinement: Or-opt blocks, adjacent swaps, then relocations
        seq, cost = local_search_oropt(seq, cost, max_rounds=1)
        seq, cost = local_search_adjacent_swaps(seq, cost)
        seq, cost = local_search_relocations(seq, cost)
        # Ruin-and-recreate with quick polishing
        seq2, cost2 = ruin_and_recreate(seq, cost, rounds=2)
        if cost2 < cost:
            seq, cost = seq2, cost2
            seq, cost = local_search_adjacent_swaps(seq, cost)
            seq, cost = local_search_oropt(seq, cost, max_rounds=1)

        if cost < global_best_cost:
            global_best_cost = cost
            global_best_seq = seq
>>>>>>> REPLACE

</DIFF>