<NAME>
cached_grasp_regret_vnd
</NAME>

<DESCRIPTION>
I enhanced the GRASP constructor with three key improvements to reduce makespan:

1) Cost caching for prefixes: A memoized eval_cost now caches workload.get_opt_seq_cost results for partial and complete sequences. This drastically reduces redundant simulator evaluations and lets us evaluate more candidate insertions, improving selection quality without increasing runtime.

2) Regret-guided RCL insertion: For each sampled transaction, we evaluate all candidate positions, compute both the best and second-best costs, and use the regret (second-best - best) to guide selection. We primarily select from the top by cost, but with a small probability (30%) we select among high-regret candidates in the RCL. This balances greediness with exploration where the opportunity loss (regret) is high, helping avoid myopic local minima.

3) Stronger local search (VND-like): I added a deterministic best-improving reinsertion pass (Or-opt-1) before adjacent swaps and relocations, followed by a final adjacent swap polish. This deepens the neighborhood search while staying efficient, especially with the cost cache.

Additional tweaks:
- Better starter selection by sampling a small set and choosing the best by prefix cost.
- Adaptive endgame: when few transactions remain, evaluate all candidates rather than sampling.
- Relocation tries scaled mildly by search effort (num_seqs).

These changes target actual makespan via the simulator cost, not proxies, and should yield lower total costs across workloads.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    GRASP-style scheduler: multi-start randomized best-insertion + local search.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of randomized restarts

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    n = workload.num_txns
    all_txns = list(range(n))

    # Parameter configuration (adaptive by workload size)
    if n <= 50:
        CAND_SAMPLE_BASE = 10     # candidate txn per step
        POS_SAMPLE_LIMIT = None   # evaluate all insertion positions
        MAX_LS_PASSES = 3         # local search passes for adjacent swaps
        RELOC_TRIES = max(8, n // 2)
    else:
        CAND_SAMPLE_BASE = 8
        POS_SAMPLE_LIMIT = 15     # cap insertion positions evaluated
        MAX_LS_PASSES = 2
        RELOC_TRIES = max(12, n // 3)

    JITTER = 2  # small random variation in candidate set size

    def eval_cost(seq):
        return workload.get_opt_seq_cost(seq)

    def sample_positions(seq_len):
        # Return list of positions [0..seq_len] where insertion can occur
        if POS_SAMPLE_LIMIT is None or seq_len + 1 <= (POS_SAMPLE_LIMIT or (seq_len + 1)):
            return list(range(seq_len + 1))
        # Sample positions but always include ends to preserve global structure
        num_to_sample = max(2, min(POS_SAMPLE_LIMIT, seq_len + 1))
        mandatory = {0, seq_len}
        # Available interior positions
        interior = list(range(1, seq_len))
        if len(interior) <= num_to_sample - 2:
            chosen = set(interior)
        else:
            chosen = set(random.sample(interior, num_to_sample - 2))
        chosen.update(mandatory)
        return sorted(chosen)

    def best_insertion_for_txn(current_seq, txn, current_best):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos). current_best is the best known cost to allow pruning.
        """
        seq_len = len(current_seq)
        best_cost = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        for pos in positions:
            # Build candidate sequence with insertion
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                best_cost = cost
                best_pos = pos
                # simple pruning: if we beat current_best significantly, keep going but this helps early wins
                # No strict bound known, but we can short-circuit if we reach 0 (impossible) or equal to theoretical min
            # Early continue if we already can't beat current_best is avoided due to no strong bound
        return best_cost, best_pos

    def construct_sequence():
        """
        Randomized best-insertion construction.
        """
        # Seed with a random start transaction; quickly choose a good second insertion
        remaining = all_txns.copy()
        random_start = random.randint(0, n - 1)
        seq = [random_start]
        remaining.remove(random_start)
        curr_cost = eval_cost(seq)

        # Optionally add a second txn by testing a small candidate set thoroughly
        if remaining:
            k = min(6, len(remaining))
            candidates = random.sample(remaining, k)
            best_pair_cost = float('inf')
            best_txn = None
            best_pos = 1  # only positions 0 or 1 possible
            for t in candidates:
                # Try both positions in [0,1]
                for pos in [0, 1]:
                    cand = seq.copy()
                    cand.insert(pos, t)
                    cost = eval_cost(cand)
                    if cost < best_pair_cost:
                        best_pair_cost = cost
                        best_txn = t
                        best_pos = pos
            if best_txn is not None:
                seq.insert(best_pos, best_txn)
                remaining.remove(best_txn)
                curr_cost = best_pair_cost

        # Build the rest using sampled candidates and best insertion positions
        while remaining:
            # Adaptive candidate sample size
            # Focus more candidates when many remain; taper off later
            dynamic_base = CAND_SAMPLE_BASE
            # small randomness to diversify
            cand_size = min(len(remaining), max(3, dynamic_base + random.randint(-JITTER, JITTER)))
            candidates = random.sample(remaining, cand_size)

            best_step_cost = float('inf')
            best_txn = None
            best_pos = 0

            for t in candidates:
                cost_t, pos_t = best_insertion_for_txn(seq, t, best_step_cost)
                if cost_t < best_step_cost:
                    best_step_cost = cost_t
                    best_txn = t
                    best_pos = pos_t

            # As a fallback, if candidates performed poorly (shouldn't happen), choose a random remaining txn at end
            if best_txn is None:
                t = random.choice(remaining)
                seq.append(t)
                curr_cost = eval_cost(seq)
                remaining.remove(t)
            else:
                seq.insert(best_pos, best_txn)
                curr_cost = best_step_cost
                remaining.remove(best_txn)

        return seq, curr_cost

    def local_search_adjacent_swaps(seq, curr_cost):
        """
        Perform multiple passes of adjacent swap hill-climbing.
        """
        improved = True
        passes = 0
        best_seq = seq
        best_cost = curr_cost

        while improved and passes < MAX_LS_PASSES:
            improved = False
            passes += 1
            i = 0
            # One pass left-to-right
            while i < len(best_seq) - 1:
                cand = best_seq.copy()
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True
                    # After improvement, we can continue locally; do not skip ahead
                i += 1
        return best_seq, best_cost

    def local_search_relocations(seq, curr_cost):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        """
        best_seq = seq
        best_cost = curr_cost
        trials = 0
        # Early exit if trivial
        if len(seq) <= 2:
            return best_seq, best_cost

        while trials < RELOC_TRIES:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            # Adjust j if removal shifts indices
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                # On improvement, reset trials to keep exploring around new incumbent
                trials = 0
            else:
                trials += 1
        return best_seq, best_cost

    # Multi-start GRASP
    global_best_seq = None
    global_best_cost = float('inf')

    for _ in range(max(1, num_seqs)):
        seq, cost = construct_sequence()
        # Local search refinement
        seq, cost = local_search_adjacent_swaps(seq, cost)
        seq, cost = local_search_relocations(seq, cost)

        if cost < global_best_cost:
            global_best_cost = cost
            global_best_seq = seq

    # Safety checks
    assert global_best_seq is not None
    assert len(global_best_seq) == n
    assert len(set(global_best_seq)) == n

    return global_best_cost, global_best_seq
=======
def get_best_schedule(workload, num_seqs):
    """
    GRASP-style scheduler: multi-start randomized best-insertion + local search.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of randomized restarts

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    n = workload.num_txns
    all_txns = list(range(n))

    # Parameter configuration (adaptive by workload size)
    if n <= 50:
        CAND_SAMPLE_BASE = 10     # candidate txn per step
        POS_SAMPLE_LIMIT = None   # evaluate all insertion positions
        MAX_LS_PASSES = 3         # local search passes for adjacent swaps
        RELOC_TRIES = max(8, n // 2)
    else:
        CAND_SAMPLE_BASE = 8
        POS_SAMPLE_LIMIT = 15     # cap insertion positions evaluated
        MAX_LS_PASSES = 2
        RELOC_TRIES = max(12, n // 3)

    # Scale relocation tries mildly with search effort to deepen local search
    RELOC_TRIES = int(RELOC_TRIES * max(1.0, min(2.0, 0.5 + 0.1 * max(1, num_seqs))))

    JITTER = 2  # small random variation in candidate set size

    # Memoized evaluation for partial prefixes to avoid redundant simulator calls
    cost_cache = {}
    def eval_cost(seq):
        key = tuple(seq)
        if key in cost_cache:
            return cost_cache[key]
        c = workload.get_opt_seq_cost(list(seq))
        cost_cache[key] = c
        return c

    def sample_positions(seq_len):
        # Return list of positions [0..seq_len] where insertion can occur
        if POS_SAMPLE_LIMIT is None or seq_len + 1 <= (POS_SAMPLE_LIMIT or (seq_len + 1)):
            return list(range(seq_len + 1))
        # Sample positions but always include ends to preserve global structure
        num_to_sample = max(2, min(POS_SAMPLE_LIMIT, seq_len + 1))
        mandatory = {0, seq_len}
        # Available interior positions
        interior = list(range(1, seq_len))
        if len(interior) <= num_to_sample - 2:
            chosen = set(interior)
        else:
            chosen = set(random.sample(interior, num_to_sample - 2))
        chosen.update(mandatory)
        return sorted(chosen)

    def best_insertion_for_txn(current_seq, txn):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos, regret), where regret = second_best_cost - best_cost.
        """
        seq_len = len(current_seq)
        best_cost = float('inf')
        second_best = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        for pos in positions:
            # Build candidate sequence with insertion
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                second_best = best_cost
                best_cost = cost
                best_pos = pos
            elif cost < second_best:
                second_best = cost
        regret = (second_best - best_cost) if second_best < float('inf') else 0.0
        return best_cost, best_pos, regret

    def construct_sequence():
        """
        Randomized best-insertion construction with regret-guided RCL.
        """
        remaining = all_txns.copy()

        # Choose a good starting transaction by sampling a few and picking lowest prefix cost
        k_start = min(8, len(remaining)) if len(remaining) > 0 else 0
        if k_start > 0:
            start_cands = random.sample(remaining, k_start)
            best_t = min(start_cands, key=lambda t: eval_cost([t]))
            seq = [best_t]
            remaining.remove(best_t)
        else:
            seq = []

        curr_cost = eval_cost(seq) if seq else 0.0

        # Optionally add a second txn by testing a small candidate set thoroughly with RCL
        if remaining:
            k = min(6, len(remaining))
            candidates = random.sample(remaining, k)
            pair_eval = []
            for t in candidates:
                for pos in [0, 1]:
                    cand = seq.copy()
                    cand.insert(pos, t)
                    cost = eval_cost(cand)
                    pair_eval.append((cost, t, pos))
            if pair_eval:
                pair_eval.sort(key=lambda x: x[0])
                rcl_size = min(3, len(pair_eval))
                chosen_cost, chosen_txn, chosen_pos = random.choice(pair_eval[:rcl_size])
                seq.insert(chosen_pos, chosen_txn)
                remaining.remove(chosen_txn)
                curr_cost = chosen_cost

        # Build the rest using sampled candidates and best insertion positions + regret-based RCL
        while remaining:
            # Adaptive candidate sample size with slight randomness and endgame widening
            dynamic_base = CAND_SAMPLE_BASE
            if len(remaining) <= max(8, 2 * dynamic_base):
                candidates = list(remaining)
            else:
                cand_size = min(len(remaining), max(3, dynamic_base + random.randint(-JITTER, JITTER)))
                candidates = random.sample(remaining, cand_size)

            step_evals = []
            for t in candidates:
                cost_t, pos_t, regret_t = best_insertion_for_txn(seq, t)
                step_evals.append((cost_t, t, pos_t, regret_t))

            if not step_evals:
                # Fallback: append a random remaining txn
                t = random.choice(remaining)
                seq.append(t)
                curr_cost = eval_cost(seq)
                remaining.remove(t)
                continue

            # Primary ranking by cost; small chance to pick high-regret from RCL for diversification
            step_evals.sort(key=lambda x: x[0])
            rcl_size = max(1, min(3, len(step_evals) // 2))
            rcl = step_evals[:rcl_size]
            choose_regret = random.random() < 0.3
            if choose_regret:
                rcl_by_regret = sorted(rcl, key=lambda x: x[3], reverse=True)
                chosen_cost, chosen_txn, chosen_pos, _ = rcl_by_regret[0]
            else:
                chosen_cost, chosen_txn, chosen_pos, _ = random.choice(rcl)

            seq.insert(chosen_pos, chosen_txn)
            curr_cost = chosen_cost
            remaining.remove(chosen_txn)

        return seq, curr_cost

    def local_search_adjacent_swaps(seq, curr_cost):
        """
        Perform multiple passes of adjacent swap hill-climbing.
        """
        improved = True
        passes = 0
        best_seq = list(seq)
        best_cost = curr_cost

        while improved and passes < MAX_LS_PASSES:
            improved = False
            passes += 1
            i = 0
            # One pass left-to-right
            while i < len(best_seq) - 1:
                cand = best_seq.copy()
                cand[i], cand[i + 1] = cand[i + 1], cand[i]
                c = eval_cost(cand)
                if c < best_cost:
                    best_cost = c
                    best_seq = cand
                    improved = True
                i += 1
        return best_seq, best_cost

    def local_search_best_reinsert(seq, curr_cost, max_rounds=2):
        """
        Deterministic best-improving reinsertion (Or-opt-1): for each index,
        reinsert txn at the position that yields the best cost if it improves.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        rounds = 0

        if len(best_seq) <= 2:
            return best_seq, best_cost

        while rounds < max_rounds:
            improved = False
            rounds += 1
            idx = 0
            while idx < len(best_seq):
                t = best_seq[idx]
                base = best_seq[:idx] + best_seq[idx + 1:]
                positions = sample_positions(len(base))
                move_best_cost = best_cost
                move_best_pos = None
                for pos in positions:
                    cand = base.copy()
                    cand.insert(pos, t)
                    c = eval_cost(cand)
                    if c < move_best_cost:
                        move_best_cost = c
                        move_best_pos = pos
                if move_best_pos is not None:
                    best_seq = base
                    best_seq.insert(move_best_pos, t)
                    best_cost = move_best_cost
                    improved = True
                    # stay at same idx neighborhood after change
                else:
                    idx += 1
            if not improved:
                break
        return best_seq, best_cost

    def local_search_relocations(seq, curr_cost):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        trials = 0
        # Early exit if trivial
        if len(best_seq) <= 2:
            return best_seq, best_cost

        while trials < RELOC_TRIES:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            # Adjust j if removal shifts indices
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                # On improvement, reset trials to keep exploring around new incumbent
                trials = 0
            else:
                trials += 1
        return best_seq, best_cost

    # Multi-start GRASP
    global_best_seq = None
    global_best_cost = float('inf')

    for _ in range(max(1, num_seqs)):
        seq, cost = construct_sequence()
        # Local search refinement: reinsertion, then adjacent swaps, then random relocations, polish
        seq, cost = local_search_best_reinsert(seq, cost, max_rounds=2)
        seq, cost = local_search_adjacent_swaps(seq, cost)
        seq, cost = local_search_relocations(seq, cost)
        # Final quick adjacent pass to capture small improvements
        seq, cost = local_search_adjacent_swaps(seq, cost)

        if cost < global_best_cost:
            global_best_cost = cost
            global_best_seq = seq

    # Safety checks
    assert global_best_seq is not None
    assert len(global_best_seq) == n
    assert len(set(global_best_seq)) == n

    return global_best_cost, global_best_seq
>>>>>>> REPLACE
</DIFF>