<NAME>
beam_vnd_ooropt_diversity
</NAME>
<DESCRIPTION>
I introduce three synergistic improvements to reduce makespan:

1) Regret-guided beam construction with regret-quota and diversity by suffix-2:
   - Replace the single-path regret insertion with a small beam of partial sequences that expands by best-insertion costs while reserving 1/3 of the beam slots for highest-regret candidates. This preserves strong exploitation while encouraging exploration where choices matter most. I also enforce diversity using a suffix-of-length-2 signature and deduplicate sequences, which reduces premature convergence and enhances coverage of promising neighborhoods.

2) Upgrade local refinement to VND with Or-opt blocks (sizes 3, 2, and 1), followed by adjacent swaps and sampled 2-opt:
   - Or-opt block reinsertion moves capture larger structural improvements that adjacent swaps and single reinsertion miss, while first-improvement VND keeps runtime in check. This is a known effective neighborhood for sequencing/scheduling problems, particularly with conflict-induced delays.

3) Smarter insertion position sampling:
   - When the sequence is small, evaluate all insertion positions deterministically; otherwise, keep the original focus-biased sampling. This improves accuracy in the critical early/endgame phases without excessive runtime.

Additionally, elite pool diversity is updated to suffix-2 signatures to prevent duplicates and encourage more varied high-quality elites. These targeted changes tighten constructive quality and deepen local search without heavy overhead, leading to lower makespans across workloads.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    # ----------------------------
    # Parameters (adaptive)
    # ----------------------------
    elite_size = max(3, min(6, 2 + num_seqs // 3))
    seed_elite_singletons = max(2, min(6, int(num_seqs)))
    seed_random_additional = max(1, min(4, int((num_seqs + 1) // 3)))

    # Candidate sampling sizes
    k_txn_sample = min(16, max(8, 2 + int(1.5 * num_seqs)))  # txns per insertion
    k_pos_sample = min(10, max(6, 2 + int(1.2 * num_seqs)))  # positions per insertion
    rem_all_threshold = 14                                    # when few remain, consider all txns

    # Regret selection probability (exploration vs exploitation)
    regret_prob = 0.65

    # Local search parameters
    ls_adj_rounds_max = 2
    two_opt_trials = min(35, max(12, n // 3))
    reinsertion_pos_factor = 1.0  # multiplier for k_pos_sample

    # Iterated local search (ILS) / perturbation
    ils_rounds = max(2, min(5, 1 + num_seqs // 4))
    perturb_swap_count = max(2, min(6, 2 + num_seqs // 3))
    perturb_block_len = max(3, min(10, 3 + num_seqs // 2))

    # Large Neighborhood Search (LNS)
    lns_iters = max(2, min(6, 2 + num_seqs // 3))
    destroy_frac_range = (0.08, 0.18)
=======
    # ----------------------------
    # Parameters (adaptive)
    # ----------------------------
    elite_size = max(3, min(6, 2 + num_seqs // 3))
    seed_elite_singletons = max(2, min(6, int(num_seqs)))
    seed_random_additional = max(1, min(4, int((num_seqs + 1) // 3)))

    # Candidate sampling sizes
    k_txn_sample = min(16, max(8, 2 + int(1.5 * num_seqs)))  # txns per insertion
    k_pos_sample = min(10, max(6, 2 + int(1.2 * num_seqs)))  # positions per insertion
    rem_all_threshold = 14                                    # when few remain, consider all txns

    # Regret selection probability (exploration vs exploitation)
    regret_prob = 0.65

    # Beam for constructive insertion
    build_beam_width = max(3, min(6, 2 + num_seqs // 2))
    beam_regret_quota = max(1, build_beam_width // 3)  # reserve some slots for high-regret
    beam_div_suffix = 2  # diversity by last-2 elements

    # Local search parameters
    ls_adj_rounds_max = 2
    two_opt_trials = min(35, max(12, n // 3))
    reinsertion_pos_factor = 1.0  # multiplier for k_pos_sample

    # Iterated local search (ILS) / perturbation
    ils_rounds = max(2, min(5, 1 + num_seqs // 4))
    perturb_swap_count = max(2, min(6, 2 + num_seqs // 3))
    perturb_block_len = max(3, min(10, 3 + num_seqs // 2))

    # Large Neighborhood Search (LNS)
    lns_iters = max(2, min(6, 2 + num_seqs // 3))
    destroy_frac_range = (0.08, 0.18)
>>>>>>> REPLACE
</DIFF>
<DIFF>
<<<<<<< SEARCH
    def position_samples(seq_len, focus_idx=None, k_positions=None):
        """Sample insertion positions; include anchors and positions near focus_idx if provided."""
        if seq_len <= 1:
            return [0, seq_len]
        k = k_positions if k_positions is not None else k_pos_sample
        pos_set = {0, seq_len, seq_len // 2}
        # Bias positions near the focus index (if provided)
        if focus_idx is not None:
            for d in [-3, -2, -1, 0, 1, 2, 3]:
                p = focus_idx + d
                if 0 <= p <= seq_len:
                    pos_set.add(p)
        # Add random internal positions
        for _ in range(min(k, seq_len + 1)):
            pos_set.add(random.randint(0, seq_len))
        return sorted(pos_set)
=======
    def position_samples(seq_len, focus_idx=None, k_positions=None):
        """Sample insertion positions; include anchors and positions near focus_idx if provided.
        When the sequence is small, evaluate all positions for accuracy."""
        if seq_len <= 1:
            return [0, seq_len]
        k = k_positions if k_positions is not None else k_pos_sample
        # For small sequences, check all positions deterministically
        if seq_len <= 12:
            return list(range(seq_len + 1))
        pos_set = {0, seq_len, seq_len // 2}
        # Bias positions near the focus index (if provided)
        if focus_idx is not None:
            for d in [-3, -2, -1, 0, 1, 2, 3]:
                p = focus_idx + d
                if 0 <= p <= seq_len:
                    pos_set.add(p)
        # Add random internal positions
        for _ in range(min(k, seq_len + 1)):
            pos_set.add(random.randint(0, seq_len))
        return sorted(pos_set)
>>>>>>> REPLACE
</DIFF>
<DIFF>
<<<<<<< SEARCH
    def regret_insertion_build(seed_t=None):
        """Construct a schedule using regret-based insertion."""
        if seed_t is None:
            seed_t = random.randint(0, n - 1)
        seq = [seed_t]
        rem = set(all_txns)
        rem.remove(seed_t)

        # Add second transaction by trying prepend/append among sampled candidates
        if rem:
            cand_txns = list(rem)
            if len(cand_txns) > k_txn_sample:
                cand_txns = random.sample(cand_txns, k_txn_sample)
            best_c2 = float('inf')
            best_seq2 = None
            best_t2 = None
            for t in cand_txns:
                seq_a = [t] + seq
                c_a = seq_cost(seq_a)
                seq_b = seq + [t]
                c_b = seq_cost(seq_b)
                if c_a < best_c2:
                    best_c2 = c_a
                    best_seq2 = seq_a
                    best_t2 = t
                if c_b < best_c2:
                    best_c2 = c_b
                    best_seq2 = seq_b
                    best_t2 = t
            if best_seq2 is not None:
                seq = best_seq2
                rem.remove(best_t2)

        while rem:
            # Candidate transactions
            if len(rem) <= rem_all_threshold:
                cand_txns = list(rem)
            else:
                cand_txns = random.sample(list(rem), min(k_txn_sample, len(rem)))

            # For each candidate transaction, evaluate best and second-best positions
            best_overall = (float('inf'), None, None)  # cost, txn, new_seq
            best_by_regret = (float('-inf'), None, None)  # regret, txn, new_seq

            for t in cand_txns:
                pos_list = position_samples(len(seq))
                best_c, best_p, second_c = evaluate_best_two_positions(seq, t, pos_list)
                # Track pure best
                if best_c < best_overall[0]:
                    new_seq = seq[:best_p] + [t] + seq[best_p:]
                    best_overall = (best_c, t, new_seq)
                # Track regret (second - best)
                regret = second_c - best_c if second_c < float('inf') else (0.0)
                if regret > best_by_regret[0]:
                    new_seq_r = seq[:best_p] + [t] + seq[best_p:]
                    best_by_regret = (regret, t, new_seq_r)

            # Choose according to regret_prob
            pick_regret = (random.random() < regret_prob)
            chosen = best_by_regret if pick_regret and best_by_regret[1] is not None else best_overall
            if chosen[1] is None:
                # Fallback random append
                t = random.choice(tuple(rem))
                seq = seq + [t]
                rem.remove(t)
            else:
                seq = chosen[2]
                rem.remove(chosen[1])

        return seq
=======
    def regret_insertion_build(seed_t=None):
        """Construct a schedule using regret-based insertion with a small beam and diversity."""
        if seed_t is None:
            seed_t = random.randint(0, n - 1)
        # Beam holds tuples: (seq, rem_set, cost)
        seq0 = [seed_t]
        rem0 = set(all_txns)
        rem0.remove(seed_t)
        beam = [(seq0, rem0, seq_cost(seq0))]

        # Optionally expand a second element to shape early order
        if rem0:
            expansions = []
            rem_list = list(rem0)
            cand_txns = rem_list if len(rem_list) <= k_txn_sample else random.sample(rem_list, k_txn_sample)
            for seq, rem, base_cost in beam:
                for t in cand_txns:
                    # Try prepend and append
                    s1 = [t] + seq
                    c1 = seq_cost(s1)
                    r1 = rem.copy()
                    if t in r1:
                        r1.remove(t)
                    expansions.append((s1, r1, c1, 0.0))
                    s2 = seq + [t]
                    c2 = seq_cost(s2)
                    r2 = rem.copy()
                    if t in r2:
                        r2.remove(t)
                    expansions.append((s2, r2, c2, 0.0))
            # Select top unique by suffix diversity
            expansions.sort(key=lambda x: x[2])
            next_beam = []
            seen_sig = set()
            for s, r, c, _ in expansions:
                sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                if sig in seen_sig:
                    continue
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                if len(next_beam) >= build_beam_width:
                    break
            if next_beam:
                beam = next_beam

        # Grow sequences until all are complete
        while True:
            if all(len(rem) == 0 for _, rem, _ in beam):
                break

            expansions = []
            seen_seqs = set()  # avoid duplicates by full sequence
            for seq, rem, base_cost in beam:
                if not rem:
                    key = tuple(seq)
                    if key not in seen_seqs:
                        seen_seqs.add(key)
                        expansions.append((seq, rem, base_cost, 0.0))
                    continue

                # Candidate transactions
                if len(rem) <= rem_all_threshold:
                    cand_txns = list(rem)
                else:
                    cand_txns = random.sample(list(rem), min(k_txn_sample, len(rem)))

                # For each candidate txn, compute best and second-best insertion pos
                for t in cand_txns:
                    # Use all positions when short sequence for accuracy
                    pos_list = position_samples(len(seq))
                    best_c, best_p, second_c = evaluate_best_two_positions(seq, t, pos_list)
                    new_seq = seq[:best_p] + [t] + seq[best_p:]
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    regret = (second_c - best_c) if second_c < float('inf') else 0.0
                    key = tuple(new_seq)
                    if key in seen_seqs:
                        continue
                    seen_seqs.add(key)
                    expansions.append((new_seq, new_rem, best_c, regret))

            if not expansions:
                break

            # Rank expansions for selection
            # Primary set: best by cost with diversity
            expansions_by_cost = sorted(expansions, key=lambda x: x[2])
            next_beam = []
            seen_sig = set()
            # First fill majority by cost
            cost_slots = max(1, build_beam_width - beam_regret_quota)
            for s, r, c, reg in expansions_by_cost:
                sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                if sig in seen_sig:
                    continue
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                if len(next_beam) >= cost_slots:
                    break

            # Then add some high-regret candidates for exploration
            if len(next_beam) < build_beam_width:
                expansions_by_regret = sorted(expansions, key=lambda x: (-x[3], x[2]))
                for s, r, c, reg in expansions_by_regret:
                    if len(next_beam) >= build_beam_width:
                        break
                    sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                    if sig in seen_sig:
                        continue
                    seen_sig.add(sig)
                    next_beam.append((s, r, c))

            # Fallback if something went wrong
            if not next_beam:
                next_beam = [(s, r, c) for s, r, c, _ in expansions_by_cost[:build_beam_width]]

            beam = next_beam

        # Select best complete sequence
        best_seq = None
        best_cost = float('inf')
        for seq, rem, cost in beam:
            if rem:
                # Append remaining deterministically and evaluate
                seq_complete = seq + sorted(list(rem))
                c = seq_cost(seq_complete)
                if c < best_cost:
                    best_cost = c
                    best_seq = seq_complete
            else:
                if cost < best_cost:
                    best_cost = cost
                    best_seq = seq
        return best_seq
>>>>>>> REPLACE
</DIFF>
<DIFF>
<<<<<<< SEARCH
    def local_refine(seq):
        best_seq = seq[:]
        best_cost = seq_cost(best_seq)
        improved_outer = True

        adj_rounds = 0

        def two_opt_sample_pass(cur_seq, cur_cost):
            tried = 0
            while tried < two_opt_trials:
                i = random.randint(0, n - 2)
                j = random.randint(i + 2, n - 1) if i + 2 < n else None
                tried += 1
                if j is None:
                    continue
                cand = cur_seq[:]
                cand[i], cand[j] = cand[j], cand[i]
                c = seq_cost(cand)
                if c < cur_cost:
                    return True, c, cand
            return False, cur_cost, cur_seq

        while improved_outer:
            improved_outer = False

            # Adjacent swap pass (limited rounds)
            if adj_rounds < ls_adj_rounds_max:
                improved = True
                while improved:
                    improved = False
                    for i in range(n - 1):
                        cand = best_seq[:]
                        cand[i], cand[i + 1] = cand[i + 1], cand[i]
                        c = seq_cost(cand)
                        if c < best_cost:
                            best_cost = c
                            best_seq = cand
                            improved = True
                            improved_outer = True
                            break
                adj_rounds += 1
                if improved_outer:
                    continue

            # Reinsertion pass: move one item to a better position
            reinsertion_done = False
            k_positions = max(6, int(reinsertion_pos_factor * k_pos_sample))
            for i in range(n):
                item = best_seq[i]
                base = best_seq[:i] + best_seq[i + 1:]
                # try positions near current i plus sampled set
                positions = position_samples(len(base), focus_idx=i, k_positions=k_positions)
                for p in positions:
                    cand = base[:p] + [item] + base[p:]
                    c = seq_cost(cand)
                    if c < best_cost:
                        best_cost = c
                        best_seq = cand
                        improved_outer = True
                        reinsertion_done = True
                        break
                if reinsertion_done:
                    break
            if improved_outer:
                continue

            # Sampled 2-opt pass (non-adjacent swaps)
            changed, new_cost, new_seq = two_opt_sample_pass(best_seq, best_cost)
            if changed:
                best_seq = new_seq
                best_cost = new_cost
                improved_outer = True

        return best_cost, best_seq
=======
    def local_refine(seq):
        best_seq = seq[:]
        best_cost = seq_cost(best_seq)
        improved_outer = True

        adj_rounds = 0

        def two_opt_sample_pass(cur_seq, cur_cost):
            tried = 0
            while tried < two_opt_trials:
                i = random.randint(0, n - 2)
                j = random.randint(i + 2, n - 1) if i + 2 < n else None
                tried += 1
                if j is None:
                    continue
                cand = cur_seq[:]
                cand[i], cand[j] = cand[j], cand[i]
                c = seq_cost(cand)
                if c < cur_cost:
                    return True, c, cand
            return False, cur_cost, cur_seq

        def or_opt_k(cur_seq, cur_cost, k_block):
            L = len(cur_seq)
            k_positions = max(6, int(reinsertion_pos_factor * k_pos_sample))
            for i in range(0, L - k_block + 1):
                block = cur_seq[i:i + k_block]
                base = cur_seq[:i] + cur_seq[i + k_block:]
                # Positions near original and sampled set
                positions = position_samples(len(base), focus_idx=i, k_positions=k_positions)
                # Avoid reinserting in the same place (no-op)
                for p in positions:
                    if p == i:
                        continue
                    cand = base[:p] + block + base[p:]
                    c = seq_cost(cand)
                    if c < cur_cost:
                        return True, c, cand
            return False, cur_cost, cur_seq

        while improved_outer:
            improved_outer = False

            # VND: Or-opt block moves (3,2,1)
            for blk in (3, 2, 1):
                changed, nc, ns = or_opt_k(best_seq, best_cost, blk)
                if changed:
                    best_seq, best_cost = ns, nc
                    improved_outer = True
                    break
            if improved_outer:
                continue

            # Adjacent swap pass (limited rounds)
            if adj_rounds < ls_adj_rounds_max:
                improved = True
                while improved:
                    improved = False
                    for i in range(n - 1):
                        cand = best_seq[:]
                        cand[i], cand[i + 1] = cand[i + 1], cand[i]
                        c = seq_cost(cand)
                        if c < best_cost:
                            best_cost = c
                            best_seq = cand
                            improved = True
                            improved_outer = True
                            break
                adj_rounds += 1
                if improved_outer:
                    continue

            # Sampled 2-opt pass (non-adjacent swaps)
            changed, new_cost, new_seq = two_opt_sample_pass(best_seq, best_cost)
            if changed:
                best_seq = new_seq
                best_cost = new_cost
                improved_outer = True

        return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>
<DIFF>
<<<<<<< SEARCH
    def add_elite(c, s):
        nonlocal elite
        elite.append((c, s))
        elite.sort(key=lambda x: x[0])
        # keep unique sequences by last element to add diversity cheaply
        uniq = []
        seen_end = set()
        for c1, s1 in elite:
            end = s1[-1] if s1 else None
            if end in seen_end:
                continue
            seen_end.add(end)
            uniq.append((c1, s1))
            if len(uniq) >= elite_size:
                break
        elite = uniq
=======
    def add_elite(c, s):
        nonlocal elite
        elite.append((c, s))
        elite.sort(key=lambda x: x[0])
        # keep unique sequences by last-2 suffix to add diversity cheaply
        uniq = []
        seen_sig = set()
        seen_full = set()
        for c1, s1 in elite:
            sig = tuple(s1[-2:]) if len(s1) >= 2 else tuple(s1)
            full = tuple(s1)
            if full in seen_full or sig in seen_sig:
                continue
            seen_full.add(full)
            seen_sig.add(sig)
            uniq.append((c1, s1))
            if len(uniq) >= elite_size:
                break
        elite = uniq
>>>>>>> REPLACE
</DIFF>