<NAME>
endgame_branch_and_bound_k8
</NAME>

<DESCRIPTION>
I add an exact endgame optimizer that performs a memoized branch-and-bound enumeration over the last K transactions (Kâ‰ˆ8) to minimize makespan precisely when the remaining set is small. This addresses the common failure mode where greedy regret insertion and local search miss the globally optimal ordering among the final few conflicting transactions. The optimizer explores all remaining transactions with best-position insertion (using the existing best_two_insertion) but enumerates orders, pruning via current best bound and partial costs. I integrate this in two critical places:

1) At the end of the constructive beam: when a beam state has <= K remaining transactions, I complete it using the endgame optimizer instead of appending a deterministic order. This improves final schedule quality directly under the true cost function.

2) In LNS repair: when the removed set size <= K, I invoke the same endgame optimizer to reinsert all removed transactions optimally into the remaining sequence, then refine. This yields a stronger rebuild than purely greedy regret.

I also add lightweight memoization across endgame calls and keep position evaluation deterministic via the existing best_two_insertion function. This change is targeted, reduces makespan on hard conflict tails, and maintains runtime by activating only when the remaining set is small.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # ----------------------------
    # Helpers
    # ----------------------------
    def position_samples(seq_len, focus_idx=None, k_positions=None):
        """Sample insertion positions; include anchors and positions near focus_idx if provided.
        When the sequence is small, evaluate all positions for accuracy."""
        if seq_len <= 1:
            return [0, seq_len]
        k = k_positions if k_positions is not None else k_pos_sample
        # For small sequences, check all positions deterministically
        if seq_len <= 12:
            return list(range(seq_len + 1))
        pos_set = {0, seq_len, seq_len // 2}
        # Bias positions near the focus index (if provided)
        if focus_idx is not None:
            for d in [-3, -2, -1, 0, 1, 2, 3]:
                p = focus_idx + d
                if 0 <= p <= seq_len:
                    pos_set.add(p)
        # Add random internal positions
        for _ in range(min(k, seq_len + 1)):
            pos_set.add(random.randint(0, seq_len))
        return sorted(pos_set)

    def evaluate_best_two_positions(base_seq, t, pos_list):
        """Return (best_cost, best_pos, second_best_cost) for inserting t into base_seq over pos_list."""
        best = (float('inf'), None)
        second = float('inf')
        for p in pos_list:
            cand = base_seq[:p] + [t] + base_seq[p:]
            c = seq_cost(cand)
            if c < best[0]:
                second = best[0]
                best = (c, p)
            elif c < second:
                second = c
        return best[0], best[1], second

    # Memoized best-two insertion per (sequence, txn, use_all_pos) with deterministic stratified positions
    best_two_cache = {}
    def best_two_insertion(base_seq, t, use_all_pos=False, focus_idx=None, k_positions=None):
        """
        Compute (best_cost, best_pos, second_best_cost) for inserting txn t into base_seq.
        - If use_all_pos or seq small, evaluate all positions exactly.
        - Else, deterministically sample anchors + a few interior positions (seeded by sequence suffix and t).
        Results are cached by (tuple(base_seq), t, use_all_pos) for reuse across beam and LNS phases.
        """
        key = (tuple(base_seq), t, bool(use_all_pos))
        if key in best_two_cache:
            return best_two_cache[key]
        L = len(base_seq)
        if use_all_pos or L <= 12:
            pos_list = list(range(L + 1))
        else:
            # Deterministic sampling: anchors + near focus + seeded interior
            pos_set = {0, L, L // 2, (L * 1) // 4, (L * 3) // 4}
            if focus_idx is not None:
                for d in (-3, -2, -1, 0, 1, 2, 3):
                    p = focus_idx + d
                    if 0 <= p <= L:
                        pos_set.add(p)
            cap = k_positions if k_positions is not None else k_pos_sample
            seed = (tuple(base_seq[-min(10, L):]), t, L)
            rng = random.Random(hash(seed) & 0xffffffff)
            for _ in range(min(cap, L + 1)):
                pos_set.add(rng.randint(0, L))
            pos_list = sorted(pos_set)
        res = evaluate_best_two_positions(base_seq, t, pos_list)
        best_two_cache[key] = res
        return res

    def regret_insertion_build(seed_t=None):
=======
    # ----------------------------
    # Helpers
    # ----------------------------
    def position_samples(seq_len, focus_idx=None, k_positions=None):
        """Sample insertion positions; include anchors and positions near focus_idx if provided.
        When the sequence is small, evaluate all positions for accuracy."""
        if seq_len <= 1:
            return [0, seq_len]
        k = k_positions if k_positions is not None else k_pos_sample
        # For small sequences, check all positions deterministically
        if seq_len <= 12:
            return list(range(seq_len + 1))
        pos_set = {0, seq_len, seq_len // 2}
        # Bias positions near the focus index (if provided)
        if focus_idx is not None:
            for d in [-3, -2, -1, 0, 1, 2, 3]:
                p = focus_idx + d
                if 0 <= p <= seq_len:
                    pos_set.add(p)
        # Add random internal positions
        for _ in range(min(k, seq_len + 1)):
            pos_set.add(random.randint(0, seq_len))
        return sorted(pos_set)

    def evaluate_best_two_positions(base_seq, t, pos_list):
        """Return (best_cost, best_pos, second_best_cost) for inserting t into base_seq over pos_list."""
        best = (float('inf'), None)
        second = float('inf')
        for p in pos_list:
            cand = base_seq[:p] + [t] + base_seq[p:]
            c = seq_cost(cand)
            if c < best[0]:
                second = best[0]
                best = (c, p)
            elif c < second:
                second = c
        return best[0], best[1], second

    # Memoized best-two insertion per (sequence, txn, use_all_pos) with deterministic stratified positions
    best_two_cache = {}
    def best_two_insertion(base_seq, t, use_all_pos=False, focus_idx=None, k_positions=None):
        """
        Compute (best_cost, best_pos, second_best_cost) for inserting txn t into base_seq.
        - If use_all_pos or seq small, evaluate all positions exactly.
        - Else, deterministically sample anchors + a few interior positions (seeded by sequence suffix and t).
        Results are cached by (tuple(base_seq), t, use_all_pos) for reuse across beam and LNS phases.
        """
        key = (tuple(base_seq), t, bool(use_all_pos))
        if key in best_two_cache:
            return best_two_cache[key]
        L = len(base_seq)
        if use_all_pos or L <= 12:
            pos_list = list(range(L + 1))
        else:
            # Deterministic sampling: anchors + near focus + seeded interior
            pos_set = {0, L, L // 2, (L * 1) // 4, (L * 3) // 4}
            if focus_idx is not None:
                for d in (-3, -2, -1, 0, 1, 2, 3):
                    p = focus_idx + d
                    if 0 <= p <= L:
                        pos_set.add(p)
            cap = k_positions if k_positions is not None else k_pos_sample
            seed = (tuple(base_seq[-min(10, L):]), t, L)
            rng = random.Random(hash(seed) & 0xffffffff)
            for _ in range(min(cap, L + 1)):
                pos_set.add(rng.randint(0, L))
            pos_list = sorted(pos_set)
        res = evaluate_best_two_positions(base_seq, t, pos_list)
        best_two_cache[key] = res
        return res

    # ----------------------------
    # Endgame exact completion (branch-and-bound over last K txns)
    # ----------------------------
    endgame_enum_K = max(6, min(9, endgame_all_pos_threshold + 3))
    endgame_memo = {}
    def endgame_optimal_completion(prefix_seq, rem_set):
        """
        Given a prefix sequence and a small remaining set of txns (|rem_set| <= K),
        enumerate txn orders with best-position insertion to find the minimal-cost completion.
        Uses branch-and-bound with the current best bound and partial-cost pruning.
        Returns (best_cost, best_seq).
        """
        key0 = (tuple(prefix_seq), frozenset(rem_set))
        if key0 in endgame_memo:
            return endgame_memo[key0]

        best_c = float('inf')
        best_s = None

        def dfs(seq, rem):
            nonlocal best_c, best_s
            # Prune by current partial cost
            c_prefix = seq_cost(seq)
            if c_prefix >= best_c:
                return
            if not rem:
                if c_prefix < best_c:
                    best_c = c_prefix
                    best_s = seq[:]
                return
            # Order candidates by high regret first, then by lower best insertion cost
            order = []
            for t in rem:
                b, p, s2 = best_two_insertion(seq, t, use_all_pos=True)
                regret = (s2 - b) if s2 < float('inf') else 0.0
                order.append((-regret, b, t, p))
            order.sort()
            for _, bcost, t, p in order:
                if bcost >= best_c:
                    continue
                new_seq = seq[:p] + [t] + seq[p:]
                new_rem = rem.copy()
                new_rem.remove(t)
                dfs(new_seq, new_rem)

        dfs(prefix_seq[:], set(rem_set))
        if best_s is None:
            # Fallback: deterministic append to avoid None
            seq_complete = prefix_seq[:] + sorted(list(rem_set))
            best_c = seq_cost(seq_complete)
            best_s = seq_complete
        endgame_memo[key0] = (best_c, best_s)
        return best_c, best_s

    def regret_insertion_build(seed_t=None):
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        # Choose best complete
        best_seq = None
        best_cost = float('inf')
        for seq, rem, cost in beam:
            if rem:
                # append rest deterministically then evaluate
                seq_complete = seq[:] + sorted(list(rem))
                c = seq_cost(seq_complete)
                if c < best_cost:
                    best_cost = c
                    best_seq = seq_complete
            else:
                if cost < best_cost:
                    best_cost = cost
                    best_seq = seq

        return best_seq
=======
        # Choose best complete (use exact endgame when few remain)
        best_seq = None
        best_cost = float('inf')
        for seq, rem, cost in beam:
            if not rem:
                # Already complete
                c = cost
                s = seq
            else:
                if len(rem) <= endgame_enum_K:
                    c, s = endgame_optimal_completion(seq, rem)
                else:
                    # append rest deterministically then evaluate
                    seq_complete = seq[:] + sorted(list(rem))
                    c = seq_cost(seq_complete)
                    s = seq_complete
            if c < best_cost:
                best_cost = c
                best_seq = s

        return best_seq
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        seq_rep = remaining[:]
        rem_set = removed[:]
        while rem_set:
            if len(rem_set) > k_txn_sample:
                cand_txns = random.sample(rem_set, k_txn_sample)
            else:
                cand_txns = rem_set[:]

            best_overall = (float('inf'), None, None)  # cost, txn, new_seq
            best_by_regret = (float('-inf'), None, None)

            for t in cand_txns:
                use_all = (len(rem_set) <= endgame_all_pos_threshold) or (len(seq_rep) <= 18)
                best_c, best_p, second_c = best_two_insertion(seq_rep, t, use_all_pos=use_all)
                # Track pure best
                if best_c < best_overall[0]:
                    new_seq = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_overall = (best_c, t, new_seq)
                # Track regret
                regret = second_c - best_c if second_c < float('inf') else 0.0
                if regret > best_by_regret[0]:
                    new_seq_r = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_by_regret = (regret, t, new_seq_r)

            pick_regret = (random.random() < regret_prob)
            chosen = best_by_regret if pick_regret and best_by_regret[1] is not None else best_overall
            if chosen[1] is None:
                t = random.choice(rem_set)
                seq_rep = seq_rep + [t]
                rem_set.remove(t)
            else:
                seq_rep = chosen[2]
                rem_set.remove(chosen[1])

        c_rep, s_rep = local_refine(seq_rep)
        return c_rep, s_rep
=======
        seq_rep = remaining[:]
        rem_set = removed[:]
        # Exact endgame rebuild when small
        if len(rem_set) <= endgame_enum_K:
            c_end, s_end = endgame_optimal_completion(seq_rep, set(rem_set))
            c_rep, s_rep = local_refine(s_end)
            return c_rep, s_rep

        while rem_set:
            if len(rem_set) > k_txn_sample:
                cand_txns = random.sample(rem_set, k_txn_sample)
            else:
                cand_txns = rem_set[:]

            best_overall = (float('inf'), None, None)  # cost, txn, new_seq
            best_by_regret = (float('-inf'), None, None)

            for t in cand_txns:
                use_all = (len(rem_set) <= endgame_all_pos_threshold) or (len(seq_rep) <= 18)
                best_c, best_p, second_c = best_two_insertion(seq_rep, t, use_all_pos=use_all)
                # Track pure best
                if best_c < best_overall[0]:
                    new_seq = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_overall = (best_c, t, new_seq)
                # Track regret
                regret = second_c - best_c if second_c < float('inf') else 0.0
                if regret > best_by_regret[0]:
                    new_seq_r = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_by_regret = (regret, t, new_seq_r)

            pick_regret = (random.random() < regret_prob)
            chosen = best_by_regret if pick_regret and best_by_regret[1] is not None else best_overall
            if chosen[1] is None:
                t = random.choice(rem_set)
                seq_rep = seq_rep + [t]
                rem_set.remove(t)
            else:
                seq_rep = chosen[2]
                rem_set.remove(chosen[1])

        c_rep, s_rep = local_refine(seq_rep)
        return c_rep, s_rep
>>>>>>> REPLACE

</DIFF>