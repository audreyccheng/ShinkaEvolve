<NAME>
best_two_cache_regret_lns_pair_swaps
</NAME>

<DESCRIPTION>
I propose three targeted improvements that directly reduce makespan by modeling conflict-sensitive choices more accurately while reusing evaluations efficiently:

1) Deterministic best-two insertion caching: Replace random position sampling with deterministic, stratified positions and add a per-episode best_two_cache keyed by (tuple(seq), txn, pos_signature). This allows reuse across construction, LNS, and local search, reducing simulator calls and enabling regret awareness without extra runtime.

2) Regret-guided LNS reinsertion using best-two: During ruin-and-recreate, select which removed transaction to reinsert next by comparing best and second-best insertion costs (regret). This targets transactions whose placement decision is most consequential for conflicts, yielding better reconstructions than greedily picking by best cost alone.

3) Stronger VND with sampled non-adjacent pair swaps: Add a fast sampled non-adjacent pair swap operator to the VND loop. This complements Or-opt and adjacent swaps by efficiently exploring long-range changes that can break entrenched conflict chains and shorten the schedule.

These changes preserve the existing structure and parameters, but materially increase solution quality by exploiting regret signals and broader neighborhoods while controlling evaluation cost through deterministic caching.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Cost cache for partial prefixes to reduce repeated evaluations
    cost_cache = {}

    def eval_cost(prefix):
        """Evaluate and cache the cost for a (possibly partial) prefix sequence."""
        key = tuple(prefix)
        if key in cost_cache:
            return cost_cache[key]
        c = workload.get_opt_seq_cost(list(prefix))
        cost_cache[key] = c
        return c
=======
    # Cost cache for partial prefixes to reduce repeated evaluations
    cost_cache = {}
    # Best-two insertion cache across the episode:
    # key: (('all', seq_len) or tuple(positions), tuple(seq), txn) -> (best_cost, best_pos, second_best_cost)
    best_two_cache = {}

    def eval_cost(prefix):
        """Evaluate and cache the cost for a (possibly partial) prefix sequence."""
        key = tuple(prefix)
        if key in cost_cache:
            return cost_cache[key]
        c = workload.get_opt_seq_cost(list(prefix))
        cost_cache[key] = c
        return c
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def sample_positions(seq_len):
        """Return list of positions [0..seq_len] where insertion can occur, with optional sampling."""
        if POS_SAMPLE_LIMIT is None or seq_len + 1 <= (POS_SAMPLE_LIMIT or (seq_len + 1)):
            return list(range(seq_len + 1))
        # Sample positions but always include ends to preserve global structure
        num_to_sample = max(2, min(POS_SAMPLE_LIMIT, seq_len + 1))
        mandatory = {0, seq_len}
        interior = list(range(1, seq_len))
        if len(interior) <= num_to_sample - 2:
            chosen = set(interior)
        else:
            chosen = set(random.sample(interior, num_to_sample - 2))
        chosen.update(mandatory)
        return sorted(chosen)
=======
    def sample_positions(seq_len):
        """Return deterministic stratified positions [0..seq_len] for insertion; include ends and evenly spaced anchors."""
        total = seq_len + 1
        if POS_SAMPLE_LIMIT is None or total <= POS_SAMPLE_LIMIT:
            return list(range(total))
        # Evenly spaced anchors including both ends; deterministic for caching
        k = max(2, min(POS_SAMPLE_LIMIT - 1, total - 1))
        anchors = {0, seq_len}
        for i in range(1, k):
            pos = round(i * seq_len / k)
            pos = max(0, min(seq_len, pos))
            anchors.add(pos)
        return sorted(anchors)
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def best_insertion_for_txn(current_seq, txn):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos, second_best_cost) to enable regret-based selection.
        """
        seq_len = len(current_seq)
        best_cost = float('inf')
        second_best = float('inf')
        best_pos = 0
        positions = sample_positions(seq_len)
        # Evaluate each possible position, track the two best costs
        for pos in positions:
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                second_best = best_cost
                best_cost = cost
                best_pos = pos
            elif cost < second_best:
                second_best = cost
        # In case we only had one position, second_best may remain inf; normalize
        if second_best == float('inf'):
            second_best = best_cost
        return best_cost, best_pos, second_best
=======
    def best_insertion_for_txn(current_seq, txn):
        """
        Try inserting txn into multiple positions in current_seq.
        Returns (best_cost, best_pos, second_best_cost) using a deterministic position set and a cache.
        """
        seq_len = len(current_seq)
        full = (POS_SAMPLE_LIMIT is None) or (seq_len + 1 <= POS_SAMPLE_LIMIT)
        if full:
            positions = list(range(seq_len + 1))
            sig = ('all', seq_len)
        else:
            positions = sample_positions(seq_len)
            sig = tuple(positions)
        key = (sig, tuple(current_seq), txn)
        cached = best_two_cache.get(key)
        if cached is not None:
            return cached

        best_cost = float('inf')
        second_best = float('inf')
        best_pos = 0
        for pos in positions:
            cand = current_seq.copy()
            cand.insert(pos, txn)
            cost = eval_cost(cand)
            if cost < best_cost:
                second_best = best_cost
                best_cost = cost
                best_pos = pos
            elif cost < second_best:
                second_best = cost
        if second_best == float('inf'):
            second_best = best_cost
        res = (best_cost, best_pos, second_best)
        best_two_cache[key] = res
        return res
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def local_search_relocations(seq, curr_cost, tries=RELOC_TRIES):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        Accepts first improving move and continues until no improvement across budgeted tries.
        """
        best_seq = list(seq)
        best_cost = curr_cost

        if len(best_seq) <= 2:
            return best_seq, best_cost

        trials = 0
        while trials < tries:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                trials = 0  # reset upon improvement
            else:
                trials += 1
        return best_seq, best_cost

    def or_opt_block(seq, curr_cost, k):
=======
    def local_search_relocations(seq, curr_cost, tries=RELOC_TRIES):
        """
        Random relocation: remove at index i and reinsert at j if improves.
        Accepts first improving move and continues until no improvement across budgeted tries.
        """
        best_seq = list(seq)
        best_cost = curr_cost

        if len(best_seq) <= 2:
            return best_seq, best_cost

        trials = 0
        while trials < tries:
            i = random.randint(0, len(best_seq) - 1)
            j = random.randint(0, len(best_seq) - 1)
            if i == j:
                trials += 1
                continue
            cand = best_seq.copy()
            t = cand.pop(i)
            if j > i:
                j -= 1
            cand.insert(j, t)
            c = eval_cost(cand)
            if c < best_cost:
                best_cost = c
                best_seq = cand
                trials = 0  # reset upon improvement
            else:
                trials += 1
        return best_seq, best_cost

    def local_search_pair_swaps(seq, curr_cost, tries=None):
        """
        Sampled non-adjacent pair swaps: explore random pairs and apply the best improving swap.
        Complements Or-opt and adjacent swaps to resolve distant conflicts.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        L = len(best_seq)
        if L <= 3:
            return best_seq, best_cost
        if tries is None:
            tries = min(200, max(60, n))

        best_delta = 0.0
        best_pair = None
        for _ in range(tries):
            i = random.randint(0, L - 1)
            j = random.randint(0, L - 1)
            if i == j or abs(i - j) <= 1:
                continue
            cand = best_seq[:]
            cand[i], cand[j] = cand[j], cand[i]
            c = eval_cost(cand)
            delta = best_cost - c
            if delta > best_delta:
                best_delta = delta
                best_pair = (i, j)
        if best_pair is not None and best_delta > 0:
            i, j = best_pair
            best_seq[i], best_seq[j] = best_seq[j], best_seq[i]
            best_cost = eval_cost(best_seq)
        return best_seq, best_cost

    def or_opt_block(seq, curr_cost, k):
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def vnd_local_search(seq, curr_cost):
        """
        Variable Neighborhood Descent:
        Or-opt blocks k=3,2,1 (best-improving), then adjacent swaps, then light relocations.
        Repeat cycle until no further improvement.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        changed = True
        while changed:
            changed = False
            for k in (3, 2, 1):
                s, c = or_opt_block(best_seq, best_cost, k)
                if c < best_cost:
                    best_seq, best_cost = s, c
                    changed = True
            s, c = local_search_adjacent_swaps(best_seq, best_cost, max_passes=1)
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
            s, c = local_search_relocations(best_seq, best_cost, tries=max(8, RELOC_TRIES // 2))
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
        return best_seq, best_cost
=======
    def vnd_local_search(seq, curr_cost):
        """
        Variable Neighborhood Descent:
        Or-opt blocks k=3,2,1 (best-improving), then adjacent swaps, then sampled pair swaps,
        then light relocations. Repeat cycle until no further improvement.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        changed = True
        while changed:
            changed = False
            for k in (3, 2, 1):
                s, c = or_opt_block(best_seq, best_cost, k)
                if c < best_cost:
                    best_seq, best_cost = s, c
                    changed = True
            s, c = local_search_adjacent_swaps(best_seq, best_cost, max_passes=1)
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
            s, c = local_search_pair_swaps(best_seq, best_cost, tries=min(200, max(60, n)))
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
            s, c = local_search_relocations(best_seq, best_cost, tries=max(8, RELOC_TRIES // 2))
            if c < best_cost:
                best_seq, best_cost = s, c
                changed = True
        return best_seq, best_cost
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def lns_ruin_recreate(seq, curr_cost, rounds=2):
        """
        Ruin-and-recreate LNS: remove a contiguous block (plus a few random extras) and reinsert greedily.
        Accept only improving reconstructions; repeat for a few rounds.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        for _ in range(max(1, rounds)):
            L = len(best_seq)
            if L < 6:
                break
            # Choose block to remove
            base_len = max(4, L // 10)
            block_len = min(L - 2, base_len + random.randint(0, 3))
            start = random.randint(0, L - block_len)
            removed = best_seq[start:start + block_len]
            skeleton = best_seq[:start] + best_seq[start + block_len:]
            # Optionally remove a few extras for diversification
            extra_count = min(3, max(0, L // 30))
            extras_idx = sorted(random.sample(range(len(skeleton)), extra_count)) if extra_count and len(skeleton) > extra_count else []
            extras = []
            offset = 0
            for idx in extras_idx:
                idx_adj = idx - offset
                extras.append(skeleton.pop(idx_adj))
                offset += 1
            to_insert = removed + extras

            # Reinsert removed items using best insertion positions
            rebuilt = list(skeleton)
            for t in to_insert:
                best_c = float('inf')
                best_p = 0
                positions = sample_positions(len(rebuilt))
                for pos in positions:
                    cand = rebuilt[:]
                    cand.insert(pos, t)
                    c = eval_cost(cand)
                    if c < best_c:
                        best_c = c
                        best_p = pos
                rebuilt.insert(best_p, t)

            c_final = eval_cost(rebuilt)
            if c_final < best_cost:
                best_cost = c_final
                best_seq = rebuilt
        return best_seq, best_cost
=======
    def lns_ruin_recreate(seq, curr_cost, rounds=2):
        """
        Ruin-and-recreate LNS: remove a contiguous block (plus a few random extras) and rebuild
        via regret-guided reinsertion using cached best-two insertions.
        Accept only improving reconstructions; repeat for a few rounds.
        """
        best_seq = list(seq)
        best_cost = curr_cost
        for _ in range(max(1, rounds)):
            L = len(best_seq)
            if L < 6:
                break
            # Choose block to remove
            base_len = max(4, L // 10)
            block_len = min(L - 2, base_len + random.randint(0, 3))
            start = random.randint(0, L - block_len)
            removed = best_seq[start:start + block_len]
            skeleton = best_seq[:start] + best_seq[start + block_len:]
            # Optionally remove a few extras for diversification
            extra_count = min(3, max(0, L // 30))
            extras_idx = sorted(random.sample(range(len(skeleton)), extra_count)) if extra_count and len(skeleton) > extra_count else []
            extras = []
            offset = 0
            for idx in extras_idx:
                idx_adj = idx - offset
                extras.append(skeleton.pop(idx_adj))
                offset += 1
            to_insert = removed + extras

            # Regret-guided reinsertion using best-two insertion cache
            rebuilt = list(skeleton)
            remaining = list(to_insert)
            while remaining:
                # sample a subset to speed up if many left
                k_t = min(len(remaining), max(4, len(remaining) // 2))
                cand_txns = remaining if len(remaining) <= k_t else random.sample(remaining, k_t)
                scored = []
                for t in cand_txns:
                    best_c, best_p, second_c = best_insertion_for_txn(rebuilt, t)
                    regret = max(0.0, second_c - best_c)
                    scored.append((regret, best_c, best_p, t))
                if not scored:
                    # fallback
                    t = remaining.pop()
                    rebuilt.append(t)
                    continue
                # Choose highest regret; tie-break on best cost
                scored.sort(key=lambda x: (-x[0], x[1]))
                regret, best_c, best_p, t = scored[0]
                rebuilt.insert(best_p, t)
                remaining.remove(t)

            c_final = eval_cost(rebuilt)
            if c_final < best_cost:
                best_cost = c_final
                best_seq = rebuilt
        return best_seq, best_cost
>>>>>>> REPLACE
</DIFF>