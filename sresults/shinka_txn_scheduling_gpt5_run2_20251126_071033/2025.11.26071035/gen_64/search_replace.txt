<NAME>
best_two_lru_and_bidirectional_relink
</NAME>

<DESCRIPTION>
I introduce a best-two insertion memoization with a lightweight LRU cache and deterministic position sampling to avoid repeated simulator calls for the same (prefix, txn) evaluation. This is used during construction and LNS repair to compute the best and second-best insertion positions efficiently, enabling higher positional accuracy (using all positions for small sequences and a deterministic stratified sample otherwise) without excessive runtime. I also upgrade the elite path relinking to a bidirectional relinking followed by a quick local polish, which helps convert good intermediate alignments into real makespan gains. These changes directly target makespan by evaluating actual schedule costs more thoroughly where it matters (insertion decisions and elite combination) while keeping runtime controlled via caching and deterministic sampling.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
import time
import random
import sys
import os
=======
import time
import random
import sys
import os
from collections import OrderedDict
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def evaluate_best_two_positions(base_seq, t, pos_list):
        """Return (best_cost, best_pos, second_best_cost) for inserting t into base_seq over pos_list."""
        best = (float('inf'), None)
        second = float('inf')
        for p in pos_list:
            cand = base_seq[:p] + [t] + base_seq[p:]
            c = seq_cost(cand)
            if c < best[0]:
                second = best[0]
                best = (c, p)
            elif c < second:
                second = c
        return best[0], best[1], second
=======
    def evaluate_best_two_positions(base_seq, t, pos_list):
        """Return (best_cost, best_pos, second_best_cost) for inserting t into base_seq over pos_list."""
        best = (float('inf'), None)
        second = float('inf')
        for p in pos_list:
            cand = base_seq[:p] + [t] + base_seq[p:]
            c = seq_cost(cand)
            if c < best[0]:
                second = best[0]
                best = (c, p)
            elif c < second:
                second = c
        return best[0], best[1], second

    # Best-two insertion memo with deterministic position sampling and simple LRU pruning
    best_two_cache = OrderedDict()
    # Cap scaled by search breadth but bounded
    best_two_cache_cap = max(8000, min(20000, 3000 * max(1, num_seqs)))

    def best_two_insertion(base_seq, t, use_all_pos=False, focus_idx=None, k_positions=None):
        """
        Compute (best_cost, best_pos, second_best_cost) for inserting txn t into base_seq.
        Caches results per (tuple(base_seq), t, pos_sig) where pos_sig encodes whether all positions
        are used or sampled for current length. Sampling is deterministic to maximize cache hits.
        """
        L = len(base_seq)
        # Build a compact position signature for cache key
        pos_sig = ('all', L) if (use_all_pos or L <= 12) else ('sample', L)
        key = (tuple(base_seq), t, pos_sig)
        if key in best_two_cache:
            # LRU touch
            val = best_two_cache.pop(key)
            best_two_cache[key] = val
            return val

        if use_all_pos or L <= 12:
            pos_list = list(range(L + 1))
        else:
            # Deterministic stratified sampling: anchors + seeded interior + optional focus vicinity
            pos_set = {0, L, L // 2, (L * 1) // 4, (L * 3) // 4}
            if focus_idx is not None:
                for d in (-3, -2, -1, 0, 1, 2, 3):
                    p = focus_idx + d
                    if 0 <= p <= L:
                        pos_set.add(p)
            cap = k_positions if k_positions is not None else k_pos_sample
            seed = (tuple(base_seq[-min(10, L):]), t, L)
            rng = random.Random(hash(seed) & 0xffffffff)
            for _ in range(min(cap, L + 1)):
                pos_set.add(rng.randint(0, L))
            pos_list = sorted(pos_set)

        res = evaluate_best_two_positions(base_seq, t, pos_list)
        best_two_cache[key] = res
        # LRU prune if needed
        if len(best_two_cache) > best_two_cache_cap:
            best_two_cache.popitem(last=False)
        return res
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                # For each candidate txn, compute best and second-best insertion pos
                for t in cand_txns:
                    # Use all positions when short sequence for accuracy
                    pos_list = position_samples(len(seq))
                    best_c, best_p, second_c = evaluate_best_two_positions(seq, t, pos_list)
=======
                # For each candidate txn, compute best and second-best insertion pos
                for t in cand_txns:
                    # Use all positions when short sequence/endgame for accuracy
                    use_all = (len(rem) <= rem_all_threshold) or (len(seq) <= 18)
                    best_c, best_p, second_c = best_two_insertion(seq, t, use_all_pos=use_all)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
            for t in cand_txns:
                pos_list = position_samples(len(seq_rep))
                best_c, best_p, second_c = evaluate_best_two_positions(seq_rep, t, pos_list)
                # Track pure best
                if best_c < best_overall[0]:
                    new_seq = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_overall = (best_c, t, new_seq)
                # Track regret
                regret = second_c - best_c if second_c < float('inf') else 0.0
                if regret > best_by_regret[0]:
                    new_seq_r = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_by_regret = (regret, t, new_seq_r)
=======
            for t in cand_txns:
                use_all = (len(rem_set) <= rem_all_threshold) or (len(seq_rep) <= 18)
                best_c, best_p, second_c = best_two_insertion(seq_rep, t, use_all_pos=use_all)
                # Track pure best
                if best_c < best_overall[0]:
                    new_seq = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_overall = (best_c, t, new_seq)
                # Track regret
                regret = second_c - best_c if second_c < float('inf') else 0.0
                if regret > best_by_regret[0]:
                    new_seq_r = seq_rep[:best_p] + [t] + seq_rep[best_p:]
                    best_by_regret = (regret, t, new_seq_r)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    if len(elite) >= 2:
        base_cost, base_seq = best_overall_cost, best_overall_seq
        # Try relinking with a few elite partners
        partners = elite[1:min(len(elite), elite_size)]
        for c_t, s_t in partners:
            pr_c, pr_s = path_relink(base_seq, s_t, max_moves=max(8, min(12, n // 8)))
            if pr_c < best_overall_cost:
                best_overall_cost, best_overall_seq = pr_c, pr_s
=======
    if len(elite) >= 2:
        base_cost, base_seq = best_overall_cost, best_overall_seq
        # Try relinking with a few elite partners (bidirectional) and quick polish
        partners = elite[1:min(len(elite), elite_size)]
        for c_t, s_t in partners:
            pr1_c, pr1_s = path_relink(base_seq, s_t, max_moves=max(8, min(12, n // 8)))
            pr2_c, pr2_s = path_relink(s_t, base_seq, max_moves=max(8, min(12, n // 8)))
            cand_c, cand_s = (pr1_c, pr1_s) if pr1_c <= pr2_c else (pr2_c, pr2_s)
            if cand_c < best_overall_cost:
                lc, ls = local_refine(cand_s)
                if lc < best_overall_cost:
                    best_overall_cost, best_overall_seq = lc, ls
                else:
                    best_overall_cost, best_overall_seq = cand_c, cand_s
>>>>>>> REPLACE

</DIFF>