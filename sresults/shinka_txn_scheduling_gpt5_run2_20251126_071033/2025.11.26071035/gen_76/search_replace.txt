<NAME>
endgame_bnb_for_last_k
</NAME>

<DESCRIPTION>
I add a bounded branch-and-bound (BnB) endgame enumerator for the last K transactions and supporting helpers. This directly addresses makespan minimization by exploring multiple insertion choices near the end, where greedy regret alone can miss optimal completions. Specifically:
- Introduce evaluate_top_positions to return top-2 insertion positions for a transaction, reducing branching to the most promising placements.
- Implement endgame_bnb, a depth-first search with pruning using a memoized cost function, regret-guided ordering, and a small time budget. It explores best and second-best positions for top few transactions, providing a strong completion.
- Integrate this BnB into regret_insertion_build: when any beam state has <= K remaining, we invoke BnB on up to two best states and return the best completion found.

This approach increases solution quality by explicitly searching a small combinatorial space where it matters most, while keeping runtime predictable through a tight time budget and bounded branching. It leverages existing memoization (seq_cost) and best-two insertion guidance for efficiency.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Cache for best-two insertion per (sequence, txn, policy) within a run
    best_two_cache = {}

    def best_two_insertion(base_seq, t, use_all_pos=False, focus_idx=None, k_positions=None):
        """
        Deterministically sample positions and compute best and second-best insertion of t into base_seq.
        Caches results per (tuple(base_seq), t, use_all_pos) to avoid recomputation across beam/LNS.
        """
        key = (tuple(base_seq), t, bool(use_all_pos))
        if key in best_two_cache:
            return best_two_cache[key]
        L = len(base_seq)
        if use_all_pos or L <= 12:
            pos_list = list(range(L + 1))
        else:
            # Deterministic stratified sampling around anchors and (optionally) focus
            rng = random.Random((hash((tuple(base_seq[-min(10, L):]), t, L)) & 0xffffffff))
            pos_set = {0, L, L // 2, (L * 1) // 4, (L * 3) // 4}
            if focus_idx is not None:
                for d in (-3, -2, -1, 0, 1, 2, 3):
                    p = focus_idx + d
                    if 0 <= p <= L:
                        pos_set.add(p)
            cap = k_positions if k_positions is not None else k_pos_sample
            for _ in range(min(cap, L + 1)):
                pos_set.add(rng.randint(0, L))
            pos_list = sorted(pos_set)
        res = evaluate_best_two_positions(base_seq, t, pos_list)
        best_two_cache[key] = res
        return res
=======
    # Cache for best-two insertion per (sequence, txn, policy) within a run
    best_two_cache = {}

    def best_two_insertion(base_seq, t, use_all_pos=False, focus_idx=None, k_positions=None):
        """
        Deterministically sample positions and compute best and second-best insertion of t into base_seq.
        Caches results per (tuple(base_seq), t, use_all_pos) to avoid recomputation across beam/LNS.
        """
        key = (tuple(base_seq), t, bool(use_all_pos))
        if key in best_two_cache:
            return best_two_cache[key]
        L = len(base_seq)
        if use_all_pos or L <= 12:
            pos_list = list(range(L + 1))
        else:
            # Deterministic stratified sampling around anchors and (optionally) focus
            rng = random.Random((hash((tuple(base_seq[-min(10, L):]), t, L)) & 0xffffffff))
            pos_set = {0, L, L // 2, (L * 1) // 4, (L * 3) // 4}
            if focus_idx is not None:
                for d in (-3, -2, -1, 0, 1, 2, 3):
                    p = focus_idx + d
                    if 0 <= p <= L:
                        pos_set.add(p)
            cap = k_positions if k_positions is not None else k_pos_sample
            for _ in range(min(cap, L + 1)):
                pos_set.add(rng.randint(0, L))
            pos_list = sorted(pos_set)
        res = evaluate_best_two_positions(base_seq, t, pos_list)
        best_two_cache[key] = res
        return res

    def evaluate_top_positions(base_seq, t, pos_list, k_top=2):
        """
        Return top-k positions by resulting cost for inserting t into base_seq over pos_list.
        Uses seq_cost memoization; k_top kept small (2) for endgame branching efficiency.
        """
        top = []
        for p in pos_list:
            cand = base_seq[:p] + [t] + base_seq[p:]
            c = seq_cost(cand)
            if len(top) < k_top:
                top.append((c, p))
                top.sort(key=lambda x: x[0])
            else:
                if c < top[-1][0]:
                    top[-1] = (c, p)
                    top.sort(key=lambda x: x[0])
        return top

    def endgame_bnb(start_seq, rem_iter):
        """
        Bounded branch-and-bound enumeration for the last few transactions.
        Explores regret-ordered candidates with best and (optionally) second-best positions.
        Prunes by current sequence cost and a small time budget to keep runtime predictable.
        """
        # Limits tuned for quality/runtime balance
        time_budget = max(0.03, min(0.10, 0.005 * n + 0.005 * num_seqs))
        start_time = time.time()
        best_cost_bnb = float('inf')
        best_seq_bnb = None
        rem_list0 = list(rem_iter)

        # Initialize upper bound via greedy completion on best positions
        greedy_seq = start_seq[:]
        rem_tmp = rem_list0[:]
        half_budget = time_budget * 0.5
        while rem_tmp and (time.time() - start_time < half_budget):
            best_choice = None
            for t in rem_tmp:
                use_all = (len(greedy_seq) <= 20)
                bc, bp, _ = best_two_insertion(greedy_seq, t, use_all_pos=use_all)
                if best_choice is None or bc < best_choice[0]:
                    best_choice = (bc, t, bp)
            if best_choice is None:
                break
            bc, t, bp = best_choice
            greedy_seq = greedy_seq[:bp] + [t] + greedy_seq[bp:]
            rem_tmp.remove(t)
        best_cost_bnb = seq_cost(greedy_seq)
        best_seq_bnb = greedy_seq

        def dfs(cur_seq, rem_list):
            nonlocal best_cost_bnb, best_seq_bnb
            # Time check
            if time.time() - start_time > time_budget:
                return
            cur_cost = seq_cost(cur_seq)
            if cur_cost >= best_cost_bnb:
                return
            if not rem_list:
                if cur_cost < best_cost_bnb:
                    best_cost_bnb = cur_cost
                    best_seq_bnb = cur_seq
                return

            # Build candidates ordered by regret, then by best insertion cost
            candidates = []
            L = len(cur_seq)
            use_all = (L <= 20)
            pos_list = list(range(L + 1)) if use_all else position_samples(L, k_positions=k_pos_sample + 4)
            for t in rem_list:
                top = evaluate_top_positions(cur_seq, t, pos_list, k_top=2)
                best_c, best_p = top[0]
                second_c = top[1][0] if len(top) > 1 else float('inf')
                regret = (second_c - best_c) if second_c < float('inf') else 0.0
                candidates.append((regret, best_c, t, best_p, top))
            candidates.sort(key=lambda x: (-x[0], x[1]))

            # Limit branching: explore top transactions and, for top few, their second-best position
            branch_txn = min(5, len(candidates))
            for idx in range(branch_txn):
                reg, bc, t, bp, top = candidates[idx]
                new_rem = [x for x in rem_list if x != t]
                # Explore best position
                new_seq = cur_seq[:bp] + [t] + cur_seq[bp:]
                dfs(new_seq, new_rem)
                # Optionally explore second-best position for top-2 candidates
                if len(top) >= 2 and idx < 2:
                    sp = top[1][1]
                    if sp != bp:
                        new_seq2 = cur_seq[:sp] + [t] + cur_seq[sp:]
                        dfs(new_seq2, new_rem)
                if time.time() - start_time > time_budget:
                    break

        dfs(start_seq[:], rem_list0)
        return best_seq_bnb
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
    def regret_insertion_build(seed_t=None):
        """Construct a schedule using regret-based insertion with a small beam and diversity."""
        if seed_t is None:
            seed_t = random.randint(0, n - 1)
        # Beam holds tuples: (seq, rem_set, cost)
        seq0 = [seed_t]
        rem0 = set(all_txns)
        rem0.remove(seed_t)
        beam = [(seq0, rem0, seq_cost(seq0))]

        # Optionally expand a second element to shape early order
        if rem0:
            expansions = []
            rem_list = list(rem0)
            cand_txns = rem_list if len(rem_list) <= k_txn_sample else random.sample(rem_list, k_txn_sample)
            for seq, rem, base_cost in beam:
                for t in cand_txns:
                    # Try prepend and append
                    s1 = [t] + seq
                    c1 = seq_cost(s1)
                    r1 = rem.copy()
                    if t in r1:
                        r1.remove(t)
                    expansions.append((s1, r1, c1, 0.0))
                    s2 = seq + [t]
                    c2 = seq_cost(s2)
                    r2 = rem.copy()
                    if t in r2:
                        r2.remove(t)
                    expansions.append((s2, r2, c2, 0.0))
            # Select top unique by suffix diversity
            expansions.sort(key=lambda x: x[2])
            next_beam = []
            seen_sig = set()
            for s, r, c, _ in expansions:
                sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                if sig in seen_sig:
                    continue
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                if len(next_beam) >= build_beam_width:
                    break
            if next_beam:
                beam = next_beam

        # Grow sequences until all are complete
        while True:
            if all(len(rem) == 0 for _, rem, _ in beam):
                break

            expansions = []
            seen_seqs = set()  # avoid duplicates by full sequence
            for seq, rem, base_cost in beam:
                if not rem:
                    key = tuple(seq)
                    if key not in seen_seqs:
                        seen_seqs.add(key)
                        expansions.append((seq, rem, base_cost, 0.0))
                    continue

                # Candidate transactions
                if len(rem) <= rem_all_threshold:
                    cand_txns = list(rem)
                else:
                    cand_txns = random.sample(list(rem), min(k_txn_sample, len(rem)))

                # For each candidate txn, compute best and second-best insertion pos
                for t in cand_txns:
                    use_all = (len(seq) <= 20) or (len(rem) <= rem_all_threshold) or (len(rem) <= build_beam_width * 2)
                    best_c, best_p, second_c = best_two_insertion(seq, t, use_all_pos=use_all)
                    new_seq = seq[:best_p] + [t] + seq[best_p:]
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    regret = (second_c - best_c) if second_c < float('inf') else 0.0
                    key = tuple(new_seq)
                    if key in seen_seqs:
                        continue
                    seen_seqs.add(key)
                    expansions.append((new_seq, new_rem, best_c, regret))

            if not expansions:
                break

            # Rank expansions for selection
            # Primary set: best by cost with diversity
            expansions_by_cost = sorted(expansions, key=lambda x: x[2])
            next_beam = []
            seen_sig = set()
            # First fill majority by cost
            cost_slots = max(1, build_beam_width - beam_regret_quota)
            for s, r, c, reg in expansions_by_cost:
                sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                if sig in seen_sig:
                    continue
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                if len(next_beam) >= cost_slots:
                    break

            # Then add some high-regret candidates for exploration
            if len(next_beam) < build_beam_width:
                expansions_by_regret = sorted(expansions, key=lambda x: (-x[3], x[2]))
                for s, r, c, reg in expansions_by_regret:
                    if len(next_beam) >= build_beam_width:
                        break
                    sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                    if sig in seen_sig:
                        continue
                    seen_sig.add(sig)
                    next_beam.append((s, r, c))

            # Fallback if something went wrong
            if not next_beam:
                next_beam = [(s, r, c) for s, r, c, _ in expansions_by_cost[:build_beam_width]]

            beam = next_beam

        # Select best complete sequence
        best_seq = None
        best_cost = float('inf')
        for seq, rem, cost in beam:
            if rem:
                # Append remaining deterministically and evaluate
                seq_complete = seq + sorted(list(rem))
                c = seq_cost(seq_complete)
                if c < best_cost:
                    best_cost = c
                    best_seq = seq_complete
            else:
                if cost < best_cost:
                    best_cost = cost
                    best_seq = seq
        return best_seq
=======
    def regret_insertion_build(seed_t=None):
        """Construct a schedule using regret-based insertion with a small beam and diversity."""
        if seed_t is None:
            seed_t = random.randint(0, n - 1)
        # Beam holds tuples: (seq, rem_set, cost)
        seq0 = [seed_t]
        rem0 = set(all_txns)
        rem0.remove(seed_t)
        beam = [(seq0, rem0, seq_cost(seq0))]

        # Optionally expand a second element to shape early order
        if rem0:
            expansions = []
            rem_list = list(rem0)
            cand_txns = rem_list if len(rem_list) <= k_txn_sample else random.sample(rem_list, k_txn_sample)
            for seq, rem, base_cost in beam:
                for t in cand_txns:
                    # Try prepend and append
                    s1 = [t] + seq
                    c1 = seq_cost(s1)
                    r1 = rem.copy()
                    if t in r1:
                        r1.remove(t)
                    expansions.append((s1, r1, c1, 0.0))
                    s2 = seq + [t]
                    c2 = seq_cost(s2)
                    r2 = rem.copy()
                    if t in r2:
                        r2.remove(t)
                    expansions.append((s2, r2, c2, 0.0))
            # Select top unique by suffix diversity
            expansions.sort(key=lambda x: x[2])
            next_beam = []
            seen_sig = set()
            for s, r, c, _ in expansions:
                sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                if sig in seen_sig:
                    continue
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                if len(next_beam) >= build_beam_width:
                    break
            if next_beam:
                beam = next_beam

        # Grow sequences until all are complete
        bnb_last_k = 8  # switch to bounded enumeration when |remaining| <= K
        while True:
            if all(len(rem) == 0 for _, rem, _ in beam):
                break

            # Endgame bounded enumeration: finalize best completion for small remaining sets
            small_states = [(seq, rem, cost) for seq, rem, cost in beam if len(rem) <= bnb_last_k]
            if small_states:
                candidates = []
                # Evaluate up to two promising states (by current cost) to bound runtime
                for seq, rem, cost in sorted(small_states, key=lambda x: x[2])[:2]:
                    best_comp = endgame_bnb(seq, list(rem))
                    candidates.append((seq_cost(best_comp), best_comp))
                if candidates:
                    candidates.sort(key=lambda x: x[0])
                    return candidates[0][1]

            expansions = []
            seen_seqs = set()  # avoid duplicates by full sequence
            for seq, rem, base_cost in beam:
                if not rem:
                    key = tuple(seq)
                    if key not in seen_seqs:
                        seen_seqs.add(key)
                        expansions.append((seq, rem, base_cost, 0.0))
                    continue

                # Candidate transactions
                if len(rem) <= rem_all_threshold:
                    cand_txns = list(rem)
                else:
                    cand_txns = random.sample(list(rem), min(k_txn_sample, len(rem)))

                # For each candidate txn, compute best and second-best insertion pos
                for t in cand_txns:
                    use_all = (len(seq) <= 20) or (len(rem) <= rem_all_threshold) or (len(rem) <= build_beam_width * 2)
                    best_c, best_p, second_c = best_two_insertion(seq, t, use_all_pos=use_all)
                    new_seq = seq[:best_p] + [t] + seq[best_p:]
                    new_rem = rem.copy()
                    new_rem.remove(t)
                    regret = (second_c - best_c) if second_c < float('inf') else 0.0
                    key = tuple(new_seq)
                    if key in seen_seqs:
                        continue
                    seen_seqs.add(key)
                    expansions.append((new_seq, new_rem, best_c, regret))

            if not expansions:
                break

            # Rank expansions for selection
            # Primary set: best by cost with diversity
            expansions_by_cost = sorted(expansions, key=lambda x: x[2])
            next_beam = []
            seen_sig = set()
            # First fill majority by cost
            cost_slots = max(1, build_beam_width - beam_regret_quota)
            for s, r, c, reg in expansions_by_cost:
                sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                if sig in seen_sig:
                    continue
                seen_sig.add(sig)
                next_beam.append((s, r, c))
                if len(next_beam) >= cost_slots:
                    break

            # Then add some high-regret candidates for exploration
            if len(next_beam) < build_beam_width:
                expansions_by_regret = sorted(expansions, key=lambda x: (-x[3], x[2]))
                for s, r, c, reg in expansions_by_regret:
                    if len(next_beam) >= build_beam_width:
                        break
                    sig = tuple(s[-beam_div_suffix:]) if len(s) >= beam_div_suffix else tuple(s)
                    if sig in seen_sig:
                        continue
                    seen_sig.add(sig)
                    next_beam.append((s, r, c))

            # Fallback if something went wrong
            if not next_beam:
                next_beam = [(s, r, c) for s, r, c, _ in expansions_by_cost[:build_beam_width]]

            beam = next_beam

        # Select best complete sequence
        best_seq = None
        best_cost = float('inf')
        for seq, rem, cost in beam:
            if rem:
                # Append remaining deterministically and evaluate
                seq_complete = seq + sorted(list(rem))
                c = seq_cost(seq_complete)
                if c < best_cost:
                    best_cost = c
                    best_seq = seq_complete
            else:
                if cost < best_cost:
                    best_cost = cost
                    best_seq = seq
        return best_seq
>>>>>>> REPLACE
</DIFF>