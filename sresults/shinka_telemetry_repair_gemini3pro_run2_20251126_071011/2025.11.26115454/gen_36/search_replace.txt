<NAME>
increase_iterations
</NAME>

<DESCRIPTION>
Increase the number of solver iterations from 4 to 10 to allow flow constraints to propagate further across the network topology, ensuring better global convergence before calculating confidence.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Step 2: Iterative Flow & Symmetry Optimization
    # We treat the network as a system of constraints.
    # We use a greedy iterative approach to propagate constraints.
    ITERATIONS = 4
=======
    # Step 2: Iterative Flow & Symmetry Optimization
    # We treat the network as a system of constraints.
    # We use a greedy iterative approach to propagate constraints.
    ITERATIONS = 10
>>>>>>> REPLACE
</DIFF>

<NAME>
lower_traffic_threshold
</NAME>

<DESCRIPTION>
Lower the traffic activity threshold from 1.0 Mbps to 0.1 Mbps. This makes the status repair logic more sensitive to low-bandwidth active links (e.g., IoT or control traffic) that might otherwise be incorrectly classified as DOWN.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
            traffic_active = (state['rx'] > 1.0 or state['tx'] > 1.0 or
                              peer_state['original'].get('rx_rate', 0.0) > 1.0 or
                              peer_state['original'].get('tx_rate', 0.0) > 1.0)
=======
            traffic_active = (state['rx'] > 0.1 or state['tx'] > 0.1 or
                              peer_state['original'].get('rx_rate', 0.0) > 0.1 or
                              peer_state['original'].get('tx_rate', 0.0) > 0.1)
>>>>>>> REPLACE
</DIFF>

<NAME>
logic_tree_confidence
</NAME>

<DESCRIPTION>
Replace the heuristic weighted-sum confidence calculation with a discrete Logic Tree model combined with a continuous flow penalty. This explicitly buckets confidence into levels:
1. "Golden" (Original + Peer + Flow agree) -> 1.0
2. "Trust Peer" (Repaired to Peer) -> 0.95
3. "Inferred" (Repaired to Flow, No Peer agreement) -> 0.8
4. "Ambiguous" (Repaired but Flow still bad) -> 0.3
It also applies a penalty strictly proportional to the residual flow imbalance, ensuring that confidence decreases if the router remains locally inconsistent.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Final Pass: Detailed Confidence Calibration
    for if_id, state in working_state.items():
        if state['status'] == 'down': continue

        # Calculate consistency scores
        r_local = state['original'].get('local_router')

        # 1. Flow Consistency (0.0 to 1.0)
        flow_score = 0.5 # Neutral default
        if r_local and r_local in topology:
            imbalance = abs(get_router_imbalance(r_local))
            throughput = get_total_throughput(r_local)
            # Strict penalty for imbalance relative to throughput
            rel_err = imbalance / throughput
            flow_score = max(0.0, 1.0 - (rel_err * 10.0))

        # 2. Measurement Consistency (0.0 to 1.0)
        meas_rx = float(state['original'].get('rx_rate', 0.0))
        meas_tx = float(state['original'].get('tx_rate', 0.0))

        # RX Confidence
        delta_rx = abs(state['rx'] - meas_rx)
        dist_rx = delta_rx / max(state['rx'], 1.0)
        meas_score_rx = max(0.0, 1.0 - (dist_rx * 5.0)) # Drop if > 20% change

        # TX Confidence
        delta_tx = abs(state['tx'] - meas_tx)
        dist_tx = delta_tx / max(state['tx'], 1.0)
        meas_score_tx = max(0.0, 1.0 - (dist_tx * 5.0))

        # Combine scores
        if r_local in topology:
            # If flow info is available, it dominates.
            # High flow score = Valid Network State found.
            state['rx_conf'] = 0.4 + 0.6 * flow_score
            state['tx_conf'] = 0.4 + 0.6 * flow_score
        else:
            # Fallback to measurement consistency
            state['rx_conf'] = 0.5 + 0.4 * meas_score_rx
            state['tx_conf'] = 0.5 + 0.4 * meas_score_tx

        # 3. Boost for Symmetry Confirmation
        peer_id = state['original'].get('connected_to')
        if peer_id and peer_id in working_state:
            peer_state = working_state[peer_id]

            # RX Check (My RX vs Peer TX)
            p_tx = float(peer_state['original'].get('tx_rate', 0.0))
            if abs(meas_rx - p_tx) / max(meas_rx, p_tx, 1.0) < HARDENING_THRESHOLD:
                state['rx_conf'] = max(state['rx_conf'], 0.95)

            # TX Check (My TX vs Peer RX)
            p_rx = float(peer_state['original'].get('rx_rate', 0.0))
            if abs(meas_tx - p_rx) / max(meas_tx, p_rx, 1.0) < HARDENING_THRESHOLD:
                state['tx_conf'] = max(state['tx_conf'], 0.95)
=======
    # Final Pass: Detailed Confidence Calibration
    for if_id, state in working_state.items():
        if state['status'] == 'down': continue

        r_local = state['original'].get('local_router')

        # 1. Evaluate Flow Quality (Global Context)
        flow_balanced = True
        flow_penalty = 0.0
        if r_local and r_local in topology:
            imb = abs(get_router_imbalance(r_local))
            total = get_total_throughput(r_local)
            if total > 0.1:
                ratio = imb / total
                if ratio > HARDENING_THRESHOLD:
                    flow_balanced = False
                # Continuous penalty: if ratio is 10%, penalty is 0.2.
                flow_penalty = min(0.5, ratio * 2.0)

        # Helper: Logic Tree for Confidence
        def get_conf(repaired_val, self_meas, peer_meas, peer_avail):
            # 1. Check agreement with Self (Original)
            # Use a slightly looser threshold for "Agreement" to allow minor solver tweaks
            kept_original = abs(repaired_val - self_meas) < max(self_meas, 1.0) * (HARDENING_THRESHOLD * 1.5)

            # 2. Check agreement with Peer
            matched_peer = False
            if peer_avail:
                matched_peer = abs(repaired_val - peer_meas) < max(peer_meas, 1.0) * (HARDENING_THRESHOLD * 1.5)

            base_score = 0.5

            if kept_original and matched_peer:
                # Golden State: Measurements agreed and we kept them.
                base_score = 1.0
            elif matched_peer:
                # We repaired to match Peer. High confidence (Trust Peer).
                base_score = 0.95
            elif kept_original:
                # We ignored Peer (or no peer).
                if flow_balanced:
                    # Flow supports our measurement. Peer likely wrong.
                    base_score = 0.95
                else:
                    # Flow is bad AND Peer disagrees. We are stubborn.
                    base_score = 0.6
            else:
                # We changed value to something else (e.g. average or flow-inference)
                if flow_balanced:
                    # We found a value that balances flow. Inferred High Confidence.
                    # But slightly less than direct measurement confirmation.
                    base_score = 0.8
                else:
                    # Changed value, Flow still bad. Total uncertainty.
                    base_score = 0.3

            # Apply Penalty based on Router Health
            return max(0.0, base_score - flow_penalty)

        peer_id = state['original'].get('connected_to')
        peer_state = working_state.get(peer_id) if peer_id else None
        peer_avail = peer_state is not None

        # Calculate RX Confidence
        meas_rx = float(state['original'].get('rx_rate', 0.0))
        peer_tx = float(peer_state['original'].get('tx_rate', 0.0)) if peer_avail else 0.0
        state['rx_conf'] = get_conf(state['rx'], meas_rx, peer_tx, peer_avail)

        # Calculate TX Confidence
        meas_tx = float(state['original'].get('tx_rate', 0.0))
        peer_rx = float(peer_state['original'].get('rx_rate', 0.0)) if peer_avail else 0.0
        state['tx_conf'] = get_conf(state['tx'], meas_tx, peer_rx, peer_avail)
>>>>>>> REPLACE
</DIFF>