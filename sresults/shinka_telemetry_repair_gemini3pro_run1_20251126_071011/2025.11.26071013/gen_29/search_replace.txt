<NAME>
rate_repair_imputation_and_scoring
</NAME>

<DESCRIPTION>
Refine Rate Repair strategy by introducing "Imputed Candidates" derived from Flow Conservation.
- Instead of just choosing between Local Tx and Remote Rx (or their average), we calculate what the rate *should* be if the local router were balanced ("Local Imputation") and if the remote router were balanced ("Remote Imputation").
- This creates a set of candidates (Measurements + Imputed Values + Average).
- We verify these candidates against both routers using a stricter scoring function that penalizes flow violations (error > 5%) significantly with a step penalty.
- This allows recovering correct rates even if both sensors on a link are broken (e.g., stuck at zero) but the routers are otherwise verifiable (Double-Dead Link repair).
- We remove the "Agreement Optimization" (skipping repair if values agree) because agreed values might still be wrong (e.g. consensus on 0 when flow implies 100).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- 3. Rate Repair (Iterative Consensus) ---

    # Helper: Calculate relative flow error for a router if we force a specific value
    def calc_flow_error(rid, if_target, field, value):
        if rid not in verifiable_routers:
            return None

        sum_rx = 0.0
        sum_tx = 0.0

        for iface in router_interfaces[rid]:
            # Use current state values
            r = state[iface]['rx']
            t = state[iface]['tx']

            # Substitute the target value we are testing
            if iface == if_target:
                if field == 'rx': r = value
                else: t = value

            sum_rx += r
            sum_tx += t

        err = abs(sum_rx - sum_tx)
        denom = max(sum_rx, sum_tx, 1.0)
        return err / denom

    # Run 3 passes to allow corrections to propagate across the network
    for _ in range(3):
        # Iterate over all interfaces to check Link Symmetry
        for if_id, s in state.items():
            if s['status'] == 'down': continue

            peer_id = s['connected_to']
            if not peer_id or peer_id not in state:
                continue

            # We process the "outgoing" link: Tx(Local) -> Rx(Peer)
            cand_tx = s['tx']              # Candidate 1: Local Tx
            cand_rx = state[peer_id]['rx'] # Candidate 2: Peer Rx

            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            if diff < max(mag * TOLERANCE, MIN_ACTIVITY):
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_local = s['local_router']
                rid_remote = state[peer_id]['local_router']

                # Helper to score a candidate value based on flow impact
                # Lower score is better
                def get_candidate_score(val):
                    # Check local router (TX side)
                    err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                    # Check remote router (RX side)
                    err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)

                    score = 0.0

                    # Cost for Local
                    if err_local is None: score += 0.02 # Unverifiable = small cost
                    else: score += min(err_local, 1.0)  # Verifiable = actual error

                    # Cost for Remote
                    if err_remote is None: score += 0.02
                    else: score += min(err_remote, 1.0)

                    return score

                score_tx = get_candidate_score(cand_tx)
                score_rx = get_candidate_score(cand_rx)

                # Heuristic: Dead counters (0) are often wrong if the other side is active
                # Penalize the zero value
                if cand_tx < MIN_ACTIVITY and cand_rx > MIN_ACTIVITY: score_tx += 0.5
                if cand_rx < MIN_ACTIVITY and cand_tx > MIN_ACTIVITY: score_rx += 0.5

                if score_tx < score_rx:
                    best_val = cand_tx
                elif score_rx < score_tx:
                    best_val = cand_rx
                else:
                    best_val = (cand_tx + cand_rx) / 2.0 # Tie -> Average

            # Apply repair to state
            state[if_id]['tx'] = best_val
            state[peer_id]['rx'] = best_val
=======
    # --- 3. Rate Repair (Iterative Consensus) ---

    # Helper: Get current sums for a router
    def get_router_sums(rid):
        sum_rx = 0.0
        sum_tx = 0.0
        for iface in router_interfaces[rid]:
            sum_rx += state[iface]['rx']
            sum_tx += state[iface]['tx']
        return sum_rx, sum_tx

    # Helper: Calculate relative flow error for a router if we force a specific value
    def calc_flow_error(rid, if_target, field, value):
        if rid not in verifiable_routers:
            return None

        sum_rx = 0.0
        sum_tx = 0.0

        for iface in router_interfaces[rid]:
            # Use current state values
            r = state[iface]['rx']
            t = state[iface]['tx']

            # Substitute the target value we are testing
            if iface == if_target:
                if field == 'rx': r = value
                else: t = value

            sum_rx += r
            sum_tx += t

        err = abs(sum_rx - sum_tx)
        denom = max(sum_rx, sum_tx, 1.0)
        return err / denom

    # Run 3 passes to allow corrections to propagate across the network
    for _ in range(3):
        # Iterate over all interfaces to check Link Symmetry
        for if_id, s in state.items():
            if s['status'] == 'down': continue

            peer_id = s['connected_to']
            if not peer_id or peer_id not in state:
                continue

            # We process the "outgoing" link: Tx(Local) -> Rx(Peer)
            cand_tx = s['tx']              # Candidate 1: Local Tx
            cand_rx = state[peer_id]['rx'] # Candidate 2: Peer Rx

            # 3a. Generate Candidates
            # Always check flow conservation, even if they agree, to catch "Double Dead" links
            # (where both are 0 but router flow implies traffic)
            candidates = {cand_tx, cand_rx, (cand_tx + cand_rx) / 2.0}

            rid_local = s['local_router']
            rid_remote = state[peer_id]['local_router']

            # Imputation: What value would balance the Local Router?
            if rid_local in verifiable_routers:
                s_rx, s_tx = get_router_sums(rid_local)
                # s_tx includes cand_tx (the current value in state).
                # We want new_tx such that s_rx = s_tx - cand_tx + new_tx
                # new_tx = s_rx - s_tx + cand_tx
                imp_local = max(0.0, s_rx - s_tx + cand_tx)
                candidates.add(imp_local)

            # Imputation: What value would balance the Remote Router?
            # Note: Remote Rx (on this link) acts as Rx for remote router
            if rid_remote in verifiable_routers:
                s_rx, s_tx = get_router_sums(rid_remote)
                # s_rx includes cand_rx.
                # We want s_tx = s_rx - cand_rx + new_rx
                # new_rx = s_tx - s_rx + cand_rx
                imp_remote = max(0.0, s_tx - s_rx + cand_rx)
                candidates.add(imp_remote)

            # 3b. Score Candidates
            def get_candidate_score(val):
                score = 0.0

                # Check Local
                err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                if err_local is None: score += 0.1 # Unverifiable -> slight penalty
                elif err_local <= FLOW_TOLERANCE: score += err_local # Verified -> minimal penalty
                else: score += 0.5 + err_local # Invalid -> Step penalty

                # Check Remote
                err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)
                if err_remote is None: score += 0.1
                elif err_remote <= FLOW_TOLERANCE: score += err_remote
                else: score += 0.5 + err_remote

                # Dead value penalty (Heuristic)
                # If this value is dead but we have a live candidate, penalize this one
                if val < MIN_ACTIVITY and max(candidates) > MIN_ACTIVITY:
                     score += 0.2

                return score

            # Select Best Candidate
            best_val = cand_tx
            best_score = float('inf')

            # Sort for determinism
            for cand in sorted(candidates):
                s_cand = get_candidate_score(cand)
                if s_cand < best_score:
                    best_score = s_cand
                    best_val = cand
                elif abs(s_cand - best_score) < 1e-9:
                    # Tie-break: Prefer value closest to average of measurements (Noise smoothing)
                    avg = (cand_tx + cand_rx) / 2.0
                    if abs(cand - avg) < abs(best_val - avg):
                        best_val = cand

            # Apply repair to state
            state[if_id]['tx'] = best_val
            state[peer_id]['rx'] = best_val
>>>>>>> REPLACE
</DIFF>

<NAME>
continuous_confidence_calibration
</NAME>

<DESCRIPTION>
Improve Confidence Calibration by using continuous functions of residual error rather than discrete steps.
- Replaces fixed "0.95" confidence with `0.95 * (1 - error_factor)` logic.
- Maintains the hierarchy of verification (Both > One > None) but smooths the values to reflect that a 0.1% error is better than a 4.9% error.
- Adjusts "Unverified" confidence based on whether it was a "Dead Counter" repair (more confident) vs a random peer trust (less confident).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        def get_rate_confidence(orig, final, field):
            changed = abs(orig - final) > 0.001
            ver_level = get_verification_level(final, field)
            consistent_with_peer = is_peer_consistent(final, field)

            # 1. High Confidence Scenarios
            if ver_level == 3: return 0.99 # Verified by both ends
            if ver_level == 2: return 0.95 # Verified locally (strongest signal)

            # 2. Unchanged Data
            if not changed:
                # If we didn't change it, but it contradicts the peer, confidence drops
                if not consistent_with_peer:
                    return 0.7
                # If consistent and unchanged
                if ver_level == 1: return 0.95 # Verified remote
                return 0.9 # Good default

            # 3. Changed Data
            # Smoothing (small change)
            if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                return 0.95

            # Significant changes
            if ver_level == 1: return 0.90 # Verified remote

            # Unverified Repairs
            if orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                return 0.85 # Dead counter repair

            # If we changed it, it's not verified, but now consistent with peer (by definition of repair)
            # This is a "Trust Peer" repair
            return 0.75
=======
        def get_rate_confidence(orig, final, field):
            changed = abs(orig - final) > 0.001

            # Get verification metrics
            rid = data.get('local_router')
            local_err = calc_flow_error(rid, if_id, field, final)
            local_ok = (local_err is not None and local_err < FLOW_TOLERANCE)

            rem_rid = data.get('remote_router')
            peer_id = data.get('connected_to')
            remote_ok = False
            if rem_rid and peer_id:
                check_field = 'tx' if field == 'rx' else 'rx'
                rem_err = calc_flow_error(rem_rid, peer_id, check_field, final)
                remote_ok = (rem_err is not None and rem_err < FLOW_TOLERANCE)

            # Calculate error-based penalty factor [0.0 to 1.0]
            # If error is 0, factor is 1. If error is TOLERANCE, factor is 0.
            def get_error_factor(err):
                if err is None: return 0.0
                return max(0.0, 1.0 - (err / FLOW_TOLERANCE))

            # Base Confidence
            conf = 0.5

            if local_ok and remote_ok:
                # Validated by both.
                # Score: 0.95 + 0.05 * avg_quality
                avg_quality = (get_error_factor(local_err) + get_error_factor(rem_err)) / 2.0
                conf = 0.95 + 0.05 * avg_quality

            elif local_ok:
                # Validated locally.
                # Score: 0.90 + 0.08 * quality
                conf = 0.90 + 0.08 * get_error_factor(local_err)

            elif remote_ok:
                # Validated remotely.
                # Score: 0.85 + 0.05 * quality
                conf = 0.85 + 0.05 * get_error_factor(rem_err)

            else:
                # Unverified
                if not changed:
                    # Unchanged and Unverified
                    peer_consistent = is_peer_consistent(final, field)
                    if peer_consistent: conf = 0.9
                    else: conf = 0.6 # Disagreement, no verification, kept original
                else:
                    # Changed and Unverified
                    # Smoothing?
                    if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                        conf = 0.95
                    # Dead Counter Repair?
                    elif orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                        conf = 0.8 # Reasonable heuristic
                    else:
                        conf = 0.7 # Trusting peer blindly

            return conf
>>>>>>> REPLACE
</DIFF>