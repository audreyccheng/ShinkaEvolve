<NAME>
improved_consensus_and_calibration
</NAME>

<DESCRIPTION>
1. Replaces the discrete voting mechanism in rate repair with a continuous cost-based scoring system (`min(error, 1.0)`) to better differentiate between small and large flow violations. This improves counter repair accuracy.
2. Increases repair passes from 2 to 3 to allow deeper propagation of corrections.
3. Completely revamps confidence calibration to penalize "Unchanged" values that are inconsistent with peers (fixing overconfidence), and provides granular confidence levels based on local/remote verification status (improving calibration).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Run 2 passes to allow corrections to propagate across the network
    for _ in range(2):
        # Iterate over all interfaces to check Link Symmetry
        for if_id, s in state.items():
            peer_id = s['connected_to']
            if not peer_id or peer_id not in state:
                continue

            # We process the "outgoing" link: Tx(Local) -> Rx(Peer)
            # (The incoming link will be processed when we iterate the peer)

            cand_tx = s['tx']              # Candidate 1: Local Tx
            cand_rx = state[peer_id]['rx'] # Candidate 2: Peer Rx

            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            best_val = cand_tx # Default to local

            if diff / mag < TOLERANCE:
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_a = s['local_router']
                rid_b = state[peer_id]['local_router']

                # Test Candidate 1 (cand_tx)
                # Does it fit Router A's flow (as Tx)? Does it fit Router B's flow (as Rx)?
                err_a_1 = calc_flow_error(rid_a, if_id, 'tx', cand_tx)
                err_b_1 = calc_flow_error(rid_b, peer_id, 'rx', cand_tx)

                # Test Candidate 2 (cand_rx)
                err_a_2 = calc_flow_error(rid_a, if_id, 'tx', cand_rx)
                err_b_2 = calc_flow_error(rid_b, peer_id, 'rx', cand_rx)

                # Vote counting
                votes_1 = 0
                votes_2 = 0

                # A candidate gets a vote if it results in low flow error (<5%)
                if err_a_1 is not None and err_a_1 < FLOW_TOLERANCE: votes_1 += 1
                if err_b_1 is not None and err_b_1 < FLOW_TOLERANCE: votes_1 += 1

                if err_a_2 is not None and err_a_2 < FLOW_TOLERANCE: votes_2 += 1
                if err_b_2 is not None and err_b_2 < FLOW_TOLERANCE: votes_2 += 1

                # Decision
                if votes_1 > votes_2:
                    best_val = cand_tx
                elif votes_2 > votes_1:
                    best_val = cand_rx
                else:
                    # Tie or No Info (e.g. edge routers). Use Heuristics.
                    # Heuristic: Dead counters often report 0. Trust non-zero.
                    if cand_tx > MIN_ACTIVITY and cand_rx <= MIN_ACTIVITY:
                        best_val = cand_tx
                    elif cand_rx > MIN_ACTIVITY and cand_tx <= MIN_ACTIVITY:
                        best_val = cand_rx
                    else:
                        # Compare raw error magnitudes if flow info exists but was ambiguous
                        sum_err_1 = (err_a_1 or 100) + (err_b_1 or 100)
                        sum_err_2 = (err_a_2 or 100) + (err_b_2 or 100)

                        if sum_err_1 < sum_err_2 and sum_err_1 < 200:
                            best_val = cand_tx
                        elif sum_err_2 < sum_err_1 and sum_err_2 < 200:
                            best_val = cand_rx
                        else:
                            # Total ambiguity -> Average
                            best_val = (cand_tx + cand_rx) / 2.0

            # Apply repair to state
            state[if_id]['tx'] = best_val
            state[peer_id]['rx'] = best_val
=======
    # Run 3 passes to allow corrections to propagate across the network
    for _ in range(3):
        # Iterate over all interfaces to check Link Symmetry
        for if_id, s in state.items():
            if s['status'] == 'down': continue

            peer_id = s['connected_to']
            if not peer_id or peer_id not in state:
                continue

            # We process the "outgoing" link: Tx(Local) -> Rx(Peer)
            cand_tx = s['tx']              # Candidate 1: Local Tx
            cand_rx = state[peer_id]['rx'] # Candidate 2: Peer Rx

            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            if diff < max(mag * TOLERANCE, MIN_ACTIVITY):
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_local = s['local_router']
                rid_remote = state[peer_id]['local_router']

                # Helper to score a candidate value based on flow impact
                # Lower score is better
                def get_candidate_score(val):
                    # Check local router (TX side)
                    err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                    # Check remote router (RX side)
                    err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)

                    score = 0.0

                    # Cost for Local
                    if err_local is None: score += 0.02 # Unverifiable = small cost
                    else: score += min(err_local, 1.0)  # Verifiable = actual error

                    # Cost for Remote
                    if err_remote is None: score += 0.02
                    else: score += min(err_remote, 1.0)

                    return score

                score_tx = get_candidate_score(cand_tx)
                score_rx = get_candidate_score(cand_rx)

                # Heuristic: Dead counters (0) are often wrong if the other side is active
                # Penalize the zero value
                if cand_tx < MIN_ACTIVITY and cand_rx > MIN_ACTIVITY: score_tx += 0.5
                if cand_rx < MIN_ACTIVITY and cand_tx > MIN_ACTIVITY: score_rx += 0.5

                if score_tx < score_rx:
                    best_val = cand_tx
                elif score_rx < score_tx:
                    best_val = cand_rx
                else:
                    best_val = (cand_tx + cand_rx) / 2.0 # Tie -> Average

            # Apply repair to state
            state[if_id]['tx'] = best_val
            state[peer_id]['rx'] = best_val
>>>>>>> REPLACE
<<<<<<< SEARCH
    # --- 4. Final Result Generation & Confidence Calibration ---
    result = {}

    for if_id, data in telemetry.items():
        # Get Final Values
        final_rx = state[if_id]['rx']
        final_tx = state[if_id]['tx']
        final_st = state[if_id]['status']

        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_st = data.get('interface_status', 'unknown')

        # -- Calibrate Confidence --

        # Helper to check remote verification
        def is_remotely_verified(val, field):
            rem_rid = data.get('remote_router')
            peer_id = data.get('connected_to')
            if not rem_rid or not peer_id:
                return False
            # If checking local RX, we check remote TX flow
            # If checking local TX, we check remote RX flow
            check_field = 'tx' if field == 'rx' else 'rx'

            err = calc_flow_error(rem_rid, peer_id, check_field, val)
            return err is not None and err < FLOW_TOLERANCE

        def get_rate_confidence(orig, final, field):
            # 1. Did we change the value?
            if abs(orig - final) < 0.001:
                return 1.0 # High confidence in original/unchanged data

            # 2. Is it just smoothing? (Small relative change < 5%)
            if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                return 0.95 # Smoothing is safe

            # 3. Noise Consensus (Both < Min Activity)
            if orig < MIN_ACTIVITY and final < MIN_ACTIVITY:
                return 0.95

            # 4. If changed, was it verified by LOCAL flow?
            rid = data.get('local_router')
            flow_err = calc_flow_error(rid, if_id, field, final)

            if flow_err is not None and flow_err < FLOW_TOLERANCE:
                return 0.95 # Very high confidence: Mathematics supports this

            # 5. Was it verified by REMOTE flow?
            if is_remotely_verified(final, field):
                return 0.90 # High confidence: Peer is verified

            # 6. Was it a "Dead Counter" repair (0 -> Non-Zero)?
            if orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                return 0.8 # Moderately high: 0 is a common error mode

            # 7. Fallback
            return 0.5 # Low confidence: Changed based on peer but no verification

        rx_conf = get_rate_confidence(orig_rx, final_rx, 'rx')
        tx_conf = get_rate_confidence(orig_tx, final_tx, 'tx')
        st_conf = status_conf_map.get(if_id, 1.0)

        # Sanity Check: If Down but Traffic, lower confidence
        if final_st == 'down' and (final_rx > 1.0 or final_tx > 1.0):
            rx_conf *= 0.5
            tx_conf *= 0.5
            st_conf *= 0.5

        # Construct Output Tuple
        res_entry = {
            'rx_rate': (orig_rx, final_rx, rx_conf),
            'tx_rate': (orig_tx, final_tx, tx_conf),
            'interface_status': (orig_st, final_st, st_conf),
            'connected_to': data.get('connected_to'),
            'local_router': data.get('local_router'),
            'remote_router': data.get('remote_router')
        }
        result[if_id] = res_entry
=======
    # --- 4. Final Result Generation & Confidence Calibration ---
    result = {}

    for if_id, data in telemetry.items():
        final_rx = state[if_id]['rx']
        final_tx = state[if_id]['tx']
        final_st = state[if_id]['status']

        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_st = data.get('interface_status', 'unknown')

        # -- Calibrate Confidence --

        # Helper: check for peer consistency
        def is_peer_consistent(val, field):
            peer_id = data.get('connected_to')
            if not peer_id or peer_id not in state:
                return True # Can't check, assume consistent

            # Compare with peer's finalized value (which should be symmetric)
            peer_val = state[peer_id]['tx'] if field == 'rx' else state[peer_id]['rx']

            # Use same tolerance as repair loop
            diff = abs(val - peer_val)
            mag = max(val, peer_val, 1.0)
            return diff < max(mag * TOLERANCE, MIN_ACTIVITY)

        # Helper: check verification
        def get_verification_level(val, field):
            # Local Verification
            rid = data.get('local_router')
            local_err = calc_flow_error(rid, if_id, field, val)
            local_ok = (local_err is not None and local_err < FLOW_TOLERANCE)

            # Remote Verification
            remote_ok = False
            peer_id = data.get('connected_to')
            rem_rid = data.get('remote_router')

            if rem_rid and peer_id:
                check_field = 'tx' if field == 'rx' else 'rx'
                rem_err = calc_flow_error(rem_rid, peer_id, check_field, val)
                if rem_err is not None and rem_err < FLOW_TOLERANCE:
                    remote_ok = True

            if local_ok and remote_ok: return 3 # Both
            if local_ok: return 2 # Local only
            if remote_ok: return 1 # Remote only
            return 0 # None

        def get_rate_confidence(orig, final, field):
            changed = abs(orig - final) > 0.001
            ver_level = get_verification_level(final, field)
            consistent_with_peer = is_peer_consistent(final, field)

            # 1. High Confidence Scenarios
            if ver_level == 3: return 0.99 # Verified by both ends
            if ver_level == 2: return 0.95 # Verified locally (strongest signal)

            # 2. Unchanged Data
            if not changed:
                # If we didn't change it, but it contradicts the peer, confidence drops
                if not consistent_with_peer:
                    return 0.7
                # If consistent and unchanged
                if ver_level == 1: return 0.95 # Verified remote
                return 0.9 # Good default

            # 3. Changed Data
            # Smoothing (small change)
            if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                return 0.95

            # Significant changes
            if ver_level == 1: return 0.90 # Verified remote

            # Unverified Repairs
            if orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                return 0.85 # Dead counter repair

            # If we changed it, it's not verified, but now consistent with peer (by definition of repair)
            # This is a "Trust Peer" repair
            return 0.75

        rx_conf = get_rate_confidence(orig_rx, final_rx, 'rx')
        tx_conf = get_rate_confidence(orig_tx, final_tx, 'tx')
        st_conf = status_conf_map.get(if_id, 1.0)

        # Sanity Check: If Down but Traffic, lower confidence
        if final_st == 'down' and (final_rx > 1.0 or final_tx > 1.0):
            rx_conf = 0.0
            tx_conf = 0.0
            st_conf = 0.0

        # Construct Output Tuple
        res_entry = {
            'rx_rate': (orig_rx, final_rx, rx_conf),
            'tx_rate': (orig_tx, final_tx, tx_conf),
            'interface_status': (orig_st, final_st, st_conf),
            'connected_to': data.get('connected_to'),
            'local_router': data.get('local_router'),
            'remote_router': data.get('remote_router')
        }
        result[if_id] = res_entry
>>>>>>> REPLACE
</DIFF>