<NAME>
residual_synthesis_and_snr
</NAME>

<DESCRIPTION>
1. Introduces `solve_residual` helper to synthesize traffic values from router flow imbalances, allowing the repair of "double-dead" links where both sides report zero but connected routers imply traffic.
2. Updates Rate Repair loop to evaluate these synthetic candidates alongside raw telemetry.
3. Refines `get_rate_confidence` to include a "Signal-to-Noise" bonus (magnitude bonus), increasing confidence for high-value verified repairs compared to low-value ones.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Helper: Calculate relative flow error for a router if we force a specific value
    def calc_flow_error(rid, if_target, field, value):
        if rid not in verifiable_routers:
            return None

        sum_rx = 0.0
        sum_tx = 0.0

        for iface in router_interfaces[rid]:
            # Use current state values
            r = state[iface]['rx']
            t = state[iface]['tx']

            # Substitute the target value we are testing
            if iface == if_target:
                if field == 'rx': r = value
                else: t = value

            sum_rx += r
            sum_tx += t

        err = abs(sum_rx - sum_tx)
        denom = max(sum_rx, sum_tx, 1.0)
        return err / denom
=======
    # Helper: Calculate relative flow error for a router if we force a specific value
    def calc_flow_error(rid, if_target, field, value):
        if rid not in verifiable_routers:
            return None

        sum_rx = 0.0
        sum_tx = 0.0

        for iface in router_interfaces[rid]:
            # Use current state values
            r = state[iface]['rx']
            t = state[iface]['tx']

            # Substitute the target value we are testing
            if iface == if_target:
                if field == 'rx': r = value
                else: t = value

            sum_rx += r
            sum_tx += t

        err = abs(sum_rx - sum_tx)
        denom = max(sum_rx, sum_tx, 1.0)
        return err / denom

    def solve_residual(rid, if_target, field):
        """Calculates value for if_target to perfectly balance the router."""
        if rid not in verifiable_routers:
            return None

        sum_in, sum_out = 0.0, 0.0
        for iface in router_interfaces[rid]:
            r = state[iface]['rx']
            t = state[iface]['tx']
            if iface == if_target:
                if field == 'rx': r = 0.0
                else: t = 0.0
            sum_in += r
            sum_out += t

        # Balance: Sum(In) = Sum(Out)
        if field == 'rx': val = sum_out - sum_in
        else: val = sum_in - sum_out

        return max(val, 0.0)
>>>>>>> REPLACE
<<<<<<< SEARCH
            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            if diff < max(mag * TOLERANCE, MIN_ACTIVITY):
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_local = s['local_router']
                rid_remote = state[peer_id]['local_router']

                # Helper to score a candidate value based on flow impact
                # Lower score is better
                def get_candidate_score(val):
                    # Check local router (TX side)
                    err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                    # Check remote router (RX side)
                    err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)

                    score = 0.0

                    # Cost for Local
                    if err_local is None: score += 0.02 # Unverifiable = small cost
                    else: score += min(err_local, 1.0)  # Verifiable = actual error

                    # Cost for Remote
                    if err_remote is None: score += 0.02
                    else: score += min(err_remote, 1.0)

                    return score

                score_tx = get_candidate_score(cand_tx)
                score_rx = get_candidate_score(cand_rx)

                # Heuristic: Dead counters (0) are often wrong if the other side is active
                # Penalize the zero value
                if cand_tx < MIN_ACTIVITY and cand_rx > MIN_ACTIVITY: score_tx += 0.5
                if cand_rx < MIN_ACTIVITY and cand_tx > MIN_ACTIVITY: score_rx += 0.5

                if score_tx < score_rx:
                    best_val = cand_tx
                elif score_rx < score_tx:
                    best_val = cand_rx
                else:
                    best_val = (cand_tx + cand_rx) / 2.0 # Tie -> Average
=======
            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            if diff < max(mag * TOLERANCE, MIN_ACTIVITY):
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_local = s['local_router']
                rid_remote = state[peer_id]['local_router']

                def get_candidate_score(val):
                    err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                    err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)

                    score = 0.0
                    # Cost for Local
                    if err_local is None: score += 0.02
                    else: score += min(err_local, 2.0)

                    # Cost for Remote
                    if err_remote is None: score += 0.02
                    else: score += min(err_remote, 2.0)
                    return score

                # Gather candidates
                candidates = [cand_tx, cand_rx]

                # Synthetic candidates from residual analysis
                synth_tx = solve_residual(rid_local, if_id, 'tx')
                if synth_tx is not None: candidates.append(synth_tx)

                synth_rx = solve_residual(rid_remote, peer_id, 'rx')
                if synth_rx is not None: candidates.append(synth_rx)

                # Evaluate unique candidates
                best_score = float('inf')
                best_val = cand_tx

                # Use set for deduplication, round to ignore micro-diffs
                unique_cands = sorted(list({round(c, 4): c for c in candidates}.values()))

                for cand in unique_cands:
                    score = get_candidate_score(cand)

                    # Heuristic: If we have a healthy non-zero candidate, penalize near-zero candidates
                    # This helps break ties in favor of activity when one side is dead
                    if cand < MIN_ACTIVITY and max(unique_cands) > MIN_ACTIVITY:
                        score += 0.25

                    if score < best_score:
                        best_score = score
                        best_val = cand
>>>>>>> REPLACE
<<<<<<< SEARCH
        def get_rate_confidence(orig, final, field):
            changed = abs(orig - final) > 0.001
            ver_level = get_verification_level(final, field)
            consistent_with_peer = is_peer_consistent(final, field)

            # 1. High Confidence Scenarios
            if ver_level == 3: return 0.99 # Verified by both ends
            if ver_level == 2: return 0.95 # Verified locally (strongest signal)

            # 2. Unchanged Data
            if not changed:
                # If we didn't change it, but it contradicts the peer, confidence drops
                if not consistent_with_peer:
                    return 0.7
                # If consistent and unchanged
                if ver_level == 1: return 0.95 # Verified remote
                return 0.9 # Good default

            # 3. Changed Data
            # Smoothing (small change)
            if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                return 0.95

            # Significant changes
            if ver_level == 1: return 0.90 # Verified remote

            # Unverified Repairs
            if orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                return 0.85 # Dead counter repair

            # If we changed it, it's not verified, but now consistent with peer (by definition of repair)
            # This is a "Trust Peer" repair
            return 0.75
=======
        def get_rate_confidence(orig, final, field):
            changed = abs(orig - final) > 0.001
            ver_level = get_verification_level(final, field)
            consistent_with_peer = is_peer_consistent(final, field)

            # Bonus for high-magnitude verified signals (SNR)
            # If value is > 5Mbps and verified, we are more sure than if it's 0.1Mbps
            mag_bonus = 0.01 if final > 5.0 else 0.0

            # 1. High Confidence Scenarios
            if ver_level == 3: return min(0.99 + mag_bonus, 1.0)
            if ver_level == 2: return min(0.97 + mag_bonus, 0.99)

            # 2. Unchanged Data
            if not changed:
                if not consistent_with_peer: return 0.7
                if ver_level == 1: return 0.95
                return 0.9

            # 3. Changed Data
            # Smoothing
            if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                return 0.95

            # Significant changes
            if ver_level == 1: return 0.92 # Remote verification is decent

            # Unverified Repairs
            # Dead repair
            if orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                if final > 5.0: return 0.85 # Strong signal
                return 0.80

            # Trust Peer / Best Guess
            if consistent_with_peer: return 0.75
            return 0.6
>>>>>>> REPLACE
</DIFF>