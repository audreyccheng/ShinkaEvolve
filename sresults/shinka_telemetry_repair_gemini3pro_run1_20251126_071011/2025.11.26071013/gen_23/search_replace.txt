<NAME>
flow_synthesis_and_continuous_confidence
</NAME>

<DESCRIPTION>
1. Introduces flow-based candidate synthesis in the rate repair loop. This allows the algorithm to propose new values (derived from flow conservation `Sum(In)=Sum(Out)`) when both local and remote measurements are suspect or inconsistent. This is particularly useful for "double dead" links or when both sides disagree significantly.
2. Replaces the bucket-based confidence scoring with a continuous calibration model based on residual flow errors. Confidence now scales linearly with the quality of the fit (flow error magnitude), providing more accurate calibration (penalizing bad repairs more, rewarding perfect fits higher).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Run 3 passes to allow corrections to propagate across the network
    for _ in range(3):
        # Iterate over all interfaces to check Link Symmetry
        for if_id, s in state.items():
            if s['status'] == 'down': continue

            peer_id = s['connected_to']
            if not peer_id or peer_id not in state:
                continue

            # We process the "outgoing" link: Tx(Local) -> Rx(Peer)
            cand_tx = s['tx']              # Candidate 1: Local Tx
            cand_rx = state[peer_id]['rx'] # Candidate 2: Peer Rx

            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            if diff < max(mag * TOLERANCE, MIN_ACTIVITY):
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_local = s['local_router']
                rid_remote = state[peer_id]['local_router']

                # Helper to score a candidate value based on flow impact
                # Lower score is better
                def get_candidate_score(val):
                    # Check local router (TX side)
                    err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                    # Check remote router (RX side)
                    err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)

                    score = 0.0

                    # Cost for Local
                    if err_local is None: score += 0.02 # Unverifiable = small cost
                    else: score += min(err_local, 1.0)  # Verifiable = actual error

                    # Cost for Remote
                    if err_remote is None: score += 0.02
                    else: score += min(err_remote, 1.0)

                    return score

                score_tx = get_candidate_score(cand_tx)
                score_rx = get_candidate_score(cand_rx)

                # Heuristic: Dead counters (0) are often wrong if the other side is active
                # Penalize the zero value
                if cand_tx < MIN_ACTIVITY and cand_rx > MIN_ACTIVITY: score_tx += 0.5
                if cand_rx < MIN_ACTIVITY and cand_tx > MIN_ACTIVITY: score_rx += 0.5

                if score_tx < score_rx:
                    best_val = cand_tx
                elif score_rx < score_tx:
                    best_val = cand_rx
                else:
                    best_val = (cand_tx + cand_rx) / 2.0 # Tie -> Average

            # Apply repair to state
            state[if_id]['tx'] = best_val
            state[peer_id]['rx'] = best_val
=======
    # Run 3 passes to allow corrections to propagate across the network
    for _ in range(3):
        # Iterate over all interfaces to check Link Symmetry
        for if_id, s in state.items():
            if s['status'] == 'down': continue

            peer_id = s['connected_to']
            if not peer_id or peer_id not in state:
                continue

            # We process the "outgoing" link: Tx(Local) -> Rx(Peer)
            cand_tx = s['tx']              # Candidate 1: Local Tx
            cand_rx = state[peer_id]['rx'] # Candidate 2: Peer Rx

            # 3a. Check for agreement
            diff = abs(cand_tx - cand_rx)
            mag = max(cand_tx, cand_rx, 1.0)

            if diff < max(mag * TOLERANCE, MIN_ACTIVITY):
                # Agree: Average to smooth out small noise
                best_val = (cand_tx + cand_rx) / 2.0
            else:
                # Disagree: Conflict Resolution using Flow Conservation
                rid_local = s['local_router']
                rid_remote = state[peer_id]['local_router']

                # Helper to predict value from flow conservation
                def get_flow_prediction(rid, if_target, field):
                    if rid not in verifiable_routers:
                        return None

                    sum_in = 0.0
                    sum_out = 0.0
                    for iface in router_interfaces[rid]:
                        if iface == if_target: continue
                        sum_in += state[iface]['rx']
                        sum_out += state[iface]['tx']

                    # Sum(In) = Sum(Out)
                    if field == 'tx':
                        # Tx_target = Sum(In) - Sum(Out_others)
                        # We need to include 'rx' of if_target in Sum(In)
                        sum_in += state[if_target]['rx']
                        val = sum_in - sum_out
                    else:
                        # Rx_target = Sum(Out) - Sum(In_others)
                        # We need to include 'tx' of if_target in Sum(Out)
                        sum_out += state[if_target]['tx']
                        val = sum_out - sum_in

                    return max(0.0, val)

                # Gather candidates
                candidates = [cand_tx, cand_rx]

                # Try to synthesize candidates from flow
                synth_tx = get_flow_prediction(rid_local, if_id, 'tx')
                if synth_tx is not None: candidates.append(synth_tx)

                synth_rx = get_flow_prediction(rid_remote, peer_id, 'rx')
                if synth_rx is not None: candidates.append(synth_rx)

                # Helper to score a candidate value based on flow impact
                def get_candidate_score(val):
                    # Check local router (TX side)
                    err_local = calc_flow_error(rid_local, if_id, 'tx', val)
                    # Check remote router (RX side)
                    err_remote = calc_flow_error(rid_remote, peer_id, 'rx', val)

                    score = 0.0

                    # Cost for Local
                    if err_local is None: score += 0.02 # Unverifiable = small cost
                    else: score += min(err_local, 1.0)  # Verifiable = actual error

                    # Cost for Remote
                    if err_remote is None: score += 0.02
                    else: score += min(err_remote, 1.0)

                    # Heuristic: Penalize exactly zero if likely active (to break ties)
                    if val < MIN_ACTIVITY:
                         score += 0.01

                    return score

                # Evaluate all candidates
                best_score = float('inf')
                best_val = cand_tx

                # Dedup candidates
                candidates = sorted(list(set(candidates)))

                for val in candidates:
                    sc = get_candidate_score(val)

                    # Extra penalty for original measurements if they look "Dead"
                    # while the other side is active.
                    if val < MIN_ACTIVITY:
                         if (val == cand_tx and cand_rx > MIN_ACTIVITY) or \
                            (val == cand_rx and cand_tx > MIN_ACTIVITY):
                             sc += 0.5

                    if sc < best_score:
                        best_score = sc
                        best_val = val

            # Apply repair to state
            state[if_id]['tx'] = best_val
            state[peer_id]['rx'] = best_val
>>>>>>> REPLACE
<<<<<<< SEARCH
        # Helper: check for peer consistency
        def is_peer_consistent(val, field):
            peer_id = data.get('connected_to')
            if not peer_id or peer_id not in state:
                return True # Can't check, assume consistent

            # Compare with peer's finalized value (which should be symmetric)
            peer_val = state[peer_id]['tx'] if field == 'rx' else state[peer_id]['rx']

            # Use same tolerance as repair loop
            diff = abs(val - peer_val)
            mag = max(val, peer_val, 1.0)
            return diff < max(mag * TOLERANCE, MIN_ACTIVITY)

        # Helper: check verification
        def get_verification_level(val, field):
            # Local Verification
            rid = data.get('local_router')
            local_err = calc_flow_error(rid, if_id, field, val)
            local_ok = (local_err is not None and local_err < FLOW_TOLERANCE)

            # Remote Verification
            remote_ok = False
            peer_id = data.get('connected_to')
            rem_rid = data.get('remote_router')

            if rem_rid and peer_id:
                check_field = 'tx' if field == 'rx' else 'rx'
                rem_err = calc_flow_error(rem_rid, peer_id, check_field, val)
                if rem_err is not None and rem_err < FLOW_TOLERANCE:
                    remote_ok = True

            if local_ok and remote_ok: return 3 # Both
            if local_ok: return 2 # Local only
            if remote_ok: return 1 # Remote only
            return 0 # None

        def get_rate_confidence(orig, final, field):
            changed = abs(orig - final) > 0.001
            ver_level = get_verification_level(final, field)
            consistent_with_peer = is_peer_consistent(final, field)

            # 1. High Confidence Scenarios
            if ver_level == 3: return 0.99 # Verified by both ends
            if ver_level == 2: return 0.95 # Verified locally (strongest signal)

            # 2. Unchanged Data
            if not changed:
                # If we didn't change it, but it contradicts the peer, confidence drops
                if not consistent_with_peer:
                    return 0.7
                # If consistent and unchanged
                if ver_level == 1: return 0.95 # Verified remote
                return 0.9 # Good default

            # 3. Changed Data
            # Smoothing (small change)
            if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                return 0.95

            # Significant changes
            if ver_level == 1: return 0.90 # Verified remote

            # Unverified Repairs
            if orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                return 0.85 # Dead counter repair

            # If we changed it, it's not verified, but now consistent with peer (by definition of repair)
            # This is a "Trust Peer" repair
            return 0.75
=======
        def get_rate_confidence(orig, final, field):
            # Calculate residual errors for calibration
            rid = data.get('local_router')
            local_err = calc_flow_error(rid, if_id, field, final)

            rem_rid = data.get('remote_router')
            peer_id = data.get('connected_to')
            remote_err = None
            if rem_rid and peer_id:
                check_field = 'tx' if field == 'rx' else 'rx'
                remote_err = calc_flow_error(rem_rid, peer_id, check_field, final)

            # Base confidence based on verification level (Continuous)
            score = 1.0

            # 1. Verification Penalties
            if local_err is not None:
                # Local verification available
                # Penalty proportional to error
                score -= min(local_err * 5.0, 0.5)
            else:
                # Unverifiable locally
                score -= 0.1

            if remote_err is not None:
                score -= min(remote_err * 5.0, 0.5)
            else:
                score -= 0.1

            # 2. Peer Consistency Penalty
            # Even if locally consistent, disagreement with peer suggests issue
            if peer_id and peer_id in state:
                peer_val = state[peer_id]['tx'] if field == 'rx' else state[peer_id]['rx']
                diff = abs(final - peer_val)
                mag = max(final, peer_val, 1.0)
                if diff > max(mag * TOLERANCE, MIN_ACTIVITY):
                    score -= 0.2

            # 3. Change Magnitude Adjustments
            changed = abs(orig - final) > max(orig * 0.001, MIN_ACTIVITY)

            if not changed:
                # Unchanged
                pass
            else:
                # Changed
                if orig > MIN_ACTIVITY and abs(orig - final) / orig < 0.05:
                     # Smoothing - minimal penalty
                     pass
                elif orig < MIN_ACTIVITY and final > MIN_ACTIVITY:
                     # Dead counter repair - moderate penalty as it's a heuristic
                     score -= 0.05
                else:
                     # Large change
                     score -= 0.05

            # 4. Global Verification Bonus/Clamp
            # If perfectly verified both sides, boost
            if local_err is not None and local_err < 0.01 and \
               remote_err is not None and remote_err < 0.01:
                score = max(score, 0.99)

            return max(0.0, min(1.0, score))
>>>>>>> REPLACE
</DIFF>