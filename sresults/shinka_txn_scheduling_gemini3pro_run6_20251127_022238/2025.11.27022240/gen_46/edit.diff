--- a/original.py
+++ b/original.py
@@ -1,333 +1,326 @@
 # EVOLVE-BLOCK-START
 """Transaction scheduling algorithm for optimizing makespan across multiple workloads"""
 
 import time
 import random
 import sys
 import os
 import math
 
 # Add the openevolve_examples directory to the path to import txn_simulator and workloads
 # Find the repository root by looking for the openevolve_examples directory
 def find_repo_root(start_path):
     """Find the repository root by looking for openevolve_examples directory."""
     current = os.path.abspath(start_path)
     # Search up the directory tree
     while current != os.path.dirname(current):  # Stop at filesystem root
         candidate = os.path.join(current, 'openevolve_examples', 'txn_scheduling')
         if os.path.exists(candidate):
             return current
         current = os.path.dirname(current)
     
     # If not found by searching up, try common locations relative to known paths
     script_dir = os.path.dirname(os.path.abspath(__file__))
     possible_roots = [
         script_dir,  # Current directory
         os.path.dirname(script_dir),  # Parent
         os.path.dirname(os.path.dirname(script_dir)),  # Grandparent
         '/home/ubuntu/ShinkaEvolve',  # Absolute path fallback for Ubuntu
         '/Users/audreycc/Documents/Work/LLMTxn/ADRS-Exps/ShinkaEvolve',  # Absolute path fallback for macOS
     ]
     for root in possible_roots:
         candidate = os.path.join(root, 'openevolve_examples', 'txn_scheduling')
         if os.path.exists(candidate):
             return root
     
     raise RuntimeError(f"Could not find openevolve_examples directory. Searched from: {start_path}")
 
 try:
     repo_root = find_repo_root(os.path.dirname(__file__))
     sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'txn_scheduling'))
 except Exception as e:
     # Allow execution to proceed if modules are already in path or mock environment
     pass
 
 from txn_simulator import Workload
 from workloads import WORKLOAD_1, WORKLOAD_2, WORKLOAD_3
 
 
 def get_best_schedule(workload, num_seqs):
     """
-    Get optimal schedule using Deep-Lookahead Beam Search and Hybrid Perturbation ILS.
-
-    Architecture:
-    1. Metrics: Computes 'Urgency' based on Duration and Conflict Volume.
-       - Weighting favors conflict heavy items to schedule them early.
-    2. Beam Search with Pilot Lookahead:
-       - Instead of just evaluating the cost of adding a candidate, we perform a 'Pilot' rollout.
-       - We tentatively add the candidate + the top 2 most urgent remaining transactions.
-       - This Depth-2 lookahead avoids "painting into a corner" where a choice looks cheap now
-         but blocks critical tasks immediately after.
-    3. Iterated Local Search (ILS) with Hybrid Kicks:
-       - Uses deterministic windowed insertion for descent.
-       - Uses a mix of 'Block Shuffle' and 'Long-Distance Swap' for perturbation to escape local optima
-         more effectively than simple swaps.
+    Get optimal schedule using Lookahead Beam Search and Multi-Phase ILS.
+    
+    Strategy:
+    1. Calculate Urgency based on Duration and Conflict Volume.
+    2. Construct initial schedule with Beam Search + Lookahead (Cost(S + c + NextBest)).
+    3. Refine by globally re-inserting top critical items.
+    4. Optimize with ILS using Block Moves and Windowed Descent.
 
     Args:
         workload: Workload object
-        num_seqs: Budget parameter
+        num_seqs: Budget parameter (controls beam width)
 
     Returns:
         (lowest_makespan, schedule)
     """
-
+    
     num_txns = workload.num_txns
-
+    
     # --- 1. METRIC PRECOMPUTATION ---
-    txn_durations = {}
-    txn_rw_sets = {}
-
+    txn_data = [] # Stores (duration, read_set, write_set)
+    
     for t in range(num_txns):
         # Duration
+        d = 1.0
         try:
             d = workload.txns[t][0][3]
         except:
-            d = 1.0
-        txn_durations[t] = d
-
+            pass
+            
         # R/W Sets
         reads = set()
         writes = set()
         try:
             ops_str = workload.txns[t][0][1]
             if isinstance(ops_str, str):
                 for op in ops_str.split():
                     if '-' in op:
                         parts = op.split('-')
                         if len(parts) == 2:
-                            op_type, key = parts
-                            if op_type == 'r': reads.add(key)
-                            elif op_type == 'w': writes.add(key)
+                            type_, key = parts
+                            if type_ == 'r': reads.add(key)
+                            elif type_ == 'w': writes.add(key)
         except:
             pass
-        txn_rw_sets[t] = (reads, writes)
+        txn_data.append((d, reads, writes))
 
     # Conflict Volume: Sum of durations of conflicting transactions
-    txn_conflict_vol = {t: 0.0 for t in range(num_txns)}
-
+    conflict_vol = [0.0] * num_txns
     for i in range(num_txns):
-        r1, w1 = txn_rw_sets[i]
+        d1, r1, w1 = txn_data[i]
         vol = 0.0
         for j in range(num_txns):
             if i == j: continue
-            r2, w2 = txn_rw_sets[j]
-            # Conflict: (W1 n (W2 u R2)) or (R1 n W2)
+            d2, r2, w2 = txn_data[j]
+            # Conflict Condition:
+            # (W1 n W2) or (W1 n R2) or (R1 n W2)
             if not w1.isdisjoint(w2) or not w1.isdisjoint(r2) or not r1.isdisjoint(w2):
-                vol += txn_durations[j]
-        txn_conflict_vol[i] = vol
+                vol += d2
+        conflict_vol[i] = vol
 
     # Urgency Score
-    # Normalize
-    max_vol = max(txn_conflict_vol.values()) if txn_conflict_vol else 1.0
-    max_dur = max(txn_durations.values()) if txn_durations else 1.0
+    # Normalize for combination
+    max_vol = max(conflict_vol) if conflict_vol else 1.0
+    max_dur = max(t[0] for t in txn_data) if txn_data else 1.0
     if max_vol == 0: max_vol = 1.0
-
-    txn_urgency = {}
+    
+    urgency = {}
     for t in range(num_txns):
-        # Weights: Balance duration and conflict.
-        # Slightly higher weight on Conflict Volume to clear bottlenecks early.
-        score = (txn_durations[t] / max_dur) + 0.8 * (txn_conflict_vol[t] / max_vol)
-        txn_urgency[t] = score
-
-    # --- 2. DEEP-LOOKAHEAD BEAM SEARCH ---
-    
-    # Adaptive Beam Width
-    BEAM_WIDTH = max(4, int(num_seqs))
-    
-    # Beam State: (cost, schedule_list, remaining_list)
-    # We initialize with empty schedule
+        # Weighted mix: 40% Duration, 60% Conflict Volume
+        # Prefer clearing heavy bottlenecks early
+        u = 0.4 * (txn_data[t][0] / max_dur) + 0.6 * (conflict_vol[t] / max_vol)
+        urgency[t] = u
+
+    # --- 2. LOOKAHEAD BEAM SEARCH ---
+    
+    BEAM_WIDTH = max(5, int(num_seqs))
+    
+    # Beam State: (cost_heuristic, schedule_list, remaining_list)
+    # Note: cost_heuristic is used for sorting in beam, we use Lookahead Cost there.
     beam = [(0, [], list(range(num_txns)))]
-
-    for step in range(num_txns):
+    
+    for _ in range(num_txns):
         candidates_pool = []
         
-        for p_cost, p_sched, p_remain in beam:
-            
-            # 1. Candidate Generation
-            # Sort remaining by urgency
-            sorted_remain = sorted(p_remain, key=lambda x: txn_urgency[x], reverse=True)
-            
-            next_candidates = set()
-            
-            # Greedy: Top 4
-            next_candidates.update(sorted_remain[:4])
-            
-            # Weighted Sampling: 3 from the rest
-            if len(sorted_remain) > 4:
-                pool = sorted_remain[4:]
-                weights = [txn_urgency[x] for x in pool]
-                if pool:
-                    samples = random.choices(pool, weights=weights, k=min(3, len(pool)))
-                    next_candidates.update(samples)
-            
-            # 2. Evaluation with Pilot Lookahead
-            for c in next_candidates:
-                sched_c = p_sched + [c]
-                
-                # Pilot: What happens if we greedily fill the next few slots?
-                # This estimates the "blocking potential" of choosing c.
-                # We pick the Top 2 most urgent items from the remaining (excluding c)
-                
-                # Efficiently find next top 2
-                pilot_items = []
-                count = 0
-                for u in sorted_remain:
-                    if u == c: continue
-                    pilot_items.append(u)
-                    count += 1
-                    if count >= 2: break
-                
-                # Construct Pilot Schedule
-                sched_pilot = sched_c + pilot_items
-                cost_pilot = workload.get_opt_seq_cost(sched_pilot)
-                
-                # Metric: (PilotCost, ImmediateCost, -Urgency)
-                # Primary: Minimize the cost after lookahead
-                # Tie-breaker: Minimize immediate cost
-                metric = (cost_pilot, -txn_urgency[c])
+        for _, p_sched, p_remain in beam:
+            
+            # Sort remaining by Urgency
+            sorted_remain = sorted(p_remain, key=lambda x: urgency[x], reverse=True)
+            
+            # Candidate Selection
+            # 1. Top K Deterministic
+            to_check = set(sorted_remain[:3])
+            
+            # 2. Weighted Random (Soft urgency)
+            if len(sorted_remain) > 3:
+                pool = sorted_remain[3:]
+                weights = [urgency[x] for x in pool]
+                # Sample 3
+                samples = random.choices(pool, weights=weights, k=min(3, len(pool)))
+                to_check.update(samples)
+            
+            # Lookahead Setup
+            # The "Next Best" item to tentatively add is the most urgent one remaining.
+            # If 'c' is the most urgent, Next Best is the 2nd most urgent.
+            best_urgent = sorted_remain[0]
+            second_best = sorted_remain[1] if len(sorted_remain) > 1 else None
+            
+            for c in to_check:
+                new_sched = p_sched + [c]
+                
+                # Lookahead Metric
+                # Determine probe item
+                probe = best_urgent if c != best_urgent else second_best
+                
+                if probe is not None:
+                    # Cost after 2 steps
+                    metric_cost = workload.get_opt_seq_cost(new_sched + [probe])
+                else:
+                    # End of list
+                    metric_cost = workload.get_opt_seq_cost(new_sched)
+                
+                # Tuple for sorting: (LookaheadCost, -Urgency)
+                metric = (metric_cost, -urgency[c])
                 
                 new_remain = list(p_remain)
                 new_remain.remove(c)
                 
-                candidates_pool.append((metric, sched_c, new_remain))
+                candidates_pool.append((metric, new_sched, new_remain))
         
         # Pruning
-        # Sort by Pilot Cost
         candidates_pool.sort(key=lambda x: x[0])
-        
-        # Select best states
-        best_candidates = candidates_pool[:BEAM_WIDTH]
-        beam = []
-        for _, sched, remain in best_candidates:
-            # We must compute exact cost for the beam state tuple to be correct for next iteration
-            # This avoids error accumulation from the pilot cost
-            real_cost = workload.get_opt_seq_cost(sched)
-            beam.append((real_cost, sched, remain))
-            
-    # Extract Best from final beam
-    best_state = min(beam, key=lambda x: x[0])
-    current_cost = best_state[0]
+        # Keep top Width
+        # Store just the tuple needed for next iteration
+        beam = [(x[0][0], x[1], x[2]) for x in candidates_pool[:BEAM_WIDTH]]
+    
+    # Best Schedule from Beam
+    best_state = beam[0]
     current_schedule = best_state[1]
-
-    # --- 3. REFINEMENT: ITERATED LOCAL SEARCH (ILS) ---
-
-    def local_descent(sched, base_cost, pass_limit=2):
-        """Windowed insertion to improve schedule locally."""
+    current_cost = workload.get_opt_seq_cost(current_schedule)
+
+    # --- 3. CRITICAL PATH RE-INSERTION ---
+    # Global optimization for the most critical items.
+    
+    num_critical = min(8, num_txns)
+    critical_txns = sorted(range(num_txns), key=lambda x: urgency[x], reverse=True)[:num_critical]
+    
+    for t in critical_txns:
+        if t not in current_schedule: continue
+        
+        curr_idx = current_schedule.index(t)
+        # Remove
+        temp_sched = current_schedule[:curr_idx] + current_schedule[curr_idx+1:]
+        
+        best_pos = curr_idx
+        best_val = current_cost
+        
+        # Try all positions
+        for p in range(len(temp_sched) + 1):
+            cand = temp_sched[:p] + [t] + temp_sched[p:]
+            val = workload.get_opt_seq_cost(cand)
+            if val < best_val:
+                best_val = val
+                best_pos = p
+        
+        if best_val < current_cost:
+            current_cost = best_val
+            current_schedule = temp_sched[:best_pos] + [t] + temp_sched[best_pos:]
+
+    # --- 4. MULTI-CYCLE ITERATED LOCAL SEARCH ---
+    
+    def local_descent(sched, base_cost, window=10):
+        s = list(sched)
+        c = base_cost
         improved = True
-        curr_sched = list(sched)
-        curr_c = base_cost
-        
         passes = 0
-        while improved and passes < pass_limit:
+        while improved and passes < 2:
             improved = False
             passes += 1
-            
-            # Randomized order of check to avoid bias
-            indices = list(range(len(curr_sched)))
-            random.shuffle(indices)
-            
-            for i in indices:
-                txn = curr_sched[i]
-                
-                # Remove
-                temp = curr_sched[:i] + curr_sched[i+1:]
-                
-                # Window: [-12, +12]
-                window = 12
+            check_order = list(range(len(s)))
+            random.shuffle(check_order)
+            
+            for i in check_order:
+                item = s[i]
+                temp = s[:i] + s[i+1:]
+                
                 start = max(0, i - window)
                 end = min(len(temp), i + window)
                 
-                best_pos = -1
-                best_val = curr_c
-                
-                # Scan window
+                best_p = -1
+                best_c = c
+                
                 for p in range(start, end + 1):
-                    cand = temp[:p] + [txn] + temp[p:]
-                    c = workload.get_opt_seq_cost(cand)
-                    if c < best_val:
-                        best_val = c
-                        best_pos = p
-                
-                if best_pos != -1:
-                    curr_sched = temp[:best_pos] + [txn] + temp[best_pos:]
-                    curr_c = best_val
+                    cand = temp[:p] + [item] + temp[p:]
+                    val = workload.get_opt_seq_cost(cand)
+                    if val < best_c:
+                        best_c = val
+                        best_p = p
+                
+                if best_p != -1:
+                    s = temp[:best_p] + [item] + temp[best_p:]
+                    c = best_c
                     improved = True
-                    
-        return curr_c, curr_sched
+        return c, s
 
     # Initial Descent
-    current_cost, current_schedule = local_descent(current_schedule, current_cost, pass_limit=2)
-
+    current_cost, current_schedule = local_descent(current_schedule, current_cost)
+    
     # ILS Loop
-    # We use a limited number of kicks to stay within time budget
     num_kicks = 4
     
     for _ in range(num_kicks):
         neighbor = list(current_schedule)
         
-        # HYBRID PERTURBATION
-        # 50% Chance: Block Shuffle (Local fix for clustered conflicts)
-        # 50% Chance: Long Swap (Global fix for ordering)
-        
-        if random.random() < 0.5:
-            # Block Shuffle: Pick block of size 4-6, shuffle it
-            bsize = random.randint(4, 6)
-            if num_txns > bsize:
-                start_idx = random.randint(0, num_txns - bsize)
-                sub = neighbor[start_idx : start_idx+bsize]
-                random.shuffle(sub)
-                neighbor[start_idx : start_idx+bsize] = sub
+        # Perturbation: Block Move vs Swap
+        # Block Move (60%): Good for moving dependent chains
+        if random.random() < 0.6:
+            block_size = random.randint(3, 6)
+            if num_txns > block_size:
+                src = random.randint(0, num_txns - block_size)
+                block = neighbor[src : src+block_size]
+                del neighbor[src : src+block_size]
+                dst = random.randint(0, len(neighbor))
+                neighbor[dst:dst] = block
         else:
-            # Long Swaps: 2 random pairs
-            for _ in range(2):
+            # Multi-Swap (40%)
+            for _ in range(3):
                 i, j = random.randint(0, num_txns-1), random.randint(0, num_txns-1)
                 neighbor[i], neighbor[j] = neighbor[j], neighbor[i]
-
+        
+        # Repair
         kick_cost = workload.get_opt_seq_cost(neighbor)
-        
-        # Repair (Shallow descent for speed)
-        new_cost, new_sched = local_descent(neighbor, kick_cost, pass_limit=1)
-        
-        # Accept if better
-        if new_cost < current_cost:
-            current_cost = new_cost
-            current_schedule = new_sched
+        repaired_cost, repaired_sched = local_descent(neighbor, kick_cost, window=8)
+        
+        # Acceptance
+        if repaired_cost < current_cost:
+            current_cost = repaired_cost
+            current_schedule = repaired_sched
 
     return current_cost, current_schedule
 
 
 def get_random_costs():
     """Evaluate scheduling algorithm on three different workloads."""
     start_time = time.time()
     
     num_seqs = 10
     
     workload1 = Workload(WORKLOAD_1)
     makespan1, schedule1 = get_best_schedule(workload1, num_seqs)
 
     workload2 = Workload(WORKLOAD_2)
     makespan2, schedule2 = get_best_schedule(workload2, num_seqs)
 
     workload3 = Workload(WORKLOAD_3)
     makespan3, schedule3 = get_best_schedule(workload3, num_seqs)
     
     total_makespan = makespan1 + makespan2 + makespan3
     schedules = [schedule1, schedule2, schedule3]
     execution_time = time.time() - start_time
     
     return total_makespan, schedules, execution_time
 
 # EVOLVE-BLOCK-END
 
 
 # This part remains fixed (not evolved)
 def run_scheduling():
     """Run the transaction scheduling algorithm for all workloads"""
     total_makespan, schedules, execution_time = get_random_costs()
     return total_makespan, schedules, execution_time
 
 
 if __name__ == "__main__":
     total_makespan, schedules, execution_time = run_scheduling()
     print(f"Total makespan: {total_makespan}, Execution time: {execution_time:.4f}s")
     print(f"Individual workload costs: {[workload.get_opt_seq_cost(schedule) for workload, schedule in zip([Workload(WORKLOAD_1), Workload(WORKLOAD_2), Workload(WORKLOAD_3)], schedules)]}")