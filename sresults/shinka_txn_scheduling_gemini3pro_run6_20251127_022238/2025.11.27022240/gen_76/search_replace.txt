<NAME>
improved_scheduling_algorithm
</NAME>

<DESCRIPTION>
I am replacing the `get_best_schedule` function with an enhanced version incorporating several optimizations based on performance analysis:
1.  **Quartic Probability Weighting ($d^4$)**: In the beam search sampling phase, transaction selection probability is now proportional to the 4th power of duration. This aggressively biases the search towards "heavy" transactions, helping to pack difficult items early.
2.  **Top-4 Lookahead**: The lookahead mechanism now evaluates the top 4 remaining LPT transactions (instead of just 1 or 3) to better assess the quality of a partial schedule.
3.  **Deterministic Anchors**: The beam search now deterministically includes the top 4 LPT candidates before sampling, ensuring critical paths are not missed due to randomness.
4.  **Robust ILS with Threshold Acceptance**: The local search phase is upgraded to a full "Ruin and Recreate" strategy with aggressive perturbation (removing 5-8 items). A threshold acceptance criterion allows accepting slightly worse solutions (0.2%) to escape local optima.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Lookahead Beam Search with Stochastic Sampling and ILS.

    Key Features:
    1. Lookahead: Evaluates candidates not just on the immediate move, but on the
       feasibility of scheduling the next largest task (LPT).
    2. Weighted Sampling: Biases exploration towards longer transactions.
    3. Iterated Local Search: Uses perturbation to escape local optima after beam search.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Used to scale the beam width

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # --- Parameters ---
    BEAM_WIDTH = int(max(10, num_seqs * 2.5))
    SAMPLES_PER_NODE = 16
    LOOKAHEAD_FACTOR = 2  # Evaluate lookahead for Top N * Factor candidates

    num_txns = workload.num_txns

    # --- Precompute Heuristics ---
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(num_txns)}
    sorted_lpt = sorted(range(num_txns), key=lambda t: txn_durations[t], reverse=True)

    # --- Initialization ---
    start_candidates = set()
    start_candidates.update(sorted_lpt[:BEAM_WIDTH])

    # Fill with random if needed
    attempts = 0
    while len(start_candidates) < BEAM_WIDTH * 2 and attempts < num_txns * 2:
        start_candidates.add(random.randint(0, num_txns - 1))
        attempts += 1

    beam = []
    for t in start_candidates:
        rem = set(range(num_txns))
        rem.remove(t)
        cost = txn_durations[t]
        # Score: Cost - TotalDuration (Work Density). Lower is better.
        beam.append({
            'cost': cost,
            'total_dur': cost,
            'seq': [t],
            'rem': rem,
            'base_score': cost - cost
        })

    beam.sort(key=lambda x: (x['base_score'], -x['total_dur']))
    beam = beam[:BEAM_WIDTH]

    # --- Beam Search Loop ---
    for _ in range(num_txns - 1):
        candidates = []

        for parent in beam:
            rem_list = list(parent['rem'])
            if not rem_list: continue

            # --- Hybrid Sampling ---
            samples = set()

            # 1. Deterministic LPT (Top 3)
            lpt_added = 0
            for t in sorted_lpt:
                if t in parent['rem']:
                    samples.add(t)
                    lpt_added += 1
                    if lpt_added >= 3:
                        break

            # 2. Weighted Random Sampling
            needed = SAMPLES_PER_NODE - len(samples)
            if needed > 0:
                pool = [t for t in rem_list if t not in samples]
                if pool:
                    if len(pool) <= needed:
                        samples.update(pool)
                    else:
                        weights = [txn_durations[t] for t in pool]
                        for _ in range(needed * 2): # Oversample to handle collisions
                            if len(samples) >= SAMPLES_PER_NODE: break
                            pick = random.choices(pool, weights=weights, k=1)[0]
                            samples.add(pick)

            # --- Base Evaluation ---
            for t in samples:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)
                new_total_dur = parent['total_dur'] + txn_durations[t]

                # Base Score: Density
                base_score = new_cost - new_total_dur

                candidates.append({
                    'cost': new_cost,
                    'total_dur': new_total_dur,
                    'seq': new_seq,
                    'rem': parent['rem'], # Ref only
                    'added': t,
                    'base_score': base_score
                })

        # --- Lookahead Stage ---
        # 1. Filter candidates by base score to keep manageable set for lookahead
        candidates.sort(key=lambda x: (x['base_score'], -x['total_dur']))

        # Deduplicate states before lookahead
        unique_cands = []
        seen_states = set()
        for cand in candidates:
            # New rem set
            new_rem = cand['rem'].copy()
            new_rem.remove(cand['added'])

            # State key
            state_key = frozenset(new_rem)
            if state_key not in seen_states:
                seen_states.add(state_key)
                cand['new_rem'] = new_rem
                unique_cands.append(cand)

        # Limit pool for expensive lookahead
        lookahead_pool = unique_cands[:BEAM_WIDTH * LOOKAHEAD_FACTOR]

        # 2. Perform Lookahead
        # Tentatively add the largest remaining transaction to see if it fits well
        for cand in lookahead_pool:
            if not cand['new_rem']:
                cand['final_score'] = cand['base_score']
                continue

            # Find max duration item in remaining
            next_heavy = None
            for t in sorted_lpt:
                if t in cand['new_rem']:
                    next_heavy = t
                    break

            if next_heavy is not None:
                la_seq = cand['seq'] + [next_heavy]
                la_cost = workload.get_opt_seq_cost(la_seq)
                la_total = cand['total_dur'] + txn_durations[next_heavy]
                cand['final_score'] = la_cost - la_total
            else:
                cand['final_score'] = cand['base_score']

        # 3. Final Selection
        lookahead_pool.sort(key=lambda x: (x['final_score'], -x['total_dur']))

        new_beam = []
        for cand in lookahead_pool[:BEAM_WIDTH]:
            new_beam.append({
                'cost': cand['cost'],
                'total_dur': cand['total_dur'],
                'seq': cand['seq'],
                'rem': cand['new_rem'],
                'base_score': cand['base_score']
            })

        if not new_beam:
            break
        beam = new_beam

    # Select best
    best_result = min(beam, key=lambda x: x['cost'])
    best_cost = best_result['cost']
    best_seq = best_result['seq']

    # --- Iterated Local Search (ILS) ---
    def refine(seq, current_cost):
        """Greedy insertion refinement"""
        w_size = 8
        improved = True
        while improved:
            improved = False
            for i in range(len(seq)):
                # Define window
                start = max(0, i - w_size)
                end = min(len(seq), i + w_size)

                # Try moving seq[i] to positions in window
                txn = seq[i]
                temp = seq[:i] + seq[i+1:]

                for k in range(start, end): # position in temp
                    cand = temp[:k] + [txn] + temp[k:]
                    c = workload.get_opt_seq_cost(cand)
                    if c < current_cost:
                        current_cost = c
                        seq = cand
                        improved = True
                        break
                if improved: break
        return seq, current_cost

    # Initial Descent
    best_seq, best_cost = refine(best_seq, best_cost)

    # Perturbation (Kick)
    for _ in range(2): # Try 2 random kicks
        p_seq = best_seq[:]
        if len(p_seq) > 2:
            idx1, idx2 = random.sample(range(len(p_seq)), 2)
            p_seq[idx1], p_seq[idx2] = p_seq[idx2], p_seq[idx1]

            # Repair
            p_seq, p_cost = refine(p_seq, workload.get_opt_seq_cost(p_seq))

            if p_cost < best_cost:
                best_cost = p_cost
                best_seq = p_seq

    return best_cost, best_seq
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Quartic-Weighted Beam Search and Threshold ILS.

    Algorithm:
    1. Beam Search:
       - Expansion: Hybrid sampling (Anchor 4 LPT + Quartic Weighted Random).
       - Weighting: d^4 weighting heavily biases selection towards long transactions.
       - Lookahead: Evaluates top-4 largest remaining transactions (Optimistic).
    2. ILS (Ruin & Recreate):
       - Ruin: Removes 5-8 items.
       - Recreate: Greedy Best-Fit.
       - Acceptance: Threshold acceptance (allows slight degradation) to escape optima.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Used to scale the beam width

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # --- Parameters ---
    BEAM_WIDTH = int(max(15, num_seqs * 2.8))
    SAMPLES_PER_NODE = 24
    MAX_CHILDREN = 4

    # Lookahead Settings
    LOOKAHEAD_FACTOR = 2.0
    LOOKAHEAD_TARGETS = 4

    # ILS Settings
    ILS_CYCLES = 10
    THRESHOLD_ALPHA = 0.002 # Accept 0.2% worse solutions

    num_txns = workload.num_txns

    # --- Precompute Heuristics ---
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(num_txns)}
    sorted_lpt = sorted(range(num_txns), key=lambda t: txn_durations[t], reverse=True)

    # --- Initialization ---
    start_candidates = set()
    start_candidates.update(sorted_lpt[:BEAM_WIDTH])
    attempts = 0
    while len(start_candidates) < BEAM_WIDTH * 2 and attempts < num_txns:
        start_candidates.add(random.randint(0, num_txns - 1))
        attempts += 1

    beam = []
    for t in start_candidates:
        rem = set(range(num_txns))
        rem.remove(t)
        cost = txn_durations[t]
        beam.append({
            'cost': cost,
            'total_dur': cost,
            'seq': [t],
            'rem': rem,
            'score': 0
        })

    # Initial Prune
    beam.sort(key=lambda x: (x['score'], -x['total_dur']))
    beam = beam[:BEAM_WIDTH]

    # --- Beam Search Loop ---
    for _ in range(num_txns - 1):
        candidates = []

        for p_idx, parent in enumerate(beam):
            rem_list = list(parent['rem'])
            if not rem_list: continue

            # --- Hybrid Sampling ---
            samples = set()

            # 1. Deterministic Anchor (Top 4 LPT)
            lpt_count = 0
            for t in sorted_lpt:
                if t in parent['rem']:
                    samples.add(t)
                    lpt_count += 1
                    if lpt_count >= 4: break

            # 2. Quartic Weighted Random Sampling
            needed = SAMPLES_PER_NODE - len(samples)
            if needed > 0:
                pool = [x for x in rem_list if x not in samples]
                if pool:
                    if len(pool) <= needed:
                        samples.update(pool)
                    else:
                        # Quartic weights (d^4)
                        weights = [txn_durations[x]**4 for x in pool]
                        try:
                            # random.choices is fast
                            chosen = set(random.choices(pool, weights=weights, k=needed * 2))
                            samples.update(chosen)
                        except ValueError:
                            pass

                        # Fill if still needed
                        if len(samples) < SAMPLES_PER_NODE:
                             needed_now = SAMPLES_PER_NODE - len(samples)
                             rem_pool = [x for x in pool if x not in samples]
                             if rem_pool:
                                 samples.update(random.sample(rem_pool, min(len(rem_pool), needed_now)))

            # --- Base Evaluation ---
            for t in samples:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)
                new_total_dur = parent['total_dur'] + txn_durations[t]

                # Base Score: Density
                base_score = new_cost - new_total_dur

                candidates.append({
                    'cost': new_cost,
                    'total_dur': new_total_dur,
                    'seq': new_seq,
                    'rem': parent['rem'],
                    'added': t,
                    'p_idx': p_idx,
                    'base_score': base_score
                })

        # --- Lookahead Phase ---
        # 1. Filter promising candidates
        candidates.sort(key=lambda x: (x['base_score'], -x['total_dur']))

        # 2. Deduplicate
        lookahead_pool = []
        seen_states = set()
        target_pool_size = int(BEAM_WIDTH * LOOKAHEAD_FACTOR)

        for cand in candidates:
            new_rem = cand['rem'].copy()
            new_rem.remove(cand['added'])
            state_key = frozenset(new_rem)

            if state_key not in seen_states:
                seen_states.add(state_key)
                cand['new_rem'] = new_rem
                lookahead_pool.append(cand)
                if len(lookahead_pool) >= target_pool_size:
                    break

        # 3. Multi-Target Optimistic Lookahead
        for cand in lookahead_pool:
            rem_set = cand['new_rem']
            if not rem_set:
                cand['final_score'] = cand['base_score']
                continue

            # Identify critical targets (Top 4 LPT)
            targets = []
            count = 0
            for t in sorted_lpt:
                if t in rem_set:
                    targets.append(t)
                    count += 1
                    if count >= LOOKAHEAD_TARGETS: break

            if targets:
                # Optimistic: Can we fit ANY of the top items well?
                best_la_score = float('inf')
                for next_t in targets:
                    la_seq = cand['seq'] + [next_t]
                    la_cost = workload.get_opt_seq_cost(la_seq)
                    la_total = cand['total_dur'] + txn_durations[next_t]
                    score = la_cost - la_total
                    if score < best_la_score:
                        best_la_score = score
                cand['final_score'] = best_la_score
            else:
                cand['final_score'] = cand['base_score']

        # 4. Final Selection
        lookahead_pool.sort(key=lambda x: (x['final_score'], -x['total_dur']))

        new_beam = []
        p_counts = {i: 0 for i in range(len(beam))}
        reserve = []

        for cand in lookahead_pool:
            p_idx = cand['p_idx']
            node = {
                'cost': cand['cost'],
                'total_dur': cand['total_dur'],
                'seq': cand['seq'],
                'rem': cand['new_rem']
            }

            if p_counts[p_idx] < MAX_CHILDREN:
                if len(new_beam) < BEAM_WIDTH:
                    new_beam.append(node)
                    p_counts[p_idx] += 1
                else:
                    pass
            else:
                reserve.append(node)

            if len(new_beam) >= BEAM_WIDTH and len(reserve) > BEAM_WIDTH:
                break

        if len(new_beam) < BEAM_WIDTH:
            for node in reserve:
                if len(new_beam) >= BEAM_WIDTH: break
                new_beam.append(node)

        if not new_beam:
            break
        beam = new_beam

    # Select best
    best_result = min(beam, key=lambda x: x['cost'])
    best_cost = best_result['cost']
    best_seq = best_result['seq']

    # --- Ruin-and-Recreate ILS ---

    def refine(seq, cost):
        """Local Search: Swaps, Insertions, Block Moves."""
        improved = True
        while improved:
            improved = False

            # 1. Swaps (Window 5)
            for i in range(len(seq) - 1):
                for offset in range(1, 6):
                    j = i + offset
                    if j >= len(seq): break
                    seq[i], seq[j] = seq[j], seq[i]
                    c = workload.get_opt_seq_cost(seq)
                    if c < cost:
                        cost = c
                        improved = True
                    else:
                        seq[i], seq[j] = seq[j], seq[i]
                if improved: break
            if improved: continue

            # 2. Insertions (Window 8)
            w_ins = 8
            for i in range(len(seq)):
                start = max(0, i - w_ins)
                end = min(len(seq), i + w_ins)
                curr = seq[i]
                temp = seq[:i] + seq[i+1:]

                for k in range(start, end):
                    if k == i: continue
                    cand = temp[:k] + [curr] + temp[k:]
                    c = workload.get_opt_seq_cost(cand)
                    if c < cost:
                        cost = c
                        seq = cand
                        improved = True
                        break
                if improved: break
            if improved: continue

            # 3. Block Moves (Size 2)
            if len(seq) > 4:
                for i in range(len(seq) - 1):
                    block = seq[i:i+2]
                    rem_seq = seq[:i] + seq[i+2:]
                    w_blk = 6
                    start = max(0, i - w_blk)
                    end = min(len(rem_seq) + 1, i + w_blk)

                    for k in range(start, end):
                        if abs(k - i) < 2: continue
                        cand = rem_seq[:k] + block + rem_seq[k:]
                        c = workload.get_opt_seq_cost(cand)
                        if c < cost:
                            cost = c
                            seq = cand
                            improved = True
                            break
                    if improved: break

        return seq, cost

    # Phase 1: Initial Descent
    best_seq, best_cost = refine(best_seq, best_cost)

    # Phase 2: Iterated Ruin and Recreate
    curr_seq = best_seq[:]
    curr_cost = best_cost

    for _ in range(ILS_CYCLES):
        p_seq = curr_seq[:]

        # Ruin: Remove random 5-8 items
        if len(p_seq) > 10:
            ruin_size = random.randint(5, 8)
            removed = []
            for _ in range(ruin_size):
                if not p_seq: break
                idx = random.randint(0, len(p_seq) - 1)
                removed.append(p_seq.pop(idx))

            # Recreate: Best-Fit greedy insertion (Heavy First)
            removed.sort(key=lambda t: txn_durations[t], reverse=True)

            for t in removed:
                best_pos = -1
                best_c = float('inf')
                # Try all positions
                for pos in range(len(p_seq) + 1):
                    cand = p_seq[:pos] + [t] + p_seq[pos:]
                    c = workload.get_opt_seq_cost(cand)
                    if c < best_c:
                        best_c = c
                        best_pos = pos
                p_seq.insert(best_pos, t)

        # Repair
        p_seq, p_cost = refine(p_seq, workload.get_opt_seq_cost(p_seq))

        # Acceptance (Threshold)
        if p_cost < best_cost:
            best_cost = p_cost
            best_seq = p_seq
            curr_seq = p_seq
            curr_cost = p_cost
        elif p_cost < curr_cost * (1.0 + THRESHOLD_ALPHA):
            curr_seq = p_seq
            curr_cost = p_cost

    return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>