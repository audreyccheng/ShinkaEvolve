<NAME>
tapered_beam_insertion_refine
</NAME>

<DESCRIPTION>
1. Implements a **Tapered Beam Width** strategy. The beam width starts large (2.0x base) to explore diverse schedule roots and linearly decays to a narrower width (0.8x base). This allocates computational budget where it matters most (early structural decisions) while maintaining efficiency.
2. Replaces the swap-based local search with a **Shift/Insert Refinement**. Moving transactions to best positions within a window handles dependency constraints better than adjacent swaps.
3. Adjusts sampling parameters (`SAMPLES_PER_NODE` reduced slightly) to balance the wider initial beam.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Parameters ---
    # Beam Width: Scale with effort, ensure minimum size for stability
    BEAM_WIDTH = int(max(10, num_seqs * 2.0))

    # Samples per node: Candidates to evaluate from each parent
    SAMPLES_PER_NODE = 20

    # Diversity: Max children to accept from a single parent in the next beam
    # This prevents one "lucky" parent from flooding the beam with minor variations
    MAX_CHILDREN = 3

    num_txns = workload.num_txns

    # --- Precompute Heuristics ---
    # Duration: Proxy for transaction complexity/conflict potential.
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(num_txns)}

    # Sorted list for easy LPT (Longest Processing Time) access
    sorted_by_duration = sorted(range(num_txns), key=lambda t: txn_durations[t], reverse=True)

    # --- Initialization ---
    # Seed beam with:
    # 1. Top LPT transactions (often best anchors)
    # 2. Random transactions (for diversity)
    start_candidates = set()
    start_candidates.update(sorted_by_duration[:BEAM_WIDTH])

    # Fill remaining slots with random starts
    while len(start_candidates) < BEAM_WIDTH * 2:
        start_candidates.add(random.randint(0, num_txns - 1))

    beam = []
    for t in start_candidates:
        rem = set(range(num_txns))
        rem.remove(t)
        beam.append({
            'cost': txn_durations[t],
            'total_dur': txn_durations[t],
            'seq': [t],
            'rem': rem
        })

    # Initial prune: Sort by cost, tie-break by total duration
    beam.sort(key=lambda x: (x['cost'], -x['total_dur']))
    beam = beam[:BEAM_WIDTH]
=======
    # --- Parameters ---
    # Base Beam Width: Scale with effort
    # We will use a dynamic width that tapers off
    BASE_WIDTH = int(max(10, num_seqs * 1.5))

    # Samples per node: Candidates to evaluate from each parent
    SAMPLES_PER_NODE = 16

    # Diversity: Max children to accept from a single parent in the next beam
    MAX_CHILDREN = 3

    num_txns = workload.num_txns

    # --- Precompute Heuristics ---
    # Duration: Proxy for transaction complexity/conflict potential.
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(num_txns)}

    # Sorted list for easy LPT (Longest Processing Time) access
    sorted_by_duration = sorted(range(num_txns), key=lambda t: txn_durations[t], reverse=True)

    # --- Initialization ---
    # Seed beam with:
    # 1. Top LPT transactions (often best anchors)
    # 2. Random transactions (for diversity)
    start_candidates = set()
    # Start wider (2.0x base) to capture good roots
    init_width = int(BASE_WIDTH * 2.0)
    start_candidates.update(sorted_by_duration[:init_width])

    # Fill remaining slots with random starts
    while len(start_candidates) < init_width * 1.5:
        start_candidates.add(random.randint(0, num_txns - 1))

    beam = []
    for t in start_candidates:
        rem = set(range(num_txns))
        rem.remove(t)
        beam.append({
            'cost': txn_durations[t],
            'total_dur': txn_durations[t],
            'seq': [t],
            'rem': rem
        })

    # Initial prune: Sort by cost, tie-break by total duration
    beam.sort(key=lambda x: (x['cost'], -x['total_dur']))
    beam = beam[:init_width]
>>>>>>> REPLACE
<<<<<<< SEARCH
    # --- Beam Search Loop ---
    for _ in range(num_txns - 1):
        candidates = []

        for p_idx, parent in enumerate(beam):
            rem_list = list(parent['rem'])
=======
    # --- Beam Search Loop ---
    for step in range(num_txns - 1):
        # Dynamic Beam Width: Taper from 2.0x to 0.8x BASE_WIDTH
        # This allocates more resources to early, critical decisions
        progress = step / num_txns
        curr_width = int(BASE_WIDTH * (2.0 - 1.2 * progress))
        curr_width = max(5, curr_width)

        candidates = []

        for p_idx, parent in enumerate(beam):
            rem_list = list(parent['rem'])
>>>>>>> REPLACE
<<<<<<< SEARCH
        # Fill beam from unique candidates
        for cand in unique_candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            p_idx = cand['p_idx']
            # Diversity Check
            if parent_usage[p_idx] < MAX_CHILDREN:
                new_beam.append({
                    'cost': cand['cost'],
                    'total_dur': cand['total_dur'],
                    'seq': cand['seq'],
                    'rem': cand['state_rem']
                })
                parent_usage[p_idx] += 1
            else:
                reserve.append(cand)

        # Fill from reserve (relax diversity if beam not full)
        if len(new_beam) < BEAM_WIDTH:
            for cand in reserve:
                if len(new_beam) >= BEAM_WIDTH:
                    break
                new_beam.append({
                    'cost': cand['cost'],
                    'total_dur': cand['total_dur'],
                    'seq': cand['seq'],
                    'rem': cand['state_rem']
                })
=======
        # Fill beam from unique candidates
        for cand in unique_candidates:
            if len(new_beam) >= curr_width:
                break

            p_idx = cand['p_idx']
            # Diversity Check
            if parent_usage[p_idx] < MAX_CHILDREN:
                new_beam.append({
                    'cost': cand['cost'],
                    'total_dur': cand['total_dur'],
                    'seq': cand['seq'],
                    'rem': cand['state_rem']
                })
                parent_usage[p_idx] += 1
            else:
                reserve.append(cand)

        # Fill from reserve (relax diversity if beam not full)
        if len(new_beam) < curr_width:
            for cand in reserve:
                if len(new_beam) >= curr_width:
                    break
                new_beam.append({
                    'cost': cand['cost'],
                    'total_dur': cand['total_dur'],
                    'seq': cand['seq'],
                    'rem': cand['state_rem']
                })
>>>>>>> REPLACE
<<<<<<< SEARCH
    # --- Local Search Refinement ---
    # Windowed swaps to fix local ordering inefficiencies
    # A small window is sufficient to catch most greedy errors
    WINDOW = 4
    for _ in range(3): # Max passes
        improved = False
        for i in range(num_txns - 1):
            # Try swapping with neighbors up to WINDOW distance
            for offset in range(1, WINDOW + 1):
                j = i + offset
                if j >= num_txns:
                    break

                # Swap
                best_seq[i], best_seq[j] = best_seq[j], best_seq[i]
                new_c = workload.get_opt_seq_cost(best_seq)

                if new_c < best_cost:
                    best_cost = new_c
                    improved = True
                    # Keep swap and continue
                else:
                    # Revert
                    best_seq[i], best_seq[j] = best_seq[j], best_seq[i]

        if not improved:
            break
=======
    # --- Local Search Refinement ---
    # Shift/Insert moves are more effective for dependency ordering than swaps
    INSERT_WINDOW = 8

    # Pass 1: Local Swaps (Fast Cleanup)
    for i in range(num_txns - 1):
        best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]
        c = workload.get_opt_seq_cost(best_seq)
        if c < best_cost:
            best_cost = c
        else:
            best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]

    # Pass 2: Windowed Insertion (Structure optimization)
    # Try moving each transaction to a better location nearby
    for i in range(num_txns):
        txn = best_seq[i]

        # Candidate sequence without the transaction
        temp_seq = best_seq[:i] + best_seq[i+1:]

        start_j = max(0, i - INSERT_WINDOW)
        end_j = min(len(temp_seq), i + INSERT_WINDOW)

        for j in range(start_j, end_j + 1):
            if j == i: continue

            cand_seq = temp_seq[:j] + [txn] + temp_seq[j:]
            c = workload.get_opt_seq_cost(cand_seq)

            if c < best_cost:
                best_cost = c
                best_seq = cand_seq
                # Greedy: Accept immediately and move to next transaction
                # Note: This shifts indices for subsequent items, but that's acceptable for a heuristic pass
                break
>>>>>>> REPLACE
</DIFF>