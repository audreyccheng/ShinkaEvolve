# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Stochastic Greedy Sampling Scheduler**
- **Implementation**: Uses a constructive greedy algorithm that samples 10 random candidates at each step, selecting the transaction that minimizes the cumulative cost of the current sequence.
- **Performance**: Achieved a combined score of 2.83 while processing 300 total transactions across three workloads.
- **Feedback**: The randomized lookahead strategy provides a balance between computational efficiency and schedule quality, though the implementation only generates a single schedule sequence rather than exploring multiple paths.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Multi-Start Randomized Greedy with Heuristic Bias**
- **Implementation**: The algorithm utilizes a multi-start greedy strategy that constructs schedules by iteratively selecting the best candidate from a mix of random samples and high-cost "heavy" items. It executes 10 restarts, switching from broad random sampling to a heuristic-biased approach that prioritizes long-duration transactions to optimize placement.
- **Performance**: Achieved a strong combined score of 2.87, demonstrating effective minimization of total makespan across all three workloads.
- **Feedback**: The hybrid approach of combining random exploration with a "heaviest-first" heuristic bias proved highly effective for schedule optimization. The multi-start mechanism ensures robustness against local optima, while the cost-based bias helps resolve bottlenecks early in the construction process.
**Program Identifier:** Generation 1 - Patch Name iterative_heuristic_greedy_scheduling - Correct Program: True

**Program Name: Genetic Algorithm with Caching for Transaction Scheduling**
- **Implementation:** Uses a Genetic Algorithm with Order Crossover (OX1), shift mutation, and tournament selection, enhanced by a dictionary cache to memoize expensive fitness calculations.
- **Performance:** Achieved a combined score of 2.23, successfully optimizing makespans across complex and simple workloads.
- **Feedback:** The caching mechanism effectively reduces computational overhead, while the specific crossover and mutation strategies maintain valid permutation structures for robust schedule optimization.
**Program Identifier:** Generation 2 - Patch Name genetic_txn_scheduler - Correct Program: True

**Program Name: Sampled Greedy Construction with Random Restarts**
- **Implementation**: The algorithm constructs schedules by iteratively appending the transaction that minimizes the current makespan from a random sample of 15 remaining candidates. This stochastic greedy process is repeated 10 times to identify the lowest cost sequence.
- **Performance**: It achieved a combined maximization score of 3.06 with correct validation across all workloads.
- **Feedback**: The sampling strategy significantly speeds up execution compared to exhaustive greedy search, balancing solution quality with runtime efficiency, though the limited sample size may miss the optimal local choice.
**Program Identifier:** Generation 3 - Patch Name implement_greedy_restarts - Correct Program: True

**Program Name: Hybrid Greedy LPT with Shift-Based Local Search**
- **Implementation**: The algorithm employs a multi-start greedy construction biased by transaction costs (LPT), followed by a hill-climbing local search that refines the schedule using random shift operations.
- **Performance**: It achieved a combined score of 3.06, correctly scheduling all 300 transactions across the workloads.
- **Feedback**: The use of cost-biased sampling during construction provides high-quality starting points, while the shift-based refinement effectively minimizes gaps in the schedule to optimize the total makespan.
**Program Identifier:** Generation 4 - Patch Name greedy_with_local_search - Correct Program: True

**Program Name: Beam Search with Diversity Constraints and Duration Tie-Breaking**
- **Implementation**: The solution implements a beam search with stochastic sampling (16 candidates) and a diversity mechanism (limiting parents to 3 children) to maintain varied search paths. It prioritizes candidates based on lowest current makespan, using a Longest Processing Time (LPT) heuristic as a secondary tie-breaker.
- **Performance**: The algorithm achieved a combined score of 3.44, successfully generating valid schedules across all three workloads.
- **Feedback**: The diversity constraint effectively prevents the beam from converging too early on local optima, while the duration-based tie-breaking improves schedule packing efficiency by placing expensive transactions earlier when costs are equal.
**Program Identifier:** Generation 5 - Patch Name beam_search_scheduler - Correct Program: True

**Program Name: Adaptive Greedy Construction with Hybrid Local Search**
- **Implementation**: Generates candidate schedules using a greedy strategy that samples high-cost transactions and switches to exhaustive search for the final 15 items, followed by refinement using random swap and shift operators.
- **Performance**: Achieved a combined score of 3.08, successfully minimizing total makespan across diverse transaction workloads.
- **Feedback**: The adaptive switch to exhaustive search for the schedule tail effectively prevents suboptimal gaps often left by greedy approaches, while the heuristic bias ensures "heavy" transactions are scheduled early to avoid bottlenecks.
**Program Identifier:** Generation 6 - Patch Name adaptive_greedy_hybrid_ls - Correct Program: True

**Program Name: Beam Search with Diversity and Local Refinement**
- **Implementation**: Implements beam search with diversity constraints to limit children per parent and random sampling, concluding with a local search pass of adjacent swaps.
- **Performance**: Achieved a combined score of 3.32 with valid schedules for all workloads.
- **Feedback**: The diversity mechanism effectively maintains population variety during the greedy construction, while the final swap pass offers a low-cost method to fix minor ordering inefficiencies.
**Program Identifier:** Generation 7 - Patch Name beam_search_with_local_refinement - Correct Program: True

**Program Name: Heuristic Beam Search with Diversity and Local Refinement**
- **Implementation**: This solution implements a Beam Search algorithm utilizing heuristic sampling (LPT/SPT) and diversity constraints to prune the search space, followed by a stochastic local search to refine the final schedule.
- **Performance**: The algorithm achieved a combined score of 3.24, demonstrating effective optimization of transaction schedules while maintaining efficient execution time.
- **Feedback**: The integration of heuristic sampling significantly reduces computational overhead by targeting likely high-quality candidates, while diversity constraints prevent the beam from converging prematurely. The final local search step proves valuable for escaping local optima inherent in the constructive phase.
**Program Identifier:** Generation 8 - Patch Name beam_search_plus_local_refine - Correct Program: True

**Program Name: Deduplicated Beam Search with Windowed Local Refinement**
- **Implementation**: The algorithm utilizes a beam search with random sampling and state deduplication based on remaining transaction sets to ensure path diversity, prioritizing longer transactions during tie-breaking. A post-processing windowed local search (size 4) iteratively swaps nearby transactions to refine the final schedule.
- **Performance**: The solution achieved a combined score of 3.39, successfully generating valid schedules with reasonable makespans.
- **Feedback**: The state deduplication strategy is highly effective for preventing the beam from converging on identical permutations, while the local swap refinement helps correct greedy ordering errors inherent to beam search.
**Program Identifier:** Generation 9 - Patch Name deduplicated_beam_search - Correct Program: True

**Program Name: Adaptive Greedy with Tail Search and Hybrid Local Search**
- **Implementation**: Constructs schedules using an adaptive greedy approach with heavy-item bias, tail-end exhaustive search, and duration-based tie-breaking, followed by local search using weighted shift and swap operators.
- **Performance**: Achieved a competitive combined score of 3.17, successfully passing all validation tests.
- **Feedback**: The combination of heuristic bias and exhaustive tail search effectively constructs high-quality initial solutions, while duration-based tie-breaking helps fill scheduling gaps before refinement.
**Program Identifier:** Generation 10 - Patch Name adaptive_greedy_tiebreak_swap - Correct Program: True

**Program Name: Deduplicated Beam Search with LPT Sampling and Local Refinement**
- **Implementation**: The algorithm employs beam search with state deduplication based on remaining transaction sets, utilizing a hybrid sampling strategy that prioritizes Longest Processing Time (LPT) candidates alongside random selection. A post-processing phase applies adjacent swaps to locally refine the best schedule found.
- **Performance**: Achieved a combined score of 3.41, demonstrating effective optimization of transaction ordering within limited execution time.
- **Feedback**: Deduplication logic is highly effective here, preventing the beam from saturating with permutations of the same task subset. The hybrid sampling strategy successfully balances greedy optimization (via LPT) with sufficient diversity to avoid local optima.
**Program Identifier:** Generation 11 - Patch Name deduplicated_lpt_beam_search - Correct Program: True

**Program Name: Weighted Greedy with Exhaustive Tail and Biased Local Search**
- **Implementation**: The algorithm combines duration-weighted greedy construction with an exhaustive search for the final 20 items and uses a shift-heavy local search to refine the schedule.
- **Performance**: Achieved a high combined score of 3.22, effectively minimizing total makespan across workloads.
- **Feedback**: The adaptive switch to exhaustive search for the sequence tail and the Longest Processing Time (LPT) tie-breaking strategy significantly enhanced packing efficiency.
**Program Identifier:** Generation 12 - Patch Name weighted_greedy_lpt_search - Correct Program: True

**Program Name: Hybrid Deduplicated Beam Search with Weighted Sampling**
- **Implementation**: Implements a beam search initialized with mixed LPT/random seeds, utilizing weighted sampling and state deduplication based on remaining transaction sets to prune redundant paths. The schedule is further improved via a multi-pass windowed insertion refinement phase.
- **Performance**: Achieved a strong combined score of 3.41, demonstrating effective makespan minimization.
- **Feedback**: The state deduplication strategy significantly improves search efficiency by preventing the beam from saturating with identical subsets, while the windowed insertion refinement successfully corrects local ordering inefficiencies left by the greedy construction.
**Program Identifier:** Generation 13 - Patch Name hybrid_dedup_beam - Correct Program: True

**Program Name: Adaptive Beam Search with Hybrid Sampling and Local Refinement**
- **Implementation**: Uses an adaptive beam width and hybrid sampling (prioritizing longest remaining transactions mixed with random selection) to construct schedules, utilizing state deduplication to prune redundant paths based on remaining transaction sets. A final windowed local search performs swaps to refine the ordering.
- **Performance**: Achieved a strong combined score of 3.36, indicating effective makespan minimization across all workloads.
- **Feedback**: The combination of LPT-driven sampling and state deduplication efficiently navigates the search space by targeting critical path transactions early, while the adaptive beam width and local search refinement successfully balance global exploration with local optimization.
**Program Identifier:** Generation 14 - Patch Name adaptive_dedup_beam_search - Correct Program: True

**Program Name: Deduplicated Beam Search with LPT Sampling and Local Search**
- **Implementation**: The algorithm uses beam search with state deduplication to discard redundant remaining sets, selecting next-step candidates via a mix of Longest Processing Time (LPT) heuristics and random sampling. A post-search local refinement phase applies adjacent swaps to optimize the final sequence.
- **Performance**: Achieved a combined score of 3.46, generating valid, optimized schedules across all workloads.
- **Feedback**: State deduplication is highly effective here, preventing the beam from filling with permutations of the same subset and ensuring diversity. The hybrid LPT/random sampling strategy successfully mitigates greedy traps while prioritizing bottleneck transactions.
**Program Identifier:** Generation 15 - Patch Name deduplicated_beam_search_with_lpt_sampling - Correct Program: True

**Program Name: Diverse Deduplicated Beam Search with Local Refinement**
- **Implementation**: Utilizes beam search with hybrid LPT/random sampling, state deduplication, and parent diversity constraints, followed by a windowed swap-based local search.
- **Performance**: Achieved a combined score of 3.48, effectively optimizing makespan across varying workload complexities.
- **Feedback**: The integration of state deduplication and diversity limits prevented beam stagnation, while the post-processing local search successfully corrected minor greedy sequencing errors.
**Program Identifier:** Generation 16 - Patch Name diverse_dedup_beam_search - Correct Program: True

**Program Name: Deduplicated Beam Search with Ends-Out Sampling and Local Search**
- **Implementation**: This approach employs beam search with state deduplication and an "ends-out" sampling strategy that explicitly selects the longest and shortest transactions during expansion, followed by adjacent swap and windowed insertion refinement.
- **Performance**: The algorithm achieved a strong combined score of 3.44, demonstrating effective optimization within the execution time limits.
- **Feedback**: The "ends-out" sampling effectively balances bottleneck management (LPT) with gap filling (SPT), while state deduplication significantly improves search efficiency by preventing the exploration of redundant subsets.
**Program Identifier:** Generation 17 - Patch Name ends_out_sampling_beam_search - Correct Program: True

**Program Name: Diverse Deduplicated Beam Search with Local Refinement**
- **Implementation**: Utilizes a beam search with state deduplication, parent diversity constraints, and hybrid LPT/random sampling, followed by a windowed swap local search for refinement.
- **Performance**: Achieved a strong combined score of 3.57, indicating highly effective makespan optimization.
- **Feedback**: The combination of state-based deduplication and diversity limits effectively maintained search breadth without exploding computational cost, while the local search resolved minor ordering inefficiencies.
**Program Identifier:** Generation 18 - Patch Name parallelism_heuristic_and_weighted_sampling - Correct Program: True

**Program Name: Stochastic Beam Search with LPT Sampling and Local Refinement**
- **Implementation**: Constructs schedules using beam search with duration-weighted sampling to favor long transactions and exhaustive tail search, followed by hill climbing using shift and swap operators.
- **Performance**: Achieved a combined score of 3.30, successfully optimizing makespan across all three workloads.
- **Feedback**: The weighted sampling effectively incorporates Longest-Processing-Time heuristics into the construction phase, while the subsequent local search refines the packing density of the final schedule.
**Program Identifier:** Generation 19 - Patch Name stochastic_beam_search_scheduler - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

Based on the analysis of the provided program evaluations and the source code of the current best program, here are the updated insights:

## Successful Algorithmic Patterns
- **Diverse Deduplicated Beam Search**: The combination of state deduplication (introduced in **Gen 9**, refined in **Gen 11, 13, 15**) and strict parent diversity constraints (**Gen 16, 18**) proved to be the most robust strategy, achieving the highest scores (3.48 - 3.57). This approach prevents the beam from converging on local optima by ensuring a mix of unique task subsets and diverse ancestry.
- **Hybrid LPT Anchoring**: The **Current Best Program (Gen 18)** explicitly selects the top 2 Longest Processing Time (LPT) transactions deterministically before filling the rest of the sample pool with weighted random choices. This "anchor" strategy ensures that bottleneck transactions are scheduled early while random sampling maintains exploration, outperforming pure weighted sampling approaches.
- **Windowed Local Refinement**: Post-processing the global search result with a localized swap strategy significantly boosted performance. **Gen 18** (Score 3.57) utilized a windowed swap (`WINDOW = 4`) to correct minor ordering inefficiencies that the beam search's "lookahead" missed, providing the final edge over similar beam search variants like **Gen 15** (Score 3.46).

## Ineffective Approaches
- **Greedy Construction with Tail Search**: Programs relying on greedy construction followed by exhaustive tail search (**Gen 10**, Score 3.17; **Gen 12**, Score 3.22) consistently underperformed compared to Beam Search. The evaluation confirms that structural errors made early in the greedy phase cannot be mitigated by optimizing the tail end of the schedule.
- **Unstructured Stochastic Search**: **Gen 19** (Score 3.30) demonstrated that Stochastic Beam Search without the strict structural controls of state deduplication and diversity constraints performs significantly worse than the structured counterparts. Randomness alone, even with heuristics, is less efficient than controlled diversity.
- **Over-Constrained Sampling**: While heuristics are beneficial, rigid sampling strategies like "Ends-Out" (selecting only longest/shortest) in **Gen 17** (Score 3.44) performed slightly worse than the flexible hybrid approach of **Gen 18**. Strictly limiting candidates to heuristic extremes appears to miss non-obvious optimization opportunities that a mix of LPT and random sampling can find.

## Implementation Insights
- **Parallelism-Aware Priority Heuristic**: The **Current Best Program (Gen 18)** utilizes a sophisticated priority tuple: `(new_cost - new_total_dur, -new_total_dur)`. By minimizing `cost - total_duration`, the algorithm explicitly rewards placements that increase parallelism (i.e., where the makespan grows significantly slower than the sum of added transaction durations), effectively targeting "free" slots in the schedule.
- **State Deduplication via Frozensets**: High-performing programs (**Gen 11-18**) implement efficient deduplication by storing `seen_states.add(frozenset(rem_list))`. This prevents the beam from wasting computational width on permutations that result in the exact same set of remaining transactions, maximizing the effective search space.
- **Parent Usage Tracking**: To enforce diversity, **Gen 18** maintains a `parent_usage` counter during the beam selection loop. It strictly enforces a `MAX_CHILDREN = 3` limit, rejecting otherwise high-scoring candidates if their parent node has already contributed too many paths to the next generation. This forces the algorithm to preserve suboptimal but distinct paths that may lead to better global solutions.

## Performance Analysis
- **Beam Search Dominance**: There is a clear performance stratification where Deduplicated Beam Search variants (**Gen 11, 13, 15, 16, 18**, scores > 3.40) consistently outperform Greedy/Hybrid approaches (**Gen 10, 12**, scores ~3.20). The "lookahead" capability combined with deduplication is the decisive factor for this problem.
- **Impact of Refinement and Diversity**: The progression from **Gen 15** (3.46) to **Gen 18** (3.57) highlights the compounding value of diversity and refinement. While the core Beam Search is strong, adding explicit parent diversity constraints and a final local search pass yielded a ~3% performance gain, which is significant at this optimization level.
- **Deduplication vs. Multi-Start**: Comparing the best Beam Search (**Gen 18**, 3.57) to earlier Multi-Start Greedy approaches (scores ~3.06), it is evident that intelligently managing the search frontier via deduplication is far more computationally efficient than simply restarting the search multiple times.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

Based on the analysis of the current best program (Gen 18) and the global insights, here are 5 actionable recommendations for future program mutations:

1.  **Implement Conflict-Aware Prioritization**
    While Gen 18 successfully uses transaction duration as a proxy for complexity, it ignores specific read/write contentions. You should precompute a "conflict degree" for each transaction (the count of other transactions it overlaps with) and update the priority tuple to `(score, -conflict_degree, -total_dur)`. This prioritizes scheduling high-contention tasks early, clearing bottlenecks that duration alone does not capture.

2.  **Adopt Tapered Beam Width Allocation**
    Constructive heuristics are most sensitive to decisions made in the first 25% of the schedule. You should implement a dynamic `BEAM_WIDTH` that starts at roughly **2x the average width** and linearly decays to **0.5x** by the end of the sequence. This reallocates the fixed computational budget to the initial phase where structural choices have the largest impact on the final makespan.

3.  **Enhance Refinement with Insertion Moves**
    Gen 18 achieved a significant boost using windowed swaps. You should extend the `Local Search Refinement` phase to include **"Shift/Insert" operations**: iterate through the schedule, temporarily remove a transaction, and test re-inserting it at best positions within a local window (e.g., `Â±5` indices). This handles dependency constraints better than swaps, which can get stuck in local optima when transactions are tightly packed.

4.  **Ensemble Heuristic Search Strategy**
    Gen 18 relies on a single heuristic logic (`cost - duration`). You should split the available `num_seqs` budget to run **two distinct, narrower beam searches** in parallel: one using the current LPT-focused logic and another prioritizing connectivity (e.g., `cost - conflict_degree`). Returning the best result from these parallel distinct strategies creates a robust portfolio approach that works across varied workload types.

5.  **Stochastic One-Step Lookahead**
    The current "greedy" beam expansion only evaluates the immediate cost. You should implement a **stochastic lookahead** for the top candidates: before finalizing the score, tentatively add one valid random or LPT transaction from the remaining set and use the *resulting* projected cost for ranking. This slight increase in evaluation depth helps avoid "traps" where a seemingly good move immediately blocks all optimal future moves.