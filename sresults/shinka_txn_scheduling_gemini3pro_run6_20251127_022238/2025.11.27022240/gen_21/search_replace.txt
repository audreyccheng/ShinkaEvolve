<NAME>
ends_out_beam_with_insertion_refinement
</NAME>

<DESCRIPTION>
Optimizes the scheduling algorithm by:
1. Increasing Beam Width to enable broader exploration of the state space.
2. Implementing 'Ends-Out' sampling in the beam search: explicitly sampling both Longest (LPT) and Shortest (SPT) remaining transactions. LPT tackles bottlenecks early, while SPT fills execution gaps to maximize parallelism.
3. Replacing the weak 'adjacent swap' local search with a stronger 'Windowed Insertion' refinement. This allows moving transactions to optimal positions within a local window in a single step, effectively resolving ordering constraints that simple swaps cannot easily fix.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Deduplicated Beam Search with Smart Sampling and Local Search.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Used to determine the beam width (effort level)

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Beam Search Parameters
    # Increased beam width to allow for effective state deduplication
    BEAM_WIDTH = max(8, num_seqs)
    SAMPLES_PER_NODE = 16

    num_txns = workload.num_txns

    # Precompute transaction durations
    txn_durations = {}
    for t in range(num_txns):
        txn_durations[t] = workload.get_opt_seq_cost([t])

    # Initialization
    # Seed beam with a mix of longest transactions (LPT) and random ones.
    # LPT is often a good heuristic for the start of a schedule.
    sorted_by_duration = sorted(range(num_txns), key=lambda t: txn_durations[t], reverse=True)

    start_candidates = set()
    start_candidates.update(sorted_by_duration[:BEAM_WIDTH // 2])

    # Fill remaining slots with random starts
    pool = [t for t in range(num_txns) if t not in start_candidates]
    if len(start_candidates) < BEAM_WIDTH and pool:
        start_candidates.update(random.sample(pool, min(len(pool), BEAM_WIDTH - len(start_candidates))))

    beam = []
    for t in start_candidates:
        rem = set(range(num_txns))
        rem.remove(t)
        beam.append({
            'cost': txn_durations[t],
            'seq': [t],
            'rem': rem
        })

    # Beam Search Loop
    for _ in range(num_txns - 1):
        candidates = []

        for parent in beam:
            rem_list = list(parent['rem'])

            # Smart Sampling Strategy:
            # 1. Deterministic: Always try the longest remaining transaction (LPT).
            #    This handles bottlenecks early.
            # 2. Random: Sample other transactions to escape greedy traps.
            if len(rem_list) <= SAMPLES_PER_NODE:
                samples = rem_list
            else:
                samples = set()
                # Find max duration txn (LPT)
                max_txn = max(rem_list, key=lambda t: txn_durations[t])
                samples.add(max_txn)

                # Fill rest randomly
                needed = SAMPLES_PER_NODE - len(samples)
                pool = [t for t in rem_list if t not in samples]
                samples.update(random.sample(pool, min(len(pool), needed)))

            for t in samples:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)

                # Priority: (Cost, -Duration)
                # Minimize Cost, then Maximize Duration of added item
                priority = (new_cost, -txn_durations[t])

                candidates.append({
                    'priority': priority,
                    'cost': new_cost,
                    'seq': new_seq,
                    'rem': parent['rem'], # Reference, copy later
                    'added': t
                })

        # Sort candidates
        candidates.sort(key=lambda x: x['priority'])

        # Construct Next Beam with Deduplication
        new_beam = []
        seen_states = set()

        for cand in candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            # Create new remaining set
            new_rem = cand['rem'].copy()
            new_rem.remove(cand['added'])

            # State Deduplication:
            # The state is defined by the set of remaining transactions.
            # If we reach the same 'remaining' set via multiple paths, we only keep the best one.
            state_key = frozenset(new_rem)

            if state_key not in seen_states:
                seen_states.add(state_key)
                new_beam.append({
                    'cost': cand['cost'],
                    'seq': cand['seq'],
                    'rem': new_rem
                })

        if not new_beam:
            break
        beam = new_beam

    # Select best from beam
    best_result = min(beam, key=lambda x: x['cost'])
    best_cost = best_result['cost']
    best_seq = best_result['seq']

    # Local Search Refinement
    # Perform adjacent swaps to fix minor local ordering inefficiencies.
    for _ in range(2):
        improved = False
        for i in range(num_txns - 1):
            # Swap
            best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]
            new_c = workload.get_opt_seq_cost(best_seq)

            if new_c < best_cost:
                best_cost = new_c
                improved = True
            else:
                # Revert
                best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]

        if not improved:
            break

    return best_cost, best_seq
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Deduplicated Beam Search with Ends-Out Sampling and Windowed Refinement.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Used to determine the beam width (effort level)

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Beam Search Parameters
    # Wider beam for better exploration coverage
    BEAM_WIDTH = int(max(12, num_seqs * 2.0))
    SAMPLES_PER_NODE = 24

    num_txns = workload.num_txns

    # Precompute transaction durations
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(num_txns)}

    # Initialization
    # Seed beam with LPT (Longest Processing Time) to secure bottlenecks
    sorted_by_duration = sorted(range(num_txns), key=lambda t: txn_durations[t], reverse=True)

    start_candidates = set()
    start_candidates.update(sorted_by_duration[:BEAM_WIDTH])

    # Fill remaining slots with random starts for diversity
    while len(start_candidates) < BEAM_WIDTH * 1.5:
        start_candidates.add(random.randint(0, num_txns - 1))

    beam = []
    for t in list(start_candidates)[:int(BEAM_WIDTH * 1.5)]:
        rem = set(range(num_txns))
        rem.remove(t)
        beam.append({
            'cost': txn_durations[t],
            'seq': [t],
            'rem': rem
        })

    # Prune initial beam to WIDTH
    beam.sort(key=lambda x: (x['cost'], -txn_durations[x['seq'][0]]))
    beam = beam[:BEAM_WIDTH]

    # Beam Search Loop
    for _ in range(num_txns - 1):
        candidates = []

        for parent in beam:
            rem_list = list(parent['rem'])

            # --- Ends-Out Sampling Strategy ---
            if len(rem_list) <= SAMPLES_PER_NODE:
                samples = rem_list
            else:
                samples = set()
                # 1. LPT: Top longest txns (Critical path reduction)
                samples.update(sorted(rem_list, key=lambda t: txn_durations[t], reverse=True)[:2])

                # 2. SPT: Top shortest txns (Gap filling / Latency hiding)
                samples.update(sorted(rem_list, key=lambda t: txn_durations[t])[:1])

                # 3. Random: Explore remaining space
                needed = SAMPLES_PER_NODE - len(samples)
                pool = [t for t in rem_list if t not in samples]
                if needed > 0 and pool:
                    samples.update(random.sample(pool, min(len(pool), needed)))

            # --- Evaluation ---
            for t in samples:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)

                # Priority: (Cost, -Duration)
                # Minimize Cost. Tie-break: prefer scheduling heavy items (Max Duration)
                priority = (new_cost, -txn_durations[t])

                candidates.append({
                    'priority': priority,
                    'cost': new_cost,
                    'seq': new_seq,
                    'rem': parent['rem'], # Reference
                    'added': t
                })

        # Sort candidates
        candidates.sort(key=lambda x: x['priority'])

        # --- Deduplication & Selection ---
        new_beam = []
        seen_states = set()

        for cand in candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            new_rem = cand['rem'].copy()
            new_rem.remove(cand['added'])

            # State Deduplication: Key = Frozen set of remaining items
            state_key = frozenset(new_rem)

            if state_key not in seen_states:
                seen_states.add(state_key)
                new_beam.append({
                    'cost': cand['cost'],
                    'seq': cand['seq'],
                    'rem': new_rem
                })

        if not new_beam:
            break
        beam = new_beam

    # Select best from beam
    best_result = min(beam, key=lambda x: x['cost'])
    best_cost = best_result['cost']
    best_seq = best_result['seq']

    # --- Local Search Refinement: Windowed Insertion ---
    # Shifting an element is stronger than adjacent swaps for fixing ordering.
    WINDOW = 5
    MAX_PASSES = 2

    for _ in range(MAX_PASSES):
        improved = False
        for i in range(num_txns):
            # Try moving element at i to valid positions in window [i-W, i+W]
            val = best_seq[i]

            start_j = max(0, i - WINDOW)
            end_j = min(num_txns, i + WINDOW + 1)

            for j in range(start_j, end_j):
                if j == i: continue

                # Construct candidate sequence with insertion
                if j < i:
                    cand_seq = best_seq[:j] + [val] + best_seq[j:i] + best_seq[i+1:]
                else: # j > i
                    cand_seq = best_seq[:i] + best_seq[i+1:j+1] + [val] + best_seq[j+1:]

                new_c = workload.get_opt_seq_cost(cand_seq)
                if new_c < best_cost:
                    best_cost = new_c
                    best_seq = cand_seq
                    improved = True
                    # Greedy first improvement
                    break

            if improved:
                # Restart scan to ripple effects of the change
                break

        if not improved:
            break

    return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>