<NAME>
beam_search_with_local_refinement
</NAME>

<DESCRIPTION>
Replaces the random greedy sampling with a structured Beam Search algorithm. Beam search explores multiple promising schedule paths in parallel, maintaining a 'beam' of the best partial schedules found so far. This avoids getting trapped in local optima early in the sequence construction.
Additionally, includes a post-processing Local Search step that attempts adjacent swaps on the best found schedule to further reduce the makespan. This hybrid approach leverages the global exploration of beam search and the local refinement of hill climbing.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using greedy cost sampling strategy.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    best_cost = float('inf')
    best_schedule = []

    def get_greedy_cost_sampled(num_samples):
        # greedy with random starting point
        start_txn = random.randint(0, workload.num_txns - 1)
        txn_seq = [start_txn]
        remaining_txns = list(range(workload.num_txns))
        remaining_txns.remove(start_txn)

        for i in range(workload.num_txns - 1):
            min_cost = float('inf')
            min_txn = -1
            holdout_txns = []

            # Determine how many samples to check
            # Check up to num_samples, but not more than available
            current_samples = min(num_samples, len(remaining_txns))

            # Sample candidates
            for _ in range(current_samples):
                # Pick a random candidate from remaining
                idx = random.randint(0, len(remaining_txns) - 1)
                t = remaining_txns[idx]

                # Move from remaining to holdout so we don't pick it again this step
                remaining_txns.pop(idx)
                holdout_txns.append(t)

                # Evaluate cost
                test_seq = txn_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)

                if cost < min_cost:
                    min_cost = cost
                    min_txn = t

            # Select the best candidate found
            if min_txn != -1:
                txn_seq.append(min_txn)
                holdout_txns.remove(min_txn)

            remaining_txns.extend(holdout_txns)

        overall_cost = workload.get_opt_seq_cost(txn_seq)
        return overall_cost, txn_seq

    # Run multiple sequences and pick the best one
    for _ in range(num_seqs):
        cost, schedule = get_greedy_cost_sampled(15)
        if cost < best_cost:
            best_cost = cost
            best_schedule = schedule

    return best_cost, best_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Beam Search with diversity and local refinement.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Used to scale the beam width

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # Beam Search configuration
    BEAM_WIDTH = max(5, num_seqs)  # Width of the beam
    SAMPLES_PER_NODE = 16          # Candidates to evaluate per parent node
    MAX_CHILDREN = 3               # Max extensions from one parent (diversity)

    num_txns = workload.num_txns

    # Pre-calculate individual costs for tie-breaking
    # Longer transactions are preferred when costs are equal to fill schedule holes
    txn_costs = {t: workload.get_opt_seq_cost([t]) for t in range(num_txns)}

    # Initialize Beam with a mix of random starts
    start_candidates = list(range(num_txns))
    random.shuffle(start_candidates)

    beam = []
    # Seed beam with single transactions
    for t in start_candidates[:min(len(start_candidates), BEAM_WIDTH * 2)]:
        beam.append({
            'cost': txn_costs[t],
            'seq': [t],
            'rem': set(range(num_txns)) - {t}
        })

    # Sort and trim to initial width
    beam.sort(key=lambda x: x['cost'])
    beam = beam[:BEAM_WIDTH]

    # Beam Search Main Loop
    for _ in range(num_txns - 1):
        candidates = []

        for p_idx, parent in enumerate(beam):
            rem_list = list(parent['rem'])

            # Sample next transactions
            if len(rem_list) <= SAMPLES_PER_NODE:
                samples = rem_list
            else:
                samples = random.sample(rem_list, SAMPLES_PER_NODE)

            for t in samples:
                new_seq = parent['seq'] + [t]
                new_cost = workload.get_opt_seq_cost(new_seq)

                # Priority: Minimize Cost, then Maximize individual Txn Duration
                candidates.append({
                    'priority': (new_cost, -txn_costs[t]),
                    'cost': new_cost,
                    'seq': new_seq,
                    'added': t,
                    'p_idx': p_idx
                })

        # Select best candidates preserving diversity
        candidates.sort(key=lambda x: x['priority'])

        new_beam = []
        parent_usage = {i: 0 for i in range(len(beam))}
        reserve = []

        for cand in candidates:
            if len(new_beam) >= BEAM_WIDTH:
                break

            p_idx = cand['p_idx']
            if parent_usage[p_idx] < MAX_CHILDREN:
                # Add to beam
                new_rem = beam[p_idx]['rem'].copy()
                new_rem.remove(cand['added'])
                new_beam.append({'cost': cand['cost'], 'seq': cand['seq'], 'rem': new_rem})
                parent_usage[p_idx] += 1
            else:
                reserve.append(cand)

        # Fill remaining spots from reserve if needed
        if len(new_beam) < BEAM_WIDTH:
            for cand in reserve:
                if len(new_beam) >= BEAM_WIDTH:
                    break
                p_idx = cand['p_idx']
                # Check if this parent+child combo is not already implicitly handled
                # (Logic ensures unique sequences as we extend unique parents with unique children)
                new_rem = beam[p_idx]['rem'].copy()
                new_rem.remove(cand['added'])
                new_beam.append({'cost': cand['cost'], 'seq': cand['seq'], 'rem': new_rem})

        if not new_beam:
            break
        beam = new_beam

    # Get best result from beam
    best_result = min(beam, key=lambda x: x['cost'])
    best_cost = best_result['cost']
    best_seq = best_result['seq']

    # Local Search Refinement
    # Attempt one pass of adjacent swaps to see if we can improve
    # This catches cases where two transactions were ordered sub-optimally in the greedy phase
    for i in range(num_txns - 1):
        # Create swap candidate
        swap_seq = best_seq[:]
        swap_seq[i], swap_seq[i+1] = swap_seq[i+1], swap_seq[i]

        # Check cost
        new_c = workload.get_opt_seq_cost(swap_seq)
        if new_c < best_cost:
            best_cost = new_c
            best_seq = swap_seq
            # We greedily accept the first improvement to save time and continue scanning
            # (In a full hill-climber we might loop until no improvements, but time is constrained)

    return best_cost, best_seq
>>>>>>> REPLACE

</DIFF>