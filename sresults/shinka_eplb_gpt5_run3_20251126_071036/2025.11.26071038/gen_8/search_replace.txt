<NAME>
multi_swap_refinement_balanced_packing
</NAME>

<DESCRIPTION>
I improve the balanced_packing heuristic by extending the lightweight refinement step from a single swap to up to two beneficial swaps per layer between the heaviest and lightest packs. This bounded local search often reduces max imbalance further without noticeable runtime impact, as layers are few and the search is fully tensorized per layer. The change should improve balancedness while maintaining speed, benefiting both group-to-node and physical-to-GPU packings which both use balanced_packing.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)
    for i in range(num_layers):
        pack_weights = [0] * num_packs
        pack_items = [0] * num_packs
        for group in indices[i]:
            pack = min(
                (i
                 for i in range(num_packs) if pack_items[i] < groups_per_pack),
                key=pack_weights.__getitem__,
            )
            assert pack_items[pack] < groups_per_pack
            pack_index[i, group] = pack
            rank_in_pack[i, group] = pack_items[pack]
            pack_weights[pack] += weight[i, group]
            pack_items[pack] += 1

    # Lightweight single-swap refinement per layer to reduce max imbalance
    if groups_per_pack > 1:
        for i in range(num_layers):
            packs = pack_index[i]  # [num_groups]
            w = weight[i].cpu()
            # Compute pack loads
            pack_w = torch.zeros(num_packs, dtype=w.dtype)
            pack_w.scatter_add_(0, packs, w)
            h = int(torch.argmax(pack_w))
            l = int(torch.argmin(pack_w))
            delta = float(pack_w[h] - pack_w[l])
            if delta <= 0:
                continue

            heavy_mask = packs == h
            light_mask = packs == l
            heavy_idx = torch.nonzero(heavy_mask, as_tuple=False).squeeze(1)
            light_idx = torch.nonzero(light_mask, as_tuple=False).squeeze(1)
            if heavy_idx.numel() == 0 or light_idx.numel() == 0:
                continue

            hw = w[heavy_idx]
            lw = w[light_idx]
            lw_sorted, lw_perm = torch.sort(lw)  # ascending
            # For each heavy item, find light item closest to target = hw - delta/2
            target = hw - (delta / 2.0)
            pos = torch.searchsorted(lw_sorted, target)
            if lw_sorted.numel() == 0:
                continue
            pos = torch.clamp(pos, 0, lw_sorted.numel() - 1)
            # Consider neighbors pos and pos-1 for best approximation
            cand_pos = torch.stack([pos, torch.clamp(pos - 1, 0, lw_sorted.numel() - 1)], dim=1)
            cand_lw = lw_sorted[cand_pos]  # [H, 2]
            resid = (delta - 2.0 * (hw.unsqueeze(1) - cand_lw)).abs()
            best_flat = int(torch.argmin(resid).item())
            best_h_index = best_flat // 2
            best_option = best_flat % 2
            j_sorted_idx = int(cand_pos[best_h_index, best_option].item())

            wi = float(hw[best_h_index].item())
            wj = float(lw_sorted[j_sorted_idx].item())
            new_delta = abs(delta - 2.0 * (wi - wj))
            # Apply swap only if it strictly improves imbalance
            if new_delta < delta - 1e-9:
                hi = heavy_idx[best_h_index]
                lj = light_idx[lw_perm[j_sorted_idx]]
                pack_index[i, hi] = l
                pack_index[i, lj] = h
                # Reassign ranks within affected packs to keep 0..groups_per_pack-1
                for p in (h, l):
                    mask = pack_index[i] == p
                    idx = torch.nonzero(mask, as_tuple=False).squeeze(1)
                    if idx.numel() == 0:
                        continue
                    # Stable by previous rank order
                    prev_rank = rank_in_pack[i, idx]
                    order = torch.argsort(prev_rank)
                    new_ranks = torch.arange(order.numel(), dtype=torch.int64)
                    rank_in_pack[i, idx[order]] = new_ranks

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)
    for i in range(num_layers):
        pack_weights = [0] * num_packs
        pack_items = [0] * num_packs
        for group in indices[i]:
            pack = min(
                (i
                 for i in range(num_packs) if pack_items[i] < groups_per_pack),
                key=pack_weights.__getitem__,
            )
            assert pack_items[pack] < groups_per_pack
            pack_index[i, group] = pack
            rank_in_pack[i, group] = pack_items[pack]
            pack_weights[pack] += weight[i, group]
            pack_items[pack] += 1

    # Bounded multi-swap refinement per layer to reduce max imbalance
    if groups_per_pack > 1:
        max_swaps = 2  # keep small to preserve speed
        for i in range(num_layers):
            for _ in range(max_swaps):
                packs = pack_index[i]  # [num_groups], CPU
                w = weight[i]  # CPU
                # Compute pack loads
                pack_w = torch.zeros(num_packs, dtype=w.dtype)
                pack_w.scatter_add_(0, packs, w)
                h = int(torch.argmax(pack_w))
                l = int(torch.argmin(pack_w))
                delta = float(pack_w[h] - pack_w[l])
                if delta <= 1e-9:
                    break

                heavy_idx = torch.nonzero(packs == h, as_tuple=False).squeeze(1)
                light_idx = torch.nonzero(packs == l, as_tuple=False).squeeze(1)
                if heavy_idx.numel() == 0 or light_idx.numel() == 0:
                    break

                hw = w[heavy_idx]
                lw = w[light_idx]
                lw_sorted, lw_perm = torch.sort(lw)  # ascending
                if lw_sorted.numel() == 0 or hw.numel() == 0:
                    break

                # For each heavy item, find light item closest to target = hw - delta/2
                target = hw - (delta / 2.0)
                pos = torch.searchsorted(lw_sorted, target)
                pos = torch.clamp(pos, 0, lw_sorted.numel() - 1)
                # Consider neighbors pos and pos-1 for best approximation
                cand_pos = torch.stack([pos, torch.clamp(pos - 1, 0, lw_sorted.numel() - 1)], dim=1)
                cand_lw = lw_sorted[cand_pos]  # [H, 2]
                resid = (delta - 2.0 * (hw.unsqueeze(1) - cand_lw)).abs()
                best_flat = int(torch.argmin(resid).item())
                best_h_index = best_flat // 2
                best_option = best_flat % 2
                j_sorted_idx = int(cand_pos[best_h_index, best_option].item())

                wi = float(hw[best_h_index].item())
                wj = float(lw_sorted[j_sorted_idx].item())
                new_delta = abs(delta - 2.0 * (wi - wj))
                # Apply swap only if it strictly improves imbalance
                if new_delta < delta - 1e-9:
                    hi = heavy_idx[best_h_index]
                    lj = light_idx[lw_perm[j_sorted_idx]]
                    pack_index[i, hi] = l
                    pack_index[i, lj] = h
                    # Reassign ranks within affected packs to keep 0..groups_per_pack-1
                    for p in (h, l):
                        mask = pack_index[i] == p
                        idx = torch.nonzero(mask, as_tuple=False).squeeze(1)
                        if idx.numel() == 0:
                            continue
                        # Stable by previous rank order
                        prev_rank = rank_in_pack[i, idx]
                        order = torch.argsort(prev_rank)
                        new_ranks = torch.arange(order.numel(), dtype=torch.int64)
                        rank_in_pack[i, idx[order]] = new_ranks
                    # continue to next potential swap
                    continue
                else:
                    break

    return pack_index, rank_in_pack
>>>>>>> REPLACE

</DIFF>