<NAME>
top2_replica_fix_and_tieaware_pack
</NAME>

<DESCRIPTION>
Two targeted improvements:
1) Strengthen the replication fix-up after water-filling by evaluating all donor→receiver moves among top-2 donors (by average load, with donor count > 1) and bottom-2 receivers. Apply the single move that strictly reduces the peak average load. This keeps O(1) per-row overhead and often lowers the worst-replica load.
2) In GPU packing, change the greedy choice to minimize projected load (current load + item weight), and use a diversity penalty only under near-ties (epsilon-scaled by mean row weight). This preserves main load balancing while still spreading same-label replicas when it doesn’t hurt balance. Speed remains effectively unchanged due to simple per-item arithmetic and small candidate loops.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # Greedy assignment with diversity-aware tie-breaking
        for g in sorted_idx:
            lab = int(row_labels[g].item())
            wv = float(row_w[g].item())

            best_p = None
            best_key = None
            for p in range(num_packs):
                if counts[p] >= cap:
                    continue
                rep = label_counts[p].get(lab, 0)
                key = (rep, loads[p], counts[p])
                if best_key is None or key < best_key:
                    best_key = key
                    best_p = p

            pack_index[i, g] = best_p
            rank_in_pack[i, g] = counts[best_p]
            counts[best_p] += 1
            loads[best_p] += wv
            label_counts[best_p][lab] += 1
            pack_groups[best_p].append(g)
=======
        # Greedy assignment with projected-load objective and near-tie diversity
        eps = 1e-6 * float(row_w.mean().item() if row_w.numel() > 0 else 1.0)
        for g in sorted_idx:
            lab = int(row_labels[g].item())
            wv = float(row_w[g].item())

            best_p = None
            best_base = None
            best_rep = None
            best_cnt = None
            for p in range(num_packs):
                if counts[p] >= cap:
                    continue
                base = loads[p] + wv  # projected load if we place g in p
                rep = label_counts[p].get(lab, 0)

                if best_p is None:
                    best_p = p
                    best_base = base
                    best_rep = rep
                    best_cnt = counts[p]
                    continue

                # Prefer smaller projected load; if near-tie within eps, prefer fewer repeats, then fewer items
                if base + eps < best_base:
                    best_p = p
                    best_base = base
                    best_rep = rep
                    best_cnt = counts[p]
                elif abs(base - best_base) <= eps:
                    if rep < best_rep or (rep == best_rep and counts[p] < best_cnt):
                        best_p = p
                        best_base = base
                        best_rep = rep
                        best_cnt = counts[p]

            pack_index[i, g] = best_p
            rank_in_pack[i, g] = counts[best_p]
            counts[best_p] += 1
            loads[best_p] += wv
            label_counts[best_p][lab] += 1
            pack_groups[best_p].append(g)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        # One-step replication fix-up: move 1 replica from donor (max avg) to
        # receiver (min avg) iff it strictly reduces the max average load.
        if num_log > 1:
            counts_safe = torch.clamp(counts, min=1)
            avg = w / counts_safe.to(w.dtype)
            donor = int(torch.argmax(avg).item())
            receiver = int(torch.argmin(avg).item())
            if donor != receiver and counts[donor] > 1:
                counts_try = counts.clone()
                counts_try[donor] -= 1
                counts_try[receiver] += 1
                avg_new = w / counts_try.to(w.dtype)
                if float(avg_new.max().item()) + 1e-9 < float(avg.max().item()):
                    counts = counts_try  # accept improvement
=======
        # Strengthened one-step fix-up: choose best move among top-2 donors and bottom-2 receivers
        if num_log > 1:
            counts_safe = torch.clamp(counts, min=1)
            avg = w / counts_safe.to(w.dtype)
            cur_max = float(avg.max().item())

            # Donors: top-k by avg with count > 1
            can_donate = (counts > 1)
            k_d = int(min(2, int(can_donate.sum().item())))
            donors = []
            if k_d > 0:
                avg_mask = avg.clone()
                avg_mask[~can_donate] = float("-inf")
                donors = torch.topk(avg_mask, k=k_d).indices.tolist()

            # Receivers: bottom-k by avg (all eligible)
            k_r = int(min(2, num_log))
            receivers = torch.topk(-avg, k=k_r).indices.tolist() if k_r > 0 else []

            best_pair = None
            best_peak = cur_max
            for d in donors:
                for r in receivers:
                    if d == r:
                        continue
                    c_try = counts.clone()
                    c_try[d] -= 1
                    c_try[r] += 1
                    avg_try = w / c_try.to(w.dtype)
                    peak = float(avg_try.max().item())
                    if peak + 1e-9 < best_peak:
                        best_peak = peak
                        best_pair = (d, r)

            if best_pair is not None:
                d, r = best_pair
                counts[d] -= 1
                counts[r] += 1
>>>>>>> REPLACE

</DIFF>