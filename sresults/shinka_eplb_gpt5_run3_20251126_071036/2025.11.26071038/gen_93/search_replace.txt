<NAME>
group_packing_refine_1x1
</NAME>

<DESCRIPTION>
Improve the groupsâ†’nodes packing by adding a tiny bounded refinement step to the balanced_packing function. After the initial LPT greedy assignment, we evaluate at most a few 1x1 swaps between the heaviest and lightest packs (also considering the second heaviest/lightest) and apply one if it strictly reduces the global maximum load. This mirrors the proven micro-refinement used at the GPU layer but without label complexity. The refinement depth is adaptive to residual imbalance with early exit, preserving speed while improving peak smoothing across nodes, which should increase balancedness.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, num_groups)
        rank_in_pack = torch.zeros_like(pack_index, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Longest-processing-time greedy with capacity constraints
    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full((num_layers, num_groups),
                             fill_value=-1,
                             dtype=torch.int64,
                             device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)
    for i in range(num_layers):
        pack_loads = [0.0] * num_packs
        pack_counts = [0] * num_packs
        for g in indices[i].tolist():
            # choose pack with capacity and minimal load; tie-break by fewer items
            best_p = None
            best_load = None
            best_cnt = None
            for p in range(num_packs):
                if pack_counts[p] >= groups_per_pack:
                    continue
                if (best_load is None or pack_loads[p] < best_load or
                    (abs(pack_loads[p] - (best_load if best_load is not None else 0.0)) <= 1e-12 and
                     (best_cnt is None or pack_counts[p] < best_cnt))):
                    best_p = p
                    best_load = pack_loads[p]
                    best_cnt = pack_counts[p]
            pack_index[i, g] = best_p
            rank_in_pack[i, g] = pack_counts[best_p]
            pack_counts[best_p] += 1
            pack_loads[best_p] += float(weight[i, g].item())
    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(num_groups,
                                  dtype=torch.int64,
                                  device=weight.device).expand(num_layers, num_groups)
        rank_in_pack = torch.zeros_like(pack_index, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Longest-processing-time greedy with capacity constraints
    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full((num_layers, num_groups),
                             fill_value=-1,
                             dtype=torch.int64,
                             device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)
    for i in range(num_layers):
        pack_loads = [0.0] * num_packs
        pack_counts = [0] * num_packs
        pack_groups = [[] for _ in range(num_packs)]
        row_w = weight[i]
        for g in indices[i].tolist():
            # choose pack with capacity and minimal load; tie-break by fewer items
            best_p = None
            best_load = None
            best_cnt = None
            for p in range(num_packs):
                if pack_counts[p] >= groups_per_pack:
                    continue
                if (best_load is None or pack_loads[p] < best_load or
                    (abs(pack_loads[p] - (best_load if best_load is not None else 0.0)) <= 1e-12 and
                     (best_cnt is None or pack_counts[p] < best_cnt))):
                    best_p = p
                    best_load = pack_loads[p]
                    best_cnt = pack_counts[p]
            pack_index[i, g] = best_p
            rank_in_pack[i, g] = pack_counts[best_p]
            pack_counts[best_p] += 1
            pack_loads[best_p] += float(row_w[g].item())
            pack_groups[best_p].append(g)

        # Tiny bounded refinement (1x1) for peak smoothing across packs
        if num_packs >= 2 and groups_per_pack > 1:
            def _refine_once() -> bool:
                order_asc = sorted(range(num_packs), key=lambda p: pack_loads[p])
                order_desc = list(reversed(order_asc))
                h1 = order_desc[0]
                l1 = order_asc[0] if order_asc[0] != h1 else (order_asc[1] if len(order_asc) > 1 else order_asc[0])
                pairs = [(h1, l1)]
                if len(order_asc) >= 3:
                    l2 = next(p for p in order_asc if p != h1 and p != l1)
                    pairs.append((h1, l2))
                if len(order_desc) >= 3:
                    h2 = next(p for p in order_desc if p != h1)
                    pairs.append((h2, l1))

                cur_max = max(pack_loads)
                best = None  # (new_peak, new_imb, d, r, ai, bi, a_item, b_item, wa, wb)
                for (d, r) in pairs:
                    if d == r:
                        continue
                    if not pack_groups[d] or not pack_groups[r]:
                        continue
                    if pack_loads[d] <= pack_loads[r]:
                        continue
                    d_idx_tensor = torch.tensor(pack_groups[d], dtype=torch.int64, device=row_w.device)
                    r_idx_tensor = torch.tensor(pack_groups[r], dtype=torch.int64, device=row_w.device)
                    d_w = row_w[d_idx_tensor]
                    r_w = row_w[r_idx_tensor]
                    kd = min(2, d_w.numel())
                    kr = min(2, r_w.numel())
                    if kd == 0 or kr == 0:
                        continue
                    d_top = torch.topk(d_w, kd).indices.tolist()
                    r_bot = torch.topk(r_w, kr, largest=False).indices.tolist()

                    other_max = max([pack_loads[p] for p in range(num_packs) if p != d and p != r], default=float("-inf"))
                    other_min = min([pack_loads[p] for p in range(num_packs) if p != d and p != r], default=float("inf"))

                    for ai in d_top:
                        wa = float(d_w[ai].item())
                        a_item = int(d_idx_tensor[ai].item())
                        for bi in r_bot:
                            wb = float(r_w[bi].item())
                            b_item = int(r_idx_tensor[bi].item())
                            new_d = pack_loads[d] - wa + wb
                            new_r = pack_loads[r] - wb + wa
                            new_peak = max(new_d, new_r, other_max)
                            new_bottom = min(new_d, new_r, other_min)
                            new_imb = new_peak - new_bottom
                            cand = (new_peak, new_imb, d, r, ai, bi, a_item, b_item, wa, wb)
                            if best is None or (cand[0] + 1e-9 < best[0] or
                                                (abs(cand[0] - best[0]) <= 1e-9 and cand[1] + 1e-9 < best[1])):
                                best = cand

                if best is None or best[0] + 1e-9 >= cur_max:
                    return False
                # apply best 1x1
                _, _, d, r, ai, bi, a_item, b_item, wa, wb = best
                pack_loads[d] = pack_loads[d] - wa + wb
                pack_loads[r] = pack_loads[r] - wb + wa
                # swap membership
                pack_groups[d][ai] = b_item
                pack_groups[r][bi] = a_item
                # update indices
                pack_index[i, a_item] = r
                pack_index[i, b_item] = d
                # update ranks in affected packs
                for rr, gg in enumerate(pack_groups[d]):
                    rank_in_pack[i, gg] = rr
                for rr, gg in enumerate(pack_groups[r]):
                    rank_in_pack[i, gg] = rr
                return True

            mean_load = sum(pack_loads) / max(1, num_packs)
            delta = max(pack_loads) - min(pack_loads)
            rel = (delta / max(mean_load, 1e-12)) if mean_load > 0 else 0.0
            refine_steps = 2 if rel > 0.12 else 1
            for _ in range(refine_steps):
                if not _refine_once():
                    break
    return pack_index, rank_in_pack
>>>>>>> REPLACE

</DIFF>