<NAME>
adaptive_tail_waterfill
</NAME>

<DESCRIPTION>
I improve the replica count allocation in _waterfill_counts_row by introducing an adaptive, peak-aware tail assignment. The current method distributes all remaining replicas using a bulk highest-average rule (w / counts), which is fast but can leave a slightly suboptimal peak. The new approach keeps the same fast bulk fill for the majority of extras, but reserves a small tail T = min(extras, max(1, round(0.1·extras))) capped at 8. For each of these T steps, it evaluates two candidates: the D’Hondt pick (argmax w/c) and the Sainte–Laguë pick (argmax w/(2c+1)), simulates the resulting new maximum average load after assignment for both, and commits the choice that yields the lower peak (tie-broken by the lower second-highest average). This retains near-O(1) overhead per step while targeting the global peak where it matters, improving balancedness with negligible runtime impact.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Greedy water-filling for remaining extras
    extras = target_total - s
    while extras > 0:
        k = min(extras, num_log)
        # Select top-k by current w_i / c_i
        scores = w / counts.to(w.dtype)
        topk_idx = torch.argsort(scores, descending=True)[:k]
        counts[topk_idx] += 1
        extras -= k
    return counts
=======
    # Greedy water-filling for remaining extras with an adaptive, peak-aware tail
    extras = target_total - s
    if extras <= 0:
        return counts

    # Stage 1: bulk fill leaving a small adaptive tail T for peak-aware decisions
    T = min(extras, max(1, int(round(0.1 * extras))))
    T = min(T, 8)  # cap for speed
    bulk = extras - T
    while bulk > 0:
        k = min(bulk, num_log)
        # Select top-k by current w_i / c_i
        scores = w / counts.to(w.dtype)
        topk_idx = torch.argsort(scores, descending=True)[:k]
        counts[topk_idx] += 1
        bulk -= k

    # Stage 2: peak-aware tail allocation (D’Hondt vs Sainte–Laguë pick per step)
    def _peak_after(idx: int) -> tuple[float, float]:
        c_try = counts.clone()
        c_try[idx] += 1
        avg_try = w / c_try.to(w.dtype)
        peak = float(avg_try.max().item())
        if avg_try.numel() >= 2:
            top2 = torch.topk(avg_try, 2).values
            second = float(top2[1].item())
        else:
            second = peak
        return peak, second

    for _ in range(T):
        dh_scores = w / counts.to(w.dtype)                 # D’Hondt (Jefferson)
        sl_scores = w / (counts.to(w.dtype) * 2.0 + 1.0)   # Sainte–Laguë
        dh_idx = int(torch.argmax(dh_scores).item())
        sl_idx = int(torch.argmax(sl_scores).item())

        pd, sd = _peak_after(dh_idx)
        ps, ss = _peak_after(sl_idx)

        if ps + 1e-9 < pd or (abs(ps - pd) <= 1e-9 and ss + 1e-9 < sd):
            counts[sl_idx] += 1
        else:
            counts[dh_idx] += 1

    return counts
>>>>>>> REPLACE

</DIFF>