<NAME>
k2_micro_swap_diverse
</NAME>

<DESCRIPTION>
We introduce a lightweight k=2 micro-refinement swap inside the GPU packing stage (balanced_packing_diverse). After the initial greedy assignment (both for the non-duplicate and duplicate label cases), we perform a single best-improvement swap between the heaviest and the lightest packs. We evaluate up to 4 candidate swaps (top-2 items from the heavy pack with bottom-2 from the light pack) and choose the one that strictly reduces the imbalance, with a tie-breaker that prefers fewer label duplicates in the target packs. This adds negligible overhead and targets the most balance-sensitive step, improving balancedness without hurting the speed profile.

No changes are made to other parts to keep the execution time near the original; the refinement is capped at one iteration (k=2), keeping computational cost minimal while extracting extra balance.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing_diverse(weight: torch.Tensor,
                             label: torch.Tensor,
                             num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Balanced packing with diversity: prefer spreading items with the same label
    across different packs to reduce hotspotting when replicas of the same
    logical expert are placed on the same GPU.

    Parameters:
        weight: [X, n], the weight of each item
        label:  [X, n], an integer label for each item (e.g., logical expert id)
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_items = weight.shape
    assert num_items % num_packs == 0
    items_per_pack = num_items // num_packs

    # Trivial case: one item per pack, fallback to standard balanced packing
    if items_per_pack == 1 or num_packs == 1:
        return balanced_packing(weight, num_packs)

    # Ensure CPU tensors for Python-side loops
    device = weight.device
    w = weight.float()
    labels = label.to(dtype=torch.int64, device=device)

    # Pre-sort indices by descending weights per row
    sorted_indices = w.sort(dim=-1, descending=True).indices

    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device=device)
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)

    for i in range(num_layers):
        row_sorted = sorted_indices[i].tolist()
        row_w = w[i]
        row_labels = labels[i]

        # Quick duplicate check to avoid overhead when not needed
        seen = set()
        has_dup = False
        for idx in range(num_items):
            l = int(row_labels[idx].item())
            if l in seen:
                has_dup = True
                break
            seen.add(l)

        if not has_dup:
            # No duplicate labels; standard greedy suffices and is faster
            pack_loads = [0.0] * num_packs
            pack_counts = [0] * num_packs
            for group in row_sorted:
                # choose among packs with capacity the one with min load
                best_p = min(
                    (p for p in range(num_packs) if pack_counts[p] < items_per_pack),
                    key=lambda p: pack_loads[p],
                )
                pack_index[i, group] = best_p
                rank_in_pack[i, group] = pack_counts[best_p]
                pack_counts[best_p] += 1
                pack_loads[best_p] += float(row_w[group].item())
            continue

        # Diversity-aware greedy
        pack_loads = [0.0] * num_packs
        pack_counts = [0] * num_packs
        label_counts = [defaultdict(int) for _ in range(num_packs)]

        for group in row_sorted:
            lab = int(row_labels[group].item())
            # Select pack preferring fewer repetitions of label, then lower load, then fewer items
            best_p = None
            best_key = None
            for p in range(num_packs):
                if pack_counts[p] >= items_per_pack:
                    continue
                rep = label_counts[p].get(lab, 0)
                key = (rep, pack_loads[p], pack_counts[p])
                if best_key is None or key < best_key:
                    best_key = key
                    best_p = p
            # Assign
            pack_index[i, group] = best_p
            rank_in_pack[i, group] = pack_counts[best_p]
            pack_counts[best_p] += 1
            pack_loads[best_p] += float(row_w[group].item())
            label_counts[best_p][lab] += 1

    return pack_index, rank_in_pack
=======
def balanced_packing_diverse(weight: torch.Tensor,
                             label: torch.Tensor,
                             num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Balanced packing with diversity: prefer spreading items with the same label
    across different packs to reduce hotspotting when replicas of the same
    logical expert are placed on the same GPU.

    Parameters:
        weight: [X, n], the weight of each item
        label:  [X, n], an integer label for each item (e.g., logical expert id)
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_items = weight.shape
    assert num_items % num_packs == 0
    items_per_pack = num_items // num_packs

    # Trivial case: one item per pack, fallback to standard balanced packing
    if items_per_pack == 1 or num_packs == 1:
        return balanced_packing(weight, num_packs)

    # Ensure CPU tensors for Python-side loops
    device = weight.device
    w = weight.float()
    labels = label.to(dtype=torch.int64, device=device)

    # Pre-sort indices by descending weights per row
    sorted_indices = w.sort(dim=-1, descending=True).indices

    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device=device)
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)

    for i in range(num_layers):
        row_sorted = sorted_indices[i].tolist()
        row_w = w[i]
        row_labels = labels[i]

        # Quick duplicate check to avoid overhead when not needed
        seen = set()
        has_dup = False
        for idx in range(num_items):
            l = int(row_labels[idx].item())
            if l in seen:
                has_dup = True
                break
            seen.add(l)

        if not has_dup:
            # No duplicate labels; standard greedy suffices and is faster
            pack_loads = [0.0] * num_packs
            pack_counts = [0] * num_packs
            for group in row_sorted:
                # choose among packs with capacity the one with min load
                best_p = min(
                    (p for p in range(num_packs) if pack_counts[p] < items_per_pack),
                    key=lambda p: pack_loads[p],
                )
                pack_index[i, group] = best_p
                rank_in_pack[i, group] = pack_counts[best_p]
                pack_counts[best_p] += 1
                pack_loads[best_p] += float(row_w[group].item())

            # Micro refinement: single k=2 best-improvement swap
            if num_packs >= 2:
                # Build groups and label counts per pack
                pack_groups = [[] for _ in range(num_packs)]
                label_counts_ref = [defaultdict(int) for _ in range(num_packs)]
                for g in range(num_items):
                    p = int(pack_index[i, g])
                    pack_groups[p].append(g)
                    lab = int(row_labels[g].item())
                    label_counts_ref[p][lab] += 1
                cur_max = max(pack_loads)
                cur_min = min(pack_loads)
                cur_imb = cur_max - cur_min
                if cur_imb > 0:
                    h = int(max(range(num_packs), key=lambda k: pack_loads[k]))
                    l = int(min(range(num_packs), key=lambda k: pack_loads[k]))
                    if pack_groups[h] and pack_groups[l]:
                        h_idx_tensor = torch.tensor(pack_groups[h], dtype=torch.int64, device=row_w.device)
                        l_idx_tensor = torch.tensor(pack_groups[l], dtype=torch.int64, device=row_w.device)
                        h_w = row_w[h_idx_tensor]
                        l_w = row_w[l_idx_tensor]
                        kh = min(2, h_w.numel())
                        kl = min(2, l_w.numel())
                        if kh > 0 and kl > 0:
                            h_top = torch.topk(h_w, kh).indices.tolist()
                            l_bot = torch.topk(l_w, kl, largest=False).indices.tolist()
                            best = None
                            best_key = None
                            for ai in h_top:
                                a_item = int(h_idx_tensor[ai].item())
                                wa = float(h_w[ai].item())
                                la = int(row_labels[a_item].item())
                                for bi in l_bot:
                                    b_item = int(l_idx_tensor[bi].item())
                                    wb = float(l_w[bi].item())
                                    lb = int(row_labels[b_item].item())
                                    new_h = pack_loads[h] - wa + wb
                                    new_l = pack_loads[l] - wb + wa
                                    new_max = max(new_h, new_l, max(pack_loads[p] for p in range(num_packs) if p != h and p != l) if num_packs > 2 else max(new_h, new_l))
                                    new_min = min(new_h, new_l, min(pack_loads[p] for p in range(num_packs) if p != h and p != l) if num_packs > 2 else min(new_h, new_l))
                                    new_imb = new_max - new_min
                                    if new_imb + 1e-9 < cur_imb:
                                        # Tie-breaker: prefer fewer new duplicates
                                        dup_h = 1 if label_counts_ref[h].get(lb, 0) > 0 else 0
                                        dup_l = 1 if label_counts_ref[l].get(la, 0) > 0 else 0
                                        key = (new_imb, dup_h + dup_l)
                                        if best_key is None or key < best_key:
                                            best_key = key
                                            best = (ai, bi, a_item, b_item, wa, wb, la, lb)
                            if best is not None:
                                ai, bi, a_item, b_item, wa, wb, la, lb = best
                                # Apply swap
                                pack_loads[h] = pack_loads[h] - wa + wb
                                pack_loads[l] = pack_loads[l] - wb + wa
                                pack_groups[h][ai] = b_item
                                pack_groups[l][bi] = a_item
                                pack_index[i, a_item] = l
                                pack_index[i, b_item] = h
                                # Update label counts
                                label_counts_ref[h][la] -= 1
                                if label_counts_ref[h][la] == 0:
                                    del label_counts_ref[h][la]
                                label_counts_ref[l][lb] -= 1
                                if label_counts_ref[l][lb] == 0:
                                    del label_counts_ref[l][lb]
                                label_counts_ref[h][lb] += 1
                                label_counts_ref[l][la] += 1
                                # Update ranks for affected packs
                                for r, g in enumerate(pack_groups[h]):
                                    rank_in_pack[i, g] = r
                                for r, g in enumerate(pack_groups[l]):
                                    rank_in_pack[i, g] = r
            continue

        # Diversity-aware greedy
        pack_loads = [0.0] * num_packs
        pack_counts = [0] * num_packs
        label_counts = [defaultdict(int) for _ in range(num_packs)]

        for group in row_sorted:
            lab = int(row_labels[group].item())
            # Select pack preferring fewer repetitions of label, then lower load, then fewer items
            best_p = None
            best_key = None
            for p in range(num_packs):
                if pack_counts[p] >= items_per_pack:
                    continue
                rep = label_counts[p].get(lab, 0)
                key = (rep, pack_loads[p], pack_counts[p])
                if best_key is None or key < best_key:
                    best_key = key
                    best_p = p
            # Assign
            pack_index[i, group] = best_p
            rank_in_pack[i, group] = pack_counts[best_p]
            pack_counts[best_p] += 1
            pack_loads[best_p] += float(row_w[group].item())
            label_counts[best_p][lab] += 1

        # Micro refinement: single k=2 best-improvement swap
        if num_packs >= 2:
            # Build groups per pack
            pack_groups = [[] for _ in range(num_packs)]
            for g in range(num_items):
                p = int(pack_index[i, g])
                pack_groups[p].append(g)
            cur_max = max(pack_loads)
            cur_min = min(pack_loads)
            cur_imb = cur_max - cur_min
            if cur_imb > 0:
                h = int(max(range(num_packs), key=lambda k: pack_loads[k]))
                l = int(min(range(num_packs), key=lambda k: pack_loads[k]))
                if pack_groups[h] and pack_groups[l]:
                    h_idx_tensor = torch.tensor(pack_groups[h], dtype=torch.int64, device=row_w.device)
                    l_idx_tensor = torch.tensor(pack_groups[l], dtype=torch.int64, device=row_w.device)
                    h_w = row_w[h_idx_tensor]
                    l_w = row_w[l_idx_tensor]
                    kh = min(2, h_w.numel())
                    kl = min(2, l_w.numel())
                    if kh > 0 and kl > 0:
                        h_top = torch.topk(h_w, kh).indices.tolist()
                        l_bot = torch.topk(l_w, kl, largest=False).indices.tolist()
                        best = None
                        best_key = None
                        for ai in h_top:
                            a_item = int(h_idx_tensor[ai].item())
                            wa = float(h_w[ai].item())
                            la = int(row_labels[a_item].item())
                            for bi in l_bot:
                                b_item = int(l_idx_tensor[bi].item())
                                wb = float(l_w[bi].item())
                                lb = int(row_labels[b_item].item())
                                new_h = pack_loads[h] - wa + wb
                                new_l = pack_loads[l] - wb + wa
                                new_max = max(new_h, new_l, max(pack_loads[p] for p in range(num_packs) if p != h and p != l) if num_packs > 2 else max(new_h, new_l))
                                new_min = min(new_h, new_l, min(pack_loads[p] for p in range(num_packs) if p != h and p != l) if num_packs > 2 else min(new_h, new_l))
                                new_imb = new_max - new_min
                                if new_imb + 1e-9 < cur_imb:
                                    dup_h = 1 if label_counts[h].get(lb, 0) > 0 else 0
                                    dup_l = 1 if label_counts[l].get(la, 0) > 0 else 0
                                    key = (new_imb, dup_h + dup_l)
                                    if best_key is None or key < best_key:
                                        best_key = key
                                        best = (ai, bi, a_item, b_item, wa, wb, la, lb)
                        if best is not None:
                            ai, bi, a_item, b_item, wa, wb, la, lb = best
                            # Apply swap
                            pack_loads[h] = pack_loads[h] - wa + wb
                            pack_loads[l] = pack_loads[l] - wb + wa
                            pack_groups[h][ai] = b_item
                            pack_groups[l][bi] = a_item
                            pack_index[i, a_item] = l
                            pack_index[i, b_item] = h
                            # Update label counts
                            label_counts[h][la] -= 1
                            if label_counts[h][la] == 0:
                                del label_counts[h][la]
                            label_counts[l][lb] -= 1
                            if label_counts[l][lb] == 0:
                                del label_counts[l][lb]
                            label_counts[h][lb] += 1
                            label_counts[l][la] += 1
                            # Update ranks for affected packs
                            for r, g in enumerate(pack_groups[h]):
                                rank_in_pack[i, g] = r
                            for r, g in enumerate(pack_groups[l]):
                                rank_in_pack[i, g] = r

    return pack_index, rank_in_pack
>>>>>>> REPLACE

</DIFF>