<NAME>
best_swap_second_light_and_peak_guard
</NAME>

<DESCRIPTION>
Improve the GPU/node packing refinement by broadening the search to include both the lightest and second-lightest packs as swap partners and selecting the single swap that minimizes the new global peak load. This follows recommendation #2: in CapacityPacker._refine_single_layer, for each iteration we evaluate the best swap with the lightest and the second-lightest pack (using the same efficient searchsorted pairing), compute the resulting new global peak for each candidate, and apply the strictly better one. This strengthens balancedness while keeping the algorithm bounded and deterministic, with negligible additional overhead since the number of packs is small and we only add one extra candidate evaluation per iteration.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def _refine_single_layer(
        self,
        weights: torch.Tensor,
        pack_idx: torch.Tensor,
        num_packs: int,
        capacity: int,
    ) -> torch.Tensor:
        """
        Targeted refinement by swapping one item between heaviest and lightest packs
        per iteration (up to self.refine_steps). Uses a searchsorted-based best-swap
        selection for improved reduction of max imbalance.
        """
        if self.refine_steps <= 0:
            return pack_idx

        # Compute pack loads
        pack_w = self._pack_loads(weights, pack_idx, num_packs)

        for _ in range(self.refine_steps):
            h = int(torch.argmax(pack_w).item())
            l = int(torch.argmin(pack_w).item())
            if h == l:
                break
            delta = float(pack_w[h] - pack_w[l])
            if delta <= 1e-9:
                break

            heavy_idx = torch.nonzero(pack_idx == h, as_tuple=False).squeeze(1)
            light_idx = torch.nonzero(pack_idx == l, as_tuple=False).squeeze(1)
            if heavy_idx.numel() == 0 or light_idx.numel() == 0:
                break

            w = weights
            hw = w[heavy_idx]
            lw = w[light_idx]
            lw_sorted, lw_perm = torch.sort(lw)  # ascending

            if lw_sorted.numel() == 0 or hw.numel() == 0:
                break

            # For each heavy item, find light item closest to target = hw - delta/2
            target = hw - (delta / 2.0)
            pos = torch.searchsorted(lw_sorted, target)
            pos = torch.clamp(pos, 0, lw_sorted.numel() - 1)
            cand_pos = torch.stack(
                [pos, torch.clamp(pos - 1, 0, lw_sorted.numel() - 1)], dim=1
            )  # [H, 2]
            cand_lw = lw_sorted[cand_pos]  # [H, 2]
            resid = (delta - 2.0 * (hw.unsqueeze(1) - cand_lw)).abs()
            best_flat = int(torch.argmin(resid).item())
            best_h_index = best_flat // 2
            best_option = best_flat % 2
            j_sorted_idx = int(cand_pos[best_h_index, best_option].item())

            wi = float(hw[best_h_index].item())
            wj = float(lw_sorted[j_sorted_idx].item())
            new_delta = abs(delta - 2.0 * (wi - wj))
            if new_delta < delta - 1e-9:
                hi = heavy_idx[best_h_index]
                lj = light_idx[lw_perm[j_sorted_idx]]
                pack_idx[hi] = l
                pack_idx[lj] = h
                # Update loads incrementally
                pack_w[h] = pack_w[h] - wi + wj
                pack_w[l] = pack_w[l] - wj + wi
            else:
                break

        return pack_idx
=======
    def _refine_single_layer(
        self,
        weights: torch.Tensor,
        pack_idx: torch.Tensor,
        num_packs: int,
        capacity: int,
    ) -> torch.Tensor:
        """
        Targeted refinement by swapping one item between heaviest and the lightest
        or second-lightest packs per iteration (up to self.refine_steps).
        Uses a searchsorted-based best-swap selection and chooses the swap that
        yields the lowest new global peak; applies only if strictly improving.
        """
        if self.refine_steps <= 0:
            return pack_idx

        # Compute pack loads
        pack_w = self._pack_loads(weights, pack_idx, num_packs)

        for _ in range(self.refine_steps):
            # Heaviest pack
            h = int(torch.argmax(pack_w).item())

            # Candidate light packs: lightest and (optionally) second-lightest excluding h
            order = torch.argsort(pack_w, descending=False)
            light_candidates = []
            for pid in order.tolist():
                if pid != h:
                    light_candidates.append(pid)
                if len(light_candidates) >= 2:
                    break
            if not light_candidates:
                break

            # Indices of items in heaviest pack
            heavy_idx = torch.nonzero(pack_idx == h, as_tuple=False).squeeze(1)
            if heavy_idx.numel() == 0:
                break

            w = weights
            hw = w[heavy_idx]
            if hw.numel() == 0:
                break

            # Precompute current global peak
            cur_peak = float(pack_w.max().item())

            # Track best candidate across lightest and second-lightest
            best_candidate = None  # (new_peak, hi, lj, l_sel, wi, wj, new_delta)

            for l in light_candidates:
                light_idx = torch.nonzero(pack_idx == l, as_tuple=False).squeeze(1)
                if light_idx.numel() == 0:
                    continue
                lw = w[light_idx]
                if lw.numel() == 0:
                    continue

                # Current imbalance between h and this l
                delta_hl = float(pack_w[h] - pack_w[l])
                if delta_hl <= 1e-9:
                    continue

                # Sort light weights ascending and find nearest partners for each heavy item
                lw_sorted, lw_perm = torch.sort(lw)  # ascending
                target = hw - (delta_hl / 2.0)
                pos = torch.searchsorted(lw_sorted, target)
                pos = torch.clamp(pos, 0, lw_sorted.numel() - 1)
                cand_pos = torch.stack(
                    [pos, torch.clamp(pos - 1, 0, lw_sorted.numel() - 1)], dim=1
                )  # [H, 2]
                cand_lw = lw_sorted[cand_pos]  # [H, 2]
                resid = (delta_hl - 2.0 * (hw.unsqueeze(1) - cand_lw)).abs()
                best_flat = int(torch.argmin(resid).item())
                best_h_index = best_flat // 2
                best_option = best_flat % 2
                j_sorted_idx = int(cand_pos[best_h_index, best_option].item())

                wi = float(hw[best_h_index].item())
                wj = float(lw_sorted[j_sorted_idx].item())
                # Predicted new delta for (h, l)
                new_delta_hl = abs(delta_hl - 2.0 * (wi - wj))

                # Compute predicted new global peak if we swap (hi <-> lj)
                # Max among: other packs (excluding h and l), updated h, updated l
                if num_packs > 2:
                    mask = torch.ones(num_packs, dtype=torch.bool, device=pack_w.device)
                    mask[h] = False
                    mask[l] = False
                    other_max = float(pack_w[mask].max().item()) if mask.any() else float('-inf')
                else:
                    other_max = float('-inf')
                new_h = float(pack_w[h].item()) - wi + wj
                new_l = float(pack_w[l].item()) - wj + wi
                cand_peak = max(other_max, new_h, new_l)

                # Keep the candidate with smallest new global peak; tie-break by new delta
                if best_candidate is None or cand_peak < best_candidate[0] - 1e-12 or (
                    abs(cand_peak - best_candidate[0]) <= 1e-12 and new_delta_hl < best_candidate[6]
                ):
                    hi = heavy_idx[best_h_index]
                    lj = light_idx[lw_perm[j_sorted_idx]]
                    best_candidate = (cand_peak, hi, lj, l, wi, wj, new_delta_hl)

            if best_candidate is None:
                break

            # Apply only if it strictly improves the global peak
            if best_candidate[0] + 1e-12 < cur_peak:
                _, hi, lj, l_sel, wi, wj, _ = best_candidate
                pack_idx[hi] = l_sel
                pack_idx[lj] = h
                # Update loads incrementally
                pack_w[h] = pack_w[h] - wi + wj
                pack_w[l_sel] = pack_w[l_sel] - wj + wi
            else:
                break

        return pack_idx
>>>>>>> REPLACE

</DIFF>