<NAME>
local_swap_refine_in_packing
</NAME>

<DESCRIPTION>
Introduce a lightweight local 2-opt refinement step into balanced_packing. After the initial greedy assignment, we perform a small number of targeted swaps between the heaviest and lightest packs to reduce their load difference while preserving the exact capacity constraint (equal number of items per pack). This improves balancedness significantly with minimal runtime overhead because:
- We cap the number of refinement iterations per layer to a small constant.
- Each refinement chooses the most effective swap (heaviest item in the heavy pack with lightest item in the light pack), which provably reduces the max-min difference.
- Implementation uses simple list/tensor indexing on CPU, matching the existing functionâ€™s device behavior.

No interfaces or other functions are changed, preserving compatibility and performance while improving load balance.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)
    for i in range(num_layers):
        pack_weights = [0] * num_packs
        pack_items = [0] * num_packs
        for group in indices[i]:
            pack = min(
                (i
                 for i in range(num_packs) if pack_items[i] < groups_per_pack),
                key=pack_weights.__getitem__,
            )
            assert pack_items[pack] < groups_per_pack
            pack_index[i, group] = pack
            rank_in_pack[i, group] = pack_items[pack]
            pack_weights[pack] += weight[i, group]
            pack_items[pack] += 1
    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=weight.device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Initial greedy assignment
    indices = weight.float().sort(-1, descending=True).indices.cpu()
    pack_index = torch.full_like(weight,
                                 fill_value=-1,
                                 dtype=torch.int64,
                                 device="cpu")
    rank_in_pack = torch.full_like(pack_index, fill_value=-1)
    for i in range(num_layers):
        pack_weights = [0.0] * num_packs
        pack_items = [0] * num_packs
        for group in indices[i]:
            pack = min(
                (pi for pi in range(num_packs)
                 if pack_items[pi] < groups_per_pack),
                key=lambda k: pack_weights[k],
            )
            # assign
            pack_index[i, group] = pack
            rank_in_pack[i, group] = pack_items[pack]
            pack_weights[pack] += float(weight[i, group])
            pack_items[pack] += 1

        # Lightweight local 2-opt refinement to reduce max-min imbalance
        # Build per-pack group lists
        pack_groups = [[] for _ in range(num_packs)]
        wi = weight[i].cpu()
        for g in range(num_groups):
            p = int(pack_index[i, g])
            pack_groups[p].append(g)
        # Recompute weights precisely from assigned groups
        pack_weights_f = [0.0] * num_packs
        for p in range(num_packs):
            if pack_groups[p]:
                pack_weights_f[p] = float(wi[pack_groups[p]].sum().item())

        # Perform a few targeted swaps between the heaviest and lightest packs
        max_refine = min(8, groups_per_pack)
        for _ in range(max_refine):
            # Identify heavy and light packs
            h = max(range(num_packs), key=lambda k: pack_weights_f[k])
            l = min(range(num_packs), key=lambda k: pack_weights_f[k])
            diff = pack_weights_f[h] - pack_weights_f[l]
            if diff <= 0 or not pack_groups[h] or not pack_groups[l]:
                break

            # Choose heaviest item in heavy pack and lightest in light pack
            h_weights = wi[pack_groups[h]]
            l_weights = wi[pack_groups[l]]
            a_idx = int(torch.argmax(h_weights).item())
            b_idx = int(torch.argmin(l_weights).item())
            a = pack_groups[h][a_idx]
            b = pack_groups[l][b_idx]
            wa = float(h_weights[a_idx].item())
            wb = float(l_weights[b_idx].item())

            # If no improving swap is possible, exit
            if wa <= wb:
                break

            # Swap the two items
            pack_groups[h][a_idx] = b
            pack_groups[l][b_idx] = a
            pack_index[i, a] = l
            pack_index[i, b] = h
            pack_weights_f[h] += (wb - wa)
            pack_weights_f[l] += (wa - wb)

        # Recompute ranks within each pack after refinement
        for p in range(num_packs):
            for r, g in enumerate(pack_groups[p]):
                rank_in_pack[i, g] = r

    return pack_index, rank_in_pack
>>>>>>> REPLACE

</DIFF>