--- a/original.py
+++ b/original.py
@@ -1,376 +1,375 @@
 # EVOLVE-BLOCK-START
 from typing import Dict, Any, Tuple, List
 import math
 
-def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
+def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
-    Repairs network telemetry using a Bayesian Flow Consensus algorithm.
-    It fuses evidence from Link Symmetry and Router Flow Conservation to
-    probabilistically determine the most likely true state of network counters.
+    Repairs network telemetry using a Momentum-Based Bayesian Consensus algorithm.
+    
+    Key Innovations:
+    1. Square-Root Noise Model: Tolerances scale with sqrt(flow) to match Poisson statistics.
+    2. Implied & Zero Hypotheses: Explicitly tests 'Link Down' and 'Conservation-Implied' values.
+    3. Momentum Updates: Uses soft updates (alpha=0.5) to stably converge on flow conservation.
+    4. Absolute Confidence Calibration: Confidence scales with goodness-of-fit, not just relative probability.
     """
-
+    
     # --- Configuration ---
-    SYMMETRY_TOLERANCE = 0.02
-    CONSERVATION_TOLERANCE_PCT = 0.03
-    MIN_SIGNIFICANT_FLOW = 0.5
-    ITERATIONS = 5
-
+    SYMMETRY_TOLERANCE = 0.02   # 2% difference allowed for hardening
+    MIN_SIG_FLOW = 0.1          # Minimum flow to consider interface UP
+    ITERATIONS = 10             # Solver iterations
+    LEARNING_RATE = 0.5         # Alpha for momentum updates (0.0 = no change, 1.0 = immediate overwrite)
+    SIGMA_K = 0.5               # Noise scaling constant: sigma = K * sqrt(flow)
+                                # At 100Mbps, sigma=5 (5%). At 10Gbps, sigma=50 (0.5%).
+    
     # --- Helper Structures ---
-    # Map interface to router
     if_to_router = {}
     for r_id, if_list in topology.items():
         for i_id in if_list:
             if_to_router[i_id] = r_id
-
-    # Group interfaces into Links for processing
-    # Link ID = tuple of sorted interface IDs to handle bidirectionality uniquely
-    links = {}
-    processed_ifs = set()
-
+            
+    # --- Step 1: Link Identification & Hardening ---
+    # Classify links into 'Internal' (pairs) and 'External' (singletons).
+    # Check symmetry for Internal links.
+    
+    # estimates: {if_id: {'rx': val, 'tx': val}}
+    estimates = {}
+    # confidences: {if_id: {'rx': conf, 'tx': conf}}
+    confidences = {}
+    # processed_links: set of keys to avoid double processing
+    processed_links = set()
+    
+    # Work items for the solver
+    # List of dicts describing what to solve
+    suspect_items = []
+    
+    # Initialize all interfaces first
     for if_id, data in telemetry.items():
-        if if_id in processed_ifs: continue
-
+        estimates[if_id] = {
+            'rx': float(data.get('rx_rate', 0.0)), 
+            'tx': float(data.get('tx_rate', 0.0))
+        }
+        # Default low confidence
+        confidences[if_id] = {'rx': 0.5, 'tx': 0.5}
+
+    # Process Links
+    for if_id, data in telemetry.items():
+        if if_id in processed_links: continue
+        
         peer_id = data.get('connected_to')
+        
         if peer_id and peer_id in telemetry:
             # Internal Link
-            link_key = tuple(sorted([if_id, peer_id]))
-            links[link_key] = {
-                'type': 'internal',
-                'if1': if_id,
-                'if2': peer_id
-            }
-            processed_ifs.add(if_id)
-            processed_ifs.add(peer_id)
+            processed_links.add(if_id)
+            processed_links.add(peer_id)
+            
+            # Check Symmetry: My TX vs Peer RX
+            tx_val = estimates[if_id]['tx']
+            rx_val = estimates[peer_id]['rx']
+            diff = abs(tx_val - rx_val)
+            denom = max(tx_val, rx_val, 1.0)
+            
+            if diff / denom < SYMMETRY_TOLERANCE:
+                # Consistent: Harden
+                consensus = (tx_val + rx_val) / 2.0
+                estimates[if_id]['tx'] = consensus
+                estimates[peer_id]['rx'] = consensus
+                confidences[if_id]['tx'] = 0.95
+                confidences[peer_id]['rx'] = 0.95
+                # Do NOT add to suspect_items (anchored)
+            else:
+                # Inconsistent: Suspect
+                suspect_items.append({
+                    'type': 'internal_link_dir',
+                    'src': if_id, 'dst': peer_id,
+                    'val_src': tx_val, 'val_dst': rx_val
+                })
+                
+            # Check Symmetry: Peer TX vs My RX
+            tx_val = estimates[peer_id]['tx']
+            rx_val = estimates[if_id]['rx']
+            diff = abs(tx_val - rx_val)
+            denom = max(tx_val, rx_val, 1.0)
+            
+            if diff / denom < SYMMETRY_TOLERANCE:
+                consensus = (tx_val + rx_val) / 2.0
+                estimates[peer_id]['tx'] = consensus
+                estimates[if_id]['rx'] = consensus
+                confidences[peer_id]['tx'] = 0.95
+                confidences[if_id]['rx'] = 0.95
+            else:
+                suspect_items.append({
+                    'type': 'internal_link_dir',
+                    'src': peer_id, 'dst': if_id,
+                    'val_src': tx_val, 'val_dst': rx_val
+                })
         else:
-            # Edge/External Link
-            links[(if_id,)] = {
-                'type': 'external',
-                'if1': if_id,
-                'if2': None
-            }
-            processed_ifs.add(if_id)
-
-    # --- Step 1: Initial Link Assessment ---
-    # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
-    # For suspect links, generate hypotheses.
-
-    # Store current best estimates for RX and TX flow on every interface
-    # structure: {if_id: {'rx': val, 'tx': val}}
-    current_estimates = {}
-
-    # Store reliability/confidence of these estimates
-    # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
-    estimate_confidence = {}
-
-    # Suspect flows to solve: list of (link_key, metric_type ('rx_flow' or 'tx_flow'))
-    # Note: 'rx_flow' for link (A,B) means A->B traffic (A TX, B RX).
-    suspect_flows = []
-
-    for link_key, info in links.items():
-        if1 = info['if1']
-        if2 = info['if2']
-
-        d1 = telemetry[if1]
-        d2 = telemetry[if2] if if2 else {}
-
-        # Analyze Flow IF1 -> IF2 (IF1 TX, IF2 RX)
-        val1_tx = d1.get('tx_rate', 0.0)
-        val2_rx = d2.get('rx_rate', 0.0) if if2 else None
-
-        if if2:
-            # Internal Link: Check Symmetry
-            denom = max(val1_tx, val2_rx, 1.0)
-            diff = abs(val1_tx - val2_rx)
-
-            if diff / denom < SYMMETRY_TOLERANCE:
-                # Consistent
-                consensus = (val1_tx + val2_rx) / 2.0
-                current_estimates[if1] = current_estimates.get(if1, {})
-                current_estimates[if1]['tx'] = consensus
-                current_estimates[if2] = current_estimates.get(if2, {})
-                current_estimates[if2]['rx'] = consensus
-
-                estimate_confidence[if1] = estimate_confidence.get(if1, {})
-                estimate_confidence[if1]['tx'] = 0.95
-                estimate_confidence[if2] = estimate_confidence.get(if2, {})
-                estimate_confidence[if2]['rx'] = 0.95
-            else:
-                # Suspect
-                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
-                # Initialize with average but low confidence
-                consensus = (val1_tx + val2_rx) / 2.0
-                current_estimates[if1] = current_estimates.get(if1, {})
-                current_estimates[if1]['tx'] = consensus
-                current_estimates[if2] = current_estimates.get(if2, {})
-                current_estimates[if2]['rx'] = consensus
-
-                estimate_confidence[if1] = estimate_confidence.get(if1, {})
-                estimate_confidence[if1]['tx'] = 0.5
-                estimate_confidence[if2] = estimate_confidence.get(if2, {})
-                estimate_confidence[if2]['rx'] = 0.5
+            # External Link
+            processed_links.add(if_id)
+            # Add both RX and TX as suspect/optimizable
+            # We initialize confidence slightly higher as there is no peer to contradict,
+            # but we allow conservation to correct it.
+            confidences[if_id]['rx'] = 0.8
+            confidences[if_id]['tx'] = 0.8
+            
+            suspect_items.append({
+                'type': 'external_rx',
+                'if': if_id,
+                'val': estimates[if_id]['rx']
+            })
+            suspect_items.append({
+                'type': 'external_tx',
+                'if': if_id,
+                'val': estimates[if_id]['tx']
+            })
+
+    # --- Step 2: Iterative Bayesian Solver with Momentum ---
+    
+    def get_router_stats(rid):
+        """Returns (net_imbalance, total_flow) for a router."""
+        if not rid: return 0.0, 1.0
+        net = 0.0
+        total = 0.0
+        for iid in topology.get(rid, []):
+            r = estimates[iid]['rx']
+            t = estimates[iid]['tx']
+            net += (r - t)
+            total += (r + t)
+        return net, max(total/2.0, 1.0) # Avg flow per direction
+
+    def get_implied_value(rid, if_id, metric):
+        """
+        Calculates the value for interface[metric] that would perfectly balance the router,
+        assuming all other interfaces are fixed.
+        """
+        if not rid: return 0.0
+        
+        # Calculate net flow of ALL OTHER interfaces
+        other_net = 0.0
+        for iid in topology.get(rid, []):
+            if iid == if_id: continue
+            other_net += (estimates[iid]['rx'] - estimates[iid]['tx'])
+            
+        # Balance equation: other_net + My_Net = 0
+        # If I am RX: My_Net = +RX.  => RX = -other_net
+        # If I am TX: My_Net = -TX.  => -TX = -other_net => TX = other_net
+        
+        if metric == 'rx':
+            return max(0.0, -other_net)
         else:
-            # External Link: Trust local blindly for now (no peer to contradict)
-            current_estimates[if1] = current_estimates.get(if1, {})
-            current_estimates[if1]['tx'] = val1_tx
-            estimate_confidence[if1] = estimate_confidence.get(if1, {})
-            estimate_confidence[if1]['tx'] = 0.90 # Less confident than hardened links
-
-        # Analyze Flow IF2 -> IF1 (IF2 TX, IF1 RX)
-        if if2:
-            val2_tx = d2.get('tx_rate', 0.0)
-            val1_rx = d1.get('rx_rate', 0.0)
-
-            denom = max(val2_tx, val1_rx, 1.0)
-            diff = abs(val2_tx - val1_rx)
-
-            if diff / denom < SYMMETRY_TOLERANCE:
-                consensus = (val2_tx + val1_rx) / 2.0
-                current_estimates[if2]['tx'] = consensus
-                current_estimates[if1]['rx'] = consensus
-                estimate_confidence[if2]['tx'] = 0.95
-                estimate_confidence[if1]['rx'] = 0.95
-            else:
-                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
-                consensus = (val2_tx + val1_rx) / 2.0
-                current_estimates[if2]['tx'] = consensus
-                current_estimates[if1]['rx'] = consensus
-                estimate_confidence[if2]['tx'] = 0.5
-                estimate_confidence[if1]['rx'] = 0.5
-        else:
-             # External RX
-            val1_rx = d1.get('rx_rate', 0.0)
-            current_estimates[if1]['rx'] = val1_rx
-            estimate_confidence[if1]['rx'] = 0.90
-
-    # --- Step 2: Iterative Bayesian Refinement ---
-
-    # Helper to calculate router imbalance given current estimates
-    def get_router_imbalance(rid):
-        if_list = topology.get(rid, [])
-        total_in = 0.0
-        total_out = 0.0
-        for iid in if_list:
-            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
-            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
-        return total_in - total_out, max(total_in, total_out, 1.0)
-
-    # Iteration loop
+            return max(0.0, other_net)
+
     for _ in range(ITERATIONS):
-        updates = {} # Store updates to apply after full pass
-
-        for flow_prob in suspect_flows:
-            link_key = flow_prob['key']
-            direction = flow_prob['dir']
-            candidates = flow_prob['candidates']
-
-            # Identify interfaces and routers involved
-            info = links[link_key]
-            if direction == '1_to_2':
-                src_if, dst_if = info['if1'], info['if2']
-                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
-            else:
-                src_if, dst_if = info['if2'], info['if1']
-                val_src, val_dst = candidates[0], candidates[1]
-
-            router_src = if_to_router.get(src_if)
-            router_dst = if_to_router.get(dst_if)
-
-            # Evaluate Hypothesis 1: Value is val_src (Local TX measurement)
-            # Evaluate Hypothesis 2: Value is val_dst (Peer RX measurement)
-            hyps = [val_src, val_dst]
-            scores = []
-
-            for h_val in hyps:
-                # Probability score based on Gaussian likelihood of imbalance
-
-                # Check Source Router Imbalance if we use h_val for this TX interface
-                old_tx = current_estimates[src_if]['tx']
-                current_estimates[src_if]['tx'] = h_val
-                imb_src, flow_src = get_router_imbalance(router_src)
-                current_estimates[src_if]['tx'] = old_tx
-
-                # Check Dest Router Imbalance if we use h_val for this RX interface
-                old_rx = current_estimates[dst_if]['rx']
-                current_estimates[dst_if]['rx'] = h_val
-                imb_dst, flow_dst = get_router_imbalance(router_dst)
-                current_estimates[dst_if]['rx'] = old_rx
-
-                # Likelihood function: P ~ exp(- |imbalance| / sigma)
-                # sigma is tolerance proportional to flow
-                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
-                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)
-
-                score_src = math.exp(-abs(imb_src) / sigma_src)
-                score_dst = math.exp(-abs(imb_dst) / sigma_dst)
-
-                scores.append(score_src * score_dst)
-
-            # Select Winner
-            s1, s2 = scores[0], scores[1]
-            total_s = s1 + s2 + 1e-9
-
-            p1 = s1 / total_s
-            p2 = s2 / total_s
-
-            if p1 > p2:
-                winner_val = val_src
-                conf = p1
-            else:
-                winner_val = val_dst
-                conf = p2
-
-            # Store update
-            updates[(src_if, 'tx')] = (winner_val, conf)
-            updates[(dst_if, 'rx')] = (winner_val, conf)
-
-        # Apply updates
-        for (if_id, metric), (val, conf) in updates.items():
-            current_estimates[if_id][metric] = val
-            estimate_confidence[if_id][metric] = conf
-
-    # --- Step 2.5: Global Confidence Calibration ---
-    # Down-weight confidence for interfaces connected to routers that remain imbalanced.
-    # This captures the "all hypotheses bad" or "external link invalid" cases.
-
-    for rid, if_list in topology.items():
-        imb, flow = get_router_imbalance(rid)
-        imb_ratio = abs(imb) / flow
-
-        # If imbalance > tolerance, penalize confidence
-        # Penalty starts at tolerance (0.03) and reaches max (0 conf) at 13% imbalance
-        if imb_ratio > CONSERVATION_TOLERANCE_PCT:
-            penalty_factor = max(0.0, 1.0 - (imb_ratio - CONSERVATION_TOLERANCE_PCT) * 10.0)
-
-            for iid in if_list:
-                if iid in estimate_confidence:
-                    if 'rx' in estimate_confidence[iid]:
-                        estimate_confidence[iid]['rx'] *= penalty_factor
-                    if 'tx' in estimate_confidence[iid]:
-                        estimate_confidence[iid]['tx'] *= penalty_factor
-
-    # --- Step 3: Final Assembly & Status Repair ---
-
+        updates = []
+        
+        for item in suspect_items:
+            # Generate Hypotheses
+            candidates = [] # List of (value, type)
+            
+            if item['type'] == 'internal_link_dir':
+                # Candidates: Src measurement, Dst measurement, Zero
+                candidates.append((item['val_src'], 'src'))
+                candidates.append((item['val_dst'], 'dst'))
+                candidates.append((0.0, 'zero'))
+                
+                src_if, dst_if = item['src'], item['dst']
+                r_src = if_to_router.get(src_if)
+                r_dst = if_to_router.get(dst_if)
+                
+                # Setup targets for update
+                targets = [(src_if, 'tx'), (dst_if, 'rx')]
+                
+                # Context Management
+                old_src = estimates[src_if]['tx']
+                old_dst = estimates[dst_if]['rx']
+                
+                scored_hyps = []
+                for val, _ in candidates:
+                    # Apply
+                    estimates[src_if]['tx'] = val
+                    estimates[dst_if]['rx'] = val
+                    
+                    # Score Src
+                    imb_s, flow_s = get_router_stats(r_src)
+                    sigma_s = max(math.sqrt(flow_s) * SIGMA_K, 1.0)
+                    prob_s = math.exp(-abs(imb_s)/sigma_s)
+                    
+                    # Score Dst
+                    imb_d, flow_d = get_router_stats(r_dst)
+                    sigma_d = max(math.sqrt(flow_d) * SIGMA_K, 1.0)
+                    prob_d = math.exp(-abs(imb_d)/sigma_d)
+                    
+                    # Combined
+                    scored_hyps.append((val, prob_s * prob_d))
+                    
+                # Restore
+                estimates[src_if]['tx'] = old_src
+                estimates[dst_if]['rx'] = old_dst
+                
+            else: # external_rx or external_tx
+                iid = item['if']
+                metric = 'rx' if item['type'] == 'external_rx' else 'tx'
+                rid = if_to_router.get(iid)
+                
+                # Candidates: Local, Zero, Implied
+                candidates.append((item['val'], 'local'))
+                candidates.append((0.0, 'zero'))
+                if rid:
+                    implied = get_implied_value(rid, iid, metric)
+                    candidates.append((implied, 'implied'))
+                
+                targets = [(iid, metric)]
+                old_val = estimates[iid][metric]
+                
+                scored_hyps = []
+                for val, _ in candidates:
+                    estimates[iid][metric] = val
+                    imb, flow = get_router_stats(rid)
+                    sigma = max(math.sqrt(flow) * SIGMA_K, 1.0)
+                    prob = math.exp(-abs(imb)/sigma)
+                    scored_hyps.append((val, prob))
+                    
+                estimates[iid][metric] = old_val
+
+            # Selection Strategy
+            # Find best hypothesis
+            best_val, best_score = max(scored_hyps, key=lambda x: x[1])
+            
+            # Calibration
+            total_score = sum(s for v,s in scored_hyps) + 1e-12
+            rel_prob = best_score / total_score
+            
+            # Confidence = Relative Probability * Absolute Goodness
+            # If the best solution still leaves the router imbalanced (low best_score),
+            # confidence drops.
+            conf = rel_prob * best_score
+            conf = max(0.01, min(0.99, conf))
+            
+            updates.append({
+                'targets': targets,
+                'val': best_val,
+                'conf': conf
+            })
+            
+        # Apply Updates (Momentum)
+        for u in updates:
+            target_val = u['val']
+            conf = u['conf']
+            for (iid, metric) in u['targets']:
+                curr = estimates[iid][metric]
+                # Update rule: New = (LR * Target) + ((1-LR) * Old)
+                estimates[iid][metric] = (LEARNING_RATE * target_val) + ((1 - LEARNING_RATE) * curr)
+                confidences[iid][metric] = conf
+
+    # --- Step 3: Result Assembly & Status Inference ---
     result = {}
-
+    
     for if_id, data in telemetry.items():
         orig_rx = data.get('rx_rate', 0.0)
         orig_tx = data.get('tx_rate', 0.0)
         orig_status = data.get('interface_status', 'unknown')
-
-        # Repaired Rates
-        est_rx = current_estimates[if_id]['rx']
-        conf_rx = estimate_confidence[if_id]['rx']
-
-        est_tx = current_estimates[if_id]['tx']
-        conf_tx = estimate_confidence[if_id]['tx']
-
-        # Status Inference
-        # Determine peer status
+        
+        rep_rx = estimates[if_id]['rx']
+        conf_rx = confidences[if_id]['rx']
+        
+        rep_tx = estimates[if_id]['tx']
+        conf_tx = confidences[if_id]['tx']
+        
+        # Determine Status
         peer_id = data.get('connected_to')
         peer_status = 'unknown'
         if peer_id and peer_id in telemetry:
             peer_status = telemetry[peer_id].get('interface_status', 'unknown')
-
-        # 1. Existence of significant traffic implies UP
-        has_rx = est_rx > MIN_SIGNIFICANT_FLOW
-        has_tx = est_tx > MIN_SIGNIFICANT_FLOW
-
+            
+        has_traffic = (rep_rx > MIN_SIG_FLOW) or (rep_tx > MIN_SIG_FLOW)
+        
         rep_status = orig_status
-        conf_status = 1.0 # Baseline
-
-        if has_rx or has_tx:
+        conf_status = 1.0
+        
+        if has_traffic:
             rep_status = 'up'
             if orig_status != 'up':
-                # We are overturning status based on traffic.
-                # Confidence depends on traffic confidence.
-                flow_conf = max(conf_rx if has_rx else 0, conf_tx if has_tx else 0)
-                conf_status = flow_conf
-
+                # If we overturn status, our confidence is limited by flow confidence
+                conf_status = (conf_rx + conf_tx) / 2.0
         elif peer_status == 'down':
-            # Peer is down and we have no traffic -> We should be down (usually)
             rep_status = 'down'
             if orig_status != 'down':
-                conf_status = 0.9
-
-        elif orig_status == 'up' and not has_rx and not has_tx:
-            # We say UP, but no traffic.
-            # Could be idle.
-            # If peer is UP, likely idle -> Keep UP.
-            # If peer is DOWN (caught above), then DOWN.
-            # If peer unknown, keep UP.
+                conf_status = 0.95
+        elif orig_status == 'up':
+            # No traffic, Peer UP or Unknown. Likely Idle.
             rep_status = 'up'
-
-        # Post-process: If status is DOWN, force rates to 0
+        else:
+            # Original DOWN, no traffic, peer not DOWN. Trust original.
+            rep_status = 'down'
+            
+        # Consistency Check
         if rep_status == 'down':
-            est_rx = 0.0
-            est_tx = 0.0
-            # High confidence in 0 if we are confident it's down
+            rep_rx = 0.0
+            rep_tx = 0.0
+            # If we are sure it's down, we are sure rate is 0
             conf_rx = max(conf_rx, conf_status)
             conf_tx = max(conf_tx, conf_status)
-
-        # Result Construction
+            
+        # Build Entry
         entry = {}
-        entry['rx_rate'] = (orig_rx, est_rx, conf_rx)
-        entry['tx_rate'] = (orig_tx, est_tx, conf_tx)
+        entry['rx_rate'] = (orig_rx, rep_rx, conf_rx)
+        entry['tx_rate'] = (orig_tx, rep_tx, conf_tx)
         entry['interface_status'] = (orig_status, rep_status, conf_status)
-
-        # Metadata
+        
         for k in ['connected_to', 'local_router', 'remote_router']:
-            if k in data:
-                entry[k] = data[k]
-
+            if k in data: entry[k] = data[k]
+            
         result[if_id] = entry
-
+        
     return result
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")