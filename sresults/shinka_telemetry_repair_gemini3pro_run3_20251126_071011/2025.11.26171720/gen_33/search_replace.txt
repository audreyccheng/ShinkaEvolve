The user wants to improve the `repair_network_telemetry` function to increase the combined score, particularly focusing on confidence calibration.

I will introduce the following changes:
1.  **Non-Linear Noise Model**: Change the `sigma` calculation to use `math.sqrt(flow)` (Poisson noise scaling) instead of purely linear scaling. This prevents over-penalizing small imbalances in low flows.
2.  **Phantom Traffic Detection**: Add `0.0` as a hypothesis in the Bayesian refinement step for suspect flows. This allows the algorithm to detect when a link is effectively down but reporting noise.
3.  **External Link Refinement**: Implement a pass to refine external/edge links. If a router is significantly imbalanced after internal links are fixed, the algorithm attempts to adjust external links to restore conservation.
4.  **Split Iteration**: Separate internal and external link updates into two phases within each iteration to prevent over-correction.

Here are the edits.

<NAME>
calibrate_confidence_and_add_external_refinement
</NAME>

<DESCRIPTION>
1. Updates the noise model (Sigma) to use `sqrt(flow)`, which better models Poisson packet noise than linear tolerance for low flows.
2. Adds `0.0` (Phantom Traffic) as a hypothesis for suspect flows to detect down links reporting noise.
3. Implements an external link refinement pass: if a router is imbalanced after internal links are fixed, the algorithm attempts to adjust external links to satisfy conservation.
4. Splits the iteration into two phases (Internal then External) to prevent over-correction.
5. Improves confidence calibration by combining relative probability with absolute goodness-of-fit.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Step 1: Initial Link Assessment ---

    current_estimates = {}
    estimate_confidence = {}
    suspect_flows = []

    for link_key, info in links.items():
        if1 = info['if1']
        if2 = info['if2']

        d1 = telemetry[if1]
        d2 = telemetry[if2] if if2 else {}

        # 1. Forward Flow: IF1 (TX) -> IF2 (RX)
        val1_tx = d1.get('tx_rate', 0.0)

        if if2:
            val2_rx = d2.get('rx_rate', 0.0)

            # Check Symmetry with Hybrid Tolerance
            diff = abs(val1_tx - val2_rx)
            denom = max(val1_tx, val2_rx, 1.0)

            is_consistent = (diff < ABS_TOLERANCE) or ((diff / denom) < SYMMETRY_TOLERANCE)

            if is_consistent:
                # Consistent: Average and Harden
                # If one is 0 and match is close, prefer 0 for cleanness, otherwise average
                if min(val1_tx, val2_rx) == 0.0 and diff < ABS_TOLERANCE:
                    consensus = 0.0
                else:
                    consensus = (val1_tx + val2_rx) / 2.0

                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.95 # High but not 1.0
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.95
            else:
                # Suspect
                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
                consensus = (val1_tx + val2_rx) / 2.0
                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.5
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.5
        else:
            # External Link
            current_estimates[if1] = current_estimates.get(if1, {})
            current_estimates[if1]['tx'] = val1_tx
            estimate_confidence[if1] = estimate_confidence.get(if1, {})
            estimate_confidence[if1]['tx'] = 0.90

        # 2. Backward Flow: IF2 (TX) -> IF1 (RX)
        if if2:
            val2_tx = d2.get('tx_rate', 0.0)
            val1_rx = d1.get('rx_rate', 0.0)

            diff = abs(val2_tx - val1_rx)
            denom = max(val2_tx, val1_rx, 1.0)

            is_consistent = (diff < ABS_TOLERANCE) or ((diff / denom) < SYMMETRY_TOLERANCE)

            if is_consistent:
                if min(val2_tx, val1_rx) == 0.0 and diff < ABS_TOLERANCE:
                    consensus = 0.0
                else:
                    consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.95
                estimate_confidence[if1]['rx'] = 0.95
            else:
                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
                consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.5
                estimate_confidence[if1]['rx'] = 0.5
        else:
            val1_rx = d1.get('rx_rate', 0.0)
            current_estimates[if1]['rx'] = val1_rx
            estimate_confidence[if1]['rx'] = 0.90
=======
    # --- Step 1: Initial Link Assessment ---

    current_estimates = {}
    estimate_confidence = {}
    suspect_flows = []
    external_flows = [] # List of (if_id, metric_type)

    for link_key, info in links.items():
        if1 = info['if1']
        if2 = info['if2']

        d1 = telemetry[if1]
        d2 = telemetry[if2] if if2 else {}

        # 1. Forward Flow: IF1 (TX) -> IF2 (RX)
        val1_tx = d1.get('tx_rate', 0.0)

        if if2:
            val2_rx = d2.get('rx_rate', 0.0)

            # Check Symmetry with Hybrid Tolerance
            diff = abs(val1_tx - val2_rx)
            denom = max(val1_tx, val2_rx, 1.0)

            is_consistent = (diff < ABS_TOLERANCE) or ((diff / denom) < SYMMETRY_TOLERANCE)

            if is_consistent:
                # Consistent: Average and Harden
                if min(val1_tx, val2_rx) == 0.0 and diff < ABS_TOLERANCE:
                    consensus = 0.0
                else:
                    consensus = (val1_tx + val2_rx) / 2.0

                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.95 # High but not 1.0
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.95
            else:
                # Suspect
                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
                consensus = (val1_tx + val2_rx) / 2.0
                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.5
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.5
        else:
            # External Link
            current_estimates[if1] = current_estimates.get(if1, {})
            current_estimates[if1]['tx'] = val1_tx
            estimate_confidence[if1] = estimate_confidence.get(if1, {})
            estimate_confidence[if1]['tx'] = 0.90
            external_flows.append((if1, 'tx'))

        # 2. Backward Flow: IF2 (TX) -> IF1 (RX)
        if if2:
            val2_tx = d2.get('tx_rate', 0.0)
            val1_rx = d1.get('rx_rate', 0.0)

            diff = abs(val2_tx - val1_rx)
            denom = max(val2_tx, val1_rx, 1.0)

            is_consistent = (diff < ABS_TOLERANCE) or ((diff / denom) < SYMMETRY_TOLERANCE)

            if is_consistent:
                if min(val2_tx, val1_rx) == 0.0 and diff < ABS_TOLERANCE:
                    consensus = 0.0
                else:
                    consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.95
                estimate_confidence[if1]['rx'] = 0.95
            else:
                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
                consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.5
                estimate_confidence[if1]['rx'] = 0.5
        else:
            val1_rx = d1.get('rx_rate', 0.0)
            current_estimates[if1]['rx'] = val1_rx
            estimate_confidence[if1]['rx'] = 0.90
            external_flows.append((if1, 'rx'))
>>>>>>> REPLACE
<<<<<<< SEARCH
    # --- Step 2: Iterative Bayesian Refinement ---

    def get_router_imbalance(rid):
        if_list = topology.get(rid, [])
        total_in = 0.0
        total_out = 0.0
        for iid in if_list:
            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
        return total_in - total_out, max(total_in, total_out, 1.0)

    for _ in range(ITERATIONS):
        updates = {}

        for flow_prob in suspect_flows:
            link_key = flow_prob['key']
            direction = flow_prob['dir']
            candidates = flow_prob['candidates']

            info = links[link_key]
            if direction == '1_to_2':
                src_if, dst_if = info['if1'], info['if2']
                val_src, val_dst = candidates[0], candidates[1]
            else:
                src_if, dst_if = info['if2'], info['if1']
                val_src, val_dst = candidates[0], candidates[1]

            router_src = if_to_router.get(src_if)
            router_dst = if_to_router.get(dst_if)

            hyps = [val_src, val_dst]
            scores = []

            for h_val in hyps:
                # Test Hypothesis
                old_tx = current_estimates[src_if]['tx']
                current_estimates[src_if]['tx'] = h_val
                imb_src, flow_src = get_router_imbalance(router_src)
                current_estimates[src_if]['tx'] = old_tx

                old_rx = current_estimates[dst_if]['rx']
                current_estimates[dst_if]['rx'] = h_val
                imb_dst, flow_dst = get_router_imbalance(router_dst)
                current_estimates[dst_if]['rx'] = old_rx

                # Likelihood
                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)

                # Score = 1.0 (perfect) -> 0.0 (bad)
                # Using exponential decay
                score_src = math.exp(-abs(imb_src) / sigma_src) if router_src else 1.0
                score_dst = math.exp(-abs(imb_dst) / sigma_dst) if router_dst else 1.0

                scores.append(score_src * score_dst)

            s1, s2 = scores[0], scores[1]
            total_s = s1 + s2 + 1e-20

            p1 = s1 / total_s
            p2 = s2 / total_s

            if p1 >= p2:
                winner_val = val_src
                win_p = p1
                fit_quality = math.sqrt(s1) # Geometric mean of src/dst fit
            else:
                winner_val = val_dst
                win_p = p2
                fit_quality = math.sqrt(s2)

            # Calibrated Confidence
            # Combines relative certainty (win_p) and absolute quality (fit_quality)
            # win_p ranges 0.5 to 1.0.
            # fit_quality ranges 0.0 to 1.0.
            conf = win_p * fit_quality
            conf = max(0.01, min(0.99, conf))

            updates[(src_if, 'tx')] = (winner_val, conf)
            updates[(dst_if, 'rx')] = (winner_val, conf)

        # Apply updates synchronously
        for (if_id, metric), (val, conf) in updates.items():
            current_estimates[if_id][metric] = val
            estimate_confidence[if_id][metric] = conf
=======
    # --- Step 2: Iterative Bayesian Refinement ---

    def get_router_imbalance(rid):
        if_list = topology.get(rid, [])
        total_in = 0.0
        total_out = 0.0
        for iid in if_list:
            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
        return total_in - total_out, max(total_in, total_out, 1.0)

    for _ in range(ITERATIONS):
        # 2a. Solve Internal Suspect Flows
        internal_updates = {}
        for flow_prob in suspect_flows:
            link_key = flow_prob['key']
            direction = flow_prob['dir']
            candidates = flow_prob['candidates']

            info = links[link_key]
            if direction == '1_to_2':
                src_if, dst_if = info['if1'], info['if2']
            else:
                src_if, dst_if = info['if2'], info['if1']

            router_src = if_to_router.get(src_if)
            router_dst = if_to_router.get(dst_if)

            # Candidates + Zero Flow (Phantom traffic check)
            hyps = list(set(candidates + [0.0]))
            scores = []

            for h_val in hyps:
                # Test Hypothesis
                old_tx = current_estimates[src_if]['tx']
                current_estimates[src_if]['tx'] = h_val
                imb_src, flow_src = get_router_imbalance(router_src)
                current_estimates[src_if]['tx'] = old_tx

                old_rx = current_estimates[dst_if]['rx']
                current_estimates[dst_if]['rx'] = h_val
                imb_dst, flow_dst = get_router_imbalance(router_dst)
                current_estimates[dst_if]['rx'] = old_rx

                # Likelihood with Non-Linear Noise Model (Sqrt scaling for Poisson noise)
                sigma_src = max(math.sqrt(flow_src), flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
                sigma_dst = max(math.sqrt(flow_dst), flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)

                score_src = math.exp(-abs(imb_src) / sigma_src) if router_src else 1.0
                score_dst = math.exp(-abs(imb_dst) / sigma_dst) if router_dst else 1.0

                # Prior: penalize 0.0 slightly if measurements are large to avoid collapse on noise
                prior = 1.0
                if h_val == 0.0 and max(candidates) > 5.0:
                    prior = 0.5

                scores.append(score_src * score_dst * prior)

            # Select Winner
            total_s = sum(scores) + 1e-20
            probs = [s / total_s for s in scores]

            best_idx = scores.index(max(scores))
            winner_val = hyps[best_idx]
            win_p = probs[best_idx]

            # Absolute quality (geometric mean of fit)
            # We normalize by removing the prior penalty for quality estimation
            raw_score = scores[best_idx] / (0.5 if (winner_val == 0.0 and max(candidates) > 5.0) else 1.0)
            fit_quality = math.sqrt(raw_score)

            conf = win_p * fit_quality
            conf = max(0.01, min(0.99, conf))

            internal_updates[(src_if, 'tx')] = (winner_val, conf)
            internal_updates[(dst_if, 'rx')] = (winner_val, conf)

        # Apply Internal Updates Immediately
        for (if_id, metric), (val, conf) in internal_updates.items():
            current_estimates[if_id][metric] = val
            estimate_confidence[if_id][metric] = conf

        # 2b. Refine External Flows (Edge Correction)
        external_updates = {}
        for if_id, metric in external_flows:
            rid = if_to_router.get(if_id)
            if not rid: continue

            # Current state (post-internal-correction)
            curr_val = current_estimates[if_id][metric]
            imb, flow = get_router_imbalance(rid)

            sigma = max(math.sqrt(flow), flow * CONSERVATION_TOLERANCE_PCT, 1.0)

            # Only intervene if significant imbalance
            if abs(imb) > sigma:
                # Calculate implied value that would fix imbalance
                # If metric is RX (In), Imb = In - Out. To fix, In needs to change by -Imb.
                # If metric is TX (Out), Imb = In - Out. To fix, Out needs to change by +Imb.

                if metric == 'rx':
                    target = curr_val - imb
                else: # tx
                    target = curr_val + imb

                target = max(0.0, target)

                # Hypotheses: [Measured, Target, 0.0]
                measured = telemetry[if_id].get(f'{metric}_rate', 0.0)
                hyps = list(set([measured, target, 0.0]))

                best_val = curr_val
                best_score = -1.0

                for h_val in hyps:
                    # Apply
                    old_val = current_estimates[if_id][metric]
                    current_estimates[if_id][metric] = h_val
                    new_imb, new_flow = get_router_imbalance(rid)
                    current_estimates[if_id][metric] = old_val

                    new_sigma = max(math.sqrt(new_flow), new_flow * CONSERVATION_TOLERANCE_PCT, 1.0)
                    score = math.exp(-abs(new_imb) / new_sigma)

                    # Priors
                    prior = 1.0
                    # Penalty for deviation from measurement
                    if abs(h_val - measured) > sigma:
                         prior *= 0.5

                    final_score = score * prior
                    if final_score > best_score:
                        best_score = final_score
                        best_val = h_val

                # Update if we found a better hypothesis
                conf = best_score
                external_updates[(if_id, metric)] = (best_val, conf)

        # Apply External Updates
        for (if_id, metric), (val, conf) in external_updates.items():
            current_estimates[if_id][metric] = val
            estimate_confidence[if_id][metric] = conf
>>>>>>> REPLACE
</DIFF>