<NAME>
config_update
</NAME>
<DESCRIPTION>
Update configuration to support locking mechanism and more iterations for convergence.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    # --- Configuration ---
    SYMMETRY_TOLERANCE = 0.02
    CONSERVATION_TOLERANCE_PCT = 0.02 # Tight conservation
    MIN_SIGNIFICANT_FLOW = 0.5
    ITERATIONS = 5
    MOMENTUM = 0.5

    # --- Helper Structures ---
=======
    # --- Configuration ---
    SYMMETRY_TOLERANCE = 0.02
    CONSERVATION_TOLERANCE_PCT = 0.02 # Tight conservation
    MIN_SIGNIFICANT_FLOW = 0.5
    ITERATIONS = 10 # More iterations for convergence with locking
    MOMENTUM = 0.6
    LOCKING_THRESHOLD = 0.85
    LOCKING_ITERATION = 4

    # --- Helper Structures ---
>>>>>>> REPLACE
</DIFF>

<NAME>
adaptive_locking_solver
</NAME>
<DESCRIPTION>
Implement Adaptive Locking Solver with Reliability-Weighted Sigma.
1. `calc_sigma` now scales with router reliability: unreliable routers get looser constraints (2.0x base sigma) to absorb noise, while reliable ones get tight constraints (1.0x).
2. Solver loop now includes a locking mechanism: high-confidence flows are locked mid-process and added to anchors.
3. Router reliability is dynamically recalculated each iteration based on the growing set of anchors/locked flows, implementing the "Device-Level Reliability" recommendation.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    def calc_sigma(flow_val):
        # Adaptive noise model
        return max(math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)

    # Pre-calculate anchor strength per router to weight external link logic
    router_anchor_ratios = {}
    for rid in topology:
        total_flow = 0.0
        anchor_flow = 0.0
        for iid in topology[rid]:
            if iid in estimates:
                # Approximate flow with initial estimates
                f = estimates[iid]['rx'] + estimates[iid]['tx']
                total_flow += f
                if (iid, 'rx') in anchors: anchor_flow += estimates[iid]['rx']
                if (iid, 'tx') in anchors: anchor_flow += estimates[iid]['tx']
        router_anchor_ratios[rid] = anchor_flow / max(total_flow, 1.0)

    # Track solver confidence (probability of winning hypothesis)
    solver_confidences = {}

    for _ in range(ITERATIONS):
        updates = []

        for flow in suspect_flows:
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                # Candidates: [Meas1, Meas2, Mean, 0.0]
                cands = [c for c in flow['cands'] if c >= 0]
                if len(cands) == 2:
                    v1, v2 = cands
                    # Add mean if difference is not massive (helps with noise)
                    if abs(v1 - v2) < max(v1, v2) * 0.2 + 5.0:
                        cands.append((v1 + v2) / 2.0)

                hyps = sorted(list(set(cands + [0.0])))

                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    # Likelihoods
                    imb_s, flow_s = get_router_state(r_src)
                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s)) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d)) if r_dst else 1.0

                    # Status-Aware Prior
                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down':
                            prior = 0.98  # Strong pull to zero if DOWN
                        else:
                            max_meas = max(flow['cands'])
                            # If UP and measuring high, zero is unlikely
                            if max_meas > 10.0: prior = 0.01
                            elif max_meas > 1.0: prior = 0.2
                    else:
                        # Slight preference for measured values over arbitrary ones
                        # (Gaussian around measurements)
                        min_dist = min([abs(h - c) for c in flow['cands']])
                        prior = math.exp(-min_dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)

                estimates[src]['tx'] = curr_tx
                estimates[dst]['rx'] = curr_rx

                total_score = sum(scores) + 1e-20
                probs = [s/total_score for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]

                # Confidence: probability mass near winner
                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((src, 'tx', win_val, win_prob))
                updates.append((dst, 'rx', win_val, win_prob))

            elif flow['type'] == 'external':
                if flow['src']: # TX
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['tx']
                    stat = flow.get('status_src')

                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val + imb)
                else: # RX
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['rx']
                    stat = flow.get('status_dst')

                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                anchor_ratio = router_anchor_ratios.get(r_id, 0.0)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    lik = math.exp(-abs(imb)/calc_sigma(rf)) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.98
                        elif meas > 10.0: prior = 0.01
                        else: prior = 0.5
                    elif abs(h - implied) < 1e-6:
                        # Conservation hypothesis
                        # Trust increases with anchor ratio
                        prior = 0.5 + (0.45 * anchor_ratio)
                    elif abs(h - meas) < 1e-6:
                        # Measurement hypothesis
                        # Trust decreases as anchor ratio increases (if conservation is reliable)
                        prior = 0.95 - (0.45 * anchor_ratio)

                    scores.append(lik * prior)

                estimates[if_id][metric] = curr_val

                total_score = sum(scores) + 1e-20
                probs = [s/total_score for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]

                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((if_id, metric, win_val, win_prob))

        # Apply Updates
        for if_id, metric, val, prob in updates:
            old = estimates[if_id][metric]
            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
            solver_confidences[(if_id, metric)] = prob
=======
    def calc_sigma(flow_val, reliability=0.5):
        # Adaptive noise model with reliability scaling
        # 1.5x factor accounts for higher variance in measurements
        base = max(1.5 * math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)
        # Unreliable routers get looser constraints (2.0 - reliability)
        return base * (2.0 - reliability)

    # Track solver confidence
    solver_confidences = {}

    # Locking state
    locked_indices = set()

    # Helper to calc reliability
    def get_router_reliability():
        rels = {}
        for rid in topology:
            total_flow = 0.0
            trusted_flow = 0.0
            for iid in topology[rid]:
                if iid in estimates:
                    f = estimates[iid]['rx'] + estimates[iid]['tx']
                    total_flow += f
                    if (iid, 'rx') in anchors: trusted_flow += estimates[iid]['rx']
                    if (iid, 'tx') in anchors: trusted_flow += estimates[iid]['tx']
            rels[rid] = trusted_flow / max(total_flow, 1.0)
        return rels

    for iter_idx in range(ITERATIONS):
        router_reliability = get_router_reliability()
        updates = []
        new_locks = []

        # Enable locking in middle iterations
        can_lock = (iter_idx >= LOCKING_ITERATION)

        for f_idx, flow in enumerate(suspect_flows):
            if f_idx in locked_indices: continue

            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                rel_src = router_reliability.get(r_src, 0.5)
                rel_dst = router_reliability.get(r_dst, 0.5)

                # Candidates
                cands = [c for c in flow['cands'] if c >= 0]
                if len(cands) == 2:
                    v1, v2 = cands
                    if abs(v1 - v2) < max(v1, v2) * 0.2 + 5.0:
                        cands.append((v1 + v2) / 2.0)

                hyps = sorted(list(set(cands + [0.0])))
                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    imb_s, flow_s = get_router_state(r_src)
                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s, rel_src)) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d, rel_dst)) if r_dst else 1.0

                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down': prior = 0.98
                        else:
                            max_meas = max(flow['cands'])
                            if max_meas > 10.0: prior = 0.01
                            elif max_meas > 1.0: prior = 0.2
                    else:
                        min_dist = min([abs(h - c) for c in flow['cands']])
                        prior = math.exp(-min_dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)

                estimates[src]['tx'] = curr_tx
                estimates[dst]['rx'] = curr_rx

                total = sum(scores) + 1e-20
                probs = [s/total for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                win_prob = sum(p for i, p in enumerate(probs) if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((src, 'tx', win_val, win_prob))
                updates.append((dst, 'rx', win_val, win_prob))

                if can_lock and win_prob > LOCKING_THRESHOLD:
                    new_locks.append(f_idx)
                    # Implicitly trusted for next iter
                    anchors.add((src, 'tx'))
                    anchors.add((dst, 'rx'))

            elif flow['type'] == 'external':
                if flow['src']:
                    if_id = flow['src']; metric = 'tx'; meas = flow['cands'][0]
                    r_id = if_to_router.get(if_id)
                    curr = estimates[if_id]['tx']
                    stat = flow.get('status_src')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr + imb)
                else:
                    if_id = flow['dst']; metric = 'rx'; meas = flow['cands'][0]
                    r_id = if_to_router.get(if_id)
                    curr = estimates[if_id]['rx']
                    stat = flow.get('status_dst')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                rel = router_reliability.get(r_id, 0.0)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    lik = math.exp(-abs(imb)/calc_sigma(rf, rel)) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.98
                        elif meas > 10.0: prior = 0.01
                        else: prior = 0.5
                    elif abs(h - implied) < 1e-6:
                        # Trust Conservation more if router is reliable
                        prior = 0.5 + (0.45 * rel)
                    elif abs(h - meas) < 1e-6:
                        # Trust Measurement more if router is unreliable
                        prior = 0.95 - (0.45 * rel)

                    scores.append(lik * prior)

                estimates[if_id][metric] = curr

                total = sum(scores) + 1e-20
                probs = [s/total for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                win_prob = sum(p for i, p in enumerate(probs) if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((if_id, metric, win_val, win_prob))

        # Apply Updates
        for if_id, metric, val, prob in updates:
            old = estimates[if_id][metric]
            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
            solver_confidences[(if_id, metric)] = prob

        # Apply locks
        for idx in new_locks:
            locked_indices.add(idx)
>>>>>>> REPLACE
</DIFF>

<NAME>
harmonic_calibration
</NAME>
<DESCRIPTION>
Upgrade confidence calibration to use Harmonic Mean between Solver Probability and Router Fit. This strictly penalizes cases where either metric is low, ensuring better calibration than a weighted average. Also integrates the dynamic reliability scores into the final fit check.
</DESCRIPTION>
<DIFF>
<<<<<<< SEARCH
    # Pre-calculate final router fits
    router_fits = {}
    for rid in topology:
        imb, flow = get_router_state(rid)
        sigma = calc_sigma(flow)
        fit = math.exp(-abs(imb) / sigma)
        router_fits[rid] = fit

    for if_id, data in telemetry.items():
        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_status = data.get('interface_status', 'unknown')

        rep_rx = estimates[if_id]['rx']
        rep_tx = estimates[if_id]['tx']

        rid = if_to_router.get(if_id)
        r_fit = router_fits.get(rid, 0.8) # Default 0.8 for unknown router

        # Confidence Calculation
        def calc_conf(metric, rep_val, orig_val):
            if (if_id, metric) in anchors: return 0.95

            # Retrieve solver certainty
            sol_prob = solver_confidences.get((if_id, metric), 0.5)

            # Combine solver certainty (relative win) with router fit (absolute check)
            # If solver was sure (0.9) and fit is good (0.9), conf -> High
            # If solver was sure (0.9) but fit is bad (0.5), conf -> Medium/Low (Something is wrong elsewhere)
            # If solver was unsure (0.5), conf -> Low regardless of fit

            combined = sol_prob * (0.3 + 0.7 * r_fit)

            # Bonus if we didn't have to change much (validation)
            if abs(rep_val - orig_val) < max(orig_val * 0.1, 1.0):
                combined = max(combined, 0.8 * r_fit + 0.1)

            return combined
=======
    # Final Router Stats
    final_reliability = get_router_reliability()
    router_fits = {}
    for rid in topology:
        imb, flow = get_router_state(rid)
        rel = final_reliability.get(rid, 0.5)
        # Strict sigma for final fit check
        sigma = calc_sigma(flow, rel)
        fit = math.exp(-abs(imb) / sigma)
        router_fits[rid] = fit

    for if_id, data in telemetry.items():
        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_status = data.get('interface_status', 'unknown')

        rep_rx = estimates[if_id]['rx']
        rep_tx = estimates[if_id]['tx']

        rid = if_to_router.get(if_id)
        r_fit = router_fits.get(rid, 0.8)

        def calc_conf(metric, rep_val, orig_val):
            if (if_id, metric) in anchors: return 0.98

            sol_prob = solver_confidences.get((if_id, metric), 0.5)

            # Harmonic Mean of Solver Probability and Router Fit
            # Requires both to be high for high confidence
            h_mean = 2 * (sol_prob * r_fit) / (sol_prob + r_fit + 1e-9)

            # Bonus for validating measurement (Small Repair)
            if abs(rep_val - orig_val) < max(orig_val * 0.05, 1.0):
                return max(h_mean, 0.85 * r_fit + 0.1)
            else:
                return h_mean
>>>>>>> REPLACE
</DIFF>