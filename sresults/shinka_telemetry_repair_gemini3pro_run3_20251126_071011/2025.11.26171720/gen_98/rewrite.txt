# EVOLVE-BLOCK-START
"""
recursive_trust_consensus
Implements a recursive trust model where router reliability (Anchor Score) propagates to neighbors.
Features:
- Phantom Prior Decay: Continuous penalty for zero-hypotheses based on alternative signal magnitude.
- Neighbor Trust: Peer signals are weighted by the global reliability score of the neighbor's router.
- Trust Transfer: Reliable routers impose stricter flow constraints on edge links.
"""
import math
from typing import Dict, Any, Tuple, List

def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                             topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
    
    # --- Configuration ---
    REL_TOL = 0.02
    ABS_TOL = 0.5
    ITERATIONS = 5
    
    # --- Helper Functions ---
    def get_sigma(val: float) -> float:
        """Adaptive standard deviation for Gaussian kernels."""
        return max(ABS_TOL, abs(val) * REL_TOL)

    def gaussian_score(x: float, target: float, sigma: float) -> float:
        """Unnormalized Gaussian Likelihood."""
        if target is None: return 0.0
        diff = abs(x - target)
        return math.exp(-0.5 * (diff / sigma) ** 2)

    def is_zero(val: float) -> bool:
        return val < ABS_TOL

    # --- Phase 1: Initialization & Status Repair ---
    state = {}
    
    # Map interfaces to routers for fast lookup
    router_map = {}
    for r, ifs in topology.items():
        for i in ifs:
            router_map[i] = r

    for if_id, data in telemetry.items():
        s_rx = float(data.get('rx_rate', 0.0))
        s_tx = float(data.get('tx_rate', 0.0))
        s_stat = data.get('interface_status', 'unknown')
        
        peer_id = data.get('connected_to')
        has_peer = False
        p_rx, p_tx, p_stat = 0.0, 0.0, 'unknown'
        
        if peer_id and peer_id in telemetry:
            has_peer = True
            p_data = telemetry[peer_id]
            p_rx = float(p_data.get('rx_rate', 0.0))
            p_tx = float(p_data.get('tx_rate', 0.0))
            p_stat = p_data.get('interface_status', 'unknown')

        # Traffic Analysis: Activity on any side suggests UP
        traffic_active = (s_rx > ABS_TOL or s_tx > ABS_TOL or 
                          p_rx > ABS_TOL or p_tx > ABS_TOL)
        
        final_stat = s_stat
        stat_conf = 1.0
        
        # Robust Status Logic
        if s_stat == 'down' and traffic_active:
            final_stat = 'up'
            stat_conf = 0.95
        elif s_stat == 'up' and not traffic_active:
            # If silent and peer is explicitly down, likely down.
            if p_stat == 'down':
                final_stat = 'down'
                stat_conf = 0.90
            
        # Initial Value Estimation
        if final_stat == 'down':
            est_rx, est_tx = 0.0, 0.0
        else:
            # Prefer Peer (Link Symmetry R3) as starting point
            est_rx = p_tx if has_peer else s_rx
            est_tx = p_rx if has_peer else s_tx
            
        state[if_id] = {
            's_rx': s_rx, 's_tx': s_tx,
            'p_rx': p_rx, 'p_tx': p_tx,
            'est_rx': est_rx, 'est_tx': est_tx,
            'status': final_stat,
            'stat_conf': stat_conf,
            'orig_stat': s_stat,
            'has_peer': has_peer,
            'peer_id': peer_id
        }

    # --- Phase 2: Recursive Trust Consensus ---
    
    # Initialize Global Router Reliability (0.5 = Neutral)
    router_reliability = {r: 0.5 for r in topology}
    
    for iteration in range(ITERATIONS):
        # 1. Update Router Reliability (Anchor Analysis)
        current_metrics = {}
        
        for r_id, if_list in topology.items():
            valid_ifs = [i for i in if_list if i in state]
            if not valid_ifs: continue
            
            sum_in, sum_out = 0.0, 0.0
            
            # Weighted Agreement Calculation
            total_weight = 0.0
            weighted_agreement = 0.0
            
            for i in valid_ifs:
                d = state[i]
                sum_in += d['est_rx']
                sum_out += d['est_tx']
                
                # Weight by magnitude (log scale)
                # Larger flows have higher impact on router reputation
                mag = max(d['est_rx'], d['est_tx'], 1.0)
                weight = math.log(10.0 + mag)
                
                # Agreement Score
                ag = 0.5
                if d['has_peer']:
                    # Strong signal: Link Symmetry
                    s_rx = get_sigma(d['est_rx'])
                    s_tx = get_sigma(d['est_tx'])
                    ag_rx = gaussian_score(d['est_rx'], d['p_tx'], s_rx)
                    ag_tx = gaussian_score(d['est_tx'], d['p_rx'], s_tx)
                    ag = (ag_rx + ag_tx) / 2.0
                else:
                    # Weak signal: Self Consistency
                    s_rx = get_sigma(d['est_rx'])
                    s_tx = get_sigma(d['est_tx'])
                    ag_rx = gaussian_score(d['est_rx'], d['s_rx'], s_rx)
                    ag_tx = gaussian_score(d['est_tx'], d['s_tx'], s_tx)
                    ag = (ag_rx + ag_tx) / 2.0 * 0.8 # Discount isolated
                
                weighted_agreement += ag * weight
                total_weight += weight
                
            reliability = weighted_agreement / max(total_weight, 1.0)
            
            # Balance Score
            imb = abs(sum_in - sum_out)
            mag = max(sum_in, sum_out, 1.0)
            balance = math.exp(- (imb / (mag * 0.05))**2 )
            
            current_metrics[r_id] = {
                'sin': sum_in, 'sout': sum_out,
                'rel': reliability, 
                'bal': balance
            }
            # Update global map for neighbor lookups
            router_reliability[r_id] = reliability

        # 2. Update Estimates
        for if_id, d in state.items():
            if d['status'] == 'down': continue
            
            local_r = router_map.get(if_id)
            r_info = current_metrics.get(local_r)
            
            # Lookup Neighbor Reliability
            neighbor_rel = 0.5
            if d['has_peer']:
                peer_if = d['peer_id']
                remote_r = router_map.get(peer_if)
                if remote_r:
                    neighbor_rel = router_reliability.get(remote_r, 0.5)
            
            def solve(current, s_val, p_val, is_rx):
                f_val = None
                f_weight = 0.0
                f_sigma_scale = 1.0
                
                if r_info:
                    # Flow Target
                    if is_rx:
                        others = r_info['sin'] - current
                        f_val = max(0.0, r_info['sout'] - others)
                    else:
                        others = r_info['sout'] - current
                        f_val = max(0.0, r_info['sin'] - others)
                        
                    # Weighting: "Trust Transfer"
                    # If router is highly reliable, flow is authoritative
                    base_w = 2.0
                    if r_info['rel'] > 0.85: base_w = 3.5 # Strong authority
                    
                    f_weight = base_w * r_info['rel'] * (0.3 + 0.7 * r_info['bal'])
                    
                    # Adaptive Sigma
                    # Relax constraints if router is currently unbalanced
                    f_sigma_scale = 1.0 + 3.0 * (1.0 - r_info['bal'])
                
                # Dynamic Source Weights
                # Trust Self more if local router is reliable
                w_self = 0.7 + 0.3 * (r_info['rel'] if r_info else 0.5)
                # Trust Peer more if neighbor router is reliable
                w_peer = 0.9 + 0.2 * neighbor_rel
                
                # Hypothesis Generation
                candidates = [s_val, 0.0]
                if d['has_peer']: candidates.append(p_val)
                if f_val is not None: candidates.append(f_val)
                # Cluster mean for noise
                if d['has_peer']:
                    candidates.append((s_val + p_val)/2.0)
                
                unique_cands = sorted(list(set(candidates)))
                max_cand = max(unique_cands) if unique_cands else 0.0
                
                best_val = current
                best_score = -1.0
                
                for cand in unique_cands:
                    sigma = get_sigma(cand)
                    
                    l_s = w_self * gaussian_score(cand, s_val, sigma)
                    l_p = w_peer * gaussian_score(cand, p_val, sigma) if d['has_peer'] else 0.0
                    
                    l_f = 0.0
                    if f_val is not None:
                        l_f = f_weight * gaussian_score(cand, f_val, sigma * f_sigma_scale)
                        
                    score = l_s + l_p + l_f
                    
                    # Continuous Phantom Prior Decay
                    # Penalize zero hypothesis based on magnitude of alternatives
                    if is_zero(cand):
                        # Decay function: 1 / (1 + (mag/8)^2)
                        # e.g., Mag=80 -> 1/101 ~ 0.01 penalty
                        penalty = 1.0 / (1.0 + (max_cand / 8.0)**2)
                        
                        flow_zero = (f_val is not None and f_val < ABS_TOL)
                        if not flow_zero:
                            score *= penalty
                        else:
                            # If flow confirms zero, penalty is lighter but still present if peers contradict
                            score *= math.sqrt(penalty)
                            
                    if score > best_score:
                        best_score = score
                        best_val = cand
                        
                return best_val

            new_rx = solve(d['est_rx'], d['s_rx'], d['p_tx'], True)
            new_tx = solve(d['est_tx'], d['s_tx'], d['p_rx'], False)
            
            d['est_rx'] = 0.5 * d['est_rx'] + 0.5 * new_rx
            d['est_tx'] = 0.5 * d['est_tx'] + 0.5 * new_tx

    # --- Phase 3: Final Output & Calibration ---
    results = {}
    
    # Final Context Recalculation
    final_metrics = {}
    for r_id, if_list in topology.items():
        valid_ifs = [i for i in if_list if i in state]
        if not valid_ifs: continue
        sin = sum(state[i]['est_rx'] for i in valid_ifs)
        sout = sum(state[i]['est_tx'] for i in valid_ifs)
        
        w_ag = 0.0
        tot_w = 0.0
        for i in valid_ifs:
            d = state[i]
            mag = max(d['est_rx'], d['est_tx'], 1.0)
            w = math.log(10.0 + mag)
            ag = 0.5
            if d['has_peer']:
                ag = (gaussian_score(d['est_rx'], d['p_tx'], get_sigma(d['est_rx'])) + 
                      gaussian_score(d['est_tx'], d['p_rx'], get_sigma(d['est_tx']))) / 2.0
            w_ag += ag * w
            tot_w += w
        
        rel = w_ag / max(tot_w, 1.0)
        bal = math.exp(-(abs(sin-sout)/max(sin,sout,1.0)*20)**2)
        final_metrics[r_id] = {'sin': sin, 'sout': sout, 'rel': rel, 'bal': bal}
        router_reliability[r_id] = rel

    for if_id, d in state.items():
        res = telemetry[if_id].copy()
        
        if d['status'] == 'down':
            crx = 1.0 if d['s_rx'] <= ABS_TOL else 0.95
            ctx = 1.0 if d['s_tx'] <= ABS_TOL else 0.95
            res['rx_rate'] = (d['s_rx'], 0.0, crx)
            res['tx_rate'] = (d['s_tx'], 0.0, ctx)
        else:
            local_r = router_map.get(if_id)
            r_info = final_metrics.get(local_r)
            
            neighbor_rel = 0.5
            if d['has_peer']:
                peer_if = d['peer_id']
                remote_r = router_map.get(peer_if)
                neighbor_rel = router_reliability.get(remote_r, 0.5)

            def calibrate(val, s_val, p_val, is_rx):
                # Reconstruct Inputs
                f_val = None
                f_weight = 0.0
                f_sigma_scale = 1.0
                w_self = 0.7 + 0.3 * (r_info['rel'] if r_info else 0.5)
                w_peer = 0.9 + 0.2 * neighbor_rel
                
                if r_info:
                    if is_rx: target = r_info['sout'] - (r_info['sin'] - d['est_rx'])
                    else:     target = r_info['sin'] - (r_info['sout'] - d['est_tx'])
                    f_val = max(0.0, target)
                    
                    base_w = 2.0
                    if r_info['rel'] > 0.85: base_w = 3.5
                    f_weight = base_w * r_info['rel'] * (0.3 + 0.7 * r_info['bal'])
                    f_sigma_scale = 1.0 + 3.0 * (1.0 - r_info['bal'])
                
                # Hyps
                hyps = {val, s_val, 0.0}
                if d['has_peer']: hyps.add(p_val)
                if f_val is not None: hyps.add(f_val)
                if d['has_peer']: hyps.add((s_val + p_val)/2.0)
                
                max_cand = max(hyps)
                sigma_win = get_sigma(val)
                
                total_mass = 0.0
                winner_mass = 0.0
                
                for h in hyps:
                    sigma = get_sigma(h)
                    l_s = w_self * gaussian_score(h, s_val, sigma)
                    l_p = w_peer * gaussian_score(h, p_val, sigma) if d['has_peer'] else 0.0
                    l_f = 0.0
                    if f_val is not None:
                        l_f = f_weight * gaussian_score(h, f_val, sigma * f_sigma_scale)
                    
                    score = l_s + l_p + l_f
                    
                    if is_zero(h):
                        penalty = 1.0 / (1.0 + (max_cand / 8.0)**2)
                        flow_zero = (f_val is not None and f_val < ABS_TOL)
                        if not flow_zero: score *= penalty
                        else: score *= math.sqrt(penalty)
                    
                    total_mass += score
                    if abs(h - val) <= sigma_win:
                        winner_mass += score
                        
                if total_mass < 1e-9: return 0.5
                prob = winner_mass / total_mass
                
                # Support Calibration
                peer_match = d['has_peer'] and abs(val - p_val) <= sigma_win
                flow_match = f_val is not None and abs(val - f_val) <= (sigma_win * f_sigma_scale)
                
                # Cap confidence based on support type
                if not peer_match and not flow_match:
                    prob = min(prob, 0.70)
                elif not peer_match and flow_match:
                    # Flow-only repair: limit based on router reliability
                    limit = 0.7 + 0.3 * (r_info['rel'] if r_info else 0.0)
                    prob = min(prob, limit)
                elif peer_match and not flow_match:
                    # Peer-only repair: strong but not perfect
                    prob = min(prob, 0.90)
                
                return max(0.5, min(1.0, prob))

            conf_rx = calibrate(d['est_rx'], d['s_rx'], d['p_tx'], True)
            conf_tx = calibrate(d['est_tx'], d['s_tx'], d['p_rx'], False)
            
            res['rx_rate'] = (d['s_rx'], d['est_rx'], conf_rx)
            res['tx_rate'] = (d['s_tx'], d['est_tx'], conf_tx)
            
        res['interface_status'] = (d['orig_stat'], d['status'], d['stat_conf'])
        results[if_id] = res

    return results