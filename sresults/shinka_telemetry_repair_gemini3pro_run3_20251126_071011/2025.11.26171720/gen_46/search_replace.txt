To improve the network telemetry repair algorithm, I propose an **Iterative Trusted Consensus** model. This builds upon the previous logic but introduces a formal "Trust Score" for every interface that evolves during the repair iterations.

The key innovations are:
1.  **Trust Tracking**: Instead of just estimating values, we estimate the trustworthiness of each interface (0.0 to 1.0). Initial trust is high if `Self` matches `Peer`, and low otherwise.
2.  **Trusted Flow Calculation**: When calculating the flow conservation target for an interface, we weight the reliability of that target by the *average trust* of the other interfaces on the router. This handles the "bad apple" problem where one bad interface makes the whole router look unbalanced. If the neighbors are trusted, the flow target becomes a strong signal that can override a faulty `Self` or `Peer`.
3.  **Weighted Voting Arbitration**: Instead of complex if/else logic, we use a weighted clustering approach. `Peer` has higher weight than `Self`. `Flow` has a dynamic weight based on neighbor trust. This allows a highly trusted neighborhood to correct an external link (which has no peer) by outvoting the local measurement.
4.  **Momentum**: Updates to estimates and trust scores use a 50/50 momentum factor to ensure stability across iterations.

This approach specifically addresses the "External Link" weakness and improves confidence calibration by linking it directly to the consensus quality.

<NAME>
iterative_trusted_consensus
</NAME>

<DESCRIPTION>
I will implement an Iterative Trusted Consensus algorithm.
Key changes:
1.  **Trust Tracking**: Each interface maintains a `trust` score (0.0-1.0) along with its value estimate. Initial trust is based on Peer agreement.
2.  **Trusted Flow Calculation**: The flow target for an interface is weighted by the average trust of the *other* interfaces on the router. This prevents low-confidence signals from polluting the flow target, while allowing high-confidence neighbors to correct a faulty interface.
3.  **Adaptive Voting**: In the arbitration phase, we cluster inputs (Self, Peer, Flow) based on their values and weights.
    *   Self Weight: 0.6 (base)
    *   Peer Weight: 1.2 (stronger)
    *   Flow Weight: `neighbor_trust * 1.5` (can override Self and Peer if neighbors are very trusted).
4.  **Zero-Flow Hypothesis**: I will implicitly handle the "Zero" case by allowing the Flow target (if trusted) to override phantom traffic, as trusted neighbors summing to 0 will produce a strong 0 flow target.
5.  **Momentum**: Updates to estimates and trust scores use a momentum factor (0.5) to ensure stability.

This addresses the "External Link" issue: if an external link is connected to a router with high-trust internal links, the `neighbor_trust` will be high, giving the Flow signal enough weight to correct the external link if it violates conservation.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                             topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
    """
    Repairs telemetry using an Iterative Calibrated Consensus model.

    Strategy:
    1. Initial Guess: Based on Link Symmetry (Peer > Self).
    2. Iterative Refinement (2 Passes):
       - Calculate Flow Targets for each interface based on current estimates of neighbors.
       - Update estimates by arbitrating between Self, Peer, and Flow.
       - This allows Flow Conservation to correct bad initial estimates (e.g., dead peer)
         that initially make the router appear unbalanced.
    3. Final Arbitration: Produces value and confidence score based on consensus quality.
    """

    # --- Configuration ---
    REL_TOL = 0.02  # 2% Relative Tolerance
    ABS_TOL = 0.5   # 0.5 Mbps Noise Floor

    results = {}

    # --- Phase 1: Status Normalization & Initialization ---
    working_state = {}

    for if_id, data in telemetry.items():
        # Extract Signals
        s_rx = float(data.get('rx_rate', 0.0))
        s_tx = float(data.get('tx_rate', 0.0))
        s_status = data.get('interface_status', 'unknown')

        peer_id = data.get('connected_to')
        has_peer = False
        p_rx, p_tx, p_status = 0.0, 0.0, 'unknown'

        if peer_id and peer_id in telemetry:
            has_peer = True
            p_data = telemetry[peer_id]
            p_rx = float(p_data.get('rx_rate', 0.0))
            p_tx = float(p_data.get('tx_rate', 0.0))
            p_status = p_data.get('interface_status', 'unknown')

        # Status Repair
        has_traffic = (s_rx > ABS_TOL or s_tx > ABS_TOL or
                       p_rx > ABS_TOL or p_tx > ABS_TOL)

        final_status = s_status
        status_conf = 1.0

        if s_status == 'down' and has_traffic:
            final_status = 'up'
            status_conf = 0.95
        elif s_status == 'up' and not has_traffic and p_status == 'down':
            final_status = 'down'
            status_conf = 0.90

        # Initial Estimates (Prefer Peer, else Self)
        # Note: We rely on iteration to fix these if Peer is wrong but Flow is right.
        if final_status == 'down':
            est_rx, est_tx = 0.0, 0.0
        else:
            # Simple initial guess: Trust Peer if available, else Self
            est_rx = p_tx if has_peer else s_rx
            est_tx = p_rx if has_peer else s_tx

        working_state[if_id] = {
            's_rx': s_rx, 's_tx': s_tx,
            'p_rx': p_rx, 'p_tx': p_tx,
            'est_rx': est_rx, 'est_tx': est_tx,
            'status': final_status, 'status_conf': status_conf,
            'orig_status': s_status,
            'has_peer': has_peer
        }

    # --- Phase 2: Iterative Refinement ---
    # We refine estimates in a loop to resolve circular dependencies in flow calculation.
    # Increased iterations and momentum ensure stability.

    for iteration in range(3):
        # 1. Calculate Router Totals from current estimates
        router_totals = {}
        for r_id, if_list in topology.items():
            valid_ifs = [i for i in if_list if i in working_state]
            t_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
            t_out = sum(working_state[i]['est_tx'] for i in valid_ifs)

            imb = abs(t_in - t_out)
            mx = max(t_in, t_out, 1.0)

            # Continuous Flow Reliability (0.0 to 1.0)
            # Perfect at 0% imbalance, degrades to 0.0 at 10% imbalance
            ratio = imb / mx
            quality = max(0.0, 1.0 - (ratio * 10.0))
            router_totals[r_id] = {'in': t_in, 'out': t_out, 'quality': quality}

        # 2. Update Estimates based on Flow Context
        for if_id, d in working_state.items():
            r_id = telemetry[if_id].get('local_router')

            # Calculate Flow Hypothesis
            f_rx, f_tx, f_qual = d['est_rx'], d['est_tx'], 0.0

            if r_id and r_id in router_totals:
                rt = router_totals[r_id]
                f_qual = rt['quality']

                # Target RX = Total_Out - (Total_In - My_RX)
                other_rx = rt['in'] - d['est_rx']
                f_rx = max(0.0, rt['out'] - other_rx)

                # Target TX = Total_In - (Total_Out - My_TX)
                other_tx = rt['out'] - d['est_tx']
                f_tx = max(0.0, rt['in'] - other_tx)

            # Update Estimates using Arbitration
            if d['status'] == 'down':
                 d['est_rx'], d['est_tx'] = 0.0, 0.0
            else:
                # RX
                val_rx, conf_rx = arbitrate(
                    d['s_rx'], d['p_tx'], f_rx,
                    d['has_peer'], f_qual, REL_TOL, ABS_TOL
                )
                # Momentum update to dampen oscillations
                d['est_rx'] = 0.6 * d['est_rx'] + 0.4 * val_rx
                d['conf_rx'] = conf_rx # Store for final pass

                # TX
                val_tx, conf_tx = arbitrate(
                    d['s_tx'], d['p_rx'], f_tx,
                    d['has_peer'], f_qual, REL_TOL, ABS_TOL
                )
                d['est_tx'] = 0.6 * d['est_tx'] + 0.4 * val_tx
                d['conf_tx'] = conf_tx

    # --- Phase 3: Final Result Generation ---
    for if_id, d in working_state.items():
        res = telemetry[if_id].copy()

        if d['status'] == 'down':
            # High confidence if signal is actually quiet
            crx = 1.0 if d['s_rx'] <= ABS_TOL else 0.95
            ctx = 1.0 if d['s_tx'] <= ABS_TOL else 0.95
            res['rx_rate'] = (d['s_rx'], 0.0, crx)
            res['tx_rate'] = (d['s_tx'], 0.0, ctx)
        else:
            res['rx_rate'] = (d['s_rx'], d['est_rx'], d.get('conf_rx', 0.5))
            res['tx_rate'] = (d['s_tx'], d['est_tx'], d.get('conf_tx', 0.5))

        res['interface_status'] = (d['orig_status'], d['status'], d['status_conf'])
        results[if_id] = res

    return results

def arbitrate(v_self: float, v_peer: float, v_flow: float,
              has_peer: bool, flow_qual: float, rel_tol: float, abs_tol: float) -> Tuple[float, float]:
    """
    Arbitrates between signals using a Soft-Consensus model.
    Scales confidence based on agreement quality and source reliability.

    Args:
        flow_qual: 0.0 (unreliable) to 1.0 (perfectly balanced router)
    """

    def dist(a, b):
        if a is None or b is None: return 999.0
        diff = abs(a - b)
        if diff <= abs_tol: return 0.0
        return diff / (max(abs(a), abs(b), 1.0) * rel_tol)

    # Calculate Distances (0.0 = Perfect match, <=1.0 = Agree)
    d_sp = dist(v_self, v_peer) if has_peer else 999.0
    d_sf = dist(v_self, v_flow)
    d_pf = dist(v_peer, v_flow) if has_peer else 999.0

    # Flow Trust Threshold
    # We only trust flow for strict arbitration if it's reasonably reliable
    flow_is_good = flow_qual > 0.5

    # 1. Unanimous Agreement (S ≈ P ≈ F)
    if d_sp <= 1.0 and d_pf <= 1.0 and flow_is_good:
         avg = (v_self + v_peer + v_flow) / 3.0
         conf = 1.0 - 0.05 * max(d_sp, d_pf)
         return avg, max(0.9, conf)

    # 2. Self ≈ Peer (Flow Outlier or Bad)
    if d_sp <= 1.0:
         avg = (v_self + v_peer) / 2.0
         # If Flow is 'good' but strongly disagrees, slightly reduce confidence
         # This implies some risk that S&P are both wrong (unlikely) or Flow is wrong (likely)
         penalty = 0.05 if (flow_is_good and d_pf > 2.0) else 0.0
         conf = 0.95 - (0.1 * d_sp) - penalty
         return avg, max(0.8, conf)

    # 3. Peer ≈ Flow (Self Outlier)
    if has_peer and d_pf <= 1.0 and flow_is_good:
         avg = (v_peer + v_flow) / 2.0
         # Confidence depends on how good the flow calc is
         conf = 0.90 * flow_qual - (0.1 * d_pf)
         return avg, max(0.7, conf)

    # 4. Self ≈ Flow (Peer Outlier)
    if d_sf <= 1.0 and flow_is_good:
         avg = (v_self + v_flow) / 2.0
         conf = 0.85 * flow_qual - (0.1 * d_sf)
         return avg, max(0.7, conf)

    # 5. Fallbacks (No Consensus)

    # Edge Case: Phantom Traffic (Self/Peer > 0, Flow ≈ 0)
    if flow_qual > 0.8 and v_flow < abs_tol:
        return 0.0, 0.8

    if has_peer:
         return v_peer, 0.60

    if flow_is_good:
         # Edge link (no peer), trust Flow
         return v_flow, 0.70 * flow_qual

    return v_self, 0.50
=======
def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                             topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
    """
    Repairs telemetry using an Iterative Trusted Consensus model.

    Key Concepts:
    1. Trust Scores: Each interface maintains a 'trust' score (0.0-1.0) based on
       agreement with Peer and Flow.
    2. Trusted Flow: Flow targets are weighted by the trust of *other* interfaces.
       High-trust neighbors can force a correction on a low-trust interface.
    3. Weighted Voting: Arbitration uses weighted clustering of Self, Peer, and Flow.
    """

    # --- Configuration ---
    REL_TOL = 0.02
    ABS_TOL = 0.5

    results = {}
    working_state = {}

    # --- Phase 1: Initialization & Status Repair ---
    for if_id, data in telemetry.items():
        s_rx = float(data.get('rx_rate', 0.0))
        s_tx = float(data.get('tx_rate', 0.0))
        s_status = data.get('interface_status', 'unknown')

        peer_id = data.get('connected_to')
        has_peer = False
        p_rx, p_tx, p_status = 0.0, 0.0, 'unknown'
        if peer_id and peer_id in telemetry:
            has_peer = True
            p_data = telemetry[peer_id]
            p_rx = float(p_data.get('rx_rate', 0.0))
            p_tx = float(p_data.get('tx_rate', 0.0))
            p_status = p_data.get('interface_status', 'unknown')

        # Status Repair
        has_traffic = (s_rx > ABS_TOL or s_tx > ABS_TOL or p_rx > ABS_TOL or p_tx > ABS_TOL)
        final_status = s_status
        status_conf = 1.0

        if s_status == 'down' and has_traffic:
            final_status = 'up'
            status_conf = 0.95
        elif s_status == 'up' and not has_traffic and p_status == 'down':
            final_status = 'down'
            status_conf = 0.90

        # Initial Trust & Estimate
        # Start with a bias towards Peer (if available)
        trust = 0.5
        est_rx, est_tx = s_rx, s_tx

        if final_status == 'down':
            est_rx, est_tx = 0.0, 0.0
            trust = 1.0 # Confident in zero
        elif has_peer:
            # Check agreement
            diff_rx = abs(s_rx - p_tx)
            match_rx = diff_rx <= ABS_TOL or (diff_rx / max(abs(s_rx), abs(p_tx), 1.0)) <= REL_TOL

            if match_rx:
                est_rx = (s_rx + p_tx) / 2.0
                trust = 0.9
            else:
                est_rx = p_tx
                trust = 0.7 # Trust Peer more, but not fully since conflict exists

            # Similar logic for TX (checking against Peer RX)
            diff_tx = abs(s_tx - p_rx)
            match_tx = diff_tx <= ABS_TOL or (diff_tx / max(abs(s_tx), abs(p_rx), 1.0)) <= REL_TOL
            if match_tx:
                est_tx = (s_tx + p_rx) / 2.0
            else:
                est_tx = p_rx
            # Averaging trust for simplicity in this struct
            trust = 0.9 if (match_rx and match_tx) else 0.7
        else:
            trust = 0.5 # Isolated, low trust

        working_state[if_id] = {
            's_rx': s_rx, 's_tx': s_tx,
            'p_rx': p_rx, 'p_tx': p_tx,
            'est_rx': est_rx, 'est_tx': est_tx,
            'trust': trust,
            'status': final_status, 'status_conf': status_conf,
            'orig_status': s_status,
            'has_peer': has_peer
        }

    # --- Phase 2: Iterative Trusted Consensus ---
    for iteration in range(3):
        # 1. Calculate Router Stats (Totals & Trust Mass)
        router_stats = {}
        for r_id, if_list in topology.items():
            valid_ifs = [i for i in if_list if i in working_state]

            sum_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
            sum_out = sum(working_state[i]['est_tx'] for i in valid_ifs)

            # Calculate average trust of the router's interfaces
            total_trust = sum(working_state[i]['trust'] for i in valid_ifs)
            avg_trust = total_trust / max(len(valid_ifs), 1)

            router_stats[r_id] = {
                'sum_in': sum_in, 'sum_out': sum_out,
                'avg_trust': avg_trust,
                'count': len(valid_ifs)
            }

        # 2. Update Interfaces
        for if_id, d in working_state.items():
            if d['status'] == 'down': continue

            r_id = telemetry[if_id].get('local_router')

            # Flow Calculation
            f_rx, f_tx = d['est_rx'], d['est_tx']
            neighbor_trust = 0.0

            if r_id and r_id in router_stats:
                rs = router_stats[r_id]
                # To get trust of *others*, we subtract our contribution
                # (Approximation for performance)
                other_trust_sum = (rs['avg_trust'] * rs['count']) - d['trust']
                other_count = max(1, rs['count'] - 1)
                neighbor_trust = other_trust_sum / other_count

                # Flow Targets
                other_rx = rs['sum_in'] - d['est_rx']
                f_rx = max(0.0, rs['sum_out'] - other_rx)

                other_tx = rs['sum_out'] - d['est_tx']
                f_tx = max(0.0, rs['sum_in'] - other_tx)

            # Arbitrate RX
            new_rx, conf_rx = arbitrate_voting(
                d['s_rx'], d['p_tx'], f_rx,
                d['has_peer'], neighbor_trust, REL_TOL, ABS_TOL
            )
            # Soft Update
            d['est_rx'] = 0.5 * d['est_rx'] + 0.5 * new_rx

            # Arbitrate TX
            new_tx, conf_tx = arbitrate_voting(
                d['s_tx'], d['p_rx'], f_tx,
                d['has_peer'], neighbor_trust, REL_TOL, ABS_TOL
            )
            d['est_tx'] = 0.5 * d['est_tx'] + 0.5 * new_tx

            # Update Trust (Momentum)
            iter_trust = (conf_rx + conf_tx) / 2.0
            d['trust'] = 0.5 * d['trust'] + 0.5 * iter_trust

            # Store confidences for final output
            d['final_conf_rx'] = conf_rx
            d['final_conf_tx'] = conf_tx

    # --- Phase 3: Final Output ---
    for if_id, d in working_state.items():
        res = telemetry[if_id].copy()

        if d['status'] == 'down':
            crx = 1.0 if d['s_rx'] <= ABS_TOL else 0.95
            ctx = 1.0 if d['s_tx'] <= ABS_TOL else 0.95
            res['rx_rate'] = (d['s_rx'], 0.0, crx)
            res['tx_rate'] = (d['s_tx'], 0.0, ctx)
        else:
            res['rx_rate'] = (d['s_rx'], d['est_rx'], d.get('final_conf_rx', 0.5))
            res['tx_rate'] = (d['s_tx'], d['est_tx'], d.get('final_conf_tx', 0.5))

        res['interface_status'] = (d['orig_status'], d['status'], d['status_conf'])
        results[if_id] = res

    return results

def arbitrate_voting(v_self, v_peer, v_flow, has_peer, flow_weight, rel_tol, abs_tol):
    """
    Weighted Clustering Voting for Consensus.

    Weights:
    - Self: 0.6 (Base truth, but often noisy or broken)
    - Peer: 1.2 (Strong hardware indication)
    - Flow: 1.5 * flow_weight (Can override all if neighbors are highly trusted)
    """
    candidates = []

    # Add Self
    candidates.append({'val': v_self, 'w': 0.6, 'type': 'self'})

    # Add Peer
    if has_peer:
        candidates.append({'val': v_peer, 'w': 1.2, 'type': 'peer'})

    # Add Flow
    # Flow weight scales with the trust of the neighborhood
    w_flow = 1.5 * flow_weight
    # If neighborhood is untrusted, flow is weak (0.0). If trusted (0.9), flow is strong (1.35).
    candidates.append({'val': v_flow, 'w': w_flow, 'type': 'flow'})

    # Clustering
    clusters = []
    for cand in candidates:
        if cand['val'] is None: continue

        # Try to add to existing cluster
        best_cluster = None
        min_dist = float('inf')

        for cl in clusters:
            # Check compatibility using cluster centroid
            centroid = cl['val_sum'] / cl['w_sum']
            diff = abs(cand['val'] - centroid)
            limit = max(abs(cand['val']), abs(centroid), 1.0) * rel_tol

            if diff <= max(abs_tol, limit):
                if diff < min_dist:
                    min_dist = diff
                    best_cluster = cl

        if best_cluster:
            best_cluster['val_sum'] += cand['val'] * cand['w']
            best_cluster['w_sum'] += cand['w']
            best_cluster['members'].add(cand['type'])
        else:
            clusters.append({
                'val_sum': cand['val'] * cand['w'],
                'w_sum': cand['w'],
                'members': {cand['type']}
            })

    # Pick Winner
    winner = max(clusters, key=lambda c: c['w_sum'])
    final_val = winner['val_sum'] / winner['w_sum']

    # Calculate Confidence
    # Base confidence on who agreed
    m = winner['members']
    if 'peer' in m and 'self' in m:
        conf = 0.95
        if 'flow' in m: conf = 0.98
    elif 'peer' in m and 'flow' in m:
        conf = 0.90
    elif 'self' in m and 'flow' in m:
        conf = 0.85
    elif 'peer' in m:
        conf = 0.70
    elif 'flow' in m:
        # Trust flow only if it was heavily weighted
        conf = 0.6 + (0.3 * flow_weight)
    else:
        conf = 0.5

    return final_val, conf
>>>>>>> REPLACE
</DIFF>