<NAME>
adaptive_sigma_annealing_and_harmonic_conf
</NAME>

<DESCRIPTION>
1.  **Device Reliability & Adaptive Sigma**: Renamed `router_anchor_ratios` to `router_reliability` and moved calculation up. Implemented `calc_sigma` which scales noise tolerance based on reliability (unreliable routers get 2x variance) and iteration count (Temperature scaling: constraints tighten over time to force convergence).
2.  **Internal Flow Logic**: Updated to use the new `calc_sigma` with reliability and iteration parameters.
3.  **External Flow Logic**: Updated to use `router_reliability` to strongly weight priors. Reliable routers (>0.8) force 'Implied' conservation values; Unreliable routers force 'Measured' values.
4.  **Confidence Calibration**: Reverted to Harmonic Mean of `sol_prob` and `r_fit` to penalize cases where either the solver is uncertain OR the final router state is poor. This prevents overconfidence in "best-of-bad-options" repairs.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def calc_sigma(flow_val):
        # Increased noise tolerance from Momentum approach (1.5x)
        return max(1.5 * math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)

    # Pre-calculate anchor strength
    router_anchor_ratios = {}
    for rid in topology:
        total_flow = 0.0
        anchor_flow = 0.0
        for iid in topology[rid]:
            if iid in estimates:
                f = estimates[iid]['rx'] + estimates[iid]['tx']
                total_flow += f
                if (iid, 'rx') in anchors: anchor_flow += estimates[iid]['rx']
                if (iid, 'tx') in anchors: anchor_flow += estimates[iid]['tx']
        router_anchor_ratios[rid] = anchor_flow / max(total_flow, 1.0)

    solver_confidences = {}

    for _ in range(ITERATIONS):
=======
    # Pre-calculate anchor strength (Reliability)
    router_reliability = {}
    for rid in topology:
        total_flow = 0.0
        anchor_flow = 0.0
        for iid in topology[rid]:
            if iid in estimates:
                f = estimates[iid]['rx'] + estimates[iid]['tx']
                total_flow += f
                if (iid, 'rx') in anchors: anchor_flow += estimates[iid]['rx']
                if (iid, 'tx') in anchors: anchor_flow += estimates[iid]['tx']
        router_reliability[rid] = anchor_flow / max(total_flow, 1.0)

    def calc_sigma(flow_val, reliability, iteration):
        # Base noise model: 1.5x Sqrt (Poisson-like) + Linear factor
        base = max(1.5 * math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)

        # Reliability scaling: Reliable routers (1.0) get tighter constraints (1.0x)
        # Unreliable routers (0.0) get looser constraints (2.0x) to absorb unknown noise
        rel_factor = 2.0 - reliability

        # Annealing/Temperature: Sharpen constraints over iterations to force consensus
        # Starts at 1.0, decreases to ~0.5 by iter 5
        temp_factor = 1.0 / (1.0 + iteration * 0.2)

        return base * rel_factor * temp_factor

    solver_confidences = {}

    for iter_idx in range(ITERATIONS):
>>>>>>> REPLACE
<<<<<<< SEARCH
        for flow in suspect_flows:
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                # Candidates: Just measurements and 0. No mean (discrete choice logic).
                cands = [c for c in flow['cands'] if c >= 0]
                hyps = sorted(list(set(cands + [0.0])))

                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    # Likelihoods
                    imb_s, flow_s = get_router_state(r_src)
                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s)) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d)) if r_dst else 1.0

                    # Prior
                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down': prior = 0.98
                        else:
                             m_val = max(flow['cands'])
                             if m_val > 5.0: prior = 0.01
                             elif m_val > 1.0: prior = 0.2
                    else:
                        # Distance to nearest candidate
                        min_dist = min([abs(h - c) for c in flow['cands']])
                        # Gaussian decay
                        prior = math.exp(-min_dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)
=======
        for flow in suspect_flows:
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                rel_src = router_reliability.get(r_src, 0.5)
                rel_dst = router_reliability.get(r_dst, 0.5)

                # Candidates: Just measurements and 0. No mean (discrete choice logic).
                cands = [c for c in flow['cands'] if c >= 0]
                hyps = sorted(list(set(cands + [0.0])))

                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    # Likelihoods with Adaptive Sigma
                    imb_s, flow_s = get_router_state(r_src)
                    sig_s = calc_sigma(flow_s, rel_src, iter_idx)
                    score_s = math.exp(-abs(imb_s)/sig_s) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    sig_d = calc_sigma(flow_d, rel_dst, iter_idx)
                    score_d = math.exp(-abs(imb_d)/sig_d) if r_dst else 1.0

                    # Prior
                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down': prior = 0.98
                        else:
                             m_val = max(flow['cands'])
                             if m_val > 5.0: prior = 0.01
                             elif m_val > 1.0: prior = 0.2
                    else:
                        # Distance to nearest candidate
                        min_dist = min([abs(h - c) for c in flow['cands']])
                        # Gaussian decay
                        prior = math.exp(-min_dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)
>>>>>>> REPLACE
<<<<<<< SEARCH
            elif flow['type'] == 'external':
                if flow['src']: # TX
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['tx']
                    stat = flow.get('status_src')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val + imb)
                else: # RX
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['rx']
                    stat = flow.get('status_dst')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                anchor_ratio = router_anchor_ratios.get(r_id, 0.0)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    lik = math.exp(-abs(imb)/calc_sigma(rf)) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.98
                        elif meas > 10.0: prior = 0.01
                        else: prior = 0.5
                    elif abs(h - implied) < 1e-6:
                        # Conservation hypothesis
                        prior = 0.5 + (0.45 * anchor_ratio)
                    else:
                        # Measurement hypothesis (or close to it)
                        dist = abs(h - meas)
                        # Use Gaussian decay from Momentum approach
                        sig_meas = max(meas * 0.05, 2.0)
                        gauss = math.exp(-(dist**2)/(2 * sig_meas**2))

                        # Weight by inverse anchor ratio (trust measurement if router weak)
                        trust_meas = 0.95 - (0.45 * anchor_ratio)
                        prior = trust_meas * gauss

                    scores.append(lik * prior)
=======
            elif flow['type'] == 'external':
                if flow['src']: # TX
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['tx']
                    stat = flow.get('status_src')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val + imb)
                else: # RX
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['rx']
                    stat = flow.get('status_dst')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                rel = router_reliability.get(r_id, 0.5)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    sig = calc_sigma(rf, rel, iter_idx)
                    lik = math.exp(-abs(imb)/sig) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.98
                        elif meas > 10.0: prior = 0.01
                        else: prior = 0.5
                    elif abs(h - implied) < 1e-6:
                        # Conservation hypothesis: Trust proportional to router reliability
                        # Range: 0.1 (unreliable) to 0.95 (reliable)
                        prior = 0.1 + (0.85 * rel)
                    else:
                        # Measurement hypothesis
                        dist = abs(h - meas)
                        sig_meas = max(meas * 0.05, 2.0)
                        gauss = math.exp(-(dist**2)/(2 * sig_meas**2))

                        # Inverse trust: If router is unreliable, trust measurement more
                        trust_meas = 0.95 - (0.85 * rel)
                        prior = trust_meas * gauss

                    scores.append(lik * prior)
>>>>>>> REPLACE
<<<<<<< SEARCH
    # --- Step 3: Confidence & Status ---
    result = {}

    router_fits = {}
    for rid in topology:
        imb, flow = get_router_state(rid)
        fit = math.exp(-abs(imb) / calc_sigma(flow))
        router_fits[rid] = fit

    for if_id, data in telemetry.items():
        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_status = data.get('interface_status', 'unknown')

        rep_rx = estimates[if_id]['rx']
        rep_tx = estimates[if_id]['tx']

        rid = if_to_router.get(if_id)
        r_fit = router_fits.get(rid, 0.8)

        def calc_conf(metric, rep_val, orig_val):
            if (if_id, metric) in anchors: return 0.98 # Higher anchor confidence

            sol_prob = solver_confidences.get((if_id, metric), 0.5)

            # Harmonic-like combination: High confidence requires both Solver Certainty AND Good Router Fit
            # (Unless we just validated the measurement)

            combined = sol_prob * (0.2 + 0.8 * r_fit)

            # If we didn't change the value much, boost confidence
            # (Validation is easier than Repair)
            if abs(rep_val - orig_val) < max(orig_val * 0.05, 1.0):
                # Trust measurement + partial fit
                combined = max(combined, 0.85 * r_fit + 0.1)

            return max(0.01, min(0.99, combined))
=======
    # --- Step 3: Confidence & Status ---
    result = {}

    router_fits = {}
    for rid in topology:
        imb, flow = get_router_state(rid)
        # Use final iteration parameters (tightest sigma) for strict fit check
        rel = router_reliability.get(rid, 0.5)
        # Use base sigma (iter=0 for loose constraint) to not penalize small imbalances
        sig = calc_sigma(flow, rel, 0)
        fit = math.exp(-abs(imb) / sig)
        router_fits[rid] = fit

    for if_id, data in telemetry.items():
        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_status = data.get('interface_status', 'unknown')

        rep_rx = estimates[if_id]['rx']
        rep_tx = estimates[if_id]['tx']

        rid = if_to_router.get(if_id)
        r_fit = router_fits.get(rid, 0.8)

        def calc_conf(metric, rep_val, orig_val):
            if (if_id, metric) in anchors: return 0.98

            sol_prob = solver_confidences.get((if_id, metric), 0.5)

            # Harmonic Mean of Solver Probability and Router Fit
            # If solver is unsure (split vote) -> Low Conf
            # If router is imbalanced (bad fit) -> Low Conf
            h_mean = 2 * (sol_prob * r_fit) / (sol_prob + r_fit + 1e-9)

            # Bonus for validating measurement (Small Repair)
            if abs(rep_val - orig_val) < max(orig_val * 0.05, 1.0):
                return max(h_mean, 0.85 * r_fit + 0.1)
            else:
                return h_mean
>>>>>>> REPLACE
</DIFF>