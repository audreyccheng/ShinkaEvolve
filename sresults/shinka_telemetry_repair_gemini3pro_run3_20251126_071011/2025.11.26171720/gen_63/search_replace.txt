<NAME>
config_step1_optimization_tasks
</NAME>

<DESCRIPTION>
1. Update configuration to include ABS_TOLERANCE for low-flow handling.
2. Modify Step 1 to populate `optimization_tasks` which includes both internal suspect links AND external links. This ensures external links are also repaired using router conservation.
3. Use strict symmetry check (relative + absolute) to define anchors.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Configuration ---
    SYMMETRY_TOLERANCE = 0.02
    CONSERVATION_TOLERANCE_PCT = 0.03
    MIN_SIGNIFICANT_FLOW = 0.5
    ITERATIONS = 5

    # --- Helper Structures ---
=======
    # --- Configuration ---
    SYMMETRY_TOLERANCE = 0.02
    CONSERVATION_TOLERANCE_PCT = 0.03
    MIN_SIGNIFICANT_FLOW = 0.5
    ABS_TOLERANCE = 1.0
    ITERATIONS = 5

    # --- Helper Structures ---
>>>>>>> REPLACE
<<<<<<< SEARCH
    # --- Step 1: Initial Link Assessment ---
    # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
    # For suspect links, generate hypotheses.

    # Store current best estimates for RX and TX flow on every interface
    # structure: {if_id: {'rx': val, 'tx': val}}
    current_estimates = {}

    # Store reliability/confidence of these estimates
    # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
    estimate_confidence = {}

    # Suspect flows to solve: list of (link_key, metric_type ('rx_flow' or 'tx_flow'))
    # Note: 'rx_flow' for link (A,B) means A->B traffic (A TX, B RX).
    suspect_flows = []

    for link_key, info in links.items():
        if1 = info['if1']
        if2 = info['if2']

        d1 = telemetry[if1]
        d2 = telemetry[if2] if if2 else {}

        # Analyze Flow IF1 -> IF2 (IF1 TX, IF2 RX)
        val1_tx = d1.get('tx_rate', 0.0)
        val2_rx = d2.get('rx_rate', 0.0) if if2 else None

        if if2:
            # Internal Link: Check Symmetry
            denom = max(val1_tx, val2_rx, 1.0)
            diff = abs(val1_tx - val2_rx)

            if diff / denom < SYMMETRY_TOLERANCE:
                # Consistent
                consensus = (val1_tx + val2_rx) / 2.0
                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.95
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.95
            else:
                # Suspect
                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
                # Initialize with average but low confidence
                consensus = (val1_tx + val2_rx) / 2.0
                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.5
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.5
        else:
            # External Link: Trust local blindly for now (no peer to contradict)
            current_estimates[if1] = current_estimates.get(if1, {})
            current_estimates[if1]['tx'] = val1_tx
            estimate_confidence[if1] = estimate_confidence.get(if1, {})
            estimate_confidence[if1]['tx'] = 0.90 # Less confident than hardened links

        # Analyze Flow IF2 -> IF1 (IF2 TX, IF1 RX)
        if if2:
            val2_tx = d2.get('tx_rate', 0.0)
            val1_rx = d1.get('rx_rate', 0.0)

            denom = max(val2_tx, val1_rx, 1.0)
            diff = abs(val2_tx - val1_rx)

            if diff / denom < SYMMETRY_TOLERANCE:
                consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.95
                estimate_confidence[if1]['rx'] = 0.95
            else:
                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
                consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.5
                estimate_confidence[if1]['rx'] = 0.5
        else:
             # External RX
            val1_rx = d1.get('rx_rate', 0.0)
            current_estimates[if1]['rx'] = val1_rx
            estimate_confidence[if1]['rx'] = 0.90
=======
    # --- Step 1: Initial Link Assessment ---
    # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
    # For suspect links, generate hypotheses.

    # Store current best estimates for RX and TX flow on every interface
    # structure: {if_id: {'rx': val, 'tx': val}}
    current_estimates = {}

    # Store reliability/confidence of these estimates
    # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
    estimate_confidence = {}

    # Optimization tasks: list of dicts describing flows to solve
    optimization_tasks = []

    for link_key, info in links.items():
        if1 = info['if1']
        if2 = info['if2']

        d1 = telemetry[if1]
        d2 = telemetry[if2] if if2 else {}

        # 1. Forward Flow: IF1 (TX) -> IF2 (RX)
        val1_tx = d1.get('tx_rate', 0.0)

        if if2:
            val2_rx = d2.get('rx_rate', 0.0)

            # Check Symmetry
            denom = max(val1_tx, val2_rx, 1.0)
            diff = abs(val1_tx - val2_rx)

            # Consistent if relative error small OR absolute error small (noise floor)
            is_consistent = (diff / denom < SYMMETRY_TOLERANCE) or (diff < ABS_TOLERANCE)

            if is_consistent:
                # Consistent: Average
                consensus = (val1_tx + val2_rx) / 2.0
                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.95
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.95
            else:
                # Suspect
                optimization_tasks.append({
                    'type': 'internal',
                    'src': if1, 'dst': if2,
                    'measured': [val1_tx, val2_rx]
                })
                # Init with average
                consensus = (val1_tx + val2_rx) / 2.0
                current_estimates[if1] = current_estimates.get(if1, {})
                current_estimates[if1]['tx'] = consensus
                current_estimates[if2] = current_estimates.get(if2, {})
                current_estimates[if2]['rx'] = consensus

                estimate_confidence[if1] = estimate_confidence.get(if1, {})
                estimate_confidence[if1]['tx'] = 0.5
                estimate_confidence[if2] = estimate_confidence.get(if2, {})
                estimate_confidence[if2]['rx'] = 0.5
        else:
            # External TX
            current_estimates[if1] = current_estimates.get(if1, {})
            current_estimates[if1]['tx'] = val1_tx
            estimate_confidence[if1] = estimate_confidence.get(if1, {})
            estimate_confidence[if1]['tx'] = 0.8 # Lower confidence so solver touches it

            optimization_tasks.append({
                'type': 'external',
                'if_id': if1, 'metric': 'tx',
                'measured': val1_tx
            })

        # 2. Backward Flow: IF2 (TX) -> IF1 (RX)
        if if2:
            val2_tx = d2.get('tx_rate', 0.0)
            val1_rx = d1.get('rx_rate', 0.0)

            denom = max(val2_tx, val1_rx, 1.0)
            diff = abs(val2_tx - val1_rx)

            is_consistent = (diff / denom < SYMMETRY_TOLERANCE) or (diff < ABS_TOLERANCE)

            if is_consistent:
                consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.95
                estimate_confidence[if1]['rx'] = 0.95
            else:
                optimization_tasks.append({
                    'type': 'internal',
                    'src': if2, 'dst': if1,
                    'measured': [val2_tx, val1_rx]
                })
                consensus = (val2_tx + val1_rx) / 2.0
                current_estimates[if2]['tx'] = consensus
                current_estimates[if1]['rx'] = consensus
                estimate_confidence[if2]['tx'] = 0.5
                estimate_confidence[if1]['rx'] = 0.5
        else:
            # External RX
            val1_rx = d1.get('rx_rate', 0.0)
            current_estimates[if1]['rx'] = val1_rx
            estimate_confidence[if1]['rx'] = 0.8

            optimization_tasks.append({
                'type': 'external',
                'if_id': if1, 'metric': 'rx',
                'measured': val1_rx
            })
>>>>>>> REPLACE
</DIFF>

<NAME>
solver_external_link_refinement
</NAME>

<DESCRIPTION>
1. Rewrite Step 2 (Solver) to handle the new generic `optimization_tasks`.
2. Support `0.0` hypothesis for internal links to detect phantom traffic.
3. Support Implied (Conservation) hypothesis for external links.
4. Implement status-aware priors (penalize flow if status is down).
5. Implement calibrated confidence: `Conf = Relative_Likelihood * Absolute_Fit_Quality`. This ensures high confidence only when the solution explains the data well.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Step 2: Iterative Bayesian Refinement ---

    # Helper to calculate router imbalance given current estimates
    def get_router_imbalance(rid):
        if_list = topology.get(rid, [])
        total_in = 0.0
        total_out = 0.0
        for iid in if_list:
            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
        return total_in - total_out, max(total_in, total_out, 1.0)

    # Iteration loop
    for _ in range(ITERATIONS):
        updates = {} # Store updates to apply after full pass

        for flow_prob in suspect_flows:
            link_key = flow_prob['key']
            direction = flow_prob['dir']
            candidates = flow_prob['candidates']

            # Identify interfaces and routers involved
            info = links[link_key]
            if direction == '1_to_2':
                src_if, dst_if = info['if1'], info['if2']
                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
            else:
                src_if, dst_if = info['if2'], info['if1']
                val_src, val_dst = candidates[0], candidates[1]

            router_src = if_to_router.get(src_if)
            router_dst = if_to_router.get(dst_if)

            # Evaluate Hypothesis 1: Value is val_src (Local TX measurement)
            # Evaluate Hypothesis 2: Value is val_dst (Peer RX measurement)
            # We also consider their average as a fallback hypothesis 3? No, keep it binary for strong signals.

            hyps = [val_src, val_dst]
            scores = []

            for h_val in hyps:
                # Probability score based on Gaussian likelihood of imbalance

                # Check Source Router Imbalance if we use h_val for this TX interface
                # Temporarily replace value in calculation
                old_tx = current_estimates[src_if]['tx']
                current_estimates[src_if]['tx'] = h_val
                imb_src, flow_src = get_router_imbalance(router_src)
                # Restore
                current_estimates[src_if]['tx'] = old_tx

                # Check Dest Router Imbalance if we use h_val for this RX interface
                old_rx = current_estimates[dst_if]['rx']
                current_estimates[dst_if]['rx'] = h_val
                imb_dst, flow_dst = get_router_imbalance(router_dst)
                current_estimates[dst_if]['rx'] = old_rx

                # Likelihood function: P ~ exp(- |imbalance| / sigma)
                # sigma is tolerance proportional to flow
                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)

                score_src = math.exp(-abs(imb_src) / sigma_src)
                score_dst = math.exp(-abs(imb_dst) / sigma_dst)

                # Combined score (Bayesian update assuming independent router evidence)
                # We add a small epsilon prior favoring "no change" if both bad,
                # but here we just multiply.
                scores.append(score_src * score_dst)

            # Select Winner
            s1, s2 = scores[0], scores[1]
            total_s = s1 + s2 + 1e-9

            p1 = s1 / total_s
            p2 = s2 / total_s

            if p1 > p2:
                winner_val = val_src
                conf = p1
            else:
                winner_val = val_dst
                conf = p2

            # Store update
            updates[(src_if, 'tx')] = (winner_val, conf)
            updates[(dst_if, 'rx')] = (winner_val, conf)

        # Apply updates
        for (if_id, metric), (val, conf) in updates.items():
            current_estimates[if_id][metric] = val
            estimate_confidence[if_id][metric] = conf
=======
    # --- Step 2: Iterative Bayesian Refinement ---

    def get_router_state(rid):
        if rid not in topology: return 0.0, 1.0
        tin, tout = 0.0, 0.0
        max_f = 0.0
        for iid in topology[rid]:
            if iid in current_estimates:
                r, t = current_estimates[iid]['rx'], current_estimates[iid]['tx']
                tin += r
                tout += t
                max_f = max(max_f, r, t)
        return (tin - tout), max(max_f, 1.0)

    for _ in range(ITERATIONS):
        updates = []

        for task in optimization_tasks:
            # Identify Hyptheses
            hyps = [] # (value, prior)

            if task['type'] == 'internal':
                src, dst = task['src'], task['dst']
                r_src, r_dst = if_to_router.get(src), if_to_router.get(dst)

                cand_vals = sorted(list(set(task['measured'] + [0.0])))

                # Assign priors based on status
                src_stat = telemetry[src].get('interface_status')
                dst_stat = telemetry[dst].get('interface_status')

                for v in cand_vals:
                    prior = 1.0
                    # If either side is down, favor 0.0 strongly
                    if (src_stat == 'down' or dst_stat == 'down'):
                        if v == 0.0: prior = 2.0
                        else: prior = 0.01
                    else:
                        # If both up, favor measurement
                        if v == 0.0:
                            if max(task['measured']) > 10.0: prior = 0.1 # Phantom penalty
                    hyps.append((v, prior))

                # Eval
                scores = []
                for val, prior in hyps:
                    # Apply
                    old_tx = current_estimates[src]['tx']
                    current_estimates[src]['tx'] = val
                    imb_s, flow_s = get_router_state(r_src)
                    current_estimates[src]['tx'] = old_tx

                    old_rx = current_estimates[dst]['rx']
                    current_estimates[dst]['rx'] = val
                    imb_d, flow_d = get_router_state(r_dst)
                    current_estimates[dst]['rx'] = old_rx

                    sig_s = max(flow_s * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
                    sig_d = max(flow_d * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)

                    sc_s = math.exp(-abs(imb_s)/sig_s) if r_src else 1.0
                    sc_d = math.exp(-abs(imb_d)/sig_d) if r_dst else 1.0

                    scores.append(sc_s * sc_d * prior)

                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx][0]

                # Confidence: relative probability * absolute quality
                total_s = sum(scores) + 1e-12
                rel_prob = scores[best_idx] / total_s

                # Absolute quality: Geometric mean of router fits (ignoring prior)
                # Re-calc fits for winner
                curr_tx = current_estimates[src]['tx']
                current_estimates[src]['tx'] = win_val
                imb_s, fs = get_router_state(r_src)
                fit_s = math.exp(-abs(imb_s)/max(fs*CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE))
                current_estimates[src]['tx'] = curr_tx

                curr_rx = current_estimates[dst]['rx']
                current_estimates[dst]['rx'] = win_val
                imb_d, fd = get_router_state(r_dst)
                fit_d = math.exp(-abs(imb_d)/max(fd*CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE))
                current_estimates[dst]['rx'] = curr_rx

                abs_qual = math.sqrt(fit_s * fit_d)
                conf = rel_prob * abs_qual

                updates.append((src, 'tx', win_val, conf))
                updates.append((dst, 'rx', win_val, conf))

            elif task['type'] == 'external':
                if_id, metric = task['if_id'], task['metric']
                r_id = if_to_router.get(if_id)
                meas = task['measured']

                # Determine implied value from conservation
                # Imb = In - Out.
                # If metric is TX (Out), New_Out = Old_Out + Imb
                # If metric is RX (In), New_In = Old_In - Imb
                curr_est = current_estimates[if_id][metric]
                imb, r_flow = get_router_state(r_id)

                if metric == 'tx': implied = max(0.0, curr_est + imb)
                else: implied = max(0.0, curr_est - imb)

                cand_vals = sorted(list(set([meas, 0.0, implied])))
                hyps = []
                status = telemetry[if_id].get('interface_status')

                for v in cand_vals:
                    prior = 1.0
                    if status == 'down':
                        if v == 0.0: prior = 2.0
                        else: prior = 0.01
                    else:
                        if v == 0.0 and meas > 10.0: prior = 0.1
                        # Penalty for deviating from measurement unless implied is strong
                        if abs(v - meas) > max(meas*0.05, 1.0):
                            prior *= 0.5
                    hyps.append((v, prior))

                scores = []
                for val, prior in hyps:
                    old_val = current_estimates[if_id][metric]
                    current_estimates[if_id][metric] = val
                    imb, flow = get_router_state(r_id)
                    current_estimates[if_id][metric] = old_val

                    sig = max(flow * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
                    sc = math.exp(-abs(imb)/sig) if r_id else 1.0
                    scores.append(sc * prior)

                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx][0]

                total_s = sum(scores) + 1e-12
                rel_prob = scores[best_idx] / total_s

                # Abs quality
                old_val = current_estimates[if_id][metric]
                current_estimates[if_id][metric] = win_val
                imb, flow = get_router_state(r_id)
                current_estimates[if_id][metric] = old_val
                sig = max(flow * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
                abs_qual = math.exp(-abs(imb)/sig)

                conf = rel_prob * abs_qual
                updates.append((if_id, metric, win_val, conf))

        # Apply updates
        for if_id, metric, val, conf in updates:
            # Momentum
            old_val = current_estimates[if_id][metric]
            new_val = old_val * 0.4 + val * 0.6
            current_estimates[if_id][metric] = new_val
            estimate_confidence[if_id][metric] = conf
>>>>>>> REPLACE
</DIFF>