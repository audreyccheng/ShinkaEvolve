--- a/original.py
+++ b/original.py
@@ -1,363 +1,455 @@
 # EVOLVE-BLOCK-START
 from typing import Dict, Any, Tuple, List
 import math
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Repairs network telemetry using a Bayesian Flow Consensus algorithm.
     It fuses evidence from Link Symmetry and Router Flow Conservation to
     probabilistically determine the most likely true state of network counters.
     """
 
     # --- Configuration ---
     SYMMETRY_TOLERANCE = 0.02
     CONSERVATION_TOLERANCE_PCT = 0.03
     MIN_SIGNIFICANT_FLOW = 0.5
+    ABS_TOLERANCE = 1.0
     ITERATIONS = 5
 
     # --- Helper Structures ---
     # Map interface to router
     if_to_router = {}
     for r_id, if_list in topology.items():
         for i_id in if_list:
             if_to_router[i_id] = r_id
 
     # Group interfaces into Links for processing
     # Link ID = tuple of sorted interface IDs to handle bidirectionality uniquely
     links = {}
     processed_ifs = set()
 
     for if_id, data in telemetry.items():
         if if_id in processed_ifs: continue
 
         peer_id = data.get('connected_to')
         if peer_id and peer_id in telemetry:
             # Internal Link
             link_key = tuple(sorted([if_id, peer_id]))
             links[link_key] = {
                 'type': 'internal',
                 'if1': if_id,
                 'if2': peer_id
             }
             processed_ifs.add(if_id)
             processed_ifs.add(peer_id)
         else:
             # Edge/External Link
             links[(if_id,)] = {
                 'type': 'external',
                 'if1': if_id,
                 'if2': None
             }
             processed_ifs.add(if_id)
 
     # --- Step 1: Initial Link Assessment ---
     # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
     # For suspect links, generate hypotheses.
 
     # Store current best estimates for RX and TX flow on every interface
     # structure: {if_id: {'rx': val, 'tx': val}}
     current_estimates = {}
 
     # Store reliability/confidence of these estimates
     # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
     estimate_confidence = {}
 
-    # Suspect flows to solve: list of (link_key, metric_type ('rx_flow' or 'tx_flow'))
-    # Note: 'rx_flow' for link (A,B) means A->B traffic (A TX, B RX).
-    suspect_flows = []
+    # Optimization tasks: list of dicts describing flows to solve
+    optimization_tasks = []
 
     for link_key, info in links.items():
         if1 = info['if1']
         if2 = info['if2']
 
         d1 = telemetry[if1]
         d2 = telemetry[if2] if if2 else {}
 
-        # Analyze Flow IF1 -> IF2 (IF1 TX, IF2 RX)
+        # 1. Forward Flow: IF1 (TX) -> IF2 (RX)
         val1_tx = d1.get('tx_rate', 0.0)
-        val2_rx = d2.get('rx_rate', 0.0) if if2 else None
 
         if if2:
-            # Internal Link: Check Symmetry
+            val2_rx = d2.get('rx_rate', 0.0)
+
+            # Check Symmetry
             denom = max(val1_tx, val2_rx, 1.0)
             diff = abs(val1_tx - val2_rx)
 
-            if diff / denom < SYMMETRY_TOLERANCE:
-                # Consistent
+            # Consistent if relative error small OR absolute error small (noise floor)
+            is_consistent = (diff / denom < SYMMETRY_TOLERANCE) or (diff < ABS_TOLERANCE)
+
+            if is_consistent:
+                # Consistent: Average
                 consensus = (val1_tx + val2_rx) / 2.0
                 current_estimates[if1] = current_estimates.get(if1, {})
                 current_estimates[if1]['tx'] = consensus
                 current_estimates[if2] = current_estimates.get(if2, {})
                 current_estimates[if2]['rx'] = consensus
 
                 estimate_confidence[if1] = estimate_confidence.get(if1, {})
                 estimate_confidence[if1]['tx'] = 0.95
                 estimate_confidence[if2] = estimate_confidence.get(if2, {})
                 estimate_confidence[if2]['rx'] = 0.95
             else:
                 # Suspect
-                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
-                # Initialize with average but low confidence
+                optimization_tasks.append({
+                    'type': 'internal',
+                    'src': if1, 'dst': if2,
+                    'measured': [val1_tx, val2_rx]
+                })
+                # Init with average
                 consensus = (val1_tx + val2_rx) / 2.0
                 current_estimates[if1] = current_estimates.get(if1, {})
                 current_estimates[if1]['tx'] = consensus
                 current_estimates[if2] = current_estimates.get(if2, {})
                 current_estimates[if2]['rx'] = consensus
 
                 estimate_confidence[if1] = estimate_confidence.get(if1, {})
                 estimate_confidence[if1]['tx'] = 0.5
                 estimate_confidence[if2] = estimate_confidence.get(if2, {})
                 estimate_confidence[if2]['rx'] = 0.5
         else:
-            # External Link: Trust local blindly for now (no peer to contradict)
+            # External TX
             current_estimates[if1] = current_estimates.get(if1, {})
             current_estimates[if1]['tx'] = val1_tx
             estimate_confidence[if1] = estimate_confidence.get(if1, {})
-            estimate_confidence[if1]['tx'] = 0.90 # Less confident than hardened links
-
-        # Analyze Flow IF2 -> IF1 (IF2 TX, IF1 RX)
+            estimate_confidence[if1]['tx'] = 0.8 # Lower confidence so solver touches it
+
+            optimization_tasks.append({
+                'type': 'external',
+                'if_id': if1, 'metric': 'tx',
+                'measured': val1_tx
+            })
+
+        # 2. Backward Flow: IF2 (TX) -> IF1 (RX)
         if if2:
             val2_tx = d2.get('tx_rate', 0.0)
             val1_rx = d1.get('rx_rate', 0.0)
 
             denom = max(val2_tx, val1_rx, 1.0)
             diff = abs(val2_tx - val1_rx)
 
-            if diff / denom < SYMMETRY_TOLERANCE:
+            is_consistent = (diff / denom < SYMMETRY_TOLERANCE) or (diff < ABS_TOLERANCE)
+
+            if is_consistent:
                 consensus = (val2_tx + val1_rx) / 2.0
                 current_estimates[if2]['tx'] = consensus
                 current_estimates[if1]['rx'] = consensus
                 estimate_confidence[if2]['tx'] = 0.95
                 estimate_confidence[if1]['rx'] = 0.95
             else:
-                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
+                optimization_tasks.append({
+                    'type': 'internal',
+                    'src': if2, 'dst': if1,
+                    'measured': [val2_tx, val1_rx]
+                })
                 consensus = (val2_tx + val1_rx) / 2.0
                 current_estimates[if2]['tx'] = consensus
                 current_estimates[if1]['rx'] = consensus
                 estimate_confidence[if2]['tx'] = 0.5
                 estimate_confidence[if1]['rx'] = 0.5
         else:
-             # External RX
+            # External RX
             val1_rx = d1.get('rx_rate', 0.0)
             current_estimates[if1]['rx'] = val1_rx
-            estimate_confidence[if1]['rx'] = 0.90
+            estimate_confidence[if1]['rx'] = 0.8
+
+            optimization_tasks.append({
+                'type': 'external',
+                'if_id': if1, 'metric': 'rx',
+                'measured': val1_rx
+            })
 
     # --- Step 2: Iterative Bayesian Refinement ---
 
-    # Helper to calculate router imbalance given current estimates
-    def get_router_imbalance(rid):
-        if_list = topology.get(rid, [])
-        total_in = 0.0
-        total_out = 0.0
-        for iid in if_list:
-            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
-            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
-        return total_in - total_out, max(total_in, total_out, 1.0)
-
-    # Iteration loop
+    def get_router_state(rid):
+        if rid not in topology: return 0.0, 1.0
+        tin, tout = 0.0, 0.0
+        max_f = 0.0
+        for iid in topology[rid]:
+            if iid in current_estimates:
+                r, t = current_estimates[iid]['rx'], current_estimates[iid]['tx']
+                tin += r
+                tout += t
+                max_f = max(max_f, r, t)
+        return (tin - tout), max(max_f, 1.0)
+
     for _ in range(ITERATIONS):
-        updates = {} # Store updates to apply after full pass
-
-        for flow_prob in suspect_flows:
-            link_key = flow_prob['key']
-            direction = flow_prob['dir']
-            candidates = flow_prob['candidates']
-
-            # Identify interfaces and routers involved
-            info = links[link_key]
-            if direction == '1_to_2':
-                src_if, dst_if = info['if1'], info['if2']
-                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
-            else:
-                src_if, dst_if = info['if2'], info['if1']
-                val_src, val_dst = candidates[0], candidates[1]
-
-            router_src = if_to_router.get(src_if)
-            router_dst = if_to_router.get(dst_if)
-
-            # Evaluate Hypothesis 1: Value is val_src (Local TX measurement)
-            # Evaluate Hypothesis 2: Value is val_dst (Peer RX measurement)
-            # We also consider their average as a fallback hypothesis 3? No, keep it binary for strong signals.
-
-            hyps = [val_src, val_dst]
-            scores = []
-
-            for h_val in hyps:
-                # Probability score based on Gaussian likelihood of imbalance
-
-                # Check Source Router Imbalance if we use h_val for this TX interface
-                # Temporarily replace value in calculation
-                old_tx = current_estimates[src_if]['tx']
-                current_estimates[src_if]['tx'] = h_val
-                imb_src, flow_src = get_router_imbalance(router_src)
-                # Restore
-                current_estimates[src_if]['tx'] = old_tx
-
-                # Check Dest Router Imbalance if we use h_val for this RX interface
-                old_rx = current_estimates[dst_if]['rx']
-                current_estimates[dst_if]['rx'] = h_val
-                imb_dst, flow_dst = get_router_imbalance(router_dst)
-                current_estimates[dst_if]['rx'] = old_rx
-
-                # Likelihood function: P ~ exp(- |imbalance| / sigma)
-                # sigma is tolerance proportional to flow
-                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
-                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)
-
-                score_src = math.exp(-abs(imb_src) / sigma_src)
-                score_dst = math.exp(-abs(imb_dst) / sigma_dst)
-
-                # Combined score (Bayesian update assuming independent router evidence)
-                # We add a small epsilon prior favoring "no change" if both bad,
-                # but here we just multiply.
-                scores.append(score_src * score_dst)
-
-            # Select Winner
-            s1, s2 = scores[0], scores[1]
-            total_s = s1 + s2 + 1e-9
-
-            p1 = s1 / total_s
-            p2 = s2 / total_s
-
-            if p1 > p2:
-                winner_val = val_src
-                conf = p1
-            else:
-                winner_val = val_dst
-                conf = p2
-
-            # Store update
-            updates[(src_if, 'tx')] = (winner_val, conf)
-            updates[(dst_if, 'rx')] = (winner_val, conf)
+        updates = []
+
+        for task in optimization_tasks:
+            # Identify Hyptheses
+            hyps = [] # (value, prior)
+
+            if task['type'] == 'internal':
+                src, dst = task['src'], task['dst']
+                r_src, r_dst = if_to_router.get(src), if_to_router.get(dst)
+
+                cand_vals = sorted(list(set(task['measured'] + [0.0])))
+
+                # Assign priors based on status
+                src_stat = telemetry[src].get('interface_status')
+                dst_stat = telemetry[dst].get('interface_status')
+
+                for v in cand_vals:
+                    prior = 1.0
+                    # If either side is down, favor 0.0 strongly
+                    if (src_stat == 'down' or dst_stat == 'down'):
+                        if v == 0.0: prior = 2.0
+                        else: prior = 0.01
+                    else:
+                        # If both up, favor measurement
+                        if v == 0.0:
+                            if max(task['measured']) > 10.0: prior = 0.1 # Phantom penalty
+                    hyps.append((v, prior))
+
+                # Eval
+                scores = []
+                for val, prior in hyps:
+                    # Apply
+                    old_tx = current_estimates[src]['tx']
+                    current_estimates[src]['tx'] = val
+                    imb_s, flow_s = get_router_state(r_src)
+                    current_estimates[src]['tx'] = old_tx
+
+                    old_rx = current_estimates[dst]['rx']
+                    current_estimates[dst]['rx'] = val
+                    imb_d, flow_d = get_router_state(r_dst)
+                    current_estimates[dst]['rx'] = old_rx
+
+                    sig_s = max(flow_s * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
+                    sig_d = max(flow_d * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
+
+                    sc_s = math.exp(-abs(imb_s)/sig_s) if r_src else 1.0
+                    sc_d = math.exp(-abs(imb_d)/sig_d) if r_dst else 1.0
+
+                    scores.append(sc_s * sc_d * prior)
+
+                best_idx = scores.index(max(scores))
+                win_val = hyps[best_idx][0]
+
+                # Confidence: relative probability * absolute quality
+                total_s = sum(scores) + 1e-12
+                rel_prob = scores[best_idx] / total_s
+
+                # Absolute quality: Geometric mean of router fits (ignoring prior)
+                # Re-calc fits for winner
+                curr_tx = current_estimates[src]['tx']
+                current_estimates[src]['tx'] = win_val
+                imb_s, fs = get_router_state(r_src)
+                fit_s = math.exp(-abs(imb_s)/max(fs*CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE))
+                current_estimates[src]['tx'] = curr_tx
+
+                curr_rx = current_estimates[dst]['rx']
+                current_estimates[dst]['rx'] = win_val
+                imb_d, fd = get_router_state(r_dst)
+                fit_d = math.exp(-abs(imb_d)/max(fd*CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE))
+                current_estimates[dst]['rx'] = curr_rx
+
+                abs_qual = math.sqrt(fit_s * fit_d)
+                conf = rel_prob * abs_qual
+
+                updates.append((src, 'tx', win_val, conf))
+                updates.append((dst, 'rx', win_val, conf))
+
+            elif task['type'] == 'external':
+                if_id, metric = task['if_id'], task['metric']
+                r_id = if_to_router.get(if_id)
+                meas = task['measured']
+
+                # Determine implied value from conservation
+                # Imb = In - Out.
+                # If metric is TX (Out), New_Out = Old_Out + Imb
+                # If metric is RX (In), New_In = Old_In - Imb
+                curr_est = current_estimates[if_id][metric]
+                imb, r_flow = get_router_state(r_id)
+
+                if metric == 'tx': implied = max(0.0, curr_est + imb)
+                else: implied = max(0.0, curr_est - imb)
+
+                cand_vals = sorted(list(set([meas, 0.0, implied])))
+                hyps = []
+                status = telemetry[if_id].get('interface_status')
+
+                for v in cand_vals:
+                    prior = 1.0
+                    if status == 'down':
+                        if v == 0.0: prior = 2.0
+                        else: prior = 0.01
+                    else:
+                        if v == 0.0 and meas > 10.0: prior = 0.1
+                        # Penalty for deviating from measurement unless implied is strong
+                        if abs(v - meas) > max(meas*0.05, 1.0):
+                            prior *= 0.5
+                    hyps.append((v, prior))
+
+                scores = []
+                for val, prior in hyps:
+                    old_val = current_estimates[if_id][metric]
+                    current_estimates[if_id][metric] = val
+                    imb, flow = get_router_state(r_id)
+                    current_estimates[if_id][metric] = old_val
+
+                    sig = max(flow * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
+                    sc = math.exp(-abs(imb)/sig) if r_id else 1.0
+                    scores.append(sc * prior)
+
+                best_idx = scores.index(max(scores))
+                win_val = hyps[best_idx][0]
+
+                total_s = sum(scores) + 1e-12
+                rel_prob = scores[best_idx] / total_s
+
+                # Abs quality
+                old_val = current_estimates[if_id][metric]
+                current_estimates[if_id][metric] = win_val
+                imb, flow = get_router_state(r_id)
+                current_estimates[if_id][metric] = old_val
+                sig = max(flow * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
+                abs_qual = math.exp(-abs(imb)/sig)
+
+                conf = rel_prob * abs_qual
+                updates.append((if_id, metric, win_val, conf))
 
         # Apply updates
-        for (if_id, metric), (val, conf) in updates.items():
-            current_estimates[if_id][metric] = val
+        for if_id, metric, val, conf in updates:
+            # Momentum
+            old_val = current_estimates[if_id][metric]
+            new_val = old_val * 0.4 + val * 0.6
+            current_estimates[if_id][metric] = new_val
             estimate_confidence[if_id][metric] = conf
 
     # --- Step 3: Final Assembly & Status Repair ---
 
     result = {}
 
     for if_id, data in telemetry.items():
         orig_rx = data.get('rx_rate', 0.0)
         orig_tx = data.get('tx_rate', 0.0)
         orig_status = data.get('interface_status', 'unknown')
 
         # Repaired Rates
         est_rx = current_estimates[if_id]['rx']
         conf_rx = estimate_confidence[if_id]['rx']
 
         est_tx = current_estimates[if_id]['tx']
         conf_tx = estimate_confidence[if_id]['tx']
 
         # Status Inference
         # Determine peer status
         peer_id = data.get('connected_to')
         peer_status = 'unknown'
         if peer_id and peer_id in telemetry:
             peer_status = telemetry[peer_id].get('interface_status', 'unknown')
 
         # 1. Existence of significant traffic implies UP
         has_rx = est_rx > MIN_SIGNIFICANT_FLOW
         has_tx = est_tx > MIN_SIGNIFICANT_FLOW
 
         rep_status = orig_status
         conf_status = 1.0 # Baseline
 
         if has_rx or has_tx:
             rep_status = 'up'
             if orig_status != 'up':
                 # We are overturning status based on traffic.
                 # Confidence depends on traffic confidence.
                 flow_conf = max(conf_rx if has_rx else 0, conf_tx if has_tx else 0)
                 conf_status = flow_conf
 
         elif peer_status == 'down':
             # Peer is down and we have no traffic -> We should be down (usually)
             rep_status = 'down'
             if orig_status != 'down':
                 conf_status = 0.9
 
         elif orig_status == 'up' and not has_rx and not has_tx:
             # We say UP, but no traffic.
             # Could be idle.
             # If peer is UP, likely idle -> Keep UP.
             # If peer is DOWN (caught above), then DOWN.
             # If peer unknown, keep UP.
             rep_status = 'up'
 
         # Post-process: If status is DOWN, force rates to 0
         if rep_status == 'down':
             est_rx = 0.0
             est_tx = 0.0
             # High confidence in 0 if we are confident it's down
             conf_rx = max(conf_rx, conf_status)
             conf_tx = max(conf_tx, conf_status)
 
         # Result Construction
         entry = {}
         entry['rx_rate'] = (orig_rx, est_rx, conf_rx)
         entry['tx_rate'] = (orig_tx, est_tx, conf_tx)
         entry['interface_status'] = (orig_status, rep_status, conf_status)
 
         # Metadata
         for k in ['connected_to', 'local_router', 'remote_router']:
             if k in data:
                 entry[k] = data[k]
 
         result[if_id] = entry
 
     return result
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")