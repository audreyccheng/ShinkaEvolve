--- a/original.py
+++ b/original.py
@@ -1,183 +1,387 @@
 # EVOLVE-BLOCK-START
 """
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+trusted_device_consensus
+Refines the Bayesian Consensus model by introducing "Device-Level Reliability" 
+to weight local measurements against peers globally. Implements "Variance-Adaptive 
+Flow Sigma" to widen the acceptance window for flow targets on imbalanced routers, 
+and "Magnitude-Dependent Priors" to dynamically penalize zero-value hypotheses.
 """
+import math
 from typing import Dict, Any, Tuple, List
-
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
-    """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-    
-    Core principle: Use network invariants to validate and repair telemetry:
-    1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
-    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
-    3. Interface Consistency: Status should be consistent across connected pairs
-    
-    Args:
-        telemetry: Dictionary where key is interface_id and value contains:
-            - interface_status: "up" or "down" 
-            - rx_rate: receive rate in Mbps
-            - tx_rate: transmit rate in Mbps
-            - connected_to: interface_id this interface connects to
-            - local_router: router_id this interface belongs to
-            - remote_router: router_id on the other side
-        topology: Dictionary where key is router_id and value contains a list of interface_ids
-        
-    Returns:
-        Dictionary with same structure but telemetry values become tuples of:
-        (original_value, repaired_value, confidence_score)
-        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
-    """
-    
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
-    
-    result = {}
-    
-    # First pass: collect all measurements and check link symmetry
-    link_symmetry_violations = {}
-    
-    for interface_id, data in telemetry.items():
-        interface_status = data.get('interface_status', 'unknown')
-        rx_rate = data.get('rx_rate', 0.0)
-        tx_rate = data.get('tx_rate', 0.0)
-        connected_to = data.get('connected_to')
-        
-        # Check link symmetry if connected interface exists
-        if connected_to and connected_to in telemetry:
-            peer_data = telemetry[connected_to]
-            peer_rx = peer_data.get('rx_rate', 0.0)
-            peer_tx = peer_data.get('tx_rate', 0.0)
-            
-            # My TX should match their RX (within tolerance)
-            tx_rx_diff = abs(tx_rate - peer_rx) / max(tx_rate, peer_rx, 1.0)
-            # My RX should match their TX (within tolerance)
-            rx_tx_diff = abs(rx_rate - peer_tx) / max(rx_rate, peer_tx, 1.0)
-            
-            link_symmetry_violations[interface_id] = {
-                'tx_rx_diff': tx_rx_diff,
-                'rx_tx_diff': rx_tx_diff,
-                'peer_rx': peer_rx,
-                'peer_tx': peer_tx
+    
+    # --- Configuration ---
+    REL_TOL = 0.02
+    ABS_TOL = 0.5
+    ITERATIONS = 5
+    
+    # --- Helper Functions ---
+    def get_sigma(val: float) -> float:
+        """Adaptive standard deviation for Gaussian kernels."""
+        return max(ABS_TOL, abs(val) * REL_TOL)
+
+    def gaussian_score(x: float, target: float, sigma: float) -> float:
+        """Unnormalized Gaussian Likelihood (0.0 to 1.0)."""
+        if target is None: return 0.0
+        diff = abs(x - target)
+        return math.exp(-0.5 * (diff / sigma) ** 2)
+    
+    def is_zero(val: float) -> bool:
+        return val < ABS_TOL
+
+    # --- Phase 1: Initialization & Status Repair ---
+    state = {}
+    
+    for if_id, data in telemetry.items():
+        s_rx = float(data.get('rx_rate', 0.0))
+        s_tx = float(data.get('tx_rate', 0.0))
+        s_stat = data.get('interface_status', 'unknown')
+        
+        peer_id = data.get('connected_to')
+        has_peer = False
+        p_rx, p_tx, p_stat = 0.0, 0.0, 'unknown'
+        
+        if peer_id and peer_id in telemetry:
+            has_peer = True
+            p_data = telemetry[peer_id]
+            p_rx = float(p_data.get('rx_rate', 0.0))
+            p_tx = float(p_data.get('tx_rate', 0.0))
+            p_stat = p_data.get('interface_status', 'unknown')
+
+        # Traffic Analysis: Detect "Ghost" activity or "Dead" links
+        proven_active = (s_rx > ABS_TOL or s_tx > ABS_TOL or 
+                         p_rx > ABS_TOL or p_tx > ABS_TOL)
+        
+        final_stat = s_stat
+        stat_conf = 1.0
+        
+        # Status Repair Logic
+        # If any side shows traffic, link is UP.
+        if s_stat == 'down' and proven_active:
+            final_stat = 'up'
+            stat_conf = 0.95
+        elif s_stat == 'up' and not proven_active:
+            # If I'm silent, and Peer is Down (and silent), I'm likely Down.
+            if p_stat == 'down':
+                final_stat = 'down'
+                stat_conf = 0.90
+            
+        # Initial Value Estimation
+        # Start with Peer if available (Symmetry R3), else Self.
+        if final_stat == 'down':
+            est_rx, est_tx = 0.0, 0.0
+        else:
+            est_rx = p_tx if has_peer else s_rx
+            est_tx = p_rx if has_peer else s_tx
+            
+        state[if_id] = {
+            's_rx': s_rx, 's_tx': s_tx,
+            'p_rx': p_rx, 'p_tx': p_tx,
+            'est_rx': est_rx, 'est_tx': est_tx,
+            'status': final_stat,
+            'stat_conf': stat_conf,
+            'orig_stat': s_stat,
+            'has_peer': has_peer
+        }
+
+    # --- Phase 2: Iterative Consensus ---
+    
+    for iteration in range(ITERATIONS):
+        # 1. Device Reliability Analysis
+        # Determine global trust per router based on agreement with neighbors
+        router_metrics = {}
+        for r_id, if_list in topology.items():
+            valid_ifs = [i for i in if_list if i in state]
+            if not valid_ifs: continue
+            
+            sum_in, sum_out = 0.0, 0.0
+            sum_agreement = 0.0
+            
+            for i in valid_ifs:
+                d = state[i]
+                sum_in += d['est_rx']
+                sum_out += d['est_tx']
+                
+                # Agreement Score
+                if d['has_peer']:
+                    ag_rx = gaussian_score(d['est_rx'], d['p_tx'], get_sigma(d['est_rx']))
+                    ag_tx = gaussian_score(d['est_tx'], d['p_rx'], get_sigma(d['est_tx']))
+                    sum_agreement += (ag_rx + ag_tx) / 2.0
+                else:
+                    # Isolated link: Compare against original self (weak signal)
+                    ag_rx = gaussian_score(d['est_rx'], d['s_rx'], get_sigma(d['est_rx']))
+                    ag_tx = gaussian_score(d['est_tx'], d['s_tx'], get_sigma(d['est_tx']))
+                    sum_agreement += (ag_rx + ag_tx) / 2.0 * 0.8 # Discount isolated
+            
+            # Global Device Trust: Average agreement of all interfaces
+            device_trust = sum_agreement / len(valid_ifs)
+            
+            # Flow Balance Score
+            imb = abs(sum_in - sum_out)
+            mag = max(sum_in, sum_out, 1.0)
+            balance = math.exp(- (imb / (mag * 0.05))**2 )
+            
+            router_metrics[r_id] = {
+                'sin': sum_in, 'sout': sum_out,
+                'trust': device_trust, 'balance': balance
             }
-    
-    # Second pass: repair using redundant signals
-    for interface_id, data in telemetry.items():
-        repaired_data = {}
-        
-        interface_status = data.get('interface_status', 'unknown')
-        rx_rate = data.get('rx_rate', 0.0)
-        tx_rate = data.get('tx_rate', 0.0)
-        connected_to = data.get('connected_to')
-        
-        # Default: no repair, high confidence
-        repaired_rx = rx_rate
-        repaired_tx = tx_rate
-        repaired_status = interface_status
-        rx_confidence = 1.0
-        tx_confidence = 1.0
-        status_confidence = 1.0
-        
-        # Check for issues and attempt repair
-        if interface_id in link_symmetry_violations:
-            violations = link_symmetry_violations[interface_id]
-            
-            # Repair RX rate if link symmetry is violated
-            if violations['rx_tx_diff'] > HARDENING_THRESHOLD:
-                # Use peer's TX as more reliable signal
-                repaired_rx = violations['peer_tx']
-                # Confidence decreases with magnitude of violation
-                rx_confidence = max(0.0, 1.0 - violations['rx_tx_diff'])
-            
-            # Repair TX rate if link symmetry is violated
-            if violations['tx_rx_diff'] > HARDENING_THRESHOLD:
-                # Use peer's RX as more reliable signal
-                repaired_tx = violations['peer_rx']
-                # Confidence decreases with magnitude of violation
-                tx_confidence = max(0.0, 1.0 - violations['tx_rx_diff'])
-        
-        # Check status consistency
-        if connected_to and connected_to in telemetry:
-            peer_status = telemetry[connected_to].get('interface_status', 'unknown')
-            # If statuses don't match, lower confidence
-            if interface_status != peer_status:
-                status_confidence = 0.5
-                # If interface is down but has non-zero rates, that's suspicious
-                if interface_status == 'down' and (rx_rate > 0 or tx_rate > 0):
-                    repaired_rx = 0.0
-                    repaired_tx = 0.0
-                    rx_confidence = 0.3
-                    tx_confidence = 0.3
-        
-        # Store repaired values with confidence scores
-        repaired_data['rx_rate'] = (rx_rate, repaired_rx, rx_confidence)
-        repaired_data['tx_rate'] = (tx_rate, repaired_tx, tx_confidence)
-        repaired_data['interface_status'] = (interface_status, repaired_status, status_confidence)
-        
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = connected_to
-        repaired_data['local_router'] = data.get('local_router')
-        repaired_data['remote_router'] = data.get('remote_router')
-        
-        result[interface_id] = repaired_data
-    
-    return result
-
+            
+        # 2. Update Estimates
+        for if_id, d in state.items():
+            if d['status'] == 'down': continue
+            
+            r_id = telemetry[if_id].get('local_router')
+            r_info = router_metrics.get(r_id)
+            
+            def solve_direction(current, s_val, p_val, is_rx):
+                f_val = None
+                f_weight = 0.0
+                f_sigma_scale = 1.0
+                
+                # Device Trust modulates Self Trust
+                # If device is trusted globally, we trust its local measurements more.
+                w_self = 0.6 + 0.4 * (r_info['trust'] if r_info else 0.5)
+                w_peer = 1.0 # Peer is always strong reference (Link Symmetry)
+                
+                if r_info:
+                    # Flow Target
+                    if is_rx:
+                        others = r_info['sin'] - current
+                        f_val = max(0.0, r_info['sout'] - others)
+                    else:
+                        others = r_info['sout'] - current
+                        f_val = max(0.0, r_info['sin'] - others)
+                    
+                    # Weighting:
+                    # Relies on Trust (Neighbors agreeing) and Balance (Conservation holds)
+                    f_weight = 2.5 * r_info['trust'] * (0.3 + 0.7 * r_info['balance'])
+                    
+                    # Adaptive Variance:
+                    # If balance is poor, flow target is fuzzy -> widen acceptance window
+                    f_sigma_scale = 1.0 + 4.0 * (1.0 - r_info['balance'])
+                
+                # Hypothesis Generation
+                candidates = [s_val, 0.0]
+                if d['has_peer']: candidates.append(p_val)
+                if f_val is not None: candidates.append(f_val)
+                
+                # Mean injection for noise handling (Cluster merging)
+                if d['has_peer']:
+                    diff = abs(s_val - p_val)
+                    if diff > ABS_TOL and (diff/max(s_val, p_val, 1.0)) < 0.15:
+                        candidates.append((s_val + p_val)/2.0)
+                        
+                best_val = current
+                best_score = -1.0
+                
+                # Calculate max magnitude for dynamic zero penalty
+                # We sort unique candidates to find the largest plausible traffic
+                unique_cands = set(candidates)
+                max_mag = max(unique_cands) if unique_cands else 0.0
+                
+                for cand in unique_cands:
+                    sigma = get_sigma(cand)
+                    
+                    # Likelihoods
+                    l_self = w_self * gaussian_score(cand, s_val, sigma)
+                    l_peer = w_peer * gaussian_score(cand, p_val, sigma) if d['has_peer'] else 0.0
+                    
+                    l_flow = 0.0
+                    if f_val is not None:
+                        # Use scaled sigma for flow to account for router imbalance
+                        l_flow = f_weight * gaussian_score(cand, f_val, sigma * f_sigma_scale)
+                    
+                    score = l_self + l_peer + l_flow
+                    
+                    # Magnitude-Dependent Zero Penalty
+                    # If competing hypotheses are large (high max_mag), 0.0 is very unlikely.
+                    if is_zero(cand):
+                        penalty = 0.15 / (1.0 + max_mag / 10.0)
+                        score *= penalty
+                        
+                    if score > best_score:
+                        best_score = score
+                        best_val = cand
+                        
+                return best_val
+
+            new_rx = solve_direction(d['est_rx'], d['s_rx'], d['p_tx'], True)
+            new_tx = solve_direction(d['est_tx'], d['s_tx'], d['p_rx'], False)
+            
+            # Momentum update
+            d['est_rx'] = 0.5 * d['est_rx'] + 0.5 * new_rx
+            d['est_tx'] = 0.5 * d['est_tx'] + 0.5 * new_tx
+
+    # --- Phase 3: Final Output & Calibration ---
+    results = {}
+    
+    # Final Context Re-calculation
+    final_metrics = {}
+    for r_id, if_list in topology.items():
+        valid_ifs = [i for i in if_list if i in state]
+        if not valid_ifs: continue
+        sin = sum(state[i]['est_rx'] for i in valid_ifs)
+        sout = sum(state[i]['est_tx'] for i in valid_ifs)
+        
+        # Re-calc trust
+        ag_sum = 0
+        for i in valid_ifs:
+            entry = state[i]
+            if entry['has_peer']:
+                 ag_sum += (gaussian_score(entry['est_rx'], entry['p_tx'], get_sigma(entry['est_rx'])) + 
+                            gaussian_score(entry['est_tx'], entry['p_rx'], get_sigma(entry['est_tx']))) / 2.0
+            else:
+                 ag_sum += 0.5
+        trust = ag_sum / len(valid_ifs)
+        bal = math.exp(-(abs(sin-sout)/max(sin,sout,1.0)*20)**2)
+        final_metrics[r_id] = {'sin': sin, 'sout': sout, 'trust': trust, 'bal': bal}
+
+    for if_id, d in state.items():
+        res = telemetry[if_id].copy()
+        
+        if d['status'] == 'down':
+            # High confidence repair for Down
+            crx = 1.0 if d['s_rx'] <= ABS_TOL else 0.95
+            ctx = 1.0 if d['s_tx'] <= ABS_TOL else 0.95
+            res['rx_rate'] = (d['s_rx'], 0.0, crx)
+            res['tx_rate'] = (d['s_tx'], 0.0, ctx)
+        else:
+            r_id = telemetry[if_id].get('local_router')
+            r_info = final_metrics.get(r_id)
+            
+            def calc_conf(val, s_val, p_val, is_rx):
+                f_val = None
+                f_weight = 0.0
+                f_sigma_scale = 1.0
+                w_self = 0.6 + 0.4 * (r_info['trust'] if r_info else 0.5)
+                
+                if r_info:
+                    if is_rx: target = r_info['sout'] - (r_info['sin'] - d['est_rx'])
+                    else:     target = r_info['sin'] - (r_info['sout'] - d['est_tx'])
+                    f_val = max(0.0, target)
+                    f_weight = 2.5 * r_info['trust'] * (0.3 + 0.7 * r_info['bal'])
+                    f_sigma_scale = 1.0 + 4.0 * (1.0 - r_info['bal'])
+                
+                # Hypothesis Set
+                hyps = {val, s_val, 0.0}
+                if d['has_peer']: hyps.add(p_val)
+                if f_val is not None: hyps.add(f_val)
+                if d['has_peer']: hyps.add((s_val + p_val)/2.0)
+                
+                max_mag = max(hyps)
+                sigma_win = get_sigma(val)
+                
+                total_mass = 0.0
+                winner_mass = 0.0
+                
+                # Re-calculate mass for probability calibration
+                for h in hyps:
+                    sigma = get_sigma(h)
+                    
+                    l_s = w_self * gaussian_score(h, s_val, sigma)
+                    l_p = 1.0 * gaussian_score(h, p_val, sigma) if d['has_peer'] else 0.0
+                    l_f = 0.0
+                    if f_val is not None:
+                        l_f = f_weight * gaussian_score(h, f_val, sigma * f_sigma_scale)
+                        
+                    score = l_s + l_p + l_f
+                    
+                    if is_zero(h):
+                        penalty = 0.15 / (1.0 + max_mag / 10.0)
+                        score *= penalty
+                    
+                    total_mass += score
+                    if abs(h - val) <= sigma_win:
+                        winner_mass += score
+                        
+                if total_mass < 1e-9: return 0.5
+                
+                prob = winner_mass / total_mass
+                
+                # Support Sanity Check
+                peer_support = d['has_peer'] and abs(val - p_val) <= sigma_win
+                flow_support = f_val is not None and abs(val - f_val) <= (sigma_win * f_sigma_scale)
+                
+                if not peer_support and not flow_support:
+                    prob = min(prob, 0.75)
+                    
+                # Fit Quality Scaling
+                # Check if the winner actually fits the data well compared to ideal fit
+                max_possible = w_self + (1.0 if d['has_peer'] else 0.0) + (f_weight if f_val is not None else 0.0)
+                
+                w_sigma = get_sigma(val)
+                ws = w_self * gaussian_score(val, s_val, w_sigma) + \
+                     (1.0 * gaussian_score(val, p_val, w_sigma) if d['has_peer'] else 0.0) + \
+                     (f_weight * gaussian_score(val, f_val, w_sigma * f_sigma_scale) if f_val is not None else 0.0)
+                     
+                fit_ratio = ws / max(1.0, max_possible)
+                
+                if fit_ratio < 0.5:
+                    prob *= fit_ratio * 2.0
+                
+                return max(0.5, min(1.0, prob))
+
+            conf_rx = calc_conf(d['est_rx'], d['s_rx'], d['p_tx'], True)
+            conf_tx = calc_conf(d['est_tx'], d['s_tx'], d['p_rx'], False)
+            
+            res['rx_rate'] = (d['s_rx'], d['est_rx'], conf_rx)
+            res['tx_rate'] = (d['s_tx'], d['est_tx'], conf_tx)
+            
+        res['interface_status'] = (d['orig_stat'], d['status'], d['stat_conf'])
+        results[if_id] = res
+
+    return results
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
     
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
     
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
     
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
     
     result = run_repair(test_telemetry, test_topology)
     
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")
 
