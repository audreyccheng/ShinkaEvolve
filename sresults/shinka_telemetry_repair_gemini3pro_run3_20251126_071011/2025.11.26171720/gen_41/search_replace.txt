<NAME>
momentum_iterative_consensus
</NAME>

<DESCRIPTION>
Replaces the naive repair implementation with a Momentum-based Iterative Consensus model.
1.  **Iterative Hypothesis Selection**: For every interface, generates candidate values from Self, Peer, Flow, and Zero (Phantom). Scores them based on Gaussian likelihood relative to sources.
2.  **Momentum Updates**: Uses a rolling average (`alpha=0.4`) during updates to dampen oscillations in circular flow dependencies.
3.  **Dynamic Flow Trust**: Weights flow signals based on the local router's conservation reliability (imbalance).
4.  **Gaussian Confidence**: Calculates final confidence scores using continuous similarity metrics rather than discrete thresholds.
5.  **External Link Handling**: Specifically boosts flow trust for external links (no peer) to allow conservation to repair edge inputs.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                             topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
    """
    Repair network interface telemetry by detecting and correcting inconsistencies.

    Core principle: Use network invariants to validate and repair telemetry:
    1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
    3. Interface Consistency: Status should be consistent across connected pairs

    Args:
        telemetry: Dictionary where key is interface_id and value contains:
            - interface_status: "up" or "down"
            - rx_rate: receive rate in Mbps
            - tx_rate: transmit rate in Mbps
            - connected_to: interface_id this interface connects to
            - local_router: router_id this interface belongs to
            - remote_router: router_id on the other side
        topology: Dictionary where key is router_id and value contains a list of interface_ids

    Returns:
        Dictionary with same structure but telemetry values become tuples of:
        (original_value, repaired_value, confidence_score)
        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
    """

    # Measurement timing tolerance (from Hodor research: ~2%)
    HARDENING_THRESHOLD = 0.02

    result = {}

    # First pass: collect all measurements and check link symmetry
    link_symmetry_violations = {}

    for interface_id, data in telemetry.items():
        interface_status = data.get('interface_status', 'unknown')
        rx_rate = data.get('rx_rate', 0.0)
        tx_rate = data.get('tx_rate', 0.0)
        connected_to = data.get('connected_to')

        # Check link symmetry if connected interface exists
        if connected_to and connected_to in telemetry:
            peer_data = telemetry[connected_to]
            peer_rx = peer_data.get('rx_rate', 0.0)
            peer_tx = peer_data.get('tx_rate', 0.0)

            # My TX should match their RX (within tolerance)
            tx_rx_diff = abs(tx_rate - peer_rx) / max(tx_rate, peer_rx, 1.0)
            # My RX should match their TX (within tolerance)
            rx_tx_diff = abs(rx_rate - peer_tx) / max(rx_rate, peer_tx, 1.0)

            link_symmetry_violations[interface_id] = {
                'tx_rx_diff': tx_rx_diff,
                'rx_tx_diff': rx_tx_diff,
                'peer_rx': peer_rx,
                'peer_tx': peer_tx
            }

    # Second pass: repair using redundant signals
    for interface_id, data in telemetry.items():
        repaired_data = {}

        interface_status = data.get('interface_status', 'unknown')
        rx_rate = data.get('rx_rate', 0.0)
        tx_rate = data.get('tx_rate', 0.0)
        connected_to = data.get('connected_to')

        # Default: no repair, high confidence
        repaired_rx = rx_rate
        repaired_tx = tx_rate
        repaired_status = interface_status
        rx_confidence = 1.0
        tx_confidence = 1.0
        status_confidence = 1.0

        # Check for issues and attempt repair
        if interface_id in link_symmetry_violations:
            violations = link_symmetry_violations[interface_id]

            # Repair RX rate if link symmetry is violated
            if violations['rx_tx_diff'] > HARDENING_THRESHOLD:
                # Use peer's TX as more reliable signal
                repaired_rx = violations['peer_tx']
                # Confidence decreases with magnitude of violation
                rx_confidence = max(0.0, 1.0 - violations['rx_tx_diff'])

            # Repair TX rate if link symmetry is violated
            if violations['tx_rx_diff'] > HARDENING_THRESHOLD:
                # Use peer's RX as more reliable signal
                repaired_tx = violations['peer_rx']
                # Confidence decreases with magnitude of violation
                tx_confidence = max(0.0, 1.0 - violations['tx_rx_diff'])

        # Check status consistency
        if connected_to and connected_to in telemetry:
            peer_status = telemetry[connected_to].get('interface_status', 'unknown')
            # If statuses don't match, lower confidence
            if interface_status != peer_status:
                status_confidence = 0.5
                # If interface is down but has non-zero rates, that's suspicious
                if interface_status == 'down' and (rx_rate > 0 or tx_rate > 0):
                    repaired_rx = 0.0
                    repaired_tx = 0.0
                    rx_confidence = 0.3
                    tx_confidence = 0.3

        # Store repaired values with confidence scores
        repaired_data['rx_rate'] = (rx_rate, repaired_rx, rx_confidence)
        repaired_data['tx_rate'] = (tx_rate, repaired_tx, tx_confidence)
        repaired_data['interface_status'] = (interface_status, repaired_status, status_confidence)

        # Copy metadata unchanged
        repaired_data['connected_to'] = connected_to
        repaired_data['local_router'] = data.get('local_router')
        repaired_data['remote_router'] = data.get('remote_router')

        result[interface_id] = repaired_data

    return result
=======
import math

def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                             topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
    """
    Repairs telemetry using an Iterative Consensus model with Momentum.

    Key Features:
    1. Hypothesis Selection: Arbitrates between Self, Peer, Flow, and Zero.
    2. Momentum Updates: Uses a rolling average during iteration to stabilize flow calculations.
    3. Dynamic Flow Trust: Flow signals are weighted by the router's current balance quality.
    4. Calibration: Confidence reflects the Gaussian likelihood of the chosen value against available signals.
    """

    # --- Configuration ---
    REL_TOL = 0.02
    ABS_TOL = 0.5
    MOMENTUM_ALPHA = 0.4 # How much new value contributes (0.4 means 60% retention)
    ITERATIONS = 4

    results = {}

    # --- Helper: Similarity Score ---
    def gaussian_similarity(v1, v2):
        if v1 is None or v2 is None: return 0.0
        diff = abs(v1 - v2)
        # Sigma scales with value magnitude (Heteroscedastic noise model)
        # Using linear scaling matching the 2% tolerance assumption
        sigma = max(ABS_TOL, max(abs(v1), abs(v2)) * REL_TOL)
        # Gaussian curve: exp(-x^2 / 2sigma^2)
        return math.exp(- (diff**2) / (2 * (sigma**2)))

    # --- Phase 1: Initialization & Status Repair ---
    working_state = {}

    for if_id, data in telemetry.items():
        s_rx = float(data.get('rx_rate', 0.0))
        s_tx = float(data.get('tx_rate', 0.0))
        s_status = data.get('interface_status', 'unknown')

        peer_id = data.get('connected_to')
        has_peer = False
        p_rx, p_tx, p_status = 0.0, 0.0, 'unknown'

        if peer_id and peer_id in telemetry:
            has_peer = True
            p_data = telemetry[peer_id]
            p_rx = float(p_data.get('rx_rate', 0.0))
            p_tx = float(p_data.get('tx_rate', 0.0))
            p_status = p_data.get('interface_status', 'unknown')

        # Status Logic
        has_traffic = (s_rx > ABS_TOL or s_tx > ABS_TOL or
                       p_rx > ABS_TOL or p_tx > ABS_TOL)

        final_status = s_status
        status_conf = 1.0

        if s_status == 'down' and has_traffic:
            final_status = 'up'
            status_conf = 0.95
        elif s_status == 'up' and not has_traffic and p_status == 'down':
            final_status = 'down'
            status_conf = 0.90

        # Initial Estimate Seeding
        if final_status == 'down':
            est_rx, est_tx = 0.0, 0.0
        else:
            # Seed with Peer if available (Symmetry), else Self
            est_rx = p_tx if has_peer else s_rx
            est_tx = p_rx if has_peer else s_tx

        working_state[if_id] = {
            's_rx': s_rx, 's_tx': s_tx,
            'p_rx': p_rx if has_peer else None,
            'p_tx': p_tx if has_peer else None,
            'est_rx': est_rx, 'est_tx': est_tx,
            'status': final_status,
            'status_conf': status_conf,
            'orig_status': s_status,
            'has_peer': has_peer
        }

    # --- Phase 2: Iterative Refinement ---
    for _ in range(ITERATIONS):
        # 1. Build Router Context
        router_context = {}
        for r_id, if_list in topology.items():
            valid_ifs = [i for i in if_list if i in working_state]
            sum_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
            sum_out = sum(working_state[i]['est_tx'] for i in valid_ifs)

            # Reliability based on imbalance
            # We want a score that is high when balance is good
            imbalance = abs(sum_in - sum_out)
            magnitude = max(sum_in, sum_out, 1.0)

            # Score: 1.0 at 0 imbalance, drops to ~0.0 at 10% imbalance
            # Using exponential decay for sharper distinction
            rel_imbalance = imbalance / magnitude
            reliability = math.exp(- rel_imbalance * 20.0) # at 5% (0.05), exp(-1) = 0.36

            router_context[r_id] = {
                'sum_in': sum_in, 'sum_out': sum_out,
                'reliability': reliability
            }

        # 2. Update Estimates
        for if_id, d in working_state.items():
            if d['status'] == 'down':
                continue # Fixed at 0.0

            r_id = telemetry[if_id].get('local_router')

            # Define Signal Hypotheses
            # We will score candidate values.

            # --- RX Update ---
            candidates_rx = [d['s_rx']]
            if d['p_tx'] is not None: candidates_rx.append(d['p_tx'])
            candidates_rx.append(0.0) # Zero hypothesis

            f_rx = None
            f_weight_rx = 0.0

            if r_id and r_id in router_context:
                rc = router_context[r_id]
                # Implied flow value: Total_Out - (Total_In - Me)
                other_in = rc['sum_in'] - d['est_rx']
                f_rx = max(0.0, rc['sum_out'] - other_in)
                candidates_rx.append(f_rx)

                # Dynamic weight for flow
                # If the router is consistent, flow is strong.
                # However, if we are the CAUSE of inconsistency, the router looks bad.
                # We use a heuristic: Trust flow more if we have no peer.
                base_flow_w = 2.0
                if not d['has_peer']: base_flow_w = 3.0 # External link needs flow
                f_weight_rx = base_flow_w * rc['reliability']

            # Scoring function
            def score_candidate(val, s_val, p_val, f_val, f_w):
                score = 0.0
                # Support from Self
                score += 1.0 * gaussian_similarity(val, s_val)
                # Support from Peer
                if p_val is not None:
                    score += 2.0 * gaussian_similarity(val, p_val)
                # Support from Flow
                if f_val is not None:
                    score += f_w * gaussian_similarity(val, f_val)
                return score

            best_rx = d['est_rx']
            best_score_rx = -1.0

            # Optimization: Try the candidates themselves as the best value
            for c in candidates_rx:
                s = score_candidate(c, d['s_rx'], d['p_tx'], f_rx, f_weight_rx)
                if s > best_score_rx:
                    best_score_rx = s
                    best_rx = c

            # Momentum Update
            d['est_rx'] = (1.0 - MOMENTUM_ALPHA) * d['est_rx'] + MOMENTUM_ALPHA * best_rx

            # --- TX Update ---
            candidates_tx = [d['s_tx']]
            if d['p_rx'] is not None: candidates_tx.append(d['p_rx'])
            candidates_tx.append(0.0)

            f_tx = None
            f_weight_tx = 0.0

            if r_id and r_id in router_context:
                rc = router_context[r_id]
                other_out = rc['sum_out'] - d['est_tx']
                f_tx = max(0.0, rc['sum_in'] - other_out)
                candidates_tx.append(f_tx)

                base_flow_w = 2.0
                if not d['has_peer']: base_flow_w = 3.0
                f_weight_tx = base_flow_w * rc['reliability']

            best_tx = d['est_tx']
            best_score_tx = -1.0

            for c in candidates_tx:
                s = score_candidate(c, d['s_tx'], d['p_rx'], f_tx, f_weight_tx)
                if s > best_score_tx:
                    best_score_tx = s
                    best_tx = c

            d['est_tx'] = (1.0 - MOMENTUM_ALPHA) * d['est_tx'] + MOMENTUM_ALPHA * best_tx

    # --- Phase 3: Final Output Construction ---
    for if_id, d in working_state.items():
        res = telemetry[if_id].copy()

        if d['status'] == 'down':
            # Confidence high if measured values are near zero
            c_rx = 0.95 if d['s_rx'] > ABS_TOL else 1.0
            c_tx = 0.95 if d['s_tx'] > ABS_TOL else 1.0
            res['rx_rate'] = (d['s_rx'], 0.0, c_rx)
            res['tx_rate'] = (d['s_tx'], 0.0, c_tx)
        else:
            # Calculate final confidence based on agreement
            final_rx = d['est_rx']
            final_tx = d['est_tx']

            # Confidence logic:
            # 1. Identify primary supporter (Peer > Flow > Self)
            # 2. Calculate distance to primary supporter

            # RX Confidence
            conf_rx = 0.5
            dist_p = gaussian_similarity(final_rx, d['p_tx']) if d['p_tx'] is not None else 0.0
            dist_s = gaussian_similarity(final_rx, d['s_rx'])

            if d['has_peer']:
                if dist_p > 0.8: # Strong agreement with Peer
                    conf_rx = 0.9 + (0.1 * dist_p)
                elif dist_p > 0.4:
                    conf_rx = 0.8
                else:
                    # Peer disagrees. Check Self/Flow.
                    conf_rx = 0.7 # Low confidence repair
            else:
                # No peer. Rely on Self/Flow.
                if dist_s > 0.9: conf_rx = 0.9 # Trust self if isolated
                else: conf_rx = 0.6 # Changed from self -> likely Flow repair

            # TX Confidence
            conf_tx = 0.5
            dist_p_tx = gaussian_similarity(final_tx, d['p_rx']) if d['p_rx'] is not None else 0.0

            if d['has_peer']:
                if dist_p_tx > 0.8:
                    conf_tx = 0.9 + (0.1 * dist_p_tx)
                elif dist_p_tx > 0.4:
                    conf_tx = 0.8
                else:
                    conf_tx = 0.7
            else:
                dist_s_tx = gaussian_similarity(final_tx, d['s_tx'])
                if dist_s_tx > 0.9: conf_tx = 0.9
                else: conf_tx = 0.6

            res['rx_rate'] = (d['s_rx'], final_rx, min(1.0, conf_rx))
            res['tx_rate'] = (d['s_tx'], final_tx, min(1.0, conf_tx))

        res['interface_status'] = (d['orig_status'], d['status'], d['status_conf'])
        results[if_id] = res

    return results
>>>>>>> REPLACE
</DIFF>