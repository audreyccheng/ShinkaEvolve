<NAME>
calibrate_priors_and_confidence
</NAME>

<DESCRIPTION>
1.  **Status-Aware Suspect Flows**: Modifies the classification step to capture interface status in `suspect_flows`.
2.  **Advanced Bayesian Solver**:
    -   Calculates `router_anchor_ratios` to weigh external link validation (trust conservation more on well-anchored routers).
    -   Includes a "Mean" hypothesis for internal links to resolve small discrepancies.
    -   Uses interface status to set strong priors for the `0.0` hypothesis.
    -   Tracks `win_prob` (probability mass of the winning cluster) as `solver_confidences`.
3.  **Calibrated Confidence**: Updates the confidence calculation to multiply the solver's certainty (`win_prob`) by the router's fit quality, ensuring we are only confident when we are both statistically sure AND the result makes physical sense.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
            else:
                # Suspect
                suspect_flows.append({
                    'type': 'internal', 'src': if1, 'dst': if2,
                    'cands': [v1, v2]
                })

            # Backward: 2(TX) -> 1(RX)
            v1, v2 = estimates[if2]['tx'], estimates[if1]['rx']
            diff = abs(v1 - v2)
            denom = max(v1, v2, 1.0)

            if diff / denom < SYMMETRY_TOLERANCE:
                avg = (v1 + v2) / 2.0
                estimates[if2]['tx'] = avg
                estimates[if1]['rx'] = avg
                anchors.add((if2, 'tx'))
                anchors.add((if1, 'rx'))
            else:
                suspect_flows.append({
                    'type': 'internal', 'src': if2, 'dst': if1,
                    'cands': [v1, v2]
                })

        else:
            # External
            # Treat as suspect but with single candidate (itself)
            # We will rely on conservation to confirm or deny it
            suspect_flows.append({
                'type': 'external', 'src': if1, 'dst': None,
                'cands': [estimates[if1]['tx']],
                'metric': 'tx'
            })
            suspect_flows.append({
                'type': 'external', 'src': None, 'dst': if1,
                'cands': [estimates[if1]['rx']],
                'metric': 'rx'
            })
=======
            else:
                # Suspect
                suspect_flows.append({
                    'type': 'internal', 'src': if1, 'dst': if2,
                    'cands': [v1, v2],
                    'status_src': telemetry[if1].get('interface_status', 'unknown'),
                    'status_dst': telemetry[if2].get('interface_status', 'unknown')
                })

            # Backward: 2(TX) -> 1(RX)
            v1, v2 = estimates[if2]['tx'], estimates[if1]['rx']
            diff = abs(v1 - v2)
            denom = max(v1, v2, 1.0)

            if diff / denom < SYMMETRY_TOLERANCE:
                avg = (v1 + v2) / 2.0
                estimates[if2]['tx'] = avg
                estimates[if1]['rx'] = avg
                anchors.add((if2, 'tx'))
                anchors.add((if1, 'rx'))
            else:
                suspect_flows.append({
                    'type': 'internal', 'src': if2, 'dst': if1,
                    'cands': [v1, v2],
                    'status_src': telemetry[if2].get('interface_status', 'unknown'),
                    'status_dst': telemetry[if1].get('interface_status', 'unknown')
                })

        else:
            # External
            suspect_flows.append({
                'type': 'external', 'src': if1, 'dst': None,
                'cands': [estimates[if1]['tx']],
                'metric': 'tx',
                'status_src': telemetry[if1].get('interface_status', 'unknown')
            })
            suspect_flows.append({
                'type': 'external', 'src': None, 'dst': if1,
                'cands': [estimates[if1]['rx']],
                'metric': 'rx',
                'status_dst': telemetry[if1].get('interface_status', 'unknown')
            })
>>>>>>> REPLACE
<<<<<<< SEARCH
    def calc_sigma(flow_val):
        # Adaptive noise model: Sqrt(flow) dominates at low rates, Pct(flow) at high rates
        return max(math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)

    for _ in range(ITERATIONS):
        updates = []

        for flow in suspect_flows:
            # Prepare context
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                # Candidates: [Meas1, Meas2, 0.0]
                # Filter duplicates and negative
                hyps = sorted(list(set([c for c in flow['cands'] if c >= 0] + [0.0])))

                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    # Apply
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    # Eval Src
                    imb_s, flow_s = get_router_state(r_src)
                    sig_s = calc_sigma(flow_s)
                    score_s = math.exp(-abs(imb_s)/sig_s) if r_src else 1.0

                    # Eval Dst
                    imb_d, flow_d = get_router_state(r_dst)
                    sig_d = calc_sigma(flow_d)
                    score_d = math.exp(-abs(imb_d)/sig_d) if r_dst else 1.0

                    # Prior
                    # Penalize 0.0 if measurements are large (unless conservation dictates)
                    prior = 1.0
                    if h == 0.0:
                        max_meas = max(flow['cands'])
                        if max_meas > 10.0: prior = 0.01 # Strong penalty for zeroing large flow
                        elif max_meas > 1.0: prior = 0.5

                    scores.append(score_s * score_d * prior)

                # Restore
                estimates[src]['tx'] = curr_tx
                estimates[dst]['rx'] = curr_rx

                # Pick winner
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                updates.append((src, 'tx', win_val))
                updates.append((dst, 'rx', win_val))

            elif flow['type'] == 'external':
                # External: We trust measurement unless implied value from conservation is much better
                if flow['src']: # TX external
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['tx']

                    # Implied value: what value balances the router?
                    # Imb = In - Out. We want Imb=0.
                    # Current Imb = In_Others + In_Self - (Out_Others + Out_Self)
                    # We vary Out_Self (TX).
                    # New_Out = Old_Out + Imb
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val + imb)

                else: # RX external
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['rx']

                    # Vary In_Self (RX).
                    # New_In = Old_In - Imb
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    sig = calc_sigma(rf)
                    lik = math.exp(-abs(imb)/sig) if r_id else 0.5

                    # Prior: Gaussian centered on measurement
                    # Sigma for prior: We trust measurement to ~5%
                    sig_meas = max(meas * 0.05, 2.0)
                    prior = math.exp(-abs(h - meas)/sig_meas)

                    # Special Prior for 0.0 (Phantom check)
                    if h == 0.0:
                        if meas > 10.0: prior *= 0.01

                    scores.append(lik * prior)

                estimates[if_id][metric] = curr_val # Restore

                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                updates.append((if_id, metric, win_val))

        # Apply Updates with Momentum
        for if_id, metric, val in updates:
            old = estimates[if_id][metric]
            # Momentum update
            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
=======
    def calc_sigma(flow_val):
        # Adaptive noise model
        return max(math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)

    # Pre-calculate anchor strength per router to weight external link logic
    router_anchor_ratios = {}
    for rid in topology:
        total_flow = 0.0
        anchor_flow = 0.0
        for iid in topology[rid]:
            if iid in estimates:
                # Approximate flow with initial estimates
                f = estimates[iid]['rx'] + estimates[iid]['tx']
                total_flow += f
                if (iid, 'rx') in anchors: anchor_flow += estimates[iid]['rx']
                if (iid, 'tx') in anchors: anchor_flow += estimates[iid]['tx']
        router_anchor_ratios[rid] = anchor_flow / max(total_flow, 1.0)

    # Track solver confidence (probability of winning hypothesis)
    solver_confidences = {}

    for _ in range(ITERATIONS):
        updates = []

        for flow in suspect_flows:
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                # Candidates: [Meas1, Meas2, Mean, 0.0]
                cands = [c for c in flow['cands'] if c >= 0]
                if len(cands) == 2:
                    v1, v2 = cands
                    # Add mean if difference is not massive (helps with noise)
                    if abs(v1 - v2) < max(v1, v2) * 0.2 + 5.0:
                        cands.append((v1 + v2) / 2.0)

                hyps = sorted(list(set(cands + [0.0])))

                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    # Likelihoods
                    imb_s, flow_s = get_router_state(r_src)
                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s)) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d)) if r_dst else 1.0

                    # Status-Aware Prior
                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down':
                            prior = 0.98  # Strong pull to zero if DOWN
                        else:
                            max_meas = max(flow['cands'])
                            # If UP and measuring high, zero is unlikely
                            if max_meas > 10.0: prior = 0.01
                            elif max_meas > 1.0: prior = 0.2
                    else:
                        # Slight preference for measured values over arbitrary ones
                        # (Gaussian around measurements)
                        min_dist = min([abs(h - c) for c in flow['cands']])
                        prior = math.exp(-min_dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)

                estimates[src]['tx'] = curr_tx
                estimates[dst]['rx'] = curr_rx

                total_score = sum(scores) + 1e-20
                probs = [s/total_score for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]

                # Confidence: probability mass near winner
                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((src, 'tx', win_val, win_prob))
                updates.append((dst, 'rx', win_val, win_prob))

            elif flow['type'] == 'external':
                if flow['src']: # TX
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['tx']
                    stat = flow.get('status_src')

                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val + imb)
                else: # RX
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr_val = estimates[if_id]['rx']
                    stat = flow.get('status_dst')

                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr_val - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                anchor_ratio = router_anchor_ratios.get(r_id, 0.0)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    lik = math.exp(-abs(imb)/calc_sigma(rf)) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.98
                        elif meas > 10.0: prior = 0.01
                        else: prior = 0.5
                    elif abs(h - implied) < 1e-6:
                        # Conservation hypothesis
                        # Trust increases with anchor ratio
                        prior = 0.5 + (0.45 * anchor_ratio)
                    elif abs(h - meas) < 1e-6:
                        # Measurement hypothesis
                        # Trust decreases as anchor ratio increases (if conservation is reliable)
                        prior = 0.95 - (0.45 * anchor_ratio)

                    scores.append(lik * prior)

                estimates[if_id][metric] = curr_val

                total_score = sum(scores) + 1e-20
                probs = [s/total_score for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]

                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((if_id, metric, win_val, win_prob))

        # Apply Updates
        for if_id, metric, val, prob in updates:
            old = estimates[if_id][metric]
            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
            solver_confidences[(if_id, metric)] = prob
>>>>>>> REPLACE
<<<<<<< SEARCH
        # Confidence Calculation
        # 1. Base Confidence: How much did we deviate?
        #    If Anchor -> High.
        #    If Deviation small -> High.
        #    If Deviation large -> Low (unless R_Fit is very high, meaning we fixed it)

        def calc_conf(rep_val, orig_val, is_anchor):
            if is_anchor: return 0.95

            # If not anchor, we relied on conservation
            # If router conservation is bad, confidence is bad
            base = r_fit

            # If we changed the value significantly, check if it makes sense
            if abs(rep_val - orig_val) > max(orig_val * 0.1, 1.0):
                # Big change.
                # If fit is perfect (1.0), we are confident we fixed it (Conf ~ 0.9)
                # If fit is poor (0.5), we are unsure (Conf ~ 0.4)
                return 0.9 * base
            else:
                # Small change. We trust the measurement roughly, adjusted by fit.
                # If fit is bad, maybe measurement was wrong but we couldn't find better?
                return 0.8 * base + 0.15

        conf_rx = calc_conf(rep_rx, orig_rx, (if_id, 'rx') in anchors)
        conf_tx = calc_conf(rep_tx, orig_tx, (if_id, 'tx') in anchors)
=======
        # Confidence Calculation
        def calc_conf(metric, rep_val, orig_val):
            if (if_id, metric) in anchors: return 0.95

            # Retrieve solver certainty
            sol_prob = solver_confidences.get((if_id, metric), 0.5)

            # Combine solver certainty (relative win) with router fit (absolute check)
            # If solver was sure (0.9) and fit is good (0.9), conf -> High
            # If solver was sure (0.9) but fit is bad (0.5), conf -> Medium/Low (Something is wrong elsewhere)
            # If solver was unsure (0.5), conf -> Low regardless of fit

            combined = sol_prob * (0.3 + 0.7 * r_fit)

            # Bonus if we didn't have to change much (validation)
            if abs(rep_val - orig_val) < max(orig_val * 0.1, 1.0):
                combined = max(combined, 0.8 * r_fit + 0.1)

            return combined

        conf_rx = calc_conf('rx', rep_rx, orig_rx)
        conf_tx = calc_conf('tx', rep_tx, orig_tx)
>>>>>>> REPLACE
</DIFF>