--- a/original.py
+++ b/original.py
@@ -1,353 +1,327 @@
 # EVOLVE-BLOCK-START
 from typing import Dict, Any, Tuple, List
 import math
 
-def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
+def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
-    Repairs network telemetry using a consensus mechanism between Link Symmetry
-    and Router Flow Conservation invariants, with ambiguity-aware confidence calibration.
-
-    Algorithm:
-    1. Identify 'clean' (consistent) and 'suspect' (inconsistent) links.
-    2. For suspect links, generate hypotheses: True Value = Local vs Peer.
-    3. Validate hypotheses using Router Flow Conservation.
-    4. Select the hypothesis that minimizes global network violation.
-    5. Detect ambiguity: If multiple hypotheses are similarly good, reduce confidence.
+    Repairs network telemetry using a Bayesian-inspired iterative consensus algorithm.
+    Features:
+    - Link Symmetry and Flow Conservation models.
+    - Explicit 'Null Flow' (0.0) hypothesis testing to detect phantom traffic.
+    - 'Computed' hypothesis for external links to allow edge correction.
+    - Confidence calibration based on both relative probability and absolute fit.
     """
-
-    # Configuration
-    TOLERANCE = 0.02  # 2% hardening threshold
-    ABS_TOLERANCE = 1.0 # 1 Mbps absolute threshold for noise/idle checks
-    MIN_FLOW_SIGNIFICANCE = 0.1  # Threshold for "active" link status
-
-    # Helper: Build Interface->Router map from topology
+    
+    # --- Configuration ---
+    SYMMETRY_TOLERANCE = 0.02
+    CONSERVATION_TOLERANCE_PCT = 0.03
+    MIN_SIGNIFICANT_FLOW = 0.5
+    ITERATIONS = 5
+    
+    # --- 1. Preprocessing & Topology ---
     if_to_router = {}
     for r_id, if_list in topology.items():
         for i_id in if_list:
             if_to_router[i_id] = r_id
-
-    # --- PHASE 1: Link Symmetry Analysis & Hypothesis Generation ---
-    link_analysis = {}
-
+            
+    # Current State Dictionary
+    # if_id -> {'rx': val, 'tx': val}
+    current_state = {}
+    
+    # Initialize with measurements
     for if_id, data in telemetry.items():
-        # Get Local Data
-        local_rx = data.get('rx_rate', 0.0)
-        local_tx = data.get('tx_rate', 0.0)
-
-        # Get Peer Data
-        peer_id = data.get('connected_to')
-        peer_data = telemetry.get(peer_id, {}) if peer_id else {}
-
-        peer_tx = peer_data.get('tx_rate', None)
-        peer_rx = peer_data.get('rx_rate', None)
-
-        # Analyze RX Symmetry
-        rx_candidates = {'local': local_rx}
-        rx_symmetry_score = 0.0
-
-        if peer_tx is not None:
-            rx_candidates['peer'] = peer_tx
-            denom = max(local_rx, peer_tx, 1.0)
-            diff = abs(local_rx - peer_tx)
-
-            # Use absolute or relative tolerance
-            if diff < ABS_TOLERANCE or diff / denom < TOLERANCE:
-                rx_symmetry_score = 1.0
-                # Consensus logic: if one is 0 and match is good, likely 0. Else average.
-                if min(local_rx, peer_tx) == 0.0:
-                    rx_candidates['consensus'] = 0.0
-                else:
-                    rx_candidates['consensus'] = (local_rx + peer_tx) / 2.0
+        current_state[if_id] = {
+            'rx': data.get('rx_rate', 0.0),
+            'tx': data.get('tx_rate', 0.0)
+        }
+
+    # Helper to compute router imbalance
+    def get_router_imbalance(rid, state):
+        if rid not in topology: return 0.0, 1.0
+        total_in = 0.0
+        total_out = 0.0
+        max_flow = 1.0
+        
+        for iid in topology[rid]:
+            if iid in state:
+                r = state[iid]['rx']
+                t = state[iid]['tx']
+                total_in += r
+                total_out += t
+                max_flow = max(max_flow, r, t)
+        
+        return (total_in - total_out), max_flow
+
+    # --- 2. Iterative Improvement ---
+    
+    for _ in range(ITERATIONS):
+        next_state = {k: v.copy() for k, v in current_state.items()}
+        
+        for if_id, data in telemetry.items():
+            peer_id = data.get('connected_to')
+            is_internal = peer_id and peer_id in telemetry
+            
+            # --- A. Handle TX Flow (if_id -> peer) ---
+            # For internal links, this handles the peer's RX as well.
+            
+            src_if = if_id
+            dst_if = peer_id
+            
+            val_local_tx = data.get('tx_rate', 0.0)
+            
+            # Gather Candidates
+            candidates_tx = {val_local_tx, 0.0}
+            
+            if is_internal:
+                val_peer_rx = telemetry[dst_if].get('rx_rate', 0.0)
+                candidates_tx.add(val_peer_rx)
+                # Average for smoothing
+                if abs(val_local_tx - val_peer_rx) < max(val_local_tx, val_peer_rx, 1.0) * 0.2:
+                    candidates_tx.add((val_local_tx + val_peer_rx) / 2.0)
             else:
-                # Disagreement
-                rx_symmetry_score = max(0.0, 1.0 - (diff / denom))
-        else:
-            rx_symmetry_score = 0.5
-
-        # Analyze TX Symmetry
-        tx_candidates = {'local': local_tx}
-        tx_symmetry_score = 0.0
-
-        if peer_rx is not None:
-            tx_candidates['peer'] = peer_rx
-            denom = max(local_tx, peer_rx, 1.0)
-            diff = abs(local_tx - peer_rx)
-
-            if diff < ABS_TOLERANCE or diff / denom < TOLERANCE:
-                tx_symmetry_score = 1.0
-                if min(local_tx, peer_rx) == 0.0:
-                    tx_candidates['consensus'] = 0.0
-                else:
-                    tx_candidates['consensus'] = (local_tx + peer_rx) / 2.0
-            else:
-                tx_symmetry_score = max(0.0, 1.0 - (diff / denom))
-        else:
-            tx_symmetry_score = 0.5
-
-        link_analysis[if_id] = {
-            'rx': {'candidates': rx_candidates, 'symmetry': rx_symmetry_score},
-            'tx': {'candidates': tx_candidates, 'symmetry': tx_symmetry_score}
-        }
-
-    # --- PHASE 2: Router Conservation Optimization ---
-    final_decisions = {}
-
-    for router_id, if_list in topology.items():
-        # Identify variables for optimization
-        reliable_inputs = 0.0
-        reliable_outputs = 0.0
-        unreliable_ifs = [] # List of {'key': (if_id, type), 'local': val, 'peer': val, 'impact': float}
-
-        # Base flow from reliable links
-        for if_id in if_list:
-            if if_id not in link_analysis: continue
-
-            for metric, inputs_dict, outputs_dict in [('rx', True, False), ('tx', False, True)]:
-                info = link_analysis[if_id][metric]
-                # High symmetry -> Reliable
-                if info['symmetry'] > 0.95:
-                    val = info['candidates'].get('consensus', info['candidates']['local'])
-                    if inputs_dict: reliable_inputs += val
-                    if outputs_dict: reliable_outputs += val
-                else:
-                    # Unreliable -> Variable
-                    cands = info['candidates']
-                    # Candidates: Default to Peer (H0), Local (H1)
-                    peer_val = cands.get('peer', cands['local'])
-                    local_val = cands['local']
-
-                    # Impact on (In - Out) if we switch from Peer -> Local
-                    diff = local_val - peer_val
-                    impact = diff if inputs_dict else -diff
-
-                    unreliable_ifs.append({
-                        'key': (if_id, metric),
-                        'local': local_val,
-                        'peer': peer_val,
-                        'impact': impact,
-                        'is_input': inputs_dict
-                    })
-
-                    # Add baseline (Peer) to sums
-                    if inputs_dict: reliable_inputs += peer_val
-                    else: reliable_outputs += peer_val
-
-        # Optimization: Select subset of swaps to minimize |In - Out|
-        # Base Imbalance (with all Peer values)
-        base_net_flow = reliable_inputs - reliable_outputs
-
-        n_vars = len(unreliable_ifs)
-        best_mask = 0
-        min_imbalance = abs(base_net_flow)
-
-        # Brute force if small (covers most routers)
-        valid_masks = []
-
-        if n_vars <= 12:
-            # Find global minimum
-            for mask in range(1 << n_vars):
-                current_impact = 0.0
-                for i in range(n_vars):
-                    if (mask >> i) & 1:
-                        current_impact += unreliable_ifs[i]['impact']
-
-                imbalance = abs(base_net_flow + current_impact)
-                if imbalance < min_imbalance:
-                    min_imbalance = imbalance
-                    best_mask = mask
-
-            # Find ambiguous solutions (those close to min_imbalance)
-            total_flow = max(reliable_inputs, reliable_outputs, 1.0) # Approx
-            ambiguity_threshold = min_imbalance + max(1.0, 0.05 * total_flow)
-
-            for mask in range(1 << n_vars):
-                current_impact = 0.0
-                for i in range(n_vars):
-                    if (mask >> i) & 1:
-                        current_impact += unreliable_ifs[i]['impact']
-
-                if abs(base_net_flow + current_impact) <= ambiguity_threshold:
-                    valid_masks.append(mask)
-        else:
-            # Greedy fallback for huge routers (rare)
-            # Just use base_mask=0 for huge routers to be safe
-            valid_masks = [0]
-
-        # Determine Final Values & Ambiguity
-        decisions = {}
-        ambiguity_scores = {} # key -> 0.0 to 1.0 (1.0 = ambiguous)
-
-        # Calculate ambiguity per variable
-        if valid_masks:
-            for i in range(n_vars):
-                # Check if bit i varies across valid_masks
-                first_val = (valid_masks[0] >> i) & 1
-                is_constant = all(((m >> i) & 1) == first_val for m in valid_masks)
-                ambiguity_scores[unreliable_ifs[i]['key']] = 0.0 if is_constant else 1.0
-
-        # Apply Best Mask
-        h1_inputs = reliable_inputs
-        h1_outputs = reliable_outputs
-
-        for i in range(n_vars):
-            item = unreliable_ifs[i]
-            key = item['key']
-            use_local = (best_mask >> i) & 1
-
-            val = item['local'] if use_local else item['peer']
-            decisions[key] = val
-
-        # Re-sum for accurate final imbalance
-        final_inputs = 0.0
-        final_outputs = 0.0
-
-        for if_id in if_list:
-            if if_id not in link_analysis: continue
-
-            # RX
-            if (if_id, 'rx') in decisions:
-                final_inputs += decisions[(if_id, 'rx')]
-            elif link_analysis[if_id]['rx']['symmetry'] > 0.95:
-                val = link_analysis[if_id]['rx']['candidates'].get('consensus', link_analysis[if_id]['rx']['candidates']['local'])
-                final_inputs += val
-
-            # TX
-            if (if_id, 'tx') in decisions:
-                final_outputs += decisions[(if_id, 'tx')]
-            elif link_analysis[if_id]['tx']['symmetry'] > 0.95:
-                val = link_analysis[if_id]['tx']['candidates'].get('consensus', link_analysis[if_id]['tx']['candidates']['local'])
-                final_outputs += val
-
-        # Conservation Score
-        final_imbalance = abs(final_inputs - final_outputs)
-        max_flow = max(final_inputs, final_outputs, 1.0)
-        conservation_score = max(0.0, 1.0 - (final_imbalance / max_flow))
-
-        # Store Results
-        for if_id in if_list:
-            if if_id not in final_decisions: final_decisions[if_id] = {}
-
-            for metric in ['rx', 'tx']:
-                key = (if_id, metric)
-                if key in decisions:
-                    val = decisions[key]
-                    is_ambiguous = ambiguity_scores.get(key, 0.0)
-                    # Confidence: Base 0.5. Bonus from Conservation. Penalty from Ambiguity.
-                    # If ambiguous (score=1.0), factor is 0.5. If stable (score=0.0), factor is 1.0.
-                    stability = 1.0 - (0.5 * is_ambiguous)
-                    conf = 0.5 + (0.4 * conservation_score * stability)
-                    final_decisions[if_id][metric] = (val, conf)
-                else:
-                    # Reliable
-                    info = link_analysis[if_id][metric]
-                    val = info['candidates'].get('consensus', info['candidates']['local'])
-                    # Reliable links are trusted, but extreme router violation reduces conf slightly
-                    final_decisions[if_id][metric] = (val, 0.9 + 0.1 * conservation_score)
-
-    # --- PHASE 3: Status Inference & Assembly ---
+                # External TX: Can we infer from router balance?
+                # We want Out = In - Other_Out.
+                # My_TX = (In - Other_Out_Excl_Me)
+                rid = if_to_router.get(src_if)
+                if rid:
+                    # Current Imb = In - Out_Total
+                    # Wanted Imb = 0
+                    # Imb = In - (Other + My_TX)
+                    # My_New_TX = In - Other = Imb + My_Old_TX
+                    cur_imb, _ = get_router_imbalance(rid, current_state)
+                    computed = cur_imb + current_state[src_if]['tx']
+                    if computed > 0:
+                        candidates_tx.add(computed)
+            
+            # Select Best Candidate for TX
+            best_tx_val = current_state[src_if]['tx']
+            best_tx_score = -1.0
+            
+            r_src = if_to_router.get(src_if)
+            r_dst = if_to_router.get(dst_if) if is_internal else None
+            
+            for val in candidates_tx:
+                # 1. Source Conservation (TX leaves router)
+                score_src = 1.0
+                if r_src:
+                    old_val = current_state[src_if]['tx']
+                    imb, flow = get_router_imbalance(r_src, current_state)
+                    # New Imb = Old_Imb - (New_Val - Old_Val)
+                    new_imb = imb - (val - old_val)
+                    sigma = max(flow * CONSERVATION_TOLERANCE_PCT, 0.5)
+                    score_src = math.exp(-abs(new_imb) / sigma)
+                
+                # 2. Dest Conservation (RX enters router) - only if internal
+                score_dst = 1.0
+                if r_dst:
+                    old_val = current_state[dst_if]['rx']
+                    imb, flow = get_router_imbalance(r_dst, current_state)
+                    # New Imb = Old_Imb + (New_Val - Old_Val)
+                    new_imb = imb + (val - old_val)
+                    sigma = max(flow * CONSERVATION_TOLERANCE_PCT, 0.5)
+                    score_dst = math.exp(-abs(new_imb) / sigma)
+                
+                # 3. Measurement Prior
+                # Prior favors local TX and Peer RX (if exists)
+                dist_local = abs(val - val_local_tx)
+                sigma_meas = max(val_local_tx * 0.05, 1.0)
+                prior = math.exp(-dist_local / sigma_meas)
+                
+                if is_internal:
+                    val_peer_rx = telemetry[dst_if].get('rx_rate', 0.0)
+                    dist_peer = abs(val - val_peer_rx)
+                    sigma_peer = max(val_peer_rx * 0.05, 1.0)
+                    prior = max(prior, math.exp(-dist_peer / sigma_peer))
+                
+                # 0.0 Prior Penalty/Boost
+                if val == 0.0:
+                    # If measurements are large, 0.0 is unlikely unless conservation demands it strongly
+                    measured_max = max(val_local_tx, telemetry[dst_if].get('rx_rate', 0.0) if is_internal else 0)
+                    if measured_max > 5.0:
+                        prior *= 0.1
+                
+                total = score_src * score_dst * math.sqrt(prior + 0.001)
+                if total > best_tx_score:
+                    best_tx_score = total
+                    best_tx_val = val
+            
+            next_state[src_if]['tx'] = best_tx_val
+            if is_internal:
+                next_state[dst_if]['rx'] = best_tx_val
+            
+            # --- B. Handle External RX Flow (Cloud -> if_id) ---
+            if not is_internal:
+                val_local_rx = data.get('rx_rate', 0.0)
+                candidates_rx = {val_local_rx, 0.0}
+                
+                # Infer from router balance?
+                # My_RX = Out_Total - Other_In = Out_Total - (In_Total - My_Old_RX)
+                # My_New_RX = My_Old_RX - Imb (since Imb = In - Out)
+                rid = if_to_router.get(if_id)
+                if rid:
+                    cur_imb, _ = get_router_imbalance(rid, current_state)
+                    computed = current_state[if_id]['rx'] - cur_imb
+                    if computed > 0:
+                        candidates_rx.add(computed)
+                
+                best_rx_val = current_state[if_id]['rx']
+                best_rx_score = -1.0
+                
+                for val in candidates_rx:
+                    # 1. Router Conservation (RX enters router)
+                    score_r = 1.0
+                    if rid:
+                        old_val = current_state[if_id]['rx']
+                        imb, flow = get_router_imbalance(rid, current_state)
+                        # New Imb = Old_Imb + (New_Val - Old_Val)
+                        new_imb = imb + (val - old_val)
+                        sigma = max(flow * CONSERVATION_TOLERANCE_PCT, 0.5)
+                        score_r = math.exp(-abs(new_imb) / sigma)
+                    
+                    # 2. Prior
+                    dist = abs(val - val_local_rx)
+                    sigma_m = max(val_local_rx * 0.05, 1.0)
+                    prior = math.exp(-dist / sigma_m)
+                    
+                    if val == 0.0 and val_local_rx > 5.0:
+                        prior *= 0.1
+                        
+                    total = score_r * math.sqrt(prior + 0.001)
+                    if total > best_rx_score:
+                        best_rx_score = total
+                        best_rx_val = val
+                        
+                next_state[if_id]['rx'] = best_rx_val
+                
+        current_state = next_state
+
+    # --- 3. Final Assembly ---
     result = {}
-
+    
     for if_id, data in telemetry.items():
+        rx_val = current_state[if_id]['rx']
+        tx_val = current_state[if_id]['tx']
+        
+        rid = if_to_router.get(if_id)
+        
+        # Conservation Quality
+        cons_score = 0.95
+        if rid:
+            imb, flow = get_router_imbalance(rid, current_state)
+            # Use a slightly loose tolerance for confidence scoring to avoid punishing minor noise
+            sigma = max(flow * 0.05, 2.0) 
+            cons_score = math.exp(-abs(imb) / sigma)
+            
+        # Measurement agreement
         orig_rx = data.get('rx_rate', 0.0)
         orig_tx = data.get('tx_rate', 0.0)
+        
+        # Determine Confidence
+        # Base confidence is conservation score.
+        conf_rx = cons_score
+        conf_tx = cons_score
+        
+        # Boost if matches measurement
+        if abs(rx_val - orig_rx) < max(orig_rx, 1.0) * 0.05:
+            conf_rx = max(conf_rx, 0.8 + 0.2 * cons_score)
+        # Boost if matches peer (for internal)
+        peer_id = data.get('connected_to')
+        if peer_id and peer_id in telemetry:
+            peer_tx = telemetry[peer_id].get('tx_rate', 0.0)
+            if abs(rx_val - peer_tx) < max(peer_tx, 1.0) * 0.05:
+                 conf_rx = max(conf_rx, 0.9 + 0.1 * cons_score)
+        
+        if abs(tx_val - orig_tx) < max(orig_tx, 1.0) * 0.05:
+            conf_tx = max(conf_tx, 0.8 + 0.2 * cons_score)
+            
+        # --- Status ---
         orig_status = data.get('interface_status', 'unknown')
-
-        dec = final_decisions.get(if_id, {})
-        rep_rx, conf_rx = dec.get('rx', (orig_rx, 0.0))
-        rep_tx, conf_tx = dec.get('tx', (orig_tx, 0.0))
-
-        peer_id = data.get('connected_to')
-        peer_status = 'unknown'
-        if peer_id and peer_id in telemetry:
-            peer_status = telemetry[peer_id].get('interface_status', 'unknown')
-
-        # Status Logic
-        has_traffic = rep_rx > MIN_FLOW_SIGNIFICANCE or rep_tx > MIN_FLOW_SIGNIFICANCE
-
+        peer_status = telemetry.get(peer_id, {}).get('interface_status', 'unknown') if peer_id in telemetry else 'unknown'
+        
+        has_traffic = (rx_val > MIN_SIGNIFICANT_FLOW) or (tx_val > MIN_SIGNIFICANT_FLOW)
+        
         rep_status = orig_status
         conf_status = 1.0
-
+        
         if has_traffic:
             rep_status = 'up'
             if orig_status != 'up':
                 conf_status = (conf_rx + conf_tx) / 2.0
         elif peer_status == 'down':
             rep_status = 'down'
             if orig_status != 'down':
                 conf_status = 0.9
-        else:
-            rep_status = orig_status
-            if orig_status == 'up' and peer_status == 'down':
-                rep_status = 'down'
-                conf_status = 0.7
-
+        elif orig_status == 'up' and not has_traffic:
+            # Idle is valid
+            rep_status = 'up'
+            
+        # Post-process down
         if rep_status == 'down':
-            rep_rx = 0.0
-            rep_tx = 0.0
-            conf_rx = max(conf_rx, 0.9)
-            conf_tx = max(conf_tx, 0.9)
-
-        repaired_entry = {}
-        repaired_entry['rx_rate'] = (orig_rx, rep_rx, conf_rx)
-        repaired_entry['tx_rate'] = (orig_tx, rep_tx, conf_tx)
-        repaired_entry['interface_status'] = (orig_status, rep_status, conf_status)
-
+            rx_val = 0.0
+            tx_val = 0.0
+            conf_rx = max(conf_rx, 0.95)
+            conf_tx = max(conf_tx, 0.95)
+            
+        entry = {}
+        entry['rx_rate'] = (orig_rx, rx_val, conf_rx)
+        entry['tx_rate'] = (orig_tx, tx_val, conf_tx)
+        entry['interface_status'] = (orig_status, rep_status, conf_status)
+        
         for k in ['connected_to', 'local_router', 'remote_router']:
-            if k in data:
-                repaired_entry[k] = data[k]
-
-        result[if_id] = repaired_entry
-
+            if k in data: entry[k] = data[k]
+            
+        result[if_id] = entry
+        
     return result
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")
