--- a/original.py
+++ b/original.py
@@ -1,427 +1,441 @@
 # EVOLVE-BLOCK-START
 from typing import Dict, Any, Tuple, List
 import math
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
-    Repairs network telemetry using a Bayesian Flow Consensus algorithm.
-    It fuses evidence from Link Symmetry and Router Flow Conservation to
-    probabilistically determine the most likely true state of network counters.
+    Repairs network telemetry using Adaptive Locking Bayesian Consensus.
+    
+    Key Features:
+    - Adaptive Locking: Promotes high-confidence suspect flows to anchors mid-convergence.
+    - Anchor-Weighted External Validation: Adjusts priors for external links based on router trustworthiness.
+    - Hybrid Noise Model: Combines Sqrt (Poisson) and Linear (Drift) error models.
+    - Harmonic Mean Calibration: Provides balanced confidence scores.
     """
 
     # --- Configuration ---
     SYMMETRY_TOLERANCE = 0.02
-    CONSERVATION_TOLERANCE_PCT = 0.03
+    CONSERVATION_TOLERANCE_PCT = 0.02
     MIN_SIGNIFICANT_FLOW = 0.5
     ITERATIONS = 5
+    LOCKING_ITERATION = 3
+    LOCKING_THRESHOLD = 0.90
+    MOMENTUM = 0.6
 
     # --- Helper Structures ---
-    # Map interface to router
     if_to_router = {}
     for r_id, if_list in topology.items():
         for i_id in if_list:
             if_to_router[i_id] = r_id
 
-    # Group interfaces into Links for processing
-    # Link ID = tuple of sorted interface IDs to handle bidirectionality uniquely
+    # State containers
+    estimates = {}
+    
+    # Link classification
     links = {}
     processed_ifs = set()
 
+    # Initial Load
     for if_id, data in telemetry.items():
+        estimates[if_id] = {
+            'rx': data.get('rx_rate', 0.0),
+            'tx': data.get('tx_rate', 0.0)
+        }
+        
         if if_id in processed_ifs: continue
-
-        peer_id = data.get('connected_to')
-        if peer_id and peer_id in telemetry:
-            # Internal Link
-            link_key = tuple(sorted([if_id, peer_id]))
-            links[link_key] = {
-                'type': 'internal',
-                'if1': if_id,
-                'if2': peer_id
-            }
+        
+        peer = data.get('connected_to')
+        if peer and peer in telemetry:
+            link_key = tuple(sorted([if_id, peer]))
+            links[link_key] = {'type': 'internal', 'if1': if_id, 'if2': peer}
             processed_ifs.add(if_id)
-            processed_ifs.add(peer_id)
+            processed_ifs.add(peer)
         else:
-            # Edge/External Link
-            links[(if_id,)] = {
-                'type': 'external',
-                'if1': if_id,
-                'if2': None
-            }
+            links[(if_id,)] = {'type': 'external', 'if1': if_id, 'if2': None}
             processed_ifs.add(if_id)
 
-    # --- Step 1: Initial Link Assessment ---
-    # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
-    # For suspect links, generate hypotheses.
-
-    # Store current best estimates for RX and TX flow on every interface
-    # structure: {if_id: {'rx': val, 'tx': val}}
-    current_estimates = {}
-
-    # Store reliability/confidence of these estimates
-    # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
-    estimate_confidence = {}
-
-    # Suspect flows to solve: list of (link_key, metric_type ('rx_flow' or 'tx_flow'))
-    # Note: 'rx_flow' for link (A,B) means A->B traffic (A TX, B RX).
+    # --- Step 1: Symmetry & Anchoring ---
+    
     suspect_flows = []
-
-    for link_key, info in links.items():
+    anchors = set()
+    locked_flows = set() # (if_id, metric)
+
+    for key, info in links.items():
         if1 = info['if1']
-        if2 = info['if2']
-
-        d1 = telemetry[if1]
-        d2 = telemetry[if2] if if2 else {}
-
-        # Analyze Flow IF1 -> IF2 (IF1 TX, IF2 RX)
-        val1_tx = d1.get('tx_rate', 0.0)
-        val2_rx = d2.get('rx_rate', 0.0) if if2 else None
-
-        if if2:
-            # Internal Link: Check Symmetry
-            denom = max(val1_tx, val2_rx, 1.0)
-            diff = abs(val1_tx - val2_rx)
-
+        
+        if info['type'] == 'internal':
+            if2 = info['if2']
+            
+            # Forward: 1(TX) -> 2(RX)
+            v1, v2 = estimates[if1]['tx'], estimates[if2]['rx']
+            diff = abs(v1 - v2)
+            denom = max(v1, v2, 1.0)
+            
             if diff / denom < SYMMETRY_TOLERANCE:
-                # Consistent
-                consensus = (val1_tx + val2_rx) / 2.0
-                current_estimates[if1] = current_estimates.get(if1, {})
-                current_estimates[if1]['tx'] = consensus
-                current_estimates[if2] = current_estimates.get(if2, {})
-                current_estimates[if2]['rx'] = consensus
-
-                estimate_confidence[if1] = estimate_confidence.get(if1, {})
-                estimate_confidence[if1]['tx'] = 0.95
-                estimate_confidence[if2] = estimate_confidence.get(if2, {})
-                estimate_confidence[if2]['rx'] = 0.95
+                avg = (v1 + v2) / 2.0
+                estimates[if1]['tx'] = avg
+                estimates[if2]['rx'] = avg
+                anchors.add((if1, 'tx'))
+                anchors.add((if2, 'rx'))
+                locked_flows.add((if1, 'tx'))
+                locked_flows.add((if2, 'rx'))
             else:
-                # Suspect
-                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
-                # Initialize with average but low confidence
-                consensus = (val1_tx + val2_rx) / 2.0
-                current_estimates[if1] = current_estimates.get(if1, {})
-                current_estimates[if1]['tx'] = consensus
-                current_estimates[if2] = current_estimates.get(if2, {})
-                current_estimates[if2]['rx'] = consensus
-
-                estimate_confidence[if1] = estimate_confidence.get(if1, {})
-                estimate_confidence[if1]['tx'] = 0.5
-                estimate_confidence[if2] = estimate_confidence.get(if2, {})
-                estimate_confidence[if2]['rx'] = 0.5
+                suspect_flows.append({
+                    'type': 'internal', 'src': if1, 'dst': if2,
+                    'cands': [v1, v2],
+                    'status_src': telemetry[if1].get('interface_status', 'unknown'),
+                    'status_dst': telemetry[if2].get('interface_status', 'unknown')
+                })
+                
+            # Backward: 2(TX) -> 1(RX)
+            v1, v2 = estimates[if2]['tx'], estimates[if1]['rx']
+            diff = abs(v1 - v2)
+            denom = max(v1, v2, 1.0)
+            
+            if diff / denom < SYMMETRY_TOLERANCE:
+                avg = (v1 + v2) / 2.0
+                estimates[if2]['tx'] = avg
+                estimates[if1]['rx'] = avg
+                anchors.add((if2, 'tx'))
+                anchors.add((if1, 'rx'))
+                locked_flows.add((if2, 'tx'))
+                locked_flows.add((if1, 'rx'))
+            else:
+                suspect_flows.append({
+                    'type': 'internal', 'src': if2, 'dst': if1,
+                    'cands': [v1, v2],
+                    'status_src': telemetry[if2].get('interface_status', 'unknown'),
+                    'status_dst': telemetry[if1].get('interface_status', 'unknown')
+                })
         else:
-            # External Link: Trust local blindly for now (no peer to contradict)
-            current_estimates[if1] = current_estimates.get(if1, {})
-            current_estimates[if1]['tx'] = val1_tx
-            estimate_confidence[if1] = estimate_confidence.get(if1, {})
-            estimate_confidence[if1]['tx'] = 0.90 # Less confident than hardened links
-
-        # Analyze Flow IF2 -> IF1 (IF2 TX, IF1 RX)
-        if if2:
-            val2_tx = d2.get('tx_rate', 0.0)
-            val1_rx = d1.get('rx_rate', 0.0)
-
-            denom = max(val2_tx, val1_rx, 1.0)
-            diff = abs(val2_tx - val1_rx)
-
-            if diff / denom < SYMMETRY_TOLERANCE:
-                consensus = (val2_tx + val1_rx) / 2.0
-                current_estimates[if2]['tx'] = consensus
-                current_estimates[if1]['rx'] = consensus
-                estimate_confidence[if2]['tx'] = 0.95
-                estimate_confidence[if1]['rx'] = 0.95
-            else:
-                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
-                consensus = (val2_tx + val1_rx) / 2.0
-                current_estimates[if2]['tx'] = consensus
-                current_estimates[if1]['rx'] = consensus
-                estimate_confidence[if2]['tx'] = 0.5
-                estimate_confidence[if1]['rx'] = 0.5
-        else:
-             # External RX
-            val1_rx = d1.get('rx_rate', 0.0)
-            current_estimates[if1]['rx'] = val1_rx
-            estimate_confidence[if1]['rx'] = 0.90
-
-    # --- Step 2: Iterative Bayesian Refinement ---
-
+            # External
+            suspect_flows.append({
+                'type': 'external', 'src': if1, 'dst': None,
+                'cands': [estimates[if1]['tx']],
+                'metric': 'tx',
+                'status_src': telemetry[if1].get('interface_status', 'unknown')
+            })
+            suspect_flows.append({
+                'type': 'external', 'src': None, 'dst': if1,
+                'cands': [estimates[if1]['rx']],
+                'metric': 'rx',
+                'status_dst': telemetry[if1].get('interface_status', 'unknown')
+            })
+
+    # --- Step 2: Iterative Solver ---
+    
     def get_router_state(rid):
         if rid not in topology: return 0.0, 1.0
         tin, tout = 0.0, 0.0
         max_f = 0.0
         for iid in topology[rid]:
-            if iid in current_estimates:
-                r = current_estimates[iid].get('rx', 0.0)
-                t = current_estimates[iid].get('tx', 0.0)
+            if iid in estimates:
+                r, t = estimates[iid]['rx'], estimates[iid]['tx']
                 tin += r
                 tout += t
                 max_f = max(max_f, r, t)
         return (tin - tout), max(max_f, 1.0)
 
     def calc_sigma(flow_val):
-        return max(math.sqrt(flow_val), flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)
-
-    solver_confidences = {}
-    MOMENTUM = 0.5
-
-    for _ in range(ITERATIONS):
+        return max(math.sqrt(flow_val) * 1.5, flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)
+
+    # Store probability of winning hypothesis
+    solver_probs = {}
+
+    for iter_idx in range(ITERATIONS):
+        # Calculate Router Anchor Strength
+        # This is dynamic: as we lock suspect flows, the anchor strength increases
+        router_anchor_strength = {}
+        for rid in topology:
+            trusted_flow = 0.0
+            total_flow = 0.0
+            for iid in topology[rid]:
+                if iid in estimates:
+                    r, t = estimates[iid]['rx'], estimates[iid]['tx']
+                    total_flow += (r + t)
+                    if (iid, 'rx') in locked_flows: trusted_flow += r
+                    if (iid, 'tx') in locked_flows: trusted_flow += t
+            router_anchor_strength[rid] = trusted_flow / max(total_flow, 1.0)
+
         updates = []
-
-        # 1. Internal Suspect Flows
-        for flow_prob in suspect_flows:
-            link_key = flow_prob['key']
-            direction = flow_prob['dir']
-            candidates = flow_prob['candidates']
-
-            info = links[link_key]
-            if direction == '1_to_2':
-                src_if, dst_if = info['if1'], info['if2']
-            else:
-                src_if, dst_if = info['if2'], info['if1']
-
-            r_src = if_to_router.get(src_if)
-            r_dst = if_to_router.get(dst_if)
-
-            # Hypotheses: [Meas1, Meas2, 0.0] + Mean
-            hyps = sorted(list(set([c for c in candidates if c >= 0] + [0.0])))
-            if len(candidates) == 2:
-                v1, v2 = candidates
-                if abs(v1-v2) < max(v1,v2)*0.2 + 5.0:
-                    hyps.append((v1+v2)/2.0)
-            hyps = sorted(list(set(hyps)))
-
-            curr_tx = current_estimates[src_if]['tx']
-            curr_rx = current_estimates[dst_if]['rx']
-
-            s_src = telemetry[src_if].get('interface_status', 'unknown')
-            s_dst = telemetry[dst_if].get('interface_status', 'unknown')
-
-            scores = []
-            for h in hyps:
-                current_estimates[src_if]['tx'] = h
-                current_estimates[dst_if]['rx'] = h
-
-                imb_s, flow_s = get_router_state(r_src)
-                score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s)) if r_src else 1.0
-
-                imb_d, flow_d = get_router_state(r_dst)
-                score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d)) if r_dst else 1.0
-
-                # Prior
-                prior = 1.0
-                if h == 0.0:
-                    if s_src == 'down' or s_dst == 'down': prior = 0.95
+        new_locks = []
+
+        for f_idx, flow in enumerate(suspect_flows):
+            if flow.get('locked', False): continue
+
+            # --- Internal Flow Logic ---
+            if flow['type'] == 'internal':
+                src, dst = flow['src'], flow['dst']
+                r_src = if_to_router.get(src)
+                r_dst = if_to_router.get(dst)
+                
+                # Candidates
+                cands = [c for c in flow['cands'] if c >= 0]
+                if len(cands) == 2:
+                    v1, v2 = cands
+                    # Add mean if not wildly divergent
+                    if abs(v1-v2) < max(v1,v2)*0.3 + 10.0:
+                        cands.append((v1+v2)/2.0)
+                
+                hyps = sorted(list(set(cands + [0.0])))
+                
+                curr_tx = estimates[src]['tx']
+                curr_rx = estimates[dst]['rx']
+                
+                scores = []
+                for h in hyps:
+                    estimates[src]['tx'] = h
+                    estimates[dst]['rx'] = h
+                    
+                    imb_s, flow_s = get_router_state(r_src)
+                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s)) if r_src else 1.0
+                    
+                    imb_d, flow_d = get_router_state(r_dst)
+                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d)) if r_dst else 1.0
+                    
+                    prior = 1.0
+                    if h == 0.0:
+                        s_src = flow.get('status_src')
+                        s_dst = flow.get('status_dst')
+                        if s_src == 'down' or s_dst == 'down': prior = 0.99
+                        else:
+                             m_val = max(flow['cands'])
+                             if m_val > 5.0: prior = 0.01
+                             elif m_val > 1.0: prior = 0.2
                     else:
-                        m_val = max(candidates)
-                        if m_val > 10.0: prior = 0.01
-                        elif m_val > 1.0: prior = 0.2
+                        # Distance to measurements
+                        dist = min([abs(h - c) for c in flow['cands']])
+                        prior = math.exp(-dist / max(h*0.05, 1.0))
+                        
+                    scores.append(score_s * score_d * prior)
+                
+                estimates[src]['tx'] = curr_tx
+                estimates[dst]['rx'] = curr_rx
+                
+                total = sum(scores) + 1e-20
+                probs = [s/total for s in scores]
+                best_idx = scores.index(max(scores))
+                win_val = hyps[best_idx]
+                win_prob = sum(p for i, p in enumerate(probs) 
+                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))
+                
+                updates.append((src, 'tx', win_val, win_prob))
+                updates.append((dst, 'rx', win_val, win_prob))
+                
+                if iter_idx == LOCKING_ITERATION and win_prob > LOCKING_THRESHOLD:
+                    new_locks.append(f_idx)
+                    locked_flows.add((src, 'tx'))
+                    locked_flows.add((dst, 'rx'))
+
+            # --- External Flow Logic ---
+            elif flow['type'] == 'external':
+                if flow['src']:
+                    if_id = flow['src']
+                    r_id = if_to_router.get(if_id)
+                    metric = 'tx'
+                    meas = flow['cands'][0]
+                    curr = estimates[if_id]['tx']
+                    stat = flow.get('status_src')
+                    imb, r_flow = get_router_state(r_id)
+                    implied = max(0.0, curr + imb)
                 else:
-                    dist = min([abs(h-c) for c in candidates])
-                    prior = math.exp(-dist / max(h*0.05, 1.0))
-
-                scores.append(score_s * score_d * prior)
-
-            current_estimates[src_if]['tx'] = curr_tx
-            current_estimates[dst_if]['rx'] = curr_rx
-
-            best_idx = scores.index(max(scores))
-            win_val = hyps[best_idx]
-
-            # Calibration: Probability mass near winner
-            total = sum(scores) + 1e-20
-            probs = [s/total for s in scores]
-            win_prob = sum(p for i, p in enumerate(probs)
-                           if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))
-
-            updates.append((src_if, 'tx', win_val, win_prob))
-            updates.append((dst_if, 'rx', win_val, win_prob))
-
-        # 2. External Flows
-        for key, info in links.items():
-            if info['type'] != 'external': continue
-            if_id = info['if1']
-            r_id = if_to_router.get(if_id)
-            if not r_id: continue
-
-            metrics = []
-            if 'tx' in current_estimates.get(if_id, {}): metrics.append('tx')
-            if 'rx' in current_estimates.get(if_id, {}): metrics.append('rx')
-
-            stat = telemetry[if_id].get('interface_status', 'unknown')
-
-            for metric in metrics:
-                curr_val = current_estimates[if_id][metric]
-                meas = telemetry[if_id].get(f'{metric}_rate', 0.0)
-
-                imb, r_flow = get_router_state(r_id)
-                if metric == 'tx': implied = max(0.0, curr_val + imb)
-                else: implied = max(0.0, curr_val - imb)
-
+                    if_id = flow['dst']
+                    r_id = if_to_router.get(if_id)
+                    metric = 'rx'
+                    meas = flow['cands'][0]
+                    curr = estimates[if_id]['rx']
+                    stat = flow.get('status_dst')
+                    imb, r_flow = get_router_state(r_id)
+                    implied = max(0.0, curr - imb)
+                
                 hyps = sorted(list(set([meas, implied, 0.0])))
                 scores = []
+                
+                anchor_ratio = router_anchor_strength.get(r_id, 0.0)
+                
                 for h in hyps:
-                    current_estimates[if_id][metric] = h
+                    estimates[if_id][metric] = h
                     imb, rf = get_router_state(r_id)
-                    lik = math.exp(-abs(imb)/calc_sigma(rf))
-
+                    lik = math.exp(-abs(imb)/calc_sigma(rf)) if r_id else 0.5
+                    
                     prior = 1.0
                     if h == 0.0:
-                        if stat == 'down': prior = 0.95
+                        if stat == 'down': prior = 0.99
                         elif meas > 10.0: prior = 0.01
+                        else: prior = 0.5
+                    elif abs(h - implied) < 1e-6:
+                        # Conservation trust scales with anchor strength
+                        # If anchors are 100%, we trust implied 90%. If 0%, trust 10%.
+                        trust = 0.1 + 0.8 * anchor_ratio
+                        prior = trust
                     elif abs(h - meas) < 1e-6:
-                        prior = 0.6
-                    elif abs(h - implied) < 1e-6:
-                        prior = 0.4
-
-                    if h > 0:
-                        prior *= math.exp(-abs(h-meas)/max(meas*0.05, 1.0))
+                        # Measurement trust is inverse of conservation trust
+                        trust = 0.9 - 0.8 * anchor_ratio
+                        prior = trust
+                        
+                        # Extra penalty if measurement deviates wildly from implied on a strong router
+                        if anchor_ratio > 0.8 and abs(h - implied) > max(implied*0.2, 5.0):
+                            prior *= 0.1
 
                     scores.append(lik * prior)
-
-                current_estimates[if_id][metric] = curr_val
-
+                
+                estimates[if_id][metric] = curr
+                
+                total = sum(scores) + 1e-20
+                probs = [s/total for s in scores]
                 best_idx = scores.index(max(scores))
                 win_val = hyps[best_idx]
-                total = sum(scores) + 1e-20
-                probs = [s/total for s in scores]
-                win_prob = sum(p for i, p in enumerate(probs)
-                           if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))
-
+                win_prob = sum(p for i, p in enumerate(probs) 
+                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))
+                
                 updates.append((if_id, metric, win_val, win_prob))
 
-        # Apply
+        # Apply Updates
         for if_id, metric, val, prob in updates:
-            old = current_estimates[if_id][metric]
-            current_estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
-            solver_confidences[(if_id, metric)] = prob
-
-    # --- Step 3: Final Assembly & Status Repair ---
-
+            old = estimates[if_id][metric]
+            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
+            solver_probs[(if_id, metric)] = prob
+            
+        # Lock flows
+        for idx in new_locks:
+            suspect_flows[idx]['locked'] = True
+
+    # --- Step 3: Final Assembly ---
+    
     result = {}
-
-    # Calculate final router conservation fits
+    
+    # Final Router Fits
     router_fits = {}
     for rid in topology:
         imb, flow = get_router_state(rid)
-        fit = math.exp(-abs(imb) / calc_sigma(flow))
-        router_fits[rid] = fit
+        router_fits[rid] = math.exp(-abs(imb) / calc_sigma(flow))
 
     for if_id, data in telemetry.items():
         orig_rx = data.get('rx_rate', 0.0)
         orig_tx = data.get('tx_rate', 0.0)
         orig_status = data.get('interface_status', 'unknown')
-
-        rep_rx = current_estimates[if_id]['rx']
-        rep_tx = current_estimates[if_id]['tx']
-
+        
+        rep_rx = estimates[if_id]['rx']
+        rep_tx = estimates[if_id]['tx']
+        
         rid = if_to_router.get(if_id)
         r_fit = router_fits.get(rid, 0.8)
-
-        def get_final_conf(metric, val, orig_val):
-            # Check if this was a Step 1 Anchor (high confidence in estimate_confidence)
-            step1_conf = estimate_confidence.get(if_id, {}).get(metric, 0.0)
-            if step1_conf > 0.9:
-                return 0.95
-
-            # Otherwise use Solver Confidence
-            sol_prob = solver_confidences.get((if_id, metric), 0.5)
-
-            # Combine: Probability * Fit Quality
-            base = sol_prob * (0.3 + 0.7 * r_fit)
-
-            # If value didn't change much from measurement, boost confidence slightly
-            if abs(val - orig_val) < max(orig_val * 0.1, 1.0):
-                base = max(base, 0.8 * r_fit + 0.1)
-
-            return max(0.01, min(0.99, base))
-
-        conf_rx = get_final_conf('rx', rep_rx, orig_rx)
-        conf_tx = get_final_conf('tx', rep_tx, orig_tx)
-
-        # Status Inference
+        
+        def calc_conf(metric, rep_val, orig_val):
+            # 1. Anchors are high confidence
+            if (if_id, metric) in anchors:
+                return 0.98
+            
+            # 2. Solver Confidence
+            prob = solver_probs.get((if_id, metric), 0.5)
+            
+            # 3. Harmonic Mean of Certainty and Fit
+            # This penalizes if either is low, but rewards if both are high
+            # Add small epsilon to avoid div by zero
+            # We treat 'prob' and 'r_fit' as two independent signals of quality
+            
+            # However, if we barely changed the value, we should be more confident
+            # (Validating the measurement)
+            is_close = abs(rep_val - orig_val) < max(orig_val * 0.05, 1.0)
+            
+            if is_close:
+                # If we agreed with measurement, we are confident unless router fit is terrible
+                base_conf = 0.8 + 0.15 * r_fit
+            else:
+                # We disagreed. We need high solver prob AND high router fit to be confident.
+                # Use harmonic mean of Prob and Fit
+                base_conf = 2 * (prob * r_fit) / (prob + r_fit + 1e-9)
+            
+            return max(0.01, min(0.99, base_conf))
+
+        conf_rx = calc_conf('rx', rep_rx, orig_rx)
+        conf_tx = calc_conf('tx', rep_tx, orig_tx)
+        
+        # Status Logic
         peer_id = data.get('connected_to')
         peer_status = 'unknown'
         if peer_id and peer_id in telemetry:
             peer_status = telemetry[peer_id].get('interface_status', 'unknown')
-
+            
         has_traffic = (rep_rx > MIN_SIGNIFICANT_FLOW) or (rep_tx > MIN_SIGNIFICANT_FLOW)
-
+        
         rep_status = orig_status
         conf_status = 1.0
-
+        
         if has_traffic:
             rep_status = 'up'
             if orig_status != 'up':
                 conf_status = (conf_rx + conf_tx) / 2.0
         elif peer_status == 'down':
             rep_status = 'down'
             if orig_status != 'down':
-                conf_status = 0.9
+                conf_status = 0.95
         else:
             rep_status = orig_status
-
+            
         if rep_status == 'down':
             rep_rx, rep_tx = 0.0, 0.0
             conf_rx = max(conf_rx, 0.95)
             conf_tx = max(conf_tx, 0.95)
-
+            
         entry = {}
         entry['rx_rate'] = (orig_rx, rep_rx, conf_rx)
         entry['tx_rate'] = (orig_tx, rep_tx, conf_tx)
         entry['interface_status'] = (orig_status, rep_status, conf_status)
         for k in ['connected_to', 'local_router', 'remote_router']:
             if k in data: entry[k] = data[k]
         result[if_id] = entry
-
+        
     return result
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")