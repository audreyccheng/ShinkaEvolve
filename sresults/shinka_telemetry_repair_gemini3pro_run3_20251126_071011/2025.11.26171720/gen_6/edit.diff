--- a/original.py
+++ b/original.py
@@ -1,183 +1,369 @@
 # EVOLVE-BLOCK-START
-"""
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
-"""
 from typing import Dict, Any, Tuple, List
-
+import math
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-    
-    Core principle: Use network invariants to validate and repair telemetry:
-    1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
-    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
-    3. Interface Consistency: Status should be consistent across connected pairs
-    
-    Args:
-        telemetry: Dictionary where key is interface_id and value contains:
-            - interface_status: "up" or "down" 
-            - rx_rate: receive rate in Mbps
-            - tx_rate: transmit rate in Mbps
-            - connected_to: interface_id this interface connects to
-            - local_router: router_id this interface belongs to
-            - remote_router: router_id on the other side
-        topology: Dictionary where key is router_id and value contains a list of interface_ids
-        
-    Returns:
-        Dictionary with same structure but telemetry values become tuples of:
-        (original_value, repaired_value, confidence_score)
-        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
+    Repairs network telemetry using a Bayesian Flow Consensus algorithm.
+    It fuses evidence from Link Symmetry and Router Flow Conservation to 
+    probabilistically determine the most likely true state of network counters.
     """
     
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
+    # --- Configuration ---
+    SYMMETRY_TOLERANCE = 0.02
+    CONSERVATION_TOLERANCE_PCT = 0.03
+    MIN_SIGNIFICANT_FLOW = 0.5
+    ITERATIONS = 3
+    
+    # --- Helper Structures ---
+    # Map interface to router
+    if_to_router = {}
+    for r_id, if_list in topology.items():
+        for i_id in if_list:
+            if_to_router[i_id] = r_id
+            
+    # Group interfaces into Links for processing
+    # Link ID = tuple of sorted interface IDs to handle bidirectionality uniquely
+    links = {}
+    processed_ifs = set()
+    
+    for if_id, data in telemetry.items():
+        if if_id in processed_ifs: continue
+        
+        peer_id = data.get('connected_to')
+        if peer_id and peer_id in telemetry:
+            # Internal Link
+            link_key = tuple(sorted([if_id, peer_id]))
+            links[link_key] = {
+                'type': 'internal',
+                'if1': if_id,
+                'if2': peer_id
+            }
+            processed_ifs.add(if_id)
+            processed_ifs.add(peer_id)
+        else:
+            # Edge/External Link
+            links[(if_id,)] = {
+                'type': 'external',
+                'if1': if_id,
+                'if2': None
+            }
+            processed_ifs.add(if_id)
+
+    # --- Step 1: Initial Link Assessment ---
+    # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
+    # For suspect links, generate hypotheses.
+    
+    # Store current best estimates for RX and TX flow on every interface
+    # structure: {if_id: {'rx': val, 'tx': val}}
+    current_estimates = {}
+    
+    # Store reliability/confidence of these estimates
+    # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
+    estimate_confidence = {}
+    
+    # Suspect flows to solve: list of (link_key, metric_type ('rx_flow' or 'tx_flow'))
+    # Note: 'rx_flow' for link (A,B) means A->B traffic (A TX, B RX).
+    suspect_flows = []
+    
+    for link_key, info in links.items():
+        if1 = info['if1']
+        if2 = info['if2']
+        
+        d1 = telemetry[if1]
+        d2 = telemetry[if2] if if2 else {}
+        
+        # Analyze Flow IF1 -> IF2 (IF1 TX, IF2 RX)
+        val1_tx = d1.get('tx_rate', 0.0)
+        val2_rx = d2.get('rx_rate', 0.0) if if2 else None
+        
+        if if2:
+            # Internal Link: Check Symmetry
+            denom = max(val1_tx, val2_rx, 1.0)
+            diff = abs(val1_tx - val2_rx)
+            
+            if diff / denom < SYMMETRY_TOLERANCE:
+                # Consistent
+                consensus = (val1_tx + val2_rx) / 2.0
+                current_estimates[if1] = current_estimates.get(if1, {})
+                current_estimates[if1]['tx'] = consensus
+                current_estimates[if2] = current_estimates.get(if2, {})
+                current_estimates[if2]['rx'] = consensus
+                
+                estimate_confidence[if1] = estimate_confidence.get(if1, {})
+                estimate_confidence[if1]['tx'] = 1.0
+                estimate_confidence[if2] = estimate_confidence.get(if2, {})
+                estimate_confidence[if2]['rx'] = 1.0
+            else:
+                # Suspect
+                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
+                # Initialize with average but low confidence
+                consensus = (val1_tx + val2_rx) / 2.0
+                current_estimates[if1] = current_estimates.get(if1, {})
+                current_estimates[if1]['tx'] = consensus
+                current_estimates[if2] = current_estimates.get(if2, {})
+                current_estimates[if2]['rx'] = consensus
+                
+                estimate_confidence[if1] = estimate_confidence.get(if1, {})
+                estimate_confidence[if1]['tx'] = 0.5
+                estimate_confidence[if2] = estimate_confidence.get(if2, {})
+                estimate_confidence[if2]['rx'] = 0.5
+        else:
+            # External Link: Trust local blindly for now (no peer to contradict)
+            current_estimates[if1] = current_estimates.get(if1, {})
+            current_estimates[if1]['tx'] = val1_tx
+            estimate_confidence[if1] = estimate_confidence.get(if1, {})
+            estimate_confidence[if1]['tx'] = 1.0 # Tentative
+            
+        # Analyze Flow IF2 -> IF1 (IF2 TX, IF1 RX)
+        if if2:
+            val2_tx = d2.get('tx_rate', 0.0)
+            val1_rx = d1.get('rx_rate', 0.0)
+            
+            denom = max(val2_tx, val1_rx, 1.0)
+            diff = abs(val2_tx - val1_rx)
+            
+            if diff / denom < SYMMETRY_TOLERANCE:
+                consensus = (val2_tx + val1_rx) / 2.0
+                current_estimates[if2]['tx'] = consensus
+                current_estimates[if1]['rx'] = consensus
+                estimate_confidence[if2]['tx'] = 1.0
+                estimate_confidence[if1]['rx'] = 1.0
+            else:
+                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
+                consensus = (val2_tx + val1_rx) / 2.0
+                current_estimates[if2]['tx'] = consensus
+                current_estimates[if1]['rx'] = consensus
+                estimate_confidence[if2]['tx'] = 0.5
+                estimate_confidence[if1]['rx'] = 0.5
+        else:
+             # External RX
+            val1_rx = d1.get('rx_rate', 0.0)
+            current_estimates[if1]['rx'] = val1_rx
+            estimate_confidence[if1]['rx'] = 1.0
+
+    # --- Step 2: Iterative Bayesian Refinement ---
+    
+    # Helper to calculate router imbalance given current estimates
+    def get_router_imbalance(rid):
+        if_list = topology.get(rid, [])
+        total_in = 0.0
+        total_out = 0.0
+        for iid in if_list:
+            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
+            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
+        return total_in - total_out, max(total_in, total_out, 1.0)
+
+    # Iteration loop
+    for _ in range(ITERATIONS):
+        updates = {} # Store updates to apply after full pass
+        
+        for flow_prob in suspect_flows:
+            link_key = flow_prob['key']
+            direction = flow_prob['dir']
+            candidates = flow_prob['candidates']
+            
+            # Identify interfaces and routers involved
+            info = links[link_key]
+            if direction == '1_to_2':
+                src_if, dst_if = info['if1'], info['if2']
+                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
+            else:
+                src_if, dst_if = info['if2'], info['if1']
+                val_src, val_dst = candidates[0], candidates[1]
+                
+            router_src = if_to_router.get(src_if)
+            router_dst = if_to_router.get(dst_if)
+            
+            # Evaluate Hypothesis 1: Value is val_src (Local TX measurement)
+            # Evaluate Hypothesis 2: Value is val_dst (Peer RX measurement)
+            # We also consider their average as a fallback hypothesis 3? No, keep it binary for strong signals.
+            
+            hyps = [val_src, val_dst]
+            scores = []
+            
+            for h_val in hyps:
+                # Probability score based on Gaussian likelihood of imbalance
+                
+                # Check Source Router Imbalance if we use h_val for this TX interface
+                # Temporarily replace value in calculation
+                old_tx = current_estimates[src_if]['tx']
+                current_estimates[src_if]['tx'] = h_val
+                imb_src, flow_src = get_router_imbalance(router_src)
+                # Restore
+                current_estimates[src_if]['tx'] = old_tx
+                
+                # Check Dest Router Imbalance if we use h_val for this RX interface
+                old_rx = current_estimates[dst_if]['rx']
+                current_estimates[dst_if]['rx'] = h_val
+                imb_dst, flow_dst = get_router_imbalance(router_dst)
+                current_estimates[dst_if]['rx'] = old_rx
+                
+                # Likelihood function: P ~ exp(- |imbalance| / sigma)
+                # sigma is tolerance proportional to flow
+                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
+                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)
+                
+                score_src = math.exp(-abs(imb_src) / sigma_src)
+                score_dst = math.exp(-abs(imb_dst) / sigma_dst)
+                
+                # Combined score (Bayesian update assuming independent router evidence)
+                # We add a small epsilon prior favoring "no change" if both bad, 
+                # but here we just multiply.
+                scores.append(score_src * score_dst)
+            
+            # Select Winner
+            s1, s2 = scores[0], scores[1]
+            total_s = s1 + s2 + 1e-9
+            
+            p1 = s1 / total_s
+            p2 = s2 / total_s
+            
+            if p1 > p2:
+                winner_val = val_src
+                # Confidence is probability mass of winner
+                # If p1 ~ 0.5, confidence is low. If p1 ~ 1.0, high.
+                # Map 0.5-1.0 to 0.0-1.0 roughly
+                conf = (p1 - 0.5) * 2.0
+                conf = max(0.0, min(1.0, conf))
+            else:
+                winner_val = val_dst
+                conf = (p2 - 0.5) * 2.0
+                conf = max(0.0, min(1.0, conf))
+            
+            # Store update
+            updates[(src_if, 'tx')] = (winner_val, conf)
+            updates[(dst_if, 'rx')] = (winner_val, conf)
+            
+        # Apply updates
+        for (if_id, metric), (val, conf) in updates.items():
+            current_estimates[if_id][metric] = val
+            estimate_confidence[if_id][metric] = conf
+
+    # --- Step 3: Final Assembly & Status Repair ---
     
     result = {}
     
-    # First pass: collect all measurements and check link symmetry
-    link_symmetry_violations = {}
-    
-    for interface_id, data in telemetry.items():
-        interface_status = data.get('interface_status', 'unknown')
-        rx_rate = data.get('rx_rate', 0.0)
-        tx_rate = data.get('tx_rate', 0.0)
-        connected_to = data.get('connected_to')
-        
-        # Check link symmetry if connected interface exists
-        if connected_to and connected_to in telemetry:
-            peer_data = telemetry[connected_to]
-            peer_rx = peer_data.get('rx_rate', 0.0)
-            peer_tx = peer_data.get('tx_rate', 0.0)
-            
-            # My TX should match their RX (within tolerance)
-            tx_rx_diff = abs(tx_rate - peer_rx) / max(tx_rate, peer_rx, 1.0)
-            # My RX should match their TX (within tolerance)
-            rx_tx_diff = abs(rx_rate - peer_tx) / max(rx_rate, peer_tx, 1.0)
-            
-            link_symmetry_violations[interface_id] = {
-                'tx_rx_diff': tx_rx_diff,
-                'rx_tx_diff': rx_tx_diff,
-                'peer_rx': peer_rx,
-                'peer_tx': peer_tx
-            }
-    
-    # Second pass: repair using redundant signals
-    for interface_id, data in telemetry.items():
-        repaired_data = {}
-        
-        interface_status = data.get('interface_status', 'unknown')
-        rx_rate = data.get('rx_rate', 0.0)
-        tx_rate = data.get('tx_rate', 0.0)
-        connected_to = data.get('connected_to')
-        
-        # Default: no repair, high confidence
-        repaired_rx = rx_rate
-        repaired_tx = tx_rate
-        repaired_status = interface_status
-        rx_confidence = 1.0
-        tx_confidence = 1.0
-        status_confidence = 1.0
-        
-        # Check for issues and attempt repair
-        if interface_id in link_symmetry_violations:
-            violations = link_symmetry_violations[interface_id]
-            
-            # Repair RX rate if link symmetry is violated
-            if violations['rx_tx_diff'] > HARDENING_THRESHOLD:
-                # Use peer's TX as more reliable signal
-                repaired_rx = violations['peer_tx']
-                # Confidence decreases with magnitude of violation
-                rx_confidence = max(0.0, 1.0 - violations['rx_tx_diff'])
-            
-            # Repair TX rate if link symmetry is violated
-            if violations['tx_rx_diff'] > HARDENING_THRESHOLD:
-                # Use peer's RX as more reliable signal
-                repaired_tx = violations['peer_rx']
-                # Confidence decreases with magnitude of violation
-                tx_confidence = max(0.0, 1.0 - violations['tx_rx_diff'])
-        
-        # Check status consistency
-        if connected_to and connected_to in telemetry:
-            peer_status = telemetry[connected_to].get('interface_status', 'unknown')
-            # If statuses don't match, lower confidence
-            if interface_status != peer_status:
-                status_confidence = 0.5
-                # If interface is down but has non-zero rates, that's suspicious
-                if interface_status == 'down' and (rx_rate > 0 or tx_rate > 0):
-                    repaired_rx = 0.0
-                    repaired_tx = 0.0
-                    rx_confidence = 0.3
-                    tx_confidence = 0.3
-        
-        # Store repaired values with confidence scores
-        repaired_data['rx_rate'] = (rx_rate, repaired_rx, rx_confidence)
-        repaired_data['tx_rate'] = (tx_rate, repaired_tx, tx_confidence)
-        repaired_data['interface_status'] = (interface_status, repaired_status, status_confidence)
-        
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = connected_to
-        repaired_data['local_router'] = data.get('local_router')
-        repaired_data['remote_router'] = data.get('remote_router')
-        
-        result[interface_id] = repaired_data
-    
+    for if_id, data in telemetry.items():
+        orig_rx = data.get('rx_rate', 0.0)
+        orig_tx = data.get('tx_rate', 0.0)
+        orig_status = data.get('interface_status', 'unknown')
+        
+        # Repaired Rates
+        est_rx = current_estimates[if_id]['rx']
+        conf_rx = estimate_confidence[if_id]['rx']
+        
+        est_tx = current_estimates[if_id]['tx']
+        conf_tx = estimate_confidence[if_id]['tx']
+        
+        # Status Inference
+        # Determine peer status
+        peer_id = data.get('connected_to')
+        peer_status = 'unknown'
+        if peer_id and peer_id in telemetry:
+            peer_status = telemetry[peer_id].get('interface_status', 'unknown')
+            
+        # 1. Existence of significant traffic implies UP
+        has_rx = est_rx > MIN_SIGNIFICANT_FLOW
+        has_tx = est_tx > MIN_SIGNIFICANT_FLOW
+        
+        rep_status = orig_status
+        conf_status = 1.0 # Baseline
+        
+        if has_rx or has_tx:
+            rep_status = 'up'
+            if orig_status != 'up':
+                # We are overturning status based on traffic.
+                # Confidence depends on traffic confidence.
+                flow_conf = max(conf_rx if has_rx else 0, conf_tx if has_tx else 0)
+                conf_status = flow_conf
+        
+        elif peer_status == 'down':
+            # Peer is down and we have no traffic -> We should be down (usually)
+            rep_status = 'down'
+            if orig_status != 'down':
+                conf_status = 0.9
+        
+        elif orig_status == 'up' and not has_rx and not has_tx:
+            # We say UP, but no traffic. 
+            # Could be idle. 
+            # If peer is UP, likely idle -> Keep UP.
+            # If peer is DOWN (caught above), then DOWN.
+            # If peer unknown, keep UP.
+            rep_status = 'up'
+        
+        # Post-process: If status is DOWN, force rates to 0
+        if rep_status == 'down':
+            est_rx = 0.0
+            est_tx = 0.0
+            # High confidence in 0 if we are confident it's down
+            conf_rx = max(conf_rx, conf_status)
+            conf_tx = max(conf_tx, conf_status)
+            
+        # Result Construction
+        entry = {}
+        entry['rx_rate'] = (orig_rx, est_rx, conf_rx)
+        entry['tx_rate'] = (orig_tx, est_tx, conf_tx)
+        entry['interface_status'] = (orig_status, rep_status, conf_status)
+        
+        # Metadata
+        for k in ['connected_to', 'local_router', 'remote_router']:
+            if k in data:
+                entry[k] = data[k]
+        
+        result[if_id] = entry
+        
     return result
-
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
     
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
     
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
     
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
     
     result = run_repair(test_telemetry, test_topology)
     
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")
 
