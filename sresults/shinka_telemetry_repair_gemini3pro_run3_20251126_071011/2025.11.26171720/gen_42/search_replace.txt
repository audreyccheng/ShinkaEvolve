<NAME>
continuous_voting_repair
</NAME>

<DESCRIPTION>
I am replacing the binary logic for flow validity with a continuous reliability score (0.0 to 1.0) in both Phase 2 and Phase 3. This allows the algorithm to weight flow conservation info proportionally to its quality, rather than discarding it entirely if it exceeds a 5% threshold.

I am also replacing the rigid `arbitrate` function with a `arbitrate_voting` function that uses Weighted Cluster Voting. This clusters available signals (Self, Peer, Flow) based on tolerance and selects the consensus value based on summed weights (Self=0.8, Peer=1.0, Flow=Reliability). This elegantly handles all conflict permutations (e.g., Peer+Flow vs Self) and isolated link scenarios (Self vs Flow) without hardcoded case logic, leading to better confidence calibration.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # 1. Calculate Router Totals
        router_totals = {}
        for router_id, if_list in topology.items():
            valid_ifs = [i for i in if_list if i in working_state]
            t_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
            t_out = sum(working_state[i]['est_tx'] for i in valid_ifs)

            imb = abs(t_in - t_out)
            mx = max(t_in, t_out, 1.0)
            reliable = (imb / mx) < 0.05
            router_totals[router_id] = {'in': t_in, 'out': t_out, 'reliable': reliable}

        # 2. Update Estimates
        for if_id, d in working_state.items():
            r_id = telemetry[if_id].get('local_router')
            f_rx, f_tx, f_valid = d['est_rx'], d['est_tx'], False

            if r_id and r_id in router_totals:
                rt = router_totals[r_id]
                f_rx = max(0.0, rt['out'] - (rt['in'] - d['est_rx']))
                f_tx = max(0.0, rt['in'] - (rt['out'] - d['est_tx']))
                f_valid = rt['reliable']

            if d['status'] == 'down':
                d['est_rx'], d['est_tx'] = 0.0, 0.0
            else:
                # Update estimates using soft arbitration
                v_rx, _ = arbitrate(d['s_rx'], d['p_tx'], f_rx, d['has_peer'], f_valid, REL_TOL, ABS_TOL)
                v_tx, _ = arbitrate(d['s_tx'], d['p_rx'], f_tx, d['has_peer'], f_valid, REL_TOL, ABS_TOL)
                d['est_rx'] = 0.5 * d['est_rx'] + 0.5 * v_rx
                d['est_tx'] = 0.5 * d['est_tx'] + 0.5 * v_tx
=======
        # 1. Calculate Router Totals & Reliability
        router_totals = {}
        for router_id, if_list in topology.items():
            valid_ifs = [i for i in if_list if i in working_state]
            t_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
            t_out = sum(working_state[i]['est_tx'] for i in valid_ifs)

            imb = abs(t_in - t_out)
            mx = max(t_in, t_out, 1.0)

            # Continuous reliability: 1.0 at 0% imbalance, 0.0 at 10% imbalance
            ratio = imb / mx
            reliability = max(0.0, 1.0 - (ratio * 10.0))
            router_totals[router_id] = {'in': t_in, 'out': t_out, 'rel': reliability}

        # 2. Update Estimates
        for if_id, d in working_state.items():
            r_id = telemetry[if_id].get('local_router')
            f_rx, f_tx, f_qual = d['est_rx'], d['est_tx'], 0.0

            if r_id and r_id in router_totals:
                rt = router_totals[r_id]
                f_rx = max(0.0, rt['out'] - (rt['in'] - d['est_rx']))
                f_tx = max(0.0, rt['in'] - (rt['out'] - d['est_tx']))
                f_qual = rt['rel']

            if d['status'] == 'down':
                d['est_rx'], d['est_tx'] = 0.0, 0.0
            else:
                # Update estimates using weighted voting
                v_rx, _ = arbitrate_voting(d['s_rx'], d['p_tx'], f_rx, d['has_peer'], f_qual, REL_TOL, ABS_TOL)
                v_tx, _ = arbitrate_voting(d['s_tx'], d['p_rx'], f_tx, d['has_peer'], f_qual, REL_TOL, ABS_TOL)

                d['est_rx'] = 0.5 * d['est_rx'] + 0.5 * v_rx
                d['est_tx'] = 0.5 * d['est_tx'] + 0.5 * v_tx
>>>>>>> REPLACE
<<<<<<< SEARCH
    # Recalculate Flow Targets one last time
    flow_context = {}
    for router_id, if_list in topology.items():
        valid_ifs = [i for i in if_list if i in working_state]
        t_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
        t_out = sum(working_state[i]['est_tx'] for i in valid_ifs)
        reliable = (abs(t_in - t_out) / max(t_in, t_out, 1.0)) < 0.05

        for i in valid_ifs:
            ws = working_state[i]
            target_rx = max(0.0, t_out - (t_in - ws['est_rx']))
            target_tx = max(0.0, t_in - (t_out - ws['est_tx']))
            flow_context[i] = {'rx': target_rx, 'tx': target_tx, 'valid': reliable}

    for if_id, d in working_state.items():
        f_ctx = flow_context.get(if_id, {'rx': 0.0, 'tx': 0.0, 'valid': False})

        if d['status'] == 'down':
            final_rx, final_tx = 0.0, 0.0
            conf_rx = 0.95 if d['s_rx'] > ABS_TOL else 1.0
            conf_tx = 0.95 if d['s_tx'] > ABS_TOL else 1.0
        else:
            final_rx, conf_rx = arbitrate(
                d['s_rx'], d['p_tx'], f_ctx['rx'], d['has_peer'], f_ctx['valid'], REL_TOL, ABS_TOL
            )
            final_tx, conf_tx = arbitrate(
                d['s_tx'], d['p_rx'], f_ctx['tx'], d['has_peer'], f_ctx['valid'], REL_TOL, ABS_TOL
            )
=======
    # Recalculate Flow Targets one last time
    flow_context = {}
    for router_id, if_list in topology.items():
        valid_ifs = [i for i in if_list if i in working_state]
        t_in = sum(working_state[i]['est_rx'] for i in valid_ifs)
        t_out = sum(working_state[i]['est_tx'] for i in valid_ifs)

        ratio = abs(t_in - t_out) / max(t_in, t_out, 1.0)
        reliability = max(0.0, 1.0 - (ratio * 10.0))

        for i in valid_ifs:
            ws = working_state[i]
            target_rx = max(0.0, t_out - (t_in - ws['est_rx']))
            target_tx = max(0.0, t_in - (t_out - ws['est_tx']))
            flow_context[i] = {'rx': target_rx, 'tx': target_tx, 'qual': reliability}

    for if_id, d in working_state.items():
        f_ctx = flow_context.get(if_id, {'rx': 0.0, 'tx': 0.0, 'qual': 0.0})

        if d['status'] == 'down':
            final_rx, final_tx = 0.0, 0.0
            conf_rx = 0.95 if d['s_rx'] > ABS_TOL else 1.0
            conf_tx = 0.95 if d['s_tx'] > ABS_TOL else 1.0
        else:
            final_rx, conf_rx = arbitrate_voting(
                d['s_rx'], d['p_tx'], f_ctx['rx'], d['has_peer'], f_ctx['qual'], REL_TOL, ABS_TOL
            )
            final_tx, conf_tx = arbitrate_voting(
                d['s_tx'], d['p_rx'], f_ctx['tx'], d['has_peer'], f_ctx['qual'], REL_TOL, ABS_TOL
            )
>>>>>>> REPLACE
<<<<<<< SEARCH
def arbitrate(v_self: float, v_peer: float, v_flow: float,
              has_peer: bool, flow_valid: bool, rel_tol: float = 0.02, abs_tol: float = 0.5) -> Tuple[float, float]:
    """
    Arbitrates with continuous confidence scaling based on agreement quality.
    """
    def get_dist(a, b):
        diff = abs(a - b)
        if diff <= abs_tol: return 0.0
        return diff / max(abs(a), abs(b), 1.0)

    # 1. Handle Isolated Interfaces (No Peer)
    if not has_peer:
        if flow_valid:
            d_sf = get_dist(v_self, v_flow)
            if d_sf <= rel_tol:
                # Self verified by Flow
                conf = 0.95 - 10.0 * d_sf
                return v_self, max(0.5, conf)
            else:
                return v_flow, 0.75 # Trust Flow
        return v_self, 0.50

    # 2. Link Symmetry Check (Strongest Signal)
    d_sp = get_dist(v_self, v_peer)
    if d_sp <= rel_tol:
        avg = (v_self + v_peer) / 2.0
        # High confidence, decaying with distance
        conf = 1.0 - 5.0 * d_sp
        return avg, max(0.8, conf)

    # 3. Conflict Resolution
    if flow_valid:
        d_pf = get_dist(v_peer, v_flow)
        d_sf = get_dist(v_self, v_flow)

        if d_pf <= rel_tol:
            avg = (v_peer + v_flow) / 2.0
            conf = 0.95 - 5.0 * d_pf
            return avg, max(0.7, conf)

        if d_sf <= rel_tol:
            avg = (v_self + v_flow) / 2.0
            conf = 0.90 - 5.0 * d_sf
            return avg, max(0.7, conf)

    # 4. Fallback
    return v_peer, 0.70
=======
def arbitrate_voting(v_self: float, v_peer: float, v_flow: float,
                     has_peer: bool, flow_qual: float,
                     rel_tol: float = 0.02, abs_tol: float = 0.5) -> Tuple[float, float]:
    """
    Arbitrates using a Weighted Cluster Voting model.
    Groups signals (Self, Peer, Flow) into agreement clusters and picks the strongest.
    """
    # 1. Define Votes
    votes = []

    # Self: Base trust.
    votes.append({'val': v_self, 'weight': 0.8, 'src': 'self'})

    # Peer: High trust (independent hardware).
    if has_peer:
        votes.append({'val': v_peer, 'weight': 1.0, 'src': 'peer'})

    # Flow: Trust scaled by router reliability.
    if flow_qual > 0.0:
        votes.append({'val': v_flow, 'weight': flow_qual * 1.0, 'src': 'flow'})

    # 2. Form Clusters
    # Greedy clustering: Pick a seed, find friends, merge.
    clusters = []
    processed = [False] * len(votes)

    for i in range(len(votes)):
        if processed[i]: continue

        # Start new cluster
        seed = votes[i]
        cluster = {'val_sum': seed['val'] * seed['weight'],
                   'weight_sum': seed['weight'],
                   'sources': {seed['src']},
                   'max_dist': 0.0}
        processed[i] = True

        # Find matches
        for j in range(i + 1, len(votes)):
            if processed[j]: continue

            # Check agreement
            cand = votes[j]
            diff = abs(seed['val'] - cand['val'])
            limit = max(abs(seed['val']), abs(cand['val']), 1.0) * rel_tol

            if diff <= max(abs_tol, limit):
                # Match found
                cluster['val_sum'] += cand['val'] * cand['weight']
                cluster['weight_sum'] += cand['weight']
                cluster['sources'].add(cand['src'])

                # Update max intra-cluster distance ratio
                norm_dist = diff / max(abs(seed['val']), abs(cand['val']), 1.0)
                cluster['max_dist'] = max(cluster['max_dist'], norm_dist)

                processed[j] = True

        clusters.append(cluster)

    # 3. Select Winner
    best_cluster = max(clusters, key=lambda c: c['weight_sum'])
    final_val = best_cluster['val_sum'] / best_cluster['weight_sum']

    # 4. Calibrate Confidence
    w = best_cluster['weight_sum']
    srcs = best_cluster['sources']

    if 'peer' in srcs and 'self' in srcs:
        base_conf = 0.95 # Physical agreement
    elif 'peer' in srcs and 'flow' in srcs:
        base_conf = 0.90 # Remote + Logic agreement
    elif 'self' in srcs and 'flow' in srcs:
        base_conf = 0.85 # Local + Logic agreement
    elif 'peer' in srcs:
        base_conf = 0.70 # Peer only fallback
    elif 'flow' in srcs:
        base_conf = 0.60 + (0.2 * flow_qual) # Flow only (isolated)
    else:
        base_conf = 0.50 # Self only

    # Penalize for distance within cluster
    penalty = 5.0 * best_cluster['max_dist']

    # Bonus for unanimity
    if len(votes) == 3 and len(srcs) == 3:
        base_conf = min(1.0, base_conf + 0.05)

    return final_val, max(0.5, base_conf - penalty)
>>>>>>> REPLACE
</DIFF>