--- a/original.py
+++ b/original.py
@@ -1,369 +1,454 @@
 # EVOLVE-BLOCK-START
 from typing import Dict, Any, Tuple, List
 import math
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]], 
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
-    Repairs network telemetry using a Bayesian Flow Consensus algorithm.
-    It fuses evidence from Link Symmetry and Router Flow Conservation to 
-    probabilistically determine the most likely true state of network counters.
+    Repairs network telemetry using a Bayesian Flow Consensus algorithm with
+    Adaptive Noise Modeling and Zero-Flow Hypothesis testing.
+
+    Algorithm:
+    1.  **Symmetry Classification**: Classify links as 'Consistent' (Anchor) or 'Suspect'.
+        Anchors have high measurement trust; Suspects have low measurement trust.
+    2.  **Iterative Bayesian Solver**:
+        For each flow (Internal or External), evaluate candidate flow rates:
+        -   Measured values
+        -   Zero (Phantom traffic check)
+        -   Conservation-Implied values (what would balance the router?)
+        Select the candidate maximizing P(Conservation) * P(Measurement).
+    3.  **Confidence Calibration**:
+        Confidence is derived from the posterior probability of the winner 
+        scaled by the absolute fit of the final conservation state.
+    4.  **Status Inference**: Derived from repaired traffic and peer status.
     """
     
     # --- Configuration ---
+    # Tolerances
     SYMMETRY_TOLERANCE = 0.02
-    CONSERVATION_TOLERANCE_PCT = 0.03
-    MIN_SIGNIFICANT_FLOW = 0.5
-    ITERATIONS = 3
+    MIN_SIGMA = 1.0  # Minimum noise floor (Mbps)
+    
+    # Iteration settings
+    ITERATIONS = 5
+    MOMENTUM = 0.5  # Blend factor: 1.0 = full update, 0.0 = no update
     
     # --- Helper Structures ---
-    # Map interface to router
     if_to_router = {}
     for r_id, if_list in topology.items():
         for i_id in if_list:
             if_to_router[i_id] = r_id
             
-    # Group interfaces into Links for processing
-    # Link ID = tuple of sorted interface IDs to handle bidirectionality uniquely
-    links = {}
-    processed_ifs = set()
-    
+    # Structure: estimates[if_id] = {'rx': val, 'tx': val}
+    estimates = {}
+    
+    # Initialize estimates
     for if_id, data in telemetry.items():
-        if if_id in processed_ifs: continue
-        
-        peer_id = data.get('connected_to')
-        if peer_id and peer_id in telemetry:
-            # Internal Link
-            link_key = tuple(sorted([if_id, peer_id]))
-            links[link_key] = {
-                'type': 'internal',
-                'if1': if_id,
-                'if2': peer_id
-            }
-            processed_ifs.add(if_id)
-            processed_ifs.add(peer_id)
+        estimates[if_id] = {
+            'rx': data.get('rx_rate', 0.0),
+            'tx': data.get('tx_rate', 0.0)
+        }
+
+    # Links identification
+    # internal_links: key -> {if1, if2}
+    # external_links: key -> {if1, dir} (dir='tx' or 'rx' relative to if1)
+    internal_links = {}
+    external_links = [] # list of (if_id, metric)
+    processed_pairs = set()
+
+    for if_id, data in telemetry.items():
+        peer = data.get('connected_to')
+        
+        # Check TX (Local -> Peer)
+        if peer and peer in telemetry:
+            pair_key = tuple(sorted([if_id, peer]))
+            if pair_key not in processed_pairs:
+                processed_pairs.add(pair_key)
+                internal_links[pair_key] = {'if1': if_id, 'if2': peer}
         else:
-            # Edge/External Link
-            links[(if_id,)] = {
-                'type': 'external',
-                'if1': if_id,
-                'if2': None
-            }
-            processed_ifs.add(if_id)
-
-    # --- Step 1: Initial Link Assessment ---
-    # Determine which links are 'Solid' (agreeing) and which are 'Suspect'.
-    # For suspect links, generate hypotheses.
-    
-    # Store current best estimates for RX and TX flow on every interface
-    # structure: {if_id: {'rx': val, 'tx': val}}
-    current_estimates = {}
-    
-    # Store reliability/confidence of these estimates
-    # structure: {if_id: {'rx': conf, 'tx': conf}} (0.0 to 1.0)
-    estimate_confidence = {}
-    
-    # Suspect flows to solve: list of (link_key, metric_type ('rx_flow' or 'tx_flow'))
-    # Note: 'rx_flow' for link (A,B) means A->B traffic (A TX, B RX).
-    suspect_flows = []
-    
-    for link_key, info in links.items():
-        if1 = info['if1']
-        if2 = info['if2']
-        
-        d1 = telemetry[if1]
-        d2 = telemetry[if2] if if2 else {}
-        
-        # Analyze Flow IF1 -> IF2 (IF1 TX, IF2 RX)
-        val1_tx = d1.get('tx_rate', 0.0)
-        val2_rx = d2.get('rx_rate', 0.0) if if2 else None
-        
-        if if2:
-            # Internal Link: Check Symmetry
-            denom = max(val1_tx, val2_rx, 1.0)
-            diff = abs(val1_tx - val2_rx)
-            
-            if diff / denom < SYMMETRY_TOLERANCE:
-                # Consistent
-                consensus = (val1_tx + val2_rx) / 2.0
-                current_estimates[if1] = current_estimates.get(if1, {})
-                current_estimates[if1]['tx'] = consensus
-                current_estimates[if2] = current_estimates.get(if2, {})
-                current_estimates[if2]['rx'] = consensus
-                
-                estimate_confidence[if1] = estimate_confidence.get(if1, {})
-                estimate_confidence[if1]['tx'] = 1.0
-                estimate_confidence[if2] = estimate_confidence.get(if2, {})
-                estimate_confidence[if2]['rx'] = 1.0
-            else:
-                # Suspect
-                suspect_flows.append({'key': link_key, 'dir': '1_to_2', 'candidates': [val1_tx, val2_rx]})
-                # Initialize with average but low confidence
-                consensus = (val1_tx + val2_rx) / 2.0
-                current_estimates[if1] = current_estimates.get(if1, {})
-                current_estimates[if1]['tx'] = consensus
-                current_estimates[if2] = current_estimates.get(if2, {})
-                current_estimates[if2]['rx'] = consensus
-                
-                estimate_confidence[if1] = estimate_confidence.get(if1, {})
-                estimate_confidence[if1]['tx'] = 0.5
-                estimate_confidence[if2] = estimate_confidence.get(if2, {})
-                estimate_confidence[if2]['rx'] = 0.5
-        else:
-            # External Link: Trust local blindly for now (no peer to contradict)
-            current_estimates[if1] = current_estimates.get(if1, {})
-            current_estimates[if1]['tx'] = val1_tx
-            estimate_confidence[if1] = estimate_confidence.get(if1, {})
-            estimate_confidence[if1]['tx'] = 1.0 # Tentative
-            
-        # Analyze Flow IF2 -> IF1 (IF2 TX, IF1 RX)
-        if if2:
-            val2_tx = d2.get('tx_rate', 0.0)
-            val1_rx = d1.get('rx_rate', 0.0)
-            
-            denom = max(val2_tx, val1_rx, 1.0)
-            diff = abs(val2_tx - val1_rx)
-            
-            if diff / denom < SYMMETRY_TOLERANCE:
-                consensus = (val2_tx + val1_rx) / 2.0
-                current_estimates[if2]['tx'] = consensus
-                current_estimates[if1]['rx'] = consensus
-                estimate_confidence[if2]['tx'] = 1.0
-                estimate_confidence[if1]['rx'] = 1.0
-            else:
-                suspect_flows.append({'key': link_key, 'dir': '2_to_1', 'candidates': [val2_tx, val1_rx]})
-                consensus = (val2_tx + val1_rx) / 2.0
-                current_estimates[if2]['tx'] = consensus
-                current_estimates[if1]['rx'] = consensus
-                estimate_confidence[if2]['tx'] = 0.5
-                estimate_confidence[if1]['rx'] = 0.5
-        else:
-             # External RX
-            val1_rx = d1.get('rx_rate', 0.0)
-            current_estimates[if1]['rx'] = val1_rx
-            estimate_confidence[if1]['rx'] = 1.0
-
-    # --- Step 2: Iterative Bayesian Refinement ---
-    
-    # Helper to calculate router imbalance given current estimates
-    def get_router_imbalance(rid):
-        if_list = topology.get(rid, [])
-        total_in = 0.0
-        total_out = 0.0
-        for iid in if_list:
-            total_in += current_estimates.get(iid, {}).get('rx', 0.0)
-            total_out += current_estimates.get(iid, {}).get('tx', 0.0)
-        return total_in - total_out, max(total_in, total_out, 1.0)
-
-    # Iteration loop
+            # External TX
+            external_links.append((if_id, 'tx'))
+        
+        # Check RX
+        # If internal, handled above (RX of one is TX of other). 
+        # If external (no peer or peer not in telemetry), add to external list
+        if not (peer and peer in telemetry):
+            external_links.append((if_id, 'rx'))
+
+    # --- Step 1: Symmetry & Measurement Trust ---
+    # We assign a 'measurement_sigma' to each measurement.
+    # If symmetry holds, sigma is small (high trust).
+    # If not, sigma is large (low trust), allowing the solver to move away from measurement.
+    
+    meas_trust = {} # (if_id, metric) -> sigma
+    
+    for if_id, data in telemetry.items():
+        for metric in ['rx', 'tx']:
+            val = estimates[if_id][metric]
+            
+            # Default trust: loose (assume suspect until proven solid)
+            # 20% error or 5.0 Mbps, whichever is larger
+            sigma = max(val * 0.2, 5.0)
+            
+            peer = data.get('connected_to')
+            if peer and peer in telemetry:
+                # Check symmetry
+                peer_metric = 'tx' if metric == 'rx' else 'rx'
+                peer_val = estimates[peer][peer_metric]
+                
+                diff = abs(val - peer_val)
+                denom = max(val, peer_val, 1.0)
+                
+                if diff / denom < SYMMETRY_TOLERANCE:
+                    # Consistent: Tighten trust
+                    # 2% error or 1.0 Mbps
+                    sigma = max(val * 0.02, 1.0)
+                    
+                    # Also average estimates for better starting point
+                    avg = (val + peer_val) / 2.0
+                    estimates[if_id][metric] = avg
+            
+            meas_trust[(if_id, metric)] = sigma
+
+    # --- Step 2: Iterative Solver ---
+    
+    def get_router_imbalance(rid, exclude_if=None, exclude_metric=None):
+        """
+        Returns (net_imbalance, total_flow_magnitude).
+        net_imbalance = Total_In - Total_Out
+        exclude parameters allow calculating 'implied' value for a specific interface.
+        """
+        if rid not in topology: return 0.0, 1.0
+        
+        tin = 0.0
+        tout = 0.0
+        total_mag = 0.0
+        
+        for iid in topology[rid]:
+            if iid in estimates:
+                # RX
+                if not (iid == exclude_if and exclude_metric == 'rx'):
+                    v = estimates[iid]['rx']
+                    tin += v
+                    total_mag += v
+                # TX
+                if not (iid == exclude_if and exclude_metric == 'tx'):
+                    v = estimates[iid]['tx']
+                    tout += v
+                    total_mag += v
+                    
+        return (tin - tout), max(total_mag, 1.0)
+
+    def conservation_sigma(flow_mag):
+        # Noise model for conservation: Square root law for Poisson-like packet noise
+        # Scale factor 0.5 roughly corresponds to normal variance in packet counts
+        # Clamp at 1.0 minimum
+        return max(0.5 * math.sqrt(flow_mag), 1.0)
+
     for _ in range(ITERATIONS):
-        updates = {} # Store updates to apply after full pass
-        
-        for flow_prob in suspect_flows:
-            link_key = flow_prob['key']
-            direction = flow_prob['dir']
-            candidates = flow_prob['candidates']
-            
-            # Identify interfaces and routers involved
-            info = links[link_key]
-            if direction == '1_to_2':
-                src_if, dst_if = info['if1'], info['if2']
-                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
-            else:
-                src_if, dst_if = info['if2'], info['if1']
-                val_src, val_dst = candidates[0], candidates[1]
-                
-            router_src = if_to_router.get(src_if)
-            router_dst = if_to_router.get(dst_if)
-            
-            # Evaluate Hypothesis 1: Value is val_src (Local TX measurement)
-            # Evaluate Hypothesis 2: Value is val_dst (Peer RX measurement)
-            # We also consider their average as a fallback hypothesis 3? No, keep it binary for strong signals.
-            
-            hyps = [val_src, val_dst]
-            scores = []
-            
-            for h_val in hyps:
-                # Probability score based on Gaussian likelihood of imbalance
-                
-                # Check Source Router Imbalance if we use h_val for this TX interface
-                # Temporarily replace value in calculation
-                old_tx = current_estimates[src_if]['tx']
-                current_estimates[src_if]['tx'] = h_val
-                imb_src, flow_src = get_router_imbalance(router_src)
-                # Restore
-                current_estimates[src_if]['tx'] = old_tx
-                
-                # Check Dest Router Imbalance if we use h_val for this RX interface
-                old_rx = current_estimates[dst_if]['rx']
-                current_estimates[dst_if]['rx'] = h_val
-                imb_dst, flow_dst = get_router_imbalance(router_dst)
-                current_estimates[dst_if]['rx'] = old_rx
-                
-                # Likelihood function: P ~ exp(- |imbalance| / sigma)
-                # sigma is tolerance proportional to flow
-                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
-                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)
-                
-                score_src = math.exp(-abs(imb_src) / sigma_src)
-                score_dst = math.exp(-abs(imb_dst) / sigma_dst)
-                
-                # Combined score (Bayesian update assuming independent router evidence)
-                # We add a small epsilon prior favoring "no change" if both bad, 
-                # but here we just multiply.
-                scores.append(score_src * score_dst)
-            
-            # Select Winner
-            s1, s2 = scores[0], scores[1]
-            total_s = s1 + s2 + 1e-9
-            
-            p1 = s1 / total_s
-            p2 = s2 / total_s
-            
-            if p1 > p2:
-                winner_val = val_src
-                # Confidence is probability mass of winner
-                # If p1 ~ 0.5, confidence is low. If p1 ~ 1.0, high.
-                # Map 0.5-1.0 to 0.0-1.0 roughly
-                conf = (p1 - 0.5) * 2.0
-                conf = max(0.0, min(1.0, conf))
-            else:
-                winner_val = val_dst
-                conf = (p2 - 0.5) * 2.0
-                conf = max(0.0, min(1.0, conf))
-            
-            # Store update
-            updates[(src_if, 'tx')] = (winner_val, conf)
-            updates[(dst_if, 'rx')] = (winner_val, conf)
-            
-        # Apply updates
-        for (if_id, metric), (val, conf) in updates.items():
-            current_estimates[if_id][metric] = val
-            estimate_confidence[if_id][metric] = conf
-
-    # --- Step 3: Final Assembly & Status Repair ---
-    
+        updates = [] # Store (if_id, metric, new_val, score)
+        
+        # 2a. Process Internal Links
+        for pair in internal_links.values():
+            if1, if2 = pair['if1'], pair['if2']
+            
+            # Dir 1: IF1(TX) -> IF2(RX)
+            src, dst = if1, if2
+            src_metric, dst_metric = 'tx', 'rx'
+            
+            # Current Estimates & Measurements
+            curr_val = estimates[src][src_metric]
+            meas_src = telemetry[src].get('tx_rate', 0.0)
+            meas_dst = telemetry[dst].get('rx_rate', 0.0)
+            
+            # Implied values from conservation (what balances the router?)
+            r_src = if_to_router.get(src)
+            r_dst = if_to_router.get(dst)
+            
+            implied_src = curr_val # Default
+            if r_src:
+                imb_others, mag = get_router_imbalance(r_src, src, 'tx')
+                # imb_others = In - Out_Others. We want In - (Out_Others + X) = 0 => X = In - Out_Others = imb_others
+                implied_src = max(0.0, imb_others)
+
+            implied_dst = curr_val
+            if r_dst:
+                imb_others, mag = get_router_imbalance(r_dst, dst, 'rx')
+                # imb_others = In_Others - Out. We want (In_Others + X) - Out = 0 => X = Out - In_Others = -imb_others
+                implied_dst = max(0.0, -imb_others)
+            
+            # Candidates
+            candidates = set()
+            candidates.add(curr_val)
+            candidates.add(meas_src)
+            candidates.add(meas_dst)
+            candidates.add(0.0)
+            candidates.add(implied_src)
+            candidates.add(implied_dst)
+            candidates.add((meas_src + meas_dst)/2.0)
+            
+            # Score Candidates
+            best_val = curr_val
+            best_score = -1.0
+            
+            for val in candidates:
+                if val < 0: continue
+                
+                # Likelihood: Conservation
+                diff_src = abs(val - implied_src)
+                if r_src:
+                    _, flow_src = get_router_imbalance(r_src)
+                    sig_src = conservation_sigma(flow_src)
+                    p_cons_src = math.exp(-diff_src / sig_src)
+                else:
+                    p_cons_src = 1.0
+                    
+                diff_dst = abs(val - implied_dst)
+                if r_dst:
+                    _, flow_dst = get_router_imbalance(r_dst)
+                    sig_dst = conservation_sigma(flow_dst)
+                    p_cons_dst = math.exp(-diff_dst / sig_dst)
+                else:
+                    p_cons_dst = 1.0
+                
+                # Likelihood: Measurement
+                sig_m_src = meas_trust[(src, src_metric)]
+                p_meas_src = math.exp(-abs(val - meas_src) / sig_m_src)
+                
+                sig_m_dst = meas_trust[(dst, dst_metric)]
+                p_meas_dst = math.exp(-abs(val - meas_dst) / sig_m_dst)
+                
+                # Prior for 0.0 (Phantom Traffic Prevention)
+                # If measurements are high, 0.0 is unlikely unless conservation strictly demands it.
+                prior = 1.0
+                if val == 0.0:
+                    avg_meas = (meas_src + meas_dst) / 2.0
+                    if avg_meas > 10.0: prior = 0.05
+                    elif avg_meas > 1.0: prior = 0.2
+                
+                total_score = p_cons_src * p_cons_dst * p_meas_src * p_meas_dst * prior
+                
+                if total_score > best_score:
+                    best_score = total_score
+                    best_val = val
+            
+            updates.append((src, src_metric, best_val, best_score))
+            updates.append((dst, dst_metric, best_val, best_score))
+            
+            # Dir 2: IF2(TX) -> IF1(RX)
+            src, dst = if2, if1
+            src_metric, dst_metric = 'tx', 'rx'
+            
+            curr_val = estimates[src][src_metric]
+            meas_src = telemetry[src].get('tx_rate', 0.0)
+            meas_dst = telemetry[dst].get('rx_rate', 0.0)
+            
+            r_src = if_to_router.get(src)
+            r_dst = if_to_router.get(dst)
+            
+            implied_src = curr_val
+            if r_src:
+                imb, _ = get_router_imbalance(r_src, src, 'tx')
+                implied_src = max(0.0, imb)
+            
+            implied_dst = curr_val
+            if r_dst:
+                imb, _ = get_router_imbalance(r_dst, dst, 'rx')
+                implied_dst = max(0.0, -imb)
+                
+            candidates = {curr_val, meas_src, meas_dst, 0.0, implied_src, implied_dst, (meas_src+meas_dst)/2.0}
+            best_val_2 = curr_val
+            best_score_2 = -1.0
+            
+            for val in candidates:
+                if val < 0: continue
+                # Conservation
+                p_cs = math.exp(-abs(val - implied_src)/conservation_sigma(get_router_imbalance(r_src)[1])) if r_src else 1.0
+                p_cd = math.exp(-abs(val - implied_dst)/conservation_sigma(get_router_imbalance(r_dst)[1])) if r_dst else 1.0
+                # Measurement
+                p_ms = math.exp(-abs(val - meas_src)/meas_trust[(src, src_metric)])
+                p_md = math.exp(-abs(val - meas_dst)/meas_trust[(dst, dst_metric)])
+                # Prior
+                prior = 1.0
+                if val == 0.0:
+                    avg_meas = (meas_src + meas_dst) / 2.0
+                    if avg_meas > 10.0: prior = 0.05
+                    elif avg_meas > 1.0: prior = 0.2
+                
+                score = p_cs * p_cd * p_ms * p_md * prior
+                if score > best_score_2:
+                    best_score_2 = score
+                    best_val_2 = val
+                    
+            updates.append((src, src_metric, best_val_2, best_score_2))
+            updates.append((dst, dst_metric, best_val_2, best_score_2))
+
+        # 2b. Process External Links
+        for if_id, metric in external_links:
+            curr_val = estimates[if_id][metric]
+            meas = telemetry[if_id].get(f'{metric}_rate', 0.0)
+            r_id = if_to_router.get(if_id)
+            
+            implied = curr_val
+            if r_id:
+                imb, _ = get_router_imbalance(r_id, if_id, metric)
+                if metric == 'tx': implied = max(0.0, imb)
+                else: implied = max(0.0, -imb)
+            
+            candidates = {curr_val, meas, 0.0, implied}
+            best_val = curr_val
+            best_score = -1.0
+            
+            for val in candidates:
+                if val < 0: continue
+                # Cons
+                p_c = math.exp(-abs(val - implied)/conservation_sigma(get_router_imbalance(r_id)[1])) if r_id else 0.5
+                # Meas
+                p_m = math.exp(-abs(val - meas)/meas_trust[(if_id, metric)])
+                # Prior
+                prior = 1.0
+                if val == 0.0 and meas > 10.0: prior = 0.05
+                elif val == 0.0 and meas > 1.0: prior = 0.2
+                
+                score = p_c * p_m * prior
+                if score > best_score:
+                    best_score = score
+                    best_val = val
+            
+            updates.append((if_id, metric, best_val, best_score))
+            
+        # Apply Updates with Momentum
+        for if_id, metric, val, score in updates:
+            old = estimates[if_id][metric]
+            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
+
+    # --- Step 3: Confidence & Status ---
     result = {}
     
+    # Pre-calculate router fits (How well did the system converge?)
+    router_fit = {}
+    for r_id in topology:
+        imb, mag = get_router_imbalance(r_id)
+        sig = conservation_sigma(mag)
+        # Quality 0.0 to 1.0. High means router is balanced.
+        router_fit[r_id] = math.exp(-abs(imb) / sig)
+        
     for if_id, data in telemetry.items():
         orig_rx = data.get('rx_rate', 0.0)
         orig_tx = data.get('tx_rate', 0.0)
         orig_status = data.get('interface_status', 'unknown')
         
-        # Repaired Rates
-        est_rx = current_estimates[if_id]['rx']
-        conf_rx = estimate_confidence[if_id]['rx']
-        
-        est_tx = current_estimates[if_id]['tx']
-        conf_tx = estimate_confidence[if_id]['tx']
-        
-        # Status Inference
-        # Determine peer status
-        peer_id = data.get('connected_to')
+        rep_rx = estimates[if_id]['rx']
+        rep_tx = estimates[if_id]['tx']
+        
+        # Confidence Estimation
+        r_id = if_to_router.get(if_id)
+        r_quality = router_fit.get(r_id, 0.5) if r_id else 0.5
+        
+        peer = data.get('connected_to')
+        if peer and peer in telemetry:
+            pr_id = if_to_router.get(peer)
+            peer_r_quality = router_fit.get(pr_id, 0.5) if pr_id else 0.5
+            # For internal link, confidence relies on both routers being balanced
+            link_quality = (r_quality * peer_r_quality) ** 0.5
+        else:
+            link_quality = r_quality
+            
+        # Baseline confidence derived from global consistency (Link Quality)
+        conf_rx = 0.9 * link_quality
+        conf_tx = 0.9 * link_quality
+        
+        # Boost for Anchors (Consistent Symmetry + High Fit)
+        if meas_trust[(if_id, 'rx')] < 2.0: conf_rx = max(conf_rx, 0.95)
+        if meas_trust[(if_id, 'tx')] < 2.0: conf_tx = max(conf_tx, 0.95)
+        
+        # Clamp
+        conf_rx = max(0.01, min(0.99, conf_rx))
+        conf_tx = max(0.01, min(0.99, conf_tx))
+        
+        # Status Logic
+        has_traffic = (rep_rx > 0.5) or (rep_tx > 0.5)
         peer_status = 'unknown'
-        if peer_id and peer_id in telemetry:
-            peer_status = telemetry[peer_id].get('interface_status', 'unknown')
-            
-        # 1. Existence of significant traffic implies UP
-        has_rx = est_rx > MIN_SIGNIFICANT_FLOW
-        has_tx = est_tx > MIN_SIGNIFICANT_FLOW
-        
+        if peer and peer in telemetry:
+             peer_status = telemetry[peer].get('interface_status', 'unknown')
+             
         rep_status = orig_status
-        conf_status = 1.0 # Baseline
-        
-        if has_rx or has_tx:
+        conf_status = 1.0
+        
+        if has_traffic:
             rep_status = 'up'
             if orig_status != 'up':
-                # We are overturning status based on traffic.
-                # Confidence depends on traffic confidence.
-                flow_conf = max(conf_rx if has_rx else 0, conf_tx if has_tx else 0)
-                conf_status = flow_conf
-        
+                conf_status = (conf_rx + conf_tx) / 2.0
         elif peer_status == 'down':
-            # Peer is down and we have no traffic -> We should be down (usually)
             rep_status = 'down'
             if orig_status != 'down':
                 conf_status = 0.9
-        
-        elif orig_status == 'up' and not has_rx and not has_tx:
-            # We say UP, but no traffic. 
-            # Could be idle. 
-            # If peer is UP, likely idle -> Keep UP.
-            # If peer is DOWN (caught above), then DOWN.
-            # If peer unknown, keep UP.
-            rep_status = 'up'
-        
-        # Post-process: If status is DOWN, force rates to 0
+        else:
+            # No traffic, peer up/unknown.
+            rep_status = orig_status
+            
         if rep_status == 'down':
-            est_rx = 0.0
-            est_tx = 0.0
-            # High confidence in 0 if we are confident it's down
-            conf_rx = max(conf_rx, conf_status)
-            conf_tx = max(conf_tx, conf_status)
-            
-        # Result Construction
+            rep_rx, rep_tx = 0.0, 0.0
+            conf_rx = max(conf_rx, 0.95)
+            conf_tx = max(conf_tx, 0.95)
+            
         entry = {}
-        entry['rx_rate'] = (orig_rx, est_rx, conf_rx)
-        entry['tx_rate'] = (orig_tx, est_tx, conf_tx)
+        entry['rx_rate'] = (orig_rx, rep_rx, conf_rx)
+        entry['tx_rate'] = (orig_tx, rep_tx, conf_tx)
         entry['interface_status'] = (orig_status, rep_status, conf_status)
-        
-        # Metadata
         for k in ['connected_to', 'local_router', 'remote_router']:
-            if k in data:
-                entry[k] = data[k]
-        
+            if k in data: entry[k] = data[k]
         result[if_id] = entry
         
     return result
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
     
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
     
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
     
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
     
     result = run_repair(test_telemetry, test_topology)
     
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")
 
