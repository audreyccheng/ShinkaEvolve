<NAME>
calibrate_noise_and_confidence
</NAME>

<DESCRIPTION>
1.  **Hybrid Noise Model**: Update the `sigma` (tolerance) calculation to use `max(Linear, Sqrt, Absolute)`. This accounts for Poisson-like variance in low/medium flows (where sqrt dominates) and systematic errors in high flows (where linear dominates). This prevents overly strict penalties for medium flows.
2.  **Calibrated Confidence**: In the internal flow resolution, scale the confidence score by the `fit_quality` (geometric mean of the router conservation scores). This ensures that even if a hypothesis is the "winner" (high relative probability), the confidence remains low if the resulting network state is still poorly balanced (low absolute probability).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                # Likelihood with Linear Noise Model (Stricter than sqrt for accuracy)
                # Using 3% tolerance plus absolute floor
                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)

                score_src = math.exp(-abs(imb_src) / sigma_src) if router_src else 1.0
                score_dst = math.exp(-abs(imb_dst) / sigma_dst) if router_dst else 1.0

                # Prior: penalize 0.0 slightly if measurements are large
                prior = 1.0
                if h_val == 0.0 and max(candidates) > 5.0:
                    prior = 0.5

                scores.append(score_src * score_dst * prior)

            # Select Winner
            total_s = sum(scores) + 1e-20
            probs = [s / total_s for s in scores]

            best_idx = scores.index(max(scores))
            winner_val = hyps[best_idx]
            win_p = probs[best_idx]

            # Confidence: Use relative probability directly (better calibration than fit_quality)
            # If win_p is high, it means this hypothesis is much better than others.
            conf = win_p
            conf = max(0.01, min(0.99, conf))

            internal_updates[(src_if, 'tx')] = (winner_val, conf)
            internal_updates[(dst_if, 'rx')] = (winner_val, conf)
=======
                # Likelihood with Hybrid Noise Model (Linear + Sqrt)
                # Adapts better to both low-rate noise (Poisson) and high-rate systematic errors
                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, math.sqrt(flow_src), ABS_TOLERANCE)
                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, math.sqrt(flow_dst), ABS_TOLERANCE)

                score_src = math.exp(-abs(imb_src) / sigma_src) if router_src else 1.0
                score_dst = math.exp(-abs(imb_dst) / sigma_dst) if router_dst else 1.0

                # Prior: penalize 0.0 slightly if measurements are large
                prior = 1.0
                if h_val == 0.0 and max(candidates) > 5.0:
                    prior = 0.5

                scores.append(score_src * score_dst * prior)

            # Select Winner
            total_s = sum(scores) + 1e-20
            probs = [s / total_s for s in scores]

            best_idx = scores.index(max(scores))
            winner_val = hyps[best_idx]
            win_p = probs[best_idx]
            best_raw_score = scores[best_idx]

            # Confidence: Combination of relative probability (Selection Confidence)
            # and absolute fit quality (Model Confidence).
            # fit_quality is sqrt(joint_prob) -> geometric mean of src/dst fits
            fit_quality = math.sqrt(best_raw_score) if best_raw_score > 0 else 0.0

            conf = win_p * fit_quality
            conf = max(0.01, min(0.99, conf))

            internal_updates[(src_if, 'tx')] = (winner_val, conf)
            internal_updates[(dst_if, 'rx')] = (winner_val, conf)
>>>>>>> REPLACE
<<<<<<< SEARCH
            curr_val = current_estimates[if_id][metric]
            imb, flow = get_router_imbalance(rid)
            sigma = max(flow * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)

            # Hypotheses: Measured, Target (fix imbalance), Zero
=======
            curr_val = current_estimates[if_id][metric]
            imb, flow = get_router_imbalance(rid)
            sigma = max(flow * CONSERVATION_TOLERANCE_PCT, math.sqrt(flow), ABS_TOLERANCE)

            # Hypotheses: Measured, Target (fix imbalance), Zero
>>>>>>> REPLACE
<<<<<<< SEARCH
                new_sigma = max(new_flow * CONSERVATION_TOLERANCE_PCT, ABS_TOLERANCE)
                score = math.exp(-abs(new_imb) / new_sigma)

                # Prior: Penalize deviation from measurement
=======
                new_sigma = max(new_flow * CONSERVATION_TOLERANCE_PCT, math.sqrt(new_flow), ABS_TOLERANCE)
                score = math.exp(-abs(new_imb) / new_sigma)

                # Prior: Penalize deviation from measurement
>>>>>>> REPLACE
</DIFF>