<NAME>
bayes_optimization_update
</NAME>

<DESCRIPTION>
Improved the Bayesian refinement loop in `repair_network_telemetry` by:
1.  Adding `0.0` as a "Null Flow" hypothesis to detect phantom traffic on downed links.
2.  Updating the noise model (sigma) to `max(pct, sqrt(flow), 1.0)` to better model network counter variance.
3.  Calibrating confidence scores by multiplying the relative probability with the absolute goodness-of-fit (geometric mean of likelihoods), ensuring low confidence when all hypotheses are poor.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Iteration loop
    for _ in range(ITERATIONS):
        updates = {} # Store updates to apply after full pass

        for flow_prob in suspect_flows:
            link_key = flow_prob['key']
            direction = flow_prob['dir']
            candidates = flow_prob['candidates']

            # Identify interfaces and routers involved
            info = links[link_key]
            if direction == '1_to_2':
                src_if, dst_if = info['if1'], info['if2']
                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
            else:
                src_if, dst_if = info['if2'], info['if1']
                val_src, val_dst = candidates[0], candidates[1]

            router_src = if_to_router.get(src_if)
            router_dst = if_to_router.get(dst_if)

            # Evaluate Hypothesis 1: Value is val_src (Local TX measurement)
            # Evaluate Hypothesis 2: Value is val_dst (Peer RX measurement)
            # We also consider their average as a fallback hypothesis 3? No, keep it binary for strong signals.

            hyps = [val_src, val_dst]
            scores = []

            for h_val in hyps:
                # Probability score based on Gaussian likelihood of imbalance

                # Check Source Router Imbalance if we use h_val for this TX interface
                # Temporarily replace value in calculation
                old_tx = current_estimates[src_if]['tx']
                current_estimates[src_if]['tx'] = h_val
                imb_src, flow_src = get_router_imbalance(router_src)
                # Restore
                current_estimates[src_if]['tx'] = old_tx

                # Check Dest Router Imbalance if we use h_val for this RX interface
                old_rx = current_estimates[dst_if]['rx']
                current_estimates[dst_if]['rx'] = h_val
                imb_dst, flow_dst = get_router_imbalance(router_dst)
                current_estimates[dst_if]['rx'] = old_rx

                # Likelihood function: P ~ exp(- |imbalance| / sigma)
                # sigma is tolerance proportional to flow
                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, 1.0)
                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, 1.0)

                score_src = math.exp(-abs(imb_src) / sigma_src)
                score_dst = math.exp(-abs(imb_dst) / sigma_dst)

                # Combined score (Bayesian update assuming independent router evidence)
                # We add a small epsilon prior favoring "no change" if both bad,
                # but here we just multiply.
                scores.append(score_src * score_dst)

            # Select Winner
            s1, s2 = scores[0], scores[1]
            total_s = s1 + s2 + 1e-9

            p1 = s1 / total_s
            p2 = s2 / total_s

            if p1 > p2:
                winner_val = val_src
                conf = p1
            else:
                winner_val = val_dst
                conf = p2

            # Store update
            updates[(src_if, 'tx')] = (winner_val, conf)
            updates[(dst_if, 'rx')] = (winner_val, conf)

        # Apply updates
        for (if_id, metric), (val, conf) in updates.items():
            current_estimates[if_id][metric] = val
            estimate_confidence[if_id][metric] = conf
=======
    # Iteration loop
    for _ in range(ITERATIONS):
        updates = {} # Store updates to apply after full pass

        for flow_prob in suspect_flows:
            link_key = flow_prob['key']
            direction = flow_prob['dir']
            candidates = flow_prob['candidates']

            # Identify interfaces and routers involved
            info = links[link_key]
            if direction == '1_to_2':
                src_if, dst_if = info['if1'], info['if2']
                val_src, val_dst = candidates[0], candidates[1] # src measured tx, dst measured rx
            else:
                src_if, dst_if = info['if2'], info['if1']
                val_src, val_dst = candidates[0], candidates[1]

            router_src = if_to_router.get(src_if)
            router_dst = if_to_router.get(dst_if)

            # Hypotheses: Src measurement, Dst measurement, and Zero (phantom traffic hypothesis)
            # Using set to merge duplicates (e.g. if src==dst or one is 0)
            unique_hyps = sorted(list(set([val_src, val_dst, 0.0])))
            scores = []

            for h_val in unique_hyps:
                # Probability score based on Gaussian likelihood of imbalance

                # Check Source Router Imbalance if we use h_val for this TX interface
                old_tx = current_estimates[src_if]['tx']
                current_estimates[src_if]['tx'] = h_val
                imb_src, flow_src = get_router_imbalance(router_src)
                current_estimates[src_if]['tx'] = old_tx # Restore

                # Check Dest Router Imbalance if we use h_val for this RX interface
                old_rx = current_estimates[dst_if]['rx']
                current_estimates[dst_if]['rx'] = h_val
                imb_dst, flow_dst = get_router_imbalance(router_dst)
                current_estimates[dst_if]['rx'] = old_rx # Restore

                # Likelihood function: P ~ exp(- |imbalance| / sigma)
                # Using a hybrid sigma model: max(percentage, sqrt(flow), constant)
                # This provides a more realistic noise floor for low flows while scaling for high flows
                sigma_src = max(flow_src * CONSERVATION_TOLERANCE_PCT, math.sqrt(flow_src), 1.0)
                sigma_dst = max(flow_dst * CONSERVATION_TOLERANCE_PCT, math.sqrt(flow_dst), 1.0)

                score_src = math.exp(-abs(imb_src) / sigma_src)
                score_dst = math.exp(-abs(imb_dst) / sigma_dst)

                scores.append(score_src * score_dst)

            # Normalize scores to probabilities
            total_s = sum(scores) + 1e-12
            probs = [s / total_s for s in scores]

            # Select Winner
            best_idx = 0
            best_prob = probs[0]
            for i in range(1, len(probs)):
                if probs[i] > best_prob:
                    best_prob = probs[i]
                    best_idx = i

            winner_val = unique_hyps[best_idx]
            raw_score = scores[best_idx]

            # Calibration: Confidence = Probability * Absolute Fit Quality
            # Fit quality is sqrt of the raw likelihood product (geometric mean of router agreements)
            fit_quality = math.sqrt(raw_score)
            conf = best_prob * fit_quality

            # Clip confidence
            conf = max(0.01, min(0.99, conf))

            # Store update
            updates[(src_if, 'tx')] = (winner_val, conf)
            updates[(dst_if, 'rx')] = (winner_val, conf)

        # Apply updates
        for (if_id, metric), (val, conf) in updates.items():
            current_estimates[if_id][metric] = val
            estimate_confidence[if_id][metric] = conf
>>>>>>> REPLACE
</DIFF>