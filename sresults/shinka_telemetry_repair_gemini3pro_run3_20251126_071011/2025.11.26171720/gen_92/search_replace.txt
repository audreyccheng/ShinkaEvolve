<NAME>
adaptive_sigma_and_continuous_prior
</NAME>

<DESCRIPTION>
This edit improves the core iterative solver by implementing two key recommendations:
1.  **Reliability-Weighted Sigma**: The noise model (`calc_sigma`) now accepts a `reliability` parameter (based on router anchor strength). Reliable routers (anchor ratio ~1.0) get tighter conservation constraints, while unreliable ones get looser constraints. This transfers trust from verified parts of the network to unverified parts (Trust Transfer).
2.  **Continuous Phantom Prior**: Replaces the hard-coded thresholds for the zero-flow hypothesis with a continuous decay function (`math.exp(-m_val / 3.0)`). This provides a smooth probability transition for distinguishing between low-volume traffic and phantom traffic, avoiding classification cliffs.

The entire loop structure is updated to pass reliability to `calc_sigma` and use the new prior logic.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def calc_sigma(flow_val):
        return max(math.sqrt(flow_val) * 1.5, flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)

    # Store probability of winning hypothesis
    solver_probs = {}

    for iter_idx in range(ITERATIONS):
        # Calculate Router Anchor Strength
        # This is dynamic: as we lock suspect flows, the anchor strength increases
        router_anchor_strength = {}
        for rid in topology:
            trusted_flow = 0.0
            total_flow = 0.0
            for iid in topology[rid]:
                if iid in estimates:
                    r, t = estimates[iid]['rx'], estimates[iid]['tx']
                    total_flow += (r + t)
                    if (iid, 'rx') in locked_flows: trusted_flow += r
                    if (iid, 'tx') in locked_flows: trusted_flow += t
            router_anchor_strength[rid] = trusted_flow / max(total_flow, 1.0)

        updates = []
        new_locks = []

        for f_idx, flow in enumerate(suspect_flows):
            if flow.get('locked', False): continue

            # --- Internal Flow Logic ---
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                # Candidates
                cands = [c for c in flow['cands'] if c >= 0]
                if len(cands) == 2:
                    v1, v2 = cands
                    # Add mean if not wildly divergent
                    if abs(v1-v2) < max(v1,v2)*0.3 + 10.0:
                        cands.append((v1+v2)/2.0)

                hyps = sorted(list(set(cands + [0.0])))

                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    imb_s, flow_s = get_router_state(r_src)
                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s)) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d)) if r_dst else 1.0

                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down': prior = 0.99
                        else:
                             m_val = max(flow['cands'])
                             if m_val > 5.0: prior = 0.01
                             elif m_val > 1.0: prior = 0.2
                    else:
                        # Distance to measurements
                        dist = min([abs(h - c) for c in flow['cands']])
                        prior = math.exp(-dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)

                estimates[src]['tx'] = curr_tx
                estimates[dst]['rx'] = curr_rx

                total = sum(scores) + 1e-20
                probs = [s/total for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((src, 'tx', win_val, win_prob))
                updates.append((dst, 'rx', win_val, win_prob))

                if iter_idx == LOCKING_ITERATION and win_prob > LOCKING_THRESHOLD:
                    new_locks.append(f_idx)
                    locked_flows.add((src, 'tx'))
                    locked_flows.add((dst, 'rx'))

            # --- External Flow Logic ---
            elif flow['type'] == 'external':
                if flow['src']:
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr = estimates[if_id]['tx']
                    stat = flow.get('status_src')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr + imb)
                else:
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr = estimates[if_id]['rx']
                    stat = flow.get('status_dst')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                anchor_ratio = router_anchor_strength.get(r_id, 0.0)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    lik = math.exp(-abs(imb)/calc_sigma(rf)) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.99
                        elif meas > 10.0: prior = 0.01
                        else: prior = 0.5
                    elif abs(h - implied) < 1e-6:
                        # Conservation trust scales with anchor strength
                        # If anchors are 100%, we trust implied 90%. If 0%, trust 10%.
                        trust = 0.1 + 0.8 * anchor_ratio
                        prior = trust
                    elif abs(h - meas) < 1e-6:
                        # Measurement trust is inverse of conservation trust
                        trust = 0.9 - 0.8 * anchor_ratio
                        prior = trust

                        # Extra penalty if measurement deviates wildly from implied on a strong router
                        if anchor_ratio > 0.8 and abs(h - implied) > max(implied*0.2, 5.0):
                            prior *= 0.1

                    scores.append(lik * prior)

                estimates[if_id][metric] = curr

                total = sum(scores) + 1e-20
                probs = [s/total for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((if_id, metric, win_val, win_prob))

        # Apply Updates
        for if_id, metric, val, prob in updates:
            old = estimates[if_id][metric]
            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
            solver_probs[(if_id, metric)] = prob

        # Lock flows
        for idx in new_locks:
            suspect_flows[idx]['locked'] = True
=======
    def calc_sigma(flow_val, reliability=0.5):
        # Adaptive sigma with reliability scaling (Trust Transfer)
        # Tighter constraints (1.0x) for reliable routers, Looser (2.0x) for unreliable
        base = max(math.sqrt(flow_val) * 1.5, flow_val * CONSERVATION_TOLERANCE_PCT, 1.0)
        return base * (2.0 - reliability)

    # Store probability of winning hypothesis
    solver_probs = {}

    for iter_idx in range(ITERATIONS):
        # Calculate Router Anchor Strength
        router_anchor_strength = {}
        for rid in topology:
            trusted_flow = 0.0
            total_flow = 0.0
            for iid in topology[rid]:
                if iid in estimates:
                    r, t = estimates[iid]['rx'], estimates[iid]['tx']
                    total_flow += (r + t)
                    if (iid, 'rx') in locked_flows: trusted_flow += r
                    if (iid, 'tx') in locked_flows: trusted_flow += t
            router_anchor_strength[rid] = trusted_flow / max(total_flow, 1.0)

        updates = []
        new_locks = []

        for f_idx, flow in enumerate(suspect_flows):
            if flow.get('locked', False): continue

            # --- Internal Flow Logic ---
            if flow['type'] == 'internal':
                src, dst = flow['src'], flow['dst']
                r_src = if_to_router.get(src)
                r_dst = if_to_router.get(dst)

                rel_src = router_anchor_strength.get(r_src, 0.5)
                rel_dst = router_anchor_strength.get(r_dst, 0.5)

                cands = [c for c in flow['cands'] if c >= 0]
                if len(cands) == 2:
                    v1, v2 = cands
                    if abs(v1-v2) < max(v1,v2)*0.3 + 10.0:
                        cands.append((v1+v2)/2.0)

                hyps = sorted(list(set(cands + [0.0])))
                curr_tx = estimates[src]['tx']
                curr_rx = estimates[dst]['rx']

                scores = []
                for h in hyps:
                    estimates[src]['tx'] = h
                    estimates[dst]['rx'] = h

                    imb_s, flow_s = get_router_state(r_src)
                    score_s = math.exp(-abs(imb_s)/calc_sigma(flow_s, rel_src)) if r_src else 1.0

                    imb_d, flow_d = get_router_state(r_dst)
                    score_d = math.exp(-abs(imb_d)/calc_sigma(flow_d, rel_dst)) if r_dst else 1.0

                    prior = 1.0
                    if h == 0.0:
                        s_src = flow.get('status_src')
                        s_dst = flow.get('status_dst')
                        if s_src == 'down' or s_dst == 'down': prior = 0.99
                        else:
                             # Continuous decay: High measurement -> low prior for 0.0 hypothesis
                             m_val = max(flow['cands'])
                             prior = math.exp(-m_val / 3.0)
                    else:
                        dist = min([abs(h - c) for c in flow['cands']])
                        prior = math.exp(-dist / max(h*0.05, 1.0))

                    scores.append(score_s * score_d * prior)

                estimates[src]['tx'] = curr_tx
                estimates[dst]['rx'] = curr_rx

                total = sum(scores) + 1e-20
                probs = [s/total for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((src, 'tx', win_val, win_prob))
                updates.append((dst, 'rx', win_val, win_prob))

                if iter_idx == LOCKING_ITERATION and win_prob > LOCKING_THRESHOLD:
                    new_locks.append(f_idx)
                    locked_flows.add((src, 'tx'))
                    locked_flows.add((dst, 'rx'))

            # --- External Flow Logic ---
            elif flow['type'] == 'external':
                if flow['src']:
                    if_id = flow['src']
                    r_id = if_to_router.get(if_id)
                    metric = 'tx'
                    meas = flow['cands'][0]
                    curr = estimates[if_id]['tx']
                    stat = flow.get('status_src')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr + imb)
                else:
                    if_id = flow['dst']
                    r_id = if_to_router.get(if_id)
                    metric = 'rx'
                    meas = flow['cands'][0]
                    curr = estimates[if_id]['rx']
                    stat = flow.get('status_dst')
                    imb, r_flow = get_router_state(r_id)
                    implied = max(0.0, curr - imb)

                hyps = sorted(list(set([meas, implied, 0.0])))
                scores = []

                rel = router_anchor_strength.get(r_id, 0.0)

                for h in hyps:
                    estimates[if_id][metric] = h
                    imb, rf = get_router_state(r_id)
                    lik = math.exp(-abs(imb)/calc_sigma(rf, rel)) if r_id else 0.5

                    prior = 1.0
                    if h == 0.0:
                        if stat == 'down': prior = 0.99
                        else: prior = math.exp(-meas / 3.0)
                    elif abs(h - implied) < 1e-6:
                        trust = 0.1 + 0.8 * rel
                        prior = trust
                    elif abs(h - meas) < 1e-6:
                        trust = 0.9 - 0.8 * rel
                        prior = trust
                        if rel > 0.8 and abs(h - implied) > max(implied*0.2, 5.0):
                            prior *= 0.1

                    scores.append(lik * prior)

                estimates[if_id][metric] = curr

                total = sum(scores) + 1e-20
                probs = [s/total for s in scores]
                best_idx = scores.index(max(scores))
                win_val = hyps[best_idx]
                win_prob = sum(p for i, p in enumerate(probs)
                             if abs(hyps[i] - win_val) < max(win_val*0.05, 1.0))

                updates.append((if_id, metric, win_val, win_prob))

        # Apply Updates
        for if_id, metric, val, prob in updates:
            old = estimates[if_id][metric]
            estimates[if_id][metric] = (old * (1 - MOMENTUM)) + (val * MOMENTUM)
            solver_probs[(if_id, metric)] = prob

        # Lock flows
        for idx in new_locks:
            suspect_flows[idx]['locked'] = True
>>>>>>> REPLACE
</DIFF>

<NAME>
neighbor_consensus_calibration
</NAME>

<DESCRIPTION>
Updates the confidence calibration logic to include neighbor router consensus. The "Effective Fit" is now calculated as the geometric mean of the local router's conservation fit and the remote peer's conservation fit. This ensures that high confidence is only assigned when a flow fits consistently into the conservation equations of both connected devices. Also updates the final router fit calculation to use the reliability-weighted `calc_sigma` for consistency.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Final Router Fits
    router_fits = {}
    for rid in topology:
        imb, flow = get_router_state(rid)
        router_fits[rid] = math.exp(-abs(imb) / calc_sigma(flow))

    for if_id, data in telemetry.items():
        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_status = data.get('interface_status', 'unknown')

        rep_rx = estimates[if_id]['rx']
        rep_tx = estimates[if_id]['tx']

        rid = if_to_router.get(if_id)
        r_fit = router_fits.get(rid, 0.8)

        def calc_conf(metric, rep_val, orig_val):
            # 1. Anchors are high confidence
            if (if_id, metric) in anchors:
                return 0.98

            # 2. Solver Confidence
            prob = solver_probs.get((if_id, metric), 0.5)

            # 3. Harmonic Mean of Certainty and Fit
            # This penalizes if either is low, but rewards if both are high
            # Add small epsilon to avoid div by zero
            # We treat 'prob' and 'r_fit' as two independent signals of quality

            # However, if we barely changed the value, we should be more confident
            # (Validating the measurement)
            is_close = abs(rep_val - orig_val) < max(orig_val * 0.05, 1.0)

            if is_close:
                # If we agreed with measurement, we are confident unless router fit is terrible
                base_conf = 0.8 + 0.15 * r_fit
            else:
                # We disagreed. We need high solver prob AND high router fit to be confident.
                # Use harmonic mean of Prob and Fit
                base_conf = 2 * (prob * r_fit) / (prob + r_fit + 1e-9)

            return max(0.01, min(0.99, base_conf))
=======
    # Final Router Fits
    router_fits = {}
    for rid in topology:
        imb, flow = get_router_state(rid)
        # Use final reliability for sigma
        rel = router_anchor_strength.get(rid, 0.5)
        router_fits[rid] = math.exp(-abs(imb) / calc_sigma(flow, rel))

    for if_id, data in telemetry.items():
        orig_rx = data.get('rx_rate', 0.0)
        orig_tx = data.get('tx_rate', 0.0)
        orig_status = data.get('interface_status', 'unknown')

        rep_rx = estimates[if_id]['rx']
        rep_tx = estimates[if_id]['tx']

        rid = if_to_router.get(if_id)
        r_fit = router_fits.get(rid, 0.8)

        # Neighbor Consensus for Calibration
        peer_router = data.get('remote_router')
        if peer_router and peer_router in router_fits:
            peer_fit = router_fits[peer_router]
            # Effective fit is geometric mean of local and remote fit
            effective_fit = math.sqrt(r_fit * peer_fit)
        else:
            effective_fit = r_fit

        def calc_conf(metric, rep_val, orig_val):
            # 1. Anchors are high confidence
            if (if_id, metric) in anchors:
                return 0.98

            # 2. Solver Confidence
            prob = solver_probs.get((if_id, metric), 0.5)

            # 3. Harmonic Mean of Certainty and Effective Fit

            # If we barely changed the value, we should be more confident
            is_close = abs(rep_val - orig_val) < max(orig_val * 0.05, 1.0)

            if is_close:
                # If we agreed with measurement, we are confident unless fits are terrible
                base_conf = 0.8 + 0.15 * effective_fit
            else:
                # We disagreed. We need high solver prob AND high fits to be confident.
                base_conf = 2 * (prob * effective_fit) / (prob + effective_fit + 1e-9)

            return max(0.01, min(0.99, base_conf))
>>>>>>> REPLACE
</DIFF>