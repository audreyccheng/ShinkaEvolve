<NAME>
steepest_descent_mixed_fit
</NAME>

<DESCRIPTION>
1.  **Steepest Descent Refinement**: Replaces the "First Improvement" heuristic in the local search `refine_solution` function with a "Steepest Descent" approach. This evaluates all possible moves and swaps from the bottleneck GPU and selects the single action that most reduces the peak pressure, helping to escape local optima more effectively.
2.  **Mixed Fit Strategy**: Introduces variability in the bin packing phase (used within the Binary Search) by randomly toggling between "Best Fit" (minimize slack) and "Worst Fit" (maximize slack/load balancing) strategies. This diversity increases the likelihood of finding a valid packing when one strategy struggles.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def refine_solution(placement, iterations=20):
        """Optimizes placement via steepest descent Move/Swap."""
        # Setup working stats
        g_map = {}
        for g, m_list in placement.items():
            w_sum = sum(m.req_rate / m.slo for m in m_list)
            s_sum = sum(m.model_size for m in m_list)
            g_map[g] = {'models': list(m_list), 'w': w_sum, 's': s_sum}

        for _ in range(iterations):
            # Identify Bottleneck
            max_p = -1.0
            src = -1
            for g in range(gpu_num):
                rem = GPU_MEM_SIZE - g_map[g]['s']
                p = g_map[g]['w'] / rem if rem > 1e-9 else float('inf')
                if p > max_p:
                    max_p = p
                    src = g

            if src == -1 or max_p < 1e-9: break

            improved = False
            src_models = g_map[src]['models']

            # 1. Try MOVE (Best Fit)
            for i, m in enumerate(src_models):
                w, s = m.req_rate / m.slo, m.model_size

                best_dst = None
                best_dst_p = float('inf')

                for dst in range(gpu_num):
                    if dst == src: continue
                    dst_stats = g_map[dst]
                    if dst_stats['s'] + s > GPU_MEM_SIZE: continue

                    dst_rem = GPU_MEM_SIZE - (dst_stats['s'] + s)
                    if dst_rem <= 1e-9: continue
                    new_dst_p = (dst_stats['w'] + w) / dst_rem

                    if new_dst_p < max_p - 1e-5:
                        if new_dst_p < best_dst_p:
                            best_dst_p = new_dst_p
                            best_dst = dst

                if best_dst is not None:
                    moved = src_models.pop(i)
                    g_map[src]['w'] -= w
                    g_map[src]['s'] -= s
                    g_map[best_dst]['models'].append(moved)
                    g_map[best_dst]['w'] += w
                    g_map[best_dst]['s'] += s
                    improved = True
                    break

            if improved: continue

            # 2. Try SWAP (First Improvement)
            for i, m_src in enumerate(src_models):
                w_src, s_src = m_src.req_rate / m_src.slo, m_src.model_size

                for dst in range(gpu_num):
                    if dst == src: continue
                    dst_models = g_map[dst]['models']

                    for j, m_dst in enumerate(dst_models):
                        w_dst, s_dst = m_dst.req_rate / m_dst.slo, m_dst.model_size

                        # Check Capacity
                        new_src_s = g_map[src]['s'] - s_src + s_dst
                        if new_src_s > GPU_MEM_SIZE: continue
                        new_dst_s = g_map[dst]['s'] - s_dst + s_src
                        if new_dst_s > GPU_MEM_SIZE: continue

                        # Check Pressure
                        rem_src = GPU_MEM_SIZE - new_src_s
                        if rem_src <= 1e-9: continue
                        p_src = (g_map[src]['w'] - w_src + w_dst) / rem_src

                        rem_dst = GPU_MEM_SIZE - new_dst_s
                        if rem_dst <= 1e-9: continue
                        p_dst = (g_map[dst]['w'] - w_dst + w_src) / rem_dst

                        if max(p_src, p_dst) < max_p - 1e-5:
                            # Swap
                            src_models[i] = m_dst
                            dst_models[j] = m_src
                            g_map[src]['w'] += (w_dst - w_src)
                            g_map[src]['s'] += (s_dst - s_src)
                            g_map[dst]['w'] += (w_src - w_dst)
                            g_map[dst]['s'] += (s_src - s_dst)
                            improved = True
                            break
                    if improved: break
                if improved: break

            if not improved: break

        return {g: g_map[g]['models'] for g in range(gpu_num)}
=======
    def refine_solution(placement, iterations=20):
        """Optimizes placement via steepest descent Move/Swap."""
        # Setup working stats
        g_map = {}
        for g, m_list in placement.items():
            w_sum = sum(m.req_rate / m.slo for m in m_list)
            s_sum = sum(m.model_size for m in m_list)
            g_map[g] = {'models': list(m_list), 'w': w_sum, 's': s_sum}

        # Cache GPU pressures calculation
        def calc_pressure(g_idx):
            rem = GPU_MEM_SIZE - g_map[g_idx]['s']
            return g_map[g_idx]['w'] / rem if rem > 1e-9 else (float('inf') if g_map[g_idx]['w'] > 0 else 0.0)

        for _ in range(iterations):
            # Identify Bottleneck
            max_p = -1.0
            src = -1
            current_pressures = [calc_pressure(g) for g in range(gpu_num)]
            for g, p in enumerate(current_pressures):
                if p > max_p:
                    max_p = p
                    src = g

            if src == -1 or max_p < 1e-9: break

            # Steepest Descent: Find the single best action across all moves/swaps
            best_action = None # (type, score, details...)
            best_val = max_p

            src_models = g_map[src]['models']

            # 1. Evaluate MOVES (Src -> Dst)
            for i, m in enumerate(src_models):
                w, s = m.req_rate / m.slo, m.model_size

                # Hypothetical Src after move
                src_rem_new = GPU_MEM_SIZE - (g_map[src]['s'] - s)
                src_w_new = g_map[src]['w'] - w
                src_p_new = src_w_new / src_rem_new if src_rem_new > 1e-9 else (float('inf') if src_w_new > 0 else 0.0)

                for dst in range(gpu_num):
                    if dst == src: continue
                    if g_map[dst]['s'] + s > GPU_MEM_SIZE: continue

                    dst_rem_new = GPU_MEM_SIZE - (g_map[dst]['s'] + s)
                    if dst_rem_new <= 1e-9: continue
                    dst_w_new = g_map[dst]['w'] + w
                    dst_p_new = dst_w_new / dst_rem_new

                    # Minimize the bottleneck of the involved GPUs
                    local_max = max(src_p_new, dst_p_new)
                    if local_max < best_val - 1e-6:
                        best_val = local_max
                        best_action = ('move', i, dst)

            # 2. Evaluate SWAPS (Src <-> Dst)
            for i, m_src in enumerate(src_models):
                w_src, s_src = m_src.req_rate / m_src.slo, m_src.model_size

                for dst in range(gpu_num):
                    if dst == src: continue
                    dst_models = g_map[dst]['models']

                    for j, m_dst in enumerate(dst_models):
                        w_dst, s_dst = m_dst.req_rate / m_dst.slo, m_dst.model_size

                        # Capacity Check
                        new_src_s = g_map[src]['s'] - s_src + s_dst
                        if new_src_s > GPU_MEM_SIZE: continue
                        new_dst_s = g_map[dst]['s'] - s_dst + s_src
                        if new_dst_s > GPU_MEM_SIZE: continue

                        # Pressure Check
                        rem_src = GPU_MEM_SIZE - new_src_s
                        if rem_src <= 1e-9: continue
                        p_src = (g_map[src]['w'] - w_src + w_dst) / rem_src

                        rem_dst = GPU_MEM_SIZE - new_dst_s
                        if rem_dst <= 1e-9: continue
                        p_dst = (g_map[dst]['w'] - w_dst + w_src) / rem_dst

                        local_max = max(p_src, p_dst)
                        if local_max < best_val - 1e-6:
                            best_val = local_max
                            best_action = ('swap', i, dst, j)

            if best_action:
                if best_action[0] == 'move':
                    _, i, dst = best_action
                    m = src_models.pop(i)
                    g_map[src]['w'] -= m.req_rate / m.slo
                    g_map[src]['s'] -= m.model_size
                    g_map[dst]['models'].append(m)
                    g_map[dst]['w'] += m.req_rate / m.slo
                    g_map[dst]['s'] += m.model_size
                else:
                    _, i, dst, j = best_action
                    m_src = src_models[i]
                    m_dst = g_map[dst]['models'][j]

                    # Update lists
                    src_models[i] = m_dst
                    g_map[dst]['models'][j] = m_src

                    # Update stats
                    w_src, s_src = m_src.req_rate / m_src.slo, m_src.model_size
                    w_dst, s_dst = m_dst.req_rate / m_dst.slo, m_dst.model_size

                    g_map[src]['w'] += (w_dst - w_src)
                    g_map[src]['s'] += (s_dst - s_src)
                    g_map[dst]['w'] += (w_src - w_dst)
                    g_map[dst]['s'] += (s_src - s_dst)
            else:
                break # Local optimum

        return {g: g_map[g]['models'] for g in range(gpu_num)}
>>>>>>> REPLACE
<<<<<<< SEARCH
                for attempt in range(25):
                    base_key, _ = strategies[attempt % len(strategies)]
                    noise = 0.0
                    if attempt >= 4:
                        noise = 0.01 + (attempt * 0.003)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0: val *= random.uniform(1.0 - noise, 1.0 + noise)
                        if id(m) in failed_items: val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)
                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        min_rem_eff = float('inf')

                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue
                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)
                                if rem_eff < min_rem_eff:
                                    min_rem_eff = rem_eff
                                    best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s
=======
                for attempt in range(30):
                    base_key, _ = strategies[attempt % len(strategies)]
                    noise = 0.0
                    if attempt >= 4:
                        noise = 0.01 + (attempt * 0.003)

                    # Randomly toggle between Best Fit and Worst Fit to escape traps
                    fit_mode = 'best_fit'
                    if attempt > 10 and random.random() < 0.25:
                        fit_mode = 'worst_fit'

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0: val *= random.uniform(1.0 - noise, 1.0 + noise)
                        if id(m) in failed_items: val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)
                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None

                        if fit_mode == 'best_fit':
                            best_metric = float('inf') # Minimize remaining effective capacity
                        else:
                            best_metric = -1.0 # Maximize remaining effective capacity

                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue
                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)

                                if fit_mode == 'best_fit':
                                    if rem_eff < best_metric:
                                        best_metric = rem_eff
                                        best_idx = i
                                else:
                                    if rem_eff > best_metric:
                                        best_metric = rem_eff
                                        best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s
>>>>>>> REPLACE
</DIFF>