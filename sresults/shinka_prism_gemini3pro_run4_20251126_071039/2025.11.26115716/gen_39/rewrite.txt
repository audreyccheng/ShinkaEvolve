# EVOLVE-BLOCK-START
"""Model placement algorithm for minimizing maximum KV cache pressure across GPUs"""

import random

GPU_MEM_SIZE = 80  # GB

def compute_model_placement(gpu_num, models):
    """
    Compute a model placement that minimizes the maximum KVPR across all GPUs.
    
    Combines binary search for optimal max-KVPR target with:
    1. Heuristic Packing with Repair: Tries to pack models using Best-Fit strategies.
       If an item fails to fit, attempts to 'repair' by swapping with a placed item (from Prior Program 6).
    2. Hybrid Randomization: Uses both noisy sorting (Current) and shuffling (Inspiration) 
       to escape local optima in packing order.
    3. Hill Climbing: Post-optimizes valid placements to further reduce KVPR (Current).
    """

    # Preprocessing
    items = []
    for m in models:
        items.append({
            'model': m,
            'w': m.req_rate / m.slo,
            's': m.model_size
        })

    def get_kvpr(w, s):
        rem = GPU_MEM_SIZE - s
        if rem <= 1e-9:
            return float('inf') if w > 1e-9 else 0.0
        return w / rem

    def get_placement_max_kvpr(placement):
        mx = 0.0
        for p in placement.values():
            w = sum(m.req_rate / m.slo for m in p)
            s = sum(m.model_size for m in p)
            mx = max(mx, get_kvpr(w, s))
        return mx

    def local_optimize(placement):
        """Hill Climbing to reduce max KVPR."""
        state = []
        for i in range(gpu_num):
            p = placement[i]
            w = sum(m.req_rate / m.slo for m in p)
            s = sum(m.model_size for m in p)
            state.append({'w': w, 's': s, 'models': list(p), 'k': get_kvpr(w, s)})

        # Limit iterations for speed, but sufficient for convergence
        for _ in range(100):
            # Sort to find bottleneck
            state.sort(key=lambda x: x['k'], reverse=True)
            src = state[0]
            current_max = src['k']
            
            if current_max <= 1e-9: break
            
            improved = False
            
            # 1. Try Move
            for i, m in enumerate(src['models']):
                m_w = m.req_rate / m.slo
                m_s = m.model_size
                
                ns_w = src['w'] - m_w
                ns_s = src['s'] - m_s
                ns_k = get_kvpr(ns_w, ns_s)
                
                # Only move if it helps the bottleneck significantly or at least clears the bar
                if ns_k >= current_max - 1e-9: continue
                
                for dst in state[1:]:
                    if dst['s'] + m_s > GPU_MEM_SIZE: continue
                    
                    nd_w = dst['w'] + m_w
                    nd_s = dst['s'] + m_s
                    nd_k = get_kvpr(nd_w, nd_s)
                    
                    if nd_k < current_max - 1e-9:
                        # Move
                        src['models'].pop(i)
                        src['w'], src['s'], src['k'] = ns_w, ns_s, ns_k
                        
                        dst['models'].append(m)
                        dst['w'], dst['s'], dst['k'] = nd_w, nd_s, nd_k
                        improved = True
                        break
                if improved: break
            
            if improved: continue
            
            # 2. Try Swap
            for i, m1 in enumerate(src['models']):
                m1_w = m1.req_rate / m1.slo
                m1_s = m1.model_size
                
                for dst in state[1:]:
                    if dst['k'] > current_max * 0.95: continue # optimization
                    
                    for j, m2 in enumerate(dst['models']):
                        m2_w = m2.req_rate / m2.slo
                        m2_s = m2.model_size
                        
                        # New Src
                        ns_s = src['s'] - m1_s + m2_s
                        if ns_s > GPU_MEM_SIZE: continue
                        ns_w = src['w'] - m1_w + m2_w
                        
                        # New Dst
                        nd_s = dst['s'] - m2_s + m1_s
                        if nd_s > GPU_MEM_SIZE: continue
                        nd_w = dst['w'] - m2_w + m1_w
                        
                        ns_k = get_kvpr(ns_w, ns_s)
                        nd_k = get_kvpr(nd_w, nd_s)
                        
                        if max(ns_k, nd_k) < current_max - 1e-9:
                            # Swap
                            src['models'][i] = m2
                            src['w'], src['s'], src['k'] = ns_w, ns_s, ns_k
                            
                            dst['models'][j] = m1
                            dst['w'], dst['s'], dst['k'] = nd_w, nd_s, nd_k
                            improved = True
                            break
                    if improved: break
                if improved: break
            
            if not improved: break
            
        return {i: state[i]['models'] for i in range(gpu_num)}

    def solve_packing(k_target, ordered_items):
        placement = {i: [] for i in range(gpu_num)}
        state = [{'w': 0.0, 's': 0.0} for _ in range(gpu_num)]
        
        for item in ordered_items:
            best_idx = -1
            best_score = -1.0
            
            # Try to place
            for i in range(gpu_num):
                st = state[i]
                if st['s'] + item['s'] > GPU_MEM_SIZE: continue
                
                rem = GPU_MEM_SIZE - (st['s'] + item['s'])
                # KVPR Check
                if rem <= 1e-9:
                    if (st['w'] + item['w']) > 1e-9: continue
                elif (st['w'] + item['w']) > k_target * rem + 1e-7:
                    continue
                
                # Best Fit Score
                score = (st['w'] + item['w']) + k_target * (st['s'] + item['s'])
                if score > best_score:
                    best_score = score
                    best_idx = i
            
            if best_idx != -1:
                placement[best_idx].append(item['model'])
                state[best_idx]['w'] += item['w']
                state[best_idx]['s'] += item['s']
            else:
                # Repair: Swap with victim
                repaired = False
                for i in range(gpu_num):
                    st = state[i]
                    for v_idx, victim in enumerate(placement[i]):
                        # Check if item fits in i replacing victim
                        new_s_i = st['s'] - victim.model_size + item['s']
                        if new_s_i > GPU_MEM_SIZE: continue
                        new_w_i = st['w'] - (victim.req_rate/victim.slo) + item['w']
                        
                        rem_i = GPU_MEM_SIZE - new_s_i
                        if rem_i <= 1e-9:
                            if new_w_i > 1e-9: continue
                        elif new_w_i > k_target * rem_i + 1e-7:
                            continue
                            
                        # Victim needs new home
                        v_w = victim.req_rate/victim.slo
                        v_s = victim.model_size
                        
                        for j in range(gpu_num):
                            if i == j: continue
                            st_j = state[j]
                            if st_j['s'] + v_s > GPU_MEM_SIZE: continue
                            
                            rem_j = GPU_MEM_SIZE - (st_j['s'] + v_s)
                            new_w_j = st_j['w'] + v_w
                            
                            if rem_j <= 1e-9:
                                if new_w_j > 1e-9: continue
                            elif new_w_j > k_target * rem_j + 1e-7:
                                continue
                                
                            # Apply Swap
                            placement[i][v_idx] = item['model']
                            state[i]['w'], state[i]['s'] = new_w_i, new_s_i
                            
                            placement[j].append(victim)
                            state[j]['w'], state[j]['s'] = new_w_j, st_j['s'] + v_s
                            repaired = True
                            break
                        if repaired: break
                    if repaired: break
                
                if not repaired: return None
        return placement

    def check_placement(k_target):
        # 1. Deterministic
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w'],
            lambda x: x['w'] / (x['s'] + 1e-9)
        ]
        
        for key in strategies:
            res = solve_packing(k_target, sorted(items, key=key, reverse=True))
            if res: return res
            
        # 2. Randomized
        rng = random.Random(42 + int(k_target))
        base_key = lambda x: x['w'] + k_target * x['s']
        
        # Noisy Sort (Current)
        for _ in range(40):
            noisy_items = sorted(items, key=lambda x: base_key(x) * rng.uniform(0.85, 1.15), reverse=True)
            res = solve_packing(k_target, noisy_items)
            if res: return res
            
        # Shuffle (Inspiration) - good for diversity
        indices = list(range(len(items)))
        for _ in range(20):
            rng.shuffle(indices)
            res = solve_packing(k_target, [items[i] for i in indices])
            if res: return res
            
        return None

    # Binary Search
    high = 1e9
    best_placement = check_placement(high)
    
    if best_placement is None:
        raise ValueError("Unable to place models on GPUs (insufficient total memory).")
    
    best_placement = local_optimize(best_placement)
    high = get_placement_max_kvpr(best_placement)
    low = 0.0
    
    for _ in range(25):
        if high - low < 1e-4: break
        mid = (low + high) / 2
        
        res = check_placement(mid)
        if res:
            res = local_optimize(res)
            mx = get_placement_max_kvpr(res)
            if mx < get_placement_max_kvpr(best_placement):
                best_placement = res
            high = min(mid, mx)
        else:
            low = mid
            
    return local_optimize(best_placement)
# EVOLVE-BLOCK-END