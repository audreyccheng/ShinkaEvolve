<NAME>
failure_driven_packing
</NAME>

<DESCRIPTION>
Implements failure-driven prioritization in the `try_pack` function. This mechanism tracks items that fail to fit during packing attempts and prioritizes them (by moving them to the front of the sort order) in subsequent stochastic trials. This helps the algorithm adaptively identify and place "bottleneck" items that are hard to pack, rather than relying solely on random permutations. Also slightly widens the random noise range for better exploration.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def try_pack(target_k, max_random_trials=0):
        """
        Attempts to pack all models such that for every GPU:
        sum(w) / (C - sum(s)) <= target_k
        Equivalent to: sum(w + target_k * s) <= target_k * C
        Returns placement dict if successful, else None.
        """

        # Strategies to determine order of packing
        # Each strategy is (key_function, reverse_bool)
        # 1. Virtual Size: w + K*s (Standard for variable size bin packing)
        # 2. Physical Size: s
        # 3. Weight: w
        # 4. Density: w/s
        strategies = [
            (lambda x: x['w'] + target_k * x['s'], True),
            (lambda x: x['s'], True),
            (lambda x: x['w'], True),
            (lambda x: x['w'] / (x['s'] + 1e-9), True),
        ]

        # Indices for trials
        trials = list(range(len(strategies)))
        if max_random_trials > 0:
            trials.extend(['rand'] * max_random_trials)

        for t in trials:
            # Sort indices based on strategy
            if isinstance(t, int):
                key_func, reverse = strategies[t]
                ordered_indices = sorted(range(len(m_data)), key=lambda i: key_func(m_data[i]), reverse=reverse)
            else:
                # Stochastic: Perturbed Virtual Size
                # (w + K*s) * random noise (0.9 to 1.1)
                # This breaks ties and local optima of deterministic sorts
                ordered_indices = sorted(range(len(m_data)),
                    key=lambda i: (m_data[i]['w'] + target_k * m_data[i]['s']) * random.uniform(0.9, 1.1),
                    reverse=True)

            # Perform Packing (Best Fit Decreasing on Virtual Slack)
            bins = [{'w': 0.0, 's': 0.0, 'idxs': []} for _ in range(gpu_num)]
            possible = True

            for idx in ordered_indices:
                item = m_data[idx]
                w, s = item['w'], item['s']

                best_bin = None
                min_virtual_slack = float('inf')

                # We want to find a bin that fits physically AND satisfies pressure constraint
                # And minimizes the leftover "pressure budget" (Slack)

                for b_idx in range(gpu_num):
                    b = bins[b_idx]

                    # 1. Physical Fit
                    if b['s'] + s > GPU_MEM_SIZE: continue

                    # 2. Pressure Fit
                    # w_new / rem_new <= K  <=>  w_new <= K * rem_new
                    rem_new = GPU_MEM_SIZE - (b['s'] + s)
                    if rem_new < 0: rem_new = 0.0

                    max_w = target_k * rem_new
                    new_w = b['w'] + w

                    if new_w <= max_w + 1e-5:
                        # Feasible. Calculate slack (virtual remaining capacity)
                        slack = max_w - new_w
                        if slack < min_virtual_slack:
                            min_virtual_slack = slack
                            best_bin = b_idx

                if best_bin is None:
                    possible = False
                    break

                bins[best_bin]['idxs'].append(idx)
                bins[best_bin]['w'] += w
                bins[best_bin]['s'] += s

            if possible:
                return {i: bins[i]['idxs'] for i in range(gpu_num)}

        return None
=======
    def try_pack(target_k, max_random_trials=0):
        """
        Attempts to pack all models such that for every GPU:
        sum(w) / (C - sum(s)) <= target_k
        Equivalent to: sum(w + target_k * s) <= target_k * C
        Returns placement dict if successful, else None.
        """

        # Strategies to determine order of packing
        # Each strategy is (key_function, reverse_bool)
        strategies = [
            (lambda x: x['w'] + target_k * x['s'], True),
            (lambda x: x['s'], True),
            (lambda x: x['w'], True),
            (lambda x: x['w'] / (x['s'] + 1e-9), True),
        ]

        # Indices for trials
        trials = list(range(len(strategies)))
        if max_random_trials > 0:
            trials.extend(['rand'] * max_random_trials)

        failed_items = set()

        for t in trials:
            # Sort indices based on strategy
            if isinstance(t, int):
                key_func, reverse = strategies[t]
                ordered_indices = sorted(range(len(m_data)), key=lambda i: key_func(m_data[i]), reverse=reverse)
            else:
                # Stochastic: Perturbed Virtual Size with Failure Feedback
                # Boost priority of items that failed in previous attempts
                def sort_key(i):
                    item = m_data[i]
                    # Base value: Virtual Size
                    val = (item['w'] + target_k * item['s'])
                    # Noise (0.85 to 1.15)
                    val *= random.uniform(0.85, 1.15)
                    # Boost if failed previously
                    if item['id'] in failed_items:
                        val += 1e9  # Push to front
                    return val

                ordered_indices = sorted(range(len(m_data)), key=sort_key, reverse=True)

            # Perform Packing (Best Fit Decreasing on Virtual Slack)
            bins = [{'w': 0.0, 's': 0.0, 'idxs': []} for _ in range(gpu_num)]
            possible = True
            first_fail_idx = None

            for idx in ordered_indices:
                item = m_data[idx]
                w, s = item['w'], item['s']

                best_bin = None
                min_virtual_slack = float('inf')

                # Best Fit strategy on virtual slack
                for b_idx in range(gpu_num):
                    b = bins[b_idx]

                    # 1. Physical Fit
                    if b['s'] + s > GPU_MEM_SIZE: continue

                    # 2. Pressure Fit
                    # w_new / rem_new <= K  <=>  w_new <= K * rem_new
                    rem_new = GPU_MEM_SIZE - (b['s'] + s)
                    if rem_new < 0: rem_new = 0.0

                    max_w = target_k * rem_new
                    new_w = b['w'] + w

                    if new_w <= max_w + 1e-5:
                        # Feasible. Calculate slack (virtual remaining capacity)
                        slack = max_w - new_w
                        if slack < min_virtual_slack:
                            min_virtual_slack = slack
                            best_bin = b_idx

                if best_bin is None:
                    possible = False
                    first_fail_idx = idx
                    break

                bins[best_bin]['idxs'].append(idx)
                bins[best_bin]['w'] += w
                bins[best_bin]['s'] += s

            if possible:
                return {i: bins[i]['idxs'] for i in range(gpu_num)}
            else:
                if first_fail_idx is not None:
                    failed_items.add(m_data[first_fail_idx]['id'])

        return None
>>>>>>> REPLACE
</DIFF>

<NAME>
increase_search_depth
</NAME>

<DESCRIPTION>
Increases the number of binary search iterations and the number of random trials per check. Given the low execution time, this allows for a finer-grained search of the optimal K and more robust packing checks, maximizing the probability of finding a high-quality solution.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # 2. Binary Search
    # -------------------------------------------------------
    # Perform search to push K down.
    # The stochastic packer gives us a good chance to find a valid config if one exists near 'mid'.
    if high > low + 1e-4:
        # Number of BS iterations
        for _ in range(16):
            mid = (low + high) / 2.0

            # Use randomization to try harder to fit into 'mid'
            sol = try_pack(mid, max_random_trials=8)

            if sol:
=======
    # 2. Binary Search
    # -------------------------------------------------------
    # Perform search to push K down.
    # The stochastic packer gives us a good chance to find a valid config if one exists near 'mid'.
    if high > low + 1e-4:
        # Number of BS iterations
        for _ in range(24):
            mid = (low + high) / 2.0

            # Use randomization to try harder to fit into 'mid'
            # Increased trials to leverage failure-driven adaptation
            sol = try_pack(mid, max_random_trials=20)

            if sol:
>>>>>>> REPLACE
</DIFF>