<NAME>
diversify_bs_packing_and_improve_ls
</NAME>

<DESCRIPTION>
1.  **Diversify Binary Search Packing**: Replaces the single-strategy randomized packer with a multi-strategy approach. It cycles through sorting by Effective Size, Physical Size, Weight, and Density, while applying random noise and prioritizing previously failed items. This increases the probability of finding a valid packing for tight constraint $K$ by trying structurally different packing orders. The number of attempts is increased to 40.
2.  **Best-Fit Local Search Move**: Modifies the Local Search "Move" operation to select the destination GPU that minimizes the resulting pressure (`best_dst_p`), rather than accepting the first valid destination. This "Best Fit" behavior helps balance the load across non-bottleneck GPUs, preserving slack for future moves and potentially allowing deeper optimization.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                # Randomized Best Fit Decreasing Check with Failure Memory
                found_placement = None
                failed_items = set()

                for attempt in range(20):
                    noise = 0.0
                    if attempt > 0:
                        noise = 0.02 + (attempt * 0.005)

                    def sort_key(m):
                        # Base: Effective size
                        val = m.model_size + (m.req_rate / m.slo) / mid
                        # Noise perturbation
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Memory: Prioritize items that failed previously
                        if id(m) in failed_items:
                            val += 1e6
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)

                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        min_rem_eff = float('inf')

                        # Best Fit on Effective Capacity
                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue

                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)
                                if rem_eff < min_rem_eff:
                                    min_rem_eff = rem_eff
                                    best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s

                    if possible_k:
                        found_placement = temp_placement
                        break
                    else:
                        if first_fail_model:
                            failed_items.add(id(first_fail_model))
=======
                # Randomized Multi-Strategy Packing Check with Failure Memory
                found_placement = None
                failed_items = set()

                # Strategies: (Base Key Lambda, Description)
                strategies = [
                    (lambda m: m.model_size + (m.req_rate / m.slo) / mid, 'Effective Size'),
                    (lambda m: m.model_size, 'Physical Size'),
                    (lambda m: m.req_rate / m.slo, 'Weight'),
                    (lambda m: (m.req_rate / m.slo) / (m.model_size + 1e-6), 'Density'),
                ]

                # Increased attempts with strategy rotation
                for attempt in range(40):
                    # Select strategy cyclically or random
                    base_key, _ = strategies[attempt % len(strategies)]

                    noise = 0.0
                    if attempt > 4: # First few attempts deterministic per strategy
                        noise = 0.01 + (attempt * 0.002)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Failure memory: boost priority significantly
                        if id(m) in failed_items:
                            val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)

                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        min_rem_eff = float('inf')

                        # Best Fit Decreasing on Effective Capacity
                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue

                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)
                                if rem_eff < min_rem_eff:
                                    min_rem_eff = rem_eff
                                    best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s

                    if possible_k:
                        found_placement = temp_placement
                        break
                    else:
                        if first_fail_model:
                            failed_items.add(id(first_fail_model))
>>>>>>> REPLACE
<<<<<<< SEARCH
        # 1. Try MOVE (Src -> Dst)
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            best_dst = None
            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                if dst_rem <= 1e-9: continue

                dst_w = gpu_stats[dst]['w'] + w
                new_dst_p = dst_w / dst_rem

                if new_dst_p < max_p - 1e-5:
                     best_dst = dst
                     break

            if best_dst is not None:
                moved_model = src_models.pop(m_idx)
                best_placement[best_dst].append(moved_model)
                improved = True
                break
=======
        # 1. Try MOVE (Src -> Dst) with Best Fit selection
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            best_dst = None
            best_dst_p = float('inf')

            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                if dst_rem <= 1e-9: continue

                dst_w = gpu_stats[dst]['w'] + w
                new_dst_p = dst_w / dst_rem

                if new_dst_p < max_p - 1e-5:
                    if new_dst_p < best_dst_p:
                        best_dst_p = new_dst_p
                        best_dst = dst

            if best_dst is not None:
                moved_model = src_models.pop(m_idx)
                best_placement[best_dst].append(moved_model)
                improved = True
                break
>>>>>>> REPLACE
</DIFF>