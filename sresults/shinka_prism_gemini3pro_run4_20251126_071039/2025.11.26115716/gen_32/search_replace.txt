<NAME>
add_deterministic_strategy
</NAME>

<DESCRIPTION>
Add a "difficulty" sorting strategy to the deterministic set in `check_placement`.
The metric `x['w'] / (GPU_MEM_SIZE - x['s'])` represents the KVPR required by the item if it were placed alone in an empty GPU. Items with high intrinsic KVPR requirements are harder to place and should be prioritized. This provides a valuable heuristic that captures the tightness of the memory constraint relative to the rate requirement.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w'],
            lambda x: x['w'] / (x['s'] + 1e-9)
        ]
=======
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w'],
            lambda x: x['w'] / (x['s'] + 1e-9),
            lambda x: x['w'] / (GPU_MEM_SIZE - x['s'] + 1e-9)
        ]
>>>>>>> REPLACE
</DIFF>

<NAME>
noisy_sorting
</NAME>

<DESCRIPTION>
Replace the purely random shuffle in the `check_placement` function with a "Noisy Heuristic" sorting strategy.
Instead of discarding the heuristic information (Weight + K*Size) by shuffling indices, we add multiplicative noise to the sort key. This allows the algorithm to explore permutations that are locally diverse (exploring the neighborhood of the optimal deterministic ordering) but globally adhere to the effective bin-packing heuristic. The random seed is also made dependent on `k_target` to ensure diversity across binary search iterations.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # 2. Randomized Strategies (Shuffle + Best Fit)
        rng = random.Random(42)
        indices = list(range(len(items)))
        for _ in range(50):
            rng.shuffle(indices)
            res = try_pack([items[i] for i in indices])
            if res: return res

        return None
=======
        # 2. Randomized Strategies (Noisy Heuristic)
        rng = random.Random(42 + int(k_target * 100))
        base_key = lambda x: x['w'] + k_target * x['s']

        for _ in range(50):
            # Sort with multiplicative noise on the key to explore near-optimal orderings
            noisy_items = sorted(items, key=lambda x: base_key(x) * rng.uniform(0.8, 1.2), reverse=True)
            res = try_pack(noisy_items)
            if res: return res

        return None
>>>>>>> REPLACE
</DIFF>

<NAME>
local_search_best_fit_move
</NAME>

<DESCRIPTION>
Refine the local search optimization (Hill Climbing) to use a "Best Fit" strategy for selecting the destination of a moved model.
Previously, the algorithm moved the model to the first valid GPU found that satisfied the improvement condition (First Fit). Now, it scans all valid destination GPUs and selects the one that results in the lowest KVPR after the move. This promotes better load balancing across all GPUs, preventing the formation of secondary bottlenecks and enabling deeper optimization of the global maximum KVPR.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = state[dst_idx]

                    if dst['s'] + m_s > GPU_MEM_SIZE: continue

                    nd_val = calc_val(dst['w'] + m_w, dst['s'] + m_s)

                    if nd_val < max_val - 1e-9:
                        # Move
                        src['models'].pop(i)
                        src['w'], src['s'], src['val'] = ns_w, ns_s, ns_val

                        dst['models'].append(m)
                        dst['w'] += m_w
                        dst['s'] += m_s
                        dst['val'] = nd_val
                        improved = True
                        break
                if improved: break
=======
                best_dst_idx = -1
                best_dst_val = float('inf')

                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = state[dst_idx]

                    if dst['s'] + m_s > GPU_MEM_SIZE: continue

                    nd_val = calc_val(dst['w'] + m_w, dst['s'] + m_s)

                    if nd_val < max_val - 1e-9:
                        if nd_val < best_dst_val:
                            best_dst_val = nd_val
                            best_dst_idx = dst_idx

                if best_dst_idx != -1:
                    src['models'].pop(i)
                    src['w'], src['s'], src['val'] = ns_w, ns_s, ns_val

                    dst = state[best_dst_idx]
                    dst['models'].append(m)
                    dst['w'] += m_w
                    dst['s'] += m_s
                    dst['val'] = best_dst_val
                    improved = True
                    break

                if improved: break
>>>>>>> REPLACE
</DIFF>