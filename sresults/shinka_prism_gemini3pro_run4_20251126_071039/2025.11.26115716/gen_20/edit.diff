--- a/original.py
+++ b/original.py
@@ -1,347 +1,315 @@
 # EVOLVE-BLOCK-START
 """Model placement algorithm for minimizing maximum KV cache pressure across GPUs"""
 
 import random
 
 GPU_MEM_SIZE = 80  # GB
 
 def compute_model_placement(gpu_num, models):
     """
     Compute a model placement that minimizes the maximum KVPR across all GPUs.
 
     Algorithm:
     1. Calculate Lower Bound (LB) for K based on aggregate stats.
     2. Binary Search for optimal K between LB and High.
        - Uses a 'Pack with Repair' strategy:
          - Greedy Best-Fit Decreasing with linearized cost (W + K*S).
          - Randomized 'Noisy' Sorting for robustness.
          - 1-step Lookahead Repair (Swap) if greedy placement fails.
        - Aggressively tightens Upper Bound using actual max KVPR of valid solutions.
     3. Post-Placement Hill Climbing to minimize KVPR of the final solution.
 
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
 
     Returns:
         A placement of models to GPUs
     """
 
     # 1. Preprocessing and Lower Bound
     items = []
     total_w = 0.0
     total_s = 0.0
     max_single_kvpr = 0.0
 
     for m in models:
         w = m.req_rate / m.slo
         s = m.model_size
         items.append({'model': m, 'w': w, 's': s})
         total_w += w
         total_s += s
 
         rem = GPU_MEM_SIZE - s
         if rem > 1e-9:
             max_single_kvpr = max(max_single_kvpr, w / rem)
         elif w > 1e-9:
             max_single_kvpr = 1e9 # Impossible single item
 
     # Theoretical global lower bound
     total_cap = gpu_num * GPU_MEM_SIZE
     rem_global = total_cap - total_s
 
     lb = 0.0
     if rem_global > 1e-9:
         lb = total_w / rem_global
     elif total_w > 1e-9:
         lb = 1e9 # Impossible
 
     lb = max(lb, max_single_kvpr)
 
     def get_max_kvpr(placement_list):
         mx = 0.0
         for p in placement_list:
             w = sum(x['w'] for x in p)
             s = sum(x['s'] for x in p)
             rem = GPU_MEM_SIZE - s
             if rem <= 1e-9:
                 if w > 1e-9: return float('inf')
                 val = 0.0
             else:
                 val = w / rem
             mx = max(mx, val)
         return mx
 
     def local_optimize(placement_list):
         """Hill climbing to improve a valid placement."""
         # Convert to state format
         state = []
         for p in placement_list:
             w = sum(x['w'] for x in p)
             s = sum(x['s'] for x in p)
             rem = GPU_MEM_SIZE - s
             kvpr = w / rem if rem > 1e-9 else (float('inf') if w > 1e-9 else 0.0)
             state.append({'w': w, 's': s, 'items': list(p), 'kvpr': kvpr})
 
         # Helper to update a bin's state
         def update_bin(b_idx):
             b = state[b_idx]
             b['w'] = sum(x['w'] for x in b['items'])
             b['s'] = sum(x['s'] for x in b['items'])
             rem = GPU_MEM_SIZE - b['s']
             b['kvpr'] = b['w'] / rem if rem > 1e-9 else (float('inf') if b['w'] > 1e-9 else 0.0)
 
         improved = True
         iter_count = 0
         while improved and iter_count < 100:
             improved = False
             iter_count += 1
 
             # Sort by pressure
             state_indices = sorted(range(gpu_num), key=lambda i: state[i]['kvpr'], reverse=True)
             src_idx = state_indices[0]
             current_max = state[src_idx]['kvpr']
 
             if current_max <= 1e-9: break
 
             src = state[src_idx]
 
             # Try Move
             for i, item in enumerate(src['items']):
                 # Predict src removal
                 ns_rem = GPU_MEM_SIZE - (src['s'] - item['s'])
                 if ns_rem <= 1e-9: continue
                 ns_kvpr = (src['w'] - item['w']) / ns_rem
 
                 # Heuristic: only move if src improves significantly or at least below current_max
                 if ns_kvpr >= current_max: continue
 
                 for dst_idx in state_indices[1:]:
                     dst = state[dst_idx]
                     if dst['s'] + item['s'] > GPU_MEM_SIZE: continue
 
                     nd_rem = GPU_MEM_SIZE - (dst['s'] + item['s'])
                     if nd_rem <= 1e-9: continue
                     nd_kvpr = (dst['w'] + item['w']) / nd_rem
 
                     if nd_kvpr < current_max:
                         # Apply Move
                         item_to_move = src['items'].pop(i)
                         dst['items'].append(item_to_move)
                         update_bin(src_idx)
                         update_bin(dst_idx)
                         improved = True
                         break
                 if improved: break
 
             if improved: continue
 
             # Try Swap
             for i, item1 in enumerate(src['items']):
                 for dst_idx in state_indices[1:]:
                     dst = state[dst_idx]
                     # Optimization: Don't swap with full GPUs
                     if dst['kvpr'] > current_max * 0.95: continue
 
                     for j, item2 in enumerate(dst['items']):
                         # Check Capacity
                         ns_s = src['s'] - item1['s'] + item2['s']
                         nd_s = dst['s'] - item2['s'] + item1['s']
                         if ns_s > GPU_MEM_SIZE or nd_s > GPU_MEM_SIZE: continue
 
                         ns_rem = GPU_MEM_SIZE - ns_s
                         nd_rem = GPU_MEM_SIZE - nd_s
                         if ns_rem <= 1e-9 or nd_rem <= 1e-9: continue
 
                         ns_kvpr = (src['w'] - item1['w'] + item2['w']) / ns_rem
                         nd_kvpr = (dst['w'] - item2['w'] + item1['w']) / nd_rem
 
                         if max(ns_kvpr, nd_kvpr) < current_max:
                             # Apply Swap
                             src['items'][i] = item2
                             dst['items'][j] = item1
                             update_bin(src_idx)
                             update_bin(dst_idx)
                             improved = True
                             break
                     if improved: break
                 if improved: break
 
         return [b['items'] for b in state]
 
     def solve(k_target, attempt_limit=5):
         limit_val = k_target * GPU_MEM_SIZE
 
-        def pack(ordered_items):
-            # bins: list of dicts {w, s, items}
-            bins = [{'w': 0.0, 's': 0.0, 'items': []} for _ in range(gpu_num)]
-
-            for item in ordered_items:
-                item_lin = item['w'] + k_target * item['s']
-
-                best_idx = -1
-                best_fill = -1.0 # Best Fit: Maximize current load (tightest packing)
+        # Beam Search Construction
+        # Sort by linear cost descending (w + k*s)
+        sorted_items = sorted(items, key=lambda x: x['w'] + k_target * x['s'], reverse=True)
+
+        # State: (loads_tuple, placement_list)
+        # loads_tuple: ((w, s), ...) for each GPU
+        beam = [(tuple((0.0, 0.0) for _ in range(gpu_num)), [[] for _ in range(gpu_num)])]
+        BEAM_WIDTH = 8
+
+        for item in sorted_items:
+            item_lin = item['w'] + k_target * item['s']
+            candidates = []
+
+            for loads, placement in beam:
+                seen_loads = set()
 
                 for i in range(gpu_num):
-                    b = bins[i]
-                    if b['s'] + item['s'] > GPU_MEM_SIZE: continue
-
-                    current_lin = b['w'] + k_target * b['s']
+                    w, s = loads[i]
+                    # Symmetry breaking: if multiple GPUs have exact same state, only try one
+                    if (w, s) in seen_loads: continue
+                    seen_loads.add((w, s))
+
+                    # Capacity Check
+                    if s + item['s'] > GPU_MEM_SIZE: continue
+
+                    # KVPR Check (Linearized: w + k*s <= k*Cap)
+                    # Use slight tolerance for float precision
+                    current_lin = w + k_target * s
                     if current_lin + item_lin > limit_val + 1e-5: continue
 
-                    if current_lin > best_fill:
-                        best_fill = current_lin
-                        best_idx = i
-
-                if best_idx != -1:
-                    bins[best_idx]['items'].append(item)
-                    bins[best_idx]['w'] += item['w']
-                    bins[best_idx]['s'] += item['s']
-                else:
-                    # Repair: Swap
-                    # Try to find a victim in bin 'v_idx' that, if replaced by 'item',
-                    # allows 'item' to fit, AND 'victim' fits elsewhere.
-                    repaired = False
-                    for i in range(gpu_num):
-                        b = bins[i]
-                        for v_idx, victim in enumerate(b['items']):
-                            # Can we swap item into b replacing victim?
-                            # Check size
-                            if b['s'] - victim['s'] + item['s'] > GPU_MEM_SIZE: continue
-                            # Check KVPR (linear)
-                            new_lin_i = (b['w'] - victim['w'] + item['w']) + k_target * (b['s'] - victim['s'] + item['s'])
-                            if new_lin_i > limit_val + 1e-5: continue
-
-                            # Victim needs a new home
-                            victim_lin = victim['w'] + k_target * victim['s']
-                            for k in range(gpu_num):
-                                if i == k: continue
-                                bk = bins[k]
-                                if bk['s'] + victim['s'] > GPU_MEM_SIZE: continue
-                                new_lin_k = (bk['w'] + k_target * bk['s']) + victim_lin
-                                if new_lin_k <= limit_val + 1e-5:
-                                    # Swap
-                                    b['items'][v_idx] = item
-                                    b['w'] += (item['w'] - victim['w'])
-                                    b['s'] += (item['s'] - victim['s'])
-
-                                    bk['items'].append(victim)
-                                    bk['w'] += victim['w']
-                                    bk['s'] += victim['s']
-                                    repaired = True
-                                    break
-                            if repaired: break
-                        if repaired: break
-
-                    if not repaired:
-                        return None
-
-            return [b['items'] for b in bins]
-
-        # 1. Deterministic
-        # Sort by linear cost descending
-        res = pack(sorted(items, key=lambda x: x['w'] + k_target * x['s'], reverse=True))
-        if res: return res
-
-        # Sort by Size descending
-        res = pack(sorted(items, key=lambda x: x['s'], reverse=True))
-        if res: return res
-
-        # 2. Noisy Randomized
-        if attempt_limit > 0:
-            rng = random.Random(42 + int(k_target * 100))
-            base_key = lambda x: x['w'] + k_target * x['s']
-            for _ in range(attempt_limit):
-                # Add noise to sort key
-                noisy_items = sorted(items, key=lambda x: base_key(x) * rng.uniform(0.9, 1.1), reverse=True)
-                res = pack(noisy_items)
-                if res: return res
-
-        return None
+                    # Construct new state
+                    new_w = w + item['w']
+                    new_s = s + item['s']
+
+                    new_loads = list(loads)
+                    new_loads[i] = (new_w, new_s)
+
+                    new_placement = [list(p) for p in placement]
+                    new_placement[i].append(item)
+
+                    # Score: Sum of squares of linearized load.
+                    # Maximizes "clumpiness" (Best Fit), reducing fragmentation.
+                    score = sum((lw + k_target * ls)**2 for lw, ls in new_loads)
+
+                    candidates.append((score, tuple(new_loads), new_placement))
+
+            if not candidates:
+                return None
+
+            # Keep top K candidates
+            candidates.sort(key=lambda x: x[0], reverse=True)
+            beam = [(c[1], c[2]) for c in candidates[:BEAM_WIDTH]]
+
+        return beam[0][2]
 
     # Binary Search
     high = 1e9
 
     # Initial feasibility check
     init_res = solve(high, 0)
     if not init_res:
         init_res = solve(high, 20)
         if not init_res:
             raise ValueError("Unable to place models (insufficient memory).")
 
     best_pl_list = local_optimize(init_res)
     high = min(high, get_max_kvpr(best_pl_list))
     low = lb
 
     # Main loop
     for _ in range(25):
         if high - low < 1e-4: break
         mid = (low + high) / 2
 
         # Try to find a valid placement for K=mid
         res = solve(mid, attempt_limit=5)
 
         if res:
             # Found a valid placement. Optimize it to see if we can go even lower.
             res = local_optimize(res)
             mx = get_max_kvpr(res)
             best_pl_list = res
             high = min(mid, mx)
         else:
             low = mid
 
     # Final optimize
     best_pl_list = local_optimize(best_pl_list)
 
     # Format return
     return {i: [x['model'] for x in p] for i, p in enumerate(best_pl_list)}
 # EVOLVE-BLOCK-END
 
 
 def run_placement(gpu_num, models):
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
 
     Returns:
         Dictionary containing GPU placements
     """
     return compute_model_placement(gpu_num, models)
 
 
 if __name__ == "__main__":
     # Test the algorithm
     import os
     import sys
 
     # Add the openevolve_examples directory to the path to import evaluator
     def find_repo_root(start_path):
         """Find the repository root by looking for openevolve_examples directory."""
         current = os.path.abspath(start_path)
         while current != os.path.dirname(current):  # Stop at filesystem root
             if os.path.exists(os.path.join(current, 'openevolve_examples', 'prism')):
                 return current
             current = os.path.dirname(current)
         raise RuntimeError("Could not find openevolve_examples directory")
 
     repo_root = find_repo_root(os.path.dirname(__file__))
     sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'prism'))
 
     from evaluator import generate_test_gpu_models, calculate_kvcache_pressure, safe_float
     import numpy as np
 
     test_cases = generate_test_gpu_models()
     all_kvpr = []
     for i, (gpu_num, gpu_models) in enumerate(test_cases):
         results = compute_model_placement(gpu_num, gpu_models)
         max_kvpr = calculate_kvcache_pressure(results)
         all_kvpr.append(safe_float(max_kvpr))
 
     avg_kvpr = np.mean(all_kvpr)
     if avg_kvpr != 0:
         avg_kvpr = 1.0 / avg_kvpr
 
     print(f"Max KVPR: {avg_kvpr:.3f}")