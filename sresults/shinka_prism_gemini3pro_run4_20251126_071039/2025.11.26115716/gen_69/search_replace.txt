<NAME>
hybrid_packing_strategies
</NAME>

<DESCRIPTION>
I will improve the feasibility check within the binary search by adding an asymptotic "Pressure" sorting strategy that prioritizes models consuming nearly all GPU memory. Additionally, I will introduce a hybrid packing strategy that toggles between "Best Fit" (minimizing slack) and "Worst Fit" (maximizing slack/load balancing) during the randomized trials. This diversity helps escape local optima where one packing heuristic fails, especially for the bin packing constraint derived from the KVPR objective.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                # Strategy pool for sorting models
                strategies = [
                    (lambda m: m.model_size + (m.req_rate / m.slo) / mid, 'Effective'),
                    (lambda m: m.model_size, 'Physical'),
                    (lambda m: m.req_rate / m.slo, 'Weight'),
                    (lambda m: (m.req_rate / m.slo) / (m.model_size + 1e-6), 'Density')
                ]

                for attempt in range(32):
                    # Cycle through strategies
                    base_key, _ = strategies[attempt % len(strategies)]

                    # Adaptive Noise
                    noise = 0.0
                    if attempt >= 4:
                        noise = 0.01 + (attempt * 0.002)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Failure memory boost
                        if id(m) in failed_items:
                            val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)

                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        min_rem_eff = float('inf')

                        # Best Fit on Effective Capacity
                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue

                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)
                                if rem_eff < min_rem_eff:
                                    min_rem_eff = rem_eff
                                    best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s
=======
                # Strategy pool for sorting models
                strategies = [
                    (lambda m: m.model_size + (m.req_rate / m.slo) / mid, 'Effective'),
                    (lambda m: m.model_size, 'Physical'),
                    (lambda m: m.req_rate / m.slo, 'Weight'),
                    (lambda m: (m.req_rate / m.slo) / (m.model_size + 1e-6), 'Density'),
                    # Asymptotic pressure key: prioritize items that consume almost all memory
                    (lambda m: (m.req_rate / m.slo) / (GPU_MEM_SIZE - m.model_size + 1e-9), 'Pressure'),
                ]

                for attempt in range(40):
                    # Cycle through strategies
                    base_key, _ = strategies[attempt % len(strategies)]

                    # Adaptive Noise
                    noise = 0.0
                    if attempt >= len(strategies):
                        noise = 0.01 + (attempt * 0.002)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Failure memory boost
                        if id(m) in failed_items:
                            val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)

                    # Toggle Packing Strategy: Mostly Best Fit, occasionally Worst Fit
                    # Worst Fit spreads the load, which can sometimes help fit a mix of items.
                    use_worst_fit = (attempt % 6 == 5)

                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        best_metric = float('inf') if not use_worst_fit else -1.0

                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue

                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)

                                if not use_worst_fit:
                                    # Best Fit: Minimize remaining space
                                    if rem_eff < best_metric:
                                        best_metric = rem_eff
                                        best_idx = i
                                else:
                                    # Worst Fit: Maximize remaining space (Load Balancing)
                                    if rem_eff > best_metric:
                                        best_metric = rem_eff
                                        best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s
>>>>>>> REPLACE
</DIFF>