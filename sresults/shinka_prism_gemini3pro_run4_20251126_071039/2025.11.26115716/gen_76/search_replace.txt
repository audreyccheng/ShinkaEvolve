<NAME>
strategies_and_sa
</NAME>

<DESCRIPTION>
1.  **Enhanced Bin Packing Strategies**: In the `solve_packing` function (used by Binary Search), I added 'Density' and 'Asymptotic Pressure' sorting strategies. This diversity helps the feasibility checker find valid packings for tighter pressure constraints (smaller K), potentially lowering the initial upper bound passed to the local search.
2.  **Simulated Annealing (SA) Refinement**: Replaced the Iterated Local Search (Greedy Hill Climbing + Perturbation) with a Simulated Annealing optimizer.
    *   **Objective**: Minimizes the $L^8$ norm of GPU pressures ($\sum P_i^8$). This acts as a smooth "soft-max" function, creating a better gradient for the optimizer than the raw Maximum function (which has flat plateaus).
    *   **Exploration**: Uses standard Move and Swap operators with a cooling schedule, allowing the algorithm to escape local optima by accepting temporary degradations.
    *   **Efficiency**: Maintains incremental state updates for $O(1)$ move evaluation (excluding the loop over items, which is fast), allowing for 4000 iterations within the time budget.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # Strategies: (Base Key Lambda, Reverse)
        strategies = [
            (lambda x: x['s'] + x['w']/target_k, True), # Effective Size (Best Fit)
            (lambda x: x['s'], True),                   # Physical Size
            (lambda x: x['w'], True),                   # Weight
        ]
=======
        # Strategies: (Base Key Lambda, Reverse)
        strategies = [
            (lambda x: x['s'] + x['w']/target_k, True),              # Effective Size (Best Fit)
            (lambda x: x['s'], True),                                # Physical Size
            (lambda x: x['w'], True),                                # Weight
            (lambda x: x['w'] / (x['s'] + 1e-6), True),              # Density
            (lambda x: x['w'] / (GPU_MEM_SIZE - x['s'] + 1e-6), True)# Asymptotic Pressure
        ]
>>>>>>> REPLACE
<<<<<<< SEARCH
    # ---------------------------------------------------------
    # 2. Iterated Local Search (ILS)
    # ---------------------------------------------------------
    # State representation: list of lists of indices
    current_sol = [list(best_placement[g]) for g in range(gpu_num)]

    # Helper to get full stats
    def get_stats(solution):
        """Returns list of dicts {w, s, p} and global metrics"""
        stats = []
        max_p = 0.0
        sum_sq_p = 0.0
        for g in range(gpu_num):
            w = sum(m_data[i]['w'] for i in solution[g])
            s = sum(m_data[i]['s'] for i in solution[g])
            rem = GPU_MEM_SIZE - s
            p = w / rem if rem > 1e-9 else (float('inf') if w > 0 else 0.0)
            stats.append({'w': w, 's': s, 'p': p})
            max_p = max(max_p, p)
            sum_sq_p += p*p
        return stats, max_p, sum_sq_p

    curr_stats, curr_max, curr_ssq = get_stats(current_sol)

    # Store global best
    global_best_sol = [list(x) for x in current_sol]
    global_best_max = curr_max

    def local_search(sol, stats, max_p, ssq_p):
        """Greedy Hill Climbing with Lexicographical Objective"""
        improved = True
        while improved:
            improved = False

            # Identify bottleneck
            src_gpu = -1
            highest_p = -1.0
            for g in range(gpu_num):
                if stats[g]['p'] > highest_p:
                    highest_p = stats[g]['p']
                    src_gpu = g

            if src_gpu == -1 or highest_p < 1e-9: break

            # Candidates for destination
            # 1. MOVE
            for i_idx, m_idx in enumerate(sol[src_gpu]):
                item = m_data[m_idx]

                # Old Src
                src_w_old = stats[src_gpu]['w']
                src_s_old = stats[src_gpu]['s']
                src_p_old = stats[src_gpu]['p']

                # New Src
                src_s_new = src_s_old - item['s']
                src_w_new = src_w_old - item['w']
                rem = GPU_MEM_SIZE - src_s_new
                src_p_new = src_w_new/rem if rem > 1e-9 else float('inf')

                best_dst = None
                best_dst_tuple = (max_p, ssq_p) # (max, sum_sq)

                for dst in range(gpu_num):
                    if dst == src_gpu: continue
                    if stats[dst]['s'] + item['s'] > GPU_MEM_SIZE: continue

                    dst_w_old = stats[dst]['w']
                    dst_s_old = stats[dst]['s']
                    dst_p_old = stats[dst]['p']

                    dst_s_new = dst_s_old + item['s']
                    dst_w_new = dst_w_old + item['w']
                    rem_d = GPU_MEM_SIZE - dst_s_new
                    dst_p_new = dst_w_new/rem_d if rem_d > 1e-9 else float('inf')

                    # New global max check
                    local_pair_max = max(src_p_new, dst_p_new)

                    if local_pair_max > highest_p - 1e-6: continue

                    # Recalculate full metrics roughly
                    new_ssq = ssq_p - (src_p_old**2 + dst_p_old**2) + (src_p_new**2 + dst_p_new**2)

                    new_max = local_pair_max
                    for g in range(gpu_num):
                        if g != src_gpu and g != dst:
                            if stats[g]['p'] > new_max:
                                new_max = stats[g]['p']

                    new_tuple = (new_max, new_ssq)

                    if new_tuple < best_dst_tuple:
                        best_dst_tuple = new_tuple
                        best_dst = dst

                if best_dst is not None:
                    # Apply Move
                    sol[src_gpu].pop(i_idx)
                    sol[best_dst].append(m_idx)

                    m = item
                    stats[src_gpu] = {'w': src_w_new, 's': src_s_new, 'p': src_p_new}

                    d_w = stats[best_dst]['w'] + m['w']
                    d_s = stats[best_dst]['s'] + m['s']
                    rem_d = GPU_MEM_SIZE - d_s
                    d_p = d_w/rem_d if rem_d > 1e-9 else float('inf')
                    stats[best_dst] = {'w': d_w, 's': d_s, 'p': d_p}

                    max_p, ssq_p = best_dst_tuple
                    improved = True
                    break

            if improved: continue

            # 2. SWAP
            for s_idx, m_src_idx in enumerate(sol[src_gpu]):
                m_src = m_data[m_src_idx]

                best_swap_tuple = (max_p, ssq_p)
                best_swap_target = None

                src_p_old = stats[src_gpu]['p']

                for dst in range(gpu_num):
                    if dst == src_gpu: continue
                    dst_p_old = stats[dst]['p']

                    for d_idx, m_dst_idx in enumerate(sol[dst]):
                        m_dst = m_data[m_dst_idx]

                        # Capacity check
                        new_src_s = stats[src_gpu]['s'] - m_src['s'] + m_dst['s']
                        if new_src_s > GPU_MEM_SIZE: continue
                        new_dst_s = stats[dst]['s'] - m_dst['s'] + m_src['s']
                        if new_dst_s > GPU_MEM_SIZE: continue

                        # Pressure check
                        rem_src = GPU_MEM_SIZE - new_src_s
                        new_src_w = stats[src_gpu]['w'] - m_src['w'] + m_dst['w']
                        new_src_p = new_src_w / rem_src if rem_src > 1e-9 else float('inf')

                        rem_dst = GPU_MEM_SIZE - new_dst_s
                        new_dst_w = stats[dst]['w'] - m_dst['w'] + m_src['w']
                        new_dst_p = new_dst_w / rem_dst if rem_dst > 1e-9 else float('inf')

                        local_pair_max = max(new_src_p, new_dst_p)
                        if local_pair_max > highest_p - 1e-6: continue

                        new_ssq = ssq_p - (src_p_old**2 + dst_p_old**2) + (new_src_p**2 + new_dst_p**2)

                        new_max = local_pair_max
                        for g in range(gpu_num):
                            if g != src_gpu and g != dst:
                                if stats[g]['p'] > new_max:
                                    new_max = stats[g]['p']

                        new_tuple = (new_max, new_ssq)
                        if new_tuple < best_swap_tuple:
                            best_swap_tuple = new_tuple
                            best_swap_target = (dst, d_idx)

                if best_swap_target:
                    dst_gpu, d_list_idx = best_swap_target
                    m_dst_idx = sol[dst_gpu][d_list_idx]

                    # Apply Swap
                    sol[src_gpu][s_idx] = m_dst_idx
                    sol[dst_gpu][d_list_idx] = m_src_idx

                    # Update Stats
                    s_w = sum(m_data[i]['w'] for i in sol[src_gpu])
                    s_s = sum(m_data[i]['s'] for i in sol[src_gpu])
                    s_p = s_w/(GPU_MEM_SIZE-s_s) if (GPU_MEM_SIZE-s_s)>1e-9 else float('inf')
                    stats[src_gpu] = {'w': s_w, 's': s_s, 'p': s_p}

                    d_w = sum(m_data[i]['w'] for i in sol[dst_gpu])
                    d_s = sum(m_data[i]['s'] for i in sol[dst_gpu])
                    d_p = d_w/(GPU_MEM_SIZE-d_s) if (GPU_MEM_SIZE-d_s)>1e-9 else float('inf')
                    stats[dst_gpu] = {'w': d_w, 's': d_s, 'p': d_p}

                    max_p, ssq_p = best_swap_tuple
                    improved = True
                    break

            if improved: continue

        return sol, stats, max_p, ssq_p

    # Initial Local Search
    current_sol, curr_stats, curr_max, curr_ssq = local_search(current_sol, curr_stats, curr_max, curr_ssq)
    global_best_sol = [list(x) for x in current_sol]
    global_best_max = curr_max

    # ILS Loop (Perturbation)
    for _ in range(15):
        if global_best_max < 1e-9: break

        # Perturbation: Ruin and Recreate the bottleneck GPU
        bottleneck_gpu = -1
        max_p = -1.0
        for g in range(gpu_num):
            if curr_stats[g]['p'] > max_p:
                max_p = curr_stats[g]['p']
                bottleneck_gpu = g

        if bottleneck_gpu == -1: break

        # Copy state
        new_sol = [list(x) for x in current_sol]

        # Force Move: Eject 2 items from bottleneck to random feasible other GPUs
        if new_sol[bottleneck_gpu]:
            moves = 0
            indices_to_move = list(range(len(new_sol[bottleneck_gpu])))
            random.shuffle(indices_to_move)

            for idx_in_list in indices_to_move:
                m_idx = new_sol[bottleneck_gpu][idx_in_list]
                item = m_data[m_idx]

                targets = list(range(gpu_num))
                random.shuffle(targets)
                moved = False
                for t in targets:
                    if t == bottleneck_gpu: continue
                    s_curr = sum(m_data[i]['s'] for i in new_sol[t])
                    if s_curr + item['s'] <= GPU_MEM_SIZE:
                        new_sol[bottleneck_gpu][idx_in_list] = -1
                        new_sol[t].append(m_idx)
                        moved = True
                        break
                if moved:
                    moves += 1
                    if moves >= 2: break

            new_sol[bottleneck_gpu] = [x for x in new_sol[bottleneck_gpu] if x != -1]

        # Run Local Search on perturbed state
        new_stats, new_max, new_ssq = get_stats(new_sol)
        new_sol, new_stats, new_max, new_ssq = local_search(new_sol, new_stats, new_max, new_ssq)

        # Acceptance: Strict improvement on primary, or any improvement on secondary if primary is equal
        if new_max < global_best_max - 1e-6:
            global_best_max = new_max
            global_best_sol = [list(x) for x in new_sol]
            current_sol = new_sol
            curr_stats, curr_max, curr_ssq = new_stats, new_max, new_ssq
        elif abs(new_max - global_best_max) < 1e-6 and new_ssq < curr_ssq:
             current_sol = new_sol
             curr_stats, curr_max, curr_ssq = new_stats, new_max, new_ssq
        else:
             # Revert
             current_sol = [list(x) for x in global_best_sol]
             curr_stats, curr_max, curr_ssq = get_stats(current_sol)

    # ---------------------------------------------------------
    # 3. Output Formatting
    # ---------------------------------------------------------
    result = {}
    for g, idxs in enumerate(global_best_sol):
        result[g] = [m_data[i]['obj'] for i in idxs]

    return result
=======
    # ---------------------------------------------------------
    # 2. Simulated Annealing (SA) Refinement
    # ---------------------------------------------------------
    # Use SA to minimize L-p norm of pressures, which approximates Min-Max smoothly.
    # Objective: Sum (P_i)^8. This penalizes the peak heavily.

    current_sol = [list(best_placement[g]) for g in range(gpu_num)]

    # State tracking
    gpu_w = []
    gpu_s = []
    gpu_p = []

    def calc_pressure(w, s):
        rem = GPU_MEM_SIZE - s
        if rem <= 1e-9: return float('inf') if w > 0 else 0.0
        return w / rem

    for g in range(gpu_num):
        w = sum(m_data[i]['w'] for i in current_sol[g])
        s = sum(m_data[i]['s'] for i in current_sol[g])
        gpu_w.append(w)
        gpu_s.append(s)
        gpu_p.append(calc_pressure(w, s))

    def get_energy(pressures):
        # L-8 norm to approximate max
        return sum(p**8 for p in pressures)

    curr_energy = get_energy(gpu_p)

    best_sol_indices = [list(x) for x in current_sol]
    best_max_p = max(gpu_p)

    # SA Parameters
    max_iter = 4000
    t_start = 1.0

    for it in range(max_iter):
        T = t_start * (1.0 - it / max_iter)
        if T < 1e-6: T = 1e-6

        # 1. Select Source GPU (Tournament Selection for High Pressure)
        c1 = random.randint(0, gpu_num - 1)
        c2 = random.randint(0, gpu_num - 1)
        src = c1 if gpu_p[c1] > gpu_p[c2] else c2

        if not current_sol[src]: continue

        # 2. Select Operation
        op_type = random.random() # 0-0.5: Move, 0.5-1.0: Swap

        dst = random.randint(0, gpu_num - 1)
        while dst == src:
            dst = random.randint(0, gpu_num - 1)

        accepted = False

        # Helper to compute delta energy
        def try_update(new_src_p, new_dst_p, old_src_p, old_dst_p):
            # Delta E
            old_term = old_src_p**8 + old_dst_p**8
            new_term = new_src_p**8 + new_dst_p**8
            delta = new_term - old_term

            # Metropolis Criteria
            # Scale delta by current energy to normalize for T
            scaled_delta = delta / (curr_energy + 1e-9)

            if delta < 0:
                return True, delta

            r = random.random()
            if r < math.exp(-scaled_delta / (T