# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Sorted Greedy KV-Cache Pressure Minimization**
- **Implementation**: The algorithm sorts models in descending order by their request-rate-to-SLO ratio and assigns each to the GPU with the lowest current ratio of accumulated load to remaining memory.
- **Performance**: The solution performed effectively, achieving a combined score of 21.89 and a 100% success rate with negligible execution time.
- **Feedback**: Prioritizing models with high request density and balancing the load-to-space ratio proved to be a robust heuristic for minimizing maximum KV cache pressure without complex optimization.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Binary Search with Dynamic Linearized Sorting Key**
- **Implementation**: Uses binary search on the target pressure ratio, validating feasibility via First-Fit Decreasing sorted by a dynamic key ($Weight + K \times Size$) representing the linearized capacity constraint.
- **Performance**: Achieved a strong score of 26.23 with 100% success rate and 0.001s execution time.
- **Feedback**: The linearized sorting metric effectively adapts the heuristic to prioritize either model size or request load based on the current pressure target, yielding optimal placements efficiently.
**Program Identifier:** Generation 1 - Patch Name parametric_kvpr_search - Correct Program: True

**Program Name: Greedy Size-Density Sorted Model Placement**
- **Implementation**: The algorithm sorts models by size and request density in descending order, then greedily assigns each model to the GPU that results in the lowest local KV cache pressure after placement.
- **Performance**: The approach achieved a combined score of 20.43 with a 100% success rate, indicating strong optimization of memory pressure.
- **Feedback**: Prioritizing large, dense models prevents resource fragmentation, and the lookahead strategy for calculating resulting pressure ensures a balanced distribution of load across GPUs.
**Program Identifier:** Generation 2 - Patch Name greedy_post_placement_min_kvpr - Correct Program: True

**Program Name: Binary Search with Multi-Heuristic Bin Packing**
- **Implementation**: The algorithm minimizes maximum KV cache pressure using binary search on the target pressure value, checking feasibility via three bin packing strategies: Best Fit and First Fit on items sorted by dynamic weight ($w + K \cdot s$), and Best Fit on size-sorted items.
- **Performance**: It achieved a strong combined score of 26.23 (max KVPR 25.233) with a 100% success rate and negligible execution time (0.001s).
- **Feedback**: Employing diverse sorting and packing heuristics within the binary search allows the solver to adapt to different data distributions, effectively balancing load and escaping local optima common in single-heuristic greedy approaches.
**Program Identifier:** Generation 3 - Patch Name improved_bin_packing_heuristics - Correct Program: True

**Program Name: Hybrid Greedy and Binary Search Best-Fit Decreasing Algorithm**
- **Implementation**: This solution employs a dual strategy: a greedy heuristic that locally minimizes immediate cache pressure, and a global optimization method that uses binary search to linearize the non-linear objective function into a Best-Fit Decreasing bin packing problem.
- **Performance**: The algorithm achieved a high combined score of 26.23 with a 100% success rate and negligible execution time (0.001s).
- **Feedback**: The approach effectively solves the fractional minimization problem by transforming it into a linear constraint (`weight + K * size`), allowing standard bin packing heuristics to find near-optimal distributions where simple greedy methods might fail.
**Program Identifier:** Generation 4 - Patch Name hybrid_kvpr_optimizer - Correct Program: True

**Program Name: Greedy KVPR Minimization with Traffic Density Sorting**
- **Implementation**: The algorithm sorts models by `req_rate/slo` descending and assigns each to the GPU that results in the minimum local KV cache pressure ratio.
- **Performance**: Achieved a combined score of 22.67 with a 100% success rate and fast execution.
- **Feedback**: Sorting by request density ensures high-load models are distributed early, while the local minimization step effectively balances pressure across available resources.
**Program Identifier:** Generation 5 - Patch Name improved_greedy_placement - Correct Program: True

**Program Name:** Ensemble Greedy Heuristics for KV Cache Pressure Minimization
- **Implementation:** The algorithm executes four distinct greedy heuristics—sorting by load, size, or isolated pressure and targeting minimal current or resulting pressure—and selects the final placement that minimizes the maximum KV pressure across all GPUs.
- **Performance:** It achieved a strong combined score of 23.48 with a 100% success rate and negligible execution time.
- **Feedback:** The ensemble approach proves highly effective for this non-linear packing problem, as different heuristics (like prioritizing model size vs. request load) outperform each other depending on the specific input distribution.
**Program Identifier:** Generation 6 - Patch Name ensemble_greedy_placement - Correct Program: True

**Program Name: Ensemble Greedy Heuristics with Multiple Sorting Keys**
- **Implementation**: The algorithm tests four different greedy strategies, sorting models by weight, size, isolated pressure, and density, then assigning them to the GPU that minimizes immediate KV cache pressure. It evaluates the resulting global maximum KVPR for each strategy and returns the optimal placement configuration.
- **Performance**: The solution achieved a high combined score of 23.69 with a 100% success rate and negligible execution time.
- **Feedback**: Using an ensemble of sorting heuristics allows the algorithm to adapt to diverse model distributions, avoiding the pitfalls of a single greedy approach. This method robustly balances memory constraints against request load to effectively minimize the system-wide maximum KVPR.
**Program Identifier:** Generation 7 - Patch Name ensemble_greedy_placement - Correct Program: True

**Program Name: Binary Search with Multi-Strategy Best Fit Packing**
- **Implementation**: The algorithm minimizes maximum KV cache pressure by binary searching for a target threshold, validating feasibility via a Best Fit packing routine that rotates through multiple sorting heuristics (e.g., weighted sum, size) and randomized trials.
- **Performance**: It delivers a strong combined score of 26.26 with a perfect success rate and minimal execution overhead (0.097s).
- **Feedback**: By transforming the non-linear KVPR constraint into a linear packing problem with dynamic item weights, the approach efficiently approximates the optimal distribution, while randomized shuffling ensures robustness when deterministic heuristics fail.
**Program Identifier:** Generation 8 - Patch Name improved_heuristics_and_search - Correct Program: True

**Program Name: Hybrid Greedy and Binary Search with Local Refinement**
- **Implementation**: Utilizes a hybrid approach combining multiple greedy heuristics and binary search on KVPR targets to generate candidates, followed by local search refinement using moves and swaps to relieve the bottleneck GPU.
- **Performance**: Achieved a high combined score of 26.23 with a perfect success rate and minimal execution time (0.001s).
- **Feedback**: The strategy of diversifying initial candidates followed by targeted local optimization proves highly effective for minimizing peak memory pressure without compromising speed.
**Program Identifier:** Generation 9 - Patch Name refined_placement_heuristics_local_search - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

## Successful Algorithmic Patterns
- **Linearization of Non-Linear Constraints**: The most impactful pattern was transforming the non-linear KV-Cache pressure objective ($Weight / (Capacity - Size) \le K$) into a linear bin-packing constraint ($Weight + K \times Size \le K \times Capacity$). Programs utilizing this transformation (Generation 1, 3, 4, 8, 9) consistently achieved scores above 26.2, while greedy approaches struggled to pass 23.7.
- **Binary Search on Efficiency Targets**: Instead of constructing a solution directly, the top programs (e.g., Generation 1, 8) use binary search to propose a target pressure value ($K$) and treat the placement as a feasibility problem. This converts an optimization problem into a series of easier decision problems.
- **Randomized Heuristic Trials**: The **Current Best Program (Generation 8)** surpassed the performance ceiling of 26.23 (held by Gen 1, 3, 4, 9) by reaching 26.26. It achieved this by incorporating a fallback mechanism that attempts 50 randomized item orderings if deterministic sorting strategies fail to find a valid packing for a given target $K$.
- **Dynamic Sorting Keys**: The best implementations dynamically adjust item priorities based on the current binary search target. Sorting by $Weight + K \times Size$ allows the algorithm to pivot between prioritizing large models (when space is tight) and heavy-load models (when pressure is high) within the same execution.

## Ineffective Approaches
- **Pure Greedy Construction**: Programs relying solely on one-pass greedy assignments (Generation 0, 2, 5) consistently underperformed, achieving scores between 20.43 and 22.67. Without the ability to backtrack or adjust a global target, these methods essentially get trapped in local optima.
- **Static Lookahead Metrics**: Generation 2 tried to minimize the "resulting local pressure" after each placement but scored poorly (20.43). This suggests that optimizing for the immediate local minimum often leads to resource fragmentation that prevents placing difficult items later.
- **Local Search Refinement**: Generation 9 attempted to improve placements using local moves and swaps but failed to improve upon the baseline binary search score of 26.23. The tight coupling of constraints in this bin-packing-like problem makes simple local swaps ineffective for escaping dense packing configurations.

## Implementation Insights
- **Robust Feasibility Checking**: The **Current Best Program (Generation 8)** implements a `check_placement` function that is highly robust. It iterates through multiple deterministic sorting strategies (Dynamic Linear Weight, Size, Weight, Density) and, crucially, follows up with randomized shuffling. This ensures that the feasibility check is not defeated by specific pathological input orderings.
- **Best-Fit Bin Packing Logic**: The top program employs a "Best Fit" strategy within its feasibility check, assigning items to the GPU that maximizes the utilization of the linearized capacity ($NewWeight + K \times NewSize$). This specific heuristic tends to leave larger, coherent gaps for subsequent items compared to First-Fit.
- **Safe Floating Point Comparisons**: The implementation avoids division-by-zero errors by checking `new_w > k_target * rem_mem` rather than computing the ratio directly. This allows the algorithm to handle cases where remaining memory approaches zero gracefully.
- **Search Bound Refinement**: The best program optimizes the binary search by updating the upper bound (`high`) not just to the tested `mid` value, but to the *actual* maximum KVPR calculated from the successful placement. This accelerates convergence toward the true optimal $K$.

## Performance Analysis
- **Algorithmic Tier Separation**: There is a distinct performance gap between constructive greedy algorithms (max score ~23.69, Gen 7) and Binary Search + Bin Packing algorithms (min score ~26.23, Gen 1). This confirms that the global target search structure is fundamentally superior for this problem class.
- **The "Randomization Gap"**: Generations 1, 3, 4, and 9 all converged to a score of 26.23, suggesting a "deterministic limit" for the standard heuristics on this dataset. Generation 8 broke this limit (26.26) solely by adding randomization, indicating that the remaining optimization gains lie in handling edge-case distributions that defy standard sorting logic.
- **Efficiency of Search**: Despite wrapping an $O(N)$ or $O(N \log N)$ packing routine inside a binary search loop (30 iterations) and including randomized trials, the execution time for the best program remained negligible (0.097s). This confirms that high-iteration search approaches are computationally viable for this problem size.
- **Ensemble Limitations**: While Generation 7 used an ensemble of four greedy heuristics to achieve the best "Greedy" score (23.69), it was still significantly outperformed by the simplest Binary Search implementation (Gen 1, 26.23). This highlights that structural improvements (Search vs. Greedy) outweigh heuristic variety.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

Based on the analysis of the current best program (Generation 8) and global insights, here are 5 actionable recommendations for future mutations:

1.  **Implement Beam Search for Placement Construction**
    Instead of a single-path greedy assignment within `try_pack`, implement a Beam Search with a small width (e.g., 3-5). By maintaining multiple partial placement states and expanding the most promising ones (based on metrics like least remaining linearized capacity), the algorithm can avoid early greedy mistakes that lead to dead ends, potentially finding valid packings for tighter $K$ targets than greedy or random shuffling alone.

2.  **Utilize "Noisy Sorting" Instead of Pure Random Shuffling**
    Refine the randomization strategy by adding small perturbations to the deterministic sort keys (e.g., $Key \times \text{random}(0.95, 1.05)$) rather than using full random shuffling. This preserves the effective "difficult items first" heuristic structure—which is proven to work well—while introducing enough variance to break pathological ties and escape local optima that block deterministic approaches.

3.  **Integrate Failure-Driven Swapping (Repair Logic)**
    Enhance the feasibility check with a repair mechanism: if an item fails to fit in any GPU, attempt to find a *single* item already placed on a GPU that, if removed, creates enough space for the current item. Perform the swap only if the displaced item can be successfully re-placed on another GPU. This simple 1-step backtracking handles fragmentation issues without the complexity of full local search.

4.  **Perform Post-Placement Load Balancing**
    After `check_placement` finds a valid configuration for a target $K$, execute a quick optimization pass that tries to move items from the GPU with the highest KVPR to GPUs with spare capacity. By lowering the *actual* maximum KVPR of the valid solution, the binary search can update its upper bound (`high`) more aggressively, accelerating convergence toward the true global minimum.

5.  **Calculate Theoretical Lower Bounds for Search Initialization**
    Initialize the binary search `low` bound using the theoretical minimum pressure derived from aggregate system resources: $K_{min} = \sum (\text{req/slo}) / (\text{Total Capacity} - \text{Total Size})$. Starting the search with a tighter [low, high] interval allows the fixed iteration budget (30 steps) to achieve higher precision in the critical region where the optimal solution lies.