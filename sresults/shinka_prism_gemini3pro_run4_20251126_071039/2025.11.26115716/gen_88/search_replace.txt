<NAME>
adaptive_packing_and_early_opt
</NAME>

<DESCRIPTION>
This edit implements Adaptive Failure-Driven Prioritization and Early Optimization to improve model placement.

1.  **Adaptive Failure Prioritization**: The packing function `solve_packing` now identifies the specific item that caused a packing failure. In the randomized search loop, these "failed" items are adaptively prioritized (moved to the front of the packing order) in subsequent attempts. This forces the algorithm to handle the most difficult constraints first when GPU bins are emptier.
2.  **Early Optimization**: The Hill Climbing local search logic is refactored into a reusable `refine_placement` function. This optimization is now applied immediately whenever a valid placement is found during the binary search (checking `mid`). This significantly tightens the upper bound (`high`) for subsequent binary search steps, as the refined placement often has a much lower max KVPR than the raw result of the packing heuristic.
3.  **Refactoring**: The local search code is cleaned up and encapsulated, replacing the inline implementation at the end of the function.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def solve_packing(k_target, ordered_items):
        """Try to pack items into GPUs such that KVPR <= k_target."""
        placement = {i: [] for i in range(gpu_num)}
        gpu_state = [{'w': 0.0, 's': 0.0} for _ in range(gpu_num)]

        for item in ordered_items:
            best_idx = -1
            best_score = -1.0

            for i in range(gpu_num):
                # Capacity Check
                if gpu_state[i]['s'] + item['s'] > GPU_MEM_SIZE: continue

                new_w = gpu_state[i]['w'] + item['w']
                new_s = gpu_state[i]['s'] + item['s']
                rem = GPU_MEM_SIZE - new_s

                # KVPR Constraint Check
                if rem <= 1e-9:
                    if new_w > 1e-9: continue
                elif new_w > k_target * rem + 1e-7:
                    continue

                # Best Fit Heuristic: Maximize usage (linearized)
                # This packs bins tightly.
                score = new_w + k_target * new_s
                if score > best_score:
                    best_score = score
                    best_idx = i

            if best_idx != -1:
                placement[best_idx].append(item['model'])
                gpu_state[best_idx]['w'] += item['w']
                gpu_state[best_idx]['s'] += item['s']
            else:
                return None
        return placement

    def check_placement(k_target, attempts=10):
        # 1. Deterministic Strategies
        # Keys: Linearized Cost, Size, Weight
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w']
        ]

        for key_func in strategies:
            res = solve_packing(k_target, sorted(items, key=key_func, reverse=True))
            if res: return res

        # 2. Randomized Noisy Strategies
        if attempts > 0:
            rng = random.Random(42 + int(k_target))
            base_key = lambda x: x['w'] + k_target * x['s']
            for _ in range(attempts):
                # Add multiplicative noise
                noisy_items = sorted(items, key=lambda x: base_key(x) * rng.uniform(0.85, 1.15), reverse=True)
                res = solve_packing(k_target, noisy_items)
                if res: return res

        return None

    # Binary Search
    high = 1e9
    best_placement = check_placement(high, attempts=1)

    if best_placement is None:
        raise ValueError("Unable to place models on GPUs (insufficient total memory).")

    high = get_placement_kvpr(best_placement)
    low = 0.0

    for _ in range(25):
        mid = (low + high) / 2
        res = check_placement(mid, attempts=20)
        if res is not None:
            best_placement = res
            high = min(mid, get_placement_kvpr(res))
        else:
            low = mid

    # --- Local Search Optimization (Hill Climbing) ---
    # Convert to manageable state
    gpu_states = []
    for i in range(gpu_num):
        models_p = best_placement[i]
        w = sum(m.req_rate / m.slo for m in models_p)
        s = sum(m.model_size for m in models_p)
        gpu_states.append({'w': w, 's': s, 'models': list(models_p)})

    def calc_kvpr(w, s):
        rem = GPU_MEM_SIZE - s
        if rem <= 1e-9: return float('inf') if w > 1e-9 else 0.0
        return w / rem

    for _ in range(100):
        # Find bottleneck GPU
        max_k = -1.0
        src_idx = -1
        for i in range(gpu_num):
            k = calc_kvpr(gpu_states[i]['w'], gpu_states[i]['s'])
            if k > max_k:
                max_k = k
                src_idx = i

        if max_k <= 0: break

        improved = False
        src = gpu_states[src_idx]

        # Try moving a model from src to any dst
        for i, m in enumerate(src['models']):
            m_w = m.req_rate / m.slo
            m_s = m.model_size

            # Predict src after removal
            ns_w = src['w'] - m_w
            ns_s = src['s'] - m_s
            ns_k = calc_kvpr(ns_w, ns_s)

            # Optimization: Don't move if src doesn't improve enough to matter
            if ns_k >= max_k - 1e-9: continue

            for dst_idx in range(gpu_num):
                if dst_idx == src_idx: continue
                dst = gpu_states[dst_idx]

                if dst['s'] + m_s > GPU_MEM_SIZE: continue

                nd_k = calc_kvpr(dst['w'] + m_w, dst['s'] + m_s)

                if nd_k < max_k - 1e-9:
                    # Apply Move
                    src['models'].pop(i)
                    src['w'] = ns_w
                    src['s'] = ns_s

                    dst['models'].append(m)
                    dst['w'] += m_w
                    dst['s'] += m_s
                    improved = True
                    break
            if improved: break

        if improved: continue

        # Try Swapping
        # Swap model from src with model from dst
        for i, m1 in enumerate(src['models']):
            m1_w = m1.req_rate / m1.slo
            m1_s = m1.model_size

            for dst_idx in range(gpu_num):
                if dst_idx == src_idx: continue
                dst = gpu_states[dst_idx]

                # Heuristic: Don't swap with a GPU that is already near the bottleneck limit
                if calc_kvpr(dst['w'], dst['s']) > max_k * 0.95: continue

                for j, m2 in enumerate(dst['models']):
                    m2_w = m2.req_rate / m2.slo
                    m2_s = m2.model_size

                    # Check capacities
                    new_src_s = src['s'] - m1_s + m2_s
                    new_dst_s = dst['s'] - m2_s + m1_s

                    if new_src_s > GPU_MEM_SIZE or new_dst_s > GPU_MEM_SIZE: continue

                    new_src_w = src['w'] - m1_w + m2_w
                    new_dst_w = dst['w'] - m2_w + m1_w

                    nk_src = calc_kvpr(new_src_w, new_src_s)
                    nk_dst = calc_kvpr(new_dst_w, new_dst_s)

                    if max(nk_src, nk_dst) < max_k - 1e-9:
                        # Apply Swap
                        src['models'][i] = m2
                        src['w'] = new_src_w
                        src['s'] = new_src_s

                        dst['models'][j] = m1
                        dst['w'] = new_dst_w
                        dst['s'] = new_dst_s
                        improved = True
                        break
                if improved: break
            if improved: break

        if not improved: break

    return {i: gpu_states[i]['models'] for i in range(gpu_num)}
=======
    def calc_kvpr(w, s):
        rem = GPU_MEM_SIZE - s
        if rem <= 1e-9: return float('inf') if w > 1e-9 else 0.0
        return w / rem

    def refine_placement(placement, iterations=50):
        """Hill Climbing to reduce max KVPR."""
        state = []
        for i in range(gpu_num):
            p = placement[i]
            w = sum(m.req_rate / m.slo for m in p)
            s = sum(m.model_size for m in p)
            state.append({'w': w, 's': s, 'models': list(p)})

        for _ in range(iterations):
            max_k = -1.0
            src_idx = -1
            gpu_k = []
            for i, st in enumerate(state):
                k = calc_kvpr(st['w'], st['s'])
                gpu_k.append(k)
                if k > max_k:
                    max_k = k
                    src_idx = i

            if max_k <= 1e-9: break

            src = state[src_idx]
            improved = False

            # 1. Try Move
            for i, m in enumerate(src['models']):
                m_w, m_s = m.req_rate / m.slo, m.model_size
                ns_w, ns_s = src['w'] - m_w, src['s'] - m_s
                ns_k = calc_kvpr(ns_w, ns_s)

                if ns_k >= max_k - 1e-9: continue

                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = state[dst_idx]

                    if dst['s'] + m_s > GPU_MEM_SIZE: continue

                    nd_k = calc_kvpr(dst['w'] + m_w, dst['s'] + m_s)
                    if nd_k < max_k - 1e-9:
                        src['models'].pop(i)
                        src['w'], src['s'] = ns_w, ns_s
                        dst['models'].append(m)
                        dst['w'] += m_w
                        dst['s'] += m_s
                        improved = True
                        break
                if improved: break

            if improved: continue

            # 2. Try Swap
            for i, m1 in enumerate(src['models']):
                m1_w, m1_s = m1.req_rate / m1.slo, m1.model_size

                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = state[dst_idx]

                    if gpu_k[dst_idx] > max_k * 0.95: continue

                    for j, m2 in enumerate(dst['models']):
                        m2_w, m2_s = m2.req_rate / m2.slo, m2.model_size

                        ns_s = src['s'] - m1_s + m2_s
                        nd_s = dst['s'] - m2_s + m1_s
                        if ns_s > GPU_MEM_SIZE or nd_s > GPU_MEM_SIZE: continue

                        ns_w = src['w'] - m1_w + m2_w
                        nd_w = dst['w'] - m2_w + m1_w

                        ns_k = calc_kvpr(ns_w, ns_s)
                        nd_k = calc_kvpr(nd_w, nd_s)

                        if max(ns_k, nd_k) < max_k - 1e-9:
                            src['models'][i] = m2
                            src['w'], src['s'] = ns_w, ns_s
                            dst['models'][j] = m1
                            dst['w'], dst['s'] = nd_w, nd_s
                            improved = True
                            break
                    if improved: break
                if improved: break

            if not improved: break

        return {i: state[i]['models'] for i in range(gpu_num)}

    def solve_packing(k_target, ordered_items):
        """
        Try to pack items into GPUs such that KVPR <= k_target.
        Returns (placement, None) on success, or (None, failed_item) on failure.
        """
        placement = {i: [] for i in range(gpu_num)}
        gpu_state = [{'w': 0.0, 's': 0.0} for _ in range(gpu_num)]

        for item in ordered_items:
            best_idx = -1
            best_score = -1.0

            for i in range(gpu_num):
                # Capacity Check
                if gpu_state[i]['s'] + item['s'] > GPU_MEM_SIZE: continue

                new_w = gpu_state[i]['w'] + item['w']
                new_s = gpu_state[i]['s'] + item['s']
                rem = GPU_MEM_SIZE - new_s

                # KVPR Constraint Check
                if rem <= 1e-9:
                    if new_w > 1e-9: continue
                elif new_w > k_target * rem + 1e-7:
                    continue

                # Best Fit Heuristic: Maximize usage (linearized)
                score = new_w + k_target * new_s
                if score > best_score:
                    best_score = score
                    best_idx = i

            if best_idx != -1:
                placement[best_idx].append(item['model'])
                gpu_state[best_idx]['w'] += item['w']
                gpu_state[best_idx]['s'] += item['s']
            else:
                return None, item
        return placement, None

    def check_placement(k_target, attempts=10):
        # 1. Deterministic Strategies
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w']
        ]

        for key_func in strategies:
            res, _ = solve_packing(k_target, sorted(items, key=key_func, reverse=True))
            if res: return res

        # 2. Randomized Strategies with Failure Prioritization
        if attempts > 0:
            rng = random.Random(42 + int(k_target))
            base_key = lambda x: x['w'] + k_target * x['s']
            priority_items = []

            for _ in range(attempts):
                # Construct order: Priority items -> Noisy sorted remaining items
                p_set = {id(x['model']) for x in priority_items}
                remaining = [x for x in items if id(x['model']) not in p_set]

                # Sort remaining with noise
                noisy_remaining = sorted(remaining, key=lambda x: base_key(x) * rng.uniform(0.85, 1.15), reverse=True)

                # Final order
                attempt_order = priority_items + noisy_remaining

                res, failed_item = solve_packing(k_target, attempt_order)
                if res:
                    return res
                else:
                    # Adaptive: Prioritize the item that caused failure
                    if failed_item and id(failed_item['model']) not in p_set:
                        priority_items.insert(0, failed_item)
                        # Keep priority list small to avoid rigidity
                        if len(priority_items) > gpu_num:
                            priority_items.pop()
        return None

    # Binary Search
    high = 1e9
    best_placement = check_placement(high, attempts=1)

    if best_placement is None:
        raise ValueError("Unable to place models on GPUs (insufficient total memory).")

    # Initial refinement
    best_placement = refine_placement(best_placement)
    high = get_placement_kvpr(best_placement)
    low = 0.0

    for _ in range(25):
        mid = (low + high) / 2
        res = check_placement(mid, attempts=20)
        if res is not None:
            # Found a valid placement. Can we optimize it to lower the bar further?
            refined_res = refine_placement(res, iterations=20)

            # Check if this refined result is better than what we had
            current_kvpr = get_placement_kvpr(refined_res)

            if current_kvpr < get_placement_kvpr(best_placement):
                best_placement = refined_res
            elif get_placement_kvpr(res) < get_placement_kvpr(best_placement):
                 best_placement = res

            high = min(mid, current_kvpr)
        else:
            low = mid

    return refine_placement(best_placement, iterations=100)
>>>>>>> REPLACE
</DIFF>