<NAME>
beam_search_packing
</NAME>

<DESCRIPTION>
Replaces the single-path greedy packing in the binary search check with a Beam Search approach (width 4-8). This maintains multiple candidate placement states, allowing the algorithm to navigate through local optima that deterministic greedy strategies might miss. The scoring function (sum of squares of loads) encourages tight packing (Best Fit behavior), helping to satisfy capacity constraints more effectively at tighter KVPR targets.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Strategy 2: Binary Search with Best-Fit Decreasing ---
    items = [{'m': m, 'w': m.req_rate/m.slo, 's': m.model_size} for m in models]

    def check_bs(k_target):
        # Sort by linear cost: w + k * s
        sorted_items = sorted(items, key=lambda x: x['w'] + k_target * x['s'], reverse=True)
        pl = {i: [] for i in range(gpu_num)}
        load = [{'w': 0.0, 's': 0.0, 'lin': 0.0} for _ in range(gpu_num)]

        for item in sorted_items:
            best_idx = -1
            best_lin = -1.0

            for i in range(gpu_num):
                new_s = load[i]['s'] + item['s']
                if new_s > GPU_MEM_SIZE: continue

                new_w = load[i]['w'] + item['w']
                rem = GPU_MEM_SIZE - new_s

                # KVPR constraint: w <= k * rem
                if rem <= 1e-9:
                    if new_w > 1e-9: continue
                elif new_w > k_target * rem + 1e-7:
                    continue

                # Best Fit: Maximize current linear load (tightest fit)
                curr_lin = load[i]['lin']
                if curr_lin > best_lin:
                    best_lin = curr_lin
                    best_idx = i

            if best_idx == -1: return None
            pl[best_idx].append(item['m'])
            load[best_idx]['s'] += item['s']
            load[best_idx]['w'] += item['w']
            load[best_idx]['lin'] += item['w'] + k_target * item['s']

        return pl

    low, high = 0.0, 1e9
    # Initialization
    bs_pl = check_bs(high)
    if bs_pl:
        high = evaluate_placement(bs_pl)
        if high == float('inf'): high = 1e9

        for _ in range(25):
            mid = (low + high) / 2
            res = check_bs(mid)
            if res:
                bs_pl = res
                high = mid
            else:
                low = mid
        candidates.append(bs_pl)
=======
    # --- Strategy 2: Binary Search with Beam Search ---
    items = [{'m': m, 'w': m.req_rate/m.slo, 's': m.model_size} for m in models]

    def check_bs(k_target, beam_width=4):
        # Sort by linear cost: w + k * s
        sorted_indices = sorted(range(len(items)), key=lambda i: items[i]['w'] + k_target * items[i]['s'], reverse=True)
        limit_val = k_target * GPU_MEM_SIZE

        # State: {'loads': [{'w', 's', 'lin'}], 'assign': [[idx]], 'score': float}
        initial_loads = [{'w': 0.0, 's': 0.0, 'lin': 0.0} for _ in range(gpu_num)]
        initial_assign = [[] for _ in range(gpu_num)]
        beam = [{'loads': initial_loads, 'assign': initial_assign, 'score': 0.0}]

        for item_idx in sorted_indices:
            item = items[item_idx]
            w, s = item['w'], item['s']
            lin_cost = w + k_target * s

            candidates = []

            for state in beam:
                tried_empty = False
                for i in range(gpu_num):
                    b = state['loads'][i]

                    # Symmetry breaking for empty bins
                    if b['s'] == 0 and b['w'] == 0:
                        if tried_empty: continue
                        tried_empty = True

                    if b['s'] + s > GPU_MEM_SIZE: continue
                    new_lin = b['lin'] + lin_cost
                    if new_lin > limit_val + 1e-5: continue

                    # Create new state
                    new_loads = [x.copy() for x in state['loads']]
                    new_loads[i]['w'] += w
                    new_loads[i]['s'] += s
                    new_loads[i]['lin'] = new_lin

                    new_assign = [x[:] for x in state['assign']]
                    new_assign[i].append(item_idx)

                    # Best Fit Heuristic: Maximize sum of squares of loads
                    new_score = state['score'] - (b['lin']**2) + (new_lin**2)

                    candidates.append({'loads': new_loads, 'assign': new_assign, 'score': new_score})

            if not candidates:
                return None

            # Prune beam
            candidates.sort(key=lambda x: x['score'], reverse=True)
            beam = candidates[:beam_width]

        best_state = beam[0]
        return {i: [items[idx]['m'] for idx in best_state['assign'][i]] for i in range(gpu_num)}

    low, high = 0.0, 1e9
    # Initialization with wider beam
    bs_pl = check_bs(high, beam_width=8)
    if bs_pl:
        high = evaluate_placement(bs_pl)
        if high == float('inf'): high = 1e9

        for _ in range(25):
            mid = (low + high) / 2
            # Use beam_width=4 for speed in loop
            res = check_bs(mid, beam_width=4)
            if res:
                bs_pl = res
                high = min(mid, evaluate_placement(res))
            else:
                low = mid
        candidates.append(bs_pl)
>>>>>>> REPLACE
</DIFF>