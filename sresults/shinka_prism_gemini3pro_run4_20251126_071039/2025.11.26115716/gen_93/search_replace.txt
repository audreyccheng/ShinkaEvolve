<NAME>
steepest_descent_refinement
</NAME>

<DESCRIPTION>
Implements "Refine Solutions via Steepest Descent" by introducing an internal `refine_solution` function that performs local search (Move and Swap) to minimize max KVPR. This function is applied:
1. Immediately upon finding a feasible packing in the Binary Search loop. This lowers the actual max pressure found, allowing the binary search upper bound (`high`) to be updated to `min(mid, actual_score)`, drastically accelerating convergence.
2. As a final optimization step, replacing the verbose inline local search code.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # ---------------------------------------------------------
    # 2. Binary Search on Target KVPR (Transformation to Bin Packing)
    # ---------------------------------------------------------
    # Problem: Minimize K such that sum(w_i)/ (C - sum(s_i)) <= K
    # Equivalent to Bin Packing with item size v_i(K) = s_i + w_i/K, bin capacity C.

    total_w = sum(m.req_rate / m.slo for m in models)
    total_s = sum(m.model_size for m in models)
    rem_global = gpu_num * GPU_MEM_SIZE - total_s

    # Theoretical lower bound: Average case fluid distribution
    if rem_global > 1e-6:
        low = total_w / rem_global
        high = best_score if best_score != float('inf') else 1000.0

        if high > low + 1e-4:
            for _ in range(20):
                mid = (low + high) / 2

                # Randomized Best Fit Decreasing Check with Failure Memory
                found_placement = None
                failed_items = set()

                # Strategy pool for sorting models
                strategies = [
                    (lambda m: m.model_size + (m.req_rate / m.slo) / mid, 'Effective'),
                    (lambda m: m.model_size, 'Physical'),
                    (lambda m: m.req_rate / m.slo, 'Weight'),
                    (lambda m: (m.req_rate / m.slo) / (m.model_size + 1e-6), 'Density')
                ]

                for attempt in range(32):
                    # Cycle through strategies
                    base_key, _ = strategies[attempt % len(strategies)]

                    # Adaptive Noise
                    noise = 0.0
                    if attempt >= 4:
                        noise = 0.01 + (attempt * 0.002)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Failure memory boost
                        if id(m) in failed_items:
                            val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)

                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        min_rem_eff = float('inf')

                        # Best Fit on Effective Capacity
                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue

                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)
                                if rem_eff < min_rem_eff:
                                    min_rem_eff = rem_eff
                                    best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s

                    if possible_k:
                        found_placement = temp_placement
                        break
                    else:
                        if first_fail_model:
                            failed_items.add(id(first_fail_model))

                if found_placement:
                    actual_score = get_max_kvpr(found_placement)
                    if actual_score < best_score:
                        best_score = actual_score
                        best_placement = found_placement
                    high = mid
                else:
                    low = mid
=======
    # ---------------------------------------------------------
    # 2. Binary Search on Target KVPR (Transformation to Bin Packing)
    # ---------------------------------------------------------
    # Problem: Minimize K such that sum(w_i)/ (C - sum(s_i)) <= K
    # Equivalent to Bin Packing with item size v_i(K) = s_i + w_i/K, bin capacity C.

    total_w = sum(m.req_rate / m.slo for m in models)
    total_s = sum(m.model_size for m in models)
    rem_global = gpu_num * GPU_MEM_SIZE - total_s

    def refine_solution(placement, iterations=20):
        """Optimizes placement via steepest descent Move/Swap."""
        # Setup working stats
        g_map = {}
        for g, m_list in placement.items():
            w_sum = sum(m.req_rate / m.slo for m in m_list)
            s_sum = sum(m.model_size for m in m_list)
            g_map[g] = {'models': list(m_list), 'w': w_sum, 's': s_sum}

        for _ in range(iterations):
            # Identify Bottleneck
            max_p = -1.0
            src = -1
            for g in range(gpu_num):
                rem = GPU_MEM_SIZE - g_map[g]['s']
                p = g_map[g]['w'] / rem if rem > 1e-9 else float('inf')
                if p > max_p:
                    max_p = p
                    src = g

            if src == -1 or max_p < 1e-9: break

            improved = False
            src_models = g_map[src]['models']

            # 1. Try MOVE (Best Fit)
            for i, m in enumerate(src_models):
                w, s = m.req_rate / m.slo, m.model_size

                best_dst = None
                best_dst_p = float('inf')

                for dst in range(gpu_num):
                    if dst == src: continue
                    dst_stats = g_map[dst]
                    if dst_stats['s'] + s > GPU_MEM_SIZE: continue

                    dst_rem = GPU_MEM_SIZE - (dst_stats['s'] + s)
                    if dst_rem <= 1e-9: continue
                    new_dst_p = (dst_stats['w'] + w) / dst_rem

                    if new_dst_p < max_p - 1e-5:
                        if new_dst_p < best_dst_p:
                            best_dst_p = new_dst_p
                            best_dst = dst

                if best_dst is not None:
                    moved = src_models.pop(i)
                    g_map[src]['w'] -= w
                    g_map[src]['s'] -= s
                    g_map[best_dst]['models'].append(moved)
                    g_map[best_dst]['w'] += w
                    g_map[best_dst]['s'] += s
                    improved = True
                    break

            if improved: continue

            # 2. Try SWAP (First Improvement)
            for i, m_src in enumerate(src_models):
                w_src, s_src = m_src.req_rate / m_src.slo, m_src.model_size

                for dst in range(gpu_num):
                    if dst == src: continue
                    dst_models = g_map[dst]['models']

                    for j, m_dst in enumerate(dst_models):
                        w_dst, s_dst = m_dst.req_rate / m_dst.slo, m_dst.model_size

                        # Check Capacity
                        new_src_s = g_map[src]['s'] - s_src + s_dst
                        if new_src_s > GPU_MEM_SIZE: continue
                        new_dst_s = g_map[dst]['s'] - s_dst + s_src
                        if new_dst_s > GPU_MEM_SIZE: continue

                        # Check Pressure
                        rem_src = GPU_MEM_SIZE - new_src_s
                        if rem_src <= 1e-9: continue
                        p_src = (g_map[src]['w'] - w_src + w_dst) / rem_src

                        rem_dst = GPU_MEM_SIZE - new_dst_s
                        if rem_dst <= 1e-9: continue
                        p_dst = (g_map[dst]['w'] - w_dst + w_src) / rem_dst

                        if max(p_src, p_dst) < max_p - 1e-5:
                            # Swap
                            src_models[i] = m_dst
                            dst_models[j] = m_src
                            g_map[src]['w'] += (w_dst - w_src)
                            g_map[src]['s'] += (s_dst - s_src)
                            g_map[dst]['w'] += (w_src - w_dst)
                            g_map[dst]['s'] += (s_src - s_dst)
                            improved = True
                            break
                    if improved: break
                if improved: break

            if not improved: break

        return {g: g_map[g]['models'] for g in range(gpu_num)}

    if rem_global > 1e-6:
        low = total_w / rem_global
        high = best_score if best_score != float('inf') else 2000.0

        if high > low + 1e-4:
            for _ in range(16):
                mid = (low + high) / 2

                found_placement = None
                failed_items = set()
                strategies = [
                    (lambda m: m.model_size + (m.req_rate / m.slo) / mid, 'Effective'),
                    (lambda m: m.model_size, 'Physical'),
                    (lambda m: m.req_rate / m.slo, 'Weight'),
                    (lambda m: (m.req_rate / m.slo) / (m.model_size + 1e-6), 'Density')
                ]

                for attempt in range(25):
                    base_key, _ = strategies[attempt % len(strategies)]
                    noise = 0.0
                    if attempt >= 4:
                        noise = 0.01 + (attempt * 0.003)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0: val *= random.uniform(1.0 - noise, 1.0 + noise)
                        if id(m) in failed_items: val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)
                    temp_placement = {i: [] for i in range(gpu_num)}
                    gpu_w = [0.0] * gpu_num
                    gpu_s = [0.0] * gpu_num
                    possible_k = True
                    first_fail_model = None

                    for model in bs_models:
                        w = model.req_rate / model.slo
                        s = model.model_size
                        eff = s + w/mid

                        best_idx = None
                        min_rem_eff = float('inf')

                        for i in range(gpu_num):
                            if gpu_s[i] + s > GPU_MEM_SIZE: continue
                            curr_eff = gpu_s[i] + gpu_w[i]/mid
                            if curr_eff + eff <= GPU_MEM_SIZE + 1e-6:
                                rem_eff = GPU_MEM_SIZE - (curr_eff + eff)
                                if rem_eff < min_rem_eff:
                                    min_rem_eff = rem_eff
                                    best_idx = i

                        if best_idx is None:
                            possible_k = False
                            first_fail_model = model
                            break

                        temp_placement[best_idx].append(model)
                        gpu_w[best_idx] += w
                        gpu_s[best_idx] += s

                    if possible_k:
                        found_placement = temp_placement
                        break
                    else:
                        if first_fail_model: failed_items.add(id(first_fail_model))

                if found_placement:
                    # Instant refinement
                    refined = refine_solution(found_placement, iterations=20)
                    actual_score = get_max_kvpr(refined)
                    if actual_score < best_score:
                        best_score = actual_score
                        best_placement = refined
                    high = min(mid, actual_score)
                else:
                    low = mid
>>>>>>> REPLACE
<<<<<<< SEARCH
    # ---------------------------------------------------------
    # 3. Local Search Refinement
    # ---------------------------------------------------------
    # Iteratively move models from the bottleneck GPU to others
    for _ in range(50):
        # Find bottleneck GPU
        max_p = -1.0
        src_gpu = -1
        gpu_stats = []

        for i in range(gpu_num):
            assigned = best_placement[i]
            w = sum(m.req_rate / m.slo for m in assigned)
            s = sum(m.model_size for m in assigned)
            rem = GPU_MEM_SIZE - s
            p = w / rem if rem > 1e-9 else float('inf')
            gpu_stats.append({'w': w, 's': s, 'p': p})
            if p > max_p:
                max_p = p
                src_gpu = i

        if src_gpu == -1 or max_p < 1e-9: break

        improved = False
        src_models = best_placement[src_gpu]

        # 1. Try MOVE (Src -> Dst)
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            best_dst = None
            min_dst_p = float('inf')

            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                if dst_rem <= 1e-9: continue

                dst_w = gpu_stats[dst]['w'] + w
                new_dst_p = dst_w / dst_rem

                if new_dst_p < max_p - 1e-5:
                     # Find best fit destination (lowest resulting pressure)
                     if new_dst_p < min_dst_p:
                         min_dst_p = new_dst_p
                         best_dst = dst

            if best_dst is not None:
                moved_model = src_models.pop(m_idx)
                best_placement[best_dst].append(moved_model)
                improved = True
                break

        if improved: continue

        # 2. Try SWAP (Src <-> Dst)
        for m_src_idx, m_src in enumerate(src_models):
            w_src = m_src.req_rate / m_src.slo
            s_src = m_src.model_size

            for dst in range(gpu_num):
                if dst == src_gpu: continue

                dst_models = best_placement[dst]
                for m_dst_idx, m_dst in enumerate(dst_models):
                    w_dst = m_dst.req_rate / m_dst.slo
                    s_dst = m_dst.model_size

                    # Capacity Check
                    new_src_s = gpu_stats[src_gpu]['s'] - s_src + s_dst
                    if new_src_s > GPU_MEM_SIZE: continue

                    new_dst_s = gpu_stats[dst]['s'] - s_dst + s_src
                    if new_dst_s > GPU_MEM_SIZE: continue

                    # Pressure Check
                    new_src_rem = GPU_MEM_SIZE - new_src_s
                    if new_src_rem <= 1e-9: continue
                    new_src_w = gpu_stats[src_gpu]['w'] - w_src + w_dst
                    new_src_p = new_src_w / new_src_rem

                    new_dst_rem = GPU_MEM_SIZE - new_dst_s
                    if new_dst_rem <= 1e-9: continue
                    new_dst_w = gpu_stats[dst]['w'] - w_dst + w_src
                    new_dst_p = new_dst_w / new_dst_rem

                    if max(new_src_p, new_dst_p) < max_p - 1e-5:
                        # Perform Swap
                        src_models[m_src_idx] = m_dst
                        dst_models[m_dst_idx] = m_src
                        improved = True
                        break
                if improved: break
            if improved: break

        if not improved: break

    return best_placement
=======
    # ---------------------------------------------------------
    # 3. Local Search Refinement
    # ---------------------------------------------------------
    # Final cleanup using the same refinement logic
    best_placement = refine_solution(best_placement, iterations=50)
    return best_placement
>>>>>>> REPLACE
</DIFF>