<NAME>
steepest_descent_lexicographical_v2
</NAME>

<DESCRIPTION>
I propose replacing the "First Improvement" Hill Climbing in `optimize_placement` with a **Steepest Descent** strategy using a **lexicographical objective**.
Instead of accepting the first move/swap that reduces the maximum KVPR, this approach evaluates all possible moves and swaps involving the bottleneck GPU, forms a candidate state vector of KVPRs, and selects the operation that produces the lexicographically smallest sorted KVPR vector. This ensures we not only reduce the peak load but also optimize the distribution of secondary loads, avoiding local optima where reducing the max significantly worsens the second-highest load.
Additionally, I add a `w/s` (density) sorting strategy to `check_placement` to better handle knapsack-like constraints.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def optimize_placement(placement, iterations=50):
        """Hill Climbing to reduce max KVPR of a valid placement."""
        # Convert to mutable state
        gpu_states = []
        for i in range(gpu_num):
            models_p = placement[i]
            w = sum(m.req_rate / m.slo for m in models_p)
            s = sum(m.model_size for m in models_p)
            gpu_states.append({'w': w, 's': s, 'models': list(models_p)})

        def calc_kvpr(w, s):
            rem = GPU_MEM_SIZE - s
            if rem <= 1e-9: return float('inf') if w > 1e-9 else 0.0
            return w / rem

        for _ in range(iterations):
            # Find bottleneck
            max_k = -1.0
            src_idx = -1
            gpu_ks = [] # Store K for all GPUs to use in heuristics
            for i in range(gpu_num):
                k = calc_kvpr(gpu_states[i]['w'], gpu_states[i]['s'])
                gpu_ks.append(k)
                if k > max_k:
                    max_k = k
                    src_idx = i

            if max_k <= 1e-9: break
            src = gpu_states[src_idx]
            improved = False

            # Move
            for i, m in enumerate(src['models']):
                m_w = m.req_rate / m.slo
                m_s = m.model_size
                ns_w, ns_s = src['w'] - m_w, src['s'] - m_s
                ns_k = calc_kvpr(ns_w, ns_s)

                if ns_k >= max_k - 1e-9: continue

                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = gpu_states[dst_idx]
                    if dst['s'] + m_s > GPU_MEM_SIZE: continue

                    nd_k = calc_kvpr(dst['w'] + m_w, dst['s'] + m_s)
                    if max(ns_k, nd_k) < max_k - 1e-9:
                        # Apply Move
                        src['models'].pop(i)
                        src['w'], src['s'] = ns_w, ns_s
                        dst['models'].append(m)
                        dst['w'] += m_w
                        dst['s'] += m_s
                        improved = True
                        break
                if improved: break

            if improved: continue

            # Swap
            for i, m1 in enumerate(src['models']):
                m1_w = m1.req_rate / m1.slo
                m1_s = m1.model_size

                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = gpu_states[dst_idx]
                    if gpu_ks[dst_idx] > max_k * 0.95: continue

                    for j, m2 in enumerate(dst['models']):
                        m2_w = m2.req_rate / m2.slo
                        m2_s = m2.model_size

                        ns_s = src['s'] - m1_s + m2_s
                        nd_s = dst['s'] - m2_s + m1_s
                        if ns_s > GPU_MEM_SIZE or nd_s > GPU_MEM_SIZE: continue

                        ns_w = src['w'] - m1_w + m2_w
                        nd_w = dst['w'] - m2_w + m1_w

                        ns_k = calc_kvpr(ns_w, ns_s)
                        nd_k = calc_kvpr(nd_w, nd_s)

                        if max(ns_k, nd_k) < max_k - 1e-9:
                            # Apply Swap
                            src['models'][i] = m2
                            src['w'], src['s'] = ns_w, ns_s
                            dst['models'][j] = m1
                            dst['w'], dst['s'] = nd_w, nd_s
                            improved = True
                            break
                    if improved: break
                if improved: break

            if not improved: break

        return {i: gpu_states[i]['models'] for i in range(gpu_num)}
=======
    def optimize_placement(placement, iterations=50):
        """Steepest Descent Hill Climbing with Lexicographical Objective."""
        # Convert to mutable state
        gpu_states = []
        for i in range(gpu_num):
            models_p = placement[i]
            w = sum(m.req_rate / m.slo for m in models_p)
            s = sum(m.model_size for m in models_p)
            gpu_states.append({'w': w, 's': s, 'models': list(models_p)})

        def calc_kvpr(w, s):
            rem = GPU_MEM_SIZE - s
            if rem <= 1e-9: return float('inf') if w > 1e-9 else 0.0
            return w / rem

        for _ in range(iterations):
            # Calculate current vector of loads
            current_kvprs = [calc_kvpr(g['w'], g['s']) for g in gpu_states]
            # Lexicographical minimization: sort descending and compare vectors
            best_vec = sorted(current_kvprs, reverse=True)
            max_k = best_vec[0]

            if max_k <= 1e-9: break

            # Identify bottleneck (source) - pick the one matching max_k
            src_idx = -1
            for i, k in enumerate(current_kvprs):
                if abs(k - max_k) < 1e-9:
                    src_idx = i
                    break

            src = gpu_states[src_idx]
            best_op = None # (type, arg1, arg2, arg3)

            # 1. Evaluate Moves from src
            for i, m in enumerate(src['models']):
                m_w, m_s = m.req_rate / m.slo, m.model_size
                ns_w, ns_s = src['w'] - m_w, src['s'] - m_s
                ns_k = calc_kvpr(ns_w, ns_s)

                for dst_idx in range(gpu_num):
                    if dst_idx == src_idx: continue
                    dst = gpu_states[dst_idx]
                    if dst['s'] + m_s > GPU_MEM_SIZE: continue

                    nd_w, nd_s = dst['w'] + m_w, dst['s'] + m_s
                    nd_k = calc_kvpr(nd_w, nd_s)

                    # Form candidate vector
                    cand_vec = list(current_kvprs)
                    cand_vec[src_idx] = ns_k
                    cand_vec[dst_idx] = nd_k
                    cand_vec.sort(reverse=True)

                    if cand_vec < best_vec:
                        best_vec = cand_vec
                        best_op = ('move', i, dst_idx, None)

            # 2. Evaluate Swaps with src
            # Optimization: Only consider swaps if move didn't fix things completely or for better exploration
            # Checking all swaps is expensive. Limit to swapping with non-bottleneck GPUs.
            if True:
                for i, m1 in enumerate(src['models']):
                    m1_w, m1_s = m1.req_rate / m1.slo, m1.model_size

                    for dst_idx in range(gpu_num):
                        if dst_idx == src_idx: continue
                        if current_kvprs[dst_idx] > max_k * 0.95: continue # Don't swap with other heavily loaded GPUs

                        dst = gpu_states[dst_idx]
                        for j, m2 in enumerate(dst['models']):
                            m2_w, m2_s = m2.req_rate / m2.slo, m2.model_size

                            ns_s = src['s'] - m1_s + m2_s
                            nd_s = dst['s'] - m2_s + m1_s
                            if ns_s > GPU_MEM_SIZE or nd_s > GPU_MEM_SIZE: continue

                            ns_w = src['w'] - m1_w + m2_w
                            nd_w = dst['w'] - m2_w + m1_w

                            ns_k = calc_kvpr(ns_w, ns_s)
                            nd_k = calc_kvpr(nd_w, nd_s)

                            cand_vec = list(current_kvprs)
                            cand_vec[src_idx] = ns_k
                            cand_vec[dst_idx] = nd_k
                            cand_vec.sort(reverse=True)

                            if cand_vec < best_vec:
                                best_vec = cand_vec
                                best_op = ('swap', i, dst_idx, j)

            if best_op:
                op_type, i, dst_idx, j = best_op
                dst = gpu_states[dst_idx]
                m1 = src['models'][i]

                if op_type == 'move':
                    src['models'].pop(i)
                    src['w'] -= m1.req_rate / m1.slo
                    src['s'] -= m1.model_size

                    dst['models'].append(m1)
                    dst['w'] += m1.req_rate / m1.slo
                    dst['s'] += m1.model_size

                elif op_type == 'swap':
                    m2 = dst['models'][j]
                    src['models'][i] = m2
                    src['w'] = src['w'] - (m1.req_rate / m1.slo) + (m2.req_rate / m2.slo)
                    src['s'] = src['s'] - m1.model_size + m2.model_size

                    dst['models'][j] = m1
                    dst['w'] = dst['w'] - (m2.req_rate / m2.slo) + (m1.req_rate / m1.slo)
                    dst['s'] = dst['s'] - m2.model_size + m1.model_size
            else:
                break # No improvement found

        return {i: gpu_states[i]['models'] for i in range(gpu_num)}
>>>>>>> REPLACE
<<<<<<< SEARCH
        # 1. Deterministic Strategies
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w']
        ]
=======
        # 1. Deterministic Strategies
        strategies = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w'],
            lambda x: x['w'] / (x['s'] + 1e-9)
        ]
>>>>>>> REPLACE
</DIFF>