<NAME>
adaptive_failure_set_and_iter
</NAME>

<DESCRIPTION>
1. Enhance the randomized packing phase in `check_placement` by replacing the single failure memory with a persistent `failed_items` set. This set accumulates IDs of items that cause packing failures across iterations. These items are prioritized (placed at the front, sorted by size) in subsequent attempts, allowing the algorithm to 'learn' and isolate multiple bottleneck items. A size limit prevents the set from growing too large and fixing the order rigidly.
2. Increase local search iterations in `refine_placement` from 150 to 500. Given the low execution time (0.006s), more iterations allow the Hill Climbing to find deeper local optima for the Min-Max objective.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # Optimize
        for _ in range(150):
            # Find bottleneck
=======
        # Optimize
        for _ in range(500):
            # Find bottleneck
>>>>>>> REPLACE
<<<<<<< SEARCH
        # 2. Adaptive Randomized Heuristics
        rng = random.Random(42 + int(k_target * 10))
        base_items = list(items)
        rng.shuffle(base_items)

        failed_item_id = -1

        for _ in range(40):
            # Perturb sort key
            # Base key: Linearized Cost
            # We sort items by (Cost * Noise)
            # If we have a failed item, we artificially boost its score to move it to front?
            # Or just explicitly insert at 0. Explicit insert is more reliable.

            current_items = sorted(base_items,
                                 key=lambda x: (x['w'] + k_target * x['s']) * rng.uniform(0.9, 1.1),
                                 reverse=True)

            if failed_item_id != -1:
                # Move failed item to front
                for i in range(len(current_items)):
                    if current_items[i]['id'] == failed_item_id:
                        current_items.insert(0, current_items.pop(i))
                        break

            res, fail_idx = try_pack(current_items)
            if res: return res

            if fail_idx != -1:
                failed_item_id = current_items[fail_idx]['id']
            else:
                failed_item_id = -1
=======
        # 2. Adaptive Randomized Heuristics
        rng = random.Random(42 + int(k_target * 10))
        base_items = list(items)

        failed_items = set()

        for _ in range(50):
            # Partition items into failed (priority) and others
            prio_items = []
            other_items = []

            for it in base_items:
                if it['id'] in failed_items:
                    prio_items.append(it)
                else:
                    other_items.append(it)

            # Sort priority items by Size Descending (hardest to pack first)
            prio_items.sort(key=lambda x: x['s'], reverse=True)

            # Sort others by Perturbed Linearized Cost
            other_items.sort(key=lambda x: (x['w'] + k_target * x['s']) * rng.uniform(0.85, 1.15),
                             reverse=True)

            current_items = prio_items + other_items

            res, fail_idx = try_pack(current_items)
            if res: return res

            if fail_idx != -1:
                # Add failed item to set for prioritization
                failed_id = current_items[fail_idx]['id']
                failed_items.add(failed_id)

                # Prevent set from growing too large (avoid getting stuck)
                if len(failed_items) > 6:
                    # Reset strategy if too many failures accumulate
                    failed_items = {failed_id}
>>>>>>> REPLACE
</DIFF>