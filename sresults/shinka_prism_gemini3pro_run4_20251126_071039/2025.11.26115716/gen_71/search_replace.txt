<NAME>
steepest_descent_local_search
</NAME>

<DESCRIPTION>
Replaces the First-Descent greedy local search with a robust Steepest Descent strategy that targets the bottleneck GPU.

Rationale:
1.  **Steepest Descent**: Instead of accepting the first valid move that reduces the max pressure, the algorithm scans all possible moves and swaps involving the bottleneck GPU and selects the one that maximizes the reduction in peak pressure. This helps in escaping shallow local optima where a suboptimal move blocks a better one.
2.  **Efficiency**: By moving statistic pre-calculation outside the loop and incrementally updating it, the overhead of recomputing stats for all GPUs is removed. This allows increasing the iteration limit (from 50 to 150) without a significant performance penalty.
3.  **Targeted Optimization**: The search strictly focuses on the GPU with the maximum pressure (`src_gpu`). By systematically evaluating all candidates from this source, we ensure the bottleneck is relieved as much as possible in each step.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # ---------------------------------------------------------
    # 3. Local Search Refinement
    # ---------------------------------------------------------
    # Iteratively move models from the bottleneck GPU to others
    for _ in range(50):
        # Find bottleneck GPU
        max_p = -1.0
        src_gpu = -1
        gpu_stats = []

        for i in range(gpu_num):
            assigned = best_placement[i]
            w = sum(m.req_rate / m.slo for m in assigned)
            s = sum(m.model_size for m in assigned)
            rem = GPU_MEM_SIZE - s
            p = w / rem if rem > 1e-9 else float('inf')
            gpu_stats.append({'w': w, 's': s, 'p': p})
            if p > max_p:
                max_p = p
                src_gpu = i

        if src_gpu == -1 or max_p < 1e-9: break

        improved = False
        src_models = best_placement[src_gpu]

        # 1. Try MOVE (Src -> Dst)
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            best_dst = None
            min_dst_p = float('inf')

            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                if dst_rem <= 1e-9: continue

                dst_w = gpu_stats[dst]['w'] + w
                new_dst_p = dst_w / dst_rem

                if new_dst_p < max_p - 1e-5:
                     # Find best fit destination (lowest resulting pressure)
                     if new_dst_p < min_dst_p:
                         min_dst_p = new_dst_p
                         best_dst = dst

            if best_dst is not None:
                moved_model = src_models.pop(m_idx)
                best_placement[best_dst].append(moved_model)
                improved = True
                break

        if improved: continue

        # 2. Try SWAP (Src <-> Dst)
        for m_src_idx, m_src in enumerate(src_models):
            w_src = m_src.req_rate / m_src.slo
            s_src = m_src.model_size

            for dst in range(gpu_num):
                if dst == src_gpu: continue

                dst_models = best_placement[dst]
                for m_dst_idx, m_dst in enumerate(dst_models):
                    w_dst = m_dst.req_rate / m_dst.slo
                    s_dst = m_dst.model_size

                    # Capacity Check
                    new_src_s = gpu_stats[src_gpu]['s'] - s_src + s_dst
                    if new_src_s > GPU_MEM_SIZE: continue

                    new_dst_s = gpu_stats[dst]['s'] - s_dst + s_src
                    if new_dst_s > GPU_MEM_SIZE: continue

                    # Pressure Check
                    new_src_rem = GPU_MEM_SIZE - new_src_s
                    if new_src_rem <= 1e-9: continue
                    new_src_w = gpu_stats[src_gpu]['w'] - w_src + w_dst
                    new_src_p = new_src_w / new_src_rem

                    new_dst_rem = GPU_MEM_SIZE - new_dst_s
                    if new_dst_rem <= 1e-9: continue
                    new_dst_w = gpu_stats[dst]['w'] - w_dst + w_src
                    new_dst_p = new_dst_w / new_dst_rem

                    if max(new_src_p, new_dst_p) < max_p - 1e-5:
                        # Perform Swap
                        src_models[m_src_idx] = m_dst
                        dst_models[m_dst_idx] = m_src
                        improved = True
                        break
                if improved: break
            if improved: break

        if not improved: break
=======
    # ---------------------------------------------------------
    # 3. Local Search Refinement
    # ---------------------------------------------------------
    # Strategy: Steepest Descent on the Bottleneck GPU
    # Instead of taking the first improvement, scan all moves/swaps involving the bottleneck
    # and pick the one that maximally reduces the bottleneck pressure.

    # Precalculate stats once
    gpu_stats = []
    for i in range(gpu_num):
        assigned = best_placement[i]
        w = sum(m.req_rate / m.slo for m in assigned)
        s = sum(m.model_size for m in assigned)
        rem = GPU_MEM_SIZE - s
        p = w / rem if rem > 1e-9 else (float('inf') if w > 0 else 0.0)
        gpu_stats.append({'w': w, 's': s, 'p': p})

    # Optimization Loop
    for _ in range(150):
        # Identify current bottleneck
        max_p = -1.0
        src_gpu = -1
        for g in range(gpu_num):
            if gpu_stats[g]['p'] > max_p:
                max_p = gpu_stats[g]['p']
                src_gpu = g

        if src_gpu == -1 or max_p < 1e-9: break

        src_models = best_placement[src_gpu]
        improved = False

        # Track the single best action across all candidates for this bottleneck
        best_action = None # Tuple: (type, improvement_score, ...args)

        # 3.1 Evaluate MOVES (Src -> Dst)
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            # Src state after move
            src_rem_new = GPU_MEM_SIZE - (gpu_stats[src_gpu]['s'] - s)
            src_p_new = (gpu_stats[src_gpu]['w'] - w) / src_rem_new if src_rem_new > 1e-9 else float('inf')

            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem_new = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                dst_p_new = (gpu_stats[dst]['w'] + w) / dst_rem_new if dst_rem_new > 1e-9 else float('inf')

                # We want the move that results in the lowest max(src, dst)
                local_peak = max(src_p_new, dst_p_new)

                # Must improve strictly upon the current max_p
                if local_peak < max_p - 1e-6:
                    # Improvement score: how much we lowered the pressure
                    score = max_p - local_peak
                    if best_action is None or score > best_action[1]:
                        best_action = ('move', score, m_idx, dst, src_p_new, dst_p_new, w, s)

        # 3.2 Evaluate SWAPS (Src <-> Dst)
        for m_src_idx, m_src in enumerate(src_models):
            w_src = m_src.req_rate / m_src.slo
            s_src = m_src.model_size

            for dst in range(gpu_num):
                if dst == src_gpu: continue

                dst_models = best_placement[dst]
                for m_dst_idx, m_dst in enumerate(dst_models):
                    w_dst = m_dst.req_rate / m_dst.slo
                    s_dst = m_dst.model_size

                    # Capacity Check
                    new_src_s = gpu_stats[src_gpu]['s'] - s_src + s_dst
                    if new_src_s > GPU_MEM_SIZE: continue
                    new_dst_s = gpu_stats[dst]['s'] - s_dst + s_src
                    if new_dst_s > GPU_MEM_SIZE: continue

                    # Pressure Check
                    new_src_rem = GPU_MEM_SIZE - new_src_s
                    if new_src_rem <= 1e-9: continue
                    new_src_w = gpu_stats[src_gpu]['w'] - w_src + w_dst
                    new_src_p = new_src_w / new_src_rem

                    new_dst_rem = GPU_MEM_SIZE - new_dst_s
                    if new_dst_rem <= 1e-9: continue
                    new_dst_w = gpu_stats[dst]['w'] - w_dst + w_src
                    new_dst_p = new_dst_w / new_dst_rem

                    local_peak = max(new_src_p, new_dst_p)

                    if local_peak < max_p - 1e-6:
                        score = max_p - local_peak
                        if best_action is None or score > best_action[1]:
                            best_action = ('swap', score, m_src_idx, m_dst_idx, dst, new_src_p, new_dst_p, new_src_s, new_src_w, new_dst_s, new_dst_w)

        # Apply Best Action
        if best_action:
            act_type = best_action[0]
            if act_type == 'move':
                _, _, m_idx, dst, src_p, dst_p, w, s = best_action
                model = src_models.pop(m_idx)
                best_placement[dst].append(model)

                # Update Stats
                gpu_stats[src_gpu]['w'] -= w
                gpu_stats[src_gpu]['s'] -= s
                gpu_stats[src_gpu]['p'] = src_p

                gpu_stats[dst]['w'] += w
                gpu_stats[dst]['s'] += s
                gpu_stats[dst]['p'] = dst_p

            elif act_type == 'swap':
                _, _, s_idx, d_idx, dst, src_p, dst_p, s_s, s_w, d_s, d_w = best_action

                mod_src = src_models[s_idx]
                mod_dst = best_placement[dst][d_idx]

                src_models[s_idx] = mod_dst
                best_placement[dst][d_idx] = mod_src

                gpu_stats[src_gpu] = {'w': s_w, 's': s_s, 'p': src_p}
                gpu_stats[dst] = {'w': d_w, 's': d_s, 'p': dst_p}

            improved = True

        if not improved: break
>>>>>>> REPLACE
</DIFF>