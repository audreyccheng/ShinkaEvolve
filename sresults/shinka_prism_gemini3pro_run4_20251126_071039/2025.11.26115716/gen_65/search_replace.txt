<NAME>
multi_strat_beam_search
</NAME>

<DESCRIPTION>
Implements a Multi-Strategy Beam Search for the feasibility check inside the Binary Search loop.
Instead of relying on a single deterministic sort order (Linearized Cost), the new `solve_check` (renamed/modified) attempts packing using:
1. Linearized Cost Descending
2. Size Descending
3. Density Descending
4. Randomized Perturbed Linearized Cost (if deterministic strategies fail)

This robust approach increases the probability of finding a feasible packing for tight K values, improving the binary search result. The beam search itself uses a "Best Fit (Sum of Squares)" heuristic and adaptive width/attempts.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    Returns:
        A placement of models to GPUs
    """

    # 1. Preprocessing and Lower Bound
=======
    Returns:
        A placement of models to GPUs
    """
    import random

    # 1. Preprocessing and Lower Bound
>>>>>>> REPLACE
<<<<<<< SEARCH
    def solve_check(k_target, beam_width=4):
        """
        Check feasibility for K using Beam Search.
        Constraint: Sum(w + K*s) <= K*C for each bin.
        """
        limit = k_target * GPU_MEM_SIZE

        # Prepare and sort items by linearized cost
        weighted = []
        for x in items:
            cost = x['w'] + k_target * x['s']
            if cost > limit + 1e-5: return None
            weighted.append((cost, x))

        # Sort descending (Best Fit Decreasing strategy)
        weighted.sort(key=lambda x: x[0], reverse=True)

        # Beam State: (score, loads_tuple, placement_list)
        # Score: Sum of squares of loads (preference for tight packing)
        # Loads: Tuple of linearized loads

        start_loads = tuple([0.0] * gpu_num)
        start_pl = tuple([[] for _ in range(gpu_num)])

        beam = [(0.0, start_loads, start_pl)]

        for cost, item in weighted:
            candidates = []
            seen_signatures = set()

            for score, loads, pl in beam:
                # Try placing in each bin
                # Optimization: Duplicate load handling (Symmetry breaking)
                tried_loads = set()

                for i in range(gpu_num):
                    current_l = loads[i]
                    if current_l in tried_loads: continue

                    if current_l + cost <= limit + 1e-5:
                        tried_loads.add(current_l)

                        new_loads_list = list(loads)
                        new_loads_list[i] += cost

                        # Signature for state merging: sorted loads
                        sig = tuple(sorted(new_loads_list))
                        if sig in seen_signatures: continue
                        seen_signatures.add(sig)

                        new_pl_list = list(pl)
                        new_pl_list[i] = pl[i] + [item]

                        # Heuristic: Maximize sum of squares (Best Fit)
                        new_score = sum(l*l for l in new_loads_list)

                        # Use negative score for sorting logic (if min-heap/sort default)
                        # Here we just store score and sort desc later
                        candidates.append((new_score, tuple(new_loads_list), tuple(new_pl_list)))

            if not candidates:
                return None

            # Select top beam_width
            candidates.sort(key=lambda x: x[0], reverse=True)
            beam = candidates[:beam_width]

        return beam[0][2]
=======
    def solve_check(k_target, beam_width=4, attempts=0):
        """
        Check feasibility for K using Beam Search with multiple sorting strategies.
        Constraint: Sum(w + K*s) <= K*C for each bin.
        """
        limit = k_target * GPU_MEM_SIZE

        def run_beam(ordered_items):
            # Beam State: (score, loads_tuple, placement_list)
            start_loads = tuple([0.0] * gpu_num)
            start_pl = tuple([[] for _ in range(gpu_num)])
            beam = [(0.0, start_loads, start_pl)]

            for item_data in ordered_items:
                # Calculate cost for this specific item
                cost = item_data['w'] + k_target * item_data['s']
                if cost > limit + 1e-5: return None

                candidates = []
                seen_signatures = set()

                for score, loads, pl in beam:
                    tried_loads = set()
                    for i in range(gpu_num):
                        current_l = loads[i]
                        if current_l in tried_loads: continue

                        if current_l + cost <= limit + 1e-5:
                            tried_loads.add(current_l)

                            new_loads_list = list(loads)
                            new_loads_list[i] += cost

                            # Symmetry breaking
                            sig = tuple(sorted(new_loads_list))
                            if sig in seen_signatures: continue
                            seen_signatures.add(sig)

                            new_pl_list = list(pl)
                            new_pl_list[i] = pl[i] + [item_data]

                            # Best Fit Heuristic: Sum of squares
                            new_score = sum(l*l for l in new_loads_list)
                            candidates.append((new_score, tuple(new_loads_list), tuple(new_pl_list)))

                if not candidates:
                    return None

                # Sort descending by score (Best Fit)
                candidates.sort(key=lambda x: x[0], reverse=True)
                beam = candidates[:beam_width]

            return beam[0][2]

        # Strategies: 1. Linearized Cost, 2. Size, 3. Density
        keys = [
            lambda x: x['w'] + k_target * x['s'],
            lambda x: x['s'],
            lambda x: x['w'] / (x['s'] + 1e-9)
        ]

        for key in keys:
            res = run_beam(sorted(items, key=key, reverse=True))
            if res: return res

        if attempts > 0:
            rng = random.Random(42 + int(k_target * 1000))
            base_key = lambda x: x['w'] + k_target * x['s']
            for _ in range(attempts):
                # Add noise to the sort key
                noisy_items = sorted(items, key=lambda x: base_key(x) * rng.uniform(0.9, 1.1), reverse=True)
                res = run_beam(noisy_items)
                if res: return res

        return None
>>>>>>> REPLACE
<<<<<<< SEARCH
    # Binary Search
    high = 1e9

    # Initial Check (try simple greedy then wide beam)
    res = solve_check(high, beam_width=1)
    if not res:
        res = solve_check(high, beam_width=8)
        if not res:
            raise ValueError("Unable to place models on GPUs.")

    # Optimize initial solution to tighten bound
    res = local_optimize(res)
    best_pl = res
    high = min(high, get_max_kvpr(res))
    low = lb

    for _ in range(25):
        if high - low < 1e-4: break
        mid = (low + high) / 2

        # Adaptive Beam Width: Fast check then robust check
        r = solve_check(mid, beam_width=2)
        if not r:
            r = solve_check(mid, beam_width=8)

        if r:
            # Found valid placement for K=mid.
            # Can we do better? Run local optimization on this placement
            r = local_optimize(r)
            mx = get_max_kvpr(r)

            if mx < get_max_kvpr(best_pl):
                best_pl = r

            high = min(mid, mx)
        else:
            low = mid
=======
    # Binary Search
    high = 1e9

    # Initial Check
    res = solve_check(high, beam_width=2, attempts=5)
    if not res:
        res = solve_check(high, beam_width=8, attempts=5)
        if not res:
            raise ValueError("Unable to place models on GPUs.")

    # Optimize initial solution to tighten bound
    res = local_optimize(res)
    best_pl = res
    high = min(high, get_max_kvpr(res))
    low = lb

    for _ in range(25):
        if high - low < 1e-4: break
        mid = (low + high) / 2

        # Try multiple strategies with increasing effort
        r = solve_check(mid, beam_width=2, attempts=2)
        if not r:
            r = solve_check(mid, beam_width=8, attempts=5)

        if r:
            # Found valid placement for K=mid.
            r = local_optimize(r)
            mx = get_max_kvpr(r)

            if mx < get_max_kvpr(best_pl):
                best_pl = r

            high = min(mid, mx)
        else:
            low = mid
>>>>>>> REPLACE
</DIFF>