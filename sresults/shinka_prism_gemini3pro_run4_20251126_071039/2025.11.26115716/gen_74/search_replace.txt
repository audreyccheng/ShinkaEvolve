<NAME>
steepest_descent_and_diverse_strategies
</NAME>

<DESCRIPTION>
1.  **Diversify Packing Strategies in Binary Search**: Modified the stochastic packing loop to cycle through different sorting strategies (Effective Size, Physical Size, Weight) instead of relying solely on Effective Size. This increases the probability of finding a valid packing for a given target pressure K by exploring different heuristic orderings. Also increased trials to 30.
2.  **Steepest Descent Local Search**: Replaced the "First Fit" local search (which takes the first improving move/swap) with a "Steepest Descent" approach. It now evaluates all possible moves and swaps for the bottleneck GPU and selects the one that results in the lowest local maximum pressure (`max(new_src_p, new_dst_p)`). This avoids suboptimal moves that barely improve the objective and might lead to local optima, ensuring deeper optimization of the bottleneck.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                # Randomized Best Fit Decreasing Check with Failure Memory
                found_placement = None
                failed_items = set()

                for attempt in range(20):
                    noise = 0.0
                    if attempt > 0:
                        noise = 0.02 + (attempt * 0.005)

                    def sort_key(m):
                        # Base: Effective size
                        val = m.model_size + (m.req_rate / m.slo) / mid
                        # Noise perturbation
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Memory: Prioritize items that failed previously
                        if id(m) in failed_items:
                            val += 1e6
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)
=======
                # Randomized Best Fit Decreasing Check with Failure Memory
                found_placement = None
                failed_items = set()

                # Strategies for sorting: Effective Size, Physical Size, Weight
                strategies = [
                    lambda m: m.model_size + (m.req_rate / m.slo) / mid,
                    lambda m: m.model_size,
                    lambda m: m.req_rate / m.slo
                ]

                for attempt in range(30):
                    base_key = strategies[attempt % len(strategies)]

                    noise = 0.0
                    if attempt > 3:
                        noise = 0.01 + (attempt * 0.003)

                    def sort_key(m):
                        val = base_key(m)
                        if noise > 0:
                            val *= random.uniform(1.0 - noise, 1.0 + noise)
                        # Memory: Prioritize items that failed previously
                        if id(m) in failed_items:
                            val += 1e9
                        return val

                    bs_models = sorted(models, key=sort_key, reverse=True)
>>>>>>> REPLACE
<<<<<<< SEARCH
    # ---------------------------------------------------------
    # 3. Local Search Refinement
    # ---------------------------------------------------------
    # Iteratively move models from the bottleneck GPU to others
    for _ in range(50):
        # Find bottleneck GPU
        max_p = -1.0
        src_gpu = -1
        gpu_stats = []

        for i in range(gpu_num):
            assigned = best_placement[i]
            w = sum(m.req_rate / m.slo for m in assigned)
            s = sum(m.model_size for m in assigned)
            rem = GPU_MEM_SIZE - s
            p = w / rem if rem > 1e-9 else float('inf')
            gpu_stats.append({'w': w, 's': s, 'p': p})
            if p > max_p:
                max_p = p
                src_gpu = i

        if src_gpu == -1 or max_p < 1e-9: break

        improved = False
        src_models = best_placement[src_gpu]

        # 1. Try MOVE (Src -> Dst)
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            best_dst = None
            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                if dst_rem <= 1e-9: continue

                dst_w = gpu_stats[dst]['w'] + w
                new_dst_p = dst_w / dst_rem

                if new_dst_p < max_p - 1e-5:
                     best_dst = dst
                     break

            if best_dst is not None:
                moved_model = src_models.pop(m_idx)
                best_placement[best_dst].append(moved_model)
                improved = True
                break

        if improved: continue

        # 2. Try SWAP (Src <-> Dst)
        for m_src_idx, m_src in enumerate(src_models):
            w_src = m_src.req_rate / m_src.slo
            s_src = m_src.model_size

            for dst in range(gpu_num):
                if dst == src_gpu: continue

                dst_models = best_placement[dst]
                for m_dst_idx, m_dst in enumerate(dst_models):
                    w_dst = m_dst.req_rate / m_dst.slo
                    s_dst = m_dst.model_size

                    # Capacity Check
                    new_src_s = gpu_stats[src_gpu]['s'] - s_src + s_dst
                    if new_src_s > GPU_MEM_SIZE: continue

                    new_dst_s = gpu_stats[dst]['s'] - s_dst + s_src
                    if new_dst_s > GPU_MEM_SIZE: continue

                    # Pressure Check
                    new_src_rem = GPU_MEM_SIZE - new_src_s
                    if new_src_rem <= 1e-9: continue
                    new_src_w = gpu_stats[src_gpu]['w'] - w_src + w_dst
                    new_src_p = new_src_w / new_src_rem

                    new_dst_rem = GPU_MEM_SIZE - new_dst_s
                    if new_dst_rem <= 1e-9: continue
                    new_dst_w = gpu_stats[dst]['w'] - w_dst + w_src
                    new_dst_p = new_dst_w / new_dst_rem

                    if max(new_src_p, new_dst_p) < max_p - 1e-5:
                        # Perform Swap
                        src_models[m_src_idx] = m_dst
                        dst_models[m_dst_idx] = m_src
                        improved = True
                        break
                if improved: break
            if improved: break

        if not improved: break
=======
    # ---------------------------------------------------------
    # 3. Local Search Refinement
    # ---------------------------------------------------------
    # Steepest Descent: Iteratively find the BEST move or swap to reduce peak pressure.

    for _ in range(60):
        # Calculate stats and find bottleneck
        gpu_stats = []
        max_p = -1.0
        src_gpu = -1

        for i in range(gpu_num):
            assigned = best_placement[i]
            w = sum(m.req_rate / m.slo for m in assigned)
            s = sum(m.model_size for m in assigned)
            rem = GPU_MEM_SIZE - s
            p = w / rem if rem > 1e-9 else (float('inf') if w > 0 else 0.0)
            gpu_stats.append({'w': w, 's': s, 'p': p})
            if p > max_p:
                max_p = p
                src_gpu = i

        if src_gpu == -1 or max_p < 1e-9: break

        src_models = best_placement[src_gpu]
        best_action = None # (type, details...)
        best_val = max_p

        # 1. Evaluate MOVES (Src -> Dst)
        for m_idx, model in enumerate(src_models):
            w = model.req_rate / model.slo
            s = model.model_size

            # Hypothetical Src after move
            src_rem_new = GPU_MEM_SIZE - (gpu_stats[src_gpu]['s'] - s)
            src_w_new = gpu_stats[src_gpu]['w'] - w
            src_p_new = src_w_new / src_rem_new if src_rem_new > 1e-9 else (float('inf') if src_w_new > 0 else 0.0)

            for dst in range(gpu_num):
                if dst == src_gpu: continue
                if gpu_stats[dst]['s'] + s > GPU_MEM_SIZE: continue

                dst_rem_new = GPU_MEM_SIZE - (gpu_stats[dst]['s'] + s)
                if dst_rem_new <= 1e-9: continue

                dst_w_new = gpu_stats[dst]['w'] + w
                dst_p_new = dst_w_new / dst_rem_new

                # Minimize the bottleneck of the involved GPUs
                local_max = max(src_p_new, dst_p_new)
                if local_max < best_val - 1e-6:
                    best_val = local_max
                    best_action = ('move', m_idx, dst)

        # 2. Evaluate SWAPS (Src <-> Dst)
        for m_src_idx, m_src in enumerate(src_models):
            w_src = m_src.req_rate / m_src.slo
            s_src = m_src.model_size

            for dst in range(gpu_num):
                if dst == src_gpu: continue

                dst_models = best_placement[dst]
                for m_dst_idx, m_dst in enumerate(dst_models):
                    w_dst = m_dst.req_rate / m_dst.slo
                    s_dst = m_dst.model_size

                    # Capacity Check
                    new_src_s = gpu_stats[src_gpu]['s'] - s_src + s_dst
                    if new_src_s > GPU_MEM_SIZE: continue

                    new_dst_s = gpu_stats[dst]['s'] - s_dst + s_src
                    if new_dst_s > GPU_MEM_SIZE: continue

                    # Pressure Check
                    new_src_rem = GPU_MEM_SIZE - new_src_s
                    if new_src_rem <= 1e-9: continue
                    new_src_w = gpu_stats[src_gpu]['w'] - w_src + w_dst
                    new_src_p = new_src_w / new_src_rem

                    new_dst_rem = GPU_MEM_SIZE - new_dst_s
                    if new_dst_rem <= 1e-9: continue
                    new_dst_w = gpu_stats[dst]['w'] - w_dst + w_src
                    new_dst_p = new_dst_w / new_dst_rem

                    local_max = max(new_src_p, new_dst_p)
                    if local_max < best_val - 1e-6:
                        best_val = local_max
                        best_action = ('swap', m_src_idx, dst, m_dst_idx)

        # Apply Best Action
        if best_action:
            if best_action[0] == 'move':
                _, m_idx, dst = best_action
                model = src_models.pop(m_idx)
                best_placement[dst].append(model)
            else:
                _, m_src_idx, dst, m_dst_idx = best_action
                # Swap logic: simple list replacement
                m_src = src_models[m_src_idx]
                m_dst = best_placement[dst][m_dst_idx]
                src_models[m_src_idx] = m_dst
                best_placement[dst][m_dst_idx] = m_src
        else:
            break
>>>>>>> REPLACE
</DIFF>