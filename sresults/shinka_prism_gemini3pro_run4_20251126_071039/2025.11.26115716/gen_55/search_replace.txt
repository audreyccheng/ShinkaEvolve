<NAME>
optimize_beam_and_binary_search
</NAME>

<DESCRIPTION>
1. Increase the beam width in the Beam Search initialization phase from 8 to 16 to improve the quality of the initial upper bound.
2. Enhance the Binary Search phase by replacing the deterministic strategy check with a "Randomized Failure-Driven Packing" approach. This includes:
   - Increasing iterations to 20.
   - Using stochastic sorting keys with noise to escape local optima.
   - Implementing a "failure memory" mechanism that prioritizes items that caused failures in previous packing attempts within the same binary search step.
   - This allows the algorithm to find valid packings for tighter target K values (lower KVPR).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    for key_fn in sort_keys:
        sorted_indices = sorted(range(len(m_data)), key=lambda i: key_fn(m_data[i]), reverse=True)
        res_indices = run_beam_search(sorted_indices, beam_width=8)

        if res_indices:
=======
    for key_fn in sort_keys:
        sorted_indices = sorted(range(len(m_data)), key=lambda i: key_fn(m_data[i]), reverse=True)
        res_indices = run_beam_search(sorted_indices, beam_width=16)

        if res_indices:
>>>>>>> REPLACE
<<<<<<< SEARCH
    # ---------------------------------------------------------
    # 2. Binary Search with Multi-Heuristic Checking
    # ---------------------------------------------------------
    # Theoretical Lower Bound
    rem_global = gpu_num * GPU_MEM_SIZE - total_s
    low = total_w / rem_global if rem_global > 1e-6 else best_max_kvpr
    high = best_max_kvpr if best_max_kvpr != float('inf') else 1000.0

    if high > low + 1e-4:
        for _ in range(15):
            mid = (low + high) / 2.0

            # Check feasibility for target K = mid
            # Effective Size = s + w/mid.
            # We try multiple sorting orders to pack better.
            check_sorts = [
                lambda x: x['s'] + x['w'] / mid, # Effective Size
                lambda x: x['s'],                # Physical Size
                lambda x: x['w']                 # Weight
            ]

            found_config = None

            for sort_key in check_sorts:
                sorted_idx = sorted(range(len(m_data)), key=lambda i: sort_key(m_data[i]), reverse=True)

                temp_p = {i: [] for i in range(gpu_num)}
                temp_state = [{'w': 0.0, 's': 0.0} for _ in range(gpu_num)]
                feasible = True

                for idx in sorted_idx:
                    item = m_data[idx]
                    eff_size = item['s'] + item['w'] / mid

                    best_gpu = None
                    min_slack = float('inf')

                    # Best Fit Decreasing on Effective Constraint
                    for i in range(gpu_num):
                        # 1. Physical Fit
                        if temp_state[i]['s'] + item['s'] > GPU_MEM_SIZE: continue

                        # 2. Effective Fit: (Current_W + w) <= mid * (Rem_Physical - s)
                        phys_rem_after = GPU_MEM_SIZE - (temp_state[i]['s'] + item['s'])
                        if phys_rem_after < 0: phys_rem_after = 0.0

                        lhs = temp_state[i]['w'] + item['w']
                        rhs = mid * phys_rem_after

                        if lhs <= rhs + 1e-6:
                            # Slack represents unused effective capacity
                            slack = rhs - lhs
                            if slack < min_slack:
                                min_slack = slack
                                best_gpu = i

                    if best_gpu is None:
                        feasible = False
                        break

                    temp_p[best_gpu].append(idx)
                    temp_state[best_gpu]['w'] += item['w']
                    temp_state[best_gpu]['s'] += item['s']

                if feasible:
                    found_config = temp_p
                    break

            if found_config:
                score = evaluate_indices(found_config)
                if score < best_max_kvpr:
                    best_max_kvpr = score
                    best_placement_indices = found_config
                high = mid
            else:
                low = mid
=======
    # ---------------------------------------------------------
    # 2. Binary Search with Multi-Heuristic Checking
    # ---------------------------------------------------------
    # Theoretical Lower Bound
    rem_global = gpu_num * GPU_MEM_SIZE - total_s
    low = total_w / rem_global if rem_global > 1e-6 else 0.0
    if best_max_kvpr != float('inf'):
        high = best_max_kvpr
    else:
        high = 5000.0

    if high > low + 1e-4:
        for _ in range(20):
            mid = (low + high) / 2.0

            # Check feasibility for target K = mid using Randomized Failure-Driven Packing
            found_config = None
            failed_items = set()

            # Base sorting keys
            strategies = [
                (lambda x: x['s'] + x['w'] / mid, 'eff'),
                (lambda x: x['s'], 'phys'),
                (lambda x: x['w'], 'weight')
            ]

            # Try multiple attempts: deterministic first, then stochastic with feedback
            for attempt in range(15):
                # Select base strategy
                if attempt < len(strategies):
                    base_key = strategies[attempt][0]
                    noise = 0.0
                else:
                    base_key = strategies[0][0] # Default to effective size
                    noise = 0.02 * (attempt - 2)

                def sort_key_fn(item):
                    val = base_key(item)
                    if noise > 0:
                        val *= random.uniform(1.0 - noise, 1.0 + noise)
                    # Priority boost for items that caused failure previously
                    if item['id'] in failed_items:
                        val += 1e9
                    return val

                sorted_idx = sorted(range(len(m_data)), key=lambda i: sort_key_fn(m_data[i]), reverse=True)

                temp_p = {i: [] for i in range(gpu_num)}
                temp_state = [{'w': 0.0, 's': 0.0} for _ in range(gpu_num)]
                feasible = True
                first_fail_id = None

                for idx in sorted_idx:
                    item = m_data[idx]

                    best_gpu = None
                    min_slack = float('inf')

                    # Best Fit Decreasing on Effective Constraint
                    for i in range(gpu_num):
                        # 1. Physical Fit
                        if temp_state[i]['s'] + item['s'] > GPU_MEM_SIZE: continue

                        # 2. Effective Fit
                        phys_rem_after = GPU_MEM_SIZE - (temp_state[i]['s'] + item['s'])
                        if phys_rem_after < 0: phys_rem_after = 0.0

                        lhs = temp_state[i]['w'] + item['w']
                        rhs = mid * phys_rem_after

                        if lhs <= rhs + 1e-6:
                            # Slack: how much pressure budget is left
                            slack = rhs - lhs
                            if slack < min_slack:
                                min_slack = slack
                                best_gpu = i

                    if best_gpu is None:
                        feasible = False
                        first_fail_id = item['id']
                        break

                    temp_p[best_gpu].append(idx)
                    temp_state[best_gpu]['w'] += item['w']
                    temp_state[best_gpu]['s'] += item['s']

                if feasible:
                    found_config = temp_p
                    break
                else:
                    if first_fail_id is not None:
                        failed_items.add(first_fail_id)

            if found_config:
                score = evaluate_indices(found_config)
                if score < best_max_kvpr:
                    best_max_kvpr = score
                    best_placement_indices = found_config
                high = mid
            else:
                low = mid
>>>>>>> REPLACE
</DIFF>