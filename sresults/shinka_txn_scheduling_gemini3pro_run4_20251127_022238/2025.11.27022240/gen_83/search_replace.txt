<NAME>
greedy_decay_alpha
</NAME>

<DESCRIPTION>
Implement a decaying alpha heuristic in the greedy construction phase. Instead of a fixed weight for transaction length, the weight starts high ("Big Rocks" priority) and decays linearly as the schedule fills up (prioritizing "Best Fit"). This aligns with the strategy of placing large, difficult items first and filling gaps with smaller ones later.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Phase 1: Diverse Adaptive Greedy ---
    GREEDY_SAMPLE = 12
    candidates = []

    for i in range(num_seqs):
        # Diversity: Jitter parameters per candidate
        if i == 0:
            # Baseline (proven good parameters)
            run_alpha = 0.05
            run_threshold = 0.90
        else:
            # Random exploration
            run_alpha = random.uniform(0.0, 0.25)
            run_threshold = random.uniform(0.80, 0.98)

        remaining = set(range(workload.num_txns))

        # Random start
        start_txn = random.choice(list(remaining))
        curr_seq = [start_txn]
        remaining.remove(start_txn)

        while remaining:
            # Dynamic Threshold
            rem_lens = [txn_lens[t] for t in remaining]
            max_rem = max(rem_lens) if rem_lens else 0
            limit = max_rem * run_threshold

            # Pool: Big Rocks + Randoms
            big_rocks = [t for t in remaining if txn_lens[t] >= limit]
            pool = list(big_rocks)

            needed = GREEDY_SAMPLE - len(pool)
            if needed > 0:
                others = [t for t in remaining if t not in big_rocks]
                if len(others) <= needed:
                    pool.extend(others)
                else:
                    pool.extend(random.sample(others, needed))

            pool = list(set(pool))

            # Selection
            best_cand = -1
            best_score = float('inf')

            for t in pool:
                cost = workload.get_opt_seq_cost(curr_seq + [t])
                score = cost - (run_alpha * txn_lens[t])

                if score < best_score:
                    best_score = score
                    best_cand = t

            curr_seq.append(best_cand)
            remaining.remove(best_cand)
=======
    # --- Phase 1: Diverse Adaptive Greedy ---
    GREEDY_SAMPLE = 12
    candidates = []

    for i in range(num_seqs):
        # Diversity: Jitter parameters per candidate
        # We use a decaying alpha: high initial weight for length (Big Rocks), low final weight (Best Fit)
        if i == 0:
            # Baseline parameters
            start_alpha = 0.40
            run_threshold = 0.90
        else:
            # Random exploration
            start_alpha = random.uniform(0.20, 0.60)
            run_threshold = random.uniform(0.80, 0.98)

        remaining = set(range(workload.num_txns))
        total_txns = workload.num_txns

        # Random start
        start_txn = random.choice(list(remaining))
        curr_seq = [start_txn]
        remaining.remove(start_txn)

        while remaining:
            # Decay Alpha: Linear decay to 0.1 * start_alpha
            progress = len(curr_seq) / total_txns
            curr_alpha = start_alpha * (1.0 - (0.9 * progress))

            # Dynamic Threshold
            rem_lens = [txn_lens[t] for t in remaining]
            max_rem = max(rem_lens) if rem_lens else 0
            limit = max_rem * run_threshold

            # Pool: Big Rocks + Randoms
            big_rocks = [t for t in remaining if txn_lens[t] >= limit]
            pool = list(big_rocks)

            needed = GREEDY_SAMPLE - len(pool)
            if needed > 0:
                others = [t for t in remaining if t not in big_rocks]
                if len(others) <= needed:
                    pool.extend(others)
                else:
                    pool.extend(random.sample(others, needed))

            pool = list(set(pool))

            # Selection
            best_cand = -1
            best_score = float('inf')

            for t in pool:
                cost = workload.get_opt_seq_cost(curr_seq + [t])
                # Score minimizes cost while rewarding length (based on current alpha)
                score = cost - (curr_alpha * txn_lens[t])

                if score < best_score:
                    best_score = score
                    best_cand = t

            curr_seq.append(best_cand)
            remaining.remove(best_cand)
>>>>>>> REPLACE
</DIFF>

<NAME>
add_sampled_best_fit
</NAME>

<DESCRIPTION>
Re-introduce the "Sampled Best-Fit" mutation operator into the LAHC engine with a low probability (4%). This operator removes a transaction and attempts to insert it at multiple random positions, keeping the best one. This "smart" mutation helps fine-tune the schedule by finding optimal slots for misplaced transactions, complementing the random shift and block move operators.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
            # Mutation Selection
            neigh_s = list(curr_s)
            slen = len(neigh_s)
            r = random.random()

            # Probabilities adapted for multi-scale moves
            # 0.0 - 0.45: Single Shift (45%)
            # 0.45 - 0.70: Micro Block Shift (25%) - Size 2-4
            # 0.70 - 0.80: Macro Block Shift (10%) - Size 5-9
            # 0.80 - 1.00: Swap (20%)

            if r < 0.45:
                # Single Shift
                if slen < 2: continue
                f, t = random.randint(0, slen-1), random.randint(0, slen-1)
                if f == t: continue
                item = neigh_s.pop(f)
                neigh_s.insert(t, item)

            elif r < 0.70:
                # Micro Block Shift
                if slen < 5: continue
                bsize = random.randint(2, 4)
                f = random.randint(0, slen - bsize)
                block = neigh_s[f : f+bsize]
                del neigh_s[f : f+bsize]
                t = random.randint(0, len(neigh_s))
                neigh_s[t:t] = block

            elif r < 0.80:
                # Macro Block Shift
                if slen < 10: continue
                bsize = random.randint(5, 9)
                f = random.randint(0, slen - bsize)
                block = neigh_s[f : f+bsize]
                del neigh_s[f : f+bsize]
                t = random.randint(0, len(neigh_s))
                neigh_s[t:t] = block

            else:
                # Swap
                if slen < 2: continue
                idx = random.randint(0, slen - 2)
                neigh_s[idx], neigh_s[idx+1] = neigh_s[idx+1], neigh_s[idx]

            neigh_c = workload.get_opt_seq_cost(neigh_s)
=======
            # Mutation Selection
            neigh_s = list(curr_s)
            slen = len(neigh_s)
            r = random.random()
            neigh_c = -1

            # 1. Sampled Best-Fit (4%) - Smart repair
            if r < 0.04:
                if slen < 5: continue
                idx = random.randint(0, slen-1)
                item = neigh_s.pop(idx)

                # Try 3 random positions
                best_loc_c = float('inf')
                best_loc_s = None

                targets = [random.randint(0, len(neigh_s)) for _ in range(3)]

                for ins_idx in targets:
                    tmp = list(neigh_s)
                    tmp.insert(ins_idx, item)
                    c = workload.get_opt_seq_cost(tmp)
                    if c < best_loc_c:
                        best_loc_c = c
                        best_loc_s = tmp

                neigh_s = best_loc_s
                neigh_c = best_loc_c

            # 2. Single Shift (46%)
            elif r < 0.50:
                if slen < 2: continue
                f, t = random.randint(0, slen-1), random.randint(0, slen-1)
                if f != t:
                    item = neigh_s.pop(f)
                    neigh_s.insert(t, item)

            # 3. Micro Block Shift (25%) - Size 2-4
            elif r < 0.75:
                if slen < 5: continue
                bsize = random.randint(2, 4)
                f = random.randint(0, slen - bsize)
                block = neigh_s[f : f+bsize]
                del neigh_s[f : f+bsize]
                t = random.randint(0, len(neigh_s))
                neigh_s[t:t] = block

            # 4. Macro Block Shift (10%) - Size 5-9
            elif r < 0.85:
                if slen < 10: continue
                bsize = random.randint(5, 9)
                f = random.randint(0, slen - bsize)
                block = neigh_s[f : f+bsize]
                del neigh_s[f : f+bsize]
                t = random.randint(0, len(neigh_s))
                neigh_s[t:t] = block

            # 5. Swap (15%)
            else:
                if slen < 2: continue
                idx = random.randint(0, slen - 2)
                neigh_s[idx], neigh_s[idx+1] = neigh_s[idx+1], neigh_s[idx]

            if neigh_c == -1:
                neigh_c = workload.get_opt_seq_cost(neigh_s)
>>>>>>> REPLACE
</DIFF>

<NAME>
marathon_history
</NAME>

<DESCRIPTION>
Increase the history length in the Marathon phase from 100 to 150. A longer history buffer in Late Acceptance Hill Climbing allows the algorithm to tolerate extended periods of non-improvement, facilitating the traversal of wider valleys in the search landscape before the cooling phase enforces convergence.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Phase 3: Marathon ---
    sprint_results.sort(key=lambda x: x[0])
    champ_c, champ_s = sprint_results[0]

    MARATHON_ITERS = 3000
    final_c, final_s = advanced_lahc(champ_s, champ_c, MARATHON_ITERS, history_len=100, allow_kick=True)

    return final_c, final_s
=======
    # --- Phase 3: Marathon ---
    sprint_results.sort(key=lambda x: x[0])
    champ_c, champ_s = sprint_results[0]

    MARATHON_ITERS = 3000
    final_c, final_s = advanced_lahc(champ_s, champ_c, MARATHON_ITERS, history_len=150, allow_kick=True)

    return final_c, final_s
>>>>>>> REPLACE
</DIFF>