<NAME>
greedy_length_tiebreaker
</NAME>

<DESCRIPTION>
I propose replacing the current complex Iterated Local Search (ILS) approach with a refined Repeated Greedy strategy. The current ILS is computationally expensive and the "early exit" in the greedy phase prevents finding the best candidate.

My solution:
1. **Intelligent Greedy Construction**: Instead of picking the first transaction that doesn't increase makespan, we evaluate a larger sample (20 candidates).
2. **Heuristic Tie-Breaking**: When multiple candidates yield the same minimal makespan (often the case when filling parallel slots), we pick the **longest transaction** (most operations). This "Best Fit Descending" heuristic packs more "work" into the available schedule gaps, leaving smaller/easier transactions for later.
3. **Robust Local Search**: We keep the full adjacent swap descent which effectively cleans up local inefficiencies.
4. **Efficiency**: Removing the expensive ILS allows us to increase the sample size and the number of restarts (in `get_random_costs`), leading to better overall exploration.

This approach combines the structural simplicity of the highest-scoring prior attempt (Score 3.17) with a smarter packing heuristic.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using repeated greedy construction with full local refinement,
    followed by Iterated Local Search (ILS) on the best candidate.

    Strategy:
    1. Generate `num_seqs` schedules. For each:
       - Construct using Randomized Greedy with lookahead.
       - Immediately apply full Adjacent Swap Descent (Local Search) to reach a local optimum.
         (Optimizing every candidate is crucial as greedy rank != local optimum rank).
    2. Select the global best from step 1.
    3. Apply Iterated Local Search (Kick + Descent) to the champion to escape local optima.

    Args:
        workload: Workload object
        num_seqs: Number of start points

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    SAMPLE_SIZE = 12
    ILS_ITERATIONS = 5     # Number of perturbation cycles
    KICK_STRENGTH = 4      # Number of random moves per kick

    candidates = []

    # Phase 1: Exploration (Generate & Refine)
    for _ in range(num_seqs):
        # A. Randomized Greedy Construction
        remaining = list(range(workload.num_txns))
        start_txn = random.choice(remaining)
        current_seq = [start_txn]
        remaining.remove(start_txn)

        # Track cost to avoid re-calculation
        current_makespan = workload.get_opt_seq_cost(current_seq)

        while remaining:
            # Sample subset of remaining transactions
            sample_size = min(len(remaining), SAMPLE_SIZE)
            sample_candidates = random.sample(remaining, sample_size)

            best_next = -1
            min_inc_cost = float('inf')

            for t in sample_candidates:
                # Evaluate appending t
                test_seq = current_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)

                if cost < min_inc_cost:
                    min_inc_cost = cost
                    best_next = t
                    # Optimization: Early exit if fits perfectly (no increase in makespan)
                    if cost <= current_makespan:
                        break

            current_seq.append(best_next)
            remaining.remove(best_next)
            current_makespan = min_inc_cost

        # B. Full Adjacent Swap Descent (Local Search)
        # Run until convergence for EVERY candidate
        improved = True
        while improved:
            improved = False
            for i in range(len(current_seq) - 1):
                # Try swap
                current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]
                new_cost = workload.get_opt_seq_cost(current_seq)

                if new_cost < current_makespan:
                    current_makespan = new_cost
                    improved = True
                else:
                    # Revert
                    current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]

        candidates.append((current_makespan, current_seq))

    # Phase 2: Exploitation (Iterated Local Search on Champion)
    candidates.sort(key=lambda x: x[0])
    best_cost, best_seq = candidates[0]

    # ILS Loop
    for _ in range(ILS_ITERATIONS):
        # Save current best state
        saved_seq = list(best_seq)

        # 1. Perturbation (Kick)
        # Apply multiple random insertions to shake up the schedule
        for _ in range(KICK_STRENGTH):
            if len(best_seq) < 2: break
            idx_from = random.randint(0, len(best_seq) - 1)
            idx_to = random.randint(0, len(best_seq) - 1)
            if idx_from != idx_to:
                txn = best_seq.pop(idx_from)
                best_seq.insert(idx_to, txn)

        # 2. Descent (Repair)
        # Optimize the perturbed schedule
        current_cost = workload.get_opt_seq_cost(best_seq)
        improved = True
        while improved:
            improved = False
            for i in range(len(best_seq) - 1):
                best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]
                new_cost = workload.get_opt_seq_cost(best_seq)
                if new_cost < current_cost:
                    current_cost = new_cost
                    improved = True
                else:
                    best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]

        # 3. Acceptance
        # If better, keep it. If worse, revert (Simple greedy acceptance)
        if current_cost < best_cost:
            best_cost = current_cost
        else:
            best_seq = saved_seq

    return best_cost, best_seq
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Repeated Greedy construction with Heuristic Tie-Breaking and Local Search.

    Improvements:
    1. Heuristic Tie-Breaking: When multiple transactions result in the same best makespan (e.g. they fit in parallel),
       prefer the "longest" transaction (most operations). This packs larger items into slack ("Best Fit Descending").
    2. No Early Exit: Evaluate all candidates in the sample to ensure the tie-breaker works.
    3. Robust Local Search: Full adjacent swap descent on every constructed sequence.

    Args:
        workload: Workload object
        num_seqs: Number of independent random starts

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    import re

    # --- Pre-computation: Transaction Lengths ---
    # We use transaction length (number of operations) as a proxy for "difficulty" or "size".
    txn_lens = {}
    try:
        for i in range(workload.num_txns):
            raw_txn = workload.txns[i]
            if isinstance(raw_txn, (list, tuple)):
                raw_txn = raw_txn[0]
            txn_str = str(raw_txn)
            # Count operations (read or write)
            ops = len(re.findall(r'[rw]-\d+', txn_str))
            txn_lens[i] = ops
    except Exception:
        # Fallback: uniform length if parsing fails
        for i in range(workload.num_txns):
            txn_lens[i] = 1

    SAMPLE_SIZE = 20  # Larger sample to find optimal fits

    best_overall_cost = float('inf')
    best_overall_schedule = []

    for _ in range(num_seqs):
        # 1. Greedy Construction
        remaining = list(range(workload.num_txns))

        # Random start
        start_txn = random.choice(remaining)
        current_seq = [start_txn]
        remaining.remove(start_txn)

        while remaining:
            # Sample candidates
            sample_size = min(len(remaining), SAMPLE_SIZE)
            candidates = random.sample(remaining, sample_size)

            best_candidate = -1
            # We want to minimize cost, then maximize length of the added transaction
            # Score tuple: (cost, -length). Python sorts tuples element-wise.
            best_score = (float('inf'), 0)

            for t in candidates:
                test_seq = current_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)

                # Use negative length to maximize it when minimizing the tuple
                score = (cost, -txn_lens[t])

                if score < best_score:
                    best_score = score
                    best_candidate = t

            current_seq.append(best_candidate)
            remaining.remove(best_candidate)

        # 2. Local Search Refinement
        # Swap adjacent transactions until no improvement
        current_cost = workload.get_opt_seq_cost(current_seq)
        improved = True
        while improved:
            improved = False
            for i in range(len(current_seq) - 1):
                # Swap
                current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]
                new_cost = workload.get_opt_seq_cost(current_seq)

                if new_cost < current_cost:
                    current_cost = new_cost
                    improved = True
                else:
                    # Revert
                    current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]

        # Update global best
        if current_cost < best_overall_cost:
            best_overall_cost = current_cost
            best_overall_schedule = list(current_seq)

    return best_overall_cost, best_overall_schedule
>>>>>>> REPLACE
<<<<<<< SEARCH
def get_random_costs():
    """
    Evaluate scheduling algorithm on three different workloads.

    Returns:
        Tuple of (total_makespan, list_of_schedules, execution_time)
    """
    start_time = time.time()
    workload_size = 100

    # Workload 1: Complex mixed read/write transactions
    workload = Workload(WORKLOAD_1)
    makespan1, schedule1 = get_best_schedule(workload, 10)
    cost1 = workload.get_opt_seq_cost(schedule1)

    # Workload 2: Simple read-then-write pattern
    workload2 = Workload(WORKLOAD_2)
    makespan2, schedule2 = get_best_schedule(workload2, 10)
    cost2 = workload2.get_opt_seq_cost(schedule2)

    # Workload 3: Minimal read/write operations
    workload3 = Workload(WORKLOAD_3)
    makespan3, schedule3 = get_best_schedule(workload3, 10)
    cost3 = workload3.get_opt_seq_cost(schedule3)

    total_makespan = cost1 + cost2 + cost3
    schedules = [schedule1, schedule2, schedule3]
    execution_time = time.time() - start_time

    return total_makespan, schedules, execution_time
=======
def get_random_costs():
    """
    Evaluate scheduling algorithm on three different workloads.

    Returns:
        Tuple of (total_makespan, list_of_schedules, execution_time)
    """
    start_time = time.time()
    # Increased number of sequences to improve exploration since ILS was removed
    NUM_SEQS = 12

    # Workload 1: Complex mixed read/write transactions
    workload = Workload(WORKLOAD_1)
    makespan1, schedule1 = get_best_schedule(workload, NUM_SEQS)
    cost1 = workload.get_opt_seq_cost(schedule1)

    # Workload 2: Simple read-then-write pattern
    workload2 = Workload(WORKLOAD_2)
    makespan2, schedule2 = get_best_schedule(workload2, NUM_SEQS)
    cost2 = workload2.get_opt_seq_cost(schedule2)

    # Workload 3: Minimal read/write operations
    workload3 = Workload(WORKLOAD_3)
    makespan3, schedule3 = get_best_schedule(workload3, NUM_SEQS)
    cost3 = workload3.get_opt_seq_cost(schedule3)

    total_makespan = cost1 + cost2 + cost3
    schedules = [schedule1, schedule2, schedule3]
    execution_time = time.time() - start_time

    return total_makespan, schedules, execution_time
>>>>>>> REPLACE
</DIFF>