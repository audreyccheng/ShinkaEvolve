<NAME>
add_math_import
</NAME>

<DESCRIPTION>
Import the math module to support Simulated Annealing calculations (exponential function).
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
import time
import random
import sys
import os
=======
import time
import random
import sys
import os
import math
>>>>>>> REPLACE
</DIFF>

<NAME>
implement_sa_scheduling
</NAME>

<DESCRIPTION>
Replace the scheduling algorithm with a hybrid approach:
1. Multi-Start Greedy Construction (Gen 8 style) with heuristic tie-breaking and immediate Swap Descent. This ensures high-quality initial candidates by fully optimizing every random start to its local minimum (fixing the issue where smart sampling reduced diversity in Gen 9).
2. Simulated Annealing (SA) refinement on the best candidate. SA helps escape local optima by accepting worsening moves with a probability that decreases over time. The move set includes both adjacent swaps (local refinement) and random insertions (global structural changes).
This combines the robustness of the population-based greedy search with the escaping capability of SA, addressing the limitation of simple Hill Climbing.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Advanced Greedy Construction and Hybrid Local Search.

    Improvements:
    1.  **Txn Length Heuristic**: Pre-computes transaction lengths (operation counts).
    2.  **Smart Sampling**: In greedy phase, candidates include both random choices and the "longest"
        remaining transactions. This encourages packing "big rocks" early if they fit.
    3.  **Tie-Breaking**: Selects candidates by minimizing `(cost, -length)`, preferring longer
        transactions when costs are equal (Best Fit Descending).
    4.  **Hybrid Local Search**: Uses Adjacent Swap Descent for fine-tuning, followed by
        Random Insertion (Shift) attempts to escape local optima.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    import re

    # --- Pre-computation: Transaction Lengths ---
    txn_lens = {}
    try:
        for i in range(workload.num_txns):
            raw_txn = workload.txns[i]
            if isinstance(raw_txn, (list, tuple)):
                raw_txn = raw_txn[0]
            txn_str = str(raw_txn)
            ops = len(re.findall(r'[rw]-\d+', txn_str))
            txn_lens[i] = ops
    except Exception:
        for i in range(workload.num_txns):
            txn_lens[i] = 1

    # Sorted list of transactions by length (descending) for priority sampling
    txns_by_len = sorted(range(workload.num_txns), key=lambda k: txn_lens[k], reverse=True)

    best_overall_cost = float('inf')
    best_overall_schedule = []

    # Parameters
    SAMPLE_SIZE_RANDOM = 12
    SAMPLE_SIZE_LONGEST = 3
    SHIFT_ATTEMPTS = 50  # Budget for random insertion moves

    for _ in range(num_seqs):
        # 1. Greedy Construction
        remaining = set(range(workload.num_txns))

        # Random start for diversity
        start_txn = random.choice(list(remaining))
        current_seq = [start_txn]
        remaining.remove(start_txn)

        while remaining:
            candidates = set()

            # A. Pick top longest available transactions
            count = 0
            for t in txns_by_len:
                if t in remaining:
                    candidates.add(t)
                    count += 1
                    if count >= SAMPLE_SIZE_LONGEST:
                        break

            # B. Pick random transactions
            sample_size = min(len(remaining), SAMPLE_SIZE_RANDOM)
            candidates.update(random.sample(list(remaining), sample_size))

            # C. Evaluate Candidates
            # We want to minimize cost, then maximize length (Best Fit Descending)
            best_candidate = -1
            best_score = (float('inf'), 0) # (cost, -length)

            for t in candidates:
                test_seq = current_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)

                # Tie-breaker: negative length so min() picks the larger length
                score = (cost, -txn_lens[t])

                if score < best_score:
                    best_score = score
                    best_candidate = t

            current_seq.append(best_candidate)
            remaining.remove(best_candidate)

        # 2. Local Search Refinement
        current_cost = workload.get_opt_seq_cost(current_seq)

        # Phase A: Adjacent Swap Descent (Hill Climbing)
        improved = True
        while improved:
            improved = False
            for i in range(len(current_seq) - 1):
                # Swap adjacent
                current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]
                new_cost = workload.get_opt_seq_cost(current_seq)

                if new_cost < current_cost:
                    current_cost = new_cost
                    improved = True
                else:
                    # Revert
                    current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]

        # Phase B: Random Insertion (Shift) Perturbation
        # Try moving a random transaction to a random position
        for _ in range(SHIFT_ATTEMPTS):
            if len(current_seq) < 2: break

            # Pick random txn and new position
            idx_from = random.randint(0, len(current_seq) - 1)
            idx_to = random.randint(0, len(current_seq) - 1)

            if idx_from == idx_to: continue

            # Move
            txn = current_seq.pop(idx_from)
            current_seq.insert(idx_to, txn)

            new_cost = workload.get_opt_seq_cost(current_seq)

            if new_cost < current_cost:
                current_cost = new_cost
                # Keep the change
            else:
                # Revert
                current_seq.pop(idx_to)
                current_seq.insert(idx_from, txn)

        # Update global best
        if current_cost < best_overall_cost:
            best_overall_cost = current_cost
            best_overall_schedule = list(current_seq)

    return best_overall_cost, best_overall_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Multi-Start Greedy Construction followed by Simulated Annealing.

    Algorithm:
    1.  **Length Analysis**: Pre-compute transaction operation counts for tie-breaking.
    2.  **Population Generation**: Generate `num_seqs` candidates.
        - Start randomly.
        - Greedy Step: Evaluate a random sample of `SAMPLE_SIZE` candidates.
        - Selection: Minimize `(makespan, -length)` (Best Fit Descending).
        - **Immediate Polish**: Apply full Adjacent Swap Descent to each greedy candidate.
          This ensures we are comparing local minima, not just rough constructions.
    3.  **Champion Selection**: Pick the best candidate from phase 2.
    4.  **Simulated Annealing (SA)**:
        - Refine the champion using a probabilistic acceptance criterion to escape local optima.
        - Moves:
          - Swap Adjacent (Small step).
          - Shift/Insert (Structural step, good for dependency resolving).
        - Cooling: Geometric decay.

    Args:
        workload: Workload object
        num_seqs: Number of independent random starts

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    import re

    # --- Pre-computation: Transaction Lengths ---
    txn_lens = {}
    try:
        for i in range(workload.num_txns):
            raw_txn = workload.txns[i]
            if isinstance(raw_txn, (list, tuple)):
                raw_txn = raw_txn[0]
            txn_str = str(raw_txn)
            ops = len(re.findall(r'[rw]-\d+', txn_str))
            txn_lens[i] = ops
    except Exception:
        for i in range(workload.num_txns):
            txn_lens[i] = 1

    SAMPLE_SIZE = 20
    candidates = []

    # --- Phase 1: Diverse Exploration (Generate & Optimize) ---
    for _ in range(num_seqs):
        # A. Greedy Construction
        remaining = list(range(workload.num_txns))
        start_txn = random.choice(remaining)
        current_seq = [start_txn]
        remaining.remove(start_txn)

        # Optimization: Track cost incrementally if possible, but simulation is complex.
        # We rely on simulation for accurate makespan.

        while remaining:
            # Sample candidates
            sample_size = min(len(remaining), SAMPLE_SIZE)
            # Pure random sampling (found to be more robust than "smart" sampling in previous gens)
            sample_cands = random.sample(remaining, sample_size)

            best_cand = -1
            # Minimize cost, Maximize length
            best_score = (float('inf'), 0)

            for t in sample_cands:
                test_seq = current_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)
                score = (cost, -txn_lens[t])

                if score < best_score:
                    best_score = score
                    best_cand = t

            current_seq.append(best_cand)
            remaining.remove(best_cand)

        # B. Fast Polish (Hill Climbing)
        # Bring candidate to a local optimum
        current_cost = workload.get_opt_seq_cost(current_seq)
        improved = True
        while improved:
            improved = False
            for i in range(len(current_seq) - 1):
                # Swap
                current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]
                new_cost = workload.get_opt_seq_cost(current_seq)

                if new_cost < current_cost:
                    current_cost = new_cost
                    improved = True
                else:
                    # Revert
                    current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]

        candidates.append((current_cost, current_seq))

    # --- Phase 2: Focused Exploitation (Simulated Annealing) ---
    # Pick the best seed
    candidates.sort(key=lambda x: x[0])
    best_cost, best_seq = candidates[0]

    # SA Parameters
    current_seq = list(best_seq)
    current_cost = best_cost

    T = 4.0               # Initial temperature (heuristic based on typical cost diffs)
    ALPHA = 0.95          # Cooling rate
    MIN_T = 0.1           # Stop temperature
    MAX_ITER = 600        # Safety break

    iter_count = 0
    while T > MIN_T and iter_count < MAX_ITER:
        iter_count += 1

        # 1. Generate Neighbor
        # 50% chance of simple Swap, 50% chance of Shift (Insertion)
        move_type = random.random()
        new_seq = list(current_seq)

        if move_type < 0.5:
            # Swap Adjacent
            if len(new_seq) < 2: continue
            idx = random.randint(0, len(new_seq) - 2)
            new_seq[idx], new_seq[idx+1] = new_seq[idx+1], new_seq[idx]
        else:
            # Shift (Insert)
            if len(new_seq) < 2: continue
            idx_from = random.randint(0, len(new_seq) - 1)
            idx_to = random.randint(0, len(new_seq) - 1)
            if idx_from == idx_to: continue
            txn = new_seq.pop(idx_from)
            new_seq.insert(idx_to, txn)

        # 2. Evaluate
        new_cost = workload.get_opt_seq_cost(new_seq)
        delta = new_cost - current_cost

        # 3. Acceptance Criterion (Metropolis)
        # If better (delta < 0), always accept.
        # If worse, accept with prob exp(-delta/T)
        if delta < 0 or random.random() < math.exp(-delta / T):
            current_seq = new_seq
            current_cost = new_cost

            # Update global best if found
            if current_cost < best_cost:
                best_cost = current_cost
                best_seq = list(current_seq)

        # Cool down
        T *= ALPHA

    return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>

<NAME>
adjust_random_costs_params
</NAME>

<DESCRIPTION>
Set `NUM_SEQS` to 10 in `get_random_costs` and explicitly use it in function calls to balance execution time with the new Simualted Annealing phase.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_random_costs():
    """
    Evaluate scheduling algorithm on three different workloads.

    Returns:
        Tuple of (total_makespan, list_of_schedules, execution_time)
    """
    start_time = time.time()
    workload_size = 100

    # Workload 1: Complex mixed read/write transactions
    workload = Workload(WORKLOAD_1)
    makespan1, schedule1 = get_best_schedule(workload, 10)
    cost1 = workload.get_opt_seq_cost(schedule1)

    # Workload 2: Simple read-then-write pattern
    workload2 = Workload(WORKLOAD_2)
    makespan2, schedule2 = get_best_schedule(workload2, 10)
    cost2 = workload2.get_opt_seq_cost(schedule2)

    # Workload 3: Minimal read/write operations
    workload3 = Workload(WORKLOAD_3)
    makespan3, schedule3 = get_best_schedule(workload3, 10)
    cost3 = workload3.get_opt_seq_cost(schedule3)

    total_makespan = cost1 + cost2 + cost3
    schedules = [schedule1, schedule2, schedule3]
    execution_time = time.time() - start_time

    return total_makespan, schedules, execution_time
=======
def get_random_costs():
    """
    Evaluate scheduling algorithm on three different workloads.

    Returns:
        Tuple of (total_makespan, list_of_schedules, execution_time)
    """
    start_time = time.time()
    # NUM_SEQS = 10 provides a good balance between exploration (multiple starts)
    # and exploitation (Simulated Annealing on the best candidate).
    NUM_SEQS = 10

    # Workload 1: Complex mixed read/write transactions
    workload = Workload(WORKLOAD_1)
    makespan1, schedule1 = get_best_schedule(workload, NUM_SEQS)
    cost1 = workload.get_opt_seq_cost(schedule1)

    # Workload 2: Simple read-then-write pattern
    workload2 = Workload(WORKLOAD_2)
    makespan2, schedule2 = get_best_schedule(workload2, NUM_SEQS)
    cost2 = workload2.get_opt_seq_cost(schedule2)

    # Workload 3: Minimal read/write operations
    workload3 = Workload(WORKLOAD_3)
    makespan3, schedule3 = get_best_schedule(workload3, NUM_SEQS)
    cost3 = workload3.get_opt_seq_cost(schedule3)

    total_makespan = cost1 + cost2 + cost3
    schedules = [schedule1, schedule2, schedule3]
    execution_time = time.time() - start_time

    return total_makespan, schedules, execution_time
>>>>>>> REPLACE
</DIFF>