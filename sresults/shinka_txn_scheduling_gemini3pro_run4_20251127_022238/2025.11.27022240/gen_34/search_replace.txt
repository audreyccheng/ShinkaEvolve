<NAME>
improved_scheduling_lahc_sprint
</NAME>

<DESCRIPTION>
I am updating `get_best_schedule` to implement a multi-stage optimization pipeline combining:
1.  **Weighted Greedy with Dynamic Big Rocks**: Selects transactions based on a score combining makespan and duration (`cost - alpha * duration`) to prioritize packing large transactions ("Big Rocks") early. The candidate pool dynamically includes all large rocks (relative to the remaining set) and random samples.
2.  **Multi-Candidate Sprint**: Instead of optimizing only the single best greedy result, the algorithm selects the top 3 distinct schedules and runs a short "Sprint" optimization (Late Acceptance Hill Climbing) on each. This preserves structural diversity.
3.  **Marathon LAHC Refinement**: The best result from the sprint undergoes a deeper "Marathon" optimization using Late Acceptance Hill Climbing (LAHC) with Block Insert, Single Insert, and Swap operators. Block insertion helps move dependency chains without breaking them.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using greedy cost sampling with Big Rocks strategy
    and local search refinement.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    best_overall_cost = float('inf')
    best_schedule = []

    # Pre-calculate individual transaction costs (lengths) for tie-breaking
    # Longer transactions are "heavier" and should be scheduled earlier if costs are equal
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(workload.num_txns)}
    # Sort transactions by duration descending to prioritize long transactions
    sorted_txns_by_len = sorted(range(workload.num_txns), key=lambda t: txn_durations[t], reverse=True)

    # Iteratively build solutions
    for i in range(num_seqs):
        # Random starting point
        start_txn = random.randint(0, workload.num_txns - 1)
        txn_seq = [start_txn]

        remaining_txns = set(range(workload.num_txns))
        remaining_txns.remove(start_txn)
        remaining_list = list(remaining_txns)

        # Build sequence
        while remaining_list:
            candidates = set()

            # Strategy:
            # 1. First iteration: Check ALL candidates for maximum quality baseline.
            # 2. Other iterations: Hybrid sampling (Big Rocks + Random).

            if i == 0:
                # Full scan for the first sequence
                candidates = set(remaining_list)
            else:
                # "Big Rocks" - prioritize longest available transactions
                # Adding the top available long transactions helps fill "holes" early
                # or schedule bottlenecks before they become critical.
                added_rocks = 0
                target_rocks = 4
                for t in sorted_txns_by_len:
                    if t in remaining_txns:
                        candidates.add(t)
                        added_rocks += 1
                        if added_rocks >= target_rocks:
                            break

                # Random sampling for diversity
                target_total = 20
                if len(remaining_list) <= target_total:
                    candidates.update(remaining_list)
                else:
                    while len(candidates) < target_total:
                        candidates.add(random.choice(remaining_list))

            # Find best candidate
            # Criteria: Minimize new makespan, Tie-break: Maximize transaction length
            best_txn = -1
            best_cost_tuple = (float('inf'), float('-inf'))

            for t in candidates:
                cost = workload.get_opt_seq_cost(txn_seq + [t])
                # We want smallest cost, then largest length (so smallest negative length)
                cost_tuple = (cost, -txn_durations[t])

                if cost_tuple < best_cost_tuple:
                    best_cost_tuple = cost_tuple
                    best_txn = t

            # Append best found
            txn_seq.append(best_txn)
            remaining_txns.remove(best_txn)
            remaining_list.remove(best_txn)

        # Check total cost
        overall_cost = workload.get_opt_seq_cost(txn_seq)
        if overall_cost < best_overall_cost:
            best_overall_cost = overall_cost
            best_schedule = txn_seq

    # Optimization Phase: Hill Climbing with Sideways Moves
    # We accept moves that improve or maintain the cost to traverse plateaus.
    if best_schedule:
        current_schedule = list(best_schedule)
        current_cost = best_overall_cost

        # Budget for optimization
        num_optimizations = 2000

        for _ in range(num_optimizations):
            # Propose a move: 70% Insert, 30% Swap
            is_insert = random.random() < 0.7

            if is_insert:
                # Insert Move
                idx1 = random.randint(0, len(current_schedule) - 1)
                idx2 = random.randint(0, len(current_schedule) - 1)
                if idx1 == idx2:
                    continue

                item = current_schedule.pop(idx1)
                current_schedule.insert(idx2, item)

                new_cost = workload.get_opt_seq_cost(current_schedule)

                if new_cost <= current_cost:
                    current_cost = new_cost
                    # Keep move
                else:
                    # Revert insert
                    item = current_schedule.pop(idx2)
                    current_schedule.insert(idx1, item)
            else:
                # Swap Move
                idx1, idx2 = random.sample(range(len(current_schedule)), 2)
                current_schedule[idx1], current_schedule[idx2] = current_schedule[idx2], current_schedule[idx1]

                new_cost = workload.get_opt_seq_cost(current_schedule)

                if new_cost <= current_cost:
                    current_cost = new_cost
                    # Keep move
                else:
                    # Revert swap
                    current_schedule[idx1], current_schedule[idx2] = current_schedule[idx2], current_schedule[idx1]

        best_overall_cost = current_cost
        best_schedule = current_schedule

    return best_overall_cost, best_schedule
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using Weighted Greedy Construction, Sprint Refinement, and LAHC.

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    # 1. Pre-calculation
    # Compute transaction durations for heuristic guidance
    txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(workload.num_txns)}
    # Sort transactions by duration (descending) for Big Rocks lookup
    sorted_txns_by_len = sorted(range(workload.num_txns), key=lambda t: txn_durations[t], reverse=True)

    candidates_pool = []

    # 2. Greedy Construction Phase
    for i in range(num_seqs):
        start_txn = random.randint(0, workload.num_txns - 1)
        txn_seq = [start_txn]

        remaining_txns = set(range(workload.num_txns))
        remaining_txns.remove(start_txn)

        while remaining_txns:
            candidates = set()

            if i == 0:
                # Full scan for first sequence (Baseline)
                candidates = remaining_txns
            else:
                # Dynamic Big Rocks Heuristic
                # Identify max duration in remaining set
                max_dur = 0
                for t in sorted_txns_by_len:
                    if t in remaining_txns:
                        max_dur = txn_durations[t]
                        break

                # Threshold: 90% of the longest remaining transaction
                threshold = max_dur * 0.90

                # Add Big Rocks
                rocks_added = 0
                for t in sorted_txns_by_len:
                    if t in remaining_txns:
                        if txn_durations[t] >= threshold:
                            candidates.add(t)
                            rocks_added += 1
                            if rocks_added >= 6:
                                break
                        else:
                            break

                # Add random samples
                if len(remaining_txns) > 20:
                    pool_list = list(remaining_txns)
                    # Sample 15 random items
                    candidates.update(random.sample(pool_list, min(15, len(pool_list))))
                else:
                    candidates.update(remaining_txns)

            # Weighted Selection
            # Score = cost - (alpha * duration)
            # Allows trading a bit of makespan for scheduling a large rock early
            best_t = -1
            best_score = float('inf')
            alpha = 0.4

            for t in candidates:
                cost = workload.get_opt_seq_cost(txn_seq + [t])
                score = cost - (alpha * txn_durations[t])

                if score < best_score:
                    best_score = score
                    best_t = t
                elif score == best_score:
                    # Tie-break: prefer longer duration
                    if txn_durations[t] > txn_durations[best_t]:
                        best_t = t

            txn_seq.append(best_t)
            remaining_txns.remove(best_t)

        total_cost = workload.get_opt_seq_cost(txn_seq)
        candidates_pool.append((total_cost, txn_seq))

    # 3. Multi-Candidate Selection (Sprint Phase)
    candidates_pool.sort(key=lambda x: x[0])

    unique_candidates = []
    seen_costs = set()
    for cost, seq in candidates_pool:
        if cost not in seen_costs:
            unique_candidates.append((cost, list(seq)))
            seen_costs.add(cost)
        if len(unique_candidates) >= 3:
            break

    if not unique_candidates and candidates_pool:
        unique_candidates = [(candidates_pool[0][0], list(candidates_pool[0][1]))]

    # Helper: Late Acceptance Hill Climbing (LAHC)
    def run_lahc(schedule, start_cost, budget):
        current_sched = list(schedule)
        current_cost = start_cost
        best_sched = list(schedule)
        best_cost = start_cost

        history_len = 50
        history = [start_cost] * history_len

        for k in range(budget):
            neighbor = list(current_sched)
            op_rand = random.random()

            # Operators: 60% Insert, 30% Block Insert, 10% Swap
            if op_rand < 0.60:
                # Single Insert
                idx1 = random.randint(0, len(neighbor) - 1)
                idx2 = random.randint(0, len(neighbor) - 1)
                if idx1 != idx2:
                    item = neighbor.pop(idx1)
                    neighbor.insert(idx2, item)

            elif op_rand < 0.90:
                # Block Insert (Move contiguous block of 2-4 items)
                block_size = random.randint(2, 4)
                if len(neighbor) > block_size:
                    start_idx = random.randint(0, len(neighbor) - block_size)
                    block = neighbor[start_idx : start_idx + block_size]
                    del neighbor[start_idx : start_idx + block_size]
                    insert_idx = random.randint(0, len(neighbor))
                    neighbor[insert_idx:insert_idx] = block
                else:
                    continue
            else:
                # Swap
                idx1, idx2 = random.sample(range(len(neighbor)), 2)
                neighbor[idx1], neighbor[idx2] = neighbor[idx2], neighbor[idx1]

            new_cost = workload.get_opt_seq_cost(neighbor)

            # LAHC Acceptance Logic
            v = k % history_len
            if new_cost <= current_cost or new_cost <= history[v]:
                current_sched = neighbor
                current_cost = new_cost
                if current_cost < best_cost:
                    best_cost = current_cost
                    best_sched = list(current_sched)

            history[v] = current_cost

        return best_cost, best_sched

    # 4. Sprint: Short optimization on top candidates
    refined_candidates = []
    for cost, seq in unique_candidates:
        imp_cost, imp_seq = run_lahc(seq, cost, 300)
        refined_candidates.append((imp_cost, imp_seq))

    # 5. Marathon: Long optimization on the winner
    refined_candidates.sort(key=lambda x: x[0])
    winner_cost, winner_seq = refined_candidates[0]

    final_cost, final_seq = run_lahc(winner_seq, winner_cost, 2500)

    return final_cost, final_seq
>>>>>>> REPLACE
</DIFF>