# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy Cost-Sampling Transaction Scheduler**
- **Implementation**: The algorithm iteratively constructs a schedule by sampling a subset of remaining transactions at each step and selecting the candidate that minimizes the current sequence's makespan cost. It employs a randomized starting point and a sample size of 10 to balance local optimization with execution speed.
- **Performance**: Achieved a combined score of 2.79, demonstrating effective reduction of total makespan across three diverse workloads.
- **Feedback**: The greedy sampling strategy effectively identifies low-cost local transitions to build efficient schedules, though the single-pass nature may limit the ability to escape local minima compared to multi-iteration approaches.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Repeated Randomized Greedy with Pairwise Local Search**
- **Implementation**: The algorithm constructs schedules by iteratively sampling a subset of candidate transactions (up to 15) to minimize partial costs, followed by an iterative adjacent-swap local search to refine the sequence.
- **Performance**: Achieved a combined score of 3.17, successfully minimizing makespan across complex, simple, and minimal read/write workloads.
- **Feedback**: Limiting the greedy search to a random sample of candidates significantly reduces computational overhead while the post-construction local search effectively corrects suboptimal placements to improve final schedule quality.
**Program Identifier:** Generation 1 - Patch Name multi_start_greedy_with_local_search - Correct Program: True

**Program Name: Beam Search with Conflict Heuristics and Local Descent**
- **Implementation:** Utilizes beam search with a read/write conflict scoring heuristic to prioritize candidates before expensive simulation, followed by a randomized adjacent-swap local descent for final refinement.
- **Performance:** Achieved a combined score of 3.04, successfully optimizing total makespan across all workloads.
- **Feedback:** The conflict heuristic effectively guides the beam search away from high-contention sequences without full simulation, while the post-processing step refines the schedule to catch local optimizations.
**Program Identifier:** Generation 2 - Patch Name beam_search_optimization - Correct Program: True

**Program Name: Stochastic Greedy Scheduling with Random Subsampling**
- **Implementation**: The algorithm builds schedules incrementally by evaluating a random sample of 15 candidate transactions at each step to minimize immediate cost, repeating the process 10 times to explore different starting points.
- **Performance**: The approach yielded a combined score of 3.07 across the three workloads.
- **Feedback**: Using a fixed sample size for the greedy step significantly improves runtime compared to an exhaustive search ($O(N)$ vs constant per step), but the reliance on local costs and random sampling risks missing globally optimal orderings.
**Program Identifier:** Generation 3 - Patch Name multi_start_greedy - Correct Program: True

**Program Name: Greedy Cost Sampling with Random Restarts**
- **Implementation**: The algorithm constructs schedules by iteratively appending the best candidate from a random sample of 10 remaining transactions based on partial makespan cost, utilizing 10 random restarts to broaden the search.
- **Performance**: The solution achieved a combined optimization score of 2.87 across the test workloads.
- **Feedback**: Limiting the greedy search to a random subset of candidates effectively reduces execution time, while the restart mechanism helps mitigate the risk of the greedy approach getting stuck in poor local optima.
**Program Identifier:** Generation 4 - Patch Name multiple_restart_greedy_scheduling - Correct Program: True

**Program Name: Hybrid Greedy Construction with Shift-Swap Local Search**
- **Implementation**: The algorithm generates initial candidates using a randomized greedy approach with an early-exit heuristic for parallel transactions, then refines the best candidate using a local search that alternates between adjacent swap descent and random insertion perturbations.
- **Performance**: Achieved a combined score of 3.12 across three workloads.
- **Feedback**: The approach effectively balances exploration via randomized construction and exploitation via deep local search, with the random insertion operator successfully helping the algorithm escape local optima.
**Program Identifier:** Generation 5 - Patch Name two_phase_greedy_insert - Correct Program: True

**Program Name: Repeated Heuristic-Filtered Greedy with Local Search**
- **Implementation**: The algorithm combines a repeated greedy construction—which filters candidates via a regex-based read/write conflict heuristic before simulator evaluation—with an adjacent-swap local search for refinement.
- **Performance**: It achieved a strong combined score of 2.91, effectively optimizing transaction ordering for minimal makespan.
- **Feedback**: The heuristic filtering significantly reduces the computational overhead of the simulator by prioritizing non-conflicting transactions. This efficiency allows for multiple restart iterations and local search passes, resulting in a robust, high-quality schedule.
**Program Identifier:** Generation 6 - Patch Name smart_greedy_conflicts - Correct Program: True

**Program Name: Randomized Greedy with Iterated Local Search Refinement**
- **Implementation**: Constructs initial schedules using a randomized greedy approach with immediate adjacent swap descent, then applies Iterated Local Search (ILS) with insertion-based perturbations to the best candidate.
- **Performance**: Achieved a combined score of 3.09, successfully balancing constructive exploration with intensive local optimization.
- **Feedback**: Applying local search immediately after greedy construction significantly improves candidate quality, while the subsequent ILS phase helps escape local optima for the final solution.
**Program Identifier:** Generation 7 - Patch Name iterated_local_search_scheduling - Correct Program: True

**Program Name: Hybrid Greedy Construction with Hill Climbing Search**
- **Implementation**: Constructs schedules using a randomized greedy strategy that evaluates a subset of next-step candidates, followed by 1000 iterations of hill-climbing pairwise swaps to refine the best schedule.
- **Performance**: Achieved a combined maximizing score of 3.32, indicating strong optimization of the total makespan.
- **Feedback**: The two-stage approach effectively balances exploration via randomized greedy sampling and exploitation via local search, improving solution quality significantly over pure greedy methods without excessive runtime.
**Program Identifier:** Generation 8 - Patch Name greedy_plus_hill_climbing - Correct Program: True

**Program Name: Repeated Greedy with Length-Based Tie-Breaking and Local Search**
- **Implementation**: This solution employs a repeated greedy construction that selects the next transaction based on minimum cost, using transaction length as a tie-breaker to fill parallel slack, followed by an adjacent swap local search.
- **Performance**: The algorithm achieved a combined maximization score of 3.25.
- **Feedback**: The "longest transaction first" tie-breaking heuristic effectively packs larger items into available parallel slots without increasing the makespan, while the local search robustly refines the initial sequence.
**Program Identifier:** Generation 9 - Patch Name greedy_length_tiebreaker - Correct Program: True

**Program Name: Hybrid Greedy Construction with Simulated Annealing Optimization**
- **Implementation**: Constructs initial schedules using a hybrid greedy strategy that alternates between full and sampled candidate evaluation, then refines the best schedule using simulated annealing with swap and insert operators.
- **Performance**: Achieved a high combined maximization score of 3.30 across three diverse workloads.
- **Feedback**: The combination of deterministic greedy initialization for quality and randomized greedy for diversity, followed by local search, effectively escapes local optima to minimize makespan.
**Program Identifier:** Generation 10 - Patch Name add_math_import - Correct Program: True

**Program Name: Hybrid Greedy Construction with Stochastic Local Search**
- **Implementation**: Builds schedules by greedily adding candidates that minimize partial makespan, selecting from the longest remaining transactions and random samples, then refines the result with swap and insert local search.
- **Performance**: Achieved a combined score of 3.46 with valid execution across all workloads.
- **Feedback**: The "Big Rocks" heuristic helps handle resource-intensive transactions early, while mixing greedy construction with local search provides a robust balance of exploration and exploitation.
**Program Identifier:** Generation 11 - Patch Name greedy_tie_break_and_insert_search - Correct Program: True

**Program Name: Hybrid Greedy-SA with Length-Based Tie-Breaking**
- **Implementation**: The solution combines a randomized greedy construction strategy that breaks ties using individual transaction lengths (Longest Processing Time) with a post-processing Simulated Annealing phase that favors insertion moves (70%) over swaps.
- **Performance**: Achieved a combined score of 3.29, successfully optimizing makespan across diverse workloads within time constraints.
- **Feedback**: The "heaviest-item" tie-breaker provides a superior initial schedule foundation, while the insertion-biased annealing effectively fine-tunes ordering by preserving relative subsequence structures better than pure swap-based mutation.
**Program Identifier:** Generation 12 - Patch Name smart_greedy_extended_sa - Correct Program: True

**Program Name: Length-Aware Greedy Construction with Hybrid Local Search**
- **Implementation**: The algorithm employs a greedy constructive heuristic that minimizes cost while using transaction length as a tie-breaker (Best Fit Descending) to prioritize complex operations. This initial schedule is refined using a two-phase local search: adjacent swap descent for fine-tuning and random insertion to escape local optima.
- **Performance**: Achieved a combined score of 3.21, demonstrating robust optimization capabilities across diverse transaction workloads.
- **Feedback**: prioritizing longer transactions during the greedy phase effectively packs complex dependencies early, while the combination of deterministic swapping and stochastic insertion prevents stagnation in local minima.
**Program Identifier:** Generation 13 - Patch Name smart_greedy_with_length_tie_break_and_shifts - Correct Program: True

**Program Name: Hybrid Big-Rocks Greedy with Hill Climbing Refinement**
- **Implementation**: The algorithm employs a multi-start greedy construction prioritizing long transactions ("Big Rocks") mixed with random sampling, followed by a hill climbing search using insertion and swap moves.
- **Performance**: The solution achieved a combined score of 3.61, successfully optimizing schedules across all three workloads.
- **Feedback**: The "Big Rocks" heuristic effectively places bottleneck transactions early, while accepting sideways moves during local search allows the algorithm to traverse plateaus and escape local optima.
**Program Identifier:** Generation 14 - Patch Name big_rocks_greedy_and_hc_refinement - Correct Program: True

**Program Name: Length-Aware Greedy Construction with Iterated Local Search**
- **Implementation**: Uses a greedy sampling strategy that prioritizes longer transactions as a tie-breaker, followed by adjacent swap descent to generate initial candidates. The best schedule is further optimized using Iterated Local Search (ILS) with random insertion perturbations and swap-based repairs.
- **Performance**: Achieved a high combined score of 3.21, effectively minimizing makespan across diverse workloads.
- **Feedback**: The length-based tie-breaking heuristic significantly improves the quality of initial candidates, while the ILS phase allows the algorithm to escape local optima that simple descent cannot resolve.
**Program Identifier:** Generation 15 - Patch Name hybrid_greedy_ils - Correct Program: True

**Program Name: Hybrid Greedy Construction with Swap and Shift Search**
- **Implementation**: The algorithm constructs schedules by selecting candidates that minimize cost and maximize length from a pool of the longest and random transactions, followed by refinement using adjacent swaps and random insertion shifts.
- **Performance**: It achieved a combined optimization score of 3.09, successfully generating valid schedules across all workloads.
- **Feedback**: Prioritizing long transactions effectively utilizes the "longest processing time" heuristic to pack expensive items early, while the shift operator allows the search to escape local optima that adjacent swaps cannot resolve due to dependencies.
**Program Identifier:** Generation 16 - Patch Name hybrid_search_smart_sampling - Correct Program: True

**Program Name: Hybrid Big Rocks Greedy Construction with Simulated Annealing**
- **Implementation**: Utilizes a greedy construction strategy that prioritizes long transactions ("Big Rocks") and random sampling to build initial solutions, followed by Simulated Annealing with insertion-heavy perturbations for refinement.
- **Performance**: Achieved a combined score of 3.36, successfully minimizing makespan across varied read/write transaction workloads.
- **Feedback**: The "Big Rocks" tie-breaking logic helps pack expensive items early to reduce tail latency, while Simulated Annealing effectively escapes local optima found during construction.
**Program Identifier:** Generation 17 - Patch Name big_rocks_sa_hybrid - Correct Program: True

**Program Name: Multi-Start Greedy Polish with Simulated Annealing**
- **Implementation**: The algorithm generates multiple initial schedules using a greedy strategy that selects transactions based on minimal cost and maximum operation count, immediately polishes each with hill climbing, and refines the best candidate using Simulated Annealing with swap and insertion moves.
- **Performance**: Achieved a combined score of 3.29, successfully optimizing the makespan across three distinct workloads.
- **Feedback**: Applying local search (polishing) immediately after greedy construction ensures that the Simulated Annealing phase starts from a high-quality local minimum, while the addition of insertion moves helps effectively reorder dependencies.
**Program Identifier:** Generation 18 - Patch Name add_math_import - Correct Program: True

**Program Name**: Greedy Sampling with Multi-Stage Local Search
- **Implementation**: Uses a greedy construction strategy mixing longest-duration transactions with random sampling, followed by a two-stage local search that refines top candidates and deeply optimizes the winner using insert and swap operations.
- **Performance**: Achieved a combined score of 3.48, successfully minimizing makespan across diverse workloads.
- **Feedback**: Prioritizing high-duration transactions during construction establishes a strong baseline, while the hierarchical local search efficiently allocates resources to polish the most promising schedule.
**Program Identifier:** Generation 19 - Patch Name multi_candidate_refinement - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

Based on the analysis of the provided program summaries (Generations 10-19) and the source code of the **Current Best Program (Generation 14)**, here are the updated optimization insights:

## Successful Algorithmic Patterns
- **"Big Rocks" Candidate Prioritization**: The most significant performance leap came from the "Big Rocks" heuristic used in **Generation 14 (Score: 3.61)**, **Generation 19 (Score: 3.48)**, and **Generation 11 (Score: 3.46)**. Unlike simple tie-breaking, this approach explicitly forces the longest available transactions (e.g., top 4) into the greedy candidate pool alongside random samples. This ensures that bottleneck operations are scheduled early while sufficient parallel slack remains.
- **Hill Climbing with Sideways Moves**: **Generation 14 (Score: 3.61)** outperformed complex Simulated Annealing approaches (e.g., Gen 17, Score 3.36) by using a Hill Climbing refinement that accepts moves with equal cost (`new_cost <= current_cost`). This allows the algorithm to traverse plateaus in the search space to escape local optima, rather than terminating immediately when no strictly better neighbor exists.
- **Insertion-Biased Mutation**: Programs that favored insertion operations over swaps during local search consistently performed well. **Generation 14** uses a 70% Insertion / 30% Swap split, and **Generation 12 (Score: 3.29)** also noted that insertion preserves relative subsequence structures better than pure swap-based mutation, effectively fine-tuning ordering without destroying dependency chains.
- **Hybrid Deterministic/Stochastic Initialization**: The best program (**Generation 14**) employs a strategy where the first greedy pass evaluates *all* candidates to establish a high-quality baseline, while subsequent passes use the "Big Rocks + Random" sampling method. This ensures the solution is never worse than a full-scan greedy attempt but benefits from randomized exploration.

## Ineffective Approaches
- **Purely Adjacent Modifications**: **Generation 16 (Score: 3.09)** and **Generation 13 (Score: 3.21)** utilized adjacent swaps or restricted scope searches. These consistently underperformed compared to global move operators (Gen 14, Gen 11), confirming that restricting the search neighborhood prevents the algorithm from resolving large-scale structural inefficiencies in the schedule.
- **Standard Simulated Annealing vs. Plateau Surfing**: While Simulated Annealing (Gen 10, 12, 17) yielded respectable scores (~3.30), it did not reach the peak performance of Gen 14 (3.61). The feedback suggests that standard cooling schedules may spend too much time exploring worse solutions or cooling too fast, whereas the "accept equal or better" (Sideways Move) strategy of Gen 14 was more efficient at navigating the specific topology of this scheduling problem within the instruction limit.
- **Over-Reliance on Tie-Breaking Alone**: Programs that relied *only* on length-based tie-breaking without forcing long transactions into the candidate pool (Gen 12, Score 3.29; Gen 15, Score 3.21) scored lower than the "Big Rocks" implementations. Merely breaking ties is insufficient if the random sampling step misses the "heavy" transactions entirely during the selection phase.

## Implementation Insights
- **Explicit "Sideways" Acceptance Logic**: The **Current Best Program (Gen 14)** implements local search acceptance as `if new_cost <= current_cost:`. This subtle implementation detail—using `<=` instead of `<`—is a critical factor enabling the high score (3.61), as it prevents the search from getting stuck on flat regions of the cost landscape.
- **Forced Candidate Injection**: In **Generation 14**, the greedy loop specifically constructs the candidate set by iterating through a pre-sorted list of transactions by duration (`sorted_txns_by_len`) and adding the first 4 available ones before filling the rest with random samples. This code pattern guarantees that the most expensive "rocks" are always considered for placement, regardless of randomness.
- **Cost-Tuple Tie-Breaking**: The effective implementation of tie-breaking in Gen 14 and Gen 19 uses Python's tuple comparison logic inside the greedy loop: `cost_tuple = (cost, -txn_durations[t])`. By minimizing this tuple, the algorithm automatically prioritizes the transaction with the longest duration (largest negative number) whenever immediate makespan costs are identical.
- **Duration Pre-calculation**: To support the "Big Rocks" strategy efficiently, the best program pre-calculates costs: `txn_durations = {t: workload.get_opt_seq_cost([t]) for t in range(workload.num_txns)}`. This avoids repeated simulation calls for single-item costs during the intensive greedy construction phase.

## Performance Analysis
- **The "Big Rocks" Performance Tier**: There is a distinct score separation based on the handling of long transactions.
    - **Explicit "Big Rocks" Selection**: ~3.46 - 3.61 (Gen 11, 14, 19).
    - **Length Tie-Breaking Only**: ~3.21 - 3.36 (Gen 12, 13, 15, 17).
    - **No Length Awareness**: < 3.10 (Gen 16, and older generations).
- **Refinement Strategy Impact**: The jump from **Generation 11 (3.46)** to **Generation 14 (3.61)** highlights the superiority of the specific local search implementation. Both used "Big Rocks," but Gen 14's specific mix of 70% insertion and plateau-surfing Hill Climbing proved significantly more effective than Gen 11's stochastic local search.
- **Convergence at Higher Optima**: The consistent movement from scores ~3.30 (Gen 8-10) to ~3.60 (Gen 14) indicates that the solution space has deeper optima that require specific structural changes (handling heavy items early) rather than just more iterations of generic optimization.
- **Robustness**: The top-performing programs (Gen 11, 14, 19) achieved their scores while maintaining valid execution across all three workloads, indicating that the greedy construction with simulation validation is a robust method for constraint satisfaction compared to earlier static heuristic attempts.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

Based on the performance analysis of Generation 14 and the global insights, here are 5 actionable recommendations for future program mutations:

1.  **Implement Late Acceptance Hill Climbing (LAHC)**: Replace the current "Sideways" Hill Climbing (`new_cost <= current_cost`) with Late Acceptance Hill Climbing, which accepts a move if the new cost is better than or equal to the cost $L$ iterations ago (e.g., $L=50$). This generalizes the successful plateau-surfing strategy of Generation 14 by allowing controlled temporary degradation to escape local optima without the complex parameter tuning of Simulated Annealing.
2.  **Adopt Multi-Candidate Refinement**: Modify the selection logic to retain the top 3 distinct schedules from the greedy sampling phase instead of just the single best one. Perform a short "pre-optimization" (e.g., 200 iterations) on each of these candidates before selecting the winner for the full optimization budget, ensuring the algorithm doesn't discard schedules that are structurally superior for refinement despite having a slightly higher initial greedy cost.
3.  **Introduce Block Insertion Operators**: Expand the insertion-heavy mutation logic (currently 70% single insertion) to include "Block Moves," where a contiguous sequence of 2-3 transactions is moved to a new position. This builds on the insight that insertion preserves ordering better than swaps, allowing the algorithm to relocate optimized dependency chains intact without breaking their internal structure.
4.  **Dynamic "Big Rocks" Candidate Pool**: Instead of a fixed limit of 4 "Big Rocks" in the greedy candidate pool, implement an adaptive threshold that includes all transactions with durations within a certain percentage (e.g., 85-90%) of the maximum remaining transaction duration. This ensures that workloads with clusters of long transactions have all critical bottlenecks evaluated for early placement, preventing the exclusion of high-impact items due to an arbitrary counter.
5.  **Weighted Score Greedy Selection**: Transition from the strict lexicographical tie-breaking `(cost, -duration)` to a weighted scoring function like `score = cost - (alpha * duration)`. This allows the greedy heuristic to tolerate a marginal increase in immediate makespan if it permits scheduling a significantly longer transaction ("Big Rock") earlier, effectively trading minor short-term inefficiency for better long-term packing.