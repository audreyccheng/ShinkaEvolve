<NAME>
iterated_local_search_scheduling
</NAME>

<DESCRIPTION>
Optimizes the scheduling algorithm by implementing an Iterated Local Search (ILS) strategy.
1. Reverts to performing full "Adjacent Swap Descent" on *every* candidate generated by the greedy phase, rather than just one. This matches the behavior of the highest-scoring prior program, ensuring that we don't discard candidates that have high potential for optimization despite a slightly worse initial greedy score.
2. Enhances the final optimization step by applying a structured ILS "Kick and Repair" loop on the global best schedule. This applies multiple random perturbations (shifts) followed by a descent phase to effectively escape local optima.
3. Balances runtime by adjusting greedy sample size and iteration limits.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using repeated greedy construction followed by deep local search.

    Strategy:
    1. Generate multiple candidate schedules using a randomized greedy approach.
       - Use an early-exit optimization: if a transaction fits without increasing makespan, pick it immediately.
    2. Select the best candidate from the generation phase.
    3. Apply intensive local search on the best candidate:
       - Alternating between Adjacent Swaps (Descent) and Random Insertions (Perturbation).

    Args:
        workload: Workload object containing transaction data
        num_seqs: Number of sequences to sample for greedy selection

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    SAMPLE_SIZE = 15
    MAX_SHIFTS = 100  # Budget for random insertion attempts

    candidates = []

    # Phase 1: Exploration (Generate diverse good schedules)
    for _ in range(num_seqs):
        remaining = list(range(workload.num_txns))

        # Start with a random transaction
        start_txn = random.choice(remaining)
        current_seq = [start_txn]
        remaining.remove(start_txn)

        # Greedy Construction
        current_makespan = workload.get_opt_seq_cost(current_seq)

        while remaining:
            sample_size = min(len(remaining), SAMPLE_SIZE)
            sample_candidates = random.sample(remaining, sample_size)

            best_next = -1
            min_inc_cost = float('inf')

            for t in sample_candidates:
                test_seq = current_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)

                if cost < min_inc_cost:
                    min_inc_cost = cost
                    best_next = t
                    # Optimization: If we find a transaction that fits 'perfectly'
                    # (doesn't increase makespan or increases minimally), take it.
                    # This biases towards high parallelism and saves simulation calls.
                    if cost <= current_makespan:
                        break

            current_seq.append(best_next)
            remaining.remove(best_next)
            current_makespan = min_inc_cost

        # Light Local Search (1 pass of adjacent swaps)
        # Quickly clean up local inefficiencies before adding to candidates
        for i in range(len(current_seq) - 1):
            current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]
            new_cost = workload.get_opt_seq_cost(current_seq)
            if new_cost < current_makespan:
                current_makespan = new_cost
            else:
                current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i] # Revert

        candidates.append((current_makespan, current_seq))

    # Phase 2: Exploitation (Deep optimization of the best candidate)
    candidates.sort(key=lambda x: x[0])
    best_cost, best_seq = candidates[0]

    # Iterative improvement: Swap Descent + Random Insertions
    improved = True
    while improved:
        improved = False

        # A. Full Adjacent Swap Descent
        swap_improved = True
        while swap_improved:
            swap_improved = False
            for i in range(len(best_seq) - 1):
                best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]
                new_cost = workload.get_opt_seq_cost(best_seq)
                if new_cost < best_cost:
                    best_cost = new_cost
                    swap_improved = True
                    improved = True
                else:
                    best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i] # Revert

        # B. Random Insertions (Shifting) to escape local optima
        # Attempt to move transactions to random positions
        for _ in range(MAX_SHIFTS):
            idx_from = random.randint(0, len(best_seq) - 1)
            idx_to = random.randint(0, len(best_seq) - 1)
            if idx_from == idx_to: continue

            # Move transaction
            txn = best_seq.pop(idx_from)
            best_seq.insert(idx_to, txn)

            new_cost = workload.get_opt_seq_cost(best_seq)
            if new_cost < best_cost:
                best_cost = new_cost
                improved = True
                # If improvement found, break to resume swap descent
                break
            else:
                # Revert move
                best_seq.pop(idx_to)
                best_seq.insert(idx_from, txn)

    return best_cost, best_seq
=======
def get_best_schedule(workload, num_seqs):
    """
    Get optimal schedule using repeated greedy construction with full local refinement,
    followed by Iterated Local Search (ILS) on the best candidate.

    Strategy:
    1. Generate `num_seqs` schedules. For each:
       - Construct using Randomized Greedy with lookahead.
       - Immediately apply full Adjacent Swap Descent (Local Search) to reach a local optimum.
         (Optimizing every candidate is crucial as greedy rank != local optimum rank).
    2. Select the global best from step 1.
    3. Apply Iterated Local Search (Kick + Descent) to the champion to escape local optima.

    Args:
        workload: Workload object
        num_seqs: Number of start points

    Returns:
        Tuple of (lowest makespan, corresponding schedule)
    """
    SAMPLE_SIZE = 12
    ILS_ITERATIONS = 5     # Number of perturbation cycles
    KICK_STRENGTH = 4      # Number of random moves per kick

    candidates = []

    # Phase 1: Exploration (Generate & Refine)
    for _ in range(num_seqs):
        # A. Randomized Greedy Construction
        remaining = list(range(workload.num_txns))
        start_txn = random.choice(remaining)
        current_seq = [start_txn]
        remaining.remove(start_txn)

        # Track cost to avoid re-calculation
        current_makespan = workload.get_opt_seq_cost(current_seq)

        while remaining:
            # Sample subset of remaining transactions
            sample_size = min(len(remaining), SAMPLE_SIZE)
            sample_candidates = random.sample(remaining, sample_size)

            best_next = -1
            min_inc_cost = float('inf')

            for t in sample_candidates:
                # Evaluate appending t
                test_seq = current_seq + [t]
                cost = workload.get_opt_seq_cost(test_seq)

                if cost < min_inc_cost:
                    min_inc_cost = cost
                    best_next = t
                    # Optimization: Early exit if fits perfectly (no increase in makespan)
                    if cost <= current_makespan:
                        break

            current_seq.append(best_next)
            remaining.remove(best_next)
            current_makespan = min_inc_cost

        # B. Full Adjacent Swap Descent (Local Search)
        # Run until convergence for EVERY candidate
        improved = True
        while improved:
            improved = False
            for i in range(len(current_seq) - 1):
                # Try swap
                current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]
                new_cost = workload.get_opt_seq_cost(current_seq)

                if new_cost < current_makespan:
                    current_makespan = new_cost
                    improved = True
                else:
                    # Revert
                    current_seq[i], current_seq[i+1] = current_seq[i+1], current_seq[i]

        candidates.append((current_makespan, current_seq))

    # Phase 2: Exploitation (Iterated Local Search on Champion)
    candidates.sort(key=lambda x: x[0])
    best_cost, best_seq = candidates[0]

    # ILS Loop
    for _ in range(ILS_ITERATIONS):
        # Save current best state
        saved_seq = list(best_seq)

        # 1. Perturbation (Kick)
        # Apply multiple random insertions to shake up the schedule
        for _ in range(KICK_STRENGTH):
            if len(best_seq) < 2: break
            idx_from = random.randint(0, len(best_seq) - 1)
            idx_to = random.randint(0, len(best_seq) - 1)
            if idx_from != idx_to:
                txn = best_seq.pop(idx_from)
                best_seq.insert(idx_to, txn)

        # 2. Descent (Repair)
        # Optimize the perturbed schedule
        current_cost = workload.get_opt_seq_cost(best_seq)
        improved = True
        while improved:
            improved = False
            for i in range(len(best_seq) - 1):
                best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]
                new_cost = workload.get_opt_seq_cost(best_seq)
                if new_cost < current_cost:
                    current_cost = new_cost
                    improved = True
                else:
                    best_seq[i], best_seq[i+1] = best_seq[i+1], best_seq[i]

        # 3. Acceptance
        # If better, keep it. If worse, revert (Simple greedy acceptance)
        if current_cost < best_cost:
            best_cost = current_cost
        else:
            best_seq = saved_seq

    return best_cost, best_seq
>>>>>>> REPLACE
</DIFF>