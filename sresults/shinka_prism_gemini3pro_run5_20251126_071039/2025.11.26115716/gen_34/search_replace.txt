<NAME>
randomized_bs_and_perturbation
</NAME>

<DESCRIPTION>
1. Enhance Binary Search: If deterministic Best-Fit Decreasing strategies fail to find a feasible packing for a given K, retry with 50 randomized shuffles of items using Best-Fit. This reduces false negatives in feasibility checks, allowing the binary search to validate tighter (lower) upper bounds for K.
2. Enhance Local Search Perturbation: Instead of repacking just the bottleneck and one partner, select up to 3 random partners (total 4 GPUs) to repack. Use a randomized density-based sort for repacking to explore diverse configurations while maintaining quality, and include a fallback to ensure feasibility. This stronger perturbation helps escape deeper local optima.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def compute_model_placement(gpu_num, models):
    """
    Compute a model placement that minimizes the maximum KVPR across all GPUs.
    Combines Binary Search with Multi-Strategy Best-Fit packing and Local Search refinement.
    """

    # Precompute model data
=======
def compute_model_placement(gpu_num, models):
    """
    Compute a model placement that minimizes the maximum KVPR across all GPUs.
    Combines Binary Search with Multi-Strategy Best-Fit packing and Local Search refinement.
    """
    import random

    # Precompute model data
>>>>>>> REPLACE
<<<<<<< SEARCH
        for key_func in strategies:
            # Best Fit Decreasing
            items_sorted = sorted(m_data, key=key_func, reverse=True)
            gpu_models = [[] for _ in range(gpu_num)]
            gpu_l = [0.0] * gpu_num
            gpu_u = [0.0] * gpu_num
            ok = True

            for item in items_sorted:
                best_g = -1
                min_residual = float('inf')

                # Check all bins
                for g in range(gpu_num):
                    # Hard mem check
                    if gpu_u[g] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue

                    # Constraint check: (L + w) <= K * (C - (U + s))
                    # Transformed: L + w + K(U + s) <= KC
                    lhs = (gpu_l[g] + item['w']) + mid * (gpu_u[g] + item['s'])
                    rhs = mid * GPU_MEM_SIZE

                    if lhs <= rhs + 1e-7:
                        # Best Fit: minimize residual capacity of transformed bin
                        res = rhs - lhs
                        if res < min_residual:
                            min_residual = res
                            best_g = g

                if best_g != -1:
                    gpu_models[best_g].append(item['obj'])
                    gpu_l[best_g] += item['w']
                    gpu_u[best_g] += item['s']
                else:
                    ok = False
                    break

            if ok:
                feasible = True
                res_placement = {i: gpu_models[i] for i in range(gpu_num)}
                break
=======
        for key_func in strategies:
            # Best Fit Decreasing
            items_sorted = sorted(m_data, key=key_func, reverse=True)
            gpu_models = [[] for _ in range(gpu_num)]
            gpu_l = [0.0] * gpu_num
            gpu_u = [0.0] * gpu_num
            ok = True

            for item in items_sorted:
                best_g = -1
                min_residual = float('inf')

                # Check all bins
                for g in range(gpu_num):
                    # Hard mem check
                    if gpu_u[g] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue

                    # Constraint check: (L + w) <= K * (C - (U + s))
                    # Transformed: L + w + K(U + s) <= KC
                    lhs = (gpu_l[g] + item['w']) + mid * (gpu_u[g] + item['s'])
                    rhs = mid * GPU_MEM_SIZE

                    if lhs <= rhs + 1e-7:
                        # Best Fit: minimize residual capacity of transformed bin
                        res = rhs - lhs
                        if res < min_residual:
                            min_residual = res
                            best_g = g

                if best_g != -1:
                    gpu_models[best_g].append(item['obj'])
                    gpu_l[best_g] += item['w']
                    gpu_u[best_g] += item['s']
                else:
                    ok = False
                    break

            if ok:
                feasible = True
                res_placement = {i: gpu_models[i] for i in range(gpu_num)}
                break

        # If deterministic strategies fail, try randomized packings to reduce false negatives
        if not feasible:
            base_items = list(m_data)
            for _ in range(50):
                random.shuffle(base_items)
                gpu_models = [[] for _ in range(gpu_num)]
                gpu_l = [0.0] * gpu_num
                gpu_u = [0.0] * gpu_num
                ok = True

                for item in base_items:
                    best_g = -1
                    min_residual = float('inf')

                    for g in range(gpu_num):
                        if gpu_u[g] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue

                        lhs = (gpu_l[g] + item['w']) + mid * (gpu_u[g] + item['s'])
                        rhs = mid * GPU_MEM_SIZE

                        if lhs <= rhs + 1e-7:
                            res = rhs - lhs
                            if res < min_residual:
                                min_residual = res
                                best_g = g

                    if best_g != -1:
                        gpu_models[best_g].append(item['obj'])
                        gpu_l[best_g] += item['w']
                        gpu_u[best_g] += item['s']
                    else:
                        ok = False
                        break

                if ok:
                    feasible = True
                    res_placement = {i: gpu_models[i] for i in range(gpu_num)}
                    break
>>>>>>> REPLACE
<<<<<<< SEARCH
        else:
            # Perturbation if stuck
            candidates = [g for g in range(gpu_num) if g != bottleneck]
            if not candidates: break
            partner = random.choice(candidates)
            victims = [bottleneck, partner]

            # Extract
            repack_items = []
            for v in victims:
                repack_items.extend(current_placement[v])
                current_placement[v] = []
                loads[v] = 0.0
                used[v] = 0.0
                pressures[v] = 0.0

            random.shuffle(repack_items)

            # Greedy repack
            success = True
            for item in repack_items:
                w, s = item.req_rate / item.slo, item.model_size
                best_v = -1
                min_p = float('inf')

                for v in victims:
                    rem = GPU_MEM_SIZE - used[v] - s
                    if rem > 1e-6:
                        p = (loads[v] + w) / rem
                        if p < min_p:
                            min_p = p
                            best_v = v

                if best_v != -1:
                    current_placement[best_v].append(item)
                    loads[best_v] += w
                    used[best_v] += s
                else:
                    success = False
                    break

            if success:
                for v in victims:
                    pressures[v] = get_pressure(loads[v], used[v])
            else:
                # Revert to best known
                current_placement = {k: list(v) for k, v in best_placement.items()}
                loads = [0.0]*gpu_num
                used = [0.0]*gpu_num
                for g in range(gpu_num):
                    for m in current_placement[g]:
                        loads[g] += m.req_rate / m.slo
                        used[g] += m.model_size
                    pressures[g] = get_pressure(loads[g], used[g])
=======
        else:
            # Perturbation if stuck: Burst Kick (Multi-GPU Repack)
            candidates = [g for g in range(gpu_num) if g != bottleneck]
            if not candidates: break

            # Select 2-3 random partners to form a larger repack group
            k_partners = min(len(candidates), 3)
            partners = random.sample(candidates, k_partners)
            victims = [bottleneck] + partners

            # Extract items
            repack_items = []
            for v in victims:
                repack_items.extend(current_placement[v])
                current_placement[v] = []
                loads[v] = 0.0
                used[v] = 0.0
                pressures[v] = 0.0

            # Randomized BFD Repack
            # Sort by density with noise to explore different packings
            # Density = (req/slo)/size.
            repack_items.sort(key=lambda x: (x.req_rate/x.slo)/(x.model_size+1e-6) * random.uniform(0.8, 1.2), reverse=True)

            # Greedy repack
            success = True
            for item in repack_items:
                w, s = item.req_rate / item.slo, item.model_size
                best_v = -1
                min_p = float('inf')

                for v in victims:
                    rem = GPU_MEM_SIZE - used[v] - s
                    if rem > 1e-6:
                        p = (loads[v] + w) / rem
                        if p < min_p:
                            min_p = p
                            best_v = v

                # Fallback to any fit if min_p packing fails
                if best_v == -1:
                    for v in victims:
                        if used[v] + s <= GPU_MEM_SIZE - 1e-6:
                            best_v = v
                            break

                if best_v != -1:
                    current_placement[best_v].append(item)
                    loads[best_v] += w
                    used[best_v] += s
                else:
                    success = False
                    break

            if success:
                for v in victims:
                    pressures[v] = get_pressure(loads[v], used[v])
            else:
                # Revert to best known
                current_placement = {k: list(v) for k, v in best_placement.items()}
                loads = [0.0]*gpu_num
                used = [0.0]*gpu_num
                for g in range(gpu_num):
                    for m in current_placement[g]:
                        loads[g] += m.req_rate / m.slo
                        used[g] += m.model_size
                    pressures[g] = get_pressure(loads[g], used[g])
>>>>>>> REPLACE
</DIFF>