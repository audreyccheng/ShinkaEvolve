<NAME>
guided_local_search
</NAME>

<DESCRIPTION>
Replaces the Steepest Descent ILS with a "Guided Local Search". This new search strategy focuses on the bottleneck GPU and prioritizes moving or swapping items that contribute most to the pressure (sorted by workload/pressure). It uses a "First Improvement" strategy on the sorted items to find moves faster. It also replaces the "Ruin & Recreate" perturbation with "Burst Kicks" (a sequence of random atomic moves) to escape local optima more efficiently.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # 3. Refinement: Steepest Descent with Burst Kicks
    return _steepest_descent_ils(gpu_num, placement_map)

def _check_feasibility_robust(gpu_num, items, K):
=======
    # 3. Refinement: Guided Local Search with Burst Kicks
    return _guided_local_search(gpu_num, placement_map)

def _check_feasibility_robust(gpu_num, items, K):
>>>>>>> REPLACE
<<<<<<< SEARCH
def _steepest_descent_ils(gpu_num, placement):
    """
    Refines placement using Steepest Descent and LNS (Ruin & Recreate).
    """
    # State tracking
    gpu_s = [sum(m.model_size for m in placement[i]) for i in range(gpu_num)]
    gpu_w = [sum(m.req_rate / m.slo for m in placement[i]) for i in range(gpu_num)]

    def get_k(i):
        rem = GPU_MEM_SIZE - gpu_s[i]
        if rem <= 1e-7: return 1e9
        return gpu_w[i] / rem

    # Initial State
    current_ks = [get_k(i) for i in range(gpu_num)]
    best_max_k = max(current_ks)
    best_sol = copy.deepcopy(placement)

    max_steps = 1000
    patience = 50
    no_improve = 0

    for _ in range(max_steps):
        # 1. Identify Bottleneck
        # Find all GPUs close to max to avoid cycling on just the first index
        max_k_val = max(current_ks)
        candidates = [i for i, k in enumerate(current_ks) if k > max_k_val - 1e-5]
        src = random.choice(candidates) if candidates else 0
        max_k = current_ks[src]

        # 2. Update Best
        global_max = max(current_ks)
        if global_max < best_max_k - 1e-7:
            best_max_k = global_max
            best_sol = copy.deepcopy(placement)
            no_improve = 0
        else:
            no_improve += 1

        # 3. LNS Ruin & Recreate (if stuck)
        if no_improve > patience:
            # Ruin: Select bottleneck 'src' + k random others
            ruin_set = {src}
            # Pick 3 random others
            others = list(range(gpu_num))
            random.shuffle(others)
            for o in others:
                if len(ruin_set) >= min(gpu_num, 4): break
                if o != src: ruin_set.add(o)

            ruin_indices = list(ruin_set)

            # Backup current state of ruin set
            backup_models = {i: list(placement[i]) for i in ruin_indices}
            backup_s = {i: gpu_s[i] for i in ruin_indices}
            backup_w = {i: gpu_w[i] for i in ruin_indices}

            # Collect models
            repack_models = []
            for i in ruin_indices:
                repack_models.extend(placement[i])
                placement[i] = []
                gpu_s[i] = 0.0
                gpu_w[i] = 0.0

            # Sort for packing (Size Descending is robust)
            repack_models.sort(key=lambda m: m.model_size, reverse=True)

            possible = True
            # Recreate: Best-Fit greedy on local K
            for m in repack_models:
                best_target = -1
                best_local_score = float('inf')

                for r_idx in ruin_indices:
                    if gpu_s[r_idx] + m.model_size <= GPU_MEM_SIZE:
                        # Hypothetical K
                        rem = GPU_MEM_SIZE - (gpu_s[r_idx] + m.model_size)
                        k = (gpu_w[r_idx] + m.req_rate/m.slo) / (rem + 1e-9)
                        if k < best_local_score:
                            best_local_score = k
                            best_target = r_idx

                if best_target != -1:
                    placement[best_target].append(m)
                    gpu_s[best_target] += m.model_size
                    gpu_w[best_target] += m.req_rate/m.slo
                else:
                    possible = False
                    break

            if possible:
                # Update Ks
                for i in ruin_indices:
                    current_ks[i] = get_k(i)
                no_improve = 0 # Reset regardless to explore this new valley
            else:
                # Revert
                for i in ruin_indices:
                    placement[i] =