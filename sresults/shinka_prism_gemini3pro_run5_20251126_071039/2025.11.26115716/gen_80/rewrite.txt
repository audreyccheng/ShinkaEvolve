# EVOLVE-BLOCK-START
"""Model placement algorithm for minimizing maximum KV cache pressure using Robust Binary Search and LNS Peak Shaving"""

import copy
import random
import math

GPU_MEM_SIZE = 80.0  # GB

def compute_model_placement(gpu_num, models):
    """
    Minimizes max KVPR using Robust Binary Search followed by LNS with Peak Shaving.
    """
    # 1. Validation and Setup
    total_size = sum(m.model_size for m in models)
    if total_size > gpu_num * GPU_MEM_SIZE:
        raise ValueError("Total model size exceeds total GPU memory capacity.")

    # Prepare items
    items = [{'w': m.req_rate / m.slo, 's': m.model_size, 'm': m} for m in models]

    # 2. Binary Search for Initial Solution
    total_w = sum(x['w'] for x in items)
    slack = gpu_num * GPU_MEM_SIZE - total_size

    low = 0.0
    if slack < 1e-6:
        high = 1000.0
    else:
        avg_pressure = total_w / slack
        high = max(10.0, avg_pressure * 6.0)

    best_placement = None
    feasible_high = False

    # Find valid upper bound
    for _ in range(20):
        feasible, placement = _check_feasibility_robust(gpu_num, items, high)
        if feasible:
            best_placement = placement
            feasible_high = True
            break
        low = high
        high *= 2.0

    if not feasible_high:
        # Fallback for extreme cases
        high = 1e9
        feasible, placement = _check_feasibility_robust(gpu_num, items, high)
        if feasible:
            best_placement = placement
        else:
            raise ValueError("Constraints too tight.")

    # Binary Search
    for _ in range(32):
        mid = (low + high) / 2.0
        feasible, placement = _check_feasibility_robust(gpu_num, items, mid)
        if feasible:
            best_placement = placement
            high = mid
        else:
            low = mid

    placement_map = {i: best_placement[i] for i in range(gpu_num)}

    # 3. LNS Refinement
    return _lns_peak_shaving(gpu_num, placement_map)

def _check_feasibility_robust(gpu_num, items, K):
    """
    Checks feasibility using multiple sorting heuristics and Best-Fit Decreasing.
    """
    virtual_cap = K * GPU_MEM_SIZE
    pack_items = []
    for x in items:
        # Virtual size v = w + K*s
        v = x['w'] + K * x['s']
        d = x['w'] / (x['s'] + 1e-7)
        pack_items.append({'v': v, 's': x['s'], 'w': x['w'], 'd': d, 'm': x['m']})

    # Heuristics: (Sort Key, Reverse)
    heuristics = [
        (lambda x: x['v'], True),
        (lambda x: x['s'], True),
        (lambda x: x['d'], True),
        (lambda x: x['w'], True),
    ]

    for key_func, rev in heuristics:
        sorted_items = sorted(pack_items, key=key_func, reverse=rev)
        if res := _pack_bfd(gpu_num, sorted_items, virtual_cap):
            return True, res
            
    return False, None

def _pack_bfd(gpu_num, items, virtual_cap):
    """
    Best Fit Decreasing packing based on minimizing residual Virtual Capacity.
    """
    bins_v = [0.0] * gpu_num
    bins_p = [0.0] * gpu_num
    placement = [[] for _ in range(gpu_num)]

    for item in items:
        v, s, m = item['v'], item['s'], item['m']
        best_bin = -1
        min_rem_v = float('inf')

        for i in range(gpu_num):
            if bins_p[i] + s <= GPU_MEM_SIZE and bins_v[i] + v <= virtual_cap + 1e-7:
                rem = virtual_cap - (bins_v[i] + v)
                if rem < min_rem_v:
                    min_rem_v = rem
                    best_bin = i
        
        if best_bin != -1:
            bins_p[best_bin] += s
            bins_v[best_bin] += v
            placement[best_bin].append(m)
        else:
            return None
    return placement

def _lns_peak_shaving(gpu_num, placement):
    """
    Iterated Local Search with Steepest Descent and Ruin & Recreate (LNS).
    """
    # Track state
    gpu_s = [sum(m.model_size for m in placement[i]) for i in range(gpu_num)]
    gpu_w = [sum(m.req_rate / m.slo for m in placement[i]) for i in range(gpu_num)]

    def get_k(i):
        rem = GPU_MEM_SIZE - gpu_s[i]
        if rem <= 1e-7: return 1e9
        return gpu_w[i] / rem

    best_sol = copy.deepcopy(placement)
    ks = [get_k(i) for i in range(gpu_num)]
    best_max_k = max(ks)
    
    no_improve = 0
    max_steps = 400
    patience = 20
    
    for step in range(max_steps):
        ks = [get_k(i) for i in range(gpu_num)]
        max_k = max(ks)
        
        # Update Best
        if max_k < best_max_k - 1e-7:
            best_max_k = max_k
            best_sol = copy.deepcopy(placement)
            no_improve = 0
        else:
            no_improve += 1
            
        # Strategy Decision
        # 1. Steepest Descent (Moves/Swaps)
        # 2. LNS (Ruin & Recreate) if stuck
        
        bottlenecks = [i for i, k in enumerate(ks) if k > max_k - 1e-5]
        src = random.choice(bottlenecks)
        
        if no_improve <= patience:
            # --- STEEPEST DESCENT ---
            best_move = None
            best_imp = 0.0
            
            # Check Moves from SRC
            for i, m in enumerate(placement[src]):
                s, w = m.model_size, m.req_rate/m.slo
                for dst in range(gpu_num):
                    if dst == src: continue
                    if gpu_s[dst] + s > GPU_MEM_SIZE: continue
                    
                    nk_src = (gpu_w[src] - w) / (GPU_MEM_SIZE - (gpu_s[src]-s) + 1e-9)
                    nk_dst = (gpu_w[dst] + w) / (GPU_MEM_SIZE - (gpu_s[dst]+s) + 1e-9)
                    
                    new_max = max(nk_src, nk_dst)
                    if new_max < max_k - 1e-7:
                        imp = max_k - new_max
                        if imp > best_imp:
                            best_imp = imp
                            best_move = ('move', i, dst, s, w)
            
            # Check Swaps (only if move isn't great)
            if best_imp < 1.0:
                for i1, m1 in enumerate(placement[src]):
                    s1, w1 = m1.model_size, m1.req_rate/m1.slo
                    for dst in range(gpu_num):
                        if dst == src: continue
                        if ks[dst] > max_k * 0.9: continue # Optimization
                        
                        for i2, m2 in enumerate(placement[dst]):
                            s2, w2 = m2.model_size, m2.req_rate/m2.slo
                            ns_src = gpu_s[src] - s1 + s2
                            ns_dst = gpu_s[dst] - s2 + s1
                            if ns_src > GPU_MEM_SIZE or ns_dst > GPU_MEM_SIZE: continue
                            
                            nk_src = (gpu_w[src]-w1+w2) / (GPU_MEM_SIZE - ns_src + 1e-9)
                            nk_dst = (gpu_w[dst]-w2+w1) / (GPU_MEM_SIZE - ns_dst + 1e-9)
                            
                            new_max = max(nk_src, nk_dst)
                            if new_max < max_k - 1e-7:
                                imp = max_k - new_max
                                if imp > best_imp:
                                    best_imp = imp
                                    best_move = ('swap', i1, dst, i2, s1, w1, s2, w2)
            
            if best_move:
                if best_move[0] == 'move':
                    _, i, dst, s, w = best_move
                    m = placement[src].pop(i)
                    placement[dst].append(m)
                    gpu_s[src] -= s; gpu_w[src] -= w
                    gpu_s[dst] += s; gpu_w[dst] += w
                else:
                    _, i1, dst, i2, s1, w1, s2, w2 = best_move
                    m1 = placement[src][i1]
                    m2 = placement[dst][i2]
                    placement[src][i1] = m2
                    placement[dst][i2] = m1
                    gpu_s[src] = gpu_s[src] - s1 + s2
                    gpu_w[src] = gpu_w[src] - w1 + w2
                    gpu_s[dst] = gpu_s[dst] - s2 + s1
                    gpu_w[dst] = gpu_w[dst] - w2 + w1
                no_improve = 0
                continue
                
        # --- RUIN & RECREATE (LNS) ---
        # If we are here, either stuck or patience exceeded
        # Select subset: Bottleneck + Min Load + Random
        subset = {src}
        
        # Find min load GPU
        min_k = float('inf')
        min_idx = -1
        for i, k in enumerate(ks):
            if k < min_k:
                min_k = k
                min_idx = i
        if min_idx != -1 and min_idx != src:
            subset.add(min_idx)
            
        # Add randoms
        candidates = [x for x in range(gpu_num) if x not in subset]
        # Number of randoms depends on failure count
        n_rand = 1 if no_improve < patience * 2 else 2
        for _ in range(n_rand):
            if candidates:
                c = random.choice(candidates)
                subset.add(c)
                candidates.remove(c)
                
        subset = list(subset)
        
        # Backup
        backup_placement = {i: list(placement[i]) for i in subset}
        backup_s = {i: gpu_s[i] for i in subset}
        backup_w = {i: gpu_w[i] for i in subset}
        
        # Ruin
        repack_models = []
        for i in subset:
            repack_models.extend(placement[i])
            placement[i] = []
            gpu_s[i] = 0.0
            gpu_w[i] = 0.0
            
        # Recreate Heuristic: Minimizing Local Peak K
        # Sort models: Density Descending
        repack_models.sort(key=lambda m: m.req_rate/m.slo / (m.model_size + 1e-7), reverse=True)
        
        feasible = True
        for m in repack_models:
            best_bin = -1
            best_local_k = float('inf')
            
            for bin_idx in subset:
                if gpu_s[bin_idx] + m.model_size <= GPU_MEM_SIZE:
                    rem = GPU_MEM_SIZE - (gpu_s[bin_idx] + m.model_size)
                    k = (gpu_w[bin_idx] + m.req_rate/m.slo) / (rem + 1e-9)
                    
                    if k < best_local_k:
                        best_local_k = k
                        best_bin = bin_idx
            
            if best_bin != -1:
                placement[best_bin].append(m)
                gpu_s[best_bin] += m.model_size
                gpu_w[best_bin] += m.req_rate/m.slo
            else:
                feasible = False
                break
                
        # Acceptance
        if feasible:
            # Check improvement
            new_subset_ks = [(gpu_w[i] / (GPU_MEM_SIZE - gpu_s[i] + 1e-9)) for i in subset]
            new_subset_max = max(new_subset_ks)
            
            # Aggressive acceptance if stuck
            threshold = max_k
            if no_improve > patience:
                threshold = max_k * 1.05 # Allow slight degradation to escape
                
            if new_subset_max < threshold:
                # Accept
                # If we actually improved the global best, reset patience
                if new_subset_max < best_max_k - 1e-7:
                    no_improve = 0
                else:
                    # Partial reset to prevent immediate re-ruin
                    no_improve = max(0, patience - 5)
            else:
                # Revert
                for i in subset:
                    placement[i] = backup_placement[i]
                    gpu_s[i] = backup_s[i]
                    gpu_w[i] = backup_w[i]
        else:
            # Revert
            for i in subset:
                placement[i] = backup_placement[i]
                gpu_s[i] = backup_s[i]
                gpu_w[i] = backup_w[i]

    return best_sol
# EVOLVE-BLOCK-END