--- a/original.py
+++ b/original.py
@@ -1,311 +1,420 @@
 # EVOLVE-BLOCK-START
 """Model placement algorithm for minimizing maximum KV cache pressure across GPUs"""
+
+import random
+import math
 
 GPU_MEM_SIZE = 80  # GB
 
 def compute_model_placement(gpu_num, models):
     """
     Compute a model placement that minimizes the maximum KVPR across all GPUs.
-    Combines Binary Search with Multi-Strategy Best-Fit packing and Local Search refinement.
+    Combines Binary Search with BFD packing and Large Neighborhood Search (LNS) refinement.
     """
 
-    # Precompute model data
+    # --- Preprocessing ---
     m_data = []
     for m in models:
-        w = m.req_rate / m.slo
+        w = m.req_rate / m.slo if m.slo > 0 else 0
         s = m.model_size
-        m_data.append({'w': w, 's': s, 'obj': m})
-
-    # --- 1. Heuristic Initialization for Binary Search Bounds ---
-    # We need a feasible upper bound.
-
-    def try_pack_with_sort(sort_key):
-        sorted_items = sorted(m_data, key=sort_key, reverse=True)
+        # Density: pressure per unit size
+        d = w / s if s > 1e-6 else 0
+        m_data.append({'w': w, 's': s, 'd': d, 'obj': m})
+
+    # --- Helper: Pressure Calculation ---
+    def get_pressure(l, u):
+        rem = GPU_MEM_SIZE - u
+        if rem <= 1e-6:
+            return float('inf') if l > 1e-6 else 0.0
+        return l / rem
+
+    # --- Phase 1: Binary Search for Initial Solution ---
+    
+    # Calculate initial bounds
+    total_w = sum(x['w'] for x in m_data)
+    total_s = sum(x['s'] for x in m_data)
+    total_rem = GPU_MEM_SIZE * gpu_num - total_s
+    # Lower bound based on total load spread over total remaining capacity
+    low_bound = total_w / total_rem if total_rem > 1e-6 else 0.0
+    
+    # Heuristic packing function for initialization
+    def pack_heuristic(sort_key_fn):
+        sorted_items = sorted(m_data, key=sort_key_fn, reverse=True)
         placements = [[] for _ in range(gpu_num)]
         loads = [0.0] * gpu_num
         used = [0.0] * gpu_num
-
+        
         for item in sorted_items:
             best_g = -1
-            best_score = float('inf')
-
+            best_p = float('inf')
+            
+            # Minimize resultant pressure
             for g in range(gpu_num):
+                if used[g] + item['s'] > GPU_MEM_SIZE - 1e-6: continue
+                
                 rem = GPU_MEM_SIZE - used[g] - item['s']
                 if rem > 1e-6:
-                    # Minimize resulting pressure
                     p = (loads[g] + item['w']) / rem
-                    if p < best_score:
-                        best_score = p
-                        best_g = g
-
+                else:
+                    p = float('inf') if (loads[g] + item['w']) > 0 else 0
+                
+                if p < best_p:
+                    best_p = p
+                    best_g = g
+            
             if best_g == -1: return None, float('inf')
+            
             placements[best_g].append(item['obj'])
             loads[best_g] += item['w']
             used[best_g] += item['s']
-
+            
         max_p = 0.0
         for g in range(gpu_num):
-            rem = GPU_MEM_SIZE - used[g]
-            if rem <= 1e-6:
-                if loads[g] > 0: return None, float('inf')
-            else:
-                max_p = max(max_p, loads[g]/rem)
+            max_p = max(max_p, get_pressure(loads[g], used[g]))
         return placements, max_p
 
-    # Try density sort (usually best)
-    init_placement, upper_bound = try_pack_with_sort(lambda x: x['w'] / x['s'] if x['s'] > 0 else 0)
-
-    # If fails, try size sort
-    if init_placement is None:
-        init_placement, upper_bound = try_pack_with_sort(lambda x: x['s'])
-
-    # If still fails, use loose bound (assuming feasible solution exists)
-    if init_placement is None:
-        upper_bound = 1000.0
-
-    # --- 2. Binary Search for Optimal K ---
-    low = 0.0
-    high = upper_bound
-    final_placement = init_placement
-
-    for _ in range(20):
+    # Try density sort to get a good upper bound
+    init_res, init_max = pack_heuristic(lambda x: x['d'])
+    if init_res:
+        best_bs_placement = init_res
+        high_bound = init_max
+    else:
+        # Fallback upper bound
+        high_bound = 1000.0
+        best_bs_placement = None
+
+    # Binary Search Loop
+    low = low_bound
+    high = high_bound
+    if high > 999 and init_res is None: high = 10.0 # Heuristic adjustment if no initial found
+    
+    for _ in range(20): 
         if high - low < 1e-4: break
         mid = (low + high) / 2.0
-
+        
         feasible = False
-        res_placement = None
-
-        # Strategies: Virtual Size, Physical Size, Load, Density
-        strategies = [
+        temp_placement = None
+        
+        # Strategies: Density, Virtual Size, Physical Size
+        sort_keys = [
+            lambda x: x['d'],
             lambda x: x['w'] + mid * x['s'],
-            lambda x: x['s'],
-            lambda x: x['w'],
-            lambda x: x['w'] / x['s'] if x['s'] > 1e-6 else 0
+            lambda x: x['s']
         ]
-
-        for key_func in strategies:
-            # Best Fit Decreasing
-            items_sorted = sorted(m_data, key=key_func, reverse=True)
-            gpu_models = [[] for _ in range(gpu_num)]
-            gpu_l = [0.0] * gpu_num
-            gpu_u = [0.0] * gpu_num
-            ok = True
-
+        
+        for key in sort_keys:
+            items_sorted = sorted(m_data, key=key, reverse=True)
+            
+            p_alloc = [[] for _ in range(gpu_num)]
+            g_l = [0.0] * gpu_num
+            g_u = [0.0] * gpu_num
+            all_fit = True
+            
             for item in items_sorted:
                 best_g = -1
-                min_residual = float('inf')
-
-                # Check all bins
+                min_slack = float('inf')
+                
+                # Check bins
                 for g in range(gpu_num):
-                    # Hard mem check
-                    if gpu_u[g] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue
-
-                    # Constraint check: (L + w) <= K * (C - (U + s))
-                    # Transformed: L + w + K(U + s) <= KC
-                    lhs = (gpu_l[g] + item['w']) + mid * (gpu_u[g] + item['s'])
-                    rhs = mid * GPU_MEM_SIZE
-
-                    if lhs <= rhs + 1e-7:
-                        # Best Fit: minimize residual capacity of transformed bin
-                        res = rhs - lhs
-                        if res < min_residual:
-                            min_residual = res
+                    if g_u[g] + item['s'] > GPU_MEM_SIZE - 1e-6: continue
+                    
+                    # Constraint: Load + w <= K * (Rem - s)
+                    rem_capacity = GPU_MEM_SIZE - g_u[g] - item['s']
+                    max_load_allowed = mid * rem_capacity
+                    current_proj_load = g_l[g] + item['w']
+                    
+                    if current_proj_load <= max_load_allowed + 1e-7:
+                        # Best Fit Decreasing: Minimize slack
+                        # Slack = Capacity_Available_Under_K - Load_Added
+                        slack = max_load_allowed - current_proj_load
+                        if slack < min_slack:
+                            min_slack = slack
                             best_g = g
-
+                
                 if best_g != -1:
-                    gpu_models[best_g].append(item['obj'])
-                    gpu_l[best_g] += item['w']
-                    gpu_u[best_g] += item['s']
+                    p_alloc[best_g].append(item['obj'])
+                    g_l[best_g] += item['w']
+                    g_u[best_g] += item['s']
                 else:
-                    ok = False
+                    all_fit = False
                     break
-
-            if ok:
+            
+            if all_fit:
                 feasible = True
-                res_placement = {i: gpu_models[i] for i in range(gpu_num)}
-                break
-
+                temp_placement = p_alloc
+                break 
+        
         if feasible:
-            final_placement = res_placement
+            best_bs_placement = temp_placement
             high = mid
         else:
             low = mid
 
-    if final_placement is None:
-        raise ValueError("Could not find feasible placement")
-
-    # --- 3. Local Search Refinement with Variance Tie-Breaking ---
-    current_placement = final_placement
-
-    # Track gpu state
-    gpu_loads = [sum(m.req_rate / m.slo for m in current_placement[g]) for g in range(gpu_num)]
-    gpu_used = [sum(m.model_size for m in current_placement[g]) for g in range(gpu_num)]
-
-    def get_pressure(l, u):
-        rem = GPU_MEM_SIZE - u
-        if rem <= 1e-6: return float('inf') if l > 1e-6 else 0.0
-        return l / rem
-
-    iter_limit = 500
-    for _ in range(iter_limit):
-        # Calculate current metrics
-        pressures = [get_pressure(gpu_loads[g], gpu_used[g]) for g in range(gpu_num)]
-        max_p = max(pressures)
-        sum_sq_p = sum(p*p for p in pressures)
-
-        # Identify bottleneck
-        bottlenecks = [g for g in range(gpu_num) if pressures[g] >= max_p - 1e-6]
-        if not bottlenecks: break
-        bn = bottlenecks[0]
-
-        best_move = None
-        # move structure: (type, partner, idx_bn, idx_pt, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_max, new_sq)
-
-        # Precompute sorted indices for max_others calculation
-        sorted_p_indices = sorted(range(gpu_num), key=lambda i: pressures[i], reverse=True)
-
-        for partner in range(gpu_num):
-            if partner == bn: continue
-
-            # Determine max_others for this (bn, partner) pair
+    if best_bs_placement is None:
+        if init_res:
+             best_bs_placement = init_res
+        else:
+             raise ValueError("No feasible placement found.")
+        
+    # --- Phase 2: Large Neighborhood Search (ILS) ---
+    current_placement = {i: list(gpu) for i, gpu in enumerate(best_bs_placement)}
+        
+    loads = [0.0] * gpu_num
+    used = [0.0] * gpu_num
+    for g in range(gpu_num):
+        for m in current_placement[g]:
+            loads[g] += m.req_rate / m.slo
+            used[g] += m.model_size
+            
+    pressures = [get_pressure(loads[g], used[g]) for g in range(gpu_num)]
+    
+    best_max_p = max(pressures)
+    best_global_placement = {k: list(v) for k,v in current_placement.items()}
+    
+    # ILS Parameters
+    iterations = 250
+    
+    for _ in range(iterations):
+        # 1. Metrics & Global Best Update
+        current_max = max(pressures)
+        current_sq = sum(p*p for p in pressures)
+        
+        if current_max < best_max_p - 1e-8:
+            best_max_p = current_max
+            best_global_placement = {k: list(v) for k,v in current_placement.items()}
+            
+        # 2. Identify Bottleneck
+        # Sort GPUs by pressure
+        sorted_gpus = sorted(range(gpu_num), key=lambda g: pressures[g], reverse=True)
+        bottleneck = sorted_gpus[0]
+        
+        # 3. Descent (Best-Improvement in Neighborhood)
+        best_move = None 
+        # (type, partner, idx_bn, idx_pt, n_bl, n_bu, n_pl, n_pu, n_max, n_sq)
+        
+        # Precompute top pressures for fast max check
+        # We need the max pressure of all GPUs excluding bottleneck and partner
+        top_indices = sorted_gpus[:3]
+        
+        # Define neighborhood: Bottleneck <-> All Partners
+        # Optimization: Filter partners? No, check all to find best relief.
+        partners = [g for g in range(gpu_num) if g != bottleneck]
+        
+        bn_items = current_placement[bottleneck]
+        
+        for partner in partners:
+            # Determine max_others
             max_others = 0.0
-            for k in range(min(3, len(sorted_p_indices))):
-                idx = sorted_p_indices[k]
-                if idx != bn and idx != partner:
-                    max_others = pressures[idx]
+            for g_idx in top_indices:
+                if g_idx != bottleneck and g_idx != partner:
+                    max_others = pressures[g_idx]
                     break
-
-            # --- Try Moving an item from BN to Partner ---
-            for i, item in enumerate(current_placement[bn]):
+            
+            # Base sq sum excluding pair
+            base_sq = current_sq - pressures[bottleneck]**2 - pressures[partner]**2
+
+            # A. Try Moving Item: Bottleneck -> Partner
+            for i, m in enumerate(bn_items):
+                w, s = m.req_rate / m.slo, m.model_size
+                
+                if used[partner] + s > GPU_MEM_SIZE - 1e-6: continue
+                
+                n_bl = loads[bottleneck] - w
+                n_bu = used[bottleneck] - s
+                n_pl = loads[partner] + w
+                n_pu = used[partner] + s
+                
+                p_b = get_pressure(n_bl, n_bu)
+                p_p = get_pressure(n_pl, n_pu)
+                
+                new_max = max(max_others, p_b, p_p)
+                
+                # Strict degradation check
+                if new_max > current_max + 1e-9: continue
+                
+                new_sq = base_sq + p_b**2 + p_p**2
+                
+                # Acceptance criteria: Better Max OR (Equal Max AND Better Variance)
+                is_better = False
+                if new_max < current_max - 1e-9: is_better = True
+                elif new_max < current_max + 1e-9 and new_sq < current_sq - 1e-9: is_better = True
+                
+                if is_better:
+                    if best_move is None:
+                        best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
+                    else:
+                        # Compare with best_move found so far
+                        bm_max, bm_sq = best_move[8], best_move[9]
+                        if new_max < bm_max - 1e-9:
+                            best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
+                        elif abs(new_max - bm_max) < 1e-9 and new_sq < bm_sq - 1e-9:
+                            best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
+
+            # B. Try Swapping: Bottleneck <-> Partner
+            # Only try if we didn't find a very good move, or check anyway? 
+            # Swaps are expensive O(N*M). Do if partner not too full.
+            pt_items = current_placement[partner]
+            for i, m1 in enumerate(bn_items):
+                w1, s1 = m1.req_rate / m1.slo, m1.model_size
+                for j, m2 in enumerate(pt_items):
+                    w2, s2 = m2.req_rate / m2.slo, m2.model_size
+                    
+                    n_bu = used[bottleneck] - s1 + s2
+                    if n_bu > GPU_MEM_SIZE - 1e-6: continue
+                    n_pu = used[partner] - s2 + s1
+                    if n_pu > GPU_MEM_SIZE - 1e-6: continue
+                    
+                    n_bl = loads[bottleneck] - w1 + w2
+                    n_pl = loads[partner] - w2 + w1
+                    
+                    p_b = get_pressure(n_bl, n_bu)
+                    p_p = get_pressure(n_pl, n_pu)
+                    
+                    new_max = max(max_others, p_b, p_p)
+                    
+                    if new_max > current_max + 1e-9: continue
+                    new_sq = base_sq + p_b**2 + p_p**2
+                    
+                    is_better = False
+                    if new_max < current_max - 1e-9: is_better = True
+                    elif new_max < current_max + 1e-9 and new_sq < current_sq - 1e-9: is_better = True
+                    
+                    if is_better:
+                        if best_move is None:
+                            best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
+                        else:
+                            bm_max, bm_sq = best_move[8], best_move[9]
+                            if new_max < bm_max - 1e-9:
+                                best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
+                            elif abs(new_max - bm_max) < 1e-9 and new_sq < bm_sq - 1e-9:
+                                best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
+        
+        # Apply Move
+        if best_move:
+            type_, pt, i, j, nbl, nbu, npl, npu, _, _ = best_move
+            if type_ == 'move':
+                item = current_placement[bottleneck].pop(i)
+                current_placement[pt].append(item)
+            else:
+                item1 = current_placement[bottleneck][i]
+                item2 = current_placement[pt][j]
+                current_placement[bottleneck][i] = item2
+                current_placement[pt][j] = item1
+            
+            loads[bottleneck] = nbl
+            used[bottleneck] = nbu
+            loads[pt] = npl
+            used[pt] = npu
+            pressures[bottleneck] = get_pressure(loads[bottleneck], used[bottleneck])
+            pressures[pt] = get_pressure(loads[pt], used[pt])
+        
+        else:
+            # 4. Perturbation (Burst Kick)
+            # If stuck, destroy packing of Bottleneck + k Random Partners
+            k_partners = min(gpu_num - 1, 3)
+            if k_partners == 0: break
+            
+            victims = [bottleneck] + random.sample([g for g in range(gpu_num) if g != bottleneck], k_partners)
+            
+            repack_items = []
+            for v in victims:
+                repack_items.extend(current_placement[v])
+                current_placement[v] = []
+                loads[v] = 0.0
+                used[v] = 0.0
+                pressures[v] = 0.0
+                
+            # Randomized Density Sort
+            # Add noise to density to traverse search space
+            repack_items.sort(key=lambda x: (x.req_rate/x.slo)/(x.model_size+1e-6) * random.uniform(0.85, 1.15), reverse=True)
+            
+            # Greedy Repack into Victims
+            success_kick = True
+            for item in repack_items:
                 w, s = item.req_rate / item.slo, item.model_size
-                if gpu_used[partner] + s >= GPU_MEM_SIZE - 1e-6: continue
-
-                new_bn_l = gpu_loads[bn] - w
-                new_bn_u = gpu_used[bn] - s
-                new_pt_l = gpu_loads[partner] + w
-                new_pt_u = gpu_used[partner] + s
-
-                p_bn = get_pressure(new_bn_l, new_bn_u)
-                p_pt = get_pressure(new_pt_l, new_pt_u)
-
-                new_local_max = max(p_bn, p_pt)
-                if new_local_max > max_p + 1e-9: continue
-
-                new_global_max = max(max_others, new_local_max)
-                new_global_sq = sum_sq_p - (pressures[bn]**2 + pressures[partner]**2) + (p_bn**2 + p_pt**2)
-
-                is_better = False
-                if new_global_max < max_p - 1e-9:
-                    is_better = True
-                elif new_global_max < max_p + 1e-9 and new_global_sq < sum_sq_p - 1e-9:
-                    is_better = True
-
-                if is_better:
-                    if best_move is None or new_global_max < best_move[8] - 1e-9 or \
-                       (abs(new_global_max - best_move[8]) < 1e-9 and new_global_sq < best_move[9]):
-                        best_move = ('move', partner, i, None, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_global_max, new_global_sq)
-
-            # --- Try Swapping items ---
-            for i, m1 in enumerate(current_placement[bn]):
-                w1, s1 = m1.req_rate / m1.slo, m1.model_size
-                for j, m2 in enumerate(current_placement[partner]):
-                    w2, s2 = m2.req_rate / m2.slo, m2.model_size
-
-                    new_bn_u = gpu_used[bn] - s1 + s2
-                    if new_bn_u >= GPU_MEM_SIZE - 1e-6: continue
-                    new_pt_u = gpu_used[partner] - s2 + s1
-                    if new_pt_u >= GPU_MEM_SIZE - 1e-6: continue
-
-                    new_bn_l = gpu_loads[bn] - w1 + w2
-                    new_pt_l = gpu_loads[partner] - w2 + w1
-
-                    p_bn = get_pressure(new_bn_l, new_bn_u)
-                    p_pt = get_pressure(new_pt_l, new_pt_u)
-
-                    new_local_max = max(p_bn, p_pt)
-                    if new_local_max > max_p + 1e-9: continue
-
-                    new_global_max = max(max_others, new_local_max)
-                    new_global_sq = sum_sq_p - (pressures[bn]**2 + pressures[partner]**2) + (p_bn**2 + p_pt**2)
-
-                    is_better = False
-                    if new_global_max < max_p - 1e-9:
-                        is_better = True
-                    elif new_global_max < max_p + 1e-9 and new_global_sq < sum_sq_p - 1e-9:
-                        is_better = True
-
-                    if is_better:
-                         if best_move is None or new_global_max < best_move[8] - 1e-9 or \
-                            (abs(new_global_max - best_move[8]) < 1e-9 and new_global_sq < best_move[9]):
-                            best_move = ('swap', partner, i, j, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_global_max, new_global_sq)
-
-        if best_move:
-            m_type, partner, i, j, n_bl, n_bu, n_pl, n_pu, n_max, n_sq = best_move
-            if m_type == 'move':
-                item = current_placement[bn].pop(i)
-                current_placement[partner].append(item)
+                best_v = -1
+                best_sc = float('inf')
+                
+                for v in victims:
+                    if used[v] + s <= GPU_MEM_SIZE - 1e-6:
+                        rem = GPU_MEM_SIZE - used[v] - s
+                        sc = (loads[v] + w) / rem if rem > 1e-6 else (float('inf') if loads[v]+w > 0 else 0)
+                        if sc < best_sc:
+                            best_sc = sc
+                            best_v = v
+                
+                if best_v != -1:
+                    current_placement[best_v].append(item)
+                    loads[best_v] += w
+                    used[best_v] += s
+                else:
+                    success_kick = False
+                    break
+            
+            if success_kick:
+                for v in victims:
+                    pressures[v] = get_pressure(loads[v], used[v])
             else:
-                item1 = current_placement[bn][i]
-                item2 = current_placement[partner][j]
-                current_placement[bn][i] = item2
-                current_placement[partner][j] = item1
-
-            gpu_loads[bn] = n_bl
-            gpu_used[bn] = n_bu
-            gpu_loads[partner] = n_pl
-            gpu_used[partner] = n_pu
-        else:
-            break
-
-    return current_placement
+                # Kick failed to find feasible packing (unlikely but possible), Revert
+                current_placement = {k: list(v) for k, v in best_global_placement.items()}
+                # Recompute state
+                loads = [0.0]*gpu_num
+                used = [0.0]*gpu_num
+                for g in range(gpu_num):
+                    for m in current_placement[g]:
+                        loads[g] += m.req_rate / m.slo
+                        used[g] += m.model_size
+                pressures = [get_pressure(loads[g], used[g]) for g in range(gpu_num)]
+                
+    return best_global_placement
 
 # EVOLVE-BLOCK-END
 
 
 def run_placement(gpu_num, models):
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
 
     Returns:
         Dictionary containing GPU placements
     """
     return compute_model_placement(gpu_num, models)
 
 
 if __name__ == "__main__":
     # Test the algorithm
     import os
     import sys
 
     # Add the openevolve_examples directory to the path to import evaluator
     def find_repo_root(start_path):
         """Find the repository root by looking for openevolve_examples directory."""
         current = os.path.abspath(start_path)
         while current != os.path.dirname(current):  # Stop at filesystem root
             if os.path.exists(os.path.join(current, 'openevolve_examples', 'prism')):
                 return current
             current = os.path.dirname(current)
         raise RuntimeError("Could not find openevolve_examples directory")
 
     repo_root = find_repo_root(os.path.dirname(__file__))
     sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'prism'))
 
     from evaluator import generate_test_gpu_models, calculate_kvcache_pressure, safe_float
     import numpy as np
 
     test_cases = generate_test_gpu_models()
     all_kvpr = []
     for i, (gpu_num, gpu_models) in enumerate(test_cases):
         results = compute_model_placement(gpu_num, gpu_models)
         max_kvpr = calculate_kvcache_pressure(results)
         all_kvpr.append(safe_float(max_kvpr))
 
     avg_kvpr = np.mean(all_kvpr)
     if avg_kvpr != 0:
         avg_kvpr = 1.0 / avg_kvpr
 
     print(f"Max KVPR: {avg_kvpr:.3f}")