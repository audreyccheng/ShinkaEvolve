<NAME>
robust_ils_with_ruin_recreate
</NAME>

<DESCRIPTION>
This edit introduces two key improvements to the model placement algorithm:
1.  **Best-Fit Decreasing (BFD) in Feasibility Checks**: Extends `_check_feasibility_multi` to use BFD for items sorted by Physical Size and Load. BFD packs items into the bin with the minimal sufficient residual capacity, which often finds valid packings in tight scenarios where FFD fails.
2.  **Ruin and Recreate Perturbation**: Replaces the simple random "kick" in `_iterated_local_search` with a "Ruin and Recreate" strategy. This approach selects the bottleneck GPU, the least loaded GPU, and a random GPU, removes all their models ("Ruin"), and then greedily repacks them to minimize local peak KVPR ("Recreate"). This structural perturbation is much more effective at escaping local optima than moving a single random item.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Strategy 3: FFD on Physical Size
    pack_items.sort(key=lambda x: x[1], reverse=True)
    res = _pack_ffd(gpu_num, pack_items, virtual_cap)
    if res: return True, res

    # Strategy 4: FFD on Load (w)
    pack_items.sort(key=lambda x: x[2], reverse=True)
    res = _pack_ffd(gpu_num, pack_items, virtual_cap)
    if res: return True, res

    return False, None
=======
    # Strategy 3: FFD on Physical Size
    pack_items.sort(key=lambda x: x[1], reverse=True)
    res = _pack_ffd(gpu_num, pack_items, virtual_cap)
    if res: return True, res

    # Strategy 4: BFD on Physical Size
    res = _pack_bfd(gpu_num, pack_items, virtual_cap)
    if res: return True, res

    # Strategy 5: FFD on Load (w)
    pack_items.sort(key=lambda x: x[2], reverse=True)
    res = _pack_ffd(gpu_num, pack_items, virtual_cap)
    if res: return True, res

    # Strategy 6: BFD on Load (w)
    res = _pack_bfd(gpu_num, pack_items, virtual_cap)
    if res: return True, res

    return False, None
>>>>>>> REPLACE
<<<<<<< SEARCH
        # 3. Kick / Perturbation if stuck
        if no_improve > patience:
            # Try a few random moves to escape
            for _ in range(3):
                s_rnd = random.randint(0, gpu_num-1)
                if not placement[s_rnd]: continue

                d_rnd = random.randint(0, gpu_num-1)
                if s_rnd == d_rnd: continue

                m_idx = random.randint(0, len(placement[s_rnd])-1)
                m = placement[s_rnd][m_idx]

                if gpu_s[d_rnd] + m.model_size <= GPU_MEM_SIZE:
                    # Execute Kick
                    placement[d_rnd].append(m)
                    placement[s_rnd].pop(m_idx)
                    gpu_s[d_rnd] += m.model_size
                    gpu_w[d_rnd] += m.req_rate/m.slo
                    gpu_s[s_rnd] -= m.model_size
                    gpu_w[s_rnd] -= m.req_rate/m.slo
                    no_improve = 0
                    break
            continue
=======
        # 3. Kick / Perturbation if stuck
        if no_improve > patience:
            # Ruin and Recreate: Repack bottleneck + min load + random GPU
            # Select GPUs involved
            candidates = {src}

            # Find min load GPU
            min_k = float('inf')
            min_idx = -1
            for i in range(gpu_num):
                if i == src: continue
                k = get_kvpr(i)
                if k < min_k:
                    min_k = k
                    min_idx = i
            if min_idx != -1: candidates.add(min_idx)

            # Add random GPU
            for _ in range(5):
                r = random.randint(0, gpu_num-1)
                if r not in candidates:
                    candidates.add(r)
                    if len(candidates) >= 3: break

            target_gpus = list(candidates)

            # Save state before ruin
            backup_placement = {g: list(placement[g]) for g in target_gpus}
            backup_s = {g: gpu_s[g] for g in target_gpus}
            backup_w = {g: gpu_w[g] for g in target_gpus}

            # Collect models
            repack_models = []
            for g in target_gpus:
                repack_models.extend(placement[g])
                placement[g] = []
                gpu_s[g] = 0.0
                gpu_w[g] = 0.0

            # Sort models descending by Physical Size (hardest to pack first)
            repack_models.sort(key=lambda m: m.model_size, reverse=True)

            # Recreate: Greedy Min-Max placement
            success = True
            for m in repack_models:
                w, s = m.req_rate/m.slo, m.model_size
                best_g = -1
                best_local_k = float('inf')

                # Find best GPU among targets
                for g in target_gpus:
                    if gpu_s[g] + s <= GPU_MEM_SIZE:
                        rem = GPU_MEM_SIZE - (gpu_s[g] + s)
                        k = (gpu_w[g] + w) / rem if rem > 1e-7 else 1e9
                        if k < best_local_k:
                            best_local_k = k
                            best_g = g

                if best_g != -1:
                    placement[best_g].append(m)
                    gpu_s[best_g] += s
                    gpu_w[best_g] += w
                else:
                    success = False
                    break

            if success:
                no_improve = 0 # Reset patience
            else:
                # Revert if failed to repack
                for g in target_gpus:
                    placement[g] = backup_placement[g]
                    gpu_s[g] = backup_s[g]
                    gpu_w[g] = backup_w[g]

            continue
>>>>>>> REPLACE
</DIFF>