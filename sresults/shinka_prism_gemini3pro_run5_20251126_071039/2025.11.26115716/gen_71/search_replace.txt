<NAME>
optimize_pack_and_recreate
</NAME>

<DESCRIPTION>
1.  **Enhanced Binary Search Feasibility Check**: Increased the number of randomized shuffling trials in `can_pack` from 5 to 20. This reduces false negatives where a feasible packing exists for a tight $K$ but isn't found by the deterministic heuristics. Given the low execution time, this extra search is affordable and helps lock in better lower bounds.
2.  **Effective Size Strategy in Perturbation**: In the Ruin & Recreate phase, added a new sorting strategy based on "Effective Size" ($w + K_{best} \cdot s$). This metric, derived from the linearized pressure constraint, is more effective for minimizing pressure than simple size or load metrics. It uses the current best known max pressure as a proxy for $K$.
3.  **Increased Perturbation Diversity**: Expanded the number of perturbation trials from 9 to 12 to accommodate the new strategy and increase exploration of the search space.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # Randomized passes to reduce false negatives
        # This helps finding a feasible packing for tighter K bounds
        indices = list(range(len(m_data)))
        for _ in range(5):
            rng.shuffle(indices)
            bins_l = [0.0]*gpu_num
            bins_u = [0.0]*gpu_num
            bins_items = [[] for _ in range(gpu_num)]
            possible = True

            for idx in indices:
                item = m_data[idx]
                best_g = -1
                min_slack = float('inf')

                for g in range(gpu_num):
                    if bins_u[g] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue
                    rem = GPU_MEM_SIZE - bins_u[g] - item['s']
                    max_load = target_k * rem
                    new_load = bins_l[g] + item['w']
                    if new_load <= max_load + 1e-7:
                        slack = max_load - new_load
                        if slack < min_slack:
                            min_slack = slack
                            best_g = g

                if best_g != -1:
                    bins_l[best_g] += item['w']
                    bins_u[best_g] += item['s']
                    bins_items[best_g].append(item['obj'])
                else:
                    possible = False
                    break
            if possible:
                return bins_items

        return None
=======
        # Randomized passes to reduce false negatives
        # This helps finding a feasible packing for tighter K bounds
        indices = list(range(len(m_data)))
        for _ in range(20):
            rng.shuffle(indices)
            bins_l = [0.0]*gpu_num
            bins_u = [0.0]*gpu_num
            bins_items = [[] for _ in range(gpu_num)]
            possible = True

            for idx in indices:
                item = m_data[idx]
                best_g = -1
                min_slack = float('inf')

                # Pre-extract values
                i_w, i_s = item['w'], item['s']

                for g in range(gpu_num):
                    if bins_u[g] + i_s >= GPU_MEM_SIZE - 1e-6: continue
                    rem = GPU_MEM_SIZE - bins_u[g] - i_s
                    max_load = target_k * rem
                    new_load = bins_l[g] + i_w

                    if new_load <= max_load + 1e-7:
                        # Best Fit: minimize slack (unused capacity relative to K)
                        slack = max_load - new_load
                        if slack < min_slack:
                            min_slack = slack
                            best_g = g

                if best_g != -1:
                    bins_l[best_g] += i_w
                    bins_u[best_g] += i_s
                    bins_items[best_g].append(item['obj'])
                else:
                    possible = False
                    break
            if possible:
                return bins_items

        return None
>>>>>>> REPLACE
<<<<<<< SEARCH
        # Strategies: Density, Size, Load (with noise)
        strategies = [
            lambda x: ((x.req_rate/x.slo)/(x.model_size+1e-6)) * rng.uniform(0.8, 1.2),
            lambda x: x.model_size * rng.uniform(0.8, 1.2),
            lambda x: (x.req_rate/x.slo) * rng.uniform(0.8, 1.2)
        ]

        for i in range(9):
            iter_items = list(repack_items)
            iter_items.sort(key=strategies[i%3], reverse=True)

            l_loads = {v: 0.0 for v in victim_list}
            l_used = {v: 0.0 for v in victim_list}
            l_alloc = {v: [] for v in victim_list}
            possible = True

            for item in iter_items:
                w, s = item.req_rate/item.slo, item.model_size
                best_v = -1
                best_sc = float('inf')

                # Best Fit (Minimize pressure)
                for v in victim_list:
                    rem = GPU_MEM_SIZE - l_used[v] - s
                    if rem > 1e-6:
                        p = (l_loads[v] + w) / rem
                        if p < best_sc:
                            best_sc = p
                            best_v = v

                # Fallback
                if best_v == -1:
                    for v in victim_list:
                        if l_used[v] + s <= GPU_MEM_SIZE - 1e-6:
                            best_v = v
                            break

                if best_v != -1:
                    l_alloc[best_v].append(item)
                    l_loads[best_v] += w
                    l_used[best_v] += s
                else:
                    possible = False
                    break

            if possible:
                lm = 0.0
                for v in victim_list:
                     p = get_p(l_loads[v], l_used[v])
                     if p > lm: lm = p

                if lm < best_local_max:
                    best_local_max = lm
                    best_local = (l_alloc, l_loads, l_used)
=======
        # Strategies: Effective Size (with current K), Density, Size, Load (with noise)
        strategies = [
            lambda x: ((x.req_rate/x.slo) + best_max_p * x.model_size) * rng.uniform(0.85, 1.15),
            lambda x: ((x.req_rate/x.slo)/(x.model_size+1e-6)) * rng.uniform(0.85, 1.15),
            lambda x: x.model_size * rng.uniform(0.85, 1.15),
            lambda x: (x.req_rate/x.slo) * rng.uniform(0.85, 1.15)
        ]

        for i in range(12):
            iter_items = list(repack_items)
            iter_items.sort(key=strategies[i%4], reverse=True)

            l_loads = {v: 0.0 for v in victim_list}
            l_used = {v: 0.0 for v in victim_list}
            l_alloc = {v: [] for v in victim_list}
            possible = True

            for item in iter_items:
                w, s = item.req_rate/item.slo, item.model_size
                best_v = -1
                best_sc = float('inf')

                # Best Fit (Minimize pressure)
                for v in victim_list:
                    rem = GPU_MEM_SIZE - l_used[v] - s
                    if rem > 1e-6:
                        p = (l_loads[v] + w) / rem
                        if p < best_sc:
                            best_sc = p
                            best_v = v

                # Fallback
                if best_v == -1:
                    for v in victim_list:
                        if l_used[v] + s <= GPU_MEM_SIZE - 1e-6:
                            best_v = v
                            break

                if best_v != -1:
                    l_alloc[best_v].append(item)
                    l_loads[best_v] += w
                    l_used[best_v] += s
                else:
                    possible = False
                    break

            if possible:
                lm = 0.0
                for v in victim_list:
                     p = get_p(l_loads[v], l_used[v])
                     if p > lm: lm = p

                if lm < best_local_max:
                    best_local_max = lm
                    best_local = (l_alloc, l_loads, l_used)
>>>>>>> REPLACE
</DIFF>