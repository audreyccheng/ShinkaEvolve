<NAME>
local_search_variance_tiebreaking
</NAME>

<DESCRIPTION>
Replaces the pairwise rebalancing local search with a steepest descent approach that includes variance-based tie-breaking. This allows the algorithm to accept moves that maintain the same maximum pressure but reduce the sum of squared pressures (smoothing the load distribution), which helps the algorithm escape from plateaus where the maximum pressure cannot be immediately reduced. It considers both single-item shifts and pairwise swaps between the bottleneck GPU and all other GPUs.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- 3. Local Search Refinement (Pairwise Rebalancing) ---
    current_placement = final_placement

    # Track gpu state: loads (l) and used memory (u)
    gpu_state = []
    for g in range(gpu_num):
        l = sum(m.req_rate / m.slo for m in current_placement[g])
        u = sum(m.model_size for m in current_placement[g])
        gpu_state.append({'l': l, 'u': u, 'items': list(current_placement[g])})

    def calc_pressure(l, u):
        rem = GPU_MEM_SIZE - u
        if rem <= 1e-6: return float('inf') if l > 1e-6 else 0.0
        return l / rem

    iter_limit = 200 # Increased iteration limit for faster but more frequent updates
    for _ in range(iter_limit):
        # Identify bottleneck
        max_p = -1.0
        bottleneck = -1
        for g in range(gpu_num):
            p = calc_pressure(gpu_state[g]['l'], gpu_state[g]['u'])
            if p > max_p:
                max_p = p
                bottleneck = g

        if bottleneck == -1: break

        improved = False

        # Try to rebalance bottleneck with another GPU
        # Sort partners by pressure (try emptiest first)
        partners = list(range(gpu_num))
        partners.sort(key=lambda g: calc_pressure(gpu_state[g]['l'], gpu_state[g]['u']))

        for partner in partners:
            if partner == bottleneck: continue

            # Combine items
            items_pool = gpu_state[bottleneck]['items'] + gpu_state[partner]['items']

            # Heuristics to repack 2 bins: Load, Size, Density
            sort_keys = [
                lambda m: m.req_rate / m.slo,
                lambda m: m.model_size,
                lambda m: (m.req_rate / m.slo) / m.model_size if m.model_size > 0 else 0
            ]

            best_local_sol = None
            # We strictly want to reduce the max pressure of this pair below global max_p
            best_pair_max = max_p

            for key in sort_keys:
                sorted_items = sorted(items_pool, key=key, reverse=True)

                # Greedy Best-Fit on 2 bins
                sub_l = [0.0, 0.0]
                sub_u = [0.0, 0.0]
                sub_bins = [[], []]
                possible = True

                for item in sorted_items:
                    w = item.req_rate / item.slo
                    s = item.model_size

                    best_b = -1
                    min_res_p = float('inf')

                    for b in [0, 1]:
                        rem = GPU_MEM_SIZE - sub_u[b] - s
                        if rem > 1e-6:
                            p = (sub_l[b] + w) / rem
                            if p < min_res_p:
                                min_res_p = p
                                best_b = b

                    if best_b == -1:
                        possible = False
                        break

                    sub_l[best_b] += w
                    sub_u[best_b] += s
                    sub_bins[best_b].append(item)

                if possible:
                    p0 = calc_pressure(sub_l[0], sub_u[0])
                    p1 = calc_pressure(sub_l[1], sub_u[1])
                    pair_max = max(p0, p1)

                    if pair_max < best_pair_max - 1e-6:
                        best_pair_max = pair_max
                        best_local_sol = (sub_l, sub_u, sub_bins)

            if best_local_sol:
                # Apply update
                sl, su, sbins = best_local_sol

                gpu_state[bottleneck]['l'] = sl[0]
                gpu_state[bottleneck]['u'] = su[0]
                gpu_state[bottleneck]['items'] = sbins[0]

                gpu_state[partner]['l'] = sl[1]
                gpu_state[partner]['u'] = su[1]
                gpu_state[partner]['items'] = sbins[1]

                current_placement[bottleneck] = sbins[0]
                current_placement[partner] = sbins[1]

                improved = True
                break

        if not improved: break

    return current_placement
=======
    # --- 3. Local Search Refinement with Variance Tie-Breaking ---
    current_placement = final_placement

    # Track gpu state
    gpu_loads = [sum(m.req_rate / m.slo for m in current_placement[g]) for g in range(gpu_num)]
    gpu_used = [sum(m.model_size for m in current_placement[g]) for g in range(gpu_num)]

    def get_pressure(l, u):
        rem = GPU_MEM_SIZE - u
        if rem <= 1e-6: return float('inf') if l > 1e-6 else 0.0
        return l / rem

    iter_limit = 500
    for _ in range(iter_limit):
        # Calculate current metrics
        pressures = [get_pressure(gpu_loads[g], gpu_used[g]) for g in range(gpu_num)]
        max_p = max(pressures)
        sum_sq_p = sum(p*p for p in pressures)

        # Identify bottleneck
        bottlenecks = [g for g in range(gpu_num) if pressures[g] >= max_p - 1e-6]
        if not bottlenecks: break
        bn = bottlenecks[0]

        best_move = None
        # move structure: (type, partner, idx_bn, idx_pt, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_max, new_sq)

        # Precompute sorted indices for max_others calculation
        sorted_p_indices = sorted(range(gpu_num), key=lambda i: pressures[i], reverse=True)

        for partner in range(gpu_num):
            if partner == bn: continue

            # Determine max_others for this (bn, partner) pair
            max_others = 0.0
            for k in range(min(3, len(sorted_p_indices))):
                idx = sorted_p_indices[k]
                if idx != bn and idx != partner:
                    max_others = pressures[idx]
                    break

            # --- Try Moving an item from BN to Partner ---
            for i, item in enumerate(current_placement[bn]):
                w, s = item.req_rate / item.slo, item.model_size
                if gpu_used[partner] + s >= GPU_MEM_SIZE - 1e-6: continue

                new_bn_l = gpu_loads[bn] - w
                new_bn_u = gpu_used[bn] - s
                new_pt_l = gpu_loads[partner] + w
                new_pt_u = gpu_used[partner] + s

                p_bn = get_pressure(new_bn_l, new_bn_u)
                p_pt = get_pressure(new_pt_l, new_pt_u)

                new_local_max = max(p_bn, p_pt)
                if new_local_max > max_p + 1e-9: continue

                new_global_max = max(max_others, new_local_max)
                new_global_sq = sum_sq_p - (pressures[bn]**2 + pressures[partner]**2) + (p_bn**2 + p_pt**2)

                is_better = False
                if new_global_max < max_p - 1e-9:
                    is_better = True
                elif new_global_max < max_p + 1e-9 and new_global_sq < sum_sq_p - 1e-9:
                    is_better = True

                if is_better:
                    if best_move is None or new_global_max < best_move[8] - 1e-9 or \
                       (abs(new_global_max - best_move[8]) < 1e-9 and new_global_sq < best_move[9]):
                        best_move = ('move', partner, i, None, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_global_max, new_global_sq)

            # --- Try Swapping items ---
            for i, m1 in enumerate(current_placement[bn]):
                w1, s1 = m1.req_rate / m1.slo, m1.model_size
                for j, m2 in enumerate(current_placement[partner]):
                    w2, s2 = m2.req_rate / m2.slo, m2.model_size

                    new_bn_u = gpu_used[bn] - s1 + s2
                    if new_bn_u >= GPU_MEM_SIZE - 1e-6: continue
                    new_pt_u = gpu_used[partner] - s2 + s1
                    if new_pt_u >= GPU_MEM_SIZE - 1e-6: continue

                    new_bn_l = gpu_loads[bn] - w1 + w2
                    new_pt_l = gpu_loads[partner] - w2 + w1

                    p_bn = get_pressure(new_bn_l, new_bn_u)
                    p_pt = get_pressure(new_pt_l, new_pt_u)

                    new_local_max = max(p_bn, p_pt)
                    if new_local_max > max_p + 1e-9: continue

                    new_global_max = max(max_others, new_local_max)
                    new_global_sq = sum_sq_p - (pressures[bn]**2 + pressures[partner]**2) + (p_bn**2 + p_pt**2)

                    is_better = False
                    if new_global_max < max_p - 1e-9:
                        is_better = True
                    elif new_global_max < max_p + 1e-9 and new_global_sq < sum_sq_p - 1e-9:
                        is_better = True

                    if is_better:
                         if best_move is None or new_global_max < best_move[8] - 1e-9 or \
                            (abs(new_global_max - best_move[8]) < 1e-9 and new_global_sq < best_move[9]):
                            best_move = ('swap', partner, i, j, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_global_max, new_global_sq)

        if best_move:
            m_type, partner, i, j, n_bl, n_bu, n_pl, n_pu, n_max, n_sq = best_move
            if m_type == 'move':
                item = current_placement[bn].pop(i)
                current_placement[partner].append(item)
            else:
                item1 = current_placement[bn][i]
                item2 = current_placement[partner][j]
                current_placement[bn][i] = item2
                current_placement[partner][j] = item1

            gpu_loads[bn] = n_bl
            gpu_used[bn] = n_bu
            gpu_loads[partner] = n_pl
            gpu_used[partner] = n_pu
        else:
            break

    return current_placement
>>>>>>> REPLACE
</DIFF>