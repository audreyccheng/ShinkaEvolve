--- a/original.py
+++ b/original.py
@@ -1,462 +1,406 @@
 # EVOLVE-BLOCK-START
 """Model placement algorithm for minimizing maximum KV cache pressure across GPUs"""
 
 import random
 import math
 
 GPU_MEM_SIZE = 80  # GB
 
 def compute_model_placement(gpu_num, models):
     """
-    Compute a model placement that minimizes the maximum KVPR across all GPUs.
-    Combines Binary Search with BFD packing and Large Neighborhood Search (LNS) refinement.
+    Minimizes max KVPR using Robust Binary Search Initialization and 
+    Variance-Reduction LNS with Regret-Based Reconstruction.
     """
-
-    # --- Preprocessing ---
+    
+    # --- Data Preparation ---
+    # Precompute weights to avoid repeated division
     m_data = []
     for m in models:
         w = m.req_rate / m.slo if m.slo > 0 else 0
         s = m.model_size
-        # Density: pressure per unit size
         d = w / s if s > 1e-6 else 0
         m_data.append({'w': w, 's': s, 'd': d, 'obj': m})
-
-    # --- Helper: Pressure Calculation ---
+        
     def get_pressure(l, u):
         rem = GPU_MEM_SIZE - u
         if rem <= 1e-6:
             return float('inf') if l > 1e-6 else 0.0
         return l / rem
 
-    # --- Phase 1: Binary Search for Initial Solution ---
-
-    # Calculate initial bounds
-    total_w = sum(x['w'] for x in m_data)
-    total_s = sum(x['s'] for x in m_data)
-    total_rem = GPU_MEM_SIZE * gpu_num - total_s
-    # Lower bound based on total load spread over total remaining capacity
-    low_bound = total_w / total_rem if total_rem > 1e-6 else 0.0
-
-    # Heuristic packing function for initialization
-    def pack_heuristic(sort_key_fn):
-        sorted_items = sorted(m_data, key=sort_key_fn, reverse=True)
-        placements = [[] for _ in range(gpu_num)]
-        loads = [0.0] * gpu_num
-        used = [0.0] * gpu_num
-
-        for item in sorted_items:
-            best_g = -1
-            best_p = float('inf')
-
-            # Minimize resultant pressure
-            for g in range(gpu_num):
-                if used[g] + item['s'] > GPU_MEM_SIZE - 1e-6: continue
-
-                rem = GPU_MEM_SIZE - used[g] - item['s']
-                if rem > 1e-6:
-                    p = (loads[g] + item['w']) / rem
+    # --- Phase 1: Robust Binary Search for Initialization ---
+    
+    # We transform the problem: (Load + w) / (Cap - (Used + s)) <= K
+    # into a Bin Packing Problem: (Load + w) + K*(Used + s) <= K*Cap
+    
+    def solve_bpp_for_k(K, items_list):
+        # Strategies: Effective Size (w+Ks), Density, Physical Size
+        strategies = [
+            lambda x: x['w'] + K * x['s'],
+            lambda x: x['d'],
+            lambda x: x['s']
+        ]
+        
+        limit_val = K * GPU_MEM_SIZE
+        
+        for key_fn in strategies:
+            sorted_items = sorted(items_list, key=key_fn, reverse=True)
+            
+            # State
+            bins_l = [0.0] * gpu_num
+            bins_u = [0.0] * gpu_num
+            allocation = [[] for _ in range(gpu_num)]
+            
+            possible = True
+            for item in sorted_items:
+                w, s = item['w'], item['s']
+                eff_s = w + K * s
+                
+                # Best Fit Decreasing (Minimizing Residual Capacity)
+                best_g = -1
+                min_slack = float('inf')
+                
+                for g in range(gpu_num):
+                    # Hard constraint: Physical Memory
+                    if bins_u[g] + s > GPU_MEM_SIZE - 1e-6: continue
+                    
+                    # Soft constraint transformed to Hard: Pressure <= K
+                    curr_eff = bins_l[g] + K * bins_u[g]
+                    if curr_eff + eff_s <= limit_val + 1e-7:
+                        slack = limit_val - (curr_eff + eff_s)
+                        if slack < min_slack:
+                            min_slack = slack
+                            best_g = g
+                
+                if best_g != -1:
+                    allocation[best_g].append(item['obj'])
+                    bins_l[best_g] += w
+                    bins_u[best_g] += s
                 else:
-                    p = float('inf') if (loads[g] + item['w']) > 0 else 0
-
+                    possible = False
+                    break
+            
+            if possible:
+                return allocation
+        return None
+
+    # Determine bounds
+    tot_w = sum(x['w'] for x in m_data)
+    tot_s = sum(x['s'] for x in m_data)
+    rem_cap = gpu_num * GPU_MEM_SIZE - tot_s
+    # Theoretical lower bound
+    low = tot_w / rem_cap if rem_cap > 1e-6 else 0.0
+    
+    # Heuristic Upper Bound (First Fit Decreasing by Density)
+    high = 1000.0 # Default loose bound
+    sim_l, sim_u = [0.0]*gpu_num, [0.0]*gpu_num
+    sim_alloc = [[] for _ in range(gpu_num)]
+    
+    # Generate a greedy initial solution to set a tight upper bound
+    feasible_heuristic = True
+    for item in sorted(m_data, key=lambda x: x['d'], reverse=True):
+        best_g = -1
+        best_p = float('inf')
+        for g in range(gpu_num):
+            if sim_u[g] + item['s'] <= GPU_MEM_SIZE - 1e-6:
+                rem = GPU_MEM_SIZE - sim_u[g] - item['s']
+                p = (sim_l[g] + item['w']) / rem if rem > 1e-6 else float('inf')
                 if p < best_p:
                     best_p = p
                     best_g = g
-
-            if best_g == -1: return None, float('inf')
-
-            placements[best_g].append(item['obj'])
-            loads[best_g] += item['w']
-            used[best_g] += item['s']
-
-        max_p = 0.0
+        if best_g == -1: 
+            feasible_heuristic = False
+            break
+        sim_alloc[best_g].append(item['obj'])
+        sim_l[best_g] += item['w']
+        sim_u[best_g] += item['s']
+    
+    heuristic_placement = None
+    if feasible_heuristic:
+        max_h_p = 0.0
         for g in range(gpu_num):
-            max_p = max(max_p, get_pressure(loads[g], used[g]))
-        return placements, max_p
-
-    # Try density sort to get a good upper bound
-    init_res, init_max = pack_heuristic(lambda x: x['d'])
-    if init_res:
-        best_bs_placement = init_res
-        high_bound = init_max
-    else:
-        # Fallback upper bound
-        high_bound = 1000.0
-        best_bs_placement = None
-
-    # Binary Search Loop
-    low = low_bound
-    high = high_bound
-    if high > 999 and init_res is None: high = 10.0 # Heuristic adjustment if no initial found
-
+            p = get_pressure(sim_l[g], sim_u[g])
+            if p > max_h_p: max_h_p = p
+        high = max_h_p
+        heuristic_placement = sim_alloc
+            
+    # Binary Search
+    final_placement = heuristic_placement
+    
     for _ in range(20):
         if high - low < 1e-4: break
         mid = (low + high) / 2.0
-
-        feasible = False
-        temp_placement = None
-
-        # Strategies: Density, Virtual Size, Physical Size
-        sort_keys = [
-            lambda x: x['d'],
-            lambda x: x['w'] + mid * x['s'],
-            lambda x: x['s']
-        ]
-
-        for key in sort_keys:
-            items_sorted = sorted(m_data, key=key, reverse=True)
-
-            p_alloc = [[] for _ in range(gpu_num)]
-            g_l = [0.0] * gpu_num
-            g_u = [0.0] * gpu_num
-            all_fit = True
-
-            for item in items_sorted:
-                best_g = -1
-                min_slack = float('inf')
-
-                # Check bins
-                for g in range(gpu_num):
-                    if g_u[g] + item['s'] > GPU_MEM_SIZE - 1e-6: continue
-
-                    # Constraint: Load + w <= K * (Rem - s)
-                    rem_capacity = GPU_MEM_SIZE - g_u[g] - item['s']
-                    max_load_allowed = mid * rem_capacity
-                    current_proj_load = g_l[g] + item['w']
-
-                    if current_proj_load <= max_load_allowed + 1e-7:
-                        # Best Fit Decreasing: Minimize slack
-                        # Slack = Capacity_Available_Under_K - Load_Added
-                        slack = max_load_allowed - current_proj_load
-                        if slack < min_slack:
-                            min_slack = slack
-                            best_g = g
-
-                if best_g != -1:
-                    p_alloc[best_g].append(item['obj'])
-                    g_l[best_g] += item['w']
-                    g_u[best_g] += item['s']
-                else:
-                    all_fit = False
-                    break
-
-            if all_fit:
-                feasible = True
-                temp_placement = p_alloc
-                break
-
-        if feasible:
-            best_bs_placement = temp_placement
+        res = solve_bpp_for_k(mid, m_data)
+        if res:
+            final_placement = res
             high = mid
         else:
             low = mid
-
-    if best_bs_placement is None:
-        if init_res:
-             best_bs_placement = init_res
-        else:
-             raise ValueError("No feasible placement found.")
-
-    # --- Phase 2: Large Neighborhood Search (ILS) ---
-    current_placement = {i: list(gpu) for i, gpu in enumerate(best_bs_placement)}
-
-    loads = [0.0] * gpu_num
-    used = [0.0] * gpu_num
+            
+    if final_placement is None:
+        raise ValueError("No feasible placement found (Constraints too tight).")
+
+    # --- Phase 2: Variance-Reduction LNS ---
+    
+    # Setup state
+    current_placement = {g: list(models) for g, models in enumerate(final_placement)}
+    g_loads = [0.0] * gpu_num
+    g_used = [0.0] * gpu_num
     for g in range(gpu_num):
         for m in current_placement[g]:
-            loads[g] += m.req_rate / m.slo
-            used[g] += m.model_size
-
-    pressures = [get_pressure(loads[g], used[g]) for g in range(gpu_num)]
-
-    best_max_p = max(pressures)
-    best_global_placement = {k: list(v) for k,v in current_placement.items()}
-
-    # ILS Parameters
-    iterations = 250
-
-    for _ in range(iterations):
-        # 1. Metrics & Global Best Update
-        current_max = max(pressures)
-        current_sq = sum(p*p for p in pressures)
-
-        if current_max < best_max_p - 1e-8:
-            best_max_p = current_max
-            best_global_placement = {k: list(v) for k,v in current_placement.items()}
-
-        # 2. Identify Bottleneck
-        # Sort GPUs by pressure
-        sorted_gpus = sorted(range(gpu_num), key=lambda g: pressures[g], reverse=True)
-        bottleneck = sorted_gpus[0]
-
-        # 3. Descent (Best-Improvement in Neighborhood)
-        best_move = None
-        # (type, partner, idx_bn, idx_pt, n_bl, n_bu, n_pl, n_pu, n_max, n_sq)
-
-        # Precompute top pressures for fast max check
-        # We need the max pressure of all GPUs excluding bottleneck and partner
-        top_indices = sorted_gpus[:3]
-
-        # Define neighborhood: Bottleneck <-> All Partners
-        # Optimization: Filter partners? No, check all to find best relief.
-        partners = [g for g in range(gpu_num) if g != bottleneck]
-
+            g_loads[g] += m.req_rate / m.slo
+            g_used[g] += m.model_size
+    
+    g_pressures = [get_pressure(g_loads[g], g_used[g]) for g in range(gpu_num)]
+    
+    best_placement = {k: list(v) for k, v in current_placement.items()}
+    best_max_p = max(g_pressures)
+    
+    max_iters = 250
+    for it in range(max_iters):
+        curr_max = max(g_pressures)
+        curr_sq = sum(p*p for p in g_pressures)
+        
+        # Update Best
+        if curr_max < best_max_p - 1e-8:
+            best_max_p = curr_max
+            best_placement = {k: list(v) for k, v in current_placement.items()}
+            
+        # Sort GPUs to identify bottleneck
+        sorted_indices = sorted(range(gpu_num), key=lambda i: g_pressures[i], reverse=True)
+        bottleneck = sorted_indices[0]
+        
+        # Termination check
+        if g_pressures[bottleneck] < 1e-6: break
+
+        # --- Descent: Check moves/swaps involving Bottleneck ---
+        best_move = None 
+        # (type, partner, idx_bn, idx_pt, new_bn_l, new_bn_u, new_pt_l, new_pt_u, new_max, new_sq)
+        
         bn_items = current_placement[bottleneck]
-
-        for partner in partners:
-            # Determine max_others
+        
+        # Optimization: Scan only promising partners (all, sorted by pressure desc)
+        # Top pressures excluding bottleneck and partner
+        top_idx_cache = sorted_indices[:3]
+
+        for partner in sorted_indices[1:]: 
+            # Calculate max pressure of other GPUs (constant for this pair)
             max_others = 0.0
-            for g_idx in top_indices:
-                if g_idx != bottleneck and g_idx != partner:
-                    max_others = pressures[g_idx]
+            for tidx in top_idx_cache:
+                if tidx != bottleneck and tidx != partner:
+                    max_others = g_pressures[tidx]
                     break
-
-            # Base sq sum excluding pair
-            base_sq = current_sq - pressures[bottleneck]**2 - pressures[partner]**2
-
-            # A. Try Moving Item: Bottleneck -> Partner
+            
+            base_sq = curr_sq - g_pressures[bottleneck]**2 - g_pressures[partner]**2
+            
+            # 1. Move BN -> Partner
             for i, m in enumerate(bn_items):
-                w, s = m.req_rate / m.slo, m.model_size
-
-                if used[partner] + s > GPU_MEM_SIZE - 1e-6: continue
-
-                n_bl = loads[bottleneck] - w
-                n_bu = used[bottleneck] - s
-                n_pl = loads[partner] + w
-                n_pu = used[partner] + s
-
-                p_b = get_pressure(n_bl, n_bu)
-                p_p = get_pressure(n_pl, n_pu)
-
-                new_max = max(max_others, p_b, p_p)
-
-                # Strict degradation check
-                if new_max > current_max + 1e-9: continue
-
-                new_sq = base_sq + p_b**2 + p_p**2
-
-                # Acceptance criteria: Better Max OR (Equal Max AND Better Variance)
+                w, s = m.req_rate/m.slo, m.model_size
+                if g_used[partner] + s > GPU_MEM_SIZE - 1e-6: continue
+                
+                n_bl = g_loads[bottleneck] - w
+                n_bu = g_used[bottleneck] - s
+                n_pl = g_loads[partner] + w
+                n_pu = g_used[partner] + s
+                
+                pb = get_pressure(n_bl, n_bu)
+                pp = get_pressure(n_pl, n_pu)
+                
+                nm = max(max_others, pb, pp)
+                # Filter strict degradation
+                if nm > curr_max + 1e-9: continue
+                
+                nsq = base_sq + pb**2 + pp**2
+                
+                # Check improvement (Lexicographical: Max then SumSq)
                 is_better = False
-                if new_max < current_max - 1e-9: is_better = True
-                elif new_max < current_max + 1e-9 and new_sq < current_sq - 1e-9: is_better = True
-
+                if nm < curr_max - 1e-9: is_better = True
+                elif nm < curr_max + 1e-9 and nsq < curr_sq - 1e-9: is_better = True
+                
                 if is_better:
-                    if best_move is None:
-                        best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
-                    else:
-                        # Compare with best_move found so far
-                        bm_max, bm_sq = best_move[8], best_move[9]
-                        if new_max < bm_max - 1e-9:
-                            best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
-                        elif abs(new_max - bm_max) < 1e-9 and new_sq < bm_sq - 1e-9:
-                            best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
-
-            # B. Try Swapping: Bottleneck <-> Partner
-            # Only try if we didn't find a very good move, or check anyway?
-            # Swaps are expensive O(N*M). Do if partner not too full.
+                    if best_move is None or (nm < best_move[8] - 1e-9) or (abs(nm - best_move[8]) < 1e-9 and nsq < best_move[9]):
+                        best_move = ('move', partner, i, -1, n_bl, n_bu, n_pl, n_pu, nm, nsq)
+
+            # 2. Swap BN <-> Partner
             pt_items = current_placement[partner]
             for i, m1 in enumerate(bn_items):
-                w1, s1 = m1.req_rate / m1.slo, m1.model_size
+                w1, s1 = m1.req_rate/m1.slo, m1.model_size
                 for j, m2 in enumerate(pt_items):
-                    w2, s2 = m2.req_rate / m2.slo, m2.model_size
-
-                    n_bu = used[bottleneck] - s1 + s2
+                    w2, s2 = m2.req_rate/m2.slo, m2.model_size
+                    
+                    n_bu = g_used[bottleneck] - s1 + s2
                     if n_bu > GPU_MEM_SIZE - 1e-6: continue
-                    n_pu = used[partner] - s2 + s1
+                    n_pu = g_used[partner] - s2 + s1
                     if n_pu > GPU_MEM_SIZE - 1e-6: continue
-
-                    n_bl = loads[bottleneck] - w1 + w2
-                    n_pl = loads[partner] - w2 + w1
-
-                    p_b = get_pressure(n_bl, n_bu)
-                    p_p = get_pressure(n_pl, n_pu)
-
-                    new_max = max(max_others, p_b, p_p)
-
-                    if new_max > current_max + 1e-9: continue
-                    new_sq = base_sq + p_b**2 + p_p**2
-
+                    
+                    n_bl = g_loads[bottleneck] - w1 + w2
+                    n_pl = g_loads[partner] - w2 + w1
+                    
+                    pb = get_pressure(n_bl, n_bu)
+                    pp = get_pressure(n_pl, n_pu)
+                    
+                    nm = max(max_others, pb, pp)
+                    if nm > curr_max + 1e-9: continue
+                    nsq = base_sq + pb**2 + pp**2
+                    
                     is_better = False
-                    if new_max < current_max - 1e-9: is_better = True
-                    elif new_max < current_max + 1e-9 and new_sq < current_sq - 1e-9: is_better = True
-
+                    if nm < curr_max - 1e-9: is_better = True
+                    elif nm < curr_max + 1e-9 and nsq < curr_sq - 1e-9: is_better = True
+                    
                     if is_better:
-                        if best_move is None:
-                            best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
-                        else:
-                            bm_max, bm_sq = best_move[8], best_move[9]
-                            if new_max < bm_max - 1e-9:
-                                best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
-                            elif abs(new_max - bm_max) < 1e-9 and new_sq < bm_sq - 1e-9:
-                                best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, new_max, new_sq)
-
-        # Apply Move
+                        if best_move is None or (nm < best_move[8] - 1e-9) or (abs(nm - best_move[8]) < 1e-9 and nsq < best_move[9]):
+                             best_move = ('swap', partner, i, j, n_bl, n_bu, n_pl, n_pu, nm, nsq)
+
         if best_move:
-            type_, pt, i, j, nbl, nbu, npl, npu, _, _ = best_move
-            if type_ == 'move':
+            mtype, pt, i, j, nbl, nbu, npl, npu, _, _ = best_move
+            if mtype == 'move':
                 item = current_placement[bottleneck].pop(i)
                 current_placement[pt].append(item)
-            else:
+            else: # swap
                 item1 = current_placement[bottleneck][i]
                 item2 = current_placement[pt][j]
                 current_placement[bottleneck][i] = item2
                 current_placement[pt][j] = item1
-
-            loads[bottleneck] = nbl
-            used[bottleneck] = nbu
-            loads[pt] = npl
-            used[pt] = npu
-            pressures[bottleneck] = get_pressure(loads[bottleneck], used[bottleneck])
-            pressures[pt] = get_pressure(loads[pt], used[pt])
-
+            
+            g_loads[bottleneck], g_used[bottleneck] = nbl, nbu
+            g_loads[pt], g_used[pt] = npl, npu
+            g_pressures[bottleneck] = get_pressure(nbl, nbu)
+            g_pressures[pt] = get_pressure(npl, npu)
+            
         else:
-            # 4. Smart Perturbation (Targeted Ruin & Recreate)
-            # Strategy: Bottleneck + Least Loaded + Random Partners
-
-            # Find least loaded GPU (to help absorb bottleneck items)
-            min_p = float('inf')
-            least_loaded = -1
-            for g in range(gpu_num):
-                if g != bottleneck and pressures[g] < min_p:
-                    min_p = pressures[g]
-                    least_loaded = g
-
-            victim_set = {bottleneck}
-            if least_loaded != -1:
-                victim_set.add(least_loaded)
-
-            # Add random partners to increase neighborhood size
-            candidates = [g for g in range(gpu_num) if g not in victim_set]
-            if candidates:
-                # Add up to 2 random partners
-                k_random = min(len(candidates), 2)
-                victim_set.update(random.sample(candidates, k_random))
-
-            victims = list(victim_set)
-
-            # Extract items
-            repack_items = []
+            # --- Perturbation: Regret-Based Ruin & Recreate ---
+            # Victims: Bottleneck + Least Loaded (to absorb) + Random
+            victims = [bottleneck]
+            others = [g for g in range(gpu_num) if g != bottleneck]
+            
+            if others:
+                min_g = min(others, key=lambda g: g_pressures[g])
+                victims.append(min_g)
+                others.remove(min_g)
+                if others:
+                    victims.append(random.choice(others))
+            
+            # Ruin
+            removed_items = []
             for v in victims:
-                repack_items.extend(current_placement[v])
+                removed_items.extend(current_placement[v])
                 current_placement[v] = []
-                loads[v] = 0.0
-                used[v] = 0.0
-                pressures[v] = 0.0
-
-            # Try multiple randomized packings to find a feasible and decent local configuration
-            best_local_config = None
-            best_local_max_p = float('inf')
-
-            # 5 trials of randomized greedy
-            for _ in range(5):
-                # Shuffle then Sort with noise to create diversity
-                random.shuffle(repack_items)
-                # Density-based sort with noise is robust
-                iter_items = sorted(repack_items, key=lambda x: (x.req_rate/x.slo)/(x.model_size+1e-6) * random.uniform(0.9, 1.1), reverse=True)
-
-                l_loads = {v: 0.0 for v in victims}
-                l_used = {v: 0.0 for v in victims}
-                l_placement = {v: [] for v in victims}
-                feasible_local = True
-
-                for item in iter_items:
-                    w, s = item.req_rate / item.slo, item.model_size
-                    best_v = -1
-                    best_sc = float('inf')
-
+                g_loads[v] = 0.0
+                g_used[v] = 0.0
+                g_pressures[v] = 0.0
+                
+            # Recreate: Regret-Based Insertion
+            pending = list(removed_items)
+            random.shuffle(pending)
+            
+            feasible_recreate = True
+            
+            # Repacking loop
+            while pending:
+                candidates_info = [] # (index_in_pending, best_bin, regret)
+                
+                # Evaluate all pending items to find the one with highest regret
+                for idx, item in enumerate(pending):
+                    w, s = item.req_rate/item.slo, item.model_size
+                    
+                    # Compute costs for this item on all victims
+                    costs = []
                     for v in victims:
-                        if l_used[v] + s <= GPU_MEM_SIZE - 1e-6:
-                            rem = GPU_MEM_SIZE - l_used[v] - s
-                            if rem > 1e-6:
-                                sc = (l_loads[v] + w) / rem
-                            else:
-                                sc = float('inf') if (l_loads[v] + w) > 0 else 0
-
-                            if sc < best_sc:
-                                best_sc = sc
-                                best_v = v
-
-                    if best_v != -1:
-                        l_placement[best_v].append(item)
-                        l_loads[best_v] += w
-                        l_used[best_v] += s
-                    else:
-                        feasible_local = False
+                        if g_used[v] + s <= GPU_MEM_SIZE - 1e-6:
+                            rem = GPU_MEM_SIZE - g_used[v] - s
+                            p = (g_loads[v] + w) / rem if rem > 1e-6 else (float('inf') if g_loads[v]+w > 0 else 0)
+                            costs.append((p, v))
+                        else:
+                            costs.append((float('inf'), v))
+                    
+                    costs.sort(key=lambda x: x[0])
+                    
+                    best_cost, best_v = costs[0]
+                    if best_cost == float('inf'):
+                        feasible_recreate = False
                         break
-
-                if feasible_local:
-                    local_max = max(get_pressure(l_loads[v], l_used[v]) for v in victims)
-                    if local_max < best_local_max_p:
-                        best_local_max_p = local_max
-                        best_local_config = (l_placement, l_loads, l_used)
-
-            if best_local_config:
-                # Apply best local result
-                l_place, l_l, l_u = best_local_config
+                    
+                    second_cost = costs[1][0] if len(costs) > 1 else float('inf')
+                    regret = second_cost - best_cost
+                    if second_cost == float('inf'): regret = 1e9 # Massive regret if only one option
+                    
+                    candidates_info.append((idx, best_v, regret))
+                
+                if not feasible_recreate: break
+                
+                # Pick item with max regret (plus noise for diversity)
+                candidates_info.sort(key=lambda x: x[2] * random.uniform(0.9, 1.1), reverse=True)
+                
+                chosen = candidates_info[0]
+                c_idx, c_bin = chosen[0], chosen[1]
+                
+                # Commit placement
+                item = pending.pop(c_idx)
+                current_placement[c_bin].append(item)
+                
+                g_loads[c_bin] += item.req_rate/item.slo
+                g_used[c_bin] += item.model_size
+            
+            if feasible_recreate:
                 for v in victims:
-                    current_placement[v] = l_place[v]
-                    loads[v] = l_l[v]
-                    used[v] = l_u[v]
-                    pressures[v] = get_pressure(loads[v], used[v])
+                    g_pressures[v] = get_pressure(g_loads[v], g_used[v])
             else:
-                # Revert to global best if perturbation fails
-                current_placement = {k: list(v) for k, v in best_global_placement.items()}
-                loads = [0.0]*gpu_num
-                used = [0.0]*gpu_num
+                # Revert if failed
+                current_placement = {k: list(v) for k, v in best_placement.items()}
                 for g in range(gpu_num):
-                    for m in current_placement[g]:
-                        loads[g] += m.req_rate / m.slo
-                        used[g] += m.model_size
-                pressures = [get_pressure(loads[g], used[g]) for g in range(gpu_num)]
-
-    return best_global_placement
-
+                    g_loads[g] = sum(m.req_rate/m.slo for m in current_placement[g])
+                    g_used[g] = sum(m.model_size for m in current_placement[g])
+                    g_pressures[g] = get_pressure(g_loads[g], g_used[g])
+                
+                if it > max_iters * 0.9: break
+
+    return best_placement
 # EVOLVE-BLOCK-END
 
 
 def run_placement(gpu_num, models):
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
 
     Returns:
         Dictionary containing GPU placements
     """
     return compute_model_placement(gpu_num, models)
 
 
 if __name__ == "__main__":
     # Test the algorithm
     import os
     import sys
 
     # Add the openevolve_examples directory to the path to import evaluator
     def find_repo_root(start_path):
         """Find the repository root by looking for openevolve_examples directory."""
         current = os.path.abspath(start_path)
         while current != os.path.dirname(current):  # Stop at filesystem root
             if os.path.exists(os.path.join(current, 'openevolve_examples', 'prism')):
                 return current
             current = os.path.dirname(current)
         raise RuntimeError("Could not find openevolve_examples directory")
 
     repo_root = find_repo_root(os.path.dirname(__file__))
     sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'prism'))
 
     from evaluator import generate_test_gpu_models, calculate_kvcache_pressure, safe_float
     import numpy as np
 
     test_cases = generate_test_gpu_models()
     all_kvpr = []
     for i, (gpu_num, gpu_models) in enumerate(test_cases):
         results = compute_model_placement(gpu_num, gpu_models)
         max_kvpr = calculate_kvcache_pressure(results)
         all_kvpr.append(safe_float(max_kvpr))
 
     avg_kvpr = np.mean(all_kvpr)
     if avg_kvpr != 0:
         avg_kvpr = 1.0 / avg_kvpr
 
     print(f"Max KVPR: {avg_kvpr:.3f}")