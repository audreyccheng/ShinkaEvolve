# EVOLVE-BLOCK-START
"""Model placement algorithm for minimizing maximum KV cache pressure using Fast Robust Packing and LNS Refinement"""

import copy
import random

GPU_MEM_SIZE = 80.0  # GB

def compute_model_placement(gpu_num, models):
    """
    Minimizes max KVPR using Robust Binary Search (BFD/FFD) 
    followed by Steepest Descent LNS (Ruin & Recreate).
    """
    # 1. Validation
    total_size = sum(m.model_size for m in models)
    if total_size > gpu_num * GPU_MEM_SIZE:
        raise ValueError("Total model size exceeds total GPU memory capacity.")

    items = [{'w': m.req_rate / m.slo, 's': m.model_size, 'm': m} for m in models]

    # 2. Binary Search
    total_w = sum(x['w'] for x in items)
    slack = gpu_num * GPU_MEM_SIZE - total_size

    low = 0.0
    if slack < 1e-6:
        high = 10000.0
    else:
        avg_pressure = total_w / slack
        high = max(10.0, avg_pressure * 8.0)

    best_placement = None
    feasible_high = False

    # Exponential search for valid upper bound
    for _ in range(20):
        feasible, placement = _check_feasibility_robust(gpu_num, items, high)
        if feasible:
            best_placement = placement
            feasible_high = True
            break
        low = high
        high *= 2.0

    if not feasible_high:
        raise ValueError("Unable to place models. Constraints likely too tight.")

    # Binary Search
    for _ in range(30):
        mid = (low + high) / 2.0
        feasible, placement = _check_feasibility_robust(gpu_num, items, mid)
        if feasible:
            best_placement = placement
            high = mid
        else:
            low = mid

    placement_map = {i: best_placement[i] for i in range(gpu_num)}

    # 3. LNS Refinement
    return _lns_refinement(gpu_num, placement_map)

def _check_feasibility_robust(gpu_num, items, K):
    """
    Checks feasibility using multiple sorting strategies and packing algorithms (BFD/FFD).
    """
    virtual_cap = K * GPU_MEM_SIZE
    pack_items = []
    for x in items:
        v = x['w'] + K * x['s']
        d = x['w'] / (x['s'] + 1e-7)
        pack_items.append({'v': v, 's': x['s'], 'w': x['w'], 'd': d, 'm': x['m']})

    # Heuristics
    heuristics = [
        (lambda x: x['v'], True),  # Virtual Size Desc
        (lambda x: x['s'], True),  # Physical Size Desc
        (lambda x: x['d'], True),  # Density Desc
        (lambda x: x['w'], True),  # Load Desc
    ]

    for key_func, rev in heuristics:
        sorted_items = sorted(pack_items, key=key_func, reverse=rev)
        
        # Try BFD first (often better)
        if res := _pack_bfd(gpu_num, sorted_items, virtual_cap):
            return True, res
        # Try FFD
        if res := _pack_ffd(gpu_num, sorted_items, virtual_cap):
            return True, res

    return False, None

def _pack_ffd(gpu_num, items, virtual_cap):
    bins_v = [0.0] * gpu_num
    bins_p = [0.0] * gpu_num
    placement = [[] for _ in range(gpu_num)]
    
    for item in items:
        placed = False
        for i in range(gpu_num):
            if bins_p[i] + item['s'] <= GPU_MEM_SIZE and bins_v[i] + item['v'] <= virtual_cap + 1e-7:
                bins_p[i] += item['s']
                bins_v[i] += item['v']
                placement[i].append(item['m'])
                placed = True
                break
        if not placed: return None
    return placement

def _pack_bfd(gpu_num, items, virtual_cap):
    bins_v = [0.0] * gpu_num
    bins_p = [0.0] * gpu_num
    placement = [[] for _ in range(gpu_num)]
    
    for item in items:
        best_bin = -1
        min_rem = float('inf')
        
        for i in range(gpu_num):
            if bins_p[i] + item['s'] <= GPU_MEM_SIZE and bins_v[i] + item['v'] <= virtual_cap + 1e-7:
                rem = virtual_cap - (bins_v[i] + item['v'])
                if rem < min_rem:
                    min_rem = rem
                    best_bin = i
                    
        if best_bin != -1:
            bins_p[best_bin] += item['s']
            bins_v[best_bin] += item['v']
            placement[best_bin].append(item['m'])
        else:
            return None
    return placement

def _lns_refinement(gpu_num, placement):
    """
    Refines placement using Steepest Descent with Ruin & Recreate (LNS).
    """
    gpu_s = [sum(m.model_size for m in placement[i]) for i in range(gpu_num)]
    gpu_w = [sum(m.req_rate / m.slo for m in placement[i]) for i in range(gpu_num)]

    def get_k(i):
        rem = GPU_MEM_SIZE - gpu_s[i]
        if rem <= 1e-7: return 1e9
        return gpu_w[i] / rem

    current_ks = [get_k(i) for i in range(gpu_num)]
    best_max_k = max(current_ks)
    best_placement = copy.deepcopy(placement)

    max_steps = 500
    patience = 20
    no_improve = 0

    for step in range(max_steps):
        # 1. Identify bottleneck
        max_k = -1.0
        src = -1
        for i in range(gpu_num):
            if current_ks[i] > max_k:
                max_k = current_ks[i]
                src = i
        
        # Check global improvement
        if max_k < best_max_k - 1e-7:
            best_max_k = max_k
            best_placement = copy.deepcopy(placement)
            no_improve = 0
        else:
            no_improve += 1

        # 2. Ruin & Recreate (Diversification)
        if no_improve > patience:
            # Select subset: Bottleneck + randoms
            ruin_indices = {src}
            candidates = list(range(gpu_num))
            random.shuffle(candidates)
            # Pick 3-5 random GPUs
            limit = min(gpu_num, random.randint(3, 5))
            for c in candidates:
                if len(ruin_indices) >= limit: break
                if c != src: ruin_indices.add(c)
            
            ruin_indices = list(ruin_indices)
            
            # Backup
            backup_state = []
            repack_models = []
            for idx in ruin_indices:
                backup_state.append((idx, list(placement[idx]), gpu_s[idx], gpu_w[idx], current_ks[idx]))
                repack_models.extend(placement[idx])
                placement[idx] = []
                gpu_s[idx] = 0.0
                gpu_w[idx] = 0.0
            
            # Sort models: Physical Size Descending (packing efficiency)
            # Second key: Load Descending (handle heavy items first)
            repack_models.sort(key=lambda m: (m.model_size, m.req_rate/m.slo), reverse=True)
            
            possible = True
            for m in repack_models:
                best_idx = -1
                best_local_k = float('inf')
                
                for idx in ruin_indices:
                    if gpu_s[idx] + m.model_size <= GPU_MEM_SIZE:
                        rem = GPU_MEM_SIZE - (gpu_s[idx] + m.model_size)
                        k = (gpu_w[idx] + m.req_rate/m.slo) / (rem + 1e-9)
                        
                        if k < best_local_k:
                            best_local_k = k
                            best_idx = idx
                            
                if best_idx != -1:
                    placement[best_idx].append(m)
                    gpu_s[best_idx] += m.model_size
                    gpu_w[best_idx] += m.req_rate/m.slo
                else:
                    possible = False
                    break
            
            if possible:
                # Update Ks
                for idx in ruin_indices:
                    current_ks[idx] = get_k(idx)
                # Reset patience to allow descent from new state
                no_improve = 0 
            else:
                # Revert
                for i, p_list, s, w, k in backup_state:
                    placement[i] = p_list
                    gpu_s[i] = s
                    gpu_w[i] = w
                    current_ks[i] = k
                    
            continue

        # 3. Steepest Descent (Intensification)
        best_move = None
        src_items = sorted(enumerate(placement[src]), key=lambda x: x[1].req_rate/x[1].slo, reverse=True)
        
        # Check Moves
        for idx, m in src_items:
            w, s = m.req_rate/m.slo, m.model_size
            for dst in range(gpu_num):
                if dst == src: continue
                if gpu_s[dst] + s > GPU_MEM_SIZE: continue
                
                nk_src = (gpu_w[src] - w) / (GPU_MEM_SIZE - (gpu_s[src] - s) + 1e-9)
                nk_dst = (gpu_w[dst] + w) / (GPU_MEM_SIZE - (gpu_s[dst] + s) + 1e-9)
                
                new_peak = max(nk_src, nk_dst)
                if new_peak > max_k + 1e-7: continue
                
                peak_diff = max_k - new_peak
                # Variance reduction proxy: Sum of squares
                var_diff = (current_ks[src]**2 + current_ks[dst]**2) - (nk_src**2 + nk_dst**2)
                
                score = None
                if peak_diff > 1e-7: score = (1, peak_diff, var_diff)
                elif peak_diff > -1e-7 and var_diff > 1e-5: score = (0, 0, var_diff)
                
                if score and (best_move is None or score > best_move[0]):
                    best_move = (score, ('move', idx, dst, s, w))

        # Check Swaps (if no high-quality move found)
        if best_move is None or best_move[0][0] == 0:
            for i1, m1 in src_items:
                w1, s1 = m1.req_rate/m1.slo, m1.model_size
                for dst in range(gpu_num):
                    if dst == src: continue
                    # Pruning: Don't swap with high pressure nodes
                    if current_ks[dst] > max_k * 0.95: continue
                    
                    for i2, m2 in enumerate(placement[dst]):
                        w2, s2 = m2.req_rate/m2.slo, m2.model_size
                        
                        ns_src = gpu_s[src] - s1 + s2
                        ns_dst = gpu_s[dst] - s2 + s1
                        if ns_src > GPU_MEM_SIZE or ns_dst > GPU_MEM_SIZE: continue
                        
                        nk_src = (gpu_w[src] - w1 + w2) / (GPU_MEM_SIZE - ns_src + 1e-9)
                        nk_dst = (gpu_w[dst] - w2 + w1) / (GPU_MEM_SIZE - ns_dst + 1e-9)
                        
                        new_peak = max(nk_src, nk_dst)
                        if new_peak > max_k + 1e-7: continue
                        
                        peak_diff = max_k - new_peak
                        var_diff = (current_ks[src]**2 + current_ks[dst]**2) - (nk_src**2 + nk_dst**2)
                        
                        score = None
                        if peak_diff > 1e-7: score = (1, peak_diff, var_diff)
                        elif peak_diff > -1e-7 and var_diff > 1e-5: score = (0, 0, var_diff)
                        
                        if score and (best_move is None or score > best_move[0]):
                            best_move = (score, ('swap', i1, dst, i2, s1, w1, s2, w2))

        # Apply
        if best_move:
            _, action = best_move
            if action[0] == 'move':
                _, idx, dst, s, w = action
                m = placement[src].pop(idx)
                placement[dst].append(m)
                gpu_s[src] -= s; gpu_w[src] -= w
                gpu_s[dst] += s; gpu_w[dst] += w
            elif action[0] == 'swap':
                _, i1, dst, i2, s1, w1, s2, w2 = action
                m1 = placement[src][i1]
                m2 = placement[dst][i2]
                placement[src][i1] = m2
                placement[dst][i2] = m1
                gpu_s[src] = gpu_s[src] - s1 + s2; gpu_w[src] = gpu_w[src] - w1 + w2
                gpu_s[dst] = gpu_s[dst] - s2 + s1; gpu_w[dst] = gpu_w[dst] - w2 + w1
            
            current_ks[src] = get_k(src)
            current_ks[dst] = get_k(dst)
            
            # Reset patience on any move (even plateau traversals help exploration)
            no_improve = 0
        else:
            no_improve += 1
            
    return best_placement
# EVOLVE-BLOCK-END