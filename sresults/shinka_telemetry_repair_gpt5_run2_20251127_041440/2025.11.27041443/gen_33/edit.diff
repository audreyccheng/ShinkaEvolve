--- a/original.py
+++ b/original.py
@@ -1,271 +1,440 @@
 # EVOLVE-BLOCK-START
 """
 Network telemetry repair algorithm that detects and corrects inconsistencies
 in network interface telemetry data using topology relationships.
 
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+This version implements a consensus-and-residual fusion approach:
+- Trust-weighted directional consensus with partial averaging near threshold
+- Magnitude-aware gating with absolute guard and sharp agreement floors
+- Asymmetric confidence shaping when only one side shows traffic
+- Router-level micro-adjustments for dominating dangling interfaces
+- Direction-aware confidence penalties informed by flow-conservation residuals
 """
 from typing import Dict, Any, Tuple, List
+from math import sqrt
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Repair network interface telemetry by detecting and correcting inconsistencies.
 
-    Core principle: Use network invariants to validate and repair telemetry:
+    Core invariants used:
     1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
     2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
     3. Interface Consistency: Status should be consistent across connected pairs
 
     Args:
         telemetry: Dictionary where key is interface_id and value contains:
             - interface_status: "up" or "down"
             - rx_rate: receive rate in Mbps
             - tx_rate: transmit rate in Mbps
             - connected_to: interface_id this interface connects to
             - local_router: router_id this interface belongs to
             - remote_router: router_id on the other side
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary with same structure but telemetry values become tuples of:
         (original_value, repaired_value, confidence_score)
         where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
     """
-
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
-    # Magnitude-aware tolerance and absolute guard to avoid over-correcting tiny flows
-    LOW_RATE_CUTOFF = 10.0  # Mbps
-    ABS_GUARD = 0.5         # Mbps; require this absolute delta to trigger a repair
+    # Hardened tolerances (Hodor guidance)
+    HARDENING_THRESHOLD = 0.02   # 2% for normal rates
+    LOW_RATE_CUTOFF = 10.0       # Mbps threshold for tiny flows
+    LOW_RATE_THRESHOLD = 0.05    # 5% tolerance when small
+    ABS_GUARD = 0.5              # Mbps; absolute guard to avoid over-correcting tiny flows
+    QUIET_EPS = 0.1              # Mbps; traffic "silence" threshold for asymmetry handling
 
     def clamp(x: float, lo: float = 0.0, hi: float = 1.0) -> float:
         return max(lo, min(hi, x))
 
     result: Dict[str, Dict[str, Tuple]] = {}
 
-    # First pass: collect all measurements and compute link symmetry stats
-    link_stats: Dict[str, Dict[str, float]] = {}
+    # Build peer mapping for quick, validated lookup
+    peers: Dict[str, str] = {}
+    for if_id, data in telemetry.items():
+        peer_id = data.get('connected_to')
+        peers[if_id] = peer_id if peer_id in telemetry else None
+
+    # Plan pairwise consensus adjustments so both ends change consistently
+    field_value_adjust: Dict[Tuple[str, str], float] = {}   # (iface, 'tx'|'rx') -> new_value
+    field_conf_assign: Dict[Tuple[str, str], float] = {}    # set confidence when adjusted
+    field_conf_floor: Dict[Tuple[str, str], float] = {}     # high floors when in strong agreement
+    field_conf_scale: Dict[Tuple[str, str], float] = {}     # multiplicative confidence scalers (asymmetry)
+
+    visited_pairs = set()
+
+    # Utility for normalized difference
+    def rel_diff(a: float, b: float) -> float:
+        return abs(a - b) / max(1.0, a, b)
+
+    # Pairwise consensus-and-hardening
+    for a_id, a_data in telemetry.items():
+        b_id = peers.get(a_id)
+        if not b_id:
+            continue
+        key = tuple(sorted([a_id, b_id]))
+        if key in visited_pairs:
+            continue
+        visited_pairs.add(key)
+
+        a_status = a_data.get('interface_status', 'unknown')
+        b_status = telemetry[b_id].get('interface_status', 'unknown')
+
+        a_tx = float(a_data.get('tx_rate', 0.0))
+        a_rx = float(a_data.get('rx_rate', 0.0))
+        b_tx = float(telemetry[b_id].get('tx_rate', 0.0))
+        b_rx = float(telemetry[b_id].get('rx_rate', 0.0))
+
+        # Only attempt counter fusion if neither side is explicitly down; down logic handled later
+        if a_status != 'down' and b_status != 'down':
+            # Direction a->b: compare a_tx with b_rx
+            abs_ab = abs(a_tx - b_rx)
+            max_ab = max(1.0, a_tx, b_rx)
+            diff_ab = abs_ab / max_ab
+            tol_ab = LOW_RATE_THRESHOLD if max(a_tx, b_rx) < LOW_RATE_CUTOFF else HARDENING_THRESHOLD
+
+            # Direction b->a: compare b_tx with a_rx
+            abs_ba = abs(b_tx - a_rx)
+            max_ba = max(1.0, b_tx, a_rx)
+            diff_ba = abs_ba / max_ba
+            tol_ba = LOW_RATE_THRESHOLD if max(b_tx, a_rx) < LOW_RATE_CUTOFF else HARDENING_THRESHOLD
+
+            # Activity-based trust for consensus weighting (novel bias)
+            # Bias toward the side that exhibits stronger traffic magnitude (more reliable signal)
+            act_a = max(a_tx, a_rx)
+            act_b = max(b_tx, b_rx)
+            denom_act = max(1e-9, act_a + act_b)
+            w_a = act_a / denom_act
+            w_b = act_b / denom_act
+
+            # a->b hardening
+            if diff_ab > tol_ab and abs_ab > ABS_GUARD:
+                # Trust-weighted consensus
+                consensus_ab = w_a * a_tx + w_b * b_rx
+                if diff_ab <= 2 * tol_ab:
+                    # Partial averaging near threshold to reduce overcorrection
+                    k = (diff_ab - tol_ab) / max(tol_ab, 1e-9)
+                    new_a_tx = a_tx * (1.0 - k) + consensus_ab * k
+                    new_b_rx = b_rx * (1.0 - k) + consensus_ab * k
+                else:
+                    # Clear violation: converge fully to consensus
+                    new_a_tx = consensus_ab
+                    new_b_rx = consensus_ab
+                field_value_adjust[(a_id, 'tx')] = new_a_tx
+                field_value_adjust[(b_id, 'rx')] = new_b_rx
+                conf_ab = clamp(1.0 - diff_ab)
+                field_conf_assign[(a_id, 'tx')] = conf_ab
+                field_conf_assign[(b_id, 'rx')] = conf_ab
+            else:
+                # Within tolerance: floor high confidence
+                if max(a_tx, b_rx) >= 10.0 and diff_ab <= 0.005:
+                    floor = 0.99
+                else:
+                    floor = 0.98
+                field_conf_floor[(a_id, 'tx')] = max(field_conf_floor.get((a_id, 'tx'), 0.0), floor)
+                field_conf_floor[(b_id, 'rx')] = max(field_conf_floor.get((b_id, 'rx'), 0.0), floor)
+
+            # b->a hardening
+            if diff_ba > tol_ba and abs_ba > ABS_GUARD:
+                consensus_ba = w_b * b_tx + w_a * a_rx
+                if diff_ba <= 2 * tol_ba:
+                    k = (diff_ba - tol_ba) / max(tol_ba, 1e-9)
+                    new_b_tx = b_tx * (1.0 - k) + consensus_ba * k
+                    new_a_rx = a_rx * (1.0 - k) + consensus_ba * k
+                else:
+                    new_b_tx = consensus_ba
+                    new_a_rx = consensus_ba
+                field_value_adjust[(b_id, 'tx')] = new_b_tx
+                field_value_adjust[(a_id, 'rx')] = new_a_rx
+                conf_ba = clamp(1.0 - diff_ba)
+                field_conf_assign[(b_id, 'tx')] = conf_ba
+                field_conf_assign[(a_id, 'rx')] = conf_ba
+            else:
+                if max(b_tx, a_rx) >= 10.0 and diff_ba <= 0.005:
+                    floor = 0.99
+                else:
+                    floor = 0.98
+                field_conf_floor[(b_id, 'tx')] = max(field_conf_floor.get((b_id, 'tx'), 0.0), floor)
+                field_conf_floor[(a_id, 'rx')] = max(field_conf_floor.get((a_id, 'rx'), 0.0), floor)
+
+            # Asymmetric confidence when only one side shows traffic (traffic-evidence asymmetry)
+            pair_up = True
+            # Direction a->b
+            if pair_up and a_tx > QUIET_EPS and b_rx <= QUIET_EPS:
+                field_conf_scale[(b_id, 'rx')] = min(0.9, field_conf_scale.get((b_id, 'rx'), 1.0))
+            if pair_up and b_rx > QUIET_EPS and a_tx <= QUIET_EPS:
+                field_conf_scale[(a_id, 'tx')] = min(0.9, field_conf_scale.get((a_id, 'tx'), 1.0))
+            # Direction b->a
+            if pair_up and b_tx > QUIET_EPS and a_rx <= QUIET_EPS:
+                field_conf_scale[(a_id, 'rx')] = min(0.9, field_conf_scale.get((a_id, 'rx'), 1.0))
+            if pair_up and a_rx > QUIET_EPS and b_tx <= QUIET_EPS:
+                field_conf_scale[(b_id, 'tx')] = min(0.9, field_conf_scale.get((b_id, 'tx'), 1.0))
+
+            # Harmonize very strong agreements via geometric-mean floors
+            strong_ab = (max(a_tx, b_rx) >= 10.0 and diff_ab <= 0.005)
+            strong_ba = (max(b_tx, a_rx) >= 10.0 and diff_ba <= 0.005)
+            if strong_ab:
+                # Geometric mean harmonization for link-direction confidences
+                fa = field_conf_floor.get((a_id, 'tx'), 0.98)
+                fb = field_conf_floor.get((b_id, 'rx'), 0.98)
+                gm = sqrt(max(1e-9, fa) * max(1e-9, fb))
+                field_conf_floor[(a_id, 'tx')] = max(field_conf_floor.get((a_id, 'tx'), 0.0), gm)
+                field_conf_floor[(b_id, 'rx')] = max(field_conf_floor.get((b_id, 'rx'), 0.0), gm)
+            if strong_ba:
+                fb = field_conf_floor.get((b_id, 'tx'), 0.98)
+                fa = field_conf_floor.get((a_id, 'rx'), 0.98)
+                gm = sqrt(max(1e-9, fa) * max(1e-9, fb))
+                field_conf_floor[(b_id, 'tx')] = max(field_conf_floor.get((b_id, 'tx'), 0.0), gm)
+                field_conf_floor[(a_id, 'rx')] = max(field_conf_floor.get((a_id, 'rx'), 0.0), gm)
+
+    # Second pass: apply planned adjustments and assign calibrated confidences
     for interface_id, data in telemetry.items():
-        rx_rate = float(data.get('rx_rate', 0.0))
-        tx_rate = float(data.get('tx_rate', 0.0))
-        connected_to = data.get('connected_to')
-
-        if connected_to and connected_to in telemetry:
-            peer = telemetry[connected_to]
-            peer_rx = float(peer.get('rx_rate', 0.0))
-            peer_tx = float(peer.get('tx_rate', 0.0))
-
-            # My TX should match their RX
-            abs_tx_rx = abs(tx_rate - peer_rx)
-            max_tx_rx = max(1.0, tx_rate, peer_rx)
-            rel_tx_rx = abs_tx_rx / max_tx_rx
-
-            # My RX should match their TX
-            abs_rx_tx = abs(rx_rate - peer_tx)
-            max_rx_tx = max(1.0, rx_rate, peer_tx)
-            rel_rx_tx = abs_rx_tx / max_rx_tx
-
-            # Dynamic thresholds
-            th_tx_rx = 0.05 if max(tx_rate, peer_rx) < LOW_RATE_CUTOFF else HARDENING_THRESHOLD
-            th_rx_tx = 0.05 if max(rx_rate, peer_tx) < LOW_RATE_CUTOFF else HARDENING_THRESHOLD
-
-            link_stats[interface_id] = {
-                'peer_rx': peer_rx,
-                'peer_tx': peer_tx,
-                'abs_tx_rx': abs_tx_rx,
-                'abs_rx_tx': abs_rx_tx,
-                'rel_tx_rx': rel_tx_rx,
-                'rel_rx_tx': rel_rx_tx,
-                'th_tx_rx': th_tx_rx,
-                'th_rx_tx': th_rx_tx,
-                'max_tx_rx': max(tx_rate, peer_rx),
-                'max_rx_tx': max(rx_rate, peer_tx),
-            }
-
-    # Second pass: repair using redundancy and assign calibrated confidences
-    for interface_id, data in telemetry.items():
-        repaired_data: Dict[str, Any] = {}
+        repaired = {}
 
         interface_status = data.get('interface_status', 'unknown')
         rx_rate = float(data.get('rx_rate', 0.0))
         tx_rate = float(data.get('tx_rate', 0.0))
         connected_to = data.get('connected_to')
 
-        # Start with conservative defaults; will raise when evidence is strong
+        # Defaults: identity with conservative base
         repaired_rx = rx_rate
         repaired_tx = tx_rate
         repaired_status = interface_status
-        rx_confidence = 0.95
-        tx_confidence = 0.95
-        status_confidence = 0.95
-
-        # Peer snapshot for redundancy use
+        rx_conf = 0.95
+        tx_conf = 0.95
+        status_conf = 0.95
+
+        # Peer snapshot
         peer_status = None
-        peer_rx = None
-        peer_tx = None
         if connected_to and connected_to in telemetry:
-            peer = telemetry[connected_to]
-            peer_status = peer.get('interface_status', 'unknown')
-            peer_rx = float(peer.get('rx_rate', 0.0))
-            peer_tx = float(peer.get('tx_rate', 0.0))
-
-        # Enforce interface consistency: if either side is down, set effective down and zero rates
+            peer_status = telemetry[connected_to].get('interface_status', 'unknown')
+
+        # Enforce interface consistency: if either side is down, set both down with zero rates
         if interface_status == 'down' or (peer_status == 'down' if peer_status is not None else False):
             both_down = (interface_status == 'down' and (peer_status == 'down' if peer_status is not None else False))
             repaired_status = 'down'
             repaired_rx = 0.0
             repaired_tx = 0.0
-            status_confidence = 0.95 if both_down else 0.7
-            rx_confidence = status_confidence
-            tx_confidence = status_confidence
+            status_conf = 0.95 if both_down else 0.7
+            rx_conf = status_conf
+            tx_conf = status_conf
         else:
-            # Use magnitude-aware symmetry check with absolute guard for value repairs
-            if interface_id in link_stats:
-                stats = link_stats[interface_id]
-
-                # RX should match peer's TX
-                abs_diff_rx = stats['abs_rx_tx']
-                rel_diff_rx = stats['rel_rx_tx']
-                tol_rx = stats['th_rx_tx']
-                max_pair_rx = stats['max_rx_tx']
-
-                if rel_diff_rx > tol_rx and abs_diff_rx > ABS_GUARD:
-                    repaired_rx = stats['peer_tx']
-                    rx_confidence = clamp(1.0 - rel_diff_rx)
-                else:
-                    # Within tolerance: strong agreement floors
-                    if max_pair_rx >= 10.0 and rel_diff_rx <= 0.005:
-                        rx_confidence = max(rx_confidence, 0.99)
-                    else:
-                        rx_confidence = max(rx_confidence, 0.97 if max_pair_rx < 10.0 else 0.98)
-
-                # TX should match peer's RX
-                abs_diff_tx = stats['abs_tx_rx']
-                rel_diff_tx = stats['rel_tx_rx']
-                tol_tx = stats['th_tx_rx']
-                max_pair_tx = stats['max_tx_rx']
-
-                if rel_diff_tx > tol_tx and abs_diff_tx > ABS_GUARD:
-                    repaired_tx = stats['peer_rx']
-                    tx_confidence = clamp(1.0 - rel_diff_tx)
-                else:
-                    if max_pair_tx >= 10.0 and rel_diff_tx <= 0.005:
-                        tx_confidence = max(tx_confidence, 0.99)
-                    else:
-                        tx_confidence = max(tx_confidence, 0.97 if max_pair_tx < 10.0 else 0.98)
-            else:
-                # No redundancy: keep values but slightly lower confidence
-                rx_confidence = max(rx_confidence, 0.9)
-                tx_confidence = max(tx_confidence, 0.9)
-
-            # If statuses differ (but neither side is down), reduce status confidence
-            if peer_status is not None and interface_status != peer_status:
-                status_confidence = min(status_confidence, 0.6)
-
-        # Store repaired values with confidence scores
-        repaired_data['rx_rate'] = (float(rx_rate), float(repaired_rx), clamp(rx_confidence))
-        repaired_data['tx_rate'] = (float(tx_rate), float(repaired_tx), clamp(tx_confidence))
-        repaired_data['interface_status'] = (interface_status, repaired_status, clamp(status_confidence))
-
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = connected_to
-        repaired_data['local_router'] = data.get('local_router')
-        repaired_data['remote_router'] = data.get('remote_router')
-
-        result[interface_id] = repaired_data
-
-    # Router-level flow conservation: direction-aware confidence attenuation
-    # Build router->interfaces mapping (prefer topology, augment with telemetry hints)
+            # Apply pairwise counter adjustments
+            if (interface_id, 'rx') in field_value_adjust:
+                repaired_rx = float(field_value_adjust[(interface_id, 'rx')])
+                rx_conf = field_conf_assign.get((interface_id, 'rx'), rx_conf)
+            if (interface_id, 'tx') in field_value_adjust:
+                repaired_tx = float(field_value_adjust[(interface_id, 'tx')])
+                tx_conf = field_conf_assign.get((interface_id, 'tx'), tx_conf)
+
+            # Status mismatch (neither side down) reduces status confidence
+            if connected_to and connected_to in telemetry:
+                if interface_status != peer_status:
+                    status_conf = min(status_conf, 0.6)
+
+            # Apply confidence floors for in-tolerance agreements
+            rx_floor = field_conf_floor.get((interface_id, 'rx'))
+            tx_floor = field_conf_floor.get((interface_id, 'tx'))
+            if rx_floor is not None:
+                rx_conf = max(rx_conf, rx_floor)
+            if tx_floor is not None:
+                tx_conf = max(tx_conf, tx_floor)
+
+            # Apply asymmetric scaling if applicable
+            if (interface_id, 'rx') in field_conf_scale:
+                rx_conf = clamp(rx_conf * field_conf_scale[(interface_id, 'rx')])
+            if (interface_id, 'tx') in field_conf_scale:
+                tx_conf = clamp(tx_conf * field_conf_scale[(interface_id, 'tx')])
+
+        # Store
+        repaired['rx_rate'] = (rx_rate, repaired_rx, clamp(rx_conf))
+        repaired['tx_rate'] = (tx_rate, repaired_tx, clamp(tx_conf))
+        repaired['interface_status'] = (interface_status, repaired_status, clamp(status_conf))
+        repaired['connected_to'] = connected_to
+        repaired['local_router'] = data.get('local_router')
+        repaired['remote_router'] = data.get('remote_router')
+        result[interface_id] = repaired
+
+    # Router-level flow conservation: micro-adjustments on dominating dangling interfaces
+    # Build router->interfaces mapping using provided topology and telemetry fallbacks
     router_ifaces: Dict[str, List[str]] = {r: list(if_list) for r, if_list in topology.items()}
     for if_id, d in telemetry.items():
         lr = d.get('local_router')
         if lr:
             router_ifaces.setdefault(lr, [])
             if if_id not in router_ifaces[lr]:
                 router_ifaces[lr].append(if_id)
         rr = d.get('remote_router')
         if rr and rr not in router_ifaces:
             router_ifaces[rr] = []
 
-    # Compute per-router residual mismatch from repaired values
+    # Compute per-router sums
+    router_sums: Dict[str, Tuple[float, float]] = {}
+    for r, if_list in router_ifaces.items():
+        sum_tx = 0.0
+        sum_rx = 0.0
+        for if_id in if_list:
+            if if_id in result:
+                sum_tx += float(result[if_id]['tx_rate'][1])
+                sum_rx += float(result[if_id]['rx_rate'][1])
+        router_sums[r] = (sum_tx, sum_rx)
+
+    # Apply tightly scoped micro-adjustments only on dominating dangling interfaces (recommendation 4)
+    for r, if_list in router_ifaces.items():
+        sum_tx, sum_rx = router_sums.get(r, (0.0, 0.0))
+        imbalance = sum_tx - sum_rx
+        abs_imb = abs(imbalance)
+        if abs_imb <= 0.0:
+            continue
+        denom = max(1.0, sum_tx, sum_rx)
+        resid_frac = abs_imb / denom
+
+        # Identify unpaired, up interfaces
+        candidates = []
+        for if_id in if_list:
+            if if_id not in result:
+                continue
+            # unpaired if peer missing in telemetry
+            connected_to = result[if_id].get('connected_to')
+            is_unpaired = not connected_to or connected_to not in telemetry
+            status = result[if_id]['interface_status'][1]
+            if is_unpaired and status == 'up':
+                txv = float(result[if_id]['tx_rate'][1])
+                rxv = float(result[if_id]['rx_rate'][1])
+                contrib = abs(txv - rxv)
+                candidates.append((contrib, if_id, txv, rxv))
+
+        if not candidates:
+            continue
+
+        candidates.sort(reverse=True)
+        top_contrib, top_if, txv, rxv = candidates[0]
+        if top_contrib < 0.5 * abs_imb:
+            continue  # not dominating enough
+
+        alpha = min(0.02, 0.5 * resid_frac)
+        if alpha <= 0.0:
+            continue
+
+        # Adjust only the larger counter toward reducing the router imbalance
+        orx, rrx, rc = result[top_if]['rx_rate']
+        otx, rtx, tc = result[top_if]['tx_rate']
+        if imbalance > 0.0:
+            # sum_tx > sum_rx: reduce tx or increase rx; nudge only larger counter
+            if rtx >= rrx:
+                new_tx = rtx * (1.0 - alpha)
+                # modest confidence increase reflecting conservation alignment
+                new_conf = max(tc, 0.6 + 0.2 * (alpha / 0.02))
+                result[top_if]['tx_rate'] = (otx, new_tx, clamp(new_conf))
+            else:
+                new_rx = rrx * (1.0 + alpha)
+                new_conf = max(rc, 0.6 + 0.2 * (alpha / 0.02))
+                result[top_if]['rx_rate'] = (orx, new_rx, clamp(new_conf))
+        else:
+            # sum_tx < sum_rx: reduce rx or increase tx; nudge only larger counter
+            if rrx >= rtx:
+                new_rx = rrx * (1.0 - alpha)
+                new_conf = max(rc, 0.6 + 0.2 * (alpha / 0.02))
+                result[top_if]['rx_rate'] = (orx, new_rx, clamp(new_conf))
+            else:
+                new_tx = rtx * (1.0 + alpha)
+                new_conf = max(tc, 0.6 + 0.2 * (alpha / 0.02))
+                result[top_if]['tx_rate'] = (otx, new_tx, clamp(new_conf))
+
+    # Recompute residuals after micro-adjustments
     router_resid: Dict[str, float] = {}
     for r, if_list in router_ifaces.items():
         sum_tx = 0.0
         sum_rx = 0.0
         for if_id in if_list:
             if if_id in result:
                 sum_tx += float(result[if_id]['tx_rate'][1])
                 sum_rx += float(result[if_id]['rx_rate'][1])
         denom = max(1.0, sum_tx, sum_rx)
         router_resid[r] = abs(sum_tx - sum_rx) / denom
 
-    # Apply direction-aware penalties with a gentle floor to avoid over-penalizing noisy sites
+    # Apply direction-aware penalties (recommendation 2) and mild status scaling
     for if_id, d in telemetry.items():
+        if if_id not in result:
+            continue
         lr = d.get('local_router')
         rr = d.get('remote_router')
         resid_local = router_resid.get(lr, 0.0)
         resid_remote = router_resid.get(rr, 0.0)
-        # TX leaves local, RX arrives from remote
-        penalty_tx = clamp(1.0 - (0.6 * resid_local + 0.4 * resid_remote), 0.7, 1.0)
-        penalty_rx = clamp(1.0 - (0.6 * resid_remote + 0.4 * resid_local), 0.7, 1.0)
+        pen_tx = clamp(1.0 - (0.6 * resid_local + 0.4 * resid_remote), 0.0, 1.0)
+        pen_rx = clamp(1.0 - (0.6 * resid_remote + 0.4 * resid_local), 0.0, 1.0)
+
         orx, rrx, rc = result[if_id]['rx_rate']
         otx, rtx, tc = result[if_id]['tx_rate']
-        result[if_id]['rx_rate'] = (orx, rrx, clamp(rc * penalty_rx))
-        result[if_id]['tx_rate'] = (otx, rtx, clamp(tc * penalty_tx))
+        ost, rst, sc = result[if_id]['interface_status']
+
+        result[if_id]['tx_rate'] = (otx, rtx, clamp(tc * pen_tx))
+        result[if_id]['rx_rate'] = (orx, rrx, clamp(rc * pen_rx))
+        # Mild status confidence scaling with penalties
+        status_scale = 0.85 + 0.15 * min(pen_tx, pen_rx)
+        result[if_id]['interface_status'] = (ost, rst, clamp(sc * status_scale))
+
+    # Ensure zero rates if repaired status is down (idempotent safety)
+    for if_id, d in result.items():
+        status = d['interface_status'][1]
+        if status == 'down':
+            orx, _, rc = d['rx_rate']
+            otx, _, tc = d['tx_rate']
+            d['rx_rate'] = (orx, 0.0, rc)
+            d['tx_rate'] = (otx, 0.0, tc)
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")
