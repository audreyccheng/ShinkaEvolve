--- a/original.py
+++ b/original.py
@@ -1,444 +1,458 @@
 # EVOLVE-BLOCK-START
 """
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+Least-squares factor-graph telemetry repair:
+- Build a global quadratic objective from data fidelity, link symmetry, and router flow factors
+- Solve the normal equations with conjugate gradient in a sparse structure
+- Enforce non-negativity and "down implies zero"
+- Calibrate confidence from invariant residuals, change sizes, and redundancy
 """
 from typing import Dict, Any, Tuple, List
-
+from math import isfinite
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
-    """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-
-    Core principle: Use network invariants to validate and repair telemetry:
-    1. Link Symmetry (R3): my_tx_rate ≈ their_rx_rate for connected interfaces
-    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
-    3. Interface Consistency: Status should be consistent across connected pairs
-
-    Args:
-        telemetry: Dictionary where key is interface_id and value contains:
-            - interface_status: "up" or "down"
-            - rx_rate: receive rate in Mbps
-            - tx_rate: transmit rate in Mbps
-            - connected_to: interface_id this interface connects to
-            - local_router: router_id this interface belongs to
-            - remote_router: router_id on the other side
-        topology: Dictionary where key is router_id and value contains a list of interface_ids
-
-    Returns:
-        Dictionary with same structure but telemetry values become tuples of:
-        (original_value, repaired_value, confidence_score)
-        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
-    """
-
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
-    # Small traffic level used to infer link up when statuses disagree (Mbps)
-    TRAFFIC_EVIDENCE_MIN = 0.5
-    # Max fractional per-interface adjustment during router redistribution
-    MAX_ROUTER_ADJ_FRAC = 0.35
+    # Core tolerances and constants (from research)
+    HARDENING_THRESHOLD = 0.02         # ≈2% timing tolerance
+    TRAFFIC_EVIDENCE_MIN = 0.5         # Mbps: traffic implying link up
+    TOL_ROUTER = HARDENING_THRESHOLD * 2.0
     EPS = 1e-9
 
+    # Factor weights (relative strengths)
+    W_DATA_BASE = 1.0                  # anchor to original telemetry
+    W_DOWN_STRONG = 50.0               # strong zeroing for down interfaces
+    W_PAIR_BASE = 4.0                  # pair equality strength
+    W_ROUTER_BASE = 2.0                # router flow strength
+    LAMBDA_RIDGE = 1e-6                # small ridge to ensure SPD
+
     def clamp(x: float, lo: float = 0.0, hi: float = 1.0) -> float:
+        if not isfinite(x):
+            return lo
         return max(lo, min(hi, x))
 
     def rel_diff(a: float, b: float) -> float:
         denom = max(abs(a), abs(b), 1e-9)
         return abs(a - b) / denom
 
-    def conf_from_residual(residual: float, tol: float) -> float:
-        # Map residual to confidence: 1 at 0 residual, degrades linearly until ~0 near 5*tol
-        denom = max(tol * 5.0, 1e-9)
-        return clamp(1.0 - residual / denom)
-
-    # Initialize structures
-    result: Dict[str, Dict[str, Tuple]] = {}
-    # Store interim repaired values and confidences per interface before router-level hardening
-    interim: Dict[str, Dict[str, Any]] = {}
-
-    # Build connected pairs
-    visited = set()
-    pairs: List[Tuple[str, str]] = []
-    for if_id, data in telemetry.items():
-        peer = data.get('connected_to')
-        if peer and peer in telemetry:
-            # Use ordered tuple to avoid duplicates
-            key = tuple(sorted([if_id, peer]))
-            if key not in visited:
-                visited.add(key)
-                pairs.append((key[0], key[1]))
-
-    # Map each interface to its peer for quick lookup and record paired IDs
-    peer_of: Dict[str, str] = {}
-    paired_ids = set()
-    for a_id, b_id in pairs:
-        peer_of[a_id] = b_id
-        peer_of[b_id] = a_id
-        paired_ids.add(a_id)
-        paired_ids.add(b_id)
-
-    # Initialize defaults for all interfaces
-    for if_id, data in telemetry.items():
-        interim[if_id] = {
-            'rx': float(data.get('rx_rate', 0.0)),
-            'tx': float(data.get('tx_rate', 0.0)),
-            'rx_conf': 1.0,
-            'tx_conf': 1.0,
-            'status': data.get('interface_status', 'unknown'),
-            'status_conf': 1.0,
-            'connected_to': data.get('connected_to'),
-            'local_router': data.get('local_router'),
-            'remote_router': data.get('remote_router'),
-            # Keep originals for output tuples
-            'orig_rx': float(data.get('rx_rate', 0.0)),
-            'orig_tx': float(data.get('tx_rate', 0.0)),
-            'orig_status': data.get('interface_status', 'unknown'),
-        }
-
-    # Pair-level hardening using link symmetry (R3) and interface consistency
-    for a_id, b_id in pairs:
-        a = telemetry[a_id]
-        b = telemetry[b_id]
-        a_stat = a.get('interface_status', 'unknown')
-        b_stat = b.get('interface_status', 'unknown')
-        a_rx, a_tx = float(a.get('rx_rate', 0.0)), float(a.get('tx_rate', 0.0))
-        b_rx, b_tx = float(b.get('rx_rate', 0.0)), float(b.get('tx_rate', 0.0))
-        max_traffic = max(a_rx, a_tx, b_rx, b_tx)
-
-        # Resolve interface status consistency across the link
-        if a_stat == b_stat:
-            resolved_status = a_stat
-            status_conf = 0.95 if resolved_status in ('up', 'down') else 0.7
-        else:
-            # Use traffic evidence: if there is noticeable traffic, link must be up
-            if max_traffic > TRAFFIC_EVIDENCE_MIN:
-                resolved_status = 'up'
-                status_conf = 0.85
-            else:
-                resolved_status = 'down'
-                status_conf = 0.75
-
-        # Apply status to both ends
-        interim[a_id]['status'] = resolved_status
-        interim[b_id]['status'] = resolved_status
-        interim[a_id]['status_conf'] = min(interim[a_id]['status_conf'], status_conf) if interim[a_id]['status_conf'] else status_conf
-        interim[b_id]['status_conf'] = min(interim[b_id]['status_conf'], status_conf) if interim[b_id]['status_conf'] else status_conf
-
-        if resolved_status == 'down':
-            # Down interfaces cannot send or receive
-            # Confidence is high if original values were already near zero, lower otherwise.
-            for ifid, rx0, tx0 in [(a_id, a_rx, a_tx), (b_id, b_rx, b_tx)]:
-                interim[ifid]['rx'] = 0.0
-                interim[ifid]['tx'] = 0.0
-                interim[ifid]['rx_conf'] = clamp(0.9 if rx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-                interim[ifid]['tx_conf'] = clamp(0.9 if tx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-            continue  # No need to harden rates if link is down
-
-        # Link is up: harden both directions using symmetry
-        # Forward direction: a.tx should match b.rx
-        d_fwd = rel_diff(a_tx, b_rx)
-        if d_fwd <= HARDENING_THRESHOLD:
-            v = 0.5 * (a_tx + b_rx)
-            conf = clamp(1.0 - 0.5 * d_fwd)  # near 1 when very close
-        else:
-            # Choose peer's counterpart as stronger signal
-            v = b_rx if abs(b_rx) > 0 else a_tx
-            conf = clamp(1.0 - d_fwd)  # lower confidence for larger violation
-        interim[a_id]['tx'] = v
-        interim[b_id]['rx'] = v
-        interim[a_id]['tx_conf'] = min(interim[a_id]['tx_conf'], conf)
-        interim[b_id]['rx_conf'] = min(interim[b_id]['rx_conf'], conf)
-
-        # Reverse direction: a.rx should match b.tx
-        d_rev = rel_diff(a_rx, b_tx)
-        if d_rev <= HARDENING_THRESHOLD:
-            v2 = 0.5 * (a_rx + b_tx)
-            conf2 = clamp(1.0 - 0.5 * d_rev)
-        else:
-            v2 = b_tx if abs(b_tx) > 0 else a_rx
-            conf2 = clamp(1.0 - d_rev)
-        interim[a_id]['rx'] = v2
-        interim[b_id]['tx'] = v2
-        interim[a_id]['rx_conf'] = min(interim[a_id]['rx_conf'], conf2)
-        interim[b_id]['tx_conf'] = min(interim[b_id]['tx_conf'], conf2)
-
-    # Enforce "down implies zero traffic" also for unpaired interfaces
-    for if_id, r in interim.items():
-        if if_id not in paired_ids and r.get('status') == 'down':
-            rx0 = r['rx']
-            tx0 = r['tx']
-            r['rx'] = 0.0
-            r['tx'] = 0.0
-            r['rx_conf'] = clamp(0.9 if rx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-            r['tx_conf'] = clamp(0.9 if tx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-
-    # Router-level dynamic flow conservation (R1)
-    # Build router to interfaces map (use provided topology if available, else derive from telemetry)
+    # Map interfaces to indices (rx and tx separate variables)
+    iface_ids = list(telemetry.keys())
+    n = len(iface_ids)
+    idx_rx: Dict[str, int] = {}
+    idx_tx: Dict[str, int] = {}
+    for k, if_id in enumerate(iface_ids):
+        idx_rx[if_id] = 2 * k
+        idx_tx[if_id] = 2 * k + 1
+    Nvar = 2 * n
+
+    # Sparse symmetric matrix H as dict of dicts, and vector g
+    H: Dict[int, Dict[int, float]] = {}
+    g: List[float] = [0.0] * Nvar
+
+    def h_add(i: int, j: int, v: float):
+        # Add v to H[i,j] and H[j,i] if i!=j; otherwise to diagonal
+        if i not in H:
+            H[i] = {}
+        H[i][j] = H[i].get(j, 0.0) + v
+        if i != j:
+            if j not in H:
+                H[j] = {}
+            H[j][i] = H[j].get(i, 0.0) + v
+
+    def add_data_anchor(vi: int, value: float, weight: float):
+        # term: weight*(x_vi - value)^2 -> H[vi,vi] += weight; g[vi] += weight*value
+        if weight <= 0.0:
+            return
+        h_add(vi, vi, weight)
+        g[vi] += weight * value
+        # redundancy count
+        redundancy[vi] = redundancy.get(vi, 0) + 1
+
+    def add_equality(i: int, j: int, weight: float):
+        # term: weight*(x_i - x_j)^2 -> H[ii]+=w, H[jj]+=w, H[ij]-=w, H[ji]-=w
+        if weight <= 0.0:
+            return
+        h_add(i, i, weight)
+        h_add(j, j, weight)
+        # for off-diagonals add -weight (we already maintain symmetry)
+        if i not in H:
+            H[i] = {}
+        if j not in H:
+            H[j] = {}
+        H[i][j] = H[i].get(j, 0.0) - weight
+        H[j][i] = H[j].get(i, 0.0) - weight
+        # redundancy counts
+        redundancy[i] = redundancy.get(i, 0) + 1
+        redundancy[j] = redundancy.get(j, 0) + 1
+
+    def add_sum_zero(indices: List[int], coeffs: List[float], weight: float):
+        # term: weight*(sum_k coeffs[k]*x[indices[k]])^2
+        # expands to weight * A^T A where A is the coefficient vector on these indices
+        if weight <= 0.0 or not indices:
+            return
+        m = len(indices)
+        for a in range(m):
+            ia = indices[a]
+            ca = coeffs[a]
+            for b in range(m):
+                ib = indices[b]
+                cb = coeffs[b]
+                h_add(ia, ib, weight * ca * cb)
+        for ia in indices:
+            redundancy[ia] = redundancy.get(ia, 0) + 1
+
+    # Prepare topology per router; if not provided, derive from telemetry metadata
     router_ifaces: Dict[str, List[str]] = {}
     if topology:
-        router_ifaces = {r: [i for i in if_list if i in interim] for r, if_list in topology.items()}
+        # Only include interfaces we have telemetry for
+        router_ifaces = {r: [i for i in if_list if i in telemetry] for r, if_list in topology.items()}
     else:
-        # If topology not provided, derive from telemetry metadata
-        # Note: Topology helps flow conservation; we derive a best-effort map when absent.
+        # Topology helps; derive best-effort from local_router metadata
         for if_id, data in telemetry.items():
             r = data.get('local_router')
             if r is not None:
                 router_ifaces.setdefault(r, []).append(if_id)
 
+    # Build peer mapping
+    peer_of: Dict[str, str] = {}
+    for if_id, data in telemetry.items():
+        peer = data.get('connected_to')
+        if peer and peer in telemetry:
+            peer_of[if_id] = peer
+
+    # Redundancy count per variable (used in confidence)
+    redundancy: Dict[int, int] = {}
+
+    # Add data anchors and down constraints
+    x0: List[float] = [0.0] * Nvar
+    status_resolved: Dict[str, str] = {}
+    status_conf: Dict[str, float] = {}
+
+    # First pass: determine link-up status by pair evidence
+    # For unpaired, keep original status; for pairs with disagreement, use traffic proof
+    # Build reverse pair map quickly
+    for if_id in iface_ids:
+        data = telemetry[if_id]
+        peer = peer_of.get(if_id)
+        my_stat = data.get('interface_status', 'unknown')
+        # Default resolution is own status for unpaired
+        if peer is None:
+            status_resolved[if_id] = my_stat
+            status_conf[if_id] = 0.9 if my_stat in ('up', 'down') else 0.7
+            continue
+        # Let the min tuple key handle once per pair
+    visited_pairs = set()
+    for if_id in iface_ids:
+        peer = peer_of.get(if_id)
+        if not peer:
+            continue
+        key = tuple(sorted([if_id, peer]))
+        if key in visited_pairs:
+            continue
+        visited_pairs.add(key)
+        a, b = key
+        a_stat = telemetry[a].get('interface_status', 'unknown')
+        b_stat = telemetry[b].get('interface_status', 'unknown')
+        a_rx, a_tx = float(telemetry[a].get('rx_rate', 0.0)), float(telemetry[a].get('tx_rate', 0.0))
+        b_rx, b_tx = float(telemetry[b].get('rx_rate', 0.0)), float(telemetry[b].get('tx_rate', 0.0))
+        max_traffic = max(a_rx, a_tx, b_rx, b_tx)
+        if a_stat == b_stat:
+            resolved = a_stat
+            conf = 0.95 if resolved in ('up', 'down') else 0.7
+        else:
+            if max_traffic > TRAFFIC_EVIDENCE_MIN:
+                resolved = 'up'; conf = 0.85
+            else:
+                resolved = 'down'; conf = 0.75
+        status_resolved[a] = resolved; status_resolved[b] = resolved
+        status_conf[a] = conf; status_conf[b] = conf
+
+    # Second pass: fill unpaired missing from previous
+    for if_id in iface_ids:
+        if if_id not in status_resolved:
+            s = telemetry[if_id].get('interface_status', 'unknown')
+            status_resolved[if_id] = s
+            status_conf[if_id] = 0.9 if s in ('up', 'down') else 0.7
+
+    # Add factors
+    for if_id in iface_ids:
+        rx0 = float(telemetry[if_id].get('rx_rate', 0.0))
+        tx0 = float(telemetry[if_id].get('tx_rate', 0.0))
+        irx = idx_rx[if_id]; itx = idx_tx[if_id]
+        x0[irx] = rx0; x0[itx] = tx0
+
+        # Data anchors (weight scaled by volume for relative robustness)
+        # Use piecewise sigma: absolute floor 1 Mbps; relative via τh
+        scale_rx = max(1.0, HARDENING_THRESHOLD * max(abs(rx0), 1.0))
+        scale_tx = max(1.0, HARDENING_THRESHOLD * max(abs(tx0), 1.0))
+        w_rx = W_DATA_BASE * (1.0 / scale_rx)
+        w_tx = W_DATA_BASE * (1.0 / scale_tx)
+
+        if status_resolved[if_id] == 'down':
+            # Strong pull to zero for down interfaces
+            add_data_anchor(irx, 0.0, W_DOWN_STRONG)
+            add_data_anchor(itx, 0.0, W_DOWN_STRONG)
+        else:
+            add_data_anchor(irx, rx0, w_rx)
+            add_data_anchor(itx, tx0, w_tx)
+
+    # Pair symmetry factors, rate-aware weighting
+    visited_pairs.clear()
+    for if_id in iface_ids:
+        peer = peer_of.get(if_id)
+        if not peer:
+            continue
+        key = tuple(sorted([if_id, peer]))
+        if key in visited_pairs:
+            continue
+        visited_pairs.add(key)
+        a, b = key
+        # Only enforce when link is up
+        if not (status_resolved[a] == 'up' and status_resolved[b] == 'up'):
+            continue
+        # Forward: a.tx ≈ b.rx
+        a_itx = idx_tx[a]; b_irx = idx_rx[b]
+        # Reverse: a.rx ≈ b.tx
+        a_irx = idx_rx[a]; b_itx = idx_tx[b]
+        # Rate-aware tolerance: higher traffic => tighter; also bounded minimum tolerance
+        a_tx0 = max(1.0, max(abs(x0[a_itx]), 1.0))
+        b_rx0 = max(1.0, max(abs(x0[b_irx]), 1.0))
+        a_rx0 = max(1.0, max(abs(x0[a_irx]), 1.0))
+        b_tx0 = max(1.0, max(abs(x0[b_itx]), 1.0))
+        tol_fwd = max(HARDENING_THRESHOLD, 5.0 / max(a_tx0, b_rx0))
+        tol_rev = max(HARDENING_THRESHOLD, 5.0 / max(a_rx0, b_tx0))
+        w_fwd = W_PAIR_BASE / max(tol_fwd, 1e-6)
+        w_rev = W_PAIR_BASE / max(tol_rev, 1e-6)
+        add_equality(a_itx, b_irx, w_fwd)
+        add_equality(a_irx, b_itx, w_rev)
+
+    # Router flow conservation factors
     for router, if_list in router_ifaces.items():
-        # Consider only interfaces present in telemetry
-        interfaces = [i for i in if_list if i in interim]
-        if not interfaces:
-            continue
-
-        # Compute sums over "up" interfaces
-        sum_tx = 0.0
-        sum_rx = 0.0
-        tx_conf_acc = 0.0
-        rx_conf_acc = 0.0
-        up_count_tx = 0
-        up_count_rx = 0
-        for i in interfaces:
-            if interim[i]['status'] == 'up':
-                sum_tx += max(0.0, interim[i]['tx'])
-                sum_rx += max(0.0, interim[i]['rx'])
-                tx_conf_acc += interim[i]['tx_conf']
-                rx_conf_acc += interim[i]['rx_conf']
-                up_count_tx += 1
-                up_count_rx += 1
-
-        if up_count_tx == 0 or up_count_rx == 0:
-            continue
-
-        # Evaluate flow imbalance
-        imbalance = rel_diff(sum_tx, sum_rx)
-        if imbalance <= HARDENING_THRESHOLD * 2:
-            # Within tolerance; no router-level scaling needed
-            continue
-
-        avg_tx_conf = tx_conf_acc / max(1, up_count_tx)
-        avg_rx_conf = rx_conf_acc / max(1, up_count_rx)
-
-        # Decide which direction to scale: scale the less trusted direction
-        scale_rx = avg_tx_conf >= avg_rx_conf  # if TX more trusted, scale RX to match TX
-        if scale_rx and sum_rx > 0.0:
-            s = sum_tx / sum_rx
-        elif (not scale_rx) and sum_tx > 0.0:
-            s = sum_rx / sum_tx
-        else:
-            s = 1.0
-
-        # Bound scaling to avoid extreme corrections
-        s_bounded = max(0.5, min(2.0, s))
-
-        # Weighted additive redistribution toward target using lower-trust interfaces more
-        # Prepare per-interface values and weights
-        up_list = [i for i in interfaces if interim[i]['status'] == 'up']
-        if not up_list:
-            continue
-        # Current totals and target delta
-        if scale_rx:
-            sum_old = sum(max(0.0, interim[i]['rx']) for i in up_list)
-            target_total = sum_tx
-        else:
-            sum_old = sum(max(0.0, interim[i]['tx']) for i in up_list)
-            target_total = sum_rx
-        need = target_total - sum_old
-        if abs(need) <= max(sum_old, target_total, 1.0) * (HARDENING_THRESHOLD * 0.5):
-            # Tiny residual; skip redistribution
-            continue
-
-        # Build weights from direction-specific confidence (lower confidence -> larger weight)
-        weights: Dict[str, float] = {}
-        caps_pos: Dict[str, float] = {}
-        caps_neg: Dict[str, float] = {}
-        values: Dict[str, float] = {}
-        for i in up_list:
-            if scale_rx:
-                conf = float(interim[i]['rx_conf'])
-                v = max(0.0, float(interim[i]['rx']))
-            else:
-                conf = float(interim[i]['tx_conf'])
-                v = max(0.0, float(interim[i]['tx']))
-            w = max(0.05, 1.0 - conf)
-            weights[i] = w
-            cap = MAX_ROUTER_ADJ_FRAC * max(v, 1.0)
-            caps_pos[i] = cap
-            caps_neg[i] = cap
-            values[i] = v
-
-        # Iterative allocation with capacity clipping
-        alloc_passes = 2
-        for _alloc in range(alloc_passes):
-            if abs(need) <= EPS:
-                break
-            # Eligible interfaces based on remaining capacity in needed direction
-            if need > 0:
-                elig = [i for i in up_list if caps_pos[i] > EPS]
-            else:
-                elig = [i for i in up_list if caps_neg[i] > EPS]
-            if not elig:
-                break
-            sumW = sum(weights[i] for i in elig)
-            if sumW <= EPS:
-                break
-            for i in elig:
-                quota = need * (weights[i] / sumW)
-                if need > 0:
-                    d = min(max(0.0, quota), caps_pos[i])
-                    caps_pos[i] -= d
-                else:
-                    d = max(min(0.0, quota), -caps_neg[i])
-                    caps_neg[i] -= -d
-                if abs(d) <= EPS:
-                    continue
-                old_v = values[i]
-                new_v = max(0.0, old_v + d)
-                values[i] = new_v
-                # Confidence drops with global imbalance, scaling magnitude and per-interface change
-                delta_rel = rel_diff(old_v, new_v)
-                if scale_rx:
-                    interim[i]['rx'] = new_v
-                    interim[i]['rx_conf'] = clamp(min(interim[i]['rx_conf'], 1.0 - min(1.0, imbalance + 0.5 * delta_rel + abs(1.0 - s_bounded) * 0.5)))
-                else:
-                    interim[i]['tx'] = new_v
-                    interim[i]['tx_conf'] = clamp(min(interim[i]['tx_conf'], 1.0 - min(1.0, imbalance + 0.5 * delta_rel + abs(1.0 - s_bounded) * 0.5)))
-                need -= d
-
-    # Final confidence calibration based on post-repair invariants
-    # Compute per-router imbalance residuals
+        # Only include interfaces that exist and are up
+        up_ifaces = [i for i in if_list if i in telemetry and status_resolved.get(i, 'up') == 'up']
+        if not up_ifaces:
+            continue
+        # Build indices and coefficients: sum(tx) - sum(rx) ≈ 0
+        idxs: List[int] = []
+        coeffs: List[float] = []
+        for i in up_ifaces:
+            idxs.append(idx_tx[i]); coeffs.append(1.0)
+            idxs.append(idx_rx[i]); coeffs.append(-1.0)
+        # Weight scaled modestly by router size to keep comparable influence
+        scale = max(1.0, len(up_ifaces))
+        w_router = W_ROUTER_BASE / scale
+        add_sum_zero(idxs, coeffs, w_router)
+
+    # Add ridge on diagonal to ensure SPD
+    for vi in range(Nvar):
+        h_add(vi, vi, LAMBDA_RIDGE)
+
+    # Conjugate Gradient solver for Hx = g
+    def matvec(vec: List[float]) -> List[float]:
+        out = [0.0] * Nvar
+        for i, row in H.items():
+            s = 0.0
+            # compute row dot vec
+            acc = 0.0
+            for j, v in row.items():
+                acc += v * vec[j]
+            out[i] = acc
+        return out
+
+    def dot(a: List[float], b: List[float]) -> float:
+        return sum(ai * bi for ai, bi in zip(a, b))
+
+    # Initialize with original vector x0
+    x = x0[:]
+    # r = g - Hx
+    Hx = matvec(x)
+    r = [g[i] - Hx[i] for i in range(Nvar)]
+    p = r[:]
+    rsold = dot(r, r)
+    tol = 1e-8 * max(1.0, (rsold ** 0.5))
+    max_iter = max(50, 5 * Nvar)  # modest iterations
+    for _ in range(max_iter):
+        Ap = matvec(p)
+        denom = dot(p, Ap)
+        if abs(denom) < 1e-18:
+            break
+        alpha = rsold / denom
+        x = [xi + alpha * pi for xi, pi in zip(x, p)]
+        r = [ri - alpha * api for ri, api in zip(r, Ap)]
+        rsnew = dot(r, r)
+        if (rsnew ** 0.5) < tol:
+            break
+        beta = rsnew / max(rsold, 1e-18)
+        p = [ri + beta * pi for ri, pi in zip(r, p)]
+        rsold = rsnew
+
+    # Project non-negativity and enforce "down implies zero"
+    repaired_rx: Dict[str, float] = {}
+    repaired_tx: Dict[str, float] = {}
+    for if_id in iface_ids:
+        irx = idx_rx[if_id]; itx = idx_tx[if_id]
+        rx_val = max(0.0, x[irx])
+        tx_val = max(0.0, x[itx])
+        if status_resolved[if_id] == 'down':
+            rx_val = 0.0; tx_val = 0.0
+        repaired_rx[if_id] = rx_val
+        repaired_tx[if_id] = tx_val
+
+    # Build confidence metrics
+    # Per-router imbalance on repaired values
     router_final_imbalance: Dict[str, float] = {}
     for router, if_list in router_ifaces.items():
-        # only consider interfaces that are in interim and up
-        up_ifaces = [i for i in if_list if i in interim and interim[i].get('status') == 'up']
+        up_ifaces = [i for i in if_list if i in telemetry and status_resolved.get(i, 'up') == 'up']
         if not up_ifaces:
             router_final_imbalance[router] = 0.0
             continue
-        sum_tx = sum(max(0.0, interim[i]['tx']) for i in up_ifaces)
-        sum_rx = sum(max(0.0, interim[i]['rx']) for i in up_ifaces)
+        sum_tx = sum(max(0.0, repaired_tx[i]) for i in up_ifaces)
+        sum_rx = sum(max(0.0, repaired_rx[i]) for i in up_ifaces)
         router_final_imbalance[router] = rel_diff(sum_tx, sum_rx)
 
-    # Weights and tolerances for confidence components
-    w_pair, w_router, w_status = 0.6, 0.3, 0.1
-    TOL_PAIR = HARDENING_THRESHOLD * 1.5
-    TOL_ROUTER = HARDENING_THRESHOLD * 2.0
-
-    for if_id, r in interim.items():
-        router = r.get('local_router')
+    # Helper for pair residual-based confidence
+    def pair_conf_for(if_id: str, direction: str) -> float:
         peer = peer_of.get(if_id)
-
-        status_comp = clamp(r.get('status_conf', 0.8))
-        resolved_status = r.get('status', 'unknown')
-
-        if peer and interim.get(peer, {}).get('status') == resolved_status:
-            res_fwd = rel_diff(r['tx'], interim[peer]['rx'])
-            res_rev = rel_diff(r['rx'], interim[peer]['tx'])
-            pair_comp_tx = conf_from_residual(res_fwd, TOL_PAIR)
-            pair_comp_rx = conf_from_residual(res_rev, TOL_PAIR)
+        if not peer:
+            return 0.55
+        if not (status_resolved.get(if_id, 'up') == 'up' and status_resolved.get(peer, 'up') == 'up'):
+            return 0.65
+        if direction == 'tx':
+            v1 = repaired_tx[if_id]; v2 = repaired_rx[peer]
+            traffic = max(v1, v2, 1.0)
         else:
-            pair_comp_tx = 0.55
-            pair_comp_rx = 0.55
-
+            v1 = repaired_rx[if_id]; v2 = repaired_tx[peer]
+            traffic = max(v1, v2, 1.0)
+        resid = rel_diff(v1, v2)
+        tol_pair = min(0.12, max(HARDENING_THRESHOLD * 1.5, 5.0 / traffic))
+        # Two-slope mapping
+        xnorm = resid / max(tol_pair, 1e-9)
+        conf = 1.0 - min(1.0, xnorm / 5.0)
+        if xnorm > 3.0:
+            conf -= 0.1 * (xnorm - 3.0) / 2.0
+        return clamp(conf)
+
+    # Assemble results with confidence calibration
+    result: Dict[str, Dict[str, Tuple]] = {}
+    for if_id in iface_ids:
+        orig_rx = float(telemetry[if_id].get('rx_rate', 0.0))
+        orig_tx = float(telemetry[if_id].get('tx_rate', 0.0))
+        s_orig = telemetry[if_id].get('interface_status', 'unknown')
+        s_res = status_resolved.get(if_id, s_orig)
+        # Status confidence tweaks
+        s_conf = status_conf.get(if_id, 0.8)
+        if s_res == 'up':
+            if repaired_rx[if_id] <= TRAFFIC_EVIDENCE_MIN and repaired_tx[if_id] <= TRAFFIC_EVIDENCE_MIN:
+                s_conf = clamp(s_conf * 0.9)
+        else:
+            if repaired_rx[if_id] > TRAFFIC_EVIDENCE_MIN or repaired_tx[if_id] > TRAFFIC_EVIDENCE_MIN:
+                s_conf = clamp(min(s_conf, 0.3))
+
+        # Pair components
+        pair_tx_conf = pair_conf_for(if_id, 'tx')
+        pair_rx_conf = pair_conf_for(if_id, 'rx')
+
+        # Router component
+        router = telemetry[if_id].get('local_router')
         router_imb = router_final_imbalance.get(router, 0.0)
-        router_comp = conf_from_residual(router_imb, TOL_ROUTER)
-
-        base_tx_conf = w_pair * pair_comp_tx + w_router * router_comp + w_status * status_comp
-        base_rx_conf = w_pair * pair_comp_rx + w_router * router_comp + w_status * status_comp
-
-        # Change penalty to discourage overconfidence on large edits
-        delta_tx_rel = rel_diff(r['orig_tx'], r['tx'])
-        delta_rx_rel = rel_diff(r['orig_rx'], r['rx'])
+        tol_router = TOL_ROUTER
+        xnorm_r = router_imb / max(tol_router, 1e-9)
+        router_comp = 1.0 - min(1.0, xnorm_r / 5.0)
+        if xnorm_r > 3.0:
+            router_comp -= 0.1 * (xnorm_r - 3.0) / 2.0
+        router_comp = clamp(router_comp)
+
+        # Redundancy bonus based on number of factors touching variables
+        vrx = idx_rx[if_id]; vtx = idx_tx[if_id]
+        red_rx = redundancy.get(vrx, 1)
+        red_tx = redundancy.get(vtx, 1)
+        bonus_rx = clamp(0.01 * min(10, red_rx - 1), 0.0, 0.08)
+        bonus_tx = clamp(0.01 * min(10, red_tx - 1), 0.0, 0.08)
+
+        # Change penalties (avoid overconfidence on large edits)
+        delta_rx_rel = rel_diff(orig_rx, repaired_rx[if_id])
+        delta_tx_rel = rel_diff(orig_tx, repaired_tx[if_id])
+        pen_rx = max(0.0, delta_rx_rel - HARDENING_THRESHOLD)
         pen_tx = max(0.0, delta_tx_rel - HARDENING_THRESHOLD)
-        pen_rx = max(0.0, delta_rx_rel - HARDENING_THRESHOLD)
-        CHANGE_PENALTY_WEIGHT = 0.5
-        final_tx_conf = clamp(base_tx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_tx))
-        final_rx_conf = clamp(base_rx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_rx))
-
-        if resolved_status == 'down':
-            final_rx_conf = 0.9 if r['orig_rx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
-            final_tx_conf = 0.9 if r['orig_tx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
-
-        r['tx_conf'] = final_tx_conf
-        r['rx_conf'] = final_rx_conf
-
-        # Subtle status calibration: if up but effectively idle, reduce status confidence slightly
-        if resolved_status == 'up':
-            if r['rx'] <= TRAFFIC_EVIDENCE_MIN and r['tx'] <= TRAFFIC_EVIDENCE_MIN:
-                r['status_conf'] = clamp(r['status_conf'] * 0.9)
-        elif resolved_status == 'down':
-            if r['rx'] > TRAFFIC_EVIDENCE_MIN or r['tx'] > TRAFFIC_EVIDENCE_MIN:
-                r['status_conf'] = clamp(min(r['status_conf'], 0.3))
-
-    # Assemble final result with (original, repaired, confidence) tuples and unchanged metadata
-    for if_id, data in telemetry.items():
-        repaired_data: Dict[str, Tuple] = {}
-        r = interim[if_id]
-
-        repaired_data['rx_rate'] = (r['orig_rx'], r['rx'], clamp(r['rx_conf']))
-        repaired_data['tx_rate'] = (r['orig_tx'], r['tx'], clamp(r['tx_conf']))
-        repaired_data['interface_status'] = (r['orig_status'], r['status'], clamp(r['status_conf']))
-
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = r['connected_to']
-        repaired_data['local_router'] = r['local_router']
-        repaired_data['remote_router'] = r['remote_router']
-
-        result[if_id] = repaired_data
+
+        # Blend components
+        w_pair, w_router, w_status = 0.6, 0.3, 0.1
+        base_rx = w_pair * pair_rx_conf + w_router * router_comp + w_status * s_conf
+        base_tx = w_pair * pair_tx_conf + w_router * router_comp + w_status * s_conf
+
+        # Apply redundancy bonuses and change penalties
+        conf_rx = clamp((base_rx + bonus_rx) * (1.0 - 0.5 * pen_rx))
+        conf_tx = clamp((base_tx + bonus_tx) * (1.0 - 0.5 * pen_tx))
+
+        # No-edit bonus
+        if rel_diff(orig_rx, repaired_rx[if_id]) <= 1e-3:
+            conf_rx = clamp(conf_rx + 0.05)
+        if rel_diff(orig_tx, repaired_tx[if_id]) <= 1e-3:
+            conf_tx = clamp(conf_tx + 0.05)
+
+        # Down status confidence override
+        if s_res == 'down':
+            conf_rx = 0.9 if orig_rx <= TRAFFIC_EVIDENCE_MIN else 0.3
+            conf_tx = 0.9 if orig_tx <= TRAFFIC_EVIDENCE_MIN else 0.3
+
+        result[if_id] = {
+            'rx_rate': (orig_rx, repaired_rx[if_id], conf_rx),
+            'tx_rate': (orig_tx, repaired_tx[if_id], conf_tx),
+            'interface_status': (s_orig, s_res, clamp(s_conf)),
+            # Metadata unchanged
+            'connected_to': telemetry[if_id].get('connected_to'),
+            'local_router': telemetry[if_id].get('local_router'),
+            'remote_router': telemetry[if_id].get('remote_router'),
+        }
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")