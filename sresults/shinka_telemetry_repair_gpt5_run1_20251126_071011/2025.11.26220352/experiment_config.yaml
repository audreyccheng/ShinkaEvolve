database_config:
  archive_size: 40
  db_path: /home/ubuntu/zresults/shinka_telemetry_repair_gpt5_run1_20251126_071011/2025.11.26220352/evolution_db.sqlite
  elite_selection_ratio: 0.3
  embedding_model: text-embedding-3-small
  enforce_island_separation: true
  exploitation_alpha: 1.0
  exploitation_ratio: 0.2
  island_elitism: true
  migration_interval: 10
  migration_rate: 0.0
  num_archive_inspirations: 4
  num_beams: 5
  num_islands: 2
  num_top_k_inspirations: 2
  parent_selection_lambda: 10.0
  parent_selection_strategy: weighted
evolution_config:
  code_embed_sim_threshold: 1.0
  embedding_model: text-embedding-3-small
  init_program_path: examples/telemetry_repair/initial.py
  job_type: local
  language: python
  llm_dynamic_selection: null
  llm_dynamic_selection_kwargs: {}
  llm_kwargs: &id001 !!python/object:omegaconf.dictconfig.DictConfig
    _content:
      max_tokens: !!python/object:omegaconf.nodes.AnyNode
        _metadata: !!python/object:omegaconf.base.Metadata
          flags: {}
          flags_root: false
          key: max_tokens
          object_type: null
          optional: true
          ref_type: &id002 !!python/name:typing.Any ''
          resolver_cache: !!python/object/apply:collections.defaultdict
          - &id003 !!python/name:builtins.dict ''
        _parent: *id001
        _val: 32768
      temperatures: &id004 !!python/object:omegaconf.listconfig.ListConfig
        _content:
        - !!python/object:omegaconf.nodes.AnyNode
          _metadata: !!python/object:omegaconf.base.Metadata
            flags: {}
            flags_root: false
            key: 0
            object_type: null
            optional: true
            ref_type: *id002
            resolver_cache: !!python/object/apply:collections.defaultdict
            - *id003
          _parent: *id004
          _val: 0.0
        - !!python/object:omegaconf.nodes.AnyNode
          _metadata: !!python/object:omegaconf.base.Metadata
            flags: {}
            flags_root: false
            key: 1
            object_type: null
            optional: true
            ref_type: *id002
            resolver_cache: !!python/object/apply:collections.defaultdict
            - *id003
          _parent: *id004
          _val: 0.5
        - !!python/object:omegaconf.nodes.AnyNode
          _metadata: !!python/object:omegaconf.base.Metadata
            flags: {}
            flags_root: false
            key: 2
            object_type: null
            optional: true
            ref_type: *id002
            resolver_cache: !!python/object/apply:collections.defaultdict
            - *id003
          _parent: *id004
          _val: 0.7
        - !!python/object:omegaconf.nodes.AnyNode
          _metadata: !!python/object:omegaconf.base.Metadata
            flags: {}
            flags_root: false
            key: 3
            object_type: null
            optional: true
            ref_type: *id002
            resolver_cache: !!python/object/apply:collections.defaultdict
            - *id003
          _parent: *id004
          _val: 1.0
        _metadata: !!python/object:omegaconf.base.ContainerMetadata
          element_type: *id002
          flags:
            allow_objects: true
          flags_root: false
          key: temperatures
          key_type: &id006 !!python/name:builtins.int ''
          object_type: &id007 !!python/name:builtins.list ''
          optional: true
          ref_type: *id002
          resolver_cache: !!python/object/apply:collections.defaultdict
          - *id003
        _parent: *id001
    _metadata: !!python/object:omegaconf.base.ContainerMetadata
      element_type: *id002
      flags:
        allow_objects: true
      flags_root: false
      key: null
      key_type: *id002
      object_type: *id003
      optional: true
      ref_type: *id002
      resolver_cache: !!python/object/apply:collections.defaultdict
      - *id003
    _parent: null
  llm_models: &id005 !!python/object:omegaconf.listconfig.ListConfig
    _content:
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 0
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id005
      _val: gpt-5
    _metadata: !!python/object:omegaconf.base.ContainerMetadata
      element_type: *id002
      flags:
        allow_objects: true
      flags_root: false
      key: null
      key_type: *id006
      object_type: *id007
      optional: true
      ref_type: *id002
      resolver_cache: !!python/object/apply:collections.defaultdict
      - *id003
    _parent: null
  max_novelty_attempts: 3
  max_parallel_jobs: 10
  max_patch_attempts: 3
  max_patch_resamples: 3
  meta_llm_kwargs: &id009 !!python/object:omegaconf.dictconfig.DictConfig
    _content:
      temperatures: &id008 !!python/object:omegaconf.listconfig.ListConfig
        _content:
        - !!python/object:omegaconf.nodes.AnyNode
          _metadata: !!python/object:omegaconf.base.Metadata
            flags: {}
            flags_root: false
            key: 0
            object_type: null
            optional: true
            ref_type: *id002
            resolver_cache: !!python/object/apply:collections.defaultdict
            - *id003
          _parent: *id008
          _val: 0.0
        _metadata: !!python/object:omegaconf.base.ContainerMetadata
          element_type: *id002
          flags:
            allow_objects: true
          flags_root: false
          key: temperatures
          key_type: *id006
          object_type: *id007
          optional: true
          ref_type: *id002
          resolver_cache: !!python/object/apply:collections.defaultdict
          - *id003
        _parent: *id009
    _metadata: !!python/object:omegaconf.base.ContainerMetadata
      element_type: *id002
      flags:
        allow_objects: true
      flags_root: false
      key: null
      key_type: *id002
      object_type: *id003
      optional: true
      ref_type: *id002
      resolver_cache: !!python/object/apply:collections.defaultdict
      - *id003
    _parent: null
  meta_llm_models: &id010 !!python/object:omegaconf.listconfig.ListConfig
    _content:
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 0
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id010
      _val: gpt-5
    _metadata: !!python/object:omegaconf.base.ContainerMetadata
      element_type: *id002
      flags:
        allow_objects: true
      flags_root: false
      key: null
      key_type: *id006
      object_type: *id007
      optional: true
      ref_type: *id002
      resolver_cache: !!python/object/apply:collections.defaultdict
      - *id003
    _parent: null
  meta_max_recommendations: 5
  meta_rec_interval: 15
  novelty_llm_kwargs: {}
  novelty_llm_models: null
  num_generations: 100
  patch_type_probs: &id011 !!python/object:omegaconf.listconfig.ListConfig
    _content:
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 0
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id011
      _val: 0.6
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 1
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id011
      _val: 0.3
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 2
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id011
      _val: 0.1
    _metadata: !!python/object:omegaconf.base.ContainerMetadata
      element_type: *id002
      flags:
        allow_objects: true
      flags_root: false
      key: null
      key_type: *id006
      object_type: *id007
      optional: true
      ref_type: *id002
      resolver_cache: !!python/object/apply:collections.defaultdict
      - *id003
    _parent: null
  patch_types: &id012 !!python/object:omegaconf.listconfig.ListConfig
    _content:
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 0
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id012
      _val: diff
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 1
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id012
      _val: full
    - !!python/object:omegaconf.nodes.AnyNode
      _metadata: !!python/object:omegaconf.base.Metadata
        flags: {}
        flags_root: false
        key: 2
        object_type: null
        optional: true
        ref_type: *id002
        resolver_cache: !!python/object/apply:collections.defaultdict
        - *id003
      _parent: *id012
      _val: cross
    _metadata: !!python/object:omegaconf.base.ContainerMetadata
      element_type: *id002
      flags:
        allow_objects: true
      flags_root: false
      key: null
      key_type: *id006
      object_type: *id007
      optional: true
      ref_type: *id002
      resolver_cache: !!python/object/apply:collections.defaultdict
      - *id003
    _parent: null
  results_dir: /home/ubuntu/zresults/shinka_telemetry_repair_gpt5_run1_20251126_071011/2025.11.26220352
  task_sys_msg: "You are an expert in network telemetry repair algorithms.\n\n# RESEARCH\
    \ CONTEXT\nThe following research provides important background on network input\
    \ validation:\n\n## Core Problem\nNetwork controllers often receive **incorrect\
    \ inputs** that don't accurately reflect network state, causing major outages.\
    \ Over 1/3 of production outages are caused by incorrect inputs to SDN controllers.\n\
    \n## Key Validation Principles\n\n### Three-Step Validation Approach (Hodor System):\n\
    1. **Signal Collection**: Gather redundant signals from network devices\n2. **Signal\
    \ Hardening**: Use redundancy to detect and correct faulty measurements  \n3.\
    \ **Dynamic Checking**: Verify inputs against hardened network state\n\n### Critical\
    \ Network Invariants for Validation:\n1. **Link Symmetry (R3)**: `my_tx_rate \u2248\
    \ their_rx_rate` for connected interfaces\n2. **Flow Conservation (R1)**: `\u03A3\
    (incoming_traffic) = \u03A3(outgoing_traffic)` at each router\n3. **Interface\
    \ Consistency**: Status should be consistent across connected pairs\n\n## Repair\
    \ Strategy from Research\n- **Detection**: Compare outgoing interface count to\
    \ incoming interface count on each side of links\n- **Repair**: Use flow conservation\
    \ principle - traffic into a router must equal traffic out\n- **Confidence**:\
    \ Higher confidence when multiple redundant signals agree\n- **Hardening threshold**\
    \ (\u03C4h \u2248 2%) to account for measurement timing differences\n\n# TASK\
    \ SPECIFICATION\n\nYour task is to evolve a Python function called `repair_network_telemetry`\
    \ that takes \npotentially corrupted network interface data and repairs it while\
    \ providing confidence scores.\n\nContext about networks: the transmission and\
    \ receiving rates are the number of bytes sent and received per second. \nIn a\
    \ healthy state, packets are not dropped on links or at routers. An interface\
    \ that is down cannot be sending or receiving.\n\nFUNCTION SIGNATURE:\n  def repair_network_telemetry(telemetry:\
    \ Dict[str, Dict[str, Any]], \n                         topology: Dict[str, List[str]])\
    \ -> Dict[str, Dict[str, Tuple]]:\n\nINPUT FORMAT:\n- Dictionary of interface_id\
    \ -> telemetry data\n        - interface_status: \"up\" or \"down\" \n       \
    \ - rx_rate: receive rate in Mbps\n        - tx_rate: transmit rate in Mbps\n\
    \        - connected_to: interface_id this interface connects to\n        - local_router:\
    \ router_id this interface belongs to\n        - remote_router: router_id on the\
    \ other side\n- Dictionary of topology where key is router_id and value contains\
    \ a list of interface_ids. You can use this\n  to find or check relationships\
    \ that should apply to counters at a single router.\n- Telemetry data may be corrupted\
    \ (wrong rates, inconsistent with connected interfaces)\n\nOUTPUT FORMAT:\n -\
    \ Same structure as telemetry, but telemetry values become (original_value, repaired_value,\
    \ confidence) tuples\n - confidence ranges from 0.0 (very uncertain) to 1.0 (very\
    \ confident in repair)\n - Non-telemetry fields (connected_to, etc.) are copied\
    \ unchanged\n \n REPAIR STRATEGY:\n- The best algorithm would be one that leaves\
    \ correct telemetry unchanged, but detects and\n  repairs telemetry that is wrong\
    \ to be correct again. \n- You can use the topology to help you repair telemetry.\
    \ \n\nCONFIDENCE CALIBRATION:\nYour confidence scores will be evaluated for calibration\
    \ - they must reflect repair accuracy:\n- That is, the confidence score should\
    \ be high when the repaired value is very close to the ground truth value.\n-\
    \ The confidence score should be low when the repaired value is very different\
    \ from the ground truth value.\n- Your solution will be penalised for overconfidence\
    \ in bad repairs (dangerous)\n- Your solution will be penalised for underconfidence\
    \ in good repairs (wasteful)\n\nEVALUATION METRICS:\n1. counter_repair_accuracy:\
    \ How close repaired rx/tx rates are to ground truth\n2. status_repair_accuracy:\
    \ How well interface status is repaired  \n3. confidence_calibration: How well\
    \ confidence scores reflect actual repair quality\n4. combined_score: Weighted\
    \ combination (75% counter + 5% status + 20% confidence)\n\nFocus on algorithms\
    \ that both repair accurately AND provide accurate indiciations of confidence.\n\
    \nThink out-loud and reason step-by-step conceptually about what idea you want\
    \ to try and why. Be detailed in your reasoning. Consider what will\nmake implementing\
    \ that idea difficult or tricky, and how to do it elegantly. Then provide your\
    \ code.\n\nIf you *don't* use the topology, please leave a comment in the code\
    \ explaining why not. It ought to be useful.\n"
  use_text_feedback: false
job_config:
  conda_env: null
  eval_program_path: examples/telemetry_repair/evaluate.py
  extra_cmd_args: {}
  time: null
results_directory: /home/ubuntu/zresults/shinka_telemetry_repair_gpt5_run1_20251126_071011/2025.11.26220352
timestamp: '2025-11-27T04:04:00.169872'
