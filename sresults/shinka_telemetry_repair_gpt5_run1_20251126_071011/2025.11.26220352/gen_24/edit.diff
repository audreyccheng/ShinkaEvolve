--- a/original.py
+++ b/original.py
@@ -1,489 +1,378 @@
 # EVOLVE-BLOCK-START
 """
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+Variance-weighted consensus telemetry repair:
+- Factor-graph inspired projections with Gaussian beliefs.
+- Link equality and router flow conservation enforced iteratively.
+- Confidence derived from residuals (logistic), changes, and posterior variances.
+
+Maintains the same inputs/outputs as prior implementations.
 """
 from typing import Dict, Any, Tuple, List
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
-    """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-
-    Core principle: Use network invariants to validate and repair telemetry:
-    1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
-    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
-    3. Interface Consistency: Status should be consistent across connected pairs
-
-    Args:
-        telemetry: Dictionary where key is interface_id and value contains:
-            - interface_status: "up" or "down"
-            - rx_rate: receive rate in Mbps
-            - tx_rate: transmit rate in Mbps
-            - connected_to: interface_id this interface connects to
-            - local_router: router_id this interface belongs to
-            - remote_router: router_id on the other side
-        topology: Dictionary where key is router_id and value contains a list of interface_ids
-
-    Returns:
-        Dictionary with same structure but telemetry values become tuples of:
-        (original_value, repaired_value, confidence_score)
-        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
-    """
-
-    # Measurement timing tolerance (from Hodor research: ~2%)
-    HARDENING_THRESHOLD = 0.02
-    # Small traffic level used to infer link up when statuses disagree (Mbps)
-    TRAFFIC_EVIDENCE_MIN = 0.5
-    # Max fractional per-interface adjustment during router redistribution
-    MAX_ROUTER_ADJ_FRAC = 0.35
-    # Pair reconciliation weight toward midpoint after router pass
-    PAIR_RECONCILE_ALPHA = 0.25
-    # Secondary router rebalancing cap (gentler than primary)
-    SECONDARY_ROUTER_ADJ_FRAC = 0.15
+    # Core tolerances
+    HARDENING_THRESHOLD = 0.02  # ~2% timing tolerance
+    TRAFFIC_EVIDENCE_MIN = 0.5  # Mbps
     EPS = 1e-9
 
+    # Iteration parameters
+    ITERATIONS = 4
+    ALPHA_LINK = 0.8
+    ALPHA_ROUTER = 0.8
+    FINAL_LINK_ALPHA = 0.35
+
+    # Noise model for priors (sigma = rel*value + abs_floor)
+    REL_SIGMA = 0.03
+    ABS_SIGMA = 0.5  # Mbps
+
+    # Helper functions
     def clamp(x: float, lo: float = 0.0, hi: float = 1.0) -> float:
         return max(lo, min(hi, x))
 
     def rel_diff(a: float, b: float) -> float:
         denom = max(abs(a), abs(b), 1e-9)
         return abs(a - b) / denom
 
-    def conf_from_residual(residual: float, tol: float) -> float:
-        # Map residual to confidence: 1 at 0 residual, degrades linearly until ~0 near 5*tol
-        denom = max(tol * 5.0, 1e-9)
-        return clamp(1.0 - residual / denom)
-
-    # Initialize structures
-    result: Dict[str, Dict[str, Tuple]] = {}
-    # Store interim repaired values and confidences per interface before router-level hardening
-    interim: Dict[str, Dict[str, Any]] = {}
+    def conf_from_residual_logistic(residual: float, tol: float) -> float:
+        # Logistic decay: 1 at residual << tol, ~0.5 near tol, down thereafter
+        tol = max(tol, 1e-9)
+        x = residual / tol
+        k = 3.0
+        # 1 / (1 + e^{k(x-1)})
+        import math
+        return clamp(1.0 / (1.0 + math.e ** (k * (x - 1.0))))
+
+    def init_variance(v: float) -> float:
+        # Variance from absolute and relative noise
+        scale = max(abs(v), 1.0)
+        sigma = REL_SIGMA * scale + ABS_SIGMA
+        return sigma * sigma
 
     # Build connected pairs
-    visited = set()
+    visited_pairs = set()
     pairs: List[Tuple[str, str]] = []
     for if_id, data in telemetry.items():
         peer = data.get('connected_to')
         if peer and peer in telemetry:
-            # Use ordered tuple to avoid duplicates
             key = tuple(sorted([if_id, peer]))
-            if key not in visited:
-                visited.add(key)
+            if key not in visited_pairs:
+                visited_pairs.add(key)
                 pairs.append((key[0], key[1]))
 
-    # Map each interface to its peer for quick lookup and record paired IDs
     peer_of: Dict[str, str] = {}
     paired_ids = set()
     for a_id, b_id in pairs:
         peer_of[a_id] = b_id
         peer_of[b_id] = a_id
         paired_ids.add(a_id)
         paired_ids.add(b_id)
 
-    # Initialize defaults for all interfaces
+    # Initialize working state
+    work: Dict[str, Dict[str, Any]] = {}
     for if_id, data in telemetry.items():
-        interim[if_id] = {
-            'rx': float(data.get('rx_rate', 0.0)),
-            'tx': float(data.get('tx_rate', 0.0)),
-            'rx_conf': 1.0,
-            'tx_conf': 1.0,
-            'status': data.get('interface_status', 'unknown'),
+        rx0 = float(data.get('rx_rate', 0.0))
+        tx0 = float(data.get('tx_rate', 0.0))
+        status0 = data.get('interface_status', 'unknown')
+        work[if_id] = {
+            'rx': rx0,
+            'tx': tx0,
+            'rx_var': init_variance(rx0),
+            'tx_var': init_variance(tx0),
+            'status': status0,
             'status_conf': 1.0,
             'connected_to': data.get('connected_to'),
             'local_router': data.get('local_router'),
             'remote_router': data.get('remote_router'),
-            # Keep originals for output tuples
-            'orig_rx': float(data.get('rx_rate', 0.0)),
-            'orig_tx': float(data.get('tx_rate', 0.0)),
-            'orig_status': data.get('interface_status', 'unknown'),
+            'orig_rx': rx0,
+            'orig_tx': tx0,
+            'orig_status': status0,
+            'base_rx_var': init_variance(rx0),
+            'base_tx_var': init_variance(tx0),
         }
 
-    # Pair-level hardening using link symmetry (R3) and interface consistency
+    # Resolve interface status consistency across links with traffic evidence
     for a_id, b_id in pairs:
-        a = telemetry[a_id]
-        b = telemetry[b_id]
-        a_stat = a.get('interface_status', 'unknown')
-        b_stat = b.get('interface_status', 'unknown')
-        a_rx, a_tx = float(a.get('rx_rate', 0.0)), float(a.get('tx_rate', 0.0))
-        b_rx, b_tx = float(b.get('rx_rate', 0.0)), float(b.get('tx_rate', 0.0))
-        max_traffic = max(a_rx, a_tx, b_rx, b_tx)
-
-        # Resolve interface status consistency across the link
+        a = work[a_id]; b = work[b_id]
+        a_stat = a['status']; b_stat = b['status']
+        max_traffic = max(a['rx'], a['tx'], b['rx'], b['tx'])
         if a_stat == b_stat:
-            resolved_status = a_stat
-            status_conf = 0.95 if resolved_status in ('up', 'down') else 0.7
+            resolved = a_stat
+            sconf = 0.95 if resolved in ('up', 'down') else 0.7
         else:
-            # Use traffic evidence: if there is noticeable traffic, link must be up
             if max_traffic > TRAFFIC_EVIDENCE_MIN:
-                resolved_status = 'up'
-                status_conf = 0.85
+                resolved = 'up'; sconf = 0.85
             else:
-                resolved_status = 'down'
-                status_conf = 0.75
-
-        # Apply status to both ends
-        interim[a_id]['status'] = resolved_status
-        interim[b_id]['status'] = resolved_status
-        interim[a_id]['status_conf'] = min(interim[a_id]['status_conf'], status_conf) if interim[a_id]['status_conf'] else status_conf
-        interim[b_id]['status_conf'] = min(interim[b_id]['status_conf'], status_conf) if interim[b_id]['status_conf'] else status_conf
-
-        if resolved_status == 'down':
-            # Down interfaces cannot send or receive
-            # Confidence is high if original values were already near zero, lower otherwise.
-            for ifid, rx0, tx0 in [(a_id, a_rx, a_tx), (b_id, b_rx, b_tx)]:
-                interim[ifid]['rx'] = 0.0
-                interim[ifid]['tx'] = 0.0
-                interim[ifid]['rx_conf'] = clamp(0.9 if rx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-                interim[ifid]['tx_conf'] = clamp(0.9 if tx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-            continue  # No need to harden rates if link is down
-
-        # Link is up: harden both directions using symmetry
-        # Forward direction: a.tx should match b.rx
-        d_fwd = rel_diff(a_tx, b_rx)
-        if d_fwd <= HARDENING_THRESHOLD:
-            v = 0.5 * (a_tx + b_rx)
-            conf = clamp(1.0 - 0.5 * d_fwd)  # near 1 when very close
-        else:
-            # Choose peer's counterpart as stronger signal
-            v = b_rx if abs(b_rx) > 0 else a_tx
-            conf = clamp(1.0 - d_fwd)  # lower confidence for larger violation
-        interim[a_id]['tx'] = v
-        interim[b_id]['rx'] = v
-        interim[a_id]['tx_conf'] = min(interim[a_id]['tx_conf'], conf)
-        interim[b_id]['rx_conf'] = min(interim[b_id]['rx_conf'], conf)
-
-        # Reverse direction: a.rx should match b.tx
-        d_rev = rel_diff(a_rx, b_tx)
-        if d_rev <= HARDENING_THRESHOLD:
-            v2 = 0.5 * (a_rx + b_tx)
-            conf2 = clamp(1.0 - 0.5 * d_rev)
-        else:
-            v2 = b_tx if abs(b_tx) > 0 else a_rx
-            conf2 = clamp(1.0 - d_rev)
-        interim[a_id]['rx'] = v2
-        interim[b_id]['tx'] = v2
-        interim[a_id]['rx_conf'] = min(interim[a_id]['rx_conf'], conf2)
-        interim[b_id]['tx_conf'] = min(interim[b_id]['tx_conf'], conf2)
-
-    # Enforce "down implies zero traffic" also for unpaired interfaces
-    for if_id, r in interim.items():
-        if if_id not in paired_ids and r.get('status') == 'down':
-            rx0 = r['rx']
-            tx0 = r['tx']
-            r['rx'] = 0.0
-            r['tx'] = 0.0
-            r['rx_conf'] = clamp(0.9 if rx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-            r['tx_conf'] = clamp(0.9 if tx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-
-    # Build router to interfaces map (use provided topology if available, else derive from telemetry)
+                resolved = 'down'; sconf = 0.75
+        a['status'] = resolved; b['status'] = resolved
+        a['status_conf'] = min(a['status_conf'], sconf)
+        b['status_conf'] = min(b['status_conf'], sconf)
+
+    # If status down, force zero rates and set small variance (high confidence)
+    for if_id, r in work.items():
+        if r['status'] == 'down':
+            rx0, tx0 = r['rx'], r['tx']
+            r['rx'] = 0.0; r['tx'] = 0.0
+            # Very small variance to keep at zero
+            r['rx_var'] = (ABS_SIGMA * 0.1) ** 2
+            r['tx_var'] = (ABS_SIGMA * 0.1) ** 2
+            r['status_conf'] = 0.9 if (rx0 <= TRAFFIC_EVIDENCE_MIN and tx0 <= TRAFFIC_EVIDENCE_MIN) else 0.5
+
+    # Build router interfaces using provided topology else derive best-effort from telemetry
     router_ifaces: Dict[str, List[str]] = {}
     if topology:
-        router_ifaces = {r: [i for i in if_list if i in interim] for r, if_list in topology.items()}
+        router_ifaces = {r: [i for i in lst if i in work] for r, lst in topology.items()}
     else:
-        # If topology not provided, derive from telemetry metadata
-        # Note: Topology helps flow conservation; we derive a best-effort map when absent.
-        for if_id, data in telemetry.items():
-            r = data.get('local_router')
-            if r is not None:
-                router_ifaces.setdefault(r, []).append(if_id)
-
-    def router_redistribute(max_adj_frac: float) -> None:
-        # Uncertainty-weighted, capacity-capped redistribution towards flow conservation
+        # Use telemetry metadata if topology not provided
+        for if_id, data in work.items():
+            rtr = data.get('local_router')
+            if rtr is not None:
+                router_ifaces.setdefault(rtr, []).append(if_id)
+
+    # Iterative variance-weighted consensus
+    import math
+    for it in range(ITERATIONS):
+        # Link consensus step
+        for a_id, b_id in pairs:
+            a = work[a_id]; b = work[b_id]
+            if a['status'] != 'up' or b['status'] != 'up':
+                continue
+            # Forward direction: a.tx <-> b.rx
+            x = float(a['tx']); vx = float(a['tx_var'])
+            y = float(b['rx']); vy = float(b['rx_var'])
+            vscale = max((x + y) / 2.0, 1.0)
+            tau_link = max(HARDENING_THRESHOLD * vscale, 0.01 * vscale)
+            p_link = 1.0 / (tau_link * tau_link)
+            px = 1.0 / max(vx, EPS)
+            py = 1.0 / max(vy, EPS)
+            denom = px + py + p_link
+            if denom > EPS:
+                v_cons = (px * x + py * y) / denom
+                new = (1.0 - ALPHA_LINK) * x + ALPHA_LINK * v_cons
+                a['tx'] = max(0.0, new)
+                b['rx'] = max(0.0, new)
+                # Posterior variance for both ends (approximate sharing)
+                v_post = 1.0 / denom
+                a['tx_var'] = max(v_post, 0.01 * a['tx_var'])
+                b['rx_var'] = max(v_post, 0.01 * b['rx_var'])
+
+            # Reverse direction: a.rx <-> b.tx
+            x = float(a['rx']); vx = float(a['rx_var'])
+            y = float(b['tx']); vy = float(b['tx_var'])
+            vscale = max((x + y) / 2.0, 1.0)
+            tau_link = max(HARDENING_THRESHOLD * vscale, 0.01 * vscale)
+            p_link = 1.0 / (tau_link * tau_link)
+            px = 1.0 / max(vx, EPS)
+            py = 1.0 / max(vy, EPS)
+            denom = px + py + p_link
+            if denom > EPS:
+                v_cons = (px * x + py * y) / denom
+                new = (1.0 - ALPHA_LINK) * x + ALPHA_LINK * v_cons
+                a['rx'] = max(0.0, new)
+                b['tx'] = max(0.0, new)
+                v_post = 1.0 / denom
+                a['rx_var'] = max(v_post, 0.01 * a['rx_var'])
+                b['tx_var'] = max(v_post, 0.01 * b['tx_var'])
+
+        # Router conservation step
         for router, if_list in router_ifaces.items():
-            interfaces = [i for i in if_list if i in interim]
-            if not interfaces:
+            # Collect up interfaces
+            up_ifaces = [i for i in if_list if work[i]['status'] == 'up']
+            if not up_ifaces:
                 continue
 
-            # Compute sums over "up" interfaces
-            sum_tx = 0.0
-            sum_rx = 0.0
-            tx_conf_acc = 0.0
-            rx_conf_acc = 0.0
-            up_list = []
-            for i in interfaces:
-                if interim[i]['status'] == 'up':
-                    up_list.append(i)
-                    sum_tx += max(0.0, interim[i]['tx'])
-                    sum_rx += max(0.0, interim[i]['rx'])
-                    tx_conf_acc += interim[i]['tx_conf']
-                    rx_conf_acc += interim[i]['rx_conf']
-
-            if not up_list:
+            sum_tx = sum(max(0.0, work[i]['tx']) for i in up_ifaces)
+            sum_rx = sum(max(0.0, work[i]['rx']) for i in up_ifaces)
+            need = sum_tx - sum_rx  # want this to be zero
+
+            # If within tolerance skip
+            if rel_diff(sum_tx, sum_rx) <= HARDENING_THRESHOLD * 1.5:
                 continue
 
-            # Evaluate flow imbalance
-            imbalance = rel_diff(sum_tx, sum_rx)
-            if imbalance <= HARDENING_THRESHOLD * 2:
-                # Within tolerance; no router-level scaling needed
+            # Use Lagrange multiplier solution: minimize sum (delta^2 / var) s.t. sum_tx+dt - (sum_rx+dr) = 0
+            var_tx_sum = sum(max(work[i]['tx_var'], EPS) for i in up_ifaces)
+            var_rx_sum = sum(max(work[i]['rx_var'], EPS) for i in up_ifaces)
+            denom = var_tx_sum + var_rx_sum
+            if denom <= EPS:
                 continue
-
-            avg_tx_conf = tx_conf_acc / max(1, len(up_list))
-            avg_rx_conf = rx_conf_acc / max(1, len(up_list))
-
-            # Decide which direction to scale: scale the less trusted direction
-            scale_rx = avg_tx_conf >= avg_rx_conf  # if TX more trusted, scale RX to match TX
-            if scale_rx and sum_rx > 0.0:
-                s = sum_tx / sum_rx
-            elif (not scale_rx) and sum_tx > 0.0:
-                s = sum_rx / sum_tx
-            else:
-                s = 1.0
-
-            # Bound scaling magnitude for confidence penalty computation
-            s_bounded = max(0.5, min(2.0, s))
-
-            # Target totals
-            if scale_rx:
-                sum_old = sum(max(0.0, interim[i]['rx']) for i in up_list)
-                target_total = sum_tx
-            else:
-                sum_old = sum(max(0.0, interim[i]['tx']) for i in up_list)
-                target_total = sum_rx
-
-            need = target_total - sum_old
-            if abs(need) <= max(sum_old, target_total, 1.0) * (HARDENING_THRESHOLD * 0.5):
-                # Tiny residual; skip redistribution
-                continue
-
-            # Build weights from direction-specific confidence (lower confidence -> larger weight)
-            weights: Dict[str, float] = {}
-            caps_pos: Dict[str, float] = {}
-            caps_neg: Dict[str, float] = {}
-            values: Dict[str, float] = {}
-            for i in up_list:
-                if scale_rx:
-                    conf = float(interim[i]['rx_conf'])
-                    v = max(0.0, float(interim[i]['rx']))
-                else:
-                    conf = float(interim[i]['tx_conf'])
-                    v = max(0.0, float(interim[i]['tx']))
-                w = max(0.05, 1.0 - conf)
-                weights[i] = w
-                cap = max_adj_frac * max(v, 1.0)
-                caps_pos[i] = cap
-                caps_neg[i] = cap
-                values[i] = v
-
-            # Iterative allocation with capacity clipping
-            for _alloc in range(2):
-                if abs(need) <= EPS:
-                    break
-                elig = [i for i in up_list if (caps_pos[i] if need > 0 else caps_neg[i]) > EPS]
-                if not elig:
-                    break
-                sumW = sum(weights[i] for i in elig)
-                if sumW <= EPS:
-                    break
-                for i in elig:
-                    quota = need * (weights[i] / sumW)
-                    if need > 0:
-                        d = min(max(0.0, quota), caps_pos[i])
-                        caps_pos[i] -= d
-                    else:
-                        d = max(min(0.0, quota), -caps_neg[i])
-                        caps_neg[i] -= -d
-                    if abs(d) <= EPS:
-                        continue
-                    old_v = values[i]
-                    new_v = max(0.0, old_v + d)
-                    values[i] = new_v
-                    # Confidence drops with global imbalance, scaling magnitude and per-interface change
-                    delta_rel = rel_diff(old_v, new_v)
-                    if scale_rx:
-                        interim[i]['rx'] = new_v
-                        interim[i]['rx_conf'] = clamp(min(interim[i]['rx_conf'],
-                                                          1.0 - min(1.0, imbalance + 0.5 * delta_rel + abs(1.0 - s_bounded) * 0.5)))
-                    else:
-                        interim[i]['tx'] = new_v
-                        interim[i]['tx_conf'] = clamp(min(interim[i]['tx_conf'],
-                                                          1.0 - min(1.0, imbalance + 0.5 * delta_rel + abs(1.0 - s_bounded) * 0.5)))
-                    need -= d
-
-    # Primary router redistribution
-    router_redistribute(MAX_ROUTER_ADJ_FRAC)
-
-    # Limited pair-symmetry reconciliation after router redistribution
+            lam = need / denom
+
+            # Apply updates with damping and non-negativity; shrink variance slightly
+            for i in up_ifaces:
+                vtx = work[i]['tx_var']; vrx = work[i]['rx_var']
+                d_tx = -ALPHA_ROUTER * lam * vtx
+                d_rx = +ALPHA_ROUTER * lam * vrx
+                # Clip to avoid negative
+                if work[i]['tx'] + d_tx < 0.0:
+                    d_tx = -work[i]['tx']
+                if work[i]['rx'] + d_rx < 0.0:
+                    d_rx = -work[i]['rx']
+                work[i]['tx'] = max(0.0, work[i]['tx'] + d_tx)
+                work[i]['rx'] = max(0.0, work[i]['rx'] + d_rx)
+                # Posterior variance contraction (heuristic)
+                work[i]['tx_var'] = max(0.8 * vtx, (ABS_SIGMA * 0.2) ** 2)
+                work[i]['rx_var'] = max(0.8 * vrx, (ABS_SIGMA * 0.2) ** 2)
+
+    # Final gentle link reconciliation to maintain symmetry after router step
     for a_id, b_id in pairs:
-        if a_id not in interim or b_id not in interim:
+        a = work[a_id]; b = work[b_id]
+        if a['status'] != 'up' or b['status'] != 'up':
             continue
-        if interim[a_id].get('status') != 'up' or interim[b_id].get('status') != 'up':
-            continue
-        # Forward direction: a.tx vs b.rx
-        a_tx_old = interim[a_id]['tx']; b_rx_old = interim[b_id]['rx']
-        res_fwd = rel_diff(a_tx_old, b_rx_old)
-        if res_fwd > HARDENING_THRESHOLD:
-            v_mid = 0.5 * (a_tx_old + b_rx_old)
-            a_tx_new = max(0.0, a_tx_old + PAIR_RECONCILE_ALPHA * (v_mid - a_tx_old))
-            b_rx_new = max(0.0, b_rx_old + PAIR_RECONCILE_ALPHA * (v_mid - b_rx_old))
-            if a_tx_new != a_tx_old:
-                drel = rel_diff(a_tx_old, a_tx_new)
-                interim[a_id]['tx'] = a_tx_new
-                interim[a_id]['tx_conf'] = clamp(min(interim[a_id]['tx_conf'], 1.0 - min(1.0, 0.5 * drel)))
-            if b_rx_new != b_rx_old:
-                drel = rel_diff(b_rx_old, b_rx_new)
-                interim[b_id]['rx'] = b_rx_new
-                interim[b_id]['rx_conf'] = clamp(min(interim[b_id]['rx_conf'], 1.0 - min(1.0, 0.5 * drel)))
-        # Reverse direction: a.rx vs b.tx
-        a_rx_old = interim[a_id]['rx']; b_tx_old = interim[b_id]['tx']
-        res_rev = rel_diff(a_rx_old, b_tx_old)
-        if res_rev > HARDENING_THRESHOLD:
-            v_mid2 = 0.5 * (a_rx_old + b_tx_old)
-            a_rx_new = max(0.0, a_rx_old + PAIR_RECONCILE_ALPHA * (v_mid2 - a_rx_old))
-            b_tx_new = max(0.0, b_tx_old + PAIR_RECONCILE_ALPHA * (v_mid2 - b_tx_old))
-            if a_rx_new != a_rx_old:
-                drel = rel_diff(a_rx_old, a_rx_new)
-                interim[a_id]['rx'] = a_rx_new
-                interim[a_id]['rx_conf'] = clamp(min(interim[a_id]['rx_conf'], 1.0 - min(1.0, 0.5 * drel)))
-            if b_tx_new != b_tx_old:
-                drel = rel_diff(b_tx_old, b_tx_new)
-                interim[b_id]['tx'] = b_tx_new
-                interim[b_id]['tx_conf'] = clamp(min(interim[b_id]['tx_conf'], 1.0 - min(1.0, 0.5 * drel)))
-
-    # Secondary (gentle) router redistribution to restore flow conservation after pair reconcile
-    router_redistribute(SECONDARY_ROUTER_ADJ_FRAC)
-
-    # Final confidence calibration based on post-repair invariants
-    # Compute per-router imbalance residuals
+        # Forward
+        x = a['tx']; y = b['rx']
+        vmid = 0.5 * (x + y)
+        a['tx'] = max(0.0, (1 - FINAL_LINK_ALPHA) * x + FINAL_LINK_ALPHA * vmid)
+        b['rx'] = max(0.0, (1 - FINAL_LINK_ALPHA) * y + FINAL_LINK_ALPHA * vmid)
+        # Reverse
+        x = a['rx']; y = b['tx']
+        vmid = 0.5 * (x + y)
+        a['rx'] = max(0.0, (1 - FINAL_LINK_ALPHA) * x + FINAL_LINK_ALPHA * vmid)
+        b['tx'] = max(0.0, (1 - FINAL_LINK_ALPHA) * y + FINAL_LINK_ALPHA * vmid)
+
+    # Enforce "down implies zero" for any unpaired interface as well
+    for if_id, r in work.items():
+        if if_id not in paired_ids and r.get('status') == 'down':
+            r['rx'] = 0.0; r['tx'] = 0.0
+            r['rx_var'] = (ABS_SIGMA * 0.1) ** 2
+            r['tx_var'] = (ABS_SIGMA * 0.1) ** 2
+
+    # Compute router imbalance for confidence
     router_final_imbalance: Dict[str, float] = {}
     for router, if_list in router_ifaces.items():
-        # only consider interfaces that are in interim and up
-        up_ifaces = [i for i in if_list if i in interim and interim[i].get('status') == 'up']
+        up_ifaces = [i for i in if_list if i in work and work[i]['status'] == 'up']
         if not up_ifaces:
             router_final_imbalance[router] = 0.0
             continue
-        sum_tx = sum(max(0.0, interim[i]['tx']) for i in up_ifaces)
-        sum_rx = sum(max(0.0, interim[i]['rx']) for i in up_ifaces)
+        sum_tx = sum(max(0.0, work[i]['tx']) for i in up_ifaces)
+        sum_rx = sum(max(0.0, work[i]['rx']) for i in up_ifaces)
         router_final_imbalance[router] = rel_diff(sum_tx, sum_rx)
 
-    # Weights and tolerances for confidence components
+    # Assemble output with confidence calibration
+    result: Dict[str, Dict[str, Tuple]] = {}
+
+    # Component weights
     w_pair, w_router, w_status = 0.6, 0.3, 0.1
-    TOL_PAIR_BASE = HARDENING_THRESHOLD * 1.5
-    TOL_ROUTER = HARDENING_THRESHOLD * 2.0
-
-    for if_id, r in interim.items():
+
+    for if_id, r in work.items():
+        out: Dict[str, Tuple] = {}
+
         router = r.get('local_router')
         peer = peer_of.get(if_id)
-
-        status_comp = clamp(r.get('status_conf', 0.8))
         resolved_status = r.get('status', 'unknown')
-
-        # Pair-based component with rate-aware tolerance (bounded) to avoid over-penalizing low rates
-        if peer and interim.get(peer, {}).get('status') == resolved_status:
-            # Forward residual and tolerance
-            res_fwd = rel_diff(r['tx'], interim[peer]['rx'])
-            traffic_tx = max(r['tx'], interim[peer]['rx'], 1.0)
-            tol_pair_tx = min(0.10, max(TOL_PAIR_BASE, 5.0 / traffic_tx))
-            pair_comp_tx = conf_from_residual(res_fwd, tol_pair_tx)
-            # Reverse residual and tolerance
-            res_rev = rel_diff(r['rx'], interim[peer]['tx'])
-            traffic_rx = max(r['rx'], interim[peer]['tx'], 1.0)
-            tol_pair_rx = min(0.10, max(TOL_PAIR_BASE, 5.0 / traffic_rx))
-            pair_comp_rx = conf_from_residual(res_rev, tol_pair_rx)
+        status_conf = clamp(r.get('status_conf', 0.8))
+
+        # Pair component confidences (rate-aware tolerance)
+        if peer and work.get(peer, {}).get('status') == resolved_status:
+            # forward a.tx vs peer.rx
+            res_fwd = rel_diff(r['tx'], work[peer]['rx'])
+            traffic_tx = max(r['tx'], work[peer]['rx'], 1.0)
+            tol_pair_tx = max(HARDENING_THRESHOLD, 5.0 / traffic_tx)
+            pair_comp_tx = conf_from_residual_logistic(res_fwd, tol_pair_tx)
+
+            # reverse a.rx vs peer.tx
+            res_rev = rel_diff(r['rx'], work[peer]['tx'])
+            traffic_rx = max(r['rx'], work[peer]['tx'], 1.0)
+            tol_pair_rx = max(HARDENING_THRESHOLD, 5.0 / traffic_rx)
+            pair_comp_rx = conf_from_residual_logistic(res_rev, tol_pair_rx)
         else:
             pair_comp_tx = 0.55
             pair_comp_rx = 0.55
 
         router_imb = router_final_imbalance.get(router, 0.0)
-        router_comp = conf_from_residual(router_imb, TOL_ROUTER)
-
-        base_tx_conf = w_pair * pair_comp_tx + w_router * router_comp + w_status * status_comp
-        base_rx_conf = w_pair * pair_comp_rx + w_router * router_comp + w_status * status_comp
-
-        # Change penalty to discourage overconfidence on large edits
-        delta_tx_rel = rel_diff(r['orig_tx'], r['tx'])
-        delta_rx_rel = rel_diff(r['orig_rx'], r['rx'])
-        pen_tx = max(0.0, delta_tx_rel - HARDENING_THRESHOLD)
-        pen_rx = max(0.0, delta_rx_rel - HARDENING_THRESHOLD)
+        router_comp = conf_from_residual_logistic(router_imb, HARDENING_THRESHOLD * 2.0)
+
+        base_tx_conf = w_pair * pair_comp_tx + w_router * router_comp + w_status * status_conf
+        base_rx_conf = w_pair * pair_comp_rx + w_router * router_comp + w_status * status_conf
+
+        # Penalties: change magnitude and posterior variance
+        def change_penalty(orig: float, new: float) -> float:
+            d = rel_diff(orig, new)
+            excess = max(0.0, d - HARDENING_THRESHOLD)
+            return excess
+
+        pen_tx = change_penalty(r['orig_tx'], r['tx'])
+        pen_rx = change_penalty(r['orig_rx'], r['rx'])
         CHANGE_PENALTY_WEIGHT = 0.5
-        final_tx_conf = clamp(base_tx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_tx))
-        final_rx_conf = clamp(base_rx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_rx))
+
+        # Posterior variance penalty relative to base variance
+        var_factor_tx = r['tx_var'] / max(r['base_tx_var'], 1e-6)
+        var_factor_rx = r['rx_var'] / max(r['base_rx_var'], 1e-6)
+        # Map var_factor to [0,1] multiplier (~1 when reduced variance, <1 when large)
+        var_mult_tx = 1.0 / (1.0 + 0.6 * var_factor_tx)
+        var_mult_rx = 1.0 / (1.0 + 0.6 * var_factor_rx)
+
+        tx_conf = clamp(base_tx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_tx) * var_mult_tx)
+        rx_conf = clamp(base_rx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_rx) * var_mult_rx)
 
         if resolved_status == 'down':
-            final_rx_conf = 0.9 if r['orig_rx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
-            final_tx_conf = 0.9 if r['orig_tx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
-
-        r['tx_conf'] = final_tx_conf
-        r['rx_conf'] = final_rx_conf
-
-        # Subtle status calibration: if up but effectively idle, reduce status confidence slightly
-        if resolved_status == 'up':
-            if r['rx'] <= TRAFFIC_EVIDENCE_MIN and r['tx'] <= TRAFFIC_EVIDENCE_MIN:
-                r['status_conf'] = clamp(r['status_conf'] * 0.9)
-        elif resolved_status == 'down':
-            if r['rx'] > TRAFFIC_EVIDENCE_MIN or r['tx'] > TRAFFIC_EVIDENCE_MIN:
-                r['status_conf'] = clamp(min(r['status_conf'], 0.3))
-
-    # Assemble final result with (original, repaired, confidence) tuples and unchanged metadata
-    for if_id, data in telemetry.items():
-        repaired_data: Dict[str, Tuple] = {}
-        r = interim[if_id]
-
-        repaired_data['rx_rate'] = (r['orig_rx'], r['rx'], clamp(r['rx_conf']))
-        repaired_data['tx_rate'] = (r['orig_tx'], r['tx'], clamp(r['tx_conf']))
-        repaired_data['interface_status'] = (r['orig_status'], r['status'], clamp(r['status_conf']))
-
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = r['connected_to']
-        repaired_data['local_router'] = r['local_router']
-        repaired_data['remote_router'] = r['remote_router']
-
-        result[if_id] = repaired_data
+            # If we forced to zero, confidence reflects whether it was near zero originally
+            rx_conf = 0.9 if r['orig_rx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
+            tx_conf = 0.9 if r['orig_tx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
+
+        # If up but both directions effectively idle, reduce status confidence slightly
+        if resolved_status == 'up' and r['rx'] <= TRAFFIC_EVIDENCE_MIN and r['tx'] <= TRAFFIC_EVIDENCE_MIN:
+            status_conf = clamp(status_conf * 0.9)
+
+        out['rx_rate'] = (r['orig_rx'], float(r['rx']), rx_conf)
+        out['tx_rate'] = (r['orig_tx'], float(r['tx']), tx_conf)
+        out['interface_status'] = (r['orig_status'], resolved_status, status_conf)
+        out['connected_to'] = r['connected_to']
+        out['local_router'] = r['local_router']
+        out['remote_router'] = r['remote_router']
+
+        result[if_id] = out
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")
