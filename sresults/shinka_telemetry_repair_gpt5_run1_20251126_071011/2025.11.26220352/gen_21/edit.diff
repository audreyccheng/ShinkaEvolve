--- a/original.py
+++ b/original.py
@@ -1,444 +1,504 @@
 # EVOLVE-BLOCK-START
 """
-Network telemetry repair algorithm that detects and corrects inconsistencies
-in network interface telemetry data using topology relationships.
-
-Takes interface telemetry data and detects/repairs inconsistencies based on
-network invariants like link symmetry and flow conservation.
+Constrained projection based telemetry repair:
+- Build directed link variables from interfaces (merge redundant observations on pairs)
+- Resolve status via traffic evidence and enforce "down => zero"
+- Solve weighted least squares with equality constraints (flow conservation) to repair rates
+- Map repaired directed rates back to per-interface tx/rx
+- Calibrate confidence using change magnitude, pair disagreement, and router imbalance
 """
 from typing import Dict, Any, Tuple, List
+from math import exp
 
 
 def repair_network_telemetry(telemetry: Dict[str, Dict[str, Any]],
                              topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
-    """
-    Repair network interface telemetry by detecting and correcting inconsistencies.
-
-    Core principle: Use network invariants to validate and repair telemetry:
-    1. Link Symmetry (R3): my_tx_rate â‰ˆ their_rx_rate for connected interfaces
-    2. Flow Conservation (R1): Sum(incoming traffic) = Sum(outgoing traffic) at each router
-    3. Interface Consistency: Status should be consistent across connected pairs
-
-    Args:
-        telemetry: Dictionary where key is interface_id and value contains:
-            - interface_status: "up" or "down"
-            - rx_rate: receive rate in Mbps
-            - tx_rate: transmit rate in Mbps
-            - connected_to: interface_id this interface connects to
-            - local_router: router_id this interface belongs to
-            - remote_router: router_id on the other side
-        topology: Dictionary where key is router_id and value contains a list of interface_ids
-
-    Returns:
-        Dictionary with same structure but telemetry values become tuples of:
-        (original_value, repaired_value, confidence_score)
-        where confidence ranges from 0.0 (very uncertain) to 1.0 (very confident)
-    """
-
-    # Measurement timing tolerance (from Hodor research: ~2%)
+    # Tolerances and constants
     HARDENING_THRESHOLD = 0.02
-    # Small traffic level used to infer link up when statuses disagree (Mbps)
     TRAFFIC_EVIDENCE_MIN = 0.5
-    # Max fractional per-interface adjustment during router redistribution
-    MAX_ROUTER_ADJ_FRAC = 0.35
     EPS = 1e-9
 
     def clamp(x: float, lo: float = 0.0, hi: float = 1.0) -> float:
         return max(lo, min(hi, x))
 
     def rel_diff(a: float, b: float) -> float:
         denom = max(abs(a), abs(b), 1e-9)
         return abs(a - b) / denom
 
-    def conf_from_residual(residual: float, tol: float) -> float:
-        # Map residual to confidence: 1 at 0 residual, degrades linearly until ~0 near 5*tol
-        denom = max(tol * 5.0, 1e-9)
-        return clamp(1.0 - residual / denom)
-
-    # Initialize structures
-    result: Dict[str, Dict[str, Tuple]] = {}
-    # Store interim repaired values and confidences per interface before router-level hardening
-    interim: Dict[str, Dict[str, Any]] = {}
-
-    # Build connected pairs
+    def rate_aware_tol(v: float) -> float:
+        # Smooth tolerance: >= 2%, relaxed at very low rates
+        return max(HARDENING_THRESHOLD, 5.0 / max(v, 1.0))
+
+    def logistic_conf(residual: float, tol: float, k: float = 3.0) -> float:
+        # Residual relative to tolerance => [0,1] confidence; residual=tol => ~0.5
+        tol = max(tol, 1e-9)
+        x = residual / tol
+        return clamp(1.0 / (1.0 + exp(k * (x - 1.0))))
+
+    # Build undirected pairs (links) and peer map
     visited = set()
     pairs: List[Tuple[str, str]] = []
+    peer_of: Dict[str, str] = {}
     for if_id, data in telemetry.items():
         peer = data.get('connected_to')
         if peer and peer in telemetry:
-            # Use ordered tuple to avoid duplicates
             key = tuple(sorted([if_id, peer]))
             if key not in visited:
                 visited.add(key)
                 pairs.append((key[0], key[1]))
-
-    # Map each interface to its peer for quick lookup and record paired IDs
-    peer_of: Dict[str, str] = {}
-    paired_ids = set()
+                peer_of[key[0]] = key[1]
+                peer_of[key[1]] = key[0]
+
+    # Resolve status per interface using pair agreement and traffic evidence
+    resolved_status: Dict[str, str] = {}
+    status_conf: Dict[str, float] = {}
     for a_id, b_id in pairs:
-        peer_of[a_id] = b_id
-        peer_of[b_id] = a_id
-        paired_ids.add(a_id)
-        paired_ids.add(b_id)
-
-    # Initialize defaults for all interfaces
-    for if_id, data in telemetry.items():
-        interim[if_id] = {
-            'rx': float(data.get('rx_rate', 0.0)),
-            'tx': float(data.get('tx_rate', 0.0)),
-            'rx_conf': 1.0,
-            'tx_conf': 1.0,
-            'status': data.get('interface_status', 'unknown'),
-            'status_conf': 1.0,
-            'connected_to': data.get('connected_to'),
-            'local_router': data.get('local_router'),
-            'remote_router': data.get('remote_router'),
-            # Keep originals for output tuples
-            'orig_rx': float(data.get('rx_rate', 0.0)),
-            'orig_tx': float(data.get('tx_rate', 0.0)),
-            'orig_status': data.get('interface_status', 'unknown'),
-        }
-
-    # Pair-level hardening using link symmetry (R3) and interface consistency
-    for a_id, b_id in pairs:
-        a = telemetry[a_id]
-        b = telemetry[b_id]
+        a = telemetry[a_id]; b = telemetry[b_id]
         a_stat = a.get('interface_status', 'unknown')
         b_stat = b.get('interface_status', 'unknown')
         a_rx, a_tx = float(a.get('rx_rate', 0.0)), float(a.get('tx_rate', 0.0))
         b_rx, b_tx = float(b.get('rx_rate', 0.0)), float(b.get('tx_rate', 0.0))
         max_traffic = max(a_rx, a_tx, b_rx, b_tx)
-
-        # Resolve interface status consistency across the link
         if a_stat == b_stat:
-            resolved_status = a_stat
-            status_conf = 0.95 if resolved_status in ('up', 'down') else 0.7
-        else:
-            # Use traffic evidence: if there is noticeable traffic, link must be up
+            st = a_stat
+            sc = 0.95 if st in ('up', 'down') else 0.7
+        else:
             if max_traffic > TRAFFIC_EVIDENCE_MIN:
-                resolved_status = 'up'
-                status_conf = 0.85
+                st, sc = 'up', 0.85
             else:
-                resolved_status = 'down'
-                status_conf = 0.75
-
-        # Apply status to both ends
-        interim[a_id]['status'] = resolved_status
-        interim[b_id]['status'] = resolved_status
-        interim[a_id]['status_conf'] = min(interim[a_id]['status_conf'], status_conf) if interim[a_id]['status_conf'] else status_conf
-        interim[b_id]['status_conf'] = min(interim[b_id]['status_conf'], status_conf) if interim[b_id]['status_conf'] else status_conf
-
-        if resolved_status == 'down':
-            # Down interfaces cannot send or receive
-            # Confidence is high if original values were already near zero, lower otherwise.
-            for ifid, rx0, tx0 in [(a_id, a_rx, a_tx), (b_id, b_rx, b_tx)]:
-                interim[ifid]['rx'] = 0.0
-                interim[ifid]['tx'] = 0.0
-                interim[ifid]['rx_conf'] = clamp(0.9 if rx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-                interim[ifid]['tx_conf'] = clamp(0.9 if tx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-            continue  # No need to harden rates if link is down
-
-        # Link is up: harden both directions using symmetry
-        # Forward direction: a.tx should match b.rx
-        d_fwd = rel_diff(a_tx, b_rx)
-        if d_fwd <= HARDENING_THRESHOLD:
-            v = 0.5 * (a_tx + b_rx)
-            conf = clamp(1.0 - 0.5 * d_fwd)  # near 1 when very close
-        else:
-            # Choose peer's counterpart as stronger signal
-            v = b_rx if abs(b_rx) > 0 else a_tx
-            conf = clamp(1.0 - d_fwd)  # lower confidence for larger violation
-        interim[a_id]['tx'] = v
-        interim[b_id]['rx'] = v
-        interim[a_id]['tx_conf'] = min(interim[a_id]['tx_conf'], conf)
-        interim[b_id]['rx_conf'] = min(interim[b_id]['rx_conf'], conf)
-
-        # Reverse direction: a.rx should match b.tx
-        d_rev = rel_diff(a_rx, b_tx)
-        if d_rev <= HARDENING_THRESHOLD:
-            v2 = 0.5 * (a_rx + b_tx)
-            conf2 = clamp(1.0 - 0.5 * d_rev)
-        else:
-            v2 = b_tx if abs(b_tx) > 0 else a_rx
-            conf2 = clamp(1.0 - d_rev)
-        interim[a_id]['rx'] = v2
-        interim[b_id]['tx'] = v2
-        interim[a_id]['rx_conf'] = min(interim[a_id]['rx_conf'], conf2)
-        interim[b_id]['tx_conf'] = min(interim[b_id]['tx_conf'], conf2)
-
-    # Enforce "down implies zero traffic" also for unpaired interfaces
+                st, sc = 'down', 0.75
+        resolved_status[a_id] = st
+        resolved_status[b_id] = st
+        status_conf[a_id] = sc
+        status_conf[b_id] = sc
+
+    # For unpaired interfaces: keep stated status; use traffic evidence to adjust if unknown
+    for if_id, data in telemetry.items():
+        if if_id in resolved_status:
+            continue
+        st = data.get('interface_status', 'unknown')
+        rx0 = float(data.get('rx_rate', 0.0))
+        tx0 = float(data.get('tx_rate', 0.0))
+        if st not in ('up', 'down'):
+            if max(rx0, tx0) > TRAFFIC_EVIDENCE_MIN:
+                st = 'up'; sc = 0.8
+            else:
+                st = 'down'; sc = 0.7
+        else:
+            sc = 0.95
+        resolved_status[if_id] = st
+        status_conf[if_id] = sc
+
+    # Directed variable construction
+    # Each variable key maps to (src_router, dst_router), observation list, and fixed_zero flag
+    class Var:
+        __slots__ = ('src', 'dst', 'obs', 'fixed_zero')
+
+        def __init__(self, src: str, dst: str, fixed_zero: bool = False):
+            self.src = src
+            self.dst = dst
+            self.obs: List[Tuple[str, str, float, float]] = []  # (if_id, dir, value, weight)
+            self.fixed_zero = fixed_zero
+
+    # Mapping from (if_id, 'tx'/'rx') to variable key
+    ifdir_to_varkey: Dict[Tuple[str, str], str] = {}
+
+    # Helper to create or fetch variable
+    variables: Dict[str, Var] = {}
+
+    def add_obs(vkey: str, src: str, dst: str, if_id: str, idir: str, val: float, w: float, fixed_zero: bool):
+        if vkey not in variables:
+            variables[vkey] = Var(src, dst, fixed_zero)
+        else:
+            # If any contributor is fixed to zero => the variable should be fixed zero
+            variables[vkey].fixed_zero = variables[vkey].fixed_zero or fixed_zero
+        variables[vkey].obs.append((if_id, idir, val, w))
+        ifdir_to_varkey[(if_id, idir)] = vkey
+
+    # Observation weight from rate-aware tolerance
+    def obs_weight(val: float) -> float:
+        tol = rate_aware_tol(abs(val))
+        # Convert tolerance to pseudo-variance weight
+        return 1.0 / (tol * tol)
+
+    # Build variables for paired links
+    for a_id, b_id in pairs:
+        a = telemetry[a_id]; b = telemetry[b_id]
+        R_a = a.get('local_router'); R_b = b.get('local_router')
+        # Variable for R_a -> R_b uses a.tx and b.rx
+        fwd_key = f"pair:{a_id}|{b_id}:fwd"
+        rev_key = f"pair:{a_id}|{b_id}:rev"
+        st = resolved_status[a_id]  # same for both ends
+        fixed_zero = (st == 'down')
+        # Forward obs
+        a_tx = float(a.get('tx_rate', 0.0)); b_rx = float(b.get('rx_rate', 0.0))
+        add_obs(fwd_key, R_a, R_b, a_id, 'tx', a_tx, obs_weight(a_tx), fixed_zero)
+        add_obs(fwd_key, R_a, R_b, b_id, 'rx', b_rx, obs_weight(b_rx), fixed_zero)
+        # Reverse obs
+        a_rx = float(a.get('rx_rate', 0.0)); b_tx = float(b.get('tx_rate', 0.0))
+        add_obs(rev_key, R_b, R_a, b_id, 'tx', b_tx, obs_weight(b_tx), fixed_zero)
+        add_obs(rev_key, R_b, R_a, a_id, 'rx', a_rx, obs_weight(a_rx), fixed_zero)
+
+    # Build variables for unpaired interfaces: separate variables for their tx and rx
+    for if_id, data in telemetry.items():
+        if if_id in peer_of:
+            continue
+        st = resolved_status.get(if_id, data.get('interface_status', 'down'))
+        fixed_zero = (st == 'down')
+        R_loc = data.get('local_router')
+        R_rem = data.get('remote_router')  # may be None
+        tx = float(data.get('tx_rate', 0.0)); rx = float(data.get('rx_rate', 0.0))
+        # Outgoing (tx): R_loc -> R_rem
+        vtx = f"unpaired:{if_id}:tx"
+        add_obs(vtx, R_loc, R_rem, if_id, 'tx', tx, obs_weight(tx), fixed_zero)
+        # Incoming (rx): R_rem -> R_loc
+        vrx = f"unpaired:{if_id}:rx"
+        add_obs(vrx, R_rem, R_loc, if_id, 'rx', rx, obs_weight(rx), fixed_zero)
+
+    # Aggregate observations per variable to get y and W
+    varkeys: List[str] = list(variables.keys())
+    m = len(varkeys)
+    y_vec = [0.0] * m
+    W_diag = [1.0] * m
+    var_src_idx: List[int] = []  # router row index (to be filled later)
+    var_dst_idx: List[int] = []
+
+    # Routers participating
+    routers_set = set()
+    for k in varkeys:
+        v = variables[k]
+        if v.src is not None:
+            routers_set.add(v.src)
+        if v.dst is not None:
+            routers_set.add(v.dst)
+
+    routers_list = sorted([r for r in routers_set if r is not None])
+
+    # Build router index mapping, and later we will drop last row/col to avoid singularity
+    router_to_row = {r: idx for idx, r in enumerate(routers_list)}
+    R = len(routers_list)
+
+    # Precompute pre-repair (observation) router imbalance using y_obs means
+    # First compute y_e and W_e to use for both solve and pre-imbalance
+    for idx, k in enumerate(varkeys):
+        v = variables[k]
+        if v.fixed_zero:
+            y = 0.0
+            W = 1e6  # extremely large weight -> keep at zero if it appears; but we'll also skip in A
+        else:
+            sumw = 0.0
+            sumwy = 0.0
+            for (_, _, val, w) in v.obs:
+                sumw += w
+                sumwy += w * val
+            if sumw <= 0:
+                sumw = 1.0
+            y = sumwy / sumw
+            # Regularize weights mildly to avoid extremes
+            W = max(sumw, 1e-3)
+        y_vec[idx] = max(0.0, y)
+        W_diag[idx] = W
+        var_src_idx.append(router_to_row.get(v.src, -1))
+        var_dst_idx.append(router_to_row.get(v.dst, -1))
+
+    # Compute pre-repair per-router imbalance using y_vec (ignore vars with missing endpoints or fixed zero)
+    pre_sum_out = [0.0] * R
+    pre_sum_in = [0.0] * R
+    for j in range(m):
+        i_src = var_src_idx[j]; i_dst = var_dst_idx[j]
+        if i_src == -1 or i_dst == -1:
+            continue
+        val = y_vec[j]
+        pre_sum_out[i_src] += val
+        pre_sum_in[i_dst] += val
+    pre_imbalance = [0.0] * R
+    for i in range(R):
+        pre_imbalance[i] = rel_diff(pre_sum_out[i], pre_sum_in[i])
+
+    # Build M = A W^{-1} A^T (size R x R) and g = A y (size R)
+    # Skip variables that are fixed to zero (we'll still keep y=0 but no need to constrain)
+    # Also handle variables with missing endpoints: exclude from A
+    M = [[0.0 for _ in range(R)] for __ in range(R)]
+    g = [0.0 for _ in range(R)]
+    for j in range(m):
+        i_src = var_src_idx[j]; i_dst = var_dst_idx[j]
+        if i_src == -1 or i_dst == -1:
+            continue
+        v = variables[varkeys[j]]
+        if v.fixed_zero:
+            continue
+        y = y_vec[j]
+        Winv = 1.0 / max(W_diag[j], 1e-9)
+        # g contribution: A*y
+        g[i_src] += y
+        g[i_dst] -= y
+        # M contribution: W^{-1} * [[1,-1],[-1,1]]
+        M[i_src][i_src] += Winv
+        M[i_dst][i_dst] += Winv
+        M[i_src][i_dst] -= Winv
+        M[i_dst][i_src] -= Winv
+
+    # Reduce system by dropping last router (to remove redundancy) if any
+    def reduce_matrix(M_full: List[List[float]], b_full: List[float]) -> Tuple[List[List[float]], List[float]]:
+        if len(M_full) == 0:
+            return [], []
+        n = len(M_full)
+        if n == 1:
+            # Return 1x1 system as-is
+            return [[M_full[0][0]]], [b_full[0]]
+        # Drop the last row/col
+        n_red = n - 1
+        M_red = [[0.0 for _ in range(n_red)] for __ in range(n_red)]
+        b_red = [0.0 for _ in range(n_red)]
+        for i in range(n_red):
+            b_red[i] = b_full[i]
+            for j in range(n_red):
+                M_red[i][j] = M_full[i][j]
+        return M_red, b_red
+
+    M_red, g_red = reduce_matrix(M, g)
+
+    # Solve linear system M_red * lam = g_red via Gaussian elimination with partial pivoting
+    def solve_linear(A_mat: List[List[float]], b_vec: List[float]) -> List[float]:
+        n = len(A_mat)
+        if n == 0:
+            return []
+        # Build augmented matrix
+        aug = [row[:] + [b_vec[i]] for i, row in enumerate(A_mat)]
+        # Forward elimination
+        for col in range(n):
+            # Pivot
+            pivot_row = max(range(col, n), key=lambda r: abs(aug[r][col]))
+            if abs(aug[pivot_row][col]) < 1e-12:
+                continue
+            if pivot_row != col:
+                aug[col], aug[pivot_row] = aug[pivot_row], aug[col]
+            # Normalize pivot row
+            piv = aug[col][col]
+            for k in range(col, n + 1):
+                aug[col][k] /= piv
+            # Eliminate below
+            for r in range(col + 1, n):
+                factor = aug[r][col]
+                if abs(factor) < 1e-18:
+                    continue
+                for k in range(col, n + 1):
+                    aug[r][k] -= factor * aug[col][k]
+        # Back substitution
+        x = [0.0] * n
+        for i in range(n - 1, -1, -1):
+            s = aug[i][n]
+            for j in range(i + 1, n):
+                s -= aug[i][j] * x[j]
+            denom = aug[i][i]
+            if abs(denom) < 1e-12:
+                x[i] = 0.0
+            else:
+                x[i] = s / denom
+        return x
+
+    lam_red = solve_linear(M_red, g_red)
+
+    # Build full lambda vector with last element = 0 (dropped equation)
+    lam = [0.0] * R
+    for i in range(R - 1):
+        lam[i] = lam_red[i]
+    lam[R - 1 if R > 0 else 0] = 0.0
+
+    # Compute repaired variable values: x = y - W^{-1} A^T lam
+    x_vec = [0.0] * m
+    for j in range(m):
+        v = variables[varkeys[j]]
+        y = y_vec[j]
+        if v.fixed_zero:
+            x = 0.0
+        else:
+            i_src = var_src_idx[j]; i_dst = var_dst_idx[j]
+            if i_src == -1 or i_dst == -1:
+                # Cannot constrain without both endpoints; leave at observation
+                x = y
+            else:
+                Winv = 1.0 / max(W_diag[j], 1e-9)
+                al = lam[i_src] - lam[i_dst]
+                x = y - Winv * al
+        x_vec[j] = max(0.0, x)  # non-negativity
+
+    # Prepare interim storage per interface for output and confidence
+    interim: Dict[str, Dict[str, Any]] = {}
+    for if_id, data in telemetry.items():
+        interim[if_id] = {
+            'orig_tx': float(data.get('tx_rate', 0.0)),
+            'orig_rx': float(data.get('rx_rate', 0.0)),
+            'tx': float(data.get('tx_rate', 0.0)),
+            'rx': float(data.get('rx_rate', 0.0)),
+            'status': resolved_status.get(if_id, data.get('interface_status', 'unknown')),
+            'status_conf': status_conf.get(if_id, 0.8),
+            'connected_to': data.get('connected_to'),
+            'local_router': data.get('local_router'),
+            'remote_router': data.get('remote_router'),
+            'tx_conf': 1.0,
+            'rx_conf': 1.0,
+            'orig_status': data.get('interface_status', 'unknown'),
+        }
+
+    # Map repaired variables back to per-interface tx/rx
+    for (if_id, idir), vkey in ifdir_to_varkey.items():
+        j = varkeys.index(vkey)
+        repaired_val = x_vec[j]
+        if idir == 'tx':
+            interim[if_id]['tx'] = repaired_val
+        else:
+            interim[if_id]['rx'] = repaired_val
+
+    # Enforce "down => zero" again to be safe and calibrate status confidence
     for if_id, r in interim.items():
-        if if_id not in paired_ids and r.get('status') == 'down':
-            rx0 = r['rx']
-            tx0 = r['tx']
+        if r['status'] == 'down':
+            # Confidence high if originals near zero, else low
+            r['tx'] = 0.0
             r['rx'] = 0.0
-            r['tx'] = 0.0
-            r['rx_conf'] = clamp(0.9 if rx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-            r['tx_conf'] = clamp(0.9 if tx0 <= TRAFFIC_EVIDENCE_MIN else 0.3)
-
-    # Router-level dynamic flow conservation (R1)
-    # Build router to interfaces map (use provided topology if available, else derive from telemetry)
-    router_ifaces: Dict[str, List[str]] = {}
-    if topology:
-        router_ifaces = {r: [i for i in if_list if i in interim] for r, if_list in topology.items()}
-    else:
-        # If topology not provided, derive from telemetry metadata
-        # Note: Topology helps flow conservation; we derive a best-effort map when absent.
-        for if_id, data in telemetry.items():
-            r = data.get('local_router')
-            if r is not None:
-                router_ifaces.setdefault(r, []).append(if_id)
-
-    for router, if_list in router_ifaces.items():
-        # Consider only interfaces present in telemetry
-        interfaces = [i for i in if_list if i in interim]
-        if not interfaces:
-            continue
-
-        # Compute sums over "up" interfaces
-        sum_tx = 0.0
-        sum_rx = 0.0
-        tx_conf_acc = 0.0
-        rx_conf_acc = 0.0
-        up_count_tx = 0
-        up_count_rx = 0
-        for i in interfaces:
-            if interim[i]['status'] == 'up':
-                sum_tx += max(0.0, interim[i]['tx'])
-                sum_rx += max(0.0, interim[i]['rx'])
-                tx_conf_acc += interim[i]['tx_conf']
-                rx_conf_acc += interim[i]['rx_conf']
-                up_count_tx += 1
-                up_count_rx += 1
-
-        if up_count_tx == 0 or up_count_rx == 0:
-            continue
-
-        # Evaluate flow imbalance
-        imbalance = rel_diff(sum_tx, sum_rx)
-        if imbalance <= HARDENING_THRESHOLD * 2:
-            # Within tolerance; no router-level scaling needed
-            continue
-
-        avg_tx_conf = tx_conf_acc / max(1, up_count_tx)
-        avg_rx_conf = rx_conf_acc / max(1, up_count_rx)
-
-        # Decide which direction to scale: scale the less trusted direction
-        scale_rx = avg_tx_conf >= avg_rx_conf  # if TX more trusted, scale RX to match TX
-        if scale_rx and sum_rx > 0.0:
-            s = sum_tx / sum_rx
-        elif (not scale_rx) and sum_tx > 0.0:
-            s = sum_rx / sum_tx
-        else:
-            s = 1.0
-
-        # Bound scaling to avoid extreme corrections
-        s_bounded = max(0.5, min(2.0, s))
-
-        # Weighted additive redistribution toward target using lower-trust interfaces more
-        # Prepare per-interface values and weights
-        up_list = [i for i in interfaces if interim[i]['status'] == 'up']
-        if not up_list:
-            continue
-        # Current totals and target delta
-        if scale_rx:
-            sum_old = sum(max(0.0, interim[i]['rx']) for i in up_list)
-            target_total = sum_tx
-        else:
-            sum_old = sum(max(0.0, interim[i]['tx']) for i in up_list)
-            target_total = sum_rx
-        need = target_total - sum_old
-        if abs(need) <= max(sum_old, target_total, 1.0) * (HARDENING_THRESHOLD * 0.5):
-            # Tiny residual; skip redistribution
-            continue
-
-        # Build weights from direction-specific confidence (lower confidence -> larger weight)
-        weights: Dict[str, float] = {}
-        caps_pos: Dict[str, float] = {}
-        caps_neg: Dict[str, float] = {}
-        values: Dict[str, float] = {}
-        for i in up_list:
-            if scale_rx:
-                conf = float(interim[i]['rx_conf'])
-                v = max(0.0, float(interim[i]['rx']))
-            else:
-                conf = float(interim[i]['tx_conf'])
-                v = max(0.0, float(interim[i]['tx']))
-            w = max(0.05, 1.0 - conf)
-            weights[i] = w
-            cap = MAX_ROUTER_ADJ_FRAC * max(v, 1.0)
-            caps_pos[i] = cap
-            caps_neg[i] = cap
-            values[i] = v
-
-        # Iterative allocation with capacity clipping
-        alloc_passes = 2
-        for _alloc in range(alloc_passes):
-            if abs(need) <= EPS:
-                break
-            # Eligible interfaces based on remaining capacity in needed direction
-            if need > 0:
-                elig = [i for i in up_list if caps_pos[i] > EPS]
-            else:
-                elig = [i for i in up_list if caps_neg[i] > EPS]
-            if not elig:
-                break
-            sumW = sum(weights[i] for i in elig)
-            if sumW <= EPS:
-                break
-            for i in elig:
-                quota = need * (weights[i] / sumW)
-                if need > 0:
-                    d = min(max(0.0, quota), caps_pos[i])
-                    caps_pos[i] -= d
-                else:
-                    d = max(min(0.0, quota), -caps_neg[i])
-                    caps_neg[i] -= -d
-                if abs(d) <= EPS:
-                    continue
-                old_v = values[i]
-                new_v = max(0.0, old_v + d)
-                values[i] = new_v
-                # Confidence drops with global imbalance, scaling magnitude and per-interface change
-                delta_rel = rel_diff(old_v, new_v)
-                if scale_rx:
-                    interim[i]['rx'] = new_v
-                    interim[i]['rx_conf'] = clamp(min(interim[i]['rx_conf'], 1.0 - min(1.0, imbalance + 0.5 * delta_rel + abs(1.0 - s_bounded) * 0.5)))
-                else:
-                    interim[i]['tx'] = new_v
-                    interim[i]['tx_conf'] = clamp(min(interim[i]['tx_conf'], 1.0 - min(1.0, imbalance + 0.5 * delta_rel + abs(1.0 - s_bounded) * 0.5)))
-                need -= d
-
-    # Final confidence calibration based on post-repair invariants
-    # Compute per-router imbalance residuals
-    router_final_imbalance: Dict[str, float] = {}
-    for router, if_list in router_ifaces.items():
-        # only consider interfaces that are in interim and up
-        up_ifaces = [i for i in if_list if i in interim and interim[i].get('status') == 'up']
-        if not up_ifaces:
-            router_final_imbalance[router] = 0.0
-            continue
-        sum_tx = sum(max(0.0, interim[i]['tx']) for i in up_ifaces)
-        sum_rx = sum(max(0.0, interim[i]['rx']) for i in up_ifaces)
-        router_final_imbalance[router] = rel_diff(sum_tx, sum_rx)
-
-    # Weights and tolerances for confidence components
-    w_pair, w_router, w_status = 0.6, 0.3, 0.1
-    TOL_PAIR = HARDENING_THRESHOLD * 1.5
-    TOL_ROUTER = HARDENING_THRESHOLD * 2.0
-
+            r['tx_conf'] = 0.9 if r['orig_tx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
+            r['rx_conf'] = 0.9 if r['orig_rx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
+            if max(r['orig_tx'], r['orig_rx']) > TRAFFIC_EVIDENCE_MIN:
+                r['status_conf'] = clamp(min(r['status_conf'], 0.4))
+            continue
+
+    # Confidence calibration: change-based, pair-consistency, router-imbalance, status
+    # Compute post-repair router imbalance for information (usually near-zero)
+    post_sum_out = [0.0] * R
+    post_sum_in = [0.0] * R
+    for j in range(m):
+        i_src = var_src_idx[j]; i_dst = var_dst_idx[j]
+        if i_src == -1 or i_dst == -1:
+            continue
+        x = x_vec[j]
+        post_sum_out[i_src] += x
+        post_sum_in[i_dst] += x
+    post_imbalance = [0.0] * R
+    for i in range(R):
+        post_imbalance[i] = rel_diff(post_sum_out[i], post_sum_in[i])
+
+    # Precompute pair disagreement per variable (from raw observations before solve)
+    var_pair_residual: Dict[str, float] = {}
+    var_pair_tol: Dict[str, float] = {}
+    for k, v in variables.items():
+        if len(v.obs) >= 2:
+            # Collect two best observations by weight
+            sorted_obs = sorted(v.obs, key=lambda o: o[3], reverse=True)
+            o1 = sorted_obs[0]; o2 = sorted_obs[1]
+            y1 = o1[2]; y2 = o2[2]
+            resid = rel_diff(y1, y2)
+            traffic = max(abs(y1), abs(y2), 1.0)
+            tol = rate_aware_tol(traffic)
+            var_pair_residual[k] = resid
+            var_pair_tol[k] = tol
+        else:
+            var_pair_residual[k] = 0.4  # default moderate uncertainty
+            var_pair_tol[k] = 0.2
+
+    # Assign confidences per interface direction
     for if_id, r in interim.items():
-        router = r.get('local_router')
-        peer = peer_of.get(if_id)
-
-        status_comp = clamp(r.get('status_conf', 0.8))
-        resolved_status = r.get('status', 'unknown')
-
-        if peer and interim.get(peer, {}).get('status') == resolved_status:
-            res_fwd = rel_diff(r['tx'], interim[peer]['rx'])
-            res_rev = rel_diff(r['rx'], interim[peer]['tx'])
-            pair_comp_tx = conf_from_residual(res_fwd, TOL_PAIR)
-            pair_comp_rx = conf_from_residual(res_rev, TOL_PAIR)
-        else:
-            pair_comp_tx = 0.55
-            pair_comp_rx = 0.55
-
-        router_imb = router_final_imbalance.get(router, 0.0)
-        router_comp = conf_from_residual(router_imb, TOL_ROUTER)
-
-        base_tx_conf = w_pair * pair_comp_tx + w_router * router_comp + w_status * status_comp
-        base_rx_conf = w_pair * pair_comp_rx + w_router * router_comp + w_status * status_comp
-
-        # Change penalty to discourage overconfidence on large edits
-        delta_tx_rel = rel_diff(r['orig_tx'], r['tx'])
-        delta_rx_rel = rel_diff(r['orig_rx'], r['rx'])
-        pen_tx = max(0.0, delta_tx_rel - HARDENING_THRESHOLD)
-        pen_rx = max(0.0, delta_rx_rel - HARDENING_THRESHOLD)
-        CHANGE_PENALTY_WEIGHT = 0.5
-        final_tx_conf = clamp(base_tx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_tx))
-        final_rx_conf = clamp(base_rx_conf * (1.0 - CHANGE_PENALTY_WEIGHT * pen_rx))
-
-        if resolved_status == 'down':
-            final_rx_conf = 0.9 if r['orig_rx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
-            final_tx_conf = 0.9 if r['orig_tx'] <= TRAFFIC_EVIDENCE_MIN else 0.3
-
-        r['tx_conf'] = final_tx_conf
-        r['rx_conf'] = final_rx_conf
-
-        # Subtle status calibration: if up but effectively idle, reduce status confidence slightly
-        if resolved_status == 'up':
-            if r['rx'] <= TRAFFIC_EVIDENCE_MIN and r['tx'] <= TRAFFIC_EVIDENCE_MIN:
-                r['status_conf'] = clamp(r['status_conf'] * 0.9)
-        elif resolved_status == 'down':
-            if r['rx'] > TRAFFIC_EVIDENCE_MIN or r['tx'] > TRAFFIC_EVIDENCE_MIN:
-                r['status_conf'] = clamp(min(r['status_conf'], 0.3))
-
-    # Assemble final result with (original, repaired, confidence) tuples and unchanged metadata
-    for if_id, data in telemetry.items():
-        repaired_data: Dict[str, Tuple] = {}
-        r = interim[if_id]
-
-        repaired_data['rx_rate'] = (r['orig_rx'], r['rx'], clamp(r['rx_conf']))
-        repaired_data['tx_rate'] = (r['orig_tx'], r['tx'], clamp(r['tx_conf']))
-        repaired_data['interface_status'] = (r['orig_status'], r['status'], clamp(r['status_conf']))
-
-        # Copy metadata unchanged
-        repaired_data['connected_to'] = r['connected_to']
-        repaired_data['local_router'] = r['local_router']
-        repaired_data['remote_router'] = r['remote_router']
-
-        result[if_id] = repaired_data
+        loc = r.get('local_router')
+        router_idx = router_to_row.get(loc, None)
+        router_comp = 0.7
+        if router_idx is not None:
+            # Use pre-repair imbalance; high imbalance lowers confidence
+            router_comp = logistic_conf(pre_imbalance[router_idx], rate_aware_tol(max(pre_sum_out[router_idx], pre_sum_in[router_idx], 1.0)))
+
+        # TX confidence
+        tx_orig = r['orig_tx']; tx_new = r['tx']
+        vkey_tx = ifdir_to_varkey.get((if_id, 'tx'))
+        pair_comp_tx = 0.6
+        if vkey_tx is not None:
+            pair_comp_tx = logistic_conf(var_pair_residual[vkey_tx], var_pair_tol[vkey_tx])
+        change_tx = rel_diff(tx_orig, tx_new)
+        tol_tx = rate_aware_tol(max(tx_new, tx_orig, 1.0))
+        change_comp_tx = logistic_conf(change_tx, tol_tx)
+        tx_conf = 0.5 * change_comp_tx + 0.3 * pair_comp_tx + 0.15 * router_comp + 0.05 * clamp(r['status_conf'])
+        # Penalize if clipped to zero with significant original
+        if tx_new <= EPS and tx_orig > TRAFFIC_EVIDENCE_MIN and r['status'] == 'up':
+            tx_conf *= 0.6
+        r['tx_conf'] = clamp(tx_conf)
+
+        # RX confidence
+        rx_orig = r['orig_rx']; rx_new = r['rx']
+        vkey_rx = ifdir_to_varkey.get((if_id, 'rx'))
+        pair_comp_rx = 0.6
+        if vkey_rx is not None:
+            pair_comp_rx = logistic_conf(var_pair_residual[vkey_rx], var_pair_tol[vkey_rx])
+        change_rx = rel_diff(rx_orig, rx_new)
+        tol_rx = rate_aware_tol(max(rx_new, rx_orig, 1.0))
+        change_comp_rx = logistic_conf(change_rx, tol_rx)
+        rx_conf = 0.5 * change_comp_rx + 0.3 * pair_comp_rx + 0.15 * router_comp + 0.05 * clamp(r['status_conf'])
+        if rx_new <= EPS and rx_orig > TRAFFIC_EVIDENCE_MIN and r['status'] == 'up':
+            rx_conf *= 0.6
+        r['rx_conf'] = clamp(rx_conf)
+
+        # If up but effectively idle, slightly reduce status confidence
+        if r['status'] == 'up' and r['tx'] <= TRAFFIC_EVIDENCE_MIN and r['rx'] <= TRAFFIC_EVIDENCE_MIN:
+            r['status_conf'] = clamp(r['status_conf'] * 0.9)
+
+    # Assemble final output
+    result: Dict[str, Dict[str, Tuple]] = {}
+    for if_id, r in interim.items():
+        out: Dict[str, Tuple] = {}
+        out['rx_rate'] = (r['orig_rx'], r['rx'], clamp(r['rx_conf']))
+        out['tx_rate'] = (r['orig_tx'], r['tx'], clamp(r['tx_conf']))
+        out['interface_status'] = (r['orig_status'], r['status'], clamp(r['status_conf']))
+        out['connected_to'] = r['connected_to']
+        out['local_router'] = r['local_router']
+        out['remote_router'] = r['remote_router']
+        result[if_id] = out
 
     return result
 
 # EVOLVE-BLOCK-END
 
 
 def run_repair(telemetry: Dict[str, Dict[str, Any]], topology: Dict[str, List[str]]) -> Dict[str, Dict[str, Tuple]]:
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         telemetry: Network interface telemetry data
         topology: Dictionary where key is router_id and value contains a list of interface_ids
 
     Returns:
         Dictionary containing repaired results with confidence scores
     """
     return repair_network_telemetry(telemetry, topology)
 
 
 if __name__ == "__main__":
     # Simple test case
     test_telemetry = {
         'if1_to_if2': {
             'interface_status': 'up',
             'rx_rate': 100.0,
             'tx_rate': 95.0,
             'connected_to': 'if2_to_if1',
             'local_router': 'router1',
             'remote_router': 'router2'
         },
         'if2_to_if1': {
             'interface_status': 'up',
             'rx_rate': 95.0,  # Should match if1's TX
             'tx_rate': 100.0,  # Should match if1's RX
             'connected_to': 'if1_to_if2',
             'local_router': 'router2',
             'remote_router': 'router1'
         }
     }
 
     test_topology = {
         'router1': ['if1_to_if2'],
         'router2': ['if2_to_if1']
     }
 
     result = run_repair(test_telemetry, test_topology)
 
     print("Repair results:")
     for if_id, data in result.items():
         print(f"\n{if_id}:")
         print(f"  RX: {data['rx_rate']}")
         print(f"  TX: {data['tx_rate']}")
         print(f"  Status: {data['interface_status']}")