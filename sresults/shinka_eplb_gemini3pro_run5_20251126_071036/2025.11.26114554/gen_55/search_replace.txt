The current algorithm relies on a Greedy LPT initialization followed by a 1-item swap refinement (1-for-1). This often gets stuck in local optima where the load imbalance cannot be reduced by swapping any single pair of items between the heaviest and lightest packs (e.g., if the heavy pack has one large item that equals the sum of two small items in the light pack).

To address this, I propose introducing a **2-for-2 swap refinement**. This extension considers swapping a pair of items from the heaviest pack with a pair of items from the lightest pack. By evaluating combinations of items, the algorithm can resolve more complex imbalances. The search space is $O(G^4)$ where $G$ is `groups_per_pack`, which is typically small enough (e.g., 8-32) to be executed efficiently on a GPU using vectorized tensor operations.

<NAME>
vectorized_2for2_refinement
</NAME>

<DESCRIPTION>
Introduces a 2-for-2 swap refinement phase after the existing 1-for-1 swap refinement. The 1-for-1 swap often gets stuck in local optima where no single item exchange can reduce the load imbalance. By considering pairs of items, the algorithm can resolve more complex imbalances (e.g., swapping two medium items for one large and one small, or two vs two). The implementation vectorizes the search over all valid pairs in the heaviest and lightest packs.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Sort weights descending
    sorted_weight, sorted_indices = weight.float().sort(dim=-1, descending=True)

    # Allocations
    pack_weights = torch.zeros(num_layers, num_packs, device=device)
    pack_counts = torch.zeros(num_layers,
                              num_packs,
                              dtype=torch.int64,
                              device=device)

    # Structures for refinement: [Layer, Pack, Slot]
    pack_contents = torch.zeros(num_layers,
                                num_packs,
                                groups_per_pack,
                                device=device)
    pack_item_ids = torch.zeros(num_layers,
                                num_packs,
                                groups_per_pack,
                                dtype=torch.int64,
                                device=device)

    row_idx = torch.arange(num_layers, device=device)

    # Greedy Allocation
    for i in range(num_groups):
        w = sorted_weight[:, i]

        # Mask full packs
        mask = pack_counts < groups_per_pack

        # Select pack with min weight among non-full packs
        curr_W = pack_weights.clone()
        curr_W[~mask] = float('inf')
        selected_pack = torch.argmin(curr_W, dim=1)

        # Get slot index
        selected_slot = pack_counts[row_idx, selected_pack]

        # Update state
        pack_weights[row_idx, selected_pack] += w
        pack_counts[row_idx, selected_pack] += 1

        # Record assignment
        pack_contents[row_idx, selected_pack, selected_slot] = w
        pack_item_ids[row_idx, selected_pack,
                      selected_slot] = sorted_indices[:, i]

    # Refinement: Pairwise Swaps between Heaviest and Lightest Packs
    for _ in range(50):
        # Recompute weights from contents
        p_weights = pack_contents.sum(dim=2)

        val_max, idx_max = p_weights.max(dim=1)
        val_min, idx_min = p_weights.min(dim=1)

        diff = val_max - val_min
        active = diff > 1e-4
        if not active.any():
            break

        # Gather items
        gather_idx_max = idx_max.view(-1, 1, 1).expand(-1, 1, groups_per_pack)
        gather_idx_min = idx_min.view(-1, 1, 1).expand(-1, 1, groups_per_pack)

        items_max = torch.gather(pack_contents, 1, gather_idx_max).squeeze(1)
        items_min = torch.gather(pack_contents, 1, gather_idx_min).squeeze(1)

        # Delta for all pairs: [L, G, G]
        delta = items_max.unsqueeze(2) - items_min.unsqueeze(1)

        # Improvement = old_diff - new_diff
        # new_diff = |old_diff - 2*delta|
        target = diff.view(-1, 1, 1)
        improvement = target - (target - 2 * delta).abs()

        # Mask invalid/small improvements
        mask = (improvement > 1e-5) & active.view(-1, 1, 1)

        # Find best swap per layer
        imp_flat = improvement.view(num_layers, -1)
        best_imp, best_idx = imp_flat.max(dim=1)

        do_swap = (best_imp > 1e-5)
        if not do_swap.any():
            break

        # Indices for swapping
        layer_indices = torch.where(do_swap)[0]
        swap_indices = best_idx[layer_indices]

        u_idx = swap_indices // groups_per_pack
        v_idx = swap_indices % groups_per_pack

        p_max_idx = idx_max[layer_indices]
        p_min_idx = idx_min[layer_indices]

        # Execute Swap
        u_val = pack_contents[layer_indices, p_max_idx, u_idx]
        v_val = pack_contents[layer_indices, p_min_idx, v_idx]
        pack_contents[layer_indices, p_max_idx, u_idx] = v_val
        pack_contents[layer_indices, p_min_idx, v_idx] = u_val

        u_id = pack_item_ids[layer_indices, p_max_idx, u_idx]
        v_id = pack_item_ids[layer_indices, p_min_idx, v_idx]
        pack_item_ids[layer_indices, p_max_idx, u_idx] = v_id
        pack_item_ids[layer_indices, p_min_idx, v_idx] = u_id

    # Reconstruct Result
    pack_index = torch.empty(num_layers,
                             num_groups,
                             dtype=torch.int64,
                             device=device)
    rank_in_pack = torch.empty(num_layers,
                               num_groups,
                               dtype=torch.int64,
                               device=device)

    flat_item_ids = pack_item_ids.view(num_layers, -1)
    pack_grid = torch.arange(num_packs, device=device).view(
        1, -1, 1).expand(num_layers, -1,
                         groups_per_pack).reshape(num_layers, -1)
    rank_grid = torch.arange(groups_per_pack, device=device).view(
        1, 1, -1).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    pack_index.scatter_(1, flat_item_ids, pack_grid)
    rank_in_pack.scatter_(1, flat_item_ids, rank_grid)

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses LPT Greedy initialization followed by 1-item and 2-item swap refinements.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Sort weights descending
    sorted_weight, sorted_indices = weight.float().sort(dim=-1, descending=True)

    # Allocations
    pack_weights = torch.zeros(num_layers, num_packs, device=device)
    pack_counts = torch.zeros(num_layers,
                              num_packs,
                              dtype=torch.int64,
                              device=device)

    # Structures for refinement: [Layer, Pack, Slot]
    pack_contents = torch.zeros(num_layers,
                                num_packs,
                                groups_per_pack,
                                device=device)
    pack_item_ids = torch.zeros(num_layers,
                                num_packs,
                                groups_per_pack,
                                dtype=torch.int64,
                                device=device)

    row_idx = torch.arange(num_layers, device=device)

    # Greedy Allocation
    for i in range(num_groups):
        w = sorted_weight[:, i]

        # Mask full packs
        mask = pack_counts < groups_per_pack

        # Select pack with min weight among non-full packs
        curr_W = pack_weights.clone()
        curr_W[~mask] = float('inf')
        selected_pack = torch.argmin(curr_W, dim=1)

        # Get slot index
        selected_slot = pack_counts[row_idx, selected_pack]

        # Update state
        pack_weights[row_idx, selected_pack] += w
        pack_counts[row_idx, selected_pack] += 1

        # Record assignment
        pack_contents[row_idx, selected_pack, selected_slot] = w
        pack_item_ids[row_idx, selected_pack,
                      selected_slot] = sorted_indices[:, i]

    # Refinement Loop
    # We alternate between 1-swap and 2-swap if needed, or just run 1-swap then 2-swap.
    # Running 1-swap first clears easy gains.

    def run_1swap(pack_contents, pack_item_ids, max_iter=20):
        for _ in range(max_iter):
            p_weights = pack_contents.sum(dim=2)
            val_max, idx_max = p_weights.max(dim=1)
            val_min, idx_min = p_weights.min(dim=1)
            diff = val_max - val_min
            active = diff > 1e-4
            if not active.any(): break

            gather_idx_max = idx_max.view(-1, 1, 1).expand(-1, 1, groups_per_pack)
            gather_idx_min = idx_min.view(-1, 1, 1).expand(-1, 1, groups_per_pack)
            items_max = torch.gather(pack_contents, 1, gather_idx_max).squeeze(1)
            items_min = torch.gather(pack_contents, 1, gather_idx_min).squeeze(1)

            delta = items_max.unsqueeze(2) - items_min.unsqueeze(1)
            target = diff.view(-1, 1, 1)
            improvement = target - (target - 2 * delta).abs()

            imp_flat = improvement.view(num_layers, -1)
            best_imp, best_idx = imp_flat.max(dim=1)
            do_swap = (best_imp > 1e-5) & active
            if not do_swap.any(): break

            layer_indices = torch.where(do_swap)[0]
            swap_indices = best_idx[layer_indices]
            u_idx = swap_indices // groups_per_pack
            v_idx = swap_indices % groups_per_pack
            p_max_idx = idx_max[layer_indices]
            p_min_idx = idx_min[layer_indices]

            u_val = pack_contents[layer_indices, p_max_idx, u_idx]
            v_val = pack_contents[layer_indices, p_min_idx, v_idx]
            pack_contents[layer_indices, p_max_idx, u_idx] = v_val
            pack_contents[layer_indices, p_min_idx, v_idx] = u_val
            u_id = pack_item_ids[layer_indices, p_max_idx, u_idx]
            v_id = pack_item_ids[layer_indices, p_min_idx, v_idx]
            pack_item_ids[layer_indices, p_max_idx, u_idx] = v_id
            pack_item_ids[layer_indices, p_min_idx, v_idx] = u_id

    run_1swap(pack_contents, pack_item_ids, max_iter=20)

    # 2-for-2 Swap Refinement
    # Only run if 1-swap didn't perfectly solve it and if G >= 2
    if groups_per_pack >= 2:
        for _ in range(10): # Expensive, fewer iterations
            p_weights = pack_contents.sum(dim=2)
            val_max, idx_max = p_weights.max(dim=1)
            val_min, idx_min = p_weights.min(dim=1)
            diff = val_max - val_min
            active = diff > 1e-4
            if not active.any(): break

            # [L, G]
            gather_idx_max = idx_max.view(-1, 1, 1).expand(-1, 1, groups_per_pack)
            gather_idx_min = idx_min.view(-1, 1, 1).expand(-1, 1, groups_per_pack)
            items_max = torch.gather(pack_contents, 1, gather_idx_max).squeeze(1)
            items_min = torch.gather(pack_contents, 1, gather_idx_min).squeeze(1)

            # Compute pair sums: [L, G, G]
            # pairs_max[l, i, j] = item[i] + item[j]
            pairs_max = items_max.unsqueeze(2) + items_max.unsqueeze(1)
            pairs_min = items_min.unsqueeze(2) + items_min.unsqueeze(1)

            # Compute deltas: [L, G, G, G, G]
            # delta[l, i, j, k, m] = pairs_max[l, i, j] - pairs_min[l, k, m]

            delta = pairs_max.unsqueeze(3).unsqueeze(4) - pairs_min.unsqueeze(1).unsqueeze(2)

            target = diff.view(-1, 1, 1, 1, 1)
            improvement = target - (target - 2 * delta).abs()

            # Mask diagonals (i==j or k==m are invalid pairs)
            improvement.diagonal(dim1=1, dim2=2).fill_(-float('inf'))
            improvement.diagonal(dim1=3, dim2=4).fill_(-float('inf'))

            # Reshape to find max
            imp_flat = improvement.view(num_layers, -1)
            best_imp, best_idx = imp_flat.max(dim=1)

            do_swap = (best_imp > 1e-5) & active
            if not do_swap.any(): break

            # Decode indices
            layer_indices = torch.where(do_swap)[0]
            flat_indices = best_idx[layer_indices]

            # g^4
            g = groups_per_pack
            g2 = g * g
            g3 = g2 * g

            idx_i = flat_indices // g3
            rem = flat_indices % g3
            idx_j = rem // g2
            rem = rem % g2
            idx_k = rem // g
            idx_m = rem % g

            p_max = idx_max[layer_indices]
            p_min = idx_min[layer_indices]

            # Perform swap
            # items_max[idx_i] <-> items_min[idx_k]
            # items_max[idx_j] <-> items_min[idx_m]

            # Extract values
            val_max_i = pack_contents[layer_indices, p_max, idx_i]
            val_max_j = pack_contents[layer_indices, p_max, idx_j]
            val_min_k = pack_contents[layer_indices, p_min, idx_k]
            val_min_m = pack_contents[layer_indices, p_min, idx_m]

            # Swap values
            pack_contents[layer_indices, p_max, idx_i] = val_min_k
            pack_contents[layer_indices, p_max, idx_j] = val_min_m
            pack_contents[layer_indices, p_min, idx_k] = val_max_i
            pack_contents[layer_indices, p_min, idx_m] = val_max_j

            # Swap IDs
            id_max_i = pack_item_ids[layer_indices, p_max, idx_i]
            id_max_j = pack_item_ids[layer_indices, p_max, idx_j]
            id_min_k = pack_item_ids[layer_indices, p_min, idx_k]
            id_min_m = pack_item_ids[layer_indices, p_min, idx_m]

            pack_item_ids[layer_indices, p_max, idx_i] = id_min_k
            pack_item_ids[layer_indices, p_max, idx_j] = id_min_m
            pack_item_ids[layer_indices, p_min, idx_k] = id_max_i
            pack_item_ids[layer_indices, p_min, idx_m] = id_max_j

    # Reconstruct Result
    pack_index = torch.empty(num_layers,
                             num_groups,
                             dtype=torch.int64,
                             device=device)
    rank_in_pack = torch.empty(num_layers,
                               num_groups,
                               dtype=torch.int64,
                               device=device)

    flat_item_ids = pack_item_ids.view(num_layers, -1)
    pack_grid = torch.arange(num_packs, device=device).view(
        1, -1, 1).expand(num_layers, -1,
                         groups_per_pack).reshape(num_layers, -1)
    rank_grid = torch.arange(groups_per_pack, device=device).view(
        1, 1, -1).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    pack_index.scatter_(1, flat_item_ids, pack_grid)
    rank_in_pack.scatter_(1, flat_item_ids, rank_grid)

    return pack_index, rank_in_pack
>>>>>>> REPLACE
</DIFF>