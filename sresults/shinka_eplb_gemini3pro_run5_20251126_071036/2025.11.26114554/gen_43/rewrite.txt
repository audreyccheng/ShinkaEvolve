# EVOLVE-BLOCK-START
"""
Expert parallelism load balancer (EPLB) for vLLM.

This module implements the core rearrangement algorithm.

The rearrangement algorithm is adapted from
[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).

Please find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example
on how the EPLB algorithm works.
"""

import torch


def _refine_packing(weights: torch.Tensor,
                    pack_indices: torch.Tensor,
                    pack_weights: torch.Tensor,
                    num_packs: int,
                    groups_per_pack: int,
                    max_iters: int = 20) -> torch.Tensor:
    """
    Iteratively refines the packing by swapping items between the max-load
    pack and any other pack to reduce the maximum load.
    
    Using vectorized "Swap Max with Any" strategy.
    """
    for _ in range(max_iters):
        # Identify max pack
        max_load, max_pid = torch.max(pack_weights, dim=0)

        # Get items in max pack
        items_max = pack_indices[max_pid]  # [groups_per_pack]
        w_max_items = weights[items_max]   # [groups_per_pack]

        # Get items in all packs
        all_items = pack_indices           # [num_packs, groups_per_pack]
        w_all_items = weights[all_items]   # [num_packs, groups_per_pack]

        # Calculate deltas for swapping item i from max pack with item j from any pack k
        # delta = w_max_i - w_k_j
        # [1, 1, G] - [P, G, 1] -> [P, G, G]
        deltas = w_max_items.view(1, 1, -1) - w_all_items.view(num_packs, groups_per_pack, 1)

        # Calculate new loads if swap happens
        # New max pack load: max_load - delta
        # New pack k load: current_k_load + delta
        new_max_load = max_load - deltas
        new_k_load = pack_weights.view(num_packs, 1, 1) + deltas

        # Objective: max(new_max_load, new_k_load)
        objectives = torch.max(new_max_load, new_k_load)

        # Mask out swaps with self (k == max_pid)
        objectives[max_pid] = float('inf')

        # Find best swap
        min_obj, flat_idx = torch.min(objectives.flatten(), dim=0)

        # If no significant improvement, stop
        if min_obj >= max_load - 1e-6:
            break

        # Decode indices
        # flat_idx is index into [P, G, G]
        best_pid = flat_idx // (groups_per_pack * groups_per_pack)
        rem = flat_idx % (groups_per_pack * groups_per_pack)
        best_k_item_idx = rem // groups_per_pack
        best_max_item_idx = rem % groups_per_pack

        # Execute swap
        item_from_max = items_max[best_max_item_idx].item()
        item_from_k = all_items[best_pid, best_k_item_idx].item()

        pack_indices[max_pid, best_max_item_idx] = item_from_k
        pack_indices[best_pid, best_k_item_idx] = item_from_max

        # Update weights
        delta_val = deltas[best_pid, best_k_item_idx, best_max_item_idx]
        pack_weights[max_pid] -= delta_val
        pack_weights[best_pid] += delta_val

    return pack_indices


def balanced_packing(weight: torch.Tensor,
                     num_packs: int,
                     beam_width: int = 8) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs using Vectorized Beam Search.
    
    Parameters:
        weight: [L, n], the weight of each item
        num_packs: number of packs
        beam_width: number of partial solutions to maintain (default 8)

    Returns:
        pack_index: [L, n], the pack index of each item
        rank_in_pack: [L, n], the rank of the item in the pack
    """
    num_layers, num_items = weight.shape
    device = weight.device
    assert num_items % num_packs == 0
    groups_per_pack = num_items // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(num_items, dtype=torch.int64,
                                  device=device).expand(num_layers, -1)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Sort items descending (critical for beam search efficiency)
    sorted_res = weight.sort(dim=-1, descending=True)
    sorted_weights = sorted_res.values
    original_indices = sorted_res.indices

    # Beam Search State
    # loads: [L, B, M]
    # counts: [L, B, M]
    beam_loads = torch.zeros((num_layers, beam_width, num_packs), dtype=weight.dtype, device=device)
    beam_counts = torch.zeros((num_layers, beam_width, num_packs), dtype=torch.int64, device=device)
    
    # Initialize inactive beams to high cost to prioritize Beam 0 initially
    beam_loads[:, 1:, :] = 1e9
    
    # History for backtracking
    # [L, N, B] stores the parent index and choice for each step
    parent_indices = torch.zeros((num_layers, num_items, beam_width), dtype=torch.int64, device=device)
    pack_choices = torch.zeros((num_layers, num_items, beam_width), dtype=torch.int64, device=device)
    
    # Constants for vectorization
    eye_packs = torch.eye(num_packs, device=device).view(1, 1, num_packs, num_packs)
    eye_packs_int = torch.eye(num_packs, dtype=torch.int64, device=device).view(1, 1, num_packs, num_packs)
    
    # Iterate over items
    for i in range(num_items):
        w = sorted_weights[:, i].view(num_layers, 1, 1, 1) # [L, 1, 1, 1]
        
        # 1. Expand Candidates
        # base_loads: [L, B, 1, M]
        base_loads = beam_loads.unsqueeze(2)
        base_counts = beam_counts.unsqueeze(2)
        
        # Add weight to each pack choice: [L, B, M, M]
        cand_loads = base_loads + (w * eye_packs)
        cand_counts = base_counts + eye_packs_int
        
        # 2. Check Constraints
        # Check if the target pack had space BEFORE addition.
        # Condition: base_counts[..., p] < groups_per_pack
        # We need the diagonal of the last two dimensions (choice == pack_idx)
        # But since base_counts is constant across choice dim (dim 2), we just check dim 3.
        # Mask shape: [L, B, M] -> Valid pack choices for each beam
        valid_choice_mask = beam_counts < groups_per_pack
        
        # Broadcast mask to [L, B, M, M] is not needed if we compute scores flattened.
        # We just need to mask the scores of invalid transitions.
        # valid_choice_mask[l, b, p] is True if we can put item in pack p.
        
        # 3. Calculate Scores (Sum of Squares L2)
        # [L, B, M]
        scores = cand_loads.pow(2).sum(dim=-1)
        
        # Apply mask: Set score to infinity if move is invalid
        scores = torch.where(valid_choice_mask.unsqueeze(2).expand_as(scores), 
                             scores, 
                             torch.tensor(float('inf'), device=device))
        
        # 4. Select Top K
        # Flatten to [L, B*M]
        scores_flat = scores.view(num_layers, -1)
        
        # TopK smallest scores
        best_scores, indices = torch.topk(scores_flat, k=beam_width, dim=1, largest=False)
        
        # Decode indices
        parent_b = indices // num_packs # [L, B]
        choice_p = indices % num_packs  # [L, B]
        
        # Store history
        parent_indices[:, i, :] = parent_b
        pack_choices[:, i, :] = choice_p
        
        # 5. Update State
        # Gather the chosen states.
        # We need to gather from cand_loads flattened: [L, B*M, M]
        cand_loads_flat = cand_loads.view(num_layers, beam_width * num_packs, num_packs)
        cand_counts_flat = cand_counts.view(num_layers, beam_width * num_packs, num_packs)
        
        gather_idx = indices.unsqueeze(2).expand(-1, -1, num_packs)
        
        beam_loads = torch.gather(cand_loads_flat, 1, gather_idx)
        beam_counts = torch.gather(cand_counts_flat, 1, gather_idx)

    # Backtracking to reconstruct solution
    # Best beam is at index 0 (since topk sorted them)
    curr_beam = torch.zeros((num_layers,), dtype=torch.int64, device=device)
    pack_index_sorted = torch.zeros((num_layers, num_items), dtype=torch.int64, device=device)
    
    for i in range(num_items - 1, -1, -1):
        # Get choice for this step
        # choice = pack_choices[l, i, curr_beam]
        p_choice = torch.gather(pack_choices[:, i, :], 1, curr_beam.unsqueeze(1)).squeeze(1)
        pack_index_sorted[:, i] = p_choice
        
        # Move to parent beam
        curr_beam = torch.gather(parent_indices[:, i, :], 1, curr_beam.unsqueeze(1)).squeeze(1)

    # Remap to original indices
    pack_index = torch.zeros_like(weight, dtype=torch.int64)
    pack_index.scatter_(1, original_indices, pack_index_sorted)

    # Compute ranks (order of arrival in pack)
    # We can just iterate packs to generate unique ranks 0..G-1
    rank_in_pack = torch.zeros_like(pack_index)
    for p in range(num_packs):
        mask = (pack_index == p)
        # cumsum gives 1-based index, subtract 1 for 0-based
        ranks = mask.cumsum(dim=1) - 1
        rank_in_pack = torch.where(mask, ranks, rank_in_pack)
        
    # Final Refinement Step (Swap Optimization)
    # Beam search is on discrete grid; refinement smooths weights
    
    # Reconstruct current pack assignments/weights for refinement
    # (Doing this per layer)
    for i in range(num_layers):
        # Construct assignment matrix [M, G]
        # This part is slightly slow in Python loop but N is small
        assignments = torch.zeros((num_packs, groups_per_pack), dtype=torch.int64, device=device)
        
        # Fill assignments
        # Use simple scatter or loop
        # For simplicity and speed with small M:
        p_idx = pack_index[i]
        r_idx = rank_in_pack[i]
        flat_idx = p_idx * groups_per_pack + r_idx
        
        # Inverse mapping: flat_idx -> item_idx
        # We need item indices at position (p, r)
        # item_ids[flat_idx] = 0..N-1
        # assignments.view(-1)[flat_idx] = 0..N-1
        item_ids = torch.arange(num_items, device=device)
        assignments.view(-1).scatter_(0, flat_idx, item_ids)
        
        current_pack_weights = torch.zeros(num_packs, device=device, dtype=weight.dtype)
        current_pack_weights.scatter_add_(0, p_idx, weight[i])
        
        # Run Refinement
        assignments = _refine_packing(
            weight[i], assignments, current_pack_weights,
            num_packs, groups_per_pack, max_iters=20
        )
        
        # Update output tensors
        flat_items = assignments.flatten()
        # p_ids for grid
        p_ids_grid = torch.arange(num_packs, device=device).unsqueeze(1).expand(-1, groups_per_pack).flatten()
        r_ids_grid = torch.arange(groups_per_pack, device=device).unsqueeze(0).expand(num_packs, -1).flatten()
        
        pack_index[i, flat_items] = p_ids_grid
        rank_in_pack[i, flat_items] = r_ids_grid

    return pack_index, rank_in_pack


def replicate_experts(
        weight: torch.Tensor,
        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Replicate experts to `num_phy` replicas, minimizing the maximum load.
    Uses Vectorized Greedy (Jefferson/D'Hondt).
    """
    n, num_log = weight.shape
    device = weight.device

    # Initialize: Each expert gets at least 1 replica
    logcnt = torch.ones((n, num_log), dtype=torch.int64, device=device)
    
    # Initialize phy2log/rank arrays
    phy2log = torch.zeros((n, num_phy), dtype=torch.int64, device=device)
    rank = torch.zeros((n, num_phy), dtype=torch.int64, device=device)
    
    # Fill initial slots
    # This part can be reconstructed later, we just need counts for greedy.
    
    # Greedy loop
    arangen = torch.arange(n, dtype=torch.int64, device=device)
    for _ in range(num_log, num_phy):
        scores = weight / logcnt
        indices = torch.argmax(scores, dim=-1)
        logcnt[arangen, indices] += 1
        
    # Reconstruct mappings
    for i in range(n):
        counts = logcnt[i]
        l_ids = torch.repeat_interleave(
            torch.arange(num_log, device=device), counts
        )
        phy2log[i] = l_ids
        
        # Generate ranks
        # Cumulative sum approach to generate 0, 1, 2... for each ID
        # There isn't a direct repeatable primitive, so we iterate
        curr = 0
        for idx in range(num_log):
            c = counts[idx].item()
            rank[i, curr:curr+c] = torch.arange(c, device=device)
            curr += c

    return phy2log, rank, logcnt


def rebalance_experts_hierarchical(
    weight: torch.Tensor,
    num_physical_experts: int,
    num_groups: int,
    num_nodes: int,
    num_gpus: int,
):
    """
    Hierarchical rebalancing: Groups->Nodes, then Replicas->GPUs.
    """
    num_layers, num_logical_experts = weight.shape
    assert num_logical_experts % num_groups == 0
    group_size = num_logical_experts // num_groups
    assert num_groups % num_nodes == 0
    groups_per_node = num_groups // num_nodes
    assert num_gpus % num_nodes == 0
    assert num_physical_experts % num_gpus == 0
    phy_experts_per_gpu = num_physical_experts // num_gpus

    def inverse(perm: torch.Tensor) -> torch.Tensor:
        inv = torch.empty_like(perm)
        inv.scatter_(
            1,
            perm,
            torch.arange(perm.size(1), dtype=torch.int64,
                         device=perm.device).expand(perm.shape),
        )
        return inv

    # Step 1: pack groups to nodes
    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)

    # Use Beam Search packing
    group_pack_index, group_rank_in_pack = balanced_packing(
        tokens_per_group, num_nodes)

    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *
                 group_size).unsqueeze(-1) +
                torch.arange(group_size,
                             dtype=torch.int64,
                             device=group_pack_index.device)).flatten(-2)
    mlog2log = inverse(log2mlog)

    # Step 2: construct redundant experts within nodes
    tokens_per_mlog = weight.gather(-1, mlog2log).view(
        -1, num_logical_experts // num_nodes)
    phy2mlog, phyrank, mlogcnt = replicate_experts(
        tokens_per_mlog, num_physical_experts // num_nodes)

    # Step 3: pack physical_experts to GPUs
    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)

    # Use Beam Search packing
    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,
                                                num_gpus // num_nodes)

    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack
    pphy2phy = inverse(phy2pphy)

    pphy2mlog = phy2mlog.gather(
        -1, pphy2phy) 
    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(
        0,
        num_logical_experts,
        num_logical_experts // num_nodes,
        device=group_pack_index.device,
    ).view(1, -1, 1)).flatten(-2)
    pphy2log = mlog2log.gather(-1, pphy2mlog)
    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)
    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)
    return pphy2log, pphyrank, logcnt


def rebalance_experts(
    weight: torch.Tensor,
    num_replicas: int,
    num_groups: int,
    num_nodes: int,
    num_gpus: int,
) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Entry point for expert-parallelism load balancer.
    """
    num_layers, num_logical_experts = weight.shape
    weight = weight.float().cpu()

    # Dispatch policy
    if num_groups % num_nodes == 0:
        # use hierarchical load-balance policy
        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
            weight, num_replicas, num_groups, num_nodes, num_gpus)
    else:
        # use global load-balance policy
        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(
            weight, num_replicas, 1, 1, num_gpus)

    num_redundant_experts = num_replicas - num_logical_experts
    maxlogcnt = num_redundant_experts + 1

    # Construct reverse mapping log2phy
    log2phy: torch.Tensor = torch.full(
        (num_layers, num_logical_experts, maxlogcnt),
        -1,
        dtype=torch.int64,
        device=logcnt.device,
    )

    # Efficient scatter
    log2phy.view(num_layers, -1).scatter_(
        -1,
        phy2log * maxlogcnt + phyrank,
        torch.arange(num_replicas, dtype=torch.int64,
                     device=log2phy.device).expand(num_layers, -1),
    )
    return phy2log, log2phy, logcnt
# EVOLVE-BLOCK-END