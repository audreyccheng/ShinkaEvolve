<NAME>
tensorized_variance_refinement
</NAME>

<DESCRIPTION>
Replaces the heuristic max-min packing refinement with a global all-pairs variance minimization strategy. This considers swapping any item from any pack with any item from any other pack to minimize the sum of squared pack loads (which implies load balancing). The tensorized implementation efficiently computes the gain for all possible swaps in parallel.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def _refine_packing(weights: torch.Tensor,
                    pack_indices: torch.Tensor,
                    pack_weights: torch.Tensor,
                    num_packs: int,
                    groups_per_pack: int,
                    max_iters: int = 20) -> torch.Tensor:
    """
    Iteratively refines the packing by swapping items between the max-load
    and min-load packs to reduce variance.

    Args:
        weights: [num_groups] weights of items
        pack_indices: [num_packs, groups_per_pack] indices of items in each pack
        pack_weights: [num_packs] total weight of each pack

    Returns:
        pack_indices: Refined item assignments
    """
    for _ in range(max_iters):
        # Identify extreme packs
        max_load, max_pid = torch.max(pack_weights, dim=0)
        min_load, min_pid = torch.min(pack_weights, dim=0)

        diff = max_load - min_load
        if diff < 1e-6:
            break

        # Get items currently in these packs
        items_max = pack_indices[max_pid] # [groups_per_pack]
        items_min = pack_indices[min_pid] # [groups_per_pack]

        w_max_items = weights[items_max] # [groups_per_pack]
        w_min_items = weights[items_min] # [groups_per_pack]

        # Calculate potential deltas for all pairs: w_i (from max) - w_j (from min)
        # Broadcast: [G, 1] - [1, G] -> [G, G]
        deltas = w_max_items.unsqueeze(1) - w_min_items.unsqueeze(0)

        # We want to perform a swap if it reduces the difference between packs.
        # New diff = |(max - d) - (min + d)| = |diff - 2d|
        # Improvement = diff - |diff - 2d|
        # We also prefer larger reductions.

        scores = diff - torch.abs(diff - 2 * deltas)

        best_score_flat, best_idx_flat = torch.max(scores.flatten(), dim=0)

        if best_score_flat <= 1e-5:
            # No beneficial swap found between these two packs
            break

        # Decode indices
        r_idx = best_idx_flat // groups_per_pack
        c_idx = best_idx_flat % groups_per_pack

        # Execute swap
        item_from_max = items_max[r_idx].item()
        item_from_min = items_min[c_idx].item()

        pack_indices[max_pid, r_idx] = item_from_min
        pack_indices[min_pid, c_idx] = item_from_max

        # Update weights
        delta_val = deltas[r_idx, c_idx]
        pack_weights[max_pid] -= delta_val
        pack_weights[min_pid] += delta_val

    return pack_indices
=======
def _refine_packing(weights: torch.Tensor,
                    pack_indices: torch.Tensor,
                    pack_weights: torch.Tensor,
                    num_packs: int,
                    groups_per_pack: int,
                    max_iters: int = 20) -> torch.Tensor:
    """
    Iteratively refines the packing by swapping items between any pair of packs
    to minimize the sum of squared pack weights (variance).

    Args:
        weights: [num_groups] weights of items
        pack_indices: [num_packs, groups_per_pack] indices of items in each pack
        pack_weights: [num_packs] total weight of each pack

    Returns:
        pack_indices: Refined item assignments
    """
    device = weights.device

    # Pre-compute pack index masks to mask out self-swaps
    # [P, 1, P, 1]
    idx_p = torch.arange(num_packs, device=device)
    mask_same_pack = (idx_p.view(-1, 1) == idx_p.view(1, -1)).view(num_packs, 1, num_packs, 1)

    for _ in range(max_iters):
        # Current item weights: [P, G]
        item_weights = weights[pack_indices]

        # w_{p1, g1}: [P, G, 1, 1]
        w1 = item_weights.view(num_packs, groups_per_pack, 1, 1)
        # w_{p2, g2}: [1, 1, P, G]
        w2 = item_weights.view(1, 1, num_packs, groups_per_pack)

        # delta = w2 - w1 (amount added to p1, subtracted from p2)
        delta = w2 - w1

        # diff_W = W1 - W2
        # [P, 1, P, 1]
        diff_W = pack_weights.view(num_packs, 1, 1, 1) - pack_weights.view(1, 1, num_packs, 1)

        # Change in variance (Sum of Squares):
        # (W1+d)^2 + (W2-d)^2 - W1^2 - W2^2 = 2d^2 + 2d(W1 - W2)
        # minimize: delta * (delta + diff_W)
        change = delta * (delta + diff_W)

        # Mask invalid swaps (same pack)
        change = torch.where(mask_same_pack, torch.tensor(float('inf'), device=device), change)

        # Find best swap
        min_val, flat_idx = torch.min(change.flatten(), dim=0)

        if min_val >= -1e-6:
            break

        # Decode indices
        idx = flat_idx.item()
        G = groups_per_pack
        P = num_packs

        p1 = idx // (G * P * G)
        rem = idx % (G * P * G)
        g1 = rem // (P * G)
        rem = rem % (P * G)
        p2 = rem // G
        g2 = rem % G

        # Execute swap
        item_idx_1 = pack_indices[p1, g1].item()
        item_idx_2 = pack_indices[p2, g2].item()

        pack_indices[p1, g1] = item_idx_2
        pack_indices[p2, g2] = item_idx_1

        # Update pack weights
        w_val_1 = weights[item_idx_1]
        w_val_2 = weights[item_idx_2]
        d = w_val_2 - w_val_1

        pack_weights[p1] += d
        pack_weights[p2] -= d

    return pack_indices
>>>>>>> REPLACE
</DIFF>