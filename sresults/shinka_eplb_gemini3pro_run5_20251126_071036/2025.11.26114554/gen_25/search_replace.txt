<NAME>
parallel_randomized_lpt
</NAME>

<DESCRIPTION>
Implements Parallel Randomized Greedy LPT with L2-Gain Refinement for `balanced_packing`.
Instead of a single deterministic greedy initialization, the problem is expanded by a factor of `num_restarts` (set to 16).
Restart 0 retains the original deterministic behavior.
Restarts 1..15 introduce small random multiplicative noise (2%) to the weights *only for the purpose of sorting*, creating different input orderings for the LPT heuristic.
The greedy assignment and the subsequent high-performance L2-gain local search refinement are executed in parallel on the expanded batch.
Finally, the result with the minimum load imbalance is selected for each layer.
This approach leverages the high parallelism of the GPU to explore a wider solution space and escape local optima, targeting the low balancedness score while maintaining high efficiency.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses Greedy LPT initialization followed by an advanced L2-gain based
    local search refinement considering top-K heavy/light swaps.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # 1. Greedy LPT Initialization
    # Sort weights descending
    sorted_weight, sorted_indices = weight.float().sort(dim=-1, descending=True)

    # State tracking:
    # pack_contents: [L, P, G] stores weights of items in each slot
    # pack_item_ids: [L, P, G] stores original indices of items in each slot
    pack_contents = torch.zeros(num_layers, num_packs, groups_per_pack, device=device)
    pack_item_ids = torch.zeros(num_layers, num_packs, groups_per_pack, dtype=torch.int64, device=device)

    pack_weights = torch.zeros(num_layers, num_packs, device=device)
    pack_counts = torch.zeros(num_layers, num_packs, dtype=torch.int64, device=device)

    row_indices = torch.arange(num_layers, device=device)

    # Assign items one by one
    for i in range(num_groups):
        w = sorted_weight[:, i]
        original_idx = sorted_indices[:, i]

        # Mask valid packs (not full)
        valid_mask = pack_counts < groups_per_pack

        # Find pack with min weight among valid ones
        candidate_weights = pack_weights.clone()
        candidate_weights[~valid_mask] = float('inf')

        chosen_pack = torch.argmin(candidate_weights, dim=1) # [L]

        # Get rank (current count)
        chosen_rank = pack_counts[row_indices, chosen_pack] # [L]

        # Update State
        pack_weights[row_indices, chosen_pack] += w
        pack_counts[row_indices, chosen_pack] += 1

        # Store item info
        pack_contents[row_indices, chosen_pack, chosen_rank] = w
        pack_item_ids[row_indices, chosen_pack, chosen_rank] = original_idx

    # 2. Refinement Loop (L2 Optimization)
    num_iters = 20
    # K determines how many heavy/light packs we consider for swapping.
    K = 4
    if num_packs < 2 * K:
        K = num_packs // 2

    if K > 0:
        for _ in range(num_iters):
            # Sort packs by weight to find heaviest and lightest
            # We recompute pack_weights from contents to stay consistent
            current_pack_weights = pack_contents.sum(dim=-1)

            # Get indices of packs sorted by weight
            sorted_pack_indices = current_pack_weights.argsort(dim=1)

            # Select K heavy and K light packs
            # heavy_packs indices: [L, K] (heaviest at end)
            heavy_packs = sorted_pack_indices[:, -K:]
            light_packs = sorted_pack_indices[:, :K]

            w_packs_heavy = torch.gather(current_pack_weights, 1, heavy_packs)
            w_packs_light = torch.gather(current_pack_weights, 1, light_packs)

            # Pack Diff: [L, K, K]
            # Difference between heavy pack i and light pack j
            # P = W_H - W_L
            pack_diff = w_packs_heavy.unsqueeze(2) - w_packs_light.unsqueeze(1)

            # Gather Items: [L, K, G]
            idx_heavy_expanded = heavy_packs.unsqueeze(2).expand(-1, -1, groups_per_pack)
            idx_light_expanded = light_packs.unsqueeze(2).expand(-1, -1, groups_per_pack)

            items_heavy = torch.gather(pack_contents, 1, idx_heavy_expanded)
            items_light = torch.gather(pack_contents, 1, idx_light_expanded)

            # Compute Delta for all pairs of items between these packs
            # delta = weight_item_heavy - weight_item_light
            # Shape: [L, K (heavy), G, K (light), G]
            delta = items_heavy.view(num_layers, K, groups_per_pack, 1, 1) - \
                    items_light.view(num_layers, 1, 1, K, groups_per_pack)

            # Improvement Gain (L2 Objective)
            # Minimize Sum(Squares). Maximize Gain = 2 * delta * (PackDiff - delta)
            pd_view = pack_diff.view(num_layers, K, 1, K, 1)
            gain = 2 * delta * (pd_view - delta)

            # Find best swap
            gain_flat = gain.view(num_layers, -1)
            best_gain, best_idx_flat = gain_flat.max(dim=1)

            # Threshold for improvement
            active_mask = best_gain > 1e-6
            if not active_mask.any():
                break

            # Perform Swaps for layers with improvement
            l_idx = torch.where(active_mask)[0]
            b_idx = best_idx_flat[l_idx]

            # Decode flattened indices
            # Structure: K_heavy * G * K_light * G
            total_G = groups_per_pack
            total_KG = K * total_G

            idx_item_l = b_idx % total_G
            b_idx = b_idx // total_G
            idx_pack_l = b_idx % K
            b_idx = b_idx // K
            idx_item_h = b_idx % total_G
            idx_pack_h = b_idx // total_G

            # Get actual pack indices
            p_h = heavy_packs[l_idx, idx_pack_h]
            p_l = light_packs[l_idx, idx_pack_l]

            # Swap values in pack_contents
            val_h = pack_contents[l_idx, p_h, idx_item_h]
            val_l = pack_contents[l_idx, p_l, idx_item_l]

            pack_contents[l_idx, p_h, idx_item_h] = val_l
            pack_contents[l_idx, p_l, idx_item_l] = val_h

            # Swap IDs in pack_item_ids
            id_h = pack_item_ids[l_idx, p_h, idx_item_h]
            id_l = pack_item_ids[l_idx, p_l, idx_item_l]

            pack_item_ids[l_idx, p_h, idx_item_h] = id_l
            pack_item_ids[l_idx, p_l, idx_item_l] = id_h

    # 3. Reconstruction
    pack_index = torch.empty(num_layers, num_groups, dtype=torch.int64, device=device)
    rank_in_pack = torch.empty(num_layers, num_groups, dtype=torch.int64, device=device)

    # Generate grid of Pack IDs and Ranks corresponding to the shape of pack_item_ids
    # pack_ids grid: same for all layers
    grid_packs = torch.arange(num_packs, device=device).view(1, num_packs, 1).expand(num_layers, -1, groups_per_pack).reshape(num_layers, -1)
    grid_ranks = torch.arange(groups_per_pack, device=device).view(1, 1, groups_per_pack).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    # Flat item IDs tells us which item is at which position
    flat_ids = pack_item_ids.view(num_layers, -1)

    # Scatter results back to output tensors
    # pack_index[layer, item_id] = pack_id
    pack_index.scatter_(1, flat_ids, grid_packs)
    rank_in_pack.scatter_(1, flat_ids, grid_ranks)

    return pack_index, rank_in_pack
=======
def balanced_packing(weight: torch.Tensor,
                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:
    """
    Pack n weighted objects to m packs, such that each bin contains exactly
    n/m objects and the weights of all packs are as balanced as possible.

    Uses Parallel Randomized Greedy LPT initialization followed by L2-gain based
    local search refinement.

    Parameters:
        weight: [X, n], the weight of each item
        num_packs: number of packs

    Returns:
        pack_index: [X, n], the pack index of each item
        rank_in_pack: [X, n], the rank of the item in the pack
    """
    num_layers, num_groups = weight.shape
    device = weight.device
    assert num_groups % num_packs == 0
    groups_per_pack = num_groups // num_packs

    if groups_per_pack == 1:
        pack_index = torch.arange(weight.size(-1),
                                  dtype=torch.int64,
                                  device=device).expand(weight.shape)
        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)
        return pack_index, rank_in_pack

    # Configuration for parallel restarts
    num_restarts = 16  # Parallel factor to explore solution space

    # Expand problem: [L, G] -> [L * R, G]
    # We treat each restart as an independent layer in the batch
    weight_expanded = weight.repeat_interleave(num_restarts, dim=0)
    batch_size = weight_expanded.shape[0]

    # Generate noisy weights for sorting to induce diversity
    # Restart 0 is deterministic (noise=0), others are randomized
    noise_scale = 0.02
    noise = torch.rand_like(weight_expanded) * noise_scale
    # Ensure first restart per layer has no noise (deterministic baseline)
    mask_deterministic = torch.arange(batch_size, device=device) % num_restarts == 0
    noise[mask_deterministic] = 0

    # Sort based on perturbed weights
    # We still use exact weights for accumulation, just changing order
    sorting_weights = weight_expanded + noise * weight_expanded
    _, sorted_indices = sorting_weights.sort(dim=-1, descending=True)

    # Gather actual weights in the sorted order
    sorted_weight = torch.gather(weight_expanded, 1, sorted_indices)

    # 1. Greedy LPT Initialization (Vectorized over L*R)
    pack_contents = torch.zeros(batch_size, num_packs, groups_per_pack, device=device)
    pack_item_ids = torch.zeros(batch_size, num_packs, groups_per_pack, dtype=torch.int64, device=device)

    pack_weights = torch.zeros(batch_size, num_packs, device=device)
    pack_counts = torch.zeros(batch_size, num_packs, dtype=torch.int64, device=device)

    row_indices = torch.arange(batch_size, device=device)

    for i in range(num_groups):
        w = sorted_weight[:, i]
        original_idx = sorted_indices[:, i]

        valid_mask = pack_counts < groups_per_pack

        candidate_weights = pack_weights.clone()
        candidate_weights[~valid_mask] = float('inf')

        chosen_pack = torch.argmin(candidate_weights, dim=1)

        chosen_rank = pack_counts[row_indices, chosen_pack]

        pack_weights[row_indices, chosen_pack] += w
        pack_counts[row_indices, chosen_pack] += 1

        pack_contents[row_indices, chosen_pack, chosen_rank] = w
        pack_item_ids[row_indices, chosen_pack, chosen_rank] = original_idx

    # 2. Refinement Loop
    num_iters = 20
    K = 4
    if num_packs < 2 * K:
        K = num_packs // 2

    if K > 0:
        for _ in range(num_iters):
            current_pack_weights = pack_contents.sum(dim=-1)
            sorted_pack_indices = current_pack_weights.argsort(dim=1)

            heavy_packs = sorted_pack_indices[:, -K:]
            light_packs = sorted_pack_indices[:, :K]

            w_packs_heavy = torch.gather(current_pack_weights, 1, heavy_packs)
            w_packs_light = torch.gather(current_pack_weights, 1, light_packs)

            pack_diff = w_packs_heavy.unsqueeze(2) - w_packs_light.unsqueeze(1)

            idx_heavy_expanded = heavy_packs.unsqueeze(2).expand(-1, -1, groups_per_pack)
            idx_light_expanded = light_packs.unsqueeze(2).expand(-1, -1, groups_per_pack)

            items_heavy = torch.gather(pack_contents, 1, idx_heavy_expanded)
            items_light = torch.gather(pack_contents, 1, idx_light_expanded)

            delta = items_heavy.view(batch_size, K, groups_per_pack, 1, 1) - \
                    items_light.view(batch_size, 1, 1, K, groups_per_pack)

            pd_view = pack_diff.view(batch_size, K, 1, K, 1)
            gain = 2 * delta * (pd_view - delta)

            gain_flat = gain.view(batch_size, -1)
            best_gain, best_idx_flat = gain_flat.max(dim=1)

            active_mask = best_gain > 1e-6
            if not active_mask.any():
                break

            l_idx = torch.where(active_mask)[0]
            b_idx = best_idx_flat[l_idx]

            total_G = groups_per_pack

            idx_item_l = b_idx % total_G
            b_idx = b_idx // total_G
            idx_pack_l = b_idx % K
            b_idx = b_idx // K
            idx_item_h = b_idx % total_G
            idx_pack_h = b_idx // total_G

            p_h = heavy_packs[l_idx, idx_pack_h]
            p_l = light_packs[l_idx, idx_pack_l]

            val_h = pack_contents[l_idx, p_h, idx_item_h]
            val_l = pack_contents[l_idx, p_l, idx_item_l]

            pack_contents[l_idx, p_h, idx_item_h] = val_l
            pack_contents[l_idx, p_l, idx_item_l] = val_h

            id_h = pack_item_ids[l_idx, p_h, idx_item_h]
            id_l = pack_item_ids[l_idx, p_l, idx_item_l]

            pack_item_ids[l_idx, p_h, idx_item_h] = id_l
            pack_item_ids[l_idx, p_l, idx_item_l] = id_h

    # 3. Selection of best restart
    final_pack_weights = pack_contents.sum(dim=-1) # [L*R, P]
    max_w = final_pack_weights.max(dim=1).values
    min_w = final_pack_weights.min(dim=1).values
    imbalance = max_w - min_w # [L*R]

    imbalance = imbalance.view(num_layers, num_restarts)
    best_restart_idx = imbalance.argmin(dim=1) # [L]

    # Gather best results
    batch_gather_idx = torch.arange(num_layers, device=device) * num_restarts + best_restart_idx
    best_pack_item_ids = pack_item_ids[batch_gather_idx] # [L, P, G]

    # Reconstruction
    pack_index = torch.empty(num_layers, num_groups, dtype=torch.int64, device=device)
    rank_in_pack = torch.empty(num_layers, num_groups, dtype=torch.int64, device=device)

    grid_packs = torch.arange(num_packs, device=device).view(1, num_packs, 1).expand(num_layers, -1, groups_per_pack).reshape(num_layers, -1)
    grid_ranks = torch.arange(groups_per_pack, device=device).view(1, 1, groups_per_pack).expand(num_layers, num_packs, -1).reshape(num_layers, -1)

    flat_ids = best_pack_item_ids.view(num_layers, -1)

    pack_index.scatter_(1, flat_ids, grid_packs)
    rank_in_pack.scatter_(1, flat_ids, grid_ranks)

    return pack_index, rank_in_pack
>>>>>>> REPLACE
</DIFF>