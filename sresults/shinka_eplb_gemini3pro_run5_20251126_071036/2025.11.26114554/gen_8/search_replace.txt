<NAME>
vectorized_local_search_refinement
</NAME>

<DESCRIPTION>
The previous greedy assignment in `balanced_packing` is efficient but can be improved by a local search refinement step. I propose adding a vectorized refinement phase that iteratively swaps items between the heaviest and lightest packs to reduce load imbalance. This approach operates in parallel across layers using tensor operations (gather/scatter), ensuring it maintains high execution speed while providing better load balancing.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Scatter results back to original order
    pack_index = torch.empty_like(pack_index_sorted)
    rank_in_pack = torch.empty_like(rank_in_pack_sorted)

    pack_index.scatter_(1, sorted_indices, pack_index_sorted)
    rank_in_pack.scatter_(1, sorted_indices, rank_in_pack_sorted)

    return pack_index, rank_in_pack
=======
    # Scatter results back to original order
    pack_index = torch.empty_like(pack_index_sorted)
    rank_in_pack = torch.empty_like(rank_in_pack_sorted)

    pack_index.scatter_(1, sorted_indices, pack_index_sorted)
    rank_in_pack.scatter_(1, sorted_indices, rank_in_pack_sorted)

    # Refinement Step
    # Construct pack_to_item map for fast access to items in each pack
    # pack_to_item: [num_layers, num_packs, groups_per_pack]
    pack_to_item = torch.empty(num_layers,
                               num_packs,
                               groups_per_pack,
                               dtype=torch.int64,
                               device=device)

    # Fill pack_to_item using the sorted results
    # We calculate flat indices to scatter sorted_indices into pack_to_item
    layer_offset = torch.arange(num_layers, device=device).unsqueeze(1) * (
        num_packs * groups_per_pack)
    flat_indices = layer_offset + pack_index_sorted * groups_per_pack + rank_in_pack_sorted
    pack_to_item.view(-1).scatter_(0, flat_indices.flatten(),
                                   sorted_indices.flatten())

    # Local Search Refinement
    # Perform pairwise swaps between the heaviest and lightest packs
    for _ in range(20):
        # Identify heaviest and lightest packs
        max_weight, max_pack = pack_weights.max(dim=1)  # [num_layers]
        min_weight, min_pack = pack_weights.min(dim=1)  # [num_layers]

        diff = max_weight - min_weight
        if diff.max() < 1e-4:
            break

        # Gather items belonging to max and min packs
        # Expand indices for gathering: [num_layers, 1, groups_per_pack]
        idx_max = max_pack.view(-1, 1, 1).expand(-1, 1, groups_per_pack)
        idx_min = min_pack.view(-1, 1, 1).expand(-1, 1, groups_per_pack)

        # items_max: [num_layers, groups_per_pack]
        items_max = pack_to_item.gather(1, idx_max).squeeze(1)
        items_min = pack_to_item.gather(1, idx_min).squeeze(1)

        # Get weights of these items: [num_layers, groups_per_pack]
        w_max = weight.gather(1, items_max)
        w_min = weight.gather(1, items_min)

        # Compute potential reduction for all pairs
        # delta = w_max[i] - w_min[j]. We want to swap if delta > 0 and 2*delta ~ diff
        # shape: [num_layers, groups_per_pack, groups_per_pack]
        delta = w_max.unsqueeze(2) - w_min.unsqueeze(1)

        # Objective: minimize abs(diff - 2*delta)
        target = diff.view(-1, 1, 1)
        obj = (target - 2 * delta).abs()

        # Mask invalid swaps: must move weight from max to min (delta > 0)
        # and result must improve (obj < target)
        mask = (delta > 0) & (obj < target)
        obj[~mask] = float('inf')

        # Find best swap per layer
        best_val_flat, best_idx_flat = obj.view(num_layers, -1).min(dim=1)
        valid_swap_mask = best_val_flat != float('inf')

        if not valid_swap_mask.any():
            break

        # Indices of layers to update
        l_valid = torch.where(valid_swap_mask)[0]
        if len(l_valid) == 0:
            break

        # Decode best indices
        best_idx_flat_valid = best_idx_flat[l_valid]
        idx_item_max = best_idx_flat_valid // groups_per_pack
        idx_item_min = best_idx_flat_valid % groups_per_pack

        # Get packs and items involved
        p_max = max_pack[l_valid]
        p_min = min_pack[l_valid]

        item_max_global = items_max[l_valid, idx_item_max]
        item_min_global = items_min[l_valid, idx_item_min]

        # Perform Swap
        # 1. Update pack_weights
        delta_w = delta[l_valid, idx_item_max, idx_item_min]
        pack_weights[l_valid, p_max] -= delta_w
        pack_weights[l_valid, p_min] += delta_w

        # 2. Update pack_index and rank_in_pack
        # item_max goes to p_min at rank idx_item_min
        pack_index[l_valid, item_max_global] = p_min
        rank_in_pack[l_valid, item_max_global] = idx_item_min

        # item_min goes to p_max at rank idx_item_max
        pack_index[l_valid, item_min_global] = p_max
        rank_in_pack[l_valid, item_min_global] = idx_item_max

        # 3. Update pack_to_item map
        pack_to_item[l_valid, p_max, idx_item_max] = item_min_global
        pack_to_item[l_valid, p_min, idx_item_min] = item_max_global

    return pack_index, rank_in_pack
>>>>>>> REPLACE

</DIFF>