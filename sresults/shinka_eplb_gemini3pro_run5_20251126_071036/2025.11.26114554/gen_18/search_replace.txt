<NAME>
hybrid_variance_minmax_refinement
</NAME>

<DESCRIPTION>
I propose replacing the `_refine_packing` function with a hybrid approach that uses two phases of refinement.

The original implementation only focused on reducing the maximum load (min-max objective) by swapping items from the heaviest pack. While this directly targets the makespan, it can get stuck in local optima where no single swap from the max pack improves the situation immediately, but a sequence of swaps involving other packs would.

The new implementation consists of two phases:
1.  **Global Variance Reduction (All-Pairs):** For the first half of iterations, the algorithm considers swapping *any* pair of items between *any* two packs to reduce the sum of squared pack weights (variance). This is a smoother global objective that helps balance the entire system and sets up a better configuration. It is implemented efficiently using tensor broadcasting (All-Pairs Tensorized Refinement).
2.  **Min-Max Greedy Refinement:** For the remaining iterations, the algorithm switches back to the original strategy of strictly reducing the maximum load by swapping items from the max-load pack. This ensures that the final result is optimized for the specific makespan metric required.

This hybrid strategy combines the global view of variance reduction with the specific targeting of the min-max objective.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def _refine_packing(weights: torch.Tensor,
                    pack_indices: torch.Tensor,
                    pack_weights: torch.Tensor,
                    num_packs: int,
                    groups_per_pack: int,
                    max_iters: int = 20) -> torch.Tensor:
    """
    Iteratively refines the packing by swapping items between the max-load
    pack and any other pack to reduce the maximum load.

    Args:
        weights: [num_groups] weights of items
        pack_indices: [num_packs, groups_per_pack] indices of items in each pack
        pack_weights: [num_packs] total weight of each pack

    Returns:
        pack_indices: Refined item assignments
    """
    for _ in range(max_iters):
        # Identify max pack
        max_load, max_pid = torch.max(pack_weights, dim=0)

        # Get items in max pack
        items_max = pack_indices[max_pid]  # [groups_per_pack]
        w_max_items = weights[items_max]  # [groups_per_pack]

        # Get items in all packs
        all_items = pack_indices  # [num_packs, groups_per_pack]
        w_all_items = weights[all_items]  # [num_packs, groups_per_pack]

        # Calculate deltas for swapping item i from max pack with item j from any pack k
        # delta = w_max_i - w_k_j
        # [1, 1, G] - [P, G, 1] -> [P, G, G]
        deltas = w_max_items.view(1, 1, -1) - w_all_items.view(
            num_packs, groups_per_pack, 1)

        # Calculate new loads if swap happens
        # New max pack load: max_load - delta
        # New pack k load: current_k_load + delta
        new_max_load = max_load - deltas
        new_k_load = pack_weights.view(num_packs, 1, 1) + deltas

        # We want to minimize the larger of the two resulting loads
        # Objective: max(new_max_load, new_k_load)
        objectives = torch.max(new_max_load, new_k_load)

        # Mask out swaps with self (k == max_pid)
        objectives[max_pid] = float('inf')

        # Find best swap
        min_obj, flat_idx = torch.min(objectives.flatten(), dim=0)

        # If the best swap doesn't improve the max load significantly, stop
        # We look for strictly better than current max_load
        if min_obj >= max_load - 1e-6:
            break

        # Decode indices
        # flat_idx is index into [P, G, G]
        best_pid = flat_idx // (groups_per_pack * groups_per_pack)
        rem = flat_idx % (groups_per_pack * groups_per_pack)
        best_k_item_idx = rem // groups_per_pack
        best_max_item_idx = rem % groups_per_pack

        # Execute swap
        item_from_max = items_max[best_max_item_idx].item()
        item_from_k = all_items[best_pid, best_k_item_idx].item()

        pack_indices[max_pid, best_max_item_idx] = item_from_k
        pack_indices[best_pid, best_k_item_idx] = item_from_max

        # Update weights
        delta_val = deltas[best_pid, best_k_item_idx, best_max_item_idx]
        pack_weights[max_pid] -= delta_val
        pack_weights[best_pid] += delta_val

    return pack_indices
=======
def _refine_packing(weights: torch.Tensor,
                    pack_indices: torch.Tensor,
                    pack_weights: torch.Tensor,
                    num_packs: int,
                    groups_per_pack: int,
                    max_iters: int = 20) -> torch.Tensor:
    """
    Iteratively refines the packing using a two-phase approach:
    1. Global variance reduction (min sum of squared loads).
    2. Min-Max refinement (greedily reducing max load).

    Args:
        weights: [num_groups] weights of items
        pack_indices: [num_packs, groups_per_pack] indices of items in each pack
        pack_weights: [num_packs] total weight of each pack

    Returns:
        pack_indices: Refined item assignments
    """
    # Phase 1: Variance Reduction (Global All-Pairs)
    # Allows swaps between any pair of packs to improve overall balance

    # Pre-computation for Phase 1
    N = num_packs * groups_per_pack
    pack_ids = torch.arange(num_packs, device=weights.device).repeat_interleave(groups_per_pack)
    mask = pack_ids.view(-1, 1) == pack_ids.view(1, -1)

    # Allocate iterations between phases
    variance_iters = max(5, max_iters // 2)
    min_max_iters = max_iters - variance_iters

    for _ in range(variance_iters):
        flat_indices = pack_indices.view(-1)
        w_flat = weights[flat_indices]
        l_flat = pack_weights[pack_ids]

        # D[i, j] = w[i] - w[j]
        # L_diff[i, j] = L[pack(j)] - L[pack(i)]
        D = w_flat.view(-1, 1) - w_flat.view(1, -1)
        L_diff = l_flat.view(1, -1) - l_flat.view(-1, 1)

        # Change in variance = 2 * D * (L_diff + D)
        change = D * (L_diff + D)
        change.masked_fill_(mask, float('inf'))

        min_val, min_idx = torch.min(change.view(-1), 0)

        if min_val > -1e-6:
            break

        idx_i = min_idx // N
        idx_j = min_idx % N

        p1 = (idx_i // groups_per_pack).item()
        g1 = (idx_i % groups_per_pack).item()
        p2 = (idx_j // groups_per_pack).item()
        g2 = (idx_j % groups_per_pack).item()

        # Execute swap
        item1 = pack_indices[p1, g1].item()
        item2 = pack_indices[p2, g2].item()

        pack_indices[p1, g1] = item2
        pack_indices[p2, g2] = item1

        # Update weights
        delta = D[idx_i, idx_j].item()
        pack_weights[p1] -= delta
        pack_weights[p2] += delta

    # Phase 2: Min-Max Reduction (Greedy on Max Load)
    # Strictly targets the bottleneck
    for _ in range(min_max_iters):
        max_load, max_pid = torch.max(pack_weights, dim=0)

        items_max = pack_indices[max_pid]
        w_max_items = weights[items_max]

        all_items = pack_indices
        w_all_items = weights[all_items]

        # deltas[k, j, i] = w_max[i] - w_k[j]
        deltas = w_max_items.view(1, 1, -1) - w_all_items.view(
            num_packs, groups_per_pack, 1)

        new_max_load = max_load - deltas
        new_k_load = pack_weights.view(num_packs, 1, 1) + deltas

        objectives = torch.max(new_max_load, new_k_load)
        objectives[max_pid] = float('inf')

        min_obj, flat_idx = torch.min(objectives.flatten(), dim=0)

        if min_obj >= max_load - 1e-6:
            break

        best_pid = flat_idx // (groups_per_pack * groups_per_pack)
        rem = flat_idx % (groups_per_pack * groups_per_pack)
        best_k_item_idx = rem // groups_per_pack
        best_max_item_idx = rem % groups_per_pack

        item_from_max = items_max[best_max_item_idx].item()
        item_from_k = all_items[best_pid, best_k_item_idx].item()

        pack_indices[max_pid, best_max_item_idx] = item_from_k
        pack_indices[best_pid, best_k_item_idx] = item_from_max

        delta_val = deltas[best_pid, best_k_item_idx, best_max_item_idx]
        pack_weights[max_pid] -= delta_val
        pack_weights[best_pid] += delta_val

    return pack_indices
>>>>>>> REPLACE
</DIFF>