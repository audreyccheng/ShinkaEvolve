<NAME>
triplet_hybrid_and_2opt
</NAME>

<DESCRIPTION>
I enhance the T-based packing by strengthening the lower bound with a lightweight triplet bound, expanding the pair and k-prefix bounds, and introducing a hybrid placement policy that balances projected max KVPR, local KVPR, and memory imbalance. This directly targets minimizing the maximum KVPR. I also add a limited 2-opt swap phase between the two worst GPUs in the local improvement step to further reduce the global maximum KVPR. These changes maintain simplicity while improving solution quality with minimal runtime overhead.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def improve_local(plc, max_iters=4000, eps=1e-12):
        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]

        def kvpr_g(g, msum=None, nsum=None):
            msum = mem[g] if msum is None else msum
            nsum = num[g] if nsum is None else nsum
            return kvpr(nsum, GPU_MEM_SIZE - msum)

        def global_max_vals():
            vals = [kvpr_g(g) for g in range(gpu_num)]
            return max(vals), vals

        it = 0
        while it < max_iters:
            it += 1
            cur_max, cur_vals = global_max_vals()
            worst = max(range(gpu_num), key=lambda g: cur_vals[g])
            improved = False
            best_move = None
            best_new_max = cur_max

            worst_models = list(per_g[worst])

            # Try single-item moves out of worst GPU
            for mdl in worst_models:
                ms = float(getattr(mdl, "model_size"))
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    # New max among unchanged GPUs
                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt:
                            if cur_vals[g] > new_max:
                                new_max = cur_vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_move = ("move", mdl, worst, tgt, ms, dn)
                        improved = True

            if improved:
                # Apply best single move
                _, mdl, src, tgt, ms, dn = best_move
                per_g[src].remove(mdl)
                per_g[tgt].append(mdl)
                mem[src] -= ms
                num[src] -= dn
                mem[tgt] += ms
                num[tgt] += dn
                continue  # iterate again

            # Try swaps between worst GPU and others (first improving swap)
            found_swap = False
            for mdl_a in worst_models:
                ms_a = float(getattr(mdl_a, "model_size"))
                dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    for mdl_b in list(per_g[tgt]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[tgt] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        src_mem = mem[worst] - ms_a + ms_b
                        src_num = num[worst] - dn_a + dn_b
                        tgt_mem = mem[tgt] - ms_b + ms_a
                        tgt_num = num[tgt] - dn_b + dn_a

                        src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                        tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                        new_max = max(src_k, tgt_k)
                        for g in range(gpu_num):
                            if g != worst and g != tgt:
                                if cur_vals[g] > new_max:
                                    new_max = cur_vals[g]

                        if new_max + eps < cur_max:
                            # Apply first improving swap
                            per_g[worst].remove(mdl_a)
                            per_g[tgt].remove(mdl_b)
                            per_g[worst].append(mdl_b)
                            per_g[tgt].append(mdl_a)
                            mem[worst] = src_mem
                            num[worst] = src_num
                            mem[tgt] = tgt_mem
                            num[tgt] = tgt_num
                            found_swap = True
                            break
                    if found_swap:
                        break
                if found_swap:
                    break

            if found_swap:
                continue

            # No improving move or swap found; stop
            break

        return {g: per_g.get(g, []) for g in range(gpu_num)}
=======
    def improve_local(plc, max_iters=4000, eps=1e-12):
        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]

        def kvpr_g(g, msum=None, nsum=None):
            msum = mem[g] if msum is None else msum
            nsum = num[g] if nsum is None else nsum
            return kvpr(nsum, GPU_MEM_SIZE - msum)

        def global_max_vals():
            vals = [kvpr_g(g) for g in range(gpu_num)]
            return max(vals), vals

        it = 0
        while it < max_iters:
            it += 1
            cur_max, cur_vals = global_max_vals()
            worst = max(range(gpu_num), key=lambda g: cur_vals[g])
            improved = False
            best_move = None
            best_new_max = cur_max

            worst_models = list(per_g[worst])

            # Try single-item moves out of worst GPU
            for mdl in worst_models:
                ms = float(getattr(mdl, "model_size"))
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    # New max among unchanged GPUs
                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt:
                            if cur_vals[g] > new_max:
                                new_max = cur_vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_move = ("move", mdl, worst, tgt, ms, dn)
                        improved = True

            if improved:
                # Apply best single move
                _, mdl, src, tgt, ms, dn = best_move
                per_g[src].remove(mdl)
                per_g[tgt].append(mdl)
                mem[src] -= ms
                num[src] -= dn
                mem[tgt] += ms
                num[tgt] += dn
                continue  # iterate again

            # Try swaps between worst GPU and others (first improving swap)
            found_swap = False
            for mdl_a in worst_models:
                ms_a = float(getattr(mdl_a, "model_size"))
                dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    for mdl_b in list(per_g[tgt]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[tgt] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        src_mem = mem[worst] - ms_a + ms_b
                        src_num = num[worst] - dn_a + dn_b
                        tgt_mem = mem[tgt] - ms_b + ms_a
                        tgt_num = num[tgt] - dn_b + dn_a

                        src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                        tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                        new_max = max(src_k, tgt_k)
                        for g in range(gpu_num):
                            if g != worst and g != tgt:
                                if cur_vals[g] > new_max:
                                    new_max = cur_vals[g]

                        if new_max + eps < cur_max:
                            # Apply first improving swap
                            per_g[worst].remove(mdl_a)
                            per_g[tgt].remove(mdl_b)
                            per_g[worst].append(mdl_b)
                            per_g[tgt].append(mdl_a)
                            mem[worst] = src_mem
                            num[worst] = src_num
                            mem[tgt] = tgt_mem
                            num[tgt] = tgt_num
                            found_swap = True
                            break
                    if found_swap:
                        break
                if found_swap:
                    break

            if found_swap:
                continue

            # No improving move or swap found; stop
            break

        # Targeted 2-opt swaps between the two worst GPUs (bounded)
        if gpu_num >= 2:
            for _ in range(12):
                cur_max, vals = global_max_vals()
                worst = max(range(gpu_num), key=lambda g: vals[g])
                # Identify second-worst
                second = None
                best_val = -float('inf')
                for g in range(gpu_num):
                    if g == worst:
                        continue
                    if vals[g] > best_val:
                        best_val = vals[g]
                        second = g
                if second is None:
                    break

                improved = False
                best_new_max = cur_max
                best_swap = None

                for mdl_a in list(per_g[worst]):
                    ms_a = float(getattr(mdl_a, "model_size"))
                    dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                    for mdl_b in list(per_g[second]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[second] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        w_mem = mem[worst] - ms_a + ms_b
                        w_num = num[worst] - dn_a + dn_b
                        s_mem = mem[second] - ms_b + ms_a
                        s_num = num[second] - dn_b + dn_a

                        w_k = kvpr(w_num, GPU_MEM_SIZE - w_mem)
                        s_k = kvpr(s_num, GPU_MEM_SIZE - s_mem)

                        new_max = max(w_k, s_k)
                        # other GPUs unchanged
                        for g in range(gpu_num):
                            if g != worst and g != second:
                                if kvpr_g(g) > new_max:
                                    new_max = kvpr_g(g)

                        if new_max + eps < best_new_max:
                            best_new_max = new_max
                            best_swap = (mdl_a, mdl_b, w_mem, w_num, s_mem, s_num)
                            improved = True

                if not improved:
                    break

                mdl_a, mdl_b, w_mem, w_num, s_mem, s_num = best_swap
                per_g[worst].remove(mdl_a)
                per_g[second].remove(mdl_b)
                per_g[worst].append(mdl_b)
                per_g[second].append(mdl_a)
                mem[worst] = w_mem
                num[worst] = w_num
                mem[second] = s_mem
                num[second] = s_num

        return {g: per_g.get(g, []) for g in range(gpu_num)}
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def parametric_pack_candidates():
        # Lower bounds on T
        indiv_lb = max(safe_div(n, max(GPU_MEM_SIZE - ms, 1e-9)) for _, ms, n in items)
        global_lb = safe_div(total_n, max(total_capacity - total_mem, 1e-9))

        # Pair bound for heavy pairs that cannot co-reside
        pair_lb = 0.0
        if gpu_num >= 2 and len(items) >= 2:
            L = min(len(items), 80)
            heavy = sorted(items, key=lambda it: it[1], reverse=True)[:L]
            for i in range(len(heavy)):
                _, mi, ni = heavy[i]
                for j in range(i + 1, len(heavy)):
                    _, mj, nj = heavy[j]
                    if mi + mj > GPU_MEM_SIZE + 1e-12:
                        denom = 2.0 * GPU_MEM_SIZE - (mi + mj)
                        pair_lb = max(pair_lb, safe_div(ni + nj, max(denom, 1e-9)))

        # k-prefix bound (small k)
        kprefix_lb = 0.0
        if items:
            by_m = sorted(items, key=lambda it: it[1], reverse=True)
            max_k = min(gpu_num, 4)
            for k in range(1, max_k + 1):
                s_m = 0.0
                s_n = 0.0
                for (_, ms, n) in by_m:
                    s_m += ms
                    s_n += n
                    if s_m > (k - 1) * GPU_MEM_SIZE + 1e-12:
                        break
                denom = k * GPU_MEM_SIZE - s_m
                kprefix_lb = max(kprefix_lb, safe_div(s_n, max(denom, 1e-9)))

        low_T = max(0.0, indiv_lb, global_lb, pair_lb, kprefix_lb)

        def try_pack(T, ordering=0, policy="resid", return_placement=False):
            cap = GPU_MEM_SIZE * T
            eps = 1e-12
            if ordering == 0:
                ordered = sorted(items, key=lambda it: (it[2] + T * it[1], it[2], it[1]), reverse=True)
            else:
                ordered = sorted(items, key=lambda it: (safe_div(it[2], max(GPU_MEM_SIZE - it[1], 1e-9)), it[1]), reverse=True)

            m_sum = [0.0] * gpu_num
            n_sum = [0.0] * gpu_num
            used_cap = [0.0] * gpu_num
            plc = [[] for _ in range(gpu_num)]

            for mdl, ms, n in ordered:
                w = n + T * ms
                best_g = None
                best_key = None

                # Current KVPRs for "minmax" policy
                cur_kvprs = [kvpr(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)] if policy != "resid" else None

                for g in range(gpu_num):
                    if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                        continue
                    resid = cap - (used_cap[g] + w)
                    if resid < -eps:
                        continue

                    if policy == "resid":
                        key = (resid, g)
                    else:
                        new_local = kvpr(n_sum[g] + n, GPU_MEM_SIZE - (m_sum[g] + ms))
                        # new global max KVPR if placed on g
                        new_max = new_local
                        for k in range(gpu_num):
                            if k != g and cur_kvprs[k] > new_max:
                                new_max = cur_kvprs[k]
                        key = (new_max, new_local, resid, g)

                    if best_key is None or key < best_key:
                        best_key = key
                        best_g = g

                if best_g is None:
                    return (False, None) if return_placement else False

                plc[best_g].append(mdl)
                m_sum[best_g] += ms
                n_sum[best_g] += n
                used_cap[best_g] += w

            if return_placement:
                return True, {g: plc[g] for g in range(gpu_num)}
            return True

        def try_any(T, need_plc=False):
            variants = [(0, "resid"), (1, "resid"), (0, "minmax"), (1, "minmax")]
            if need_plc:
                feas = []
                for ov, pol in variants:
                    ok, p = try_pack(T, ov, pol, True)
                    if ok:
                        feas.append(p)
                return (len(feas) > 0), feas
            else:
                for ov, pol in variants:
                    if try_pack(T, ov, pol, False):
                        return True
                return False

        # Exponential search for an initial feasible T
        T = max(low_T, 1e-9)
        found = False
        for _ in range(50):
            if try_any(T, need_plc=False):
                found = True
                break
            T *= 2.0
        if not found:
            return []

        # Binary search to tighten T
        low, high = low_T, T
        for _ in range(40):
            mid = (low + high) / 2.0
            if try_any(mid, need_plc=False):
                high = mid
            else:
                low = mid

        # Build placements at near-optimal T and small neighborhood
        Ts = [high * 0.985, high * 0.99, high, high * 1.005, high * 1.01, (low + high) / 2.0]
        all_plcs = []
        for Tv in Ts:
            ok, feas_plcs = try_any(Tv, need_plc=True)
            if ok:
                all_plcs.extend(feas_plcs)
        if not all_plcs:
            return []
        return all_plcs
=======
    def parametric_pack_candidates():
        # Lower bounds on T
        indiv_lb = max(safe_div(n, max(GPU_MEM_SIZE - ms, 1e-9)) for _, ms, n in items)
        global_lb = safe_div(total_n, max(total_capacity - total_mem, 1e-9))

        # Pair bound for heavy pairs that cannot co-reside
        pair_lb = 0.0
        if gpu_num >= 2 and len(items) >= 2:
            L = min(len(items), 120)
            heavy = sorted(items, key=lambda it: it[1], reverse=True)[:L]
            for i in range(len(heavy)):
                _, mi, ni = heavy[i]
                for j in range(i + 1, len(heavy)):
                    _, mj, nj = heavy[j]
                    if mi + mj > GPU_MEM_SIZE + 1e-12:
                        denom = 2.0 * GPU_MEM_SIZE - (mi + mj)
                        pair_lb = max(pair_lb, safe_div(ni + nj, max(denom, 1e-9)))

        # Triplet bound (lightweight)
        triplet_lb = 0.0
        if gpu_num >= 3 and len(items) >= 3:
            Ltr = min(len(items), 60)
            top_by_mem = sorted(items, key=lambda it: it[1], reverse=True)[:Ltr]
            for i in range(Ltr):
                mi, ni = top_by_mem[i][1], top_by_mem[i][2]
                for j in range(i + 1, min(Ltr, i + 1 + 8)):
                    mj, nj = top_by_mem[j][1], top_by_mem[j][2]
                    for k in range(j + 1, min(Ltr, j + 1 + 8)):
                        mk, nk = top_by_mem[k][1], top_by_mem[k][2]
                        total_m = mi + mj + mk
                        if total_m > 2.0 * GPU_MEM_SIZE + 1e-12:
                            denom = 3.0 * GPU_MEM_SIZE - total_m
                            triplet_lb = max(triplet_lb, safe_div(ni + nj + nk, max(denom, 1e-9)))

        # k-prefix bound (small k)
        kprefix_lb = 0.0
        if items:
            by_m = sorted(items, key=lambda it: it[1], reverse=True)
            max_k = min(gpu_num, 6)
            for k in range(1, max_k + 1):
                s_m = 0.0
                s_n = 0.0
                for (_, ms, n) in by_m:
                    s_m += ms
                    s_n += n
                    if s_m > (k - 1) * GPU_MEM_SIZE + 1e-12:
                        break
                denom = k * GPU_MEM_SIZE - s_m
                kprefix_lb = max(kprefix_lb, safe_div(s_n, max(denom, 1e-9)))

        low_T = max(0.0, indiv_lb, global_lb, pair_lb, triplet_lb, kprefix_lb)

        def try_pack(T, ordering=0, policy="resid", return_placement=False):
            cap = GPU_MEM_SIZE * T
            eps = 1e-12
            if ordering == 0:
                ordered = sorted(items, key=lambda it: (it[2] + T * it[1], it[2], it[1]), reverse=True)
            elif ordering == 1:
                ordered = sorted(items, key=lambda it: (safe_div(it[2], max(GPU_MEM_SIZE - it[1], 1e-9)), it[1]), reverse=True)
            else:
                # pressure per GB
                ordered = sorted(items, key=lambda it: (safe_div(it[2], max(it[1], 1e-12)), it[2]), reverse=True)

            m_sum = [0.0] * gpu_num
            n_sum = [0.0] * gpu_num
            used_cap = [0.0] * gpu_num
            plc = [[] for _ in range(gpu_num)]

            for mdl, ms, n in ordered:
                w = n + T * ms
                best_g = None
                best_key = None

                # Current KVPRs for "minmax"/"hybrid" policy
                cur_kvprs = [kvpr(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)] if policy != "resid" else None
                # Average memory fraction after placing this model (independent of target GPU)
                avg_mem_frac = (sum(m_sum) + ms) / (gpu_num * GPU_MEM_SIZE) if gpu_num > 0 else 0.0
                Tnorm = max(T, 1e-12)
                alpha = 0.15
                beta = 0.05

                for g in range(gpu_num):
                    if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                        continue
                    resid = cap - (used_cap[g] + w)
                    if resid < -eps:
                        continue

                    if policy == "resid":
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    else:
                        new_local = kvpr(n_sum[g] + n, GPU_MEM_SIZE - (m_sum[g] + ms))
                        # new global max KVPR if placed on g
                        new_max = new_local
                        for k in range(gpu_num):
                            if k != g and cur_kvprs[k] > new_max:
                                new_max = cur_kvprs[k]
                        if policy == "minmax":
                            key = (new_max, new_local, resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                        else:
                            # hybrid: balance projected global KVPR, local KVPR, and memory imbalance
                            mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                            mem_imb = abs(mem_frac_after - avg_mem_frac)
                            J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                            key = (J, new_max, new_local, resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)

                    if best_key is None or key < best_key:
                        best_key = key
                        best_g = g

                if best_g is None:
                    return (False, None) if return_placement else False

                plc[best_g].append(mdl)
                m_sum[best_g] += ms
                n_sum[best_g] += n
                used_cap[best_g] += w

            if return_placement:
                return True, {g: plc[g] for g in range(gpu_num)}
            return True

        def try_any(T, need_plc=False):
            variants = [
                (0, "resid"), (1, "resid"), (2, "resid"),
                (0, "minmax"), (1, "minmax"),
                (0, "hybrid"), (1, "hybrid")
            ]
            if need_plc:
                feas = []
                for ov, pol in variants:
                    ok, p = try_pack(T, ov, pol, True)
                    if ok:
                        feas.append(p)
                return (len(feas) > 0), feas
            else:
                for ov, pol in variants:
                    if try_pack(T, ov, pol, False):
                        return True
                return False

        # Exponential search for an initial feasible T
        T = max(low_T, 1e-9)
        found = False
        for _ in range(50):
            if try_any(T, need_plc=False):
                found = True
                break
            T *= 2.0
        if not found:
            return []

        # Binary search to tighten T
        low, high = low_T, T
        for _ in range(40):
            mid = (low + high) / 2.0
            if try_any(mid, need_plc=False):
                high = mid
            else:
                low = mid

        # Build placements at near-optimal T and small neighborhood
        Ts = [high * 0.985, high * 0.99, high, high * 1.005, high * 1.01, (low + high) / 2.0]
        all_plcs = []
        for Tv in Ts:
            ok, feas_plcs = try_any(Tv, need_plc=True)
            if ok:
                all_plcs.extend(feas_plcs)
        if not all_plcs:
            return []
        return all_plcs
>>>>>>> REPLACE

</DIFF>