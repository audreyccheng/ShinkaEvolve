<NAME>
two_phase_t_and_bounds_hybrid
</NAME>

<DESCRIPTION>
I introduce three targeted improvements to reduce the maximum KVPR while keeping the code simple and fast:

1) Tighten the lower bounds on T by adding a lightweight triplet bound and extending the k-prefix bound depth from 4 to 6. This improves the initial T and helps the search converge to better placements.

2) Add a two-phase, in-placement T update inside assign_balanced_slack. After packing the first 40% of remaining items, recompute a residual-global lower bound T’ using the remaining items and the sum of residual per-GPU capacities, bump the working T to T’ if needed, adjust per-GPU slack K accordingly, rebuild weights for the remaining items, and continue. This corrects discrete effects and better equalizes slack mid-pack.

3) Introduce a hybrid selection rule in assign_balanced_slack that balances KV slack tightening, per-GPU KVPR, and memory imbalance. Use this rule in both the initial feasibility sweep and the T-neighborhood evaluation. Also widen the T-neighborhood around the first feasible T slightly and add an extra hybrid variant to capture residual KVPR differences.

These changes are minimal and self-contained, adhere to the constraints, and should improve the combined score by lowering the true maximum KVPR without significantly increasing runtime.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def compute_lower_bound():
        # Per-item bound: T >= dR / (S - s)
        lb1 = 0.0
        infeasible_single = False
        for it in items:
            dR = it['dR']; s = it['size']
            denom = S - s
            if denom <= 0:
                if dR > 0:
                    infeasible_single = True
                continue
            if dR > 0 and dR != float('inf'):
                cand = dR / denom
                if cand > lb1:
                    lb1 = cand

        # Global bound: T >= total_R / (gpu_num*S - total_size)
        denom2 = gpu_num * S - total_size
        if denom2 <= 0 and total_R > 0:
            return float('inf'), True, infeasible_single
        lb2 = 0.0 if total_R <= 0 or denom2 <= 0 else (total_R / denom2)

        # Pair bound: for pairs that cannot co-reside (s_i + s_j > S)
        lb_pair = 0.0
        P = min(len(items), 200)
        by_size = sorted(items, key=lambda x: x['size'], reverse=True)[:P]
        for i in range(len(by_size)):
            si = by_size[i]['size']; ri = by_size[i]['dR']
            for j in range(i + 1, len(by_size)):
                sj = by_size[j]['size']; rj = by_size[j]['dR']
                if si + sj > S:
                    denom = 2 * S - (si + sj)
                    if denom > 0:
                        ri_f = 0.0 if ri == float('inf') else ri
                        rj_f = 0.0 if rj == float('inf') else rj
                        cand = (ri_f + rj_f) / denom
                        if cand > lb_pair:
                            lb_pair = cand

        # k-bin prefix bound for k in {1..min(gpu_num,4)}
        lb_k = 0.0
        sorted_by_size = sorted(items, key=lambda x: x['size'], reverse=True)
        prefix_sizes = []
        prefix_rates = []
        cs = 0.0; cr = 0.0
        for it in sorted_by_size:
            cs += it['size']; cr += (0.0 if it['dR'] == float('inf') else it['dR'])
            prefix_sizes.append(cs); prefix_rates.append(cr)
        for k in range(1, min(gpu_num, 4) + 1):
            threshold = (k - 1) * S
            idx = -1
            for t in range(len(prefix_sizes)):
                if prefix_sizes[t] > threshold:
                    idx = t
                    break
            if idx >= 0:
                numer = prefix_rates[idx]
                denom = k * S - prefix_sizes[idx]
                if denom > 0 and numer > 0:
                    cand = numer / denom
                    if cand > lb_k:
                        lb_k = cand

        lower = max(0.0, lb1, lb2, lb_pair, lb_k)
        return lower, False, infeasible_single
=======
    def compute_lower_bound():
        # Per-item bound: T >= dR / (S - s)
        lb1 = 0.0
        infeasible_single = False
        for it in items:
            dR = it['dR']; s = it['size']
            denom = S - s
            if denom <= 0:
                if (dR != float('inf') and dR > 0) or dR == float('inf'):
                    infeasible_single = True
                continue
            if dR > 0 and dR != float('inf'):
                cand = dR / denom
                if cand > lb1:
                    lb1 = cand

        # Global bound: T >= total_R / (gpu_num*S - total_size)
        denom2 = gpu_num * S - total_size
        if denom2 <= 0 and total_R > 0:
            return float('inf'), True, infeasible_single
        lb2 = 0.0 if total_R <= 0 or denom2 <= 0 else (total_R / denom2)

        # Pair bound: for pairs that cannot co-reside (s_i + s_j > S)
        lb_pair = 0.0
        P = min(len(items), 200)
        by_size = sorted(items, key=lambda x: x['size'], reverse=True)[:P]
        for i in range(len(by_size)):
            si = by_size[i]['size']; ri = by_size[i]['dR']
            for j in range(i + 1, len(by_size)):
                sj = by_size[j]['size']; rj = by_size[j]['dR']
                if si + sj > S:
                    denom = 2 * S - (si + sj)
                    if denom > 0:
                        ri_f = 0.0 if ri == float('inf') else ri
                        rj_f = 0.0 if rj == float('inf') else rj
                        cand = (ri_f + rj_f) / denom
                        if cand > lb_pair:
                            lb_pair = cand

        # Lightweight triplet bound: for triples with si + sj + sk > 2S
        lb_triplet = 0.0
        if len(by_size) >= 3:
            KTOP = min(8, len(by_size))
            topK = by_size[:KTOP]
            for i in range(len(by_size)):
                si = by_size[i]['size']; ri = by_size[i]['dR']
                for j in range(i + 1, len(by_size)):
                    sj = by_size[j]['size']; rj = by_size[j]['dR']
                    for k in range(min(KTOP, len(by_size))):
                        mk = topK[k]
                        if mk is by_size[i] or mk is by_size[j]:
                            continue
                        sk = mk['size']; rk = mk['dR']
                        ssum = si + sj + sk
                        if ssum > 2 * S:
                            denom = 3 * S - ssum
                            if denom > 0:
                                ri_f = 0.0 if ri == float('inf') else ri
                                rj_f = 0.0 if rj == float('inf') else rj
                                rk_f = 0.0 if rk == float('inf') else rk
                                cand = (ri_f + rj_f + rk_f) / denom
                                if cand > lb_triplet:
                                    lb_triplet = cand

        # k-bin prefix bound for k in {1..min(gpu_num,6)}
        lb_k = 0.0
        sorted_by_size = sorted(items, key=lambda x: x['size'], reverse=True)
        prefix_sizes = []
        prefix_rates = []
        cs = 0.0; cr = 0.0
        for it in sorted_by_size:
            cs += it['size']; cr += (0.0 if it['dR'] == float('inf') else it['dR'])
            prefix_sizes.append(cs); prefix_rates.append(cr)
        for k in range(1, min(gpu_num, 6) + 1):
            threshold = (k - 1) * S
            idx = -1
            for t in range(len(prefix_sizes)):
                if prefix_sizes[t] > threshold:
                    idx = t
                    break
            if idx >= 0:
                numer = prefix_rates[idx]
                denom = k * S - prefix_sizes[idx]
                if denom > 0 and numer > 0:
                    cand = numer / denom
                    if cand > lb_k:
                        lb_k = cand

        lower = max(0.0, lb1, lb2, lb_pair, lb_triplet, lb_k)
        return lower, False, infeasible_single
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def assign_balanced_slack(T, order='w_desc', seed_H=0, choose_rule='tight', seeds=1):
        if T < 0:
            return None
        # Build enriched list
        enriched = []
        for it in items:
            dR = it['dR']; sz = it['size']
            if dR == float('inf'):
                return None  # cannot handle infinite demand ratios under bounded T
            w = dR + T * sz
            if w < 0:
                w = 0.0
            enriched.append([w, dR, sz, it['obj']])

        # Orderings
        if order == 'w_desc':
            enriched.sort(key=lambda x: x[0], reverse=True)
        elif order == 'intrinsic_desc':
            # dR/(S - sz)
            enriched.sort(key=lambda x: (x[1] / max(S - x[2], 1e-9)), reverse=True)
        elif order == 'size_desc':
            enriched.sort(key=lambda x: x[2], reverse=True)
        elif order == 'density_desc':
            enriched.sort(key=lambda x: (x[1] / (x[2] if x[2] > 0 else 1e-9)), reverse=True)
        else:
            enriched.sort(key=lambda x: x[0], reverse=True)

        best_assign = None
        best_val = float('inf')

        for _ in range(max(1, seeds)):
            # per-GPU states
            assign = {i: [] for i in range(gpu_num)}
            used_mem = [0.0] * gpu_num
            sum_R = [0.0] * gpu_num
            K = [T * S] * gpu_num  # KV slack

            # Seeding: spread top H intrinsic-pressure models using worst-fit on K
            H = int(seed_H) if seed_H else 0
            if H > 0 and len(enriched) > 0:
                intrinsic = sorted(enriched, key=lambda x: (x[1] / max(S - x[2], 1e-9)), reverse=True)
                seeds_list = intrinsic[:min(H, len(enriched))]
                # Remove seeds from enriched while preserving original sequence among the rest
                seed_ids = set(id(x) for x in seeds_list)
                remaining = [x for x in enriched if id(x) not in seed_ids]
                for w, dR, sz, m in seeds_list:
                    # Choose GPU with largest K that can fit both memory and slack
                    candidates = []
                    for gid in range(gpu_num):
                        if used_mem[gid] + sz <= S + 1e-9 and K[gid] >= w - 1e-9:
                            candidates.append(gid)
                    if not candidates:
                        assign = None
                        break
                    # Worst-fit on K; tie-break by larger memory slack, then lower resulting local kvpr
                    def key_fn(g):
                        rem = S - (used_mem[g] + sz)
                        kvnew = kvpr(sum_R[g] + dR, rem) if rem > 0 else float('inf')
                        return (-K[g], -(rem), kvnew)
                    candidates.sort(key=lambda g: key_fn(g))
                    chosen = candidates[0]
                    if rng.random() < 0.2 and len(candidates) > 1:
                        chosen = candidates[rng.randrange(min(2, len(candidates)))]
                    assign[chosen].append(m)
                    used_mem[chosen] += sz
                    sum_R[chosen] += dR
                    K[chosen] -= w
                if assign is None:
                    continue
                enriched = remaining

            # Main packing: equalize K by choosing GPU that leaves minimal nonnegative K'
            for w, dR, sz, m in enriched:
                options = []
                for gid in range(gpu_num):
                    if used_mem[gid] + sz <= S + 1e-9 and K[gid] >= w - 1e-9:
                        K_after = K[gid] - w
                        if choose_rule == 'min_kvpr':
                            rem = S - (used_mem[gid] + sz)
                            if rem <= 0:
                                continue
                            kv_new = kvpr(sum_R[gid] + dR, rem)
                            options.append((gid, K_after, kv_new))
                        else:
                            options.append((gid, K_after, None))
                if not options:
                    assign = None
                    break
                # Selection: prefer minimal K_after (tightest feasible), tie-break by min kvpr or larger mem slack
                if choose_rule == 'min_kvpr':
                    options.sort(key=lambda t: (t[1], t[2]))
                else:
                    options.sort(key=lambda t: t[1])
                chosen = options[0][0]
                # Tiny randomization among top-2 close in K_after
                if len(options) > 1:
                    bestK = options[0][1]
                    near = [op for op in options if abs(op[1] - bestK) <= max(1e-9, 0.001 * (T * S + 1e-9))]
                    if len(near) >= 2 and rng.random() < 0.25:
                        chosen = near[rng.randrange(min(2, len(near)))][0]

                assign[chosen].append(m)
                used_mem[chosen] += sz
                sum_R[chosen] += dR
                K[chosen] -= w

            if assign is None:
                continue

            # Validate constraints strictly
            ok = True
            for gid in range(gpu_num):
                if used_mem[gid] - S > 1e-6:
                    ok = False; break
                rem = S - used_mem[gid]
                if rem <= 0 and sum_R[gid] > 0:
                    ok = False; break
                if T > 0 and (sum_R[gid] / max(rem, 1e-12)) - T > 1e-6:
                    ok = False; break
            if not ok:
                continue

            # Keep best by measured max KVPR
            val = 0.0
            for gid in range(gpu_num):
                rem = S - used_mem[gid]
                val = max(val, kvpr(sum_R[gid], rem))
            if val < best_val:
                best_val = val
                best_assign = assign

        return best_assign
=======
    def assign_balanced_slack(T, order='w_desc', seed_H=0, choose_rule='tight', seeds=1):
        if T < 0:
            return None
        # Build enriched list
        enriched = []
        for it in items:
            dR = it['dR']; sz = it['size']
            if dR == float('inf'):
                return None  # cannot handle infinite demand ratios under bounded T
            w = dR + T * sz
            if w < 0:
                w = 0.0
            enriched.append([w, dR, sz, it['obj']])

        # Orderings
        def sort_enriched(arr, Tcur):
            if order == 'w_desc':
                arr.sort(key=lambda x: x[0], reverse=True)
            elif order == 'intrinsic_desc':
                arr.sort(key=lambda x: (x[1] / max(S - x[2], 1e-9)), reverse=True)
            elif order == 'size_desc':
                arr.sort(key=lambda x: x[2], reverse=True)
            elif order == 'density_desc':
                arr.sort(key=lambda x: (x[1] / (x[2] if x[2] > 0 else 1e-9)), reverse=True)
            else:
                arr.sort(key=lambda x: x[0], reverse=True)

        sort_enriched(enriched, T)

        best_assign = None
        best_val = float('inf')

        for _ in range(max(1, seeds)):
            # per-GPU states
            assign = {i: [] for i in range(gpu_num)}
            used_mem = [0.0] * gpu_num
            sum_R = [0.0] * gpu_num
            T_current = T
            K = [T_current * S] * gpu_num  # KV slack

            # Seeding: spread top H intrinsic-pressure models using worst-fit on K
            H = int(seed_H) if seed_H else 0
            if H > 0 and len(enriched) > 0:
                intrinsic = sorted(enriched, key=lambda x: (x[1] / max(S - x[2], 1e-9)), reverse=True)
                seeds_list = intrinsic[:min(H, len(enriched))]
                # Remove seeds from enriched while preserving original sequence among the rest
                seed_ids = set(id(x) for x in seeds_list)
                remaining = [x for x in enriched if id(x) not in seed_ids]
                for w, dR, sz, m in seeds_list:
                    # Choose GPU with largest K that can fit both memory and slack
                    candidates = []
                    for gid in range(gpu_num):
                        if used_mem[gid] + sz <= S + 1e-9 and K[gid] >= w - 1e-9:
                            candidates.append(gid)
                    if not candidates:
                        assign = None
                        break
                    # Worst-fit on K; tie-break by larger memory slack, then lower resulting local kvpr
                    def key_fn(g):
                        rem = S - (used_mem[g] + sz)
                        kvnew = kvpr(sum_R[g] + dR, rem) if rem > 0 else float('inf')
                        return (-K[g], -(rem), kvnew)
                    candidates.sort(key=lambda g: key_fn(g))
                    chosen = candidates[0]
                    if rng.random() < 0.2 and len(candidates) > 1:
                        chosen = candidates[rng.randrange(min(2, len(candidates)))]
                    assign[chosen].append(m)
                    used_mem[chosen] += sz
                    sum_R[chosen] += dR
                    K[chosen] -= w
                if assign is None:
                    continue
                enriched = remaining

            # Helper to place a sequence of items with a given T_current
            def place_sequence(seq_items):
                nonlocal assign, used_mem, sum_R, K, T_current
                for w, dR, sz, m in seq_items:
                    options = []
                    for gid in range(gpu_num):
                        if used_mem[gid] + sz <= S + 1e-9 and K[gid] >= w - 1e-9:
                            K_after = K[gid] - w
                            if choose_rule in ('min_kvpr', 'hybrid'):
                                rem = S - (used_mem[gid] + sz)
                                if rem <= 0:
                                    continue
                                kv_new = kvpr(sum_R[gid] + dR, rem)
                                if choose_rule == 'hybrid':
                                    cap = T_current * S
                                    K_after_norm = max(0.0, K_after) / max(cap, 1e-12)
                                    avg_mem_frac = (sum(used_mem) + sz) / (gpu_num * S) if S > 0 else 0.0
                                    mem_after_frac = (used_mem[gid] + sz) / S if S > 0 else 0.0
                                    mem_imbalance = abs(mem_after_frac - avg_mem_frac)
                                    alpha = 0.15
                                    beta = 0.05
                                    kv_new_norm = kv_new / max(T_current, 1e-12) if T_current > 0 else kv_new
                                    hybrid = K_after_norm + alpha * kv_new_norm + beta * mem_imbalance
                                    options.append((gid, K_after, kv_new, hybrid))
                                else:
                                    options.append((gid, K_after, kv_new, None))
                            else:
                                options.append((gid, K_after, None, None))
                    if not options:
                        return False
                    # Selection
                    if choose_rule == 'min_kvpr':
                        options.sort(key=lambda t: (t[1], t[2]))
                    elif choose_rule == 'hybrid':
                        options.sort(key=lambda t: (t[1], t[3], t[2]))
                    else:
                        options.sort(key=lambda t: t[1])
                    chosen = options[0][0]
                    # Tiny randomization among top-2 close in K_after
                    if len(options) > 1:
                        bestK = options[0][1]
                        near = [op for op in options if abs(op[1] - bestK) <= max(1e-9, 0.001 * (T_current * S + 1e-9))]
                        if len(near) >= 2 and rng.random() < 0.25:
                            chosen = near[rng.randrange(min(2, len(near)))][0]
                    # Commit
                    assign[chosen].append(m)
                    used_mem[chosen] += sz
                    sum_R[chosen] += dR
                    K[chosen] -= w
                return True

            # Two-phase placement with mid-pack T update
            seq_all = list(enriched)
            cut = int(0.4 * len(seq_all))
            ok = True
            if cut > 0:
                ok = place_sequence(seq_all[:cut])
                if not ok:
                    assign = None
                else:
                    # Recompute residual global lower bound using remaining items and residual capacities
                    rem_items = seq_all[cut:]
                    if rem_items:
                        rem_total_R = sum(x[1] for x in rem_items)
                        rem_total_size = sum(x[2] for x in rem_items)
                        free_sum = sum(S - used_mem[g] for g in range(gpu_num))
                        denom = free_sum - rem_total_size
                        if denom > 0 and rem_total_R > 0:
                            T2 = rem_total_R / denom
                            if T2 > T_current:
                                delta = T2 - T_current
                                for g in range(gpu_num):
                                    K[g] += delta * (S - used_mem[g])
                                T_current = T2
                        # Rebuild weights and resort remaining according to the (possibly) updated T
                        rem_enriched = []
                        for _, dR, sz, m in rem_items:
                            w2 = dR + T_current * sz
                            rem_enriched.append([w2, dR, sz, m])
                        sort_enriched(rem_enriched, T_current)
                        ok = place_sequence(rem_enriched)
                        if not ok:
                            assign = None
            else:
                # No cut; place all in one go
                ok = place_sequence(seq_all)
                if not ok:
                    assign = None

            if assign is None:
                continue

            # Validate constraints strictly
            ok = True
            for gid in range(gpu_num):
                if used_mem[gid] - S > 1e-6:
                    ok = False; break
                rem = S - used_mem[gid]
                if rem <= 0 and sum_R[gid] > 0:
                    ok = False; break
                if T_current > 0 and (sum_R[gid] / max(rem, 1e-12)) - T_current > 1e-6:
                    ok = False; break
            if not ok:
                continue

            # Keep best by measured max KVPR
            val = 0.0
            for gid in range(gpu_num):
                rem = S - used_mem[gid]
                val = max(val, kvpr(sum_R[gid], rem))
            if val < best_val:
                best_val = val
                best_assign = assign

        return best_assign
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def find_first_feasible_T(start_T):
        T = max(0.0, start_T)
        growth = 1.08
        max_steps = 40
        for _ in range(max_steps):
            for (order, choose_rule, seedH, seeds) in [
                ('w_desc', 'tight', min(4, max(1, gpu_num)), 1),
                ('intrinsic_desc', 'tight', min(3, max(1, gpu_num - 1)), 1),
                ('w_desc', 'min_kvpr', 0, 1),
            ]:
                cand = assign_balanced_slack(T, order=order, seed_H=seedH, choose_rule=choose_rule, seeds=1)
                if cand is not None:
                    return T, cand
            T = T * growth if T > 0 else 1e-6
        return None, None
=======
    def find_first_feasible_T(start_T):
        T = max(0.0, start_T)
        growth = 1.08
        max_steps = 40
        for _ in range(max_steps):
            for (order, choose_rule, seedH, seeds) in [
                ('w_desc', 'tight', min(4, max(1, gpu_num)), 1),
                ('intrinsic_desc', 'tight', min(3, max(1, gpu_num - 1)), 1),
                ('w_desc', 'hybrid', min(3, max(1, gpu_num - 1)), 1),
                ('w_desc', 'min_kvpr', 0, 1),
            ]:
                cand = assign_balanced_slack(T, order=order, seed_H=seedH, choose_rule=choose_rule, seeds=1)
                if cand is not None:
                    return T, cand
            T = T * growth if T > 0 else 1e-6
        return None, None
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    candidates_T = []
    for mul in [0.99, 1.0, 1.005, 1.02]:
        val = max(lower, T_feas * mul)
        candidates_T.append(val)
    candidates_T.append(0.5 * (lower + T_feas))
    candidates_T = sorted(set(round(t, 12) for t in candidates_T))
=======
    candidates_T = []
    for mul in [0.985, 0.99, 1.0, 1.005, 1.01, 1.015, 1.02]:
        val = max(lower, T_feas * mul)
        candidates_T.append(val)
    # Include midpoint between lower and T_feas
    candidates_T.append(0.5 * (lower + T_feas))
    candidates_T = sorted(set(round(t, 12) for t in candidates_T))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    variants = [
        ('w_desc', 'tight', min(4, max(1, gpu_num)), 2),
        ('intrinsic_desc', 'tight', min(3, max(1, gpu_num - 1))),
        ('density_desc', 'tight', 0),
        ('w_desc', 'min_kvpr', 0),
        ('size_desc', 'tight', 0),
    ]
=======
    variants = [
        ('w_desc', 'tight', min(4, max(1, gpu_num)), 2),
        ('intrinsic_desc', 'tight', min(3, max(1, gpu_num - 1))),
        ('w_desc', 'hybrid', min(3, max(1, gpu_num - 1)), 2),
        ('density_desc', 'hybrid', 0),
        ('density_desc', 'tight', 0),
        ('w_desc', 'min_kvpr', 0),
        ('size_desc', 'tight', 0),
    ]
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def feasible_assign_for_T(T):
        best = None
        bestv = float('inf')
        for (order, choose_rule, seedH) in [
            ('w_desc', 'tight', min(4, max(1, gpu_num))),
            ('intrinsic_desc', 'tight', min(3, max(1, gpu_num - 1))),
            ('w_desc', 'min_kvpr', 0),
            ('density_desc', 'tight', 0),
        ]:
            cand = assign_balanced_slack(T, order=order, seed_H=seedH, choose_rule=choose_rule, seeds=1)
            if cand is not None:
                val = eval_max_kvpr(cand)
                if val < bestv:
                    bestv = val
                    best = cand
        return best
=======
    def feasible_assign_for_T(T):
        best = None
        bestv = float('inf')
        for (order, choose_rule, seedH) in [
            ('w_desc', 'tight', min(4, max(1, gpu_num))),
            ('intrinsic_desc', 'tight', min(3, max(1, gpu_num - 1))),
            ('w_desc', 'hybrid', min(3, max(1, gpu_num - 1))),
            ('w_desc', 'min_kvpr', 0),
            ('density_desc', 'tight', 0),
        ]:
            cand = assign_balanced_slack(T, order=order, seed_H=seedH, choose_rule=choose_rule, seeds=1)
            if cand is not None:
                val = eval_max_kvpr(cand)
                if val < bestv:
                    bestv = val
                    best = cand
        return best
>>>>>>> REPLACE

</DIFF>