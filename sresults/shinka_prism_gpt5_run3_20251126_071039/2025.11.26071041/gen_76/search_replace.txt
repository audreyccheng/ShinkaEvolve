<NAME>
zero_n_memory_redistribution
</NAME>

<DESCRIPTION>
I add a targeted post-optimization step inside improve_local that redistributes memory-only (near-zero KV pressure) models from the most KVPR-congested GPU to others. Since these models contribute no numerator to KVPR (req_rate/slo ≈ 0) but consume memory (reducing the denominator), moving them can significantly reduce the maximum KVPR by freeing memory on the worst GPU without increasing others’ numerators. This greedy, bounded loop searches for the best improving move of a zero-pressure model at each iteration and applies it, repeating until no further improvement is possible or a small iteration cap is reached. This keeps the algorithm simple, respects memory constraints, and tends to reduce the global max KVPR with minimal runtime overhead.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # Targeted 2-opt swaps between the two worst GPUs (bounded)
        if gpu_num >= 2:
            for _ in range(12):
                cur_max, vals = global_max_vals()
                worst = max(range(gpu_num), key=lambda g: vals[g])
                # identify second-worst
                second = None
                best_val = -float('inf')
                for g in range(gpu_num):
                    if g == worst:
                        continue
                    if vals[g] > best_val:
                        best_val = vals[g]
                        second = g
                if second is None:
                    break

                improved = False
                best_new_max = cur_max
                best_swap = None

                for mdl_a in list(per_g[worst]):
                    ms_a = float(getattr(mdl_a, "model_size"))
                    dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                    for mdl_b in list(per_g[second]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[second] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        w_mem = mem[worst] - ms_a + ms_b
                        w_num = num[worst] - dn_a + dn_b
                        s_mem = mem[second] - ms_b + ms_a
                        s_num = num[second] - dn_b + dn_a

                        w_k = kvpr(w_num, GPU_MEM_SIZE - w_mem)
                        s_k = kvpr(s_num, GPU_MEM_SIZE - s_mem)

                        new_max = max(w_k, s_k)
                        # other GPUs unchanged
                        for g in range(gpu_num):
                            if g != worst and g != second:
                                if kvpr_g(g) > new_max:
                                    new_max = kvpr_g(g)

                        if new_max + eps < best_new_max:
                            best_new_max = new_max
                            best_swap = (mdl_a, mdl_b, w_mem, w_num, s_mem, s_num)
                            improved = True

                if not improved:
                    break

                mdl_a, mdl_b, w_mem, w_num, s_mem, s_num = best_swap
                per_g[worst].remove(mdl_a)
                per_g[second].remove(mdl_b)
                per_g[worst].append(mdl_b)
                per_g[second].append(mdl_a)
                mem[worst] = w_mem
                num[worst] = w_num
                mem[second] = s_mem
                num[second] = s_num

        return {g: per_g.get(g, []) for g in range(gpu_num)}
=======
        # Targeted 2-opt swaps between the two worst GPUs (bounded)
        if gpu_num >= 2:
            for _ in range(12):
                cur_max, vals = global_max_vals()
                worst = max(range(gpu_num), key=lambda g: vals[g])
                # identify second-worst
                second = None
                best_val = -float('inf')
                for g in range(gpu_num):
                    if g == worst:
                        continue
                    if vals[g] > best_val:
                        best_val = vals[g]
                        second = g
                if second is None:
                    break

                improved = False
                best_new_max = cur_max
                best_swap = None

                for mdl_a in list(per_g[worst]):
                    ms_a = float(getattr(mdl_a, "model_size"))
                    dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                    for mdl_b in list(per_g[second]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[second] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        w_mem = mem[worst] - ms_a + ms_b
                        w_num = num[worst] - dn_a + dn_b
                        s_mem = mem[second] - ms_b + ms_a
                        s_num = num[second] - dn_b + dn_a

                        w_k = kvpr(w_num, GPU_MEM_SIZE - w_mem)
                        s_k = kvpr(s_num, GPU_MEM_SIZE - s_mem)

                        new_max = max(w_k, s_k)
                        # other GPUs unchanged
                        for g in range(gpu_num):
                            if g != worst and g != second:
                                if kvpr_g(g) > new_max:
                                    new_max = kvpr_g(g)

                        if new_max + eps < best_new_max:
                            best_new_max = new_max
                            best_swap = (mdl_a, mdl_b, w_mem, w_num, s_mem, s_num)
                            improved = True

                if not improved:
                    break

                mdl_a, mdl_b, w_mem, w_num, s_mem, s_num = best_swap
                per_g[worst].remove(mdl_a)
                per_g[second].remove(mdl_b)
                per_g[worst].append(mdl_b)
                per_g[second].append(mdl_a)
                mem[worst] = w_mem
                num[worst] = w_num
                mem[second] = s_mem
                num[second] = s_num

        # Final pass: redistribute memory-only (n≈0) models to reduce max KVPR by freeing memory on worst GPU
        zero_eps = 1e-12
        for _ in range(400):
            cur_max, vals = global_max_vals()
            worst = max(range(gpu_num), key=lambda g: vals[g])
            # Collect zero-pressure candidates on worst GPU (sorted largest-first by memory)
            zcands = []
            for mdl in list(per_g[worst]):
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                if abs(dn) <= zero_eps:
                    zcands.append((mdl, float(getattr(mdl, "model_size"))))
            if not zcands:
                break
            zcands.sort(key=lambda t: t[1], reverse=True)

            best_move = None
            best_new_max = cur_max
            for mdl, ms in zcands:
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue
                    src_mem = mem[worst] - ms
                    src_num = num[worst]  # dn ≈ 0
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt]

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt:
                            v = kvpr_g(g)
                            if v > new_max:
                                new_max = v
                    if new_max + 1e-12 < best_new_max:
                        best_new_max = new_max
                        best_move = (mdl, worst, tgt, ms)
            if best_move is None:
                break
            mdl, src, tgt, ms = best_move
            per_g[src].remove(mdl)
            per_g[tgt].append(mdl)
            mem[src] -= ms
            mem[tgt] += ms
            # nums unchanged (n≈0), iterate again

        return {g: per_g.get(g, []) for g in range(gpu_num)}
>>>>>>> REPLACE

</DIFF>