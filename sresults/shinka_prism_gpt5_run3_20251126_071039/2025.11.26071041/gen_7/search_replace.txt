<NAME>
parametric_refinement_bsearch
</NAME>

<DESCRIPTION>
I add a parametric binary search refinement step after the greedy-and-improve phase. This step uses a transformed weight feasibility test (w = dR + T * size, capacity = T * GPU_MEM_SIZE) with Best-Fit Decreasing to check if a target maximum KVPR T is achievable while respecting memory constraints. We compute safe lower and upper bounds for T, perform a binary search, and adopt the refined placement if it reduces the maximum KVPR compared to the best heuristic solution. This keeps the implementation simple, robust, and improves min-max KVPR without changing the external interface or adding dependencies.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    if best_placement is None:
        # Fall back to an error consistent with greedy behavior
        # Try a final simple size-desc heuristic to produce a clearer error state
        ordered = sorted(models, key=lambda m: m.model_size, reverse=True)
        # This will raise ValueError if infeasible
        best_placement, _, _ = greedy_assign(ordered)

    return best_placement
=======
    if best_placement is None:
        # Fall back to an error consistent with greedy behavior
        # Try a final simple size-desc heuristic to produce a clearer error state
        ordered = sorted(models, key=lambda m: m.model_size, reverse=True)
        # This will raise ValueError if infeasible
        best_placement, _, _ = greedy_assign(ordered)

    # Parametric refinement: binary search on max KVPR target T with transformed weights
    def max_kvpr_of(placement_dict):
        max_v = 0.0
        for gid in range(gpu_num):
            bucket = placement_dict.get(gid, [])
            R = 0.0
            used = 0.0
            for m in bucket:
                R += (m.req_rate / m.slo)
                used += m.model_size
            v = kvpr(R, GPU_MEM_SIZE - used)
            if v > max_v:
                max_v = v
        return max_v

    def bfd_assign_for_T(T):
        # Best-Fit-Decreasing by transformed weights for target T
        eps = 1e-12
        capacity = T * GPU_MEM_SIZE
        if capacity < -eps:
            return None
        items = []
        for m in models:
            dR = m.req_rate / m.slo
            w = dR + T * m.model_size
            if w < 0:
                w = 0.0
            items.append((w, dR, m.model_size, m))
        items.sort(key=lambda x: x[0], reverse=True)

        used_w = [0.0 for _ in range(gpu_num)]
        bins_R = [0.0 for _ in range(gpu_num)]
        bins_used_mem = [0.0 for _ in range(gpu_num)]
        assign = {i: [] for i in range(gpu_num)}

        for w, dR, sz, m in items:
            best_bin = None
            best_after = float('inf')
            for gid in range(gpu_num):
                nw = used_w[gid] + w
                if nw <= capacity + 1e-9:  # tiny slack
                    if nw < best_after:
                        best_after = nw
                        best_bin = gid
            if best_bin is None:
                return None
            used_w[best_bin] += w
            bins_R[best_bin] += dR
            bins_used_mem[best_bin] += sz
            assign[best_bin].append(m)

        # Validate real constraints
        for gid in range(gpu_num):
            if bins_used_mem[gid] - GPU_MEM_SIZE > 1e-6:
                return None
            rem = GPU_MEM_SIZE - bins_used_mem[gid]
            if rem <= 0:
                return None
            if (bins_R[gid] / rem) - T > 1e-6:
                return None
        return assign

    # Compute bounds for binary search
    S = GPU_MEM_SIZE
    total_R = sum((m.req_rate / m.slo) for m in models)
    total_size = sum(m.model_size for m in models)

    # Lower bound 1: per-model bound
    lb1 = 0.0
    infeasible_single = False
    for m in models:
        dR = m.req_rate / m.slo
        denom = S - m.model_size
        if denom <= 0:
            if dR > 0:
                infeasible_single = True
            continue
        if dR > 0:
            cand = dR / denom
            if cand > lb1:
                lb1 = cand

    # Lower bound 2: global bound
    denom2 = gpu_num * S - total_size
    if denom2 <= 0 and total_R > 0:
        return best_placement
    lb2 = 0.0 if denom2 <= 0 else ((total_R / denom2) if total_R > 0 else 0.0)

    lower = lb1 if lb1 > lb2 else lb2
    if infeasible_single:
        return best_placement

    # Upper bound from current best placement
    hi = max_kvpr_of(best_placement)
    if not (hi < float('inf')):
        return best_placement

    lo = max(0.0, lower)
    if lo > hi:
        lo = hi

    best_bsearch_placement = best_placement
    best_bsearch_T = hi

    for _ in range(32):
        mid = (lo + hi) / 2.0
        cand_place = bfd_assign_for_T(mid)
        if cand_place is not None:
            hi = mid
            best_bsearch_placement = cand_place
            best_bsearch_T = mid
        else:
            lo = mid

    # Adopt if improved
    final_T = max_kvpr_of(best_bsearch_placement)
    if final_T + 1e-12 < best_max_kvpr:
        return best_bsearch_placement

    return best_placement
>>>>>>> REPLACE

</DIFF>