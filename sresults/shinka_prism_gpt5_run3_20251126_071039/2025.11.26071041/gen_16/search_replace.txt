<NAME>
tighter_bounds_and_local_refine
</NAME>

<DESCRIPTION>
I improve the placement by (1) tightening the lower bound on the KVPR threshold T with pair and k-bin prefix bounds, which reduces search space and stabilizes packing decisions, and (2) enriching candidate generation around the final T (with slight perturbations and both orderings) followed by a lightweight local search (bounded single-item moves and first-improving swaps) to reduce the maximum KVPR. These targeted changes keep the code simple, maintain feasibility, and typically lower the measured max KVPR with negligible runtime overhead.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # ---------- Lower bounds on KVPR (T) ----------
    # Per-item bound: T >= n_i / (80 - m_i)
    per_item_lb = max(safe_div(n, GPU_MEM_SIZE - ms) for _, _, ms, n in items)
    # Global bound: T >= sum(n_i) / (G*80 - sum(m_i))
    global_lb = safe_div(total_demand, total_capacity - total_mem)
    low_T = max(0.0, per_item_lb, global_lb)
=======
    # ---------- Lower bounds on KVPR (T) ----------
    # Per-item bound: T >= n_i / (80 - m_i)
    per_item_lb = max(safe_div(n, GPU_MEM_SIZE - ms) for _, _, ms, n in items)
    # Global bound: T >= sum(n_i) / (G*80 - sum(m_i))
    global_lb = safe_div(total_demand, max(total_capacity - total_mem, 1e-9))

    # Pair bound: for pairs that cannot co-reside (m_i + m_j > 80),
    # T >= (n_i + n_j) / (2*80 - (m_i + m_j))
    pair_lb = 0.0
    # Consider top P by memory to keep O(P^2) small
    P = min(len(items), 200)
    heavy = sorted(items, key=lambda it: it[2], reverse=True)[:P]
    for i in range(len(heavy)):
        _, _, mi, ni = heavy[i]
        for j in range(i + 1, len(heavy)):
            _, _, mj, nj = heavy[j]
            if mi + mj > GPU_MEM_SIZE + 1e-12:
                denom = 2 * GPU_MEM_SIZE - (mi + mj)
                pair_lb = max(pair_lb, safe_div(ni + nj, max(denom, 1e-9)))

    # k-bin prefix bound for k = 1..min(G,4)
    kprefix_lb = 0.0
    items_by_m = sorted(items, key=lambda it: it[2], reverse=True)
    for k in range(1, min(gpu_num, 4) + 1):
        sum_m = 0.0
        sum_n = 0.0
        for it in items_by_m:
            sum_m += it[2]
            sum_n += it[3]
            if sum_m > (k - 1) * GPU_MEM_SIZE + 1e-12:
                break
        denom = k * GPU_MEM_SIZE - sum_m
        kprefix_lb = max(kprefix_lb, safe_div(sum_n, max(denom, 1e-9)))

    low_T = max(0.0, per_item_lb, global_lb, pair_lb, kprefix_lb)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # ---------- Build and select best candidate at near-optimal T ----------
    ok, candidates = try_pack_any(high, need_placement=True)
    if not ok:
        # Fallback: use the last known feasible T (should not happen)
        ok, candidates = try_pack_any(T, need_placement=True)
        if not ok:
            raise ValueError("Feasible packing unexpectedly unavailable")

    # Score candidates by actual measured max KVPR
    def measured_max_kvpr(plc):
        vals = []
        for g in range(gpu_num):
            used_mem = sum(getattr(m, "model_size") for m in plc.get(g, []))
            numer = sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in plc.get(g, []))
            vals.append(safe_div(numer, GPU_MEM_SIZE - used_mem))
        return max(vals) if vals else 0.0

    best_plc = None
    best_score = float('inf')
    for plc in candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc

    # Ensure all GPUs exist in the mapping
    for g in range(gpu_num):
        best_plc.setdefault(g, [])

    return best_plc
=======
    # ---------- Build and select best candidate at near-optimal T ----------
    ok, candidates = try_pack_any(high, need_placement=True)
    if not ok:
        # Fallback: use the last known feasible T (should not happen)
        ok, candidates = try_pack_any(T, need_placement=True)
        if not ok:
            raise ValueError("Feasible packing unexpectedly unavailable")

    # Add a few extra candidates around near-optimal T to exploit discrete effects
    Ts = [high, high * 0.995, high * 1.005]
    for Tv in Ts:
        for ov in (0, 1):
            okv, plc = try_pack(Tv, ov, return_placement=True)
            if okv:
                candidates.append(plc)

    # Score candidates by actual measured max KVPR
    def measured_max_kvpr(plc):
        vals = []
        for g in range(gpu_num):
            used_mem = sum(getattr(m, "model_size") for m in plc.get(g, []))
            numer = sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in plc.get(g, []))
            vals.append(safe_div(numer, GPU_MEM_SIZE - used_mem))
        return max(vals) if vals else 0.0

    best_plc = None
    best_score = float('inf')
    for plc in candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc

    # ---------- Lightweight local improvement (moves + swaps) ----------
    def local_improve(plc, move_budget=20, swap_budget=10, eps=1e-12):
        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]

        def kvpr_g(g, msum=None, nsum=None):
            msum = mem[g] if msum is None else msum
            nsum = num[g] if nsum is None else nsum
            return safe_div(nsum, GPU_MEM_SIZE - msum)

        def global_vals():
            vals = [kvpr_g(g) for g in range(gpu_num)]
            return max(vals), vals

        # Single-item moves from the worst GPU
        for _ in range(move_budget):
            cur_max, vals = global_vals()
            worst = max(range(gpu_num), key=lambda g: vals[g])

            best_new_max = cur_max
            best_move = None

            for mdl in list(per_g[worst]):
                ms = float(getattr(mdl, "model_size"))
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr_g(worst, src_mem, src_num)
                    tgt_k = kvpr_g(tgt, tgt_mem, tgt_num)

                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt and vals[g] > new_max:
                            new_max = vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_move = (mdl, worst, tgt, ms, dn)

            if best_move is None:
                break

            mdl, src, tgt, ms, dn = best_move
            per_g[src].remove(mdl)
            per_g[tgt].append(mdl)
            mem[src] -= ms
            num[src] -= dn
            mem[tgt] += ms
            num[tgt] += dn

        # First-improving swaps involving the current worst GPU
        for _ in range(swap_budget):
            cur_max, vals = global_vals()
            worst = max(range(gpu_num), key=lambda g: vals[g])
            improved = False

            for mdl_a in list(per_g[worst]):
                ms_a = float(getattr(mdl_a, "model_size"))
                dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    for mdl_b in list(per_g[tgt]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[tgt] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        src_mem = mem[worst] - ms_a + ms_b
                        src_num = num[worst] - dn_a + dn_b
                        tgt_mem = mem[tgt] - ms_b + ms_a
                        tgt_num = num[tgt] - dn_b + dn_a

                        src_k = kvpr_g(worst, src_mem, src_num)
                        tgt_k = kvpr_g(tgt, tgt_mem, tgt_num)

                        new_max = max(src_k, tgt_k)
                        for g in range(gpu_num):
                            if g != worst and g != tgt and vals[g] > new_max:
                                new_max = vals[g]

                        if new_max + eps < cur_max:
                            # Apply swap
                            per_g[worst].remove(mdl_a)
                            per_g[tgt].remove(mdl_b)
                            per_g[worst].append(mdl_b)
                            per_g[tgt].append(mdl_a)
                            mem[worst] = src_mem
                            num[worst] = src_num
                            mem[tgt] = tgt_mem
                            num[tgt] = tgt_num
                            improved = True
                            break
                    if improved:
                        break
                if improved:
                    break
            if not improved:
                break

        return {g: per_g.get(g, []) for g in range(gpu_num)}

    best_plc = local_improve(best_plc, move_budget=20, swap_budget=10)

    # Ensure all GPUs exist in the mapping
    for g in range(gpu_num):
        best_plc.setdefault(g, [])

    return best_plc
>>>>>>> REPLACE

</DIFF>