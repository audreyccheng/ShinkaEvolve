# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy KVPR-Minimizing Model Placement**
- **Implementation**: Greedily sorts models by r_j/s_j (req_rate/SLO) descending and assigns each to the GPU with the lowest current weighted_req_rate/remaining_mem among those with enough free memory (80GB per GPU), updating per-GPU totals after placement. It fails fast by raising an error when a model cannot fit, and does not implement a τ-feasibility check or post-placement ratio evaluation.
- **Performance**: Combined score 21.89; max_kvpr 20.892; success_rate 1.000; execution_time 0.000s.
- **Feedback**: The simple ratio-based balancing yields consistently feasible placements with near-zero runtime and strong KVPR results on the evaluator. Potential improvements include choosing GPUs based on the projected ratio after placement, adding τ checks, and avoiding a fixed 80GB assumption to better generalize and further reduce peak KV pressure.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Greedy Min-Max KVPR GPU Placement**
- **Implementation**: Greedy assignment after sorting models by (req_rate/slo)/(80−size), placing each on the GPU that minimizes the resulting global max KVPR with tie-breakers (lower target KVPR, more remaining memory). A bounded local improvement then moves single models from the most-pressured GPU if it strictly reduces the max KVPR; memory fit is enforced and KVPR is R/rem_mem (inf at zero).
- **Performance**: Combined score 23.13; max_kvpr 22.127; success_rate 1.000; execution_time 0.000s.
- **Feedback**: Passed all validations; the sorting heuristic plus lookahead and local hill-climb effectively balances KV cache pressure across GPUs. Infinity handling is minimal when remaining memory hits zero, but this did not affect the provided tests.
**Program Identifier:** Generation 1 - Patch Name balanced_minmax_kvpr - Correct Program: True

**Program Name: Greedy KV Cache Pressure Balancer**
- **Implementation**: Sorts models by (req_rate/slo) per GB and greedily assigns each to the GPU that minimizes the projected maximum KVPR across all GPUs, with tie-breakers on local KVPR, remaining memory, and GPU id. Enforces 80 GB per-GPU memory, avoids overcommit via hard-fit checks, and guards against zero SLO/size with infinities and epsilons.
- **Performance**: Combined score 20.74; max_kvpr 19.743; success_rate 1.000; execution_time ~0.000s.
- **Feedback**: Passes all validation tests; the global-max KVPR lookahead and tie-breakers yield balanced placements without overcommit. Numerical edge-case handling (zero SLO/size) improves stability and consistency across test cases.
**Program Identifier:** Generation 2 - Patch Name minimax_greedy_kvpr - Correct Program: True

**Program Name: Greedy + Local Search KVPR Balancer**
- **Implementation**: Greedy min-max placement guided by multiple model orderings; for each placement step, it picks the GPU that minimizes the resulting global max KVPR with memory-aware tie-breaks. It then applies bounded local improvement (best-improving single moves from the max-pressure GPU and capped pairwise swaps) using per-GPU sum(r/s) and remaining memory tracking, with infeasible fits rejected.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: Correct and passed all validations; multi-ordering plus local refinement consistently produced balanced placements with low peak pressure. The fixed 80 GB per-GPU assumption and capped improvement iterations trade some optimality for speed and robustness.
**Program Identifier:** Generation 3 - Patch Name multi_heuristic_and_swap_improvement - Correct Program: True

**Program Name: Greedy-MinMax KVPR Placement with Parametric Search**
- **Implementation**: Uses multi-ordering greedy min–max assignment with lookahead and tie-breakers, then bounded local improvement (single-move and capped pairwise swaps), assuming 80 GB/GPU. It further runs a binary search over target KVPR using a transformed capacity model and best-fit-decreasing packing (w = dR + T*size; capacity = T*S), adopting the refined placement if it improves the max KVPR.
- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.002s runtime.
- **Feedback**: The diverse orderings, lookahead placement, and capped local search provided robust, fast placements that passed all validation tests. Parametric refinement effectively tightened worst-case KVPR when feasible, while safety checks (infinite-rememory handling and feasibility bounds) prevented invalid placements.
**Program Identifier:** Generation 4 - Patch Name parametric_bsearch_bfd - Correct Program: True

**Program Name: Binary-searched best-fit KVPR placement**
- **Implementation**: Uses a transformed-capacity formulation w_i(T)=n_i+T*m_i with per-GPU cap 80*T, performing exponential search to find a feasible T and binary search to minimize it, then packs via best-fit decreasing under two orderings (transformed weight and intrinsic pressure). Includes strict input validation, global/individual lower bounds, small numerical slack, a quality-based post-selection, and a greedy fallback, returning a complete GPU-id mapping.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.
- **Feedback**: Dual ordering plus post-selection by measured KVPR yields consistently feasible, near-optimal placements with excellent speed. The fixed 80 GB constraint and robust feasibility checks improved stability and prevented invalid allocations, contributing to perfect success across tests.
**Program Identifier:** Generation 5 - Patch Name kvpr_bisect_packing - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placement**
- **Implementation**: Uses a transformed-capacity bin packing with KVPR threshold T (exponential search for feasibility, binary search to tighten), packing via five ordering variants with tie-breakers to minimize global max KVPR, plus candidate scoring, a greedy fallback, and a local hill-climbing improvement pass. Enforces single-GPU fit, safe divisions, and returns a full GPU-indexed placement map.
- **Performance**: Combined score 25.43; max_kvpr 24.426; success_rate 1.000; execution_time 0.009s.
- **Feedback**: The mix of ordering variants and local improvement reliably finds feasible, balanced placements quickly, yielding perfect success and very low runtime. Evaluation indicates the strategy effectively controls worst-case KVPR across GPUs.
**Program Identifier:** Generation 6 - Patch Name kvpr_bisect_pack_local_search - Correct Program: True

**Program Name: Greedy-Refined KVPR Balancer**
- **Implementation**: Uses a greedy min–max assignment with lookahead and tie-breakers across multiple orderings (pressure weight, r/s, size asc/desc, density), followed by capped local move/swap improvements. It then binary-searches a target KVPR and applies Best-Fit-Decreasing with transformed weights w = dR + T*size to further tighten placement, with 80 GB/GPU and safety checks enforced.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: Consistently finds feasible, low-pressure placements and passes all validation tests, indicating correctness and robustness. The layered greedy+local+parametric refinement and thoughtful tie-breakers likely drive both quality and speed.
**Program Identifier:** Generation 7 - Patch Name parametric_refinement_bsearch - Correct Program: True

**Program Name: KVPR-Aware GPU Placement with Local Search**
- **Implementation**: Computes per-model demand (req_rate/slo) and defines KVPR as demand over remaining GPU memory. Builds initial placements via KVPR-focused regret-based insertion and a memory-oriented dual packing (max-free then best-fit), then applies bounded move/swap local search to minimize the global max KVPR and selects the best candidate.
- **Performance**: Achieved combined score 26.01 with max_kvpr 25.012, 100% success rate, and 0.001s execution time.
- **Feedback**: KVPR-aware initialization plus local improvement effectively balances load and keeps pressure low across GPUs, with strict memory feasibility checks. The method is fast and robust across test cases; KVPR-based tie-breaking improves stability in edge placements.
**Program Identifier:** Generation 8 - Patch Name regret_waterfill_swaps - Correct Program: True

**Program Name: KVPR-optimized bin packing with binary search**
- **Implementation**: Uses per-item/global lower bounds and an exponential+binary search on a KVPR threshold T, reducing placement to a transformed bin-packing (cap=T*80, weight=n_i+T*m_i) under memory constraints. Applies best-fit-decreasing with two ordering variants and selects the placement with the lowest measured max KVPR; includes strict input validation and safe division.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.
- **Feedback**: The dual-ordering heuristic plus near-optimal T search consistently found feasible placements with low KVPR while remaining extremely fast. Robust validation (e.g., per-GPU memory, SLO > 0, oversized models) improved stability and ensured all tests passed.
**Program Identifier:** Generation 9 - Patch Name dual_bisect_bfd - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

## Successful Algorithmic Patterns
- Parametric KVPR threshold with transformed-capacity packing led to the top scores. Both “Binary-searched best-fit KVPR placement” (Generation 5, kvpr_bisect_packing) and “KVPR-optimized bin packing with binary search” (Generation 9, dual_bisect_bfd) reached the best combined score 26.23 (max_kvpr 25.233, success_rate 1.000, ~0.001s). Key techniques:
  - Exponential+binary search over a KVPR threshold T with transformed weights w_i(T) = n_i + T*m_i and per-GPU cap T*80.
  - Best-fit-decreasing packing under transformed weights, with dual ordering variants and post-selection by measured max KVPR.
  - Strong validation: per-item/global lower bounds on T, strict feasibility checks, and small numerical slack.
- Multi-ordering greedy min–max with bounded local improvements was consistently near-top. “Greedy + Local Search KVPR Balancer” (Generation 3), “Greedy-MinMax KVPR Placement with Parametric Search” (Gen 4), and “Greedy-Refined KVPR Balancer” (Gen 7) all hit 26.17 (max_kvpr 25.168, success_rate 1.000, ~0.002s), leveraging:
  - Lookahead that minimizes projected global max KVPR at each placement step.
  - Multiple model orderings and memory-aware tie-breaks, followed by single-move and capped swap improvements.
- KVPR-aware initialization combined with local search was also strong. “KVPR-Aware GPU Placement with Local Search” (Gen 8) achieved 26.01 (max_kvpr 25.012, 1.000, 0.001s) using regret-based insertion, a memory-oriented dual packing, and bounded moves/swaps.

## Ineffective Approaches
- Pure greedy ratio-based placement without projecting post-placement KVPR lagged significantly. “Greedy KVPR-Minimizing Model Placement” (initial_program) scored 21.89 (max_kvpr 20.892); it sorted by r/s and chose the GPU with the lowest current pressure without evaluating the resulting max KVPR, lacked τ-feasibility checks, and hard-coded 80 GB per GPU.
- Greedy with ad-hoc prioritization improved slightly but plateaued below the best. “Greedy Min-Max KVPR GPU Placement” (Gen 1) at 23.13 (max_kvpr 22.127) sorted by (r/s)/(80−size) and used bounded single-model improvements; minimal infinity handling and no global KVPR threshold search limited balance quality.
- Lookahead-only without parametric search or diversified ordering didn’t close the gap. “Greedy KV Cache Pressure Balancer” (Gen 2) scored 20.74 (max_kvpr 19.743) despite projected-max-KVPR lookahead, indicating that ordering choice and the lack of a T-search-based transformed packing can dominate outcomes.

## Implementation Insights
- What makes the current best programs effective (Gen 5 and Gen 9, both 26.23):
  - Transformed-capacity model aligns the combinatorial packing with the target objective (minimizing max KVPR), enabling a monotone feasibility search over T.
  - Dual ordering strategies (by transformed weight and by intrinsic pressure n/(80−m)), followed by post-selection based on actual measured max KVPR, mitigate ordering sensitivity and stabilize results.
  - Tight best-fit residual packing in transformed space reduces per-GPU slack, directly lowering the worst-case KVPR.
  - Strong guards: individual fit checks (model ≤ 80 GB), per-item/global lower bounds on T, safe divisions, and small numerical slack lead to perfect success and consistent feasibility decisions.
- Local search helps but provides diminishing returns versus parametric search. Programs with greedy+local search alone hit 26.17; adding binary-searched transformed packing yields the final improvement to 26.23 without increasing runtime materially.
- Over-engineering does not necessarily outperform simpler dual-ordering parametric packing. “KVPR-Minimizing GPU Model Placement” (Gen 6) used five orderings plus hill-climbing and scored 25.43 (max_kvpr 24.426, 0.009s), trailing the simpler dual-ordering bisect+BFD approach at 26.23.

## Performance Analysis
- Clear progression: pure greedy (21.89–23.13) < greedy with lookahead (20.74) < greedy+local improvements (26.17) ≲ greedy+local+parametric refinement (26.17) < dual-ordering parametric packing (26.23). The final 0.06 gain from 26.17 to 26.23 is consistent and repeatable across Gen 5 and Gen 9.
- Runtime remained ultra-low across techniques; the parametric search with BFD achieved 0.001s, comparable to or faster than greedy+local approaches (0.002s), showing the T-search does not harm speed.
- Success rate was uniformly 1.000 among correct programs, so differentiation is driven by max KVPR/combined score rather than feasibility. Approaches that explicitly minimize projected global max KVPR and/or operate in the transformed-capacity space correlate with the top scores.
- Dual-ordering plus post-selection is a recurring factor in the highest tiers: both best programs (26.23) and several strong variants (26.17, 26.01) emphasize multiple orderings or candidate generation with a final selection by measured KVPR, highlighting robustness against ordering-induced suboptimal placements.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

1. Add a short, bounded local search after the final parametric packing to reduce the measured max KVPR. Focus on the most loaded GPU: try single-item moves and one-swap improvements that strictly decrease the global max KVPR while keeping memory ≤ 80 GB; cap to a small budget (e.g., up to 20 candidate moves and 10 swaps). This leverages the near-optimality of the T-based packing while capturing the consistent gains seen from local refinements in strong programs (26.17 tier).

2. Generate and select from a few additional candidate placements around the final T to exploit discrete packing effects. Build placements at T = high, and at slightly perturbed thresholds like high*(1±0.5%) using both current orderings, and also test First-Fit-Decreasing in transformed space alongside Best-Fit-Decreasing. Measure actual max KVPR for all candidates and pick the best; keep the total variants small (e.g., 6–8) to preserve ~0.001s runtime.

3. Tighten the initial lower bound on T with inexpensive subset-based bounds to speed and stabilize the search. In addition to per-item and global bounds, compute pair bounds for the top P memory-heavy pairs that cannot co-reside (m_i + m_j > 80): T ≥ (n_i + n_j) / (160 − m_i − m_j); set P ≈ 200 or all pairs if N is small. Add a k-bin prefix bound: for k = 1..min(gpu_num, 4), take items sorted by memory, find the shortest prefix S where sum(m_S) > (k−1)*80, and set T ≥ sum(n_S) / max(k*80 − sum(m_S), ε); use the max of all bounds as low_T.

4. Use a two-phase hybrid placement to improve balance before BFD consolidation. Seed placement by spreading the top H “intrinsic pressure” models (highest n/(80−m)) with a worst-fit strategy in transformed space (choose GPU with largest residual cap T*80 − (n_g + T*m_g)), then run the usual transformed Best-Fit-Decreasing for the remaining models. Set H to a small fraction (e.g., min(4, max(1, gpu_num)), or ≈10% of items) to keep runtime negligible while improving denominator balancing.

5. Introduce lightweight stochastic tie-breaking and tiny randomized restarts to reduce ordering sensitivity while keeping speed. When multiple GPUs are within an epsilon residual in transformed space, randomly pick among the top-k (k=2–3) candidates; run 2 seeds per T/order variant and select by measured max KVPR. This preserves the dual-ordering parametric core while adding robustness that has correlated with top-tier results via candidate post-selection.