<NAME>
two_phase_t_update_and_t_neighborhood
</NAME>

<DESCRIPTION>
I introduce two targeted improvements to reduce the maximum KVPR further while keeping the algorithm simple and fast:
1) Two-phase in-placement T update inside try_pack: After placing the first 40% of items (by the initial ordering), I recompute a lightweight lower bound T' using only the remaining items (indiv, pair, triplet, and k-prefix bounds). I then re-sort the remaining items using w = n + T'·m for order-only purposes while keeping the original transformed-capacity feasibility checks under T. This corrects mid-pack misalignment due to discrete effects and improves load balancing without altering the core feasibility policy.
2) Slightly wider T-neighborhood for candidate generation: I expand the set of T values around the near-optimal T to {0.985, 0.99, 1.0, 1.005, 1.01, 1.015}·T and include the midpoint (low+high)/2. This diversification helps avoid hidden spikes in max KVPR.
Additionally, I make the hybrid policy adaptive by increasing α from 0.2 to 0.25 when the variance of current per-GPU KVPRs is very low, focusing the objective more on local KVPR equalization when GPUs are already similar.

These changes adhere to the problem constraints, keep code simple, and aim to reduce the global max KVPR, improving the combined score.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        for _, mdl, ms, n in ordered:
            w = n + T * ms
            candidates = []
            # Precompute current kvprs
            cur_kvprs = [kvpr_val(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)]

            # Precompute globals for hybrid memory balance
            total_m_after = sum(m_sum) + ms
            avg_mem_frac = total_m_after / (gpu_num * GPU_MEM_SIZE) if gpu_num > 0 else 0.0
            Tnorm = max(T, 1e-12)
            alpha = 0.2
            beta = 0.05

            for g in range(gpu_num):
                if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                    continue
                residual = cap - (used_cap[g] + w)
                if residual < -eps:
                    continue
                if policy == "resid":
                    candidates.append((g, residual, None, None, None))
                else:
                    new_n = n_sum[g] + n
                    new_m = m_sum[g] + ms
                    new_local = kvpr_val(new_n, GPU_MEM_SIZE - new_m)
                    # New global max if placed on g
                    new_max = new_local
                    for k in range(gpu_num):
                        if k != g and cur_kvprs[k] > new_max:
                            new_max = cur_kvprs[k]
                    if policy == "hybrid":
                        mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                        mem_imb = abs(mem_frac_after - avg_mem_frac)
                        J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                        candidates.append((g, residual, new_max, new_local, J))
                    else:
                        candidates.append((g, residual, new_max, new_local, None))

            if not candidates:
                return (False, None) if return_placement else False

            if policy == "resid":
                # Best-fit: minimize transformed residual; tie by more remaining mem then gpu id
                chosen = min(
                    candidates,
                    key=lambda c: (c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            elif policy == "hybrid":
                # Blend projected max KVPR, local KVPR, and memory imbalance
                chosen = min(
                    candidates,
                    key=lambda c: (c[4], c[2], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            else:
                # Minimize global new max KVPR; tie-break by local KVPR then residual then more remaining mem then id
                chosen = min(
                    candidates,
                    key=lambda c: (c[2], c[3], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]

            # Place
            placement[chosen].append(mdl)
            n_sum[chosen] += n
            m_sum[chosen] += ms
            used_cap[chosen] += w
=======
        idx_iter = 0
        phase_split = max(1, int(0.4 * len(ordered)))
        first_phase_done = False
        while idx_iter < len(ordered):
            _, mdl, ms, n = ordered[idx_iter]
            w = n + T * ms
            candidates = []
            # Precompute current kvprs
            cur_kvprs = [kvpr_val(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)]

            # Precompute globals for hybrid memory balance
            total_m_after = sum(m_sum) + ms
            avg_mem_frac = total_m_after / (gpu_num * GPU_MEM_SIZE) if gpu_num > 0 else 0.0
            Tnorm = max(T, 1e-12)
            # Adaptive alpha based on variance of current KVPRs
            if gpu_num > 0:
                mean_k = sum(cur_kvprs) / gpu_num
                var_k = sum((kv - mean_k) ** 2 for kv in cur_kvprs) / gpu_num
            else:
                var_k = 0.0
            alpha = 0.25 if var_k < 1e-6 else 0.2
            beta = 0.05

            for g in range(gpu_num):
                if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                    continue
                residual = cap - (used_cap[g] + w)
                if residual < -eps:
                    continue
                if policy == "resid":
                    candidates.append((g, residual, None, None, None))
                else:
                    new_n = n_sum[g] + n
                    new_m = m_sum[g] + ms
                    new_local = kvpr_val(new_n, GPU_MEM_SIZE - new_m)
                    # New global max if placed on g
                    new_max = new_local
                    for k in range(gpu_num):
                        if k != g and cur_kvprs[k] > new_max:
                            new_max = cur_kvprs[k]
                    if policy == "hybrid":
                        mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                        mem_imb = abs(mem_frac_after - avg_mem_frac)
                        J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                        candidates.append((g, residual, new_max, new_local, J))
                    else:
                        candidates.append((g, residual, new_max, new_local, None))

            if not candidates:
                return (False, None) if return_placement else False

            if policy == "resid":
                # Best-fit: minimize transformed residual; tie by more remaining mem then gpu id
                chosen = min(
                    candidates,
                    key=lambda c: (c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            elif policy == "hybrid":
                # Blend projected max KVPR, local KVPR, and memory imbalance
                chosen = min(
                    candidates,
                    key=lambda c: (c[4], c[2], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            else:
                # Minimize global new max KVPR; tie-break by local KVPR then residual then more remaining mem then id
                chosen = min(
                    candidates,
                    key=lambda c: (c[2], c[3], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]

            # Place
            placement[chosen].append(mdl)
            n_sum[chosen] += n
            m_sum[chosen] += ms
            used_cap[chosen] += w

            idx_iter += 1

            # Two-phase in-placement T update: recompute a tighter ordering for the remaining items
            if (not first_phase_done) and idx_iter == phase_split and (len(ordered) - idx_iter) > 1:
                remaining = ordered[idx_iter:]

                # Compute a quick lower bound T' on remaining items
                rem_indiv_lb = 0.0
                if remaining:
                    rem_indiv_lb = max(safe_div(it[3], GPU_MEM_SIZE - it[2]) for it in remaining)

                # Pair bound on remaining (light)
                rem_pair_lb = 0.0
                P2 = min(len(remaining), 120)
                rem_heavy = sorted(remaining, key=lambda it: it[2], reverse=True)[:P2]
                for i2 in range(len(rem_heavy)):
                    mi = rem_heavy[i2][2]; ni = rem_heavy[i2][3]
                    for j2 in range(i2 + 1, len(rem_heavy)):
                        mj = rem_heavy[j2][2]; nj = rem_heavy[j2][3]
                        if mi + mj > GPU_MEM_SIZE + 1e-12:
                            denom = 2.0 * GPU_MEM_SIZE - (mi + mj)
                            rem_pair_lb = max(rem_pair_lb, safe_div(ni + nj, max(denom, 1e-9)))

                # Triplet bound on remaining (very light)
                rem_triplet_lb = 0.0
                L2 = min(len(remaining), 40)
                rem_top = sorted(remaining, key=lambda it: it[2], reverse=True)[:L2]
                for i2 in range(L2):
                    mi = rem_top[i2][2]; ni = rem_top[i2][3]
                    for j2 in range(i2 + 1, min(L2, i2 + 1 + 8)):
                        mj = rem_top[j2][2]; nj = rem_top[j2][3]
                        for k2 in range(j2 + 1, min(L2, j2 + 1 + 8)):
                            mk = rem_top[k2][2]; nk = rem_top[k2][3]
                            tm = mi + mj + mk
                            if tm > 2.0 * GPU_MEM_SIZE + 1e-12:
                                denom = 3.0 * GPU_MEM_SIZE - tm
                                rem_triplet_lb = max(rem_triplet_lb, safe_div(ni + nj + nk, max(denom, 1e-9)))

                # k-prefix bound on remaining
                rem_kprefix_lb = 0.0
                rem_by_m = sorted(remaining, key=lambda it: it[2], reverse=True)
                for k2 in range(1, min(gpu_num, 4) + 1):
                    s_m = 0.0
                    s_n = 0.0
                    for it in rem_by_m:
                        s_m += it[2]
                        s_n += it[3]
                        if s_m > (k2 - 1) * GPU_MEM_SIZE + 1e-12:
                            break
                    denom = k2 * GPU_MEM_SIZE - s_m
                    rem_kprefix_lb = max(rem_kprefix_lb, safe_div(s_n, max(denom, 1e-9)))

                Tprime = max(T, rem_indiv_lb, rem_pair_lb, rem_triplet_lb, rem_kprefix_lb)

                # Re-sort remaining items using T' for order weights (capacity checks still use T)
                if order_variant == 0:
                    rem_sorted = sorted(remaining, key=lambda it: (it[3] + Tprime * it[2], it[3], it[2]), reverse=True)
                elif order_variant == 1:
                    rem_sorted = sorted(remaining, key=lambda it: (safe_div(it[3], max(GPU_MEM_SIZE - it[2], 1e-9)), it[2]), reverse=True)
                else:
                    rem_sorted = sorted(remaining, key=lambda it: (safe_div(it[3], max(it[2], 1e-9)), it[3]), reverse=True)

                ordered = ordered[:idx_iter] + rem_sorted
                first_phase_done = True

        if return_placement:
            return True, {g: placement[g] for g in range(gpu_num)}
        return True
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    Ts = [high, high * 0.995, high * 1.005]
=======
    Ts = [high * f for f in (0.985, 0.99, 1.0, 1.005, 1.01, 1.015)]
    Ts.append((low + high) / 2.0)
>>>>>>> REPLACE

</DIFF>