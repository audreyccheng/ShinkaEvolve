{
  "unprocessed_programs": [],
  "meta_summary": "**Program Name: Greedy KVPR-Minimizing Model Placement**\n- **Implementation**: Greedily sorts models by r_j/s_j (req_rate/SLO) descending and assigns each to the GPU with the lowest current weighted_req_rate/remaining_mem among those with enough free memory (80GB per GPU), updating per-GPU totals after placement. It fails fast by raising an error when a model cannot fit, and does not implement a \u03c4-feasibility check or post-placement ratio evaluation.\n- **Performance**: Combined score 21.89; max_kvpr 20.892; success_rate 1.000; execution_time 0.000s.\n- **Feedback**: The simple ratio-based balancing yields consistently feasible placements with near-zero runtime and strong KVPR results on the evaluator. Potential improvements include choosing GPUs based on the projected ratio after placement, adding \u03c4 checks, and avoiding a fixed 80GB assumption to better generalize and further reduce peak KV pressure.\n**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True\n\n**Program Name: Greedy Min-Max KVPR GPU Placement**\n- **Implementation**: Greedy assignment after sorting models by (req_rate/slo)/(80\u2212size), placing each on the GPU that minimizes the resulting global max KVPR with tie-breakers (lower target KVPR, more remaining memory). A bounded local improvement then moves single models from the most-pressured GPU if it strictly reduces the max KVPR; memory fit is enforced and KVPR is R/rem_mem (inf at zero).\n- **Performance**: Combined score 23.13; max_kvpr 22.127; success_rate 1.000; execution_time 0.000s.\n- **Feedback**: Passed all validations; the sorting heuristic plus lookahead and local hill-climb effectively balances KV cache pressure across GPUs. Infinity handling is minimal when remaining memory hits zero, but this did not affect the provided tests.\n**Program Identifier:** Generation 1 - Patch Name balanced_minmax_kvpr - Correct Program: True\n\n**Program Name: Greedy KV Cache Pressure Balancer**\n- **Implementation**: Sorts models by (req_rate/slo) per GB and greedily assigns each to the GPU that minimizes the projected maximum KVPR across all GPUs, with tie-breakers on local KVPR, remaining memory, and GPU id. Enforces 80 GB per-GPU memory, avoids overcommit via hard-fit checks, and guards against zero SLO/size with infinities and epsilons.\n- **Performance**: Combined score 20.74; max_kvpr 19.743; success_rate 1.000; execution_time ~0.000s.\n- **Feedback**: Passes all validation tests; the global-max KVPR lookahead and tie-breakers yield balanced placements without overcommit. Numerical edge-case handling (zero SLO/size) improves stability and consistency across test cases.\n**Program Identifier:** Generation 2 - Patch Name minimax_greedy_kvpr - Correct Program: True\n\n**Program Name: Greedy + Local Search KVPR Balancer**\n- **Implementation**: Greedy min-max placement guided by multiple model orderings; for each placement step, it picks the GPU that minimizes the resulting global max KVPR with memory-aware tie-breaks. It then applies bounded local improvement (best-improving single moves from the max-pressure GPU and capped pairwise swaps) using per-GPU sum(r/s) and remaining memory tracking, with infeasible fits rejected.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: Correct and passed all validations; multi-ordering plus local refinement consistently produced balanced placements with low peak pressure. The fixed 80 GB per-GPU assumption and capped improvement iterations trade some optimality for speed and robustness.\n**Program Identifier:** Generation 3 - Patch Name multi_heuristic_and_swap_improvement - Correct Program: True\n\n**Program Name: Greedy-MinMax KVPR Placement with Parametric Search**\n- **Implementation**: Uses multi-ordering greedy min\u2013max assignment with lookahead and tie-breakers, then bounded local improvement (single-move and capped pairwise swaps), assuming 80 GB/GPU. It further runs a binary search over target KVPR using a transformed capacity model and best-fit-decreasing packing (w = dR + T*size; capacity = T*S), adopting the refined placement if it improves the max KVPR.\n- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.002s runtime.\n- **Feedback**: The diverse orderings, lookahead placement, and capped local search provided robust, fast placements that passed all validation tests. Parametric refinement effectively tightened worst-case KVPR when feasible, while safety checks (infinite-rememory handling and feasibility bounds) prevented invalid placements.\n**Program Identifier:** Generation 4 - Patch Name parametric_bsearch_bfd - Correct Program: True\n\n**Program Name: Binary-searched best-fit KVPR placement**\n- **Implementation**: Uses a transformed-capacity formulation w_i(T)=n_i+T*m_i with per-GPU cap 80*T, performing exponential search to find a feasible T and binary search to minimize it, then packs via best-fit decreasing under two orderings (transformed weight and intrinsic pressure). Includes strict input validation, global/individual lower bounds, small numerical slack, a quality-based post-selection, and a greedy fallback, returning a complete GPU-id mapping.\n- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.\n- **Feedback**: Dual ordering plus post-selection by measured KVPR yields consistently feasible, near-optimal placements with excellent speed. The fixed 80 GB constraint and robust feasibility checks improved stability and prevented invalid allocations, contributing to perfect success across tests.\n**Program Identifier:** Generation 5 - Patch Name kvpr_bisect_packing - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement**\n- **Implementation**: Uses a transformed-capacity bin packing with KVPR threshold T (exponential search for feasibility, binary search to tighten), packing via five ordering variants with tie-breakers to minimize global max KVPR, plus candidate scoring, a greedy fallback, and a local hill-climbing improvement pass. Enforces single-GPU fit, safe divisions, and returns a full GPU-indexed placement map.\n- **Performance**: Combined score 25.43; max_kvpr 24.426; success_rate 1.000; execution_time 0.009s.\n- **Feedback**: The mix of ordering variants and local improvement reliably finds feasible, balanced placements quickly, yielding perfect success and very low runtime. Evaluation indicates the strategy effectively controls worst-case KVPR across GPUs.\n**Program Identifier:** Generation 6 - Patch Name kvpr_bisect_pack_local_search - Correct Program: True\n\n**Program Name: Greedy-Refined KVPR Balancer**\n- **Implementation**: Uses a greedy min\u2013max assignment with lookahead and tie-breakers across multiple orderings (pressure weight, r/s, size asc/desc, density), followed by capped local move/swap improvements. It then binary-searches a target KVPR and applies Best-Fit-Decreasing with transformed weights w = dR + T*size to further tighten placement, with 80 GB/GPU and safety checks enforced.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: Consistently finds feasible, low-pressure placements and passes all validation tests, indicating correctness and robustness. The layered greedy+local+parametric refinement and thoughtful tie-breakers likely drive both quality and speed.\n**Program Identifier:** Generation 7 - Patch Name parametric_refinement_bsearch - Correct Program: True\n\n**Program Name: KVPR-Aware GPU Placement with Local Search**\n- **Implementation**: Computes per-model demand (req_rate/slo) and defines KVPR as demand over remaining GPU memory. Builds initial placements via KVPR-focused regret-based insertion and a memory-oriented dual packing (max-free then best-fit), then applies bounded move/swap local search to minimize the global max KVPR and selects the best candidate.\n- **Performance**: Achieved combined score 26.01 with max_kvpr 25.012, 100% success rate, and 0.001s execution time.\n- **Feedback**: KVPR-aware initialization plus local improvement effectively balances load and keeps pressure low across GPUs, with strict memory feasibility checks. The method is fast and robust across test cases; KVPR-based tie-breaking improves stability in edge placements.\n**Program Identifier:** Generation 8 - Patch Name regret_waterfill_swaps - Correct Program: True\n\n**Program Name: KVPR-optimized bin packing with binary search**\n- **Implementation**: Uses per-item/global lower bounds and an exponential+binary search on a KVPR threshold T, reducing placement to a transformed bin-packing (cap=T*80, weight=n_i+T*m_i) under memory constraints. Applies best-fit-decreasing with two ordering variants and selects the placement with the lowest measured max KVPR; includes strict input validation and safe division.\n- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.\n- **Feedback**: The dual-ordering heuristic plus near-optimal T search consistently found feasible placements with low KVPR while remaining extremely fast. Robust validation (e.g., per-GPU memory, SLO > 0, oversized models) improved stability and ensured all tests passed.\n**Program Identifier:** Generation 9 - Patch Name dual_bisect_bfd - Correct Program: True\n\n**Program Name: Minimax KVPR GPU Placement with BFD Refinement**\n- **Implementation**: Multi-ordering greedy min-max placement with lookahead and tie-breakers, followed by local improvement via capped single-item moves and pairwise swaps. A final binary search on target KVPR uses BFD over transformed weights (dR + T\u00b7size) with validation, adopting improvements.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.021s.\n- **Feedback**: Passed all validation tests; the layered heuristics plus parametric BFD tightening produced balanced, feasible placements with very low runtime. Robustness benefited from multiple orderings, careful tie-breaking, and explicit handling of infeasible single-model cases.\n**Program Identifier:** Generation 10 - Patch Name kvpr_minimax_param_refine - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placer**\n- **Implementation**: Performs binary search on a KVPR threshold T and reduces feasibility to transformed-capacity bin packing (weight n + T*m, capacity T*80) with two-phase seeding and best/first-fit variants. Establishes strong lower bounds (per-item, global, pairwise, k-prefix), generates multiple candidate placements around T, and applies local move/swap search to reduce the max per-GPU KVPR.\n- **Performance**: Combined score 24.55; max_kvpr 23.551; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: The multi-bound initialization, diversified packing variants, and local search achieved low maximum KVPR with perfect feasibility and very low latency. Potential minor improvements could come from broader candidate diversification or adaptive seeding, but the current implementation already passes all validation tests.\n**Program Identifier:** Generation 11 - Patch Name kvpr_parametric_hybrid_ls - Correct Program: True\n\n**Program Name: KVPR-minimizing placement with LB and packing**\n- **Implementation**: Computes tight lower bounds (per-item, global, pair, k-bin) on target KVPR T, then performs transformed bin packing with weights w = dR + T*size using BFD/FFD variants, seeding by intrinsic pressure, and deterministic tie-breaking, with a greedy KVPR fallback. Selects among candidate T values by measured max-KVPR and applies bounded local refinement (targeted moves and swaps) plus safety checks.\n- **Performance**: Combined score 25.73 (max_kvpr 24.730), success_rate 1.000, execution_time 0.001s.\n- **Feedback**: Passed all validations with excellent speed; LB-guided sweeping and local refinement effectively reduce the worst-case KVPR. Additional variant exploration or deeper local search could yield marginal improvements while maintaining low latency.\n**Program Identifier:** Generation 12 - Patch Name pairbound_threshold_sweep - Correct Program: True\n\n**Program Name: KVPR-aware GPU placement with binary search and refinement**\n- **Implementation**: Computes a lower bound on KVPR threshold T, then performs exponential+binary search with feasibility packing using transformed weights w(T)=n+T*m across multiple item orderings and policies. It generates diverse candidates, selects the lowest measured max-KVPR placement, and applies a local move-based improvement; includes strict memory/SLO checks and fills all GPU keys.\n- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.004s.\n- **Feedback**: Multi-variant packing plus local refinement consistently finds near-optimal placements with perfect success and very low runtime. The w(T)-based search with tight lower bounds is stable, and the greedy min-max fallback boosts robustness.\n**Program Identifier:** Generation 13 - Patch Name hybrid_tsearch_minmax_local - Correct Program: True\n\n**Program Name: Balanced-slack KVPR Minimization**\n- **Implementation**: Computes tight lower bounds for the KVPR threshold T (per-item, global, pairwise, k-bin) and finds a feasible T via a multiplicative sweep while packing with a slack-equalization bin packer (weight w=dR+T*size), seeded ordering, and min-K_after/min-KVPR tie-breaks with slight randomization. Around the first feasible T it explores multiple orderings, applies targeted move/swap local refinement, and uses strict memory/KVPR checks with a deterministic greedy fallback for feasibility.\n- **Performance**: Combined score 36.51; success_rate 1.000; execution_time 0.002s; reported max_kvpr metric 35.512.\n- **Feedback**: Lower-bound-guided T search plus equalized-slack packing quickly yields balanced placements, with local refinement providing incremental improvements. Robust handling of edge cases (e.g., slo==0), deterministic seeding, and validation checks led to reliable, passing results across all tests.\n**Program Identifier:** Generation 14 - Patch Name slack_equalization_t_search - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement with Slack Equalization**\n- **Implementation**: Computes tight lower bounds (per-item, global, pairwise, k-bin) on target KV pressure, then packs via a slack-equalization scheduler with weight w=dR+T*size, exploring multiple orderings, tie-breakers, and deterministic randomness. Feasible T is found by a multiplicative sweep, followed by variant trials and a local refine phase (moves/swaps) plus a greedy fallback and strict safety checks.\n- **Performance**: Combined score 25.99 (max_kvpr 24.988; success_rate 1.000; execution_time 0.003s).\n- **Feedback**: Lower-bound-guided T selection and K-slack equalization with local refinement effectively balances memory and request rates, yielding low max KVPR and perfect feasibility at very low runtime. The greedy fallback robustly covers slo==0/infeasible cases, and deterministic seeding ensures reproducibility.\n**Program Identifier:** Generation 15 - Patch Name kvpr_balanced_param_local - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Placement**\n- **Implementation**: Lower-bound\u2013guided search on a KVPR threshold combined with transformed bin packing (w_i = n_i + T*m_i, cap = T*80) under strict per-GPU memory constraints, using two ordering heuristics and exponential warm-up followed by binary search. Near-optimal candidates are measured by actual KVPR and refined via local moves and first-improving swaps to reduce the worst GPU pressure.\n- **Performance**: Combined score 24.44; max_kvpr 23.442; success_rate 1.000; execution_time 0.001s.\n- **Feedback**: Strong bounds (per-item, global, pair, k-prefix) tighten the initial feasible region and speed convergence, while dual orderings and local refinement improve packings around the optimal threshold. The approach is robust (100% success) and extremely fast; remaining improvements would likely come from enhanced local search or additional ordering strategies.\n**Program Identifier:** Generation 16 - Patch Name tighter_bounds_and_local_refine - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR Placement**\n- **Implementation**: Uses strong lower bounds (per-item, global, pairwise, k-bin) to seed a balanced-slack bin packing that minimizes max KVPR by packing weights w = dR + T*s with multiple orderings, light deterministic randomization, and strict validation. It then applies localized move/swap refinement and selects the best among refined, search-based, and greedy fallback placements (fallback also covers dR=inf cases).\n- **Performance**: Combined score 25.99 with max_kvpr 24.988, success_rate 1.000, execution_time 0.003s.\n- **Feedback**: Bound-guided search plus local refinement consistently yields low max KVPR while remaining very fast, and the greedy fallback ensures robustness in edge cases (e.g., SLO=0 or tight memory). Final memory checks and candidate selection contribute to reliability without noticeable runtime cost.\n**Program Identifier:** Generation 17 - Patch Name tsearch_local_refine_fix - Correct Program: True\n\n**Program Name: Min-Max KV Cache Pressure Placement**\n- **Implementation**: Computes tight lower bounds (per-item, global, heavy-pair, k-prefix) on the KVPR threshold T, then performs exponential+binary search with a T-aware best-fit/min-max packer across multiple orderings. Diversifies candidates around near-optimal T, adds a demand-per-GB greedy baseline, and applies single-move and swap local search to reduce the measured max KVPR.\n- **Performance**: Combined score 25.70; max_kvpr 24.702; success_rate 1.000; execution_time 0.004s.\n- **Feedback**: The program is correct and passes all validation tests. Strong bounds plus candidate diversification and local improvement yield robust, low-pressure placements while remaining extremely fast.\n**Program Identifier:** Generation 18 - Patch Name pair_kprefix_t_perturb_and_swaps - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Placement via Search and Local Moves**\n- **Implementation**: Computes tight lower bounds (individual, global, pair-based, k-bin), then uses exponential+binary search on a KVPR threshold T, packing with transformed weights w(T)=n+T*m under multiple ordering/policy heuristics. It selects the best measured placement, adds a greedy min-max candidate, and performs bounded local improvements via moves and swaps.\n- **Performance**: Combined score 25.67 with max_kvpr 24.667, 100% success rate, and 0.004s execution time.\n- **Feedback**: The method is correct and robust, consistently finding feasible placements that balance KV cache pressure with very low latency. The mix of diverse heuristics and local refinement likely drives the strong KVPR; exploring more variants or deeper local search could yield marginal gains.\n**Program Identifier:** Generation 19 - Patch Name t_perturb_kbin_pairbounds_swap_local - Correct Program: True\n\n**Program Name: Greedy-Search KVPR Balancer for GPU Placement**\n- **Implementation**: Greedy min\u2013max assignment with lookahead and tie-breaking (favoring lower resulting max KVPR, lower per-GPU KVPR, then more remaining memory), followed by bounded local improvements (single-model moves and capped pairwise swaps). Seeds with multiple model orderings, picks the best, then runs a parametric binary search on target KVPR using best-fit-decreasing in a transformed space, with optional final refinement and robust feasibility checks.\n- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.002s execution time.\n- **Feedback**: Ensemble seeding plus the parametric feasibility pass yielded consistent, fast placements that passed all validations. Further gains may come from expanding swap neighborhoods or adaptive iteration budgets, but the current approach is already efficient and robust.\n**Program Identifier:** Generation 20 - Patch Name add_parametric_refinement - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Model Placement**\n- **Implementation**: Greedy min-max placement with lookahead and deterministic tie-breaking is followed by local improvement (move/swap) and multiple candidate orderings. It then runs a parametric binary search on T using a transformed capacity model (w = dR + T*size) with a best-fit decreasing assigner, bounded by several lower bounds, and optional refinement.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: The layered approach (heuristics + parametric search) effectively reduces worst-case KVPR while keeping runtime low, and it consistently produced feasible placements. Strong feasibility checks, careful tie-breaking, and capped local search iterations improved stability and robustness across test cases.\n**Program Identifier:** Generation 21 - Patch Name hybrid_bfd_and_bounds - Correct Program: True\n\n**Program Name: KVPR-Aware Multi-Stage GPU Placement**\n- **Implementation**: Uses a multi-stage heuristic: greedy min-max assignment with KVPR lookahead and deterministic tie-breaking, followed by local improvements (single moves, pairwise swaps, and length-2 eject chains). It explores multiple model orderings, selects the best by (max, second, avg) KVPR, then applies a parametric Best-Fit-Decreasing with binary search on a KVPR target using several lower bounds, and optionally refines the result.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: The multi-start ordering plus targeted local search and parametric refinement effectively reduces peak KVPR while maintaining speed, yielding robust placements and 100% success. Iteration caps, careful tie-breaking, and bound-guided binary search contribute to stability and fast convergence, and the solution passed all validation tests.\n**Program Identifier:** Generation 22 - Patch Name bfd_kbounds_ejectchain_tielex - Correct Program: True\n\n**Program Name: Threshold-guided KVPR min-max placement**\n- **Implementation**: Computes tight lower bounds (individual/global/pair/triplet/k-prefix) to initialize an exponential+binary search over a KVPR threshold T, then packs using multiple orderings (w(T)=n+T\u00b7m, intrinsic KVPR, demand/GB) and policies (residual, minmax, hybrid) under a transformed capacity model. Generates diverse candidates near-optimal T, adds a greedy min-max baseline, selects by measured KVPR, and applies local improvements (moves, swaps, two-opt); enforces 80 GB per-GPU and input validity.\n- **Performance**: Combined score 25.76; max_kvpr 24.760; success_rate 1.000; execution_time 0.006s.\n- **Feedback**: The program is correct and passes all validation tests. Candidate diversity plus local search consistently achieves low max KVPR with very fast runtime; bounded combinatorics in LB and swap stages maintain efficiency.\n**Program Identifier:** Generation 23 - Patch Name triplet_bound_hybrid_policy_2opt_tiebreak - Correct Program: True\n\n**Program Name: KVPR-Aware Multi-Strategy Placement**\n- **Implementation**: Combines a parametric T-based bin packing (with lower bounds, exponential/binary search, and two orderings) with KVPR-aware regret insertion and memory heuristics, then applies local move/swap search to minimize the global max KVPR. It generates multiple candidates, evaluates by measured max KVPR, and uses strict validations, tie-breakers, and feasibility fallbacks.\n- **Performance**: Combined score 26.19; max_kvpr 25.192; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Delivers consistently feasible, low-KVPR placements at very low runtime; the parametric initialization plus local search notably improves quality. Passed all validation tests, and numerical guards/fallback strategies enhance robustness across diverse cases.\n**Program Identifier:** Generation 24 - Patch Name add_parametric_T_candidates - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Uses greedy lookahead assignment across multiple model orderings with strict tie-breaking, then applies a capped local improvement phase (move/swap) to reduce the maximum KV cache pressure. It further performs a binary search on a KVPR target using transformed weights and several analytic lower bounds to tighten solutions, while enforcing memory feasibility.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.030s.\n- **Feedback**: Multi-heuristic seeding plus limited local search provides robust, fast placements, and the parametric refinement reliably lowers worst-case pressure. The approach balances solution quality and speed well, though the fixed 80 GB GPU memory assumption should be parameterized for broader applicability.\n**Program Identifier:** Generation 25 - Patch Name hybrid_bfd_and_tighter_bounds - Correct Program: True\n\n**Program Name: Slack-Equalized KVPR GPU Placement**\n- **Implementation**: Uses tight lower bounds (single/global/pair/triplet/k-prefix) and a multiplicative sweep over T to drive a slack-equalization assignment (w = dR + T*size) with seeding, ordering variants, dynamic T updates, and a local move/swap refinement; includes a greedy KVPR-minimizing fallback for infeasible cases.\n- **Performance**: Combined score 24.52; max_kvpr 23.518; success_rate 1.000; execution_time 0.004s.\n- **Feedback**: The multi-bound initialization and dynamic slack updating quickly find feasible low-KVPR placements, while local refinement reduces peak pressure further. Greedy fallback for slo=0 models safeguards feasibility, contributing to 100% success with very low runtime.\n**Program Identifier:** Generation 26 - Patch Name kvpr_two_phase_slack - Correct Program: True\n\n**Program Name: Slack-Equalized KVPR-Minimizing Model Placement**\n- **Implementation**: Computes strong lower bounds for T (max KVPR), then performs a multiplicative sweep to a feasible T and packs using KV-slack equalization with weights w=dR+T*s and K_g=T*S\u2212(sumR_g+T*mem_g), trying multiple orderings and tie-breakers. Includes a deterministic greedy fallback for infeasible/infinite-demand cases and a bounded local move/swap refinement to reduce the worst-GPU KVPR.\n- **Performance**: Combined score 36.51; max_kvpr 35.512; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: The lower-bound-guided search plus local refinement produced consistently feasible, high-quality placements with very low latency and perfect success. Edge cases with zero-SLO/infinite demand are handled via the greedy path, which zeroes their pressure in sums\u2014robust for feasibility but potentially conservative for optimality.\n**Program Identifier:** Generation 27 - Patch Name slack_bsearch_hybrid - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Model Placement**\n- **Implementation**: Uses a greedy, lookahead min-max placement with lexicographic KVPR scoring across multiple model orderings, followed by local move/swap improvements. Adds a parametric binary search on target KVPR using transformed best-fit packing with multiple lower bounds, then selects the best candidate and optionally refines it.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.004s.\n- **Feedback**: The multi-heuristic pipeline and careful tie-breaking yield low worst-case KVPR with perfect feasibility and very fast runtime. Lower-bound seeding stabilizes the binary search, and clear fallbacks make the solver robust across test cases.\n**Program Identifier:** Generation 28 - Patch Name lex_triplet_hybrid - Correct Program: True\n\n**Program Name: Balanced-slack KVPR minimization with local search**\n- **Implementation**: Uses lower-bound-guided target-KVPR (T) search with a balanced-slack bin packer (weight = dR + T*size), multiple orderings/tie-breaks, and seeding of high-pressure items. Augments with multi-order greedy placement, bounded move/swap local refinements, a binary search to tighten T, deterministic RNG, and strict memory/KVPR validation with a greedy fallback.\n- **Performance**: Combined score 29.35 (max_kvpr 28.347, success_rate 1.000) with 0.003s execution time.\n- **Feedback**: The multi-heuristic T-sweep plus local refinement reliably reduces peak KVPR while maintaining feasibility; fallback paths handle edge cases (e.g., infinite dR or tight memory). Passed all validation tests, indicating correctness and robustness.\n**Program Identifier:** Generation 29 - Patch Name kvpr_balanced_bsearch - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Placement with Dynamic Bounds**\n- **Implementation**: Uses multiple analytical lower bounds (individual, global, pair, triplet, k-prefix) to bound T, then performs exponential search plus binary search for a feasible threshold with multi-order, multi-policy packers (residual, minmax, hybrid) and a dynamic mid-pack T refinement. Generates diverse candidates and applies local improvement (single-item moves, swaps, and 2-opt between worst GPUs) to minimize the measured max KVPR under strict memory checks.\n- **Performance**: Combined score 25.76, success_rate 1.000, max_kvpr 24.760, execution_time 0.008s.\n- **Feedback**: The combination of strong bounds, diversified packing heuristics, and targeted local search yields robust, high-quality placements and very fast runtime, passing all validations. Minor tuning (e.g., hybrid weights or expanded swap neighborhoods) might further tighten the max KVPR, but current results are already strong.\n**Program Identifier:** Generation 30 - Patch Name two_phase_t_update - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Placement with Bounds and Heuristics**\n- **Implementation**: Computes tight lower bounds on the KVPR threshold T (individual, global, pair, triplet, k-prefix), searches T via exponential then binary search, and packs with multiple orderings/policies (residual/minmax/hybrid) including a two-phase reordering; selects among diverse candidates (plus a greedy min-max) and applies local improvements (single moves, swaps, targeted 2-opt).\n- **Performance**: Combined score 25.76 with max_kvpr 24.760, 100% success rate, and 0.033s execution time.\n- **Feedback**: Diverse heuristics and local refinement produce strong balance (low max KVPR) and robustness across cases, while tight bounds accelerate feasibility checks and reduce search iterations; the solution is correct and passes all tests.\n**Program Identifier:** Generation 31 - Patch Name two_phase_t_update_and_t_neighborhood - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR GPU Placement**\n- **Implementation**: Computes multiple lower bounds and applies a balanced-slack packer using w = dR + T*s and K_g = T*S - (sumR + T*used) to test feasibility while sweeping/binary-searching T with varied orderings, seeding, and light randomization. Augments with a greedy constructor plus local move/swap refinements and a safe greedy fallback to guarantee feasibility under memory constraints.\n- **Performance**: Combined score 29.35; max_kvpr 28.347; success_rate 1.000; execution_time 0.006s.\n- **Feedback**: Passed all validation tests; the bound-guided search and local refinement achieved low max KVPR efficiently. The fallback and stochastic tie-breaking improved robustness across diverse inputs.\n**Program Identifier:** Generation 32 - Patch Name two_phase_t_and_bounds_hybrid - Correct Program: True\n\n**Program Name: KVPR-Minimizing Multi-GPU Model Placement Planner**\n- **Implementation**: Uses a parametric KVPR threshold T with strong lower bounds (per-item, global, heavy pair/triplet, k-prefix), searching T via exponential then binary search. Packing employs three selection rules (tight, min_kvpr, hybrid), explores a T-neighborhood of candidates, scores by (max, second, avg KVPR), and applies bounded local refinements (moves, swaps, short eject chains).\n- **Performance**: Combined score 24.14; max_kvpr 23.137; success_rate 1.000; execution_time 0.007s.\n- **Feedback**: The diversified candidate generation plus local refinement effectively reduces peak KVPR while maintaining balance, achieving perfect feasibility and very fast execution. Robust validation and the two-phase in-placement T bump improve stability and packing tightness; the program is correct and passes all tests.\n**Program Identifier:** Generation 33 - Patch Name kvpr_balanced_parametric_planner - Correct Program: True\n\n**Program Name: Min-Max KV Cache Placement**\n- **Implementation**: Uses analytic lower bounds to bracket a KVPR threshold T, then performs exponential/binary search while packing with transformed weights w = n + T*m under 80GB per-GPU memory. Explores multiple ordering/policy variants, selects the best by KVPR profile, and applies local move/swap refinements targeting the worst GPU.\n- **Performance**: Combined score 25.74; max_kvpr 24.741; success_rate 1.000; execution_time 0.012s.\n- **Feedback**: Bound-guided search plus diverse heuristic candidates yielded consistently feasible, near-optimal placements with very low runtime. Local improvements further balanced peak pressure, and robust checks (memory fit, non-co-resident bounds) ensured correctness and stability.\n**Program Identifier:** Generation 34 - Patch Name tighten_bounds_and_candidates_plus_swaps - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Combines a parametric T-based bin-packing transform (with indiv/global/pair/k-prefix lower bounds and binary search) and a KVPR-aware regret insertion, followed by local move/swap search to minimize the global max KVPR; also builds memory-oriented packings as fallbacks and selects the best candidate by measured KVPR. Input validation and safe division guard feasibility and numerical stability.\n- **Performance**: Achieved combined score 26.22 (max_kvpr 25.220; success_rate 1.000; execution_time 0.016s).\n- **Feedback**: Multi-start candidates plus local improvement deliver consistent feasibility and low peak pressure, reflected in 100% success and fast runtime; the T-search and KVPR-aware scoring appear to drive most of the gains. Further gains may be possible by tuning candidate ordering/policies or adapting GPU_MEM_SIZE dynamically, but current implementation already passes all validations.\n**Program Identifier:** Generation 35 - Patch Name t_neighborhood_minmax_pack - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement**\n- **Implementation**: Builds multiple candidate placements using parametric T-based transformed packing (with individual/global/pair/k-prefix lower bounds and best-fit/min-max policies), regret-based insertion, and memory-oriented heuristics, then refines via local search (move/swap and targeted 2-opt) to reduce global max KVPR. Enforces 80 GB GPU memory constraints, uses safe division and tie-breaking by local KVPR/residuals, and selects the best placement by measured max KVPR.\n- **Performance**: Combined score 26.23 with max_kvpr 25.231, 100% success rate, and 0.008s runtime.\n- **Feedback**: Passed all validation tests with robust, fast performance; near-optimal T search plus multi-candidate seeding and local improvements drive low KVPR and high reliability. The approach scales efficiently while maintaining feasibility under tight memory constraints.\n**Program Identifier:** Generation 36 - Patch Name t_neighborhood_and_hybrid_policy - Correct Program: True\n\n**Program Name: Dual-fit KVPR Minimization for GPU Placement**\n- **Implementation**: Computes tight lower bounds, then searches the minimal feasible KVPR threshold via exponential plus binary search, packing with a Lagrangian dual \u201cwater-filling\u201d heuristic (multiple orderings, subgradient updates) and light repair; near-optimal candidates are locally refined, with greedy and best-fit fallbacks for guaranteed feasibility. Robust input validation and safe divisions handle edge cases.\n- **Performance**: Combined score 25.11; max_kvpr 24.110; success_rate 1.000; execution_time 0.067s.\n- **Feedback**: Consistently produced feasible, low-pressure placements, indicating the dual-based packing, candidate diversification, and local refinement effectively reduce peak KVPR. Tight bounds and limited dual iterations delivered strong efficiency without sacrificing solution quality.\n**Program Identifier:** Generation 37 - Patch Name dual_waterfill_minmax - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR-Minimizing GPU Placement**\n- **Implementation**: Computes strong lower bounds (per-item, global, pairwise, k-bin) then does a multiplicative search over T with a balanced-slack bin packing (w = dR + T*size) using multiple orderings, seeding, and slight randomization, followed by local move/swap refinement. Includes a memory-safe greedy fallback minimizing local KVPR increases, with special handling for slo=0 and infeasible cases; assumes GPU_MEM_SIZE=80 GB.\n- **Performance**: Combined score 36.51; max_kvpr 35.512; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: Consistently finds feasible, low-KVPR placements and passes all validation tests. The lower-bound-guided T sweep plus local refinement effectively reduces worst-GPU pressure, while the greedy fallback ensures robustness on edge cases (e.g., infinite dR from slo=0).\n**Program Identifier:** Generation 38 - Patch Name balanced_slack_refine_simple - Correct Program: True\n\n**Program Name: Softmax-guided KVPR-balanced GPU placement**\n- **Implementation**: Uses exponentiated-gradient soft assignment minimizing a softmax potential of KVPR, followed by deterministic rounding that minimizes objective increase, with a memory-first greedy fallback and local move/swap refinement. Assumes 80 GB GPUs, treats SLO=0 with a large surrogate rate (1e9), and enforces post-refinement memory safety.\n- **Performance**: Achieved combined score 22.50 with success_rate 1.000, max_kvpr 21.498, and execution_time 0.002s.\n- **Feedback**: Soft assignment plus targeted refinement effectively balances peak KVPR while maintaining feasibility, leading to consistent success across tests; fallback was rarely needed. Parameter choices (beta=7.0, eta=0.12, bounded move/swap budgets) provide a solid speed-quality tradeoff.\n**Program Identifier:** Generation 39 - Patch Name softmax_dual_balance - Correct Program: True\n\n**Program Name: Balanced-slack KVPR GPU Placement**\n- **Implementation**: Uses tight lower bounds (single/global/pair/triplet/k-prefix) to seed a balanced-slack packer with weight w=dR+T*size and GPU slack K_g=T*S-(sumR+T*used_mem), including a two-phase T update, multiple ordering/choice heuristics, and deterministic seeding. It then searches neighbor T values and performs local refinement (single moves, 2-opt swaps, eject chains), with numeric guards (slo==0) and a greedy min-max fallback.\n- **Performance**: Combined score 20.45; max_kvpr 19.449; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Passed all validation tests; placements were consistently feasible and memory-safe. Lower-bound\u2013guided T sweeping plus local refinement likely drove strong KVPR results and speed, while robust edge-case handling and fallback improved reliability.\n**Program Identifier:** Generation 40 - Patch Name kvpr_balanced_pipeline - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placer**\n- **Implementation**: Multi-stage packing that pre-places memory-only models (largest-first with max-free/best-fit), computes tight lower bounds on target KVPR (individual, global, pair, triplet, k-prefix), and packs active models using a transformed weight w = n + T\u00b7m with a hybrid cost (max KVPR, local KVPR, memory imbalance) plus two adaptive retuning phases. It performs exponential then binary search over T, explores multiple order/policy variants, and applies local improvement via single-item moves and limited swaps.\n- **Performance**: Combined score 25.60 (max_kvpr 24.600; success_rate 1.000; execution_time 0.009s).\n- **Feedback**: Passed all validations; the strong lower bounds and adaptive hybrid heuristic achieved balanced allocations with low maximum KV cache pressure while remaining very fast. Variant exploration and local refinements improved robustness and final KVPR without noticeable runtime overhead.\n**Program Identifier:** Generation 41 - Patch Name kvpr_balanced_slack_pack_v3 - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Placement with Refinement**\n- **Implementation**: Greedy lookahead placement minimizes resultant max KVPR, then applies bounded local search (single moves, pair swaps, and two-hop eviction chains). It tests multiple model orderings and performs a parametric binary search on KVPR using a transformed best-fit-decreasing assignment seeded by analytic lower bounds, with careful tie-breakers and memory-safe KVPR calculation.\n- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 1.000 success rate, and 0.003s runtime.\n- **Feedback**: Evaluation confirms correctness and stability across cases with very low latency. Multi-ordering seeding, strong tie-breaking, and lower-bound\u2013guided binary search likely contribute to consistently tight KVPR without sacrificing speed.\n**Program Identifier:** Generation 42 - Patch Name balanced_slack_bfd_and_triplet_lb - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement**\n- **Implementation**: Uses a hybrid multi-start heuristic combining parametric T-based transformed packing (with lower-bound computation, feasibility search, and multiple order/policy variants), regret-based insertion, and memory-oriented packers. Each candidate is refined by KVPR-aware local search (single moves, swaps, and bounded 2-opt) with strict 80GB memory constraints and numerical safeguards.\n- **Performance**: Achieved combined score 26.24 with max_kvpr 25.238, success_rate 1.000, and execution_time 0.039s.\n- **Feedback**: Validated as correct, passing all tests. Diverse candidate generation plus KVPR-aware local improvement consistently reduces max KVPR, and efficient feasibility checks (including top-2 KVPR caching) keep runtime low.\n**Program Identifier:** Generation 43 - Patch Name hybrid_policy_and_stronger_bounds - Correct Program: True\n\n**Program Name: Min-max KVPR GPU Placer**\n- **Implementation**: Uses a greedy min\u2013max assignment with lookahead across multiple model orderings, followed by bounded local improvements (moves and swaps with tie-breakers). Adds a parametric refinement via binary search on a KVPR target T using best-fit decreasing on transformed weights w = dR + T*size, with strengthened lower bounds (single/global/pair/k-prefix) and robust memory/KVPR checks.\n- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Consistently finds feasible, well-balanced placements and lowers peak KVPR without harming speed; the multi-ordering seed plus binary-search refinement likely tighten the maximum pressure. Passed all validations, indicating reliable handling of memory constraints and numerical edge cases.\n**Program Identifier:** Generation 44 - Patch Name hybrid_bfd_and_bounds - Correct Program: True\n\n**Program Name: KVPR-Min GPU Placement (Greedy + Parametric)**\n- **Implementation**: Greedy min-max assignment across multiple model orderings with lexicographic tie-breakers and local move/swap refinement. A parametric binary search on target KVPR uses transformed-weight BFD packing, guided by per-model, global, pair, triplet, and k-prefix lower bounds.\n- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.005s execution time.\n- **Feedback**: The portfolio of orderings plus local improvements and a bounded binary search produced balanced KVPR and strong robustness. Lexicographic scoring and feasibility checks kept placements valid, while capped search and tie-breakers maintained speed.\n**Program Identifier:** Generation 45 - Patch Name multi_order_tpacker - Correct Program: True\n\n**Program Name: Min-max KVPR GPU model placement**\n- **Implementation**: Partitions models into memory-only (slo==0) and active, placing memory-only by largest-first onto GPUs with most remaining memory. Uses a greedy global min-max assignment ordered by critical weight dR/(S - size), then performs hill-climbing and light simulated annealing (moves and swaps) with strict memory checks and tie-breakers to minimize peak KVPR.\n- **Performance**: Combined score 23.68, max_kvpr 22.683, success_rate 1.000, execution_time 0.002s.\n- **Feedback**: The critical-weight ordering plus targeted local improvements reliably found feasible, low-pressure placements quickly. Minor tuning of annealing parameters or move budgets might further reduce the maximum KVPR while maintaining the algorithm\u2019s speed and robustness.\n**Program Identifier:** Generation 46 - Patch Name annealed_flow_equalizer - Correct Program: True\n\n**Program Name: Greedy-Bisection KVPR Balancer**\n- **Implementation**: Greedy min-max assignment with lookahead and deterministic tie-breaking across multiple initial orderings, followed by local move/swap refinement to reduce peak KVPR. A binary search over target KVPR uses transformed bin-packing (w = dR + T*size) with multiple ordering/rule variants, adopting and optionally refining the best result.\n- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.022s.\n- **Feedback**: Heuristics plus parametric search consistently found feasible, well-balanced placements that minimize worst-case KVPR; tie-breakers and local refinements likely improved stability. The algorithm is very fast and passed all validation tests.\n**Program Identifier:** Generation 47 - Patch Name multi_variant_tpacker_and_refine - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement with Slack Equalization**\n- **Implementation**: Pre-packs memory-only models by largest-first memory balancing, then places demand-bearing models using a slack-equalization heuristic with weights w = dR + T*size, guided by strong lower bounds (per-item, global, pair, triplet, k-prefix) and a multiplicative sweep to find feasible T. Uses multiple ordering strategies, hybrid scoring (slack, projected KVPR, memory balance), mid-placement T retuning, local move/swap refinement, and a greedy fallback for infeasible cases.\n- **Performance**: Combined score 25.59; max_kvpr 24.589; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: Robust feasibility and stability stem from tight lower bounds and a reliable fallback, while the hybrid scoring and T retuning help achieve low KVPR quickly. Fixed GPU_MEM_SIZE and attribute-based model assumptions keep it fast and reproducible but may reduce flexibility across varying hardware settings.\n**Program Identifier:** Generation 48 - Patch Name kvslack_hybrid_prepack - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Builds multiple candidates via a parametric T-based transformed packing (with analytical lower bounds, multiple orderings, and resid/minmax/hybrid policies) and a KVPR-aware regret insertion plus memory packers. Applies local search (single moves, swaps, targeted 2-opt) to reduce the global max KVPR and selects the best measured placement.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.033s.\n- **Feedback**: The T-guided candidate generation combined with KVPR-aware tie-breaking and local search delivers low max pressure with very fast runtimes. Rigorous feasibility checks and diverse fallbacks ensured 100% success and the program passed all validation tests.\n**Program Identifier:** Generation 49 - Patch Name triplet_hybrid_and_2opt - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Model Placement**\n- **Implementation**: Uses tight lower bounds (individual, global, pair, triplet, k-prefix) and searches a KVPR threshold T via exponential+binary search with packing by transformed weight n+T*m, multiple orderings (intrinsic, per-GB) and policies (residual/minmax/hybrid), seeded by zero-demand memory balancing. Generates diverse candidates, selects by (max, second, avg) KVPR, then applies local improvements (moves, swaps, bounded 2-opt).\n- **Performance**: Achieved combined score 25.76 (max_kvpr 24.760), 100% success rate, and 0.011s runtime.\n- **Feedback**: The combination of strong bounds, diversified heuristics, and targeted local search yields robust feasibility and low peak pressure, explaining the perfect success and speed. Zero-demand pre-placement and careful tie-breaking/numeric safeguards help balance memory and avoid false infeasibility.\n**Program Identifier:** Generation 50 - Patch Name preplace_zero_demand_and_seeded_pack - Correct Program: True\n\n**Program Name: Parametric Min-Max KVPR Placement with Local Search**\n- **Implementation**: Builds multiple candidate placements via a parametric T-based transformed packing (tightened with lower bounds and binary search), a KVPR-aware regret-based insertion, and memory-oriented heuristics, then refines each with iterative move/swap and targeted 2-opt between worst GPUs to reduce the global max KVPR. Uses robust validations, safe division, and epsilon guards, finally selecting the placement with the lowest measured max KVPR.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.032s.\n- **Feedback**: Diverse candidate generation plus local refinement reliably found low-pressure, feasible placements with perfect success and very low runtime, passing all validation tests. The fixed GPU_MEM_SIZE=80 constant and heuristic parameters (e.g., T-neighborhood, eps) worked well here but may require adjustment for different hardware profiles.\n**Program Identifier:** Generation 51 - Patch Name triplet_kprefix_hybrid_pack - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement**\n- **Implementation**: Generates multiple initial placements via parametric T-based transformed packing (with tight lower bounds and exponential/binary search), regret-based insertion, and memory heuristics, then applies bounded local search (single moves, swaps, targeted 2-opt) to minimize the global max KVPR. Uses KVPR-aware tie-breaking, strict feasibility checks, and an 80 GB per-GPU constraint, selecting the best candidate by measured max KVPR.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.047s.\n- **Feedback**: Evaluation confirms correctness and full pass on all tests; multi-strategy seeding plus local improvement achieves strong KVPR reduction with low latency. Hard-coded capacity and careful numerical safeguards enhanced robustness and consistent feasibility across cases.\n**Program Identifier:** Generation 52 - Patch Name none - Correct Program: True\n\n**Program Name: KVPR-Minimizing Multi-Strategy GPU Model Placement**\n- **Implementation**: Combines a parametric T-based packing (with transformed weight w(T)=n+T*m and lower-bound-driven binary search) with regret-based insertion, memory-aware packing fallbacks, and a KVPR-focused local search (moves, swaps, targeted 2-opt). Robust validation (memory/SLO checks) and a measured max-KVPR selector choose the best improved candidate.\n- **Performance**: Combined score 26.24 with max_kvpr 25.238, 100% success rate, and ~0.047s execution time.\n- **Feedback**: Passed all validation tests; the multi-heuristic initialization plus local refinement effectively reduces peak KVPR while ensuring feasibility and speed. Results suggest the ordering/policy mix and T-search are well-calibrated for low pressure and quick convergence.\n**Program Identifier:** Generation 53 - Patch Name triplet_and_hybrid_norm_fix - Correct Program: True\n\n**Program Name: KVPR-Aware Multi-Stage GPU Placement**\n- **Implementation**: Combines a parametric T-based transformed packing (with individual/global/pair/triplet/k-prefix lower bounds, exponential+binary T search, multiple orderings/policies, and adaptive retuning) with a KVPR-focused regret insertion and memory heuristics, followed by local search (single moves and targeted swaps) and lexicographic KVPR tie-breaking.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.052s.\n- **Feedback**: The near-optimal T search plus KVPR-aware local improvements effectively minimized peak pressure, while multi-candidate generation improved robustness and feasibility. Evaluation shows 100% success with very fast runtime and strong KVPR performance across test cases.\n**Program Identifier:** Generation 54 - Patch Name dynamic_t_retune_and_better_tiebreak - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR Minimizer**\n- **Implementation**: Uses lower-bound\u2013guided T-sweep with balanced-slack packing (weight w = dR + T*s), multiple ordering/selection rules, intrinsic seeding, and light randomization; includes a greedy min-local-KVPR fallback and targeted move/swap local search with strict memory checks.\n- **Performance**: Combined score 36.90; max_kvpr 35.898; success_rate 1.000; execution_time 0.002s.\n- **Feedback**: Passed all validation tests; tight bounds plus refinement yielded consistently feasible, low-pressure placements with very low runtime. Robust handling of slo=0 and infeasible placements enhanced stability across cases.\n**Program Identifier:** Generation 55 - Patch Name kvpr_balanced_slack_plus - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Uses a greedy min-max assignment with lookahead and rigorous tie-breaking, followed by local improvements (move, swap, and two-hop eject chains). It evaluates multiple model orderings, then applies a parametric refinement via binary search on a KVPR target using transformed best-fit decreasing packing with analytical lower bounds; memory-only models are placed afterward by remaining capacity.\n- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.003s execution time.\n- **Feedback**: The blend of multi-ordering greedy placement, local search, and parametric BFD refinement produced robust, balanced allocations across all tests. Strong lower bounds and efficient tie-breakers kept the search tight and fast, while the method reliably met constraints in all cases.\n**Program Identifier:** Generation 56 - Patch Name preplace_memonly_and_seeded_bsearch - Correct Program: True\n\n**Program Name: Min-max KVPR GPU Placement**\n- **Implementation**: Combines parametric T-based transformed packing (with tight lower bounds, exponential+binary search, and multiple orderings/policies) with a KVPR-aware regret-insertion heuristic and memory-based fallbacks. It selects the best of several candidates after a local-search phase (single moves, swaps, targeted 2-opt between worst GPUs) to minimize measured max KVPR.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.038s.\n- **Feedback**: The algorithm is correct, robust, and fast; diverse candidate generation plus local refinement likely drive the strong KVPR outcome and 100% feasibility. Note the fixed GPU_MEM_SIZE=80 GB assumption; otherwise, evaluation indicates reliable performance across cases.\n**Program Identifier:** Generation 57 - Patch Name tighten_bounds_and_feasibility - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement via Parametric Search**\n- **Implementation**: Combines parametric T-based transformed packing (lower-bound tightening, exponential/binary T search, multiple orderings/policies, and mid-course retuning) with KVPR-aware regret insertion and memory-oriented fallbacks. A local search phase (single moves and targeted swaps) further reduces the global maximum KVPR.\n- **Performance**: Achieved combined score 26.24 with max_kvpr 25.238, 100% success rate, and 0.040s execution time.\n- **Feedback**: Diverse candidate generation plus local improvement ensured robustness and fast runtime, yielding consistent feasibility and strong max-KVPR minimization. Further gains may come from tuning hybrid weights (alpha/beta) and T-neighborhood breadth.\n**Program Identifier:** Generation 58 - Patch Name adaptive_retune_T_and_expand_combos - Correct Program: True\n\n**Program Name: Slack-equalization KVPR placement with refinement**\n- **Implementation**: Computes strong lower bounds for target KVPR T, then uses a slack-equalization packer (weight w = dR + T*size) with multiple orderings, tight-feasibility selection, and light randomization to find a feasible placement; falls back to a KVPR-aware greedy heuristic when needed. Post-optimization applies targeted local moves/swaps on the most loaded GPU and selects the best among T-based, refined, and greedy-refined placements; handles slo==0 safely and enforces 80GB per-GPU memory.\n- **Performance**: Combined score 36.90 with max_kvpr 35.898, success_rate 1.000, and execution_time 0.002s.\n- **Feedback**: Evaluation indicates the bound-guided T search plus local refinement yields consistently feasible, low-KVPR placements with very low runtime. The robust fallback and handling of edge cases (e.g., slo==0) contributed to reliability, passing all validation tests.\n**Program Identifier:** Generation 59 - Patch Name balanced_slack_greedy_mix - Correct Program: True\n\n**Program Name: Min-Max KVPR Placement with Parametric and Local Search**\n- **Implementation**: Builds multiple placements via a parametric T-based packing that derives tight lower bounds (individual, global, pair, triplet, k-prefix) and uses greedy policies (residual/minmax/hybrid) with mid-placement T retuning; augments with regret-based insertion and memory heuristics. Candidates are refined by local search (best-improving moves, swaps, targeted 2-opt) and selected by a (max, second, avg) KVPR tie-break.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.049s.\n- **Feedback**: The bound-driven T search plus local refinement consistently produced feasible, low-pressure placements with strong robustness from numerical safeguards and capacity checks. Minor gains may be possible by tuning hybrid weights or variant coverage, but the approach already passes all validations efficiently.\n**Program Identifier:** Generation 60 - Patch Name kvpr_balanced_parametric_retune - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Combines a parametric T-based transformed packing (with tight lower bounds and binary search) with multiple heuristic initializers (regret-based insertion; memory-oriented dual/best-fit) across several ordering/policy variants. Applies iterative local search (moves, swaps, targeted 2-opt) and a donation-first refinement to reduce peak KVPR, with strict feasibility checks to avoid infinite pressures.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.046s.\n- **Feedback**: Parametric search provided strong initial placements, and local improvements reliably lowered the maximum pressure. The method is robust and fast, indicating effective candidate generation and tie-breaking choices.\n**Program Identifier:** Generation 61 - Patch Name donation_first_refine_and_resid_guard - Correct Program: True\n\n**Program Name: Beam search model placement minimizing KVPR**\n- **Implementation**: Uses a beam search with difficulty-based item ordering, GPU ranking by projected max KVPR, and lower-bound pruning (global feasibility and item-based bounds). Includes robust validation, a greedy fallback when the beam stalls, and a polishing phase that donates models from worst to best GPUs to reduce peak KVPR.\n- **Performance**: Combined score 22.96; max_kvpr 21.963; success_rate 1.000; execution_time 0.008s.\n- **Feedback**: Effective heuristics and bounds yield high-quality, balanced placements with very low runtime. The fallback and polishing steps enhance robustness and helped achieve a perfect success rate across tests.\n**Program Identifier:** Generation 62 - Patch Name beam_bounded_minmax - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR Model Placement**\n- **Implementation**: Multi-stage allocator that pre-places memory-only models, computes strong lower bounds (single/global/pair/triplet/prefix), then packs remaining models via a balanced-slack scheme (w = dR + T*s; K_g = T*S - (sumR_g + T*used_mem_g)) with multiple orderings, seeding, and a mid-pack T update. It augments this with a multiplicative sweep to find feasible T, candidate-T refinement, greedy multi-order fallback with local improvements, binary search on T, and final local move/swap refinement; deterministic randomness and strict memory checks are included.\n- **Performance**: Combined score 29.35; max_kvpr 28.347; success_rate 1.000; execution_time 0.006s.\n- **Feedback**: The algorithm is correct and passes all validation tests, achieving high reliability and very low runtime. Diverse heuristics (balanced-slack + greedy + local search) and strong bounds deliver robust KVPR minimization while ensuring feasibility through safe fallbacks.\n**Program Identifier:** Generation 63 - Patch Name preplace_mem_only_and_residual_T - Correct Program: True\n\n**Program Name: Greedy LNS KVPR GPU Placer**\n- **Implementation**: Uses a greedy min-max placement minimizing resulting global KVPR (R/remaining_mem) with tie-breaks, pre-placing slo==0 \u201cmemory-only\u201d models and trying two orderings. Then applies a ruin-and-recreate Large Neighborhood Search to improve the best candidate, with final safety fallbacks and a fixed 80 GB/GPU memory limit.\n- **Performance**: Combined score 0.00 (max_kvpr 0.000; success_rate 0.000; execution_time 0.000s).\n- **Feedback**: Fails all validation due to a syntax error in LNS selection (\u201cdel sel[k:] if \u2026\u201d is invalid), preventing execution. The assumption that slo==0 implies zero KV demand may also misalign with the evaluator and hurt feasibility; fix the syntax and verify slo==0 handling.\n**Program Identifier:** Generation 64 - Patch Name lns_memory_balancing - Correct Program: False\n\n**Program Name: Min-Max KVPR GPU Model Placement**\n- **Implementation**: Greedy min-max seeding followed by a bounded branch-and-bound over top-P \u201cdanger\u201d items (n/(S\u2212s) with a size bias), using tight pruning via current/global lower bounds, a Hall-type memory feasibility check, symmetry pruning on identical GPU states, and a node budget (60k). Remaining items are completed with the same greedy placer; deterministic tie-breaks and feasibility checks ensure fast, valid placements under 80 GB/GPU.\n- **Performance**: Combined score 25.57; max_kvpr 24.565; success_rate 1.000; execution_time 0.050s.\n- **Feedback**: The greedy+B&B hybrid achieves consistently feasible, low-peak KVPR placements with very low runtime due to effective pruning and ordering. Design choices (top-P focus, Hall feasibility, and symmetry pruning) are the main contributors to both the perfect success rate and the strong KVPR reduction within tight time bounds.\n**Program Identifier:** Generation 65 - Patch Name bnb_waterfill_minmax - Correct Program: True\n\n**Program Name: Greedy-LNS KVPR Placement**\n- **Implementation**: Pre-places memory-only models (slo==0) by best-fit, then greedily minimizes the resulting global max KVPR across GPUs over multiple deterministic orderings, followed by a bounded Large Neighborhood Search (donations, swaps, and small ruin-and-recreate). Assumes uniform 80 GB per GPU, uses KVPR = demand/remain with tie-breakers, and enforces a final memory safety check.\n- **Performance**: Combined score 0.00; max_kvpr 0.000; success_rate 0.000; execution_time 0.000s.\n- **Feedback**: Strict preplacement that raises on infeasible memory-only fits and a hardcoded 80 GB capacity likely misaligned with test conditions, causing failures and zero pass rate. Make capacity dynamic from inputs and avoid exceptions (graceful degradation) to improve robustness and success.\n**Program Identifier:** Generation 66 - Patch Name lns_donation_swap - Correct Program: False\n\n**Program Name: KVPR-Minimizing Multi-GPU Placement via Parametric Packing**\n- **Implementation**: Uses a parametric T-based transformed packing with tight lower bounds (individual/global, pair, triplet, k-prefix), exponential/binary search on T, regret-based insertion, memory-aware fallbacks, and local improvement (move/swap/2-opt) to minimize max KVPR. It deduplicates/prunes candidates, scores by measured KVPR, and includes numerical safeguards and tie-breaking.\n- **Performance**: Combined score 26.22; max_kvpr 25.215; success_rate 1.000; execution_time 0.009s.\n- **Feedback**: Multi-start candidate generation plus targeted local search delivered consistently feasible, balanced placements with very low runtime. The lower-bound-guided T search and hybrid placement policies likely contributed to the strong min-max KVPR performance and perfect pass rate.\n**Program Identifier:** Generation 67 - Patch Name none - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Uses a parametric T-based transformed packing with lower-bound-guided exponential/binary search to directly minimize max KVPR, augmented by regret-based insertion and memory-oriented packing fallbacks. It generates multiple candidates across orderings/policies with mid-placement T retuning, then applies local search (targeted moves/swaps) and selects via (max, second, average) KVPR tie-break; strict input validation and 80 GB/GPU constraints enforced.\n- **Performance**: Combined score 25.79; max_kvpr 24.785; success_rate 1.000; execution_time 0.005s.\n- **Feedback**: Passes all validation tests; the multi-start plus local refinement strategy achieves strong KVPR minimization with high robustness and very low runtime. Fallback strategies and careful tie-breaking improve feasibility and stability across diverse model sets.\n**Program Identifier:** Generation 68 - Patch Name targeted_moves_and_candidate_pruning - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement**\n- **Implementation**: Multi-strategy pipeline combining a parametric T-based transformed packing (with tight lower bounds and multiple orderings/policies) to generate candidates, followed by a KVPR-aware regret insertion and memory-oriented packers as fallbacks. A local search phase (donation moves and bounded swaps) refines candidates, and the best placement is selected by measured max KVPR under strict capacity/feasibility checks.\n- **Performance**: Combined score 24.98; max_kvpr 23.979; success_rate 1.000; execution_time 0.011s.\n- **Feedback**: The solution is correct and passes all validation tests, showing robustness with a 100% success rate and very low latency. The hybrid candidate generation plus local improvement effectively keeps maximum KVPR low while ensuring feasibility across diverse cases.\n**Program Identifier:** Generation 69 - Patch Name donation_first_local_refinement - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Multi-stage heuristic minimizing per-GPU KVPR: parametric T-based packing guided by lower bounds (individual/global/pair/triplet/k-prefix) with mid-placement T retune, plus regret-based insertion, memory-oriented fallbacks, and a local search (donations and bounded swaps). Handles slo==0 as memory-only, enforces feasibility (per-model and total memory), and selects the best placement via (max, second, avg) KVPR tie-break.\n- **Performance**: Combined score 24.82; max_kvpr 23.824; success_rate 1.000; execution_time 0.006s.\n- **Feedback**: The T-search with hybrid policy and local refinement consistently produced low max KVPR while remaining extremely fast. Pre-placing memory-only models and generating multiple candidate placements improved robustness, yielding a 100% success rate across tests.\n**Program Identifier:** Generation 70 - Patch Name kvpr_minmax_prepack_retune_v2 - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Model Placement via Slack Balancing**\n- **Implementation**: Computes multi-source lower bounds on optimal KVPR, then multiplicatively searches T and packs models with a balanced-slack heuristic (weight w=dR+T*s) using several orderings, deterministic seeding, and strict feasibility checks. It then probes nearby T values, runs a light binary search, and applies a focused move/swap local search, with a robust greedy KVPR-minimizing fallback for infeasible or edge cases (e.g., SLO==0).\n- **Performance**: Combined score 89.76 with max_kvpr 88.755, success_rate 1.000, and execution_time 0.006s.\n- **Feedback**: The approach is fast and consistently feasible, passing all validation tests while keeping peak KVPR low. The layered search (sweep + variants + local refinement) appears to find high-quality placements quickly; the SLO==0 handling via fallback improves robustness without hurting speed.\n**Program Identifier:** Generation 71 - Patch Name t_sweep_bsearch_and_variants - Correct Program: True\n\n**Program Name: KVPR-balanced placement via slack equalization**\n- **Implementation**: Computes tight lower bounds on target KVPR (T) and uses a slack-equalization packer (weight w = dR + T*s) with multiple orderings, followed by short local move/swap refinement and a KVPR-aware greedy fallback. Handles slo==0 safely, enforces memory constraints, and uses deterministic seeding for stability.\n- **Performance**: Combined score 26.06; max_kvpr 25.062; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Lower-bound\u2013guided search rapidly finds feasible, low-KVPR placements; the local refinement and greedy baseline improve robustness with negligible overhead. Deterministic randomness and guards for zero-SLO/infinite ratios aid reliability, though reliance on a fixed 80GB GPU size and fallback for infeasible cases may affect rare edge scenarios.\n**Program Identifier:** Generation 72 - Patch Name balanced_slack_crossover - Correct Program: True\n\n**Program Name: KVPR-Minimizing Multi-Strategy Placement**\n- **Implementation**: Uses a parametric T-based transformed packing with bounds (individual/global/pair/triplet/k-prefix), exponential/binary search for feasible T, and policies (resid/minmax/hybrid) to generate placements; adds regret-based insertion and memory-pack heuristics, then applies local search (single-move, swap, targeted 2-opt) and lexicographic scoring to select the best. Robust input validation and safe numerical handling ensure feasibility and stability.\n- **Performance**: Combined score 26.24 with max_kvpr 25.238, 100% success rate, and 0.046s execution time.\n- **Feedback**: Evaluation indicates the multi-start candidate generation plus local improvements effectively minimizes peak KV cache pressure while maintaining speed. The bound-tightened T search and regret-aware placement likely drive high solution quality across diverse cases.\n**Program Identifier:** Generation 73 - Patch Name tighten_t_search_and_tiebreak - Correct Program: True\n\n**Program Name: KVPR-balanced slack bin-packing for GPU placement**\n- **Implementation**: Uses a slack-equalization packer parameterized by T with item weights w = dR + T*s, exploring multiple orderings and randomized tie-breaking, followed by binary search over T and local move/swap refinements. Includes strong lower bounds to seed T, a robust greedy fallback, and explicit handling for slo==0 plus final memory safety checks.\n- **Performance**: Combined score 89.76; max_kvpr 88.755; success_rate 1.000; execution_time 0.006s.\n- **Feedback**: The multi-stage pipeline (bounds \u2192 feasibility sweep \u2192 multi-variant assignment \u2192 local refinement) reliably achieves low max KVPR and consistently valid placements, outperforming the greedy baseline while remaining fast. Special-case handling of zero-SLO models and final safety validation enhance robustness without notable overhead.\n**Program Identifier:** Generation 74 - Patch Name allow_slo0_in_tpacker - Correct Program: True\n\n**Program Name: KVPR-Aware Parametric Packing with Local Search**\n- **Implementation**: Multi-strategy solver combining parametric T-based transformed packing (w = n + T*m) with lower-bound estimation (individual, global, pair, triplet, k-prefix), exponential/binary search over T, and diversified orderings/policies. Falls back to regret-based insertion and memory-oriented heuristics, then runs move/swap local search and selects the best placement by lexicographic (max, second, avg) KVPR.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.061s.\n- **Feedback**: Parametric search produced strong initial placements and the local refinements consistently reduced the peak KVPR, yielding stable, high success with low runtime. Candidate diversity and robust tie-breaking improved robustness across cases while strict feasibility checks prevented invalid placements.\n**Program Identifier:** Generation 75 - Patch Name broaden_feasibility_variants_and_diversify_candidates - Correct Program: True\n\n**Program Name: KVPR-aware multi-heuristic GPU placement**\n- **Implementation**: Combines a parametric T-based packing (w = n + T*m) guided by tight lower bounds (individual, global, pair, triplet, k-prefix) with multiple orderings/policies, plus regret-based insertion and memory-first heuristics to generate candidates. Applies a KVPR-focused local search (best single moves, swaps, targeted worst/second-worst 2-opt, and zero-pressure redistribution) and selects the best measured max-KVPR placement.\n- **Performance**: Combined score 26.24 (success_rate 1.000, execution_time 0.046s) with reported max_kvpr 25.238.\n- **Feedback**: Evaluation indicates a correct, robust solver with excellent reliability and speed; the ensemble of candidates plus targeted local refinements likely drove the low peak KVPR. The careful feasibility checks and fallbacks ensure consistent placements across cases.\n**Program Identifier:** Generation 76 - Patch Name zero_n_memory_redistribution - Correct Program: True\n\n**Program Name: Parametric Minimax KVPR GPU Placement**\n- **Implementation**: Uses a parametric minimax formulation with tight lower bounds (individual/global/pair/triplet/k-prefix) to initialize T, followed by exponential+binary search, heavy-spread seeding, multiple item orderings, and mid-run retuning. It ensembles regret insertion and memory-pack fallbacks, then applies a local worst-to-best move refinement to polish placements.\n- **Performance**: Combined score 24.95; max_kvpr 23.953; success_rate 1.000; execution_time 0.016s.\n- **Feedback**: Passed all validation tests with consistently feasible, low-KVPR placements; the combination of bounds, diversified orderings, and refinement likely drives both quality and speed. Minor redundant bookkeeping in the seeding step does not affect correctness but could be simplified for clarity.\n**Program Identifier:** Generation 77 - Patch Name kvpr_balancer_pipeline - Correct Program: True\n\n**Program Name: KVPR Slack-Balancing Placement with Greedy Fallback**\n- **Implementation**: Computes dR=req_rate/slo and multiple lower bounds (per-item/global/pair/k-prefix), then searches a target KVPR T using a slack-equalization packer (w=dR+T*size) with several orderings, seeding, and randomized tie-breaks; feasibility is validated and T is tightened via multiplicative sweep and light binary search. Adds bounded local move/swap refinement and a robust greedy min-local-KVPR fallback, with strict memory safety checks.\n- **Performance**: Combined score 89.76 with max_kvpr 88.755, 100% success rate, and 0.006s execution time.\n- **Feedback**: Lower-bound-guided T search plus diverse orderings and local refinement reliably found low-pressure, feasible placements while maintaining speed; the greedy fallback ensured robustness on edge cases. Fixed GPU_MEM_SIZE (80 GB) and heuristic parameters may limit adaptability across heterogeneous hardware or shifting workloads.\n**Program Identifier:** Generation 78 - Patch Name enable_t_packing_for_memory_only_and_binary_search - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR Minimization with Greedy Fallback**\n- **Implementation**: Uses a balanced-slack bin-packing approach that sweeps T from strong lower bounds (per-item, global, pair, k-bin prefix) and packs by weight w=dR+T*s with multiple orderings, tightness rules, and deterministic tie-breaking, followed by local move/swap refinement. Provides a KVPR-aware greedy fallback and treats slo==0 as memory-only to ensure feasibility and memory safety.\n- **Performance**: Combined score 36.90; max_kvpr 35.901; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Evaluation shows robust, fast placements with perfect success; slack equalization plus local search consistently lowers max KVPR compared to greedy alone. Workloads with slo==0 trigger fallback paths but remain correct and memory-safe.\n**Program Identifier:** Generation 79 - Patch Name kvpr_balanced_greedy_and_eval_fixes - Correct Program: True\n\n**Program Name: Dual-driven KVPR Minimization Placement**\n- **Implementation**: Places SLO=0 models via largest-first bin packing, then seeds active models with a greedy minimax KVPR placement. Refines using dual-sensitivity (alpha/beta) water-filling rebalancing, targeted moves, limited swaps, and single-item descent, with safety checks and a greedy fallback.\n- **Performance**: Combined score 25.55; max_kvpr 24.548; success_rate 1.000; execution_time 0.001s.\n- **Feedback**: Consistently produced feasible, low-pressure placements and passed all validations. Dual-driven balancing and swap/descent phases reduced worst-GPU pressure with negligible overhead; the fixed 80GB GPU memory assumption and capped move budgets are notable design choices.\n**Program Identifier:** Generation 80 - Patch Name dual_waterfill_rebalance - Correct Program: True\n\n**Program Name: Slack-equalized KVPR GPU placement**\n- **Implementation**: Uses a lower-bound-driven search over KVPR threshold T and a slack-equalization packer (weight w = dR + T*s) with multiple orderings, tight/min-kvpr tie-breaks, and deterministic seeding; treats slo==0 as memory-only, then applies a greedy fallback and a bounded local move/swap refinement. Includes per-item/pair/global/k-bin bounds, a multiplicative sweep to first feasibility, light binary search, and strict memory/KVPR validation.\n- **Performance**: Combined score 89.76 with max_kvpr 88.755, success_rate 1.000, and execution_time 0.006s.\n- **Feedback**: The method is correct and consistently feasible; multi-bound initialization plus local refinement likely drive the strong score while keeping runtime very low. Robust edge-case handling (e.g., slo==0) and a greedy safety net improve reliability across tests.\n**Program Identifier:** Generation 81 - Patch Name kvpr_balanced_slack_refine - Correct Program: True\n\n**Program Name: KVPR-Balanced GPU Model Placement**\n- **Implementation**: Pre-places memory-only (slo=0) models largest-first, then assigns remaining models via slack-equalization around a target KVPR T (w = dR + T*size, K_g = T*S \u2212 (sumR + T*used_mem)), using a lower-bound\u2013guided feasibility sweep, multiple orderings, and a greedy fallback. It evaluates nearby T variants, then runs targeted local move/swap refinements and picks the placement with the lowest measured max KVPR under strict memory checks.\n- **Performance**: Combined score 36.90; max_kvpr 35.898; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Lower-bound initialization plus balanced slack packing produced consistent feasibility and low KVPR, with small randomized tie-breaks and local search yielding incremental gains. Robust handling of slo=0 and defensive fallbacks ensured reliability while maintaining excellent runtime.\n**Program Identifier:** Generation 82 - Patch Name preplace_memory_only_and_adjust_bounds - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Combines parametric T-based transformed packing (with analytical lower bounds, adaptive T retuning at 40%/75%, multiple orderings/policies, and jitter micro-restarts) with a regret-based KVPR insertion and memory-oriented heuristics to build diverse candidates. A KVPR-aware local search (single moves, swaps, bounded 2-opt) refines placements, and a lexicographic (max, second, avg) KVPR score selects the best.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.079s.\n- **Feedback**: The fusion of transformed packing with KVPR-focused local improvements yields consistently feasible, well-balanced placements and low worst-GPU pressure. Strong tie-breaking and validation (80 GB cap, SLO/rate checks) enhance robustness and efficiency across test cases.\n**Program Identifier:** Generation 83 - Patch Name none - Correct Program: True\n\n**Program Name: Multistage KVPR-Minimizing Placement**\n- **Implementation**: Generates diverse candidates via a T-parameterized min\u2013max packing (with lower bounds and binary search), regret-based insertion, and memory-oriented heuristics, then applies bounded move/swap local search plus donation refinement and selects the lexicographically best KVPR vector. Includes strict feasibility checks (per-GPU memory, infinite-KVPR avoidance) and deterministic tie-breaking to ensure robustness.\n- **Performance**: Combined score 26.24; max_kvpr 25.242; success_rate 1.000; execution_time 0.051s.\n- **Feedback**: Multi-start candidate generation followed by local refinement consistently reduced peak KVPR while keeping runtime low, yielding a perfect success rate. The parametric packing step appears to drive solution quality, with refinement steps smoothing worst-GPU outliers across test cases.\n**Program Identifier:** Generation 84 - Patch Name variants_ratio_lexi - Correct Program: True\n\n**Program Name: KVPR-Aware Multi-Strategy Placement**\n- **Implementation**: Combines a parametric T-based packing (with individual, global, pair, triplet, and k-prefix lower bounds, adaptive retuning, and multiple order/policy variants) with regret-based insertion, greedy min-max, and memory-oriented packers to generate diverse candidates. Applies a KVPR-focused local search (moves, swaps, targeted 2-opt) and selects the final placement via a lexicographic KVPR vector.\n- **Performance**: Achieved combined score 26.24 with max_kvpr 25.238, 100% success rate, and 0.077s runtime.\n- **Feedback**: Evaluation indicates the hybrid parametric-plus-local search approach is both robust and efficient, consistently finding feasible placements and reducing peak KVPR. Lexicographic scoring and KVPR-aware tie-breaking help balance pressure across GPUs, contributing to stability and low hotspots.\n**Program Identifier:** Generation 85 - Patch Name greedy_minmax_candidate_and_lexitiebreak - Correct Program: True\n\n**Program Name: Balanced KVPR Slack Packing with Local Refinement**\n- **Implementation**: Uses lower bounds (per-item, global, pair, k-bin) to seed a target KVPR T, then applies a slack-equalization packer with weight w = dR + T*s across several orderings and tie-breakers, followed by bounded local move/swap refinement. Includes a greedy KVPR-increase fallback, deterministic seeding, numeric tolerances, and strict memory/edge-case handling (e.g., slo==0 as memory-only).\n- **Performance**: Achieved combined score 36.51 (max_kvpr 35.512) with 100% success and 0.002s runtime.\n- **Feedback**: The solution is correct and passes all validation tests. Bound-guided search plus lightweight refinement delivers strong KVPR at very low latency, while the fallback ensures feasibility under tight or degenerate conditions.\n**Program Identifier:** Generation 86 - Patch Name treat_slo_zero_as_memory_only - Correct Program: True\n\n**Program Name: KVPR-Aware Multi-Strategy GPU Placement**\n- **Implementation**: Builds multiple candidate placements via a parametric T-based transformed packing (with tight lower bounds, exponential/binary search over T, multiple orderings/policies, and adaptive retuning at 40%/75%), regret-based insertion, and memory-centric heuristics, then applies local search (moves/swaps, targeted 2-opt) and a donation-first refinement before selecting by lexicographic KVPR score. Robust validation, feasibility checks, and careful tie-breaking minimize max KVPR while respecting 80 GB per-GPU memory.\n- **Performance**: Achieved combined score 26.24 with max_kvpr 25.238, 100% success rate, and 0.065s runtime; all validation tests passed.\n- **Feedback**: The multi-candidate strategy plus local refinement effectively lowers peak KVPR and ensures robustness across cases, with lexicographic scoring stabilizing selection. Runtime is already low; most gains likely come from the parametric packing\u2019s bound-driven search and the subsequent targeted local improvements.\n**Program Identifier:** Generation 87 - Patch Name add_refine_peak_postprocessing - Correct Program: True\n\n**Program Name: Minimax KV-Pressure GPU Placement**\n- **Implementation**: Separates memory-only (slo==0) from active models, pre-placing memory-only largest-first by remaining memory, then minimizes max KVPR via a bracketed search on T with a feasibility oracle using weights w = dR + T*size, per-GPU slack K, residual T retuning, and micro-restarts. Final placement is refined with local move-based optimization and compared against a greedy baseline; robust greedy fallbacks handle infeasibility.\n- **Performance**: Combined score 23.57; max_kvpr 22.575; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Layered lower bounds (item, global, pair, k-prefix, triplet) and the feasibility-driven search delivered correct, low-latency placements across tests. Safety nets and post-placement refinement likely improved robustness and consistency without harming speed.\n**Program Identifier:** Generation 88 - Patch Name kvpr_balanced_bsearch - Correct Program: True\n\n**Program Name: KVPR-Minimizing GPU Placement**\n- **Implementation**: Uses a slack-equalization packer with weight w = dR + T*s, guided by multi-bound lower estimates (per-item, global, pair, k-bin) and a multiplicative sweep to find feasible T, plus randomized tie-breaking and seeding. Includes a greedy KVPR-increase fallback and local refinement via targeted moves/swaps, selecting the best among multiple pack variants.\n- **Performance**: Combined score 89.76; max_kvpr 88.755; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Lower bounds and slack-based packing rapidly find feasible low-pressure placements, while local refinement and variant sweeps further reduce peak KVPR. Robust handling of SLO==0 and a safe greedy fallback ensure reliability and memory safety, achieving 100% success.\n**Program Identifier:** Generation 89 - Patch Name treat_slo0_as_memory_only_and_expand_variants - Correct Program: True\n\n**Program Name: Slack-equalized KVPR GPU Placement**\n- **Implementation**: Uses a T-parameter slack-equalization packer (weight w = dR + T*size) with intrinsic-pressure seeding, multiple orderings, and deterministic light randomization to minimize max KVPR. Tight lower bounds (per-item, global, pair/triplet, k-bin prefix) guide a multiplicative feasibility sweep and bisection bracketing; a targeted local move/swap search and a KVPR-minimizing greedy fallback ensure robustness and memory safety.\n- **Performance**: Combined score 95.04; max_kvpr 94.043; success_rate 1.000; execution_time 0.007s.\n- **Feedback**: Layered bounds, T-search, and local refinement collectively lower peak KVPR while maintaining feasibility, including explicit handling of slo=0. Extremely fast and consistently correct across tests, indicating strong practical efficiency and stability.\n**Program Identifier:** Generation 90 - Patch Name t_bracket_triplet_bound - Correct Program: True\n\n**Program Name: KVPR-Balanced GPU Model Placement**\n- **Implementation**: Pre-places memory-only models (slo==0) largest-first on GPUs with most free memory, then assigns demanders via a Lagrangian-style packing using weights w = dR + T*size, where T is initialized from multiple lower bounds and refined by feasibility sweep, binary search, and neighborhood probing. It ranks placements by lexicographic KVPR vectors, applies a quick local move refinement, and uses a robust greedy fallback when bounds or capacity checks fail.\n- **Performance**: Achieved combined score 22.86 with max_kvpr 21.857, 100% success rate, and 0.003s execution time.\n- **Feedback**: The bound-guided T search with mid-course retuning balances KV pressure effectively while keeping runtime minimal, and lexicographic selection plus local refinement further trims worst-GPU KVPR. Greedy fallback and strict memory safety checks increase robustness on edge cases without degrading overall results.\n**Program Identifier:** Generation 91 - Patch Name kvpr_tsearch_prepack - Correct Program: True\n\n**Program Name: Hybrid slack-equalized KVPR GPU placement**\n- **Implementation**: Pre-places memory-only models, computes multi-source lower bounds for target KVPR T, then packs rate-bearing models via slack-equalization (w = dR + T*s, K_g = T*(S - used)) with multiple orderings and light randomization. It sweeps nearby T values, applies local move/swap refinement, compares against a greedy baseline, and returns the placement with the lowest measured max-KVPR.\n- **Performance**: Combined score 36.90; max_kvpr 35.901; success_rate 1.000; execution_time 0.003s.\n- **Feedback**: Lower-bound guided T search plus slack-balancing and local refinement effectively reduces peak pressure versus pure greedy while remaining fast. Robust greedy fallbacks and final memory-safety checks ensure consistent feasibility and contributed to the perfect success rate.\n**Program Identifier:** Generation 92 - Patch Name preplace_mem_only_and_residual_tpacking - Correct Program: True\n\n**Program Name: Balanced-Slack KVPR Minimization**\n- **Implementation**: Uses a lower-bounded search on target KVPR T with a balanced-slack packer (weight w = dR + T*s; slack K_g = T*S - (sumR + T*mem)) across multiple orderings, plus deterministic randomization, a greedy fallback, and local move/swap refinement; supports SLO=0 and strict 80 GB per-GPU memory checks. Lower bounds include per-item, global, pair, triplet, and k-bin prefix constraints, with multiplicative sweep and binary search to tighten T.\n- **Performance**: Combined score 95.04; max_kvpr 94.043; success_rate 1.000; execution_time 0.007s.\n- **Feedback**: Multi-bound bracketing and local refinement effectively reduce peak KVPR while maintaining feasibility and speed. Robust handling of edge cases (e.g., SLO=0, oversized items) and final memory safety checks contributed to passing all validation tests.\n**Program Identifier:** Generation 93 - Patch Name fix_t_bracket_triplet_bound - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placer**\n- **Implementation**: Uses a parametric T-based packing with strong lower bounds (individual/global, pair, triplet, k-prefix), binary search, and adaptive retuning, combined with regret-based insertion and KVPR-aware local search (single moves, swaps, and donation). Diversifies via multiple orderings/policies, improves each candidate locally, and selects the best by lexicographic per-GPU KVPR.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.060s.\n- **Feedback**: Adaptive T tuning and peak-shaving moves/swaps notably reduce the worst KVPR while fallbacks ensure feasibility and speed. Minor note: the __main__ demo prints the inverse of average KVPR, but this does not affect evaluation.\n**Program Identifier:** Generation 94 - Patch Name kvpr_balanced_placement_v5 - Correct Program: True\n\n**Program Name: MWU-based KVPR-Minimizing GPU Placement**\n- **Implementation**: Uses an MWU-based feasibility oracle over a KVPR threshold T with transformed weights w = n + T\u00b7ms and dual-priced greedy assignment, augmented by a small repair heuristic and multi-order restarts. It finds T via tight lower bounds, exponential search, and binary search, then probes nearby T and selects the placement with minimal measured max KVPR; includes strict validation and a memory-only best-fit fallback.\n- **Performance**: Achieved combined score 1.00 with max_kvpr 0.000, success_rate 1.000, and execution_time 0.184s.\n- **Feedback**: Multi-order restarts and the repair step effectively avoid local minima, yielding zero measured max KVPR on all test cases. The approach is both robust (passes all validations) and fast; the fallback likely triggers rarely given the strong feasibility search.\n**Program Identifier:** Generation 95 - Patch Name mwu_dual_bisection - Correct Program: True\n\n**Program Name: Min-max KVPR Multi-Strategy Placement**\n- **Implementation**: Combines a parametric T-based packing (with tight lower bounds, multi-ordering, and binary search) with a regret-based insertion, diversified memory-pack heuristics, and multi-stage local search (moves, swaps, targeted 2-opt), followed by peak-refinement. Robust validation, safe division guards, lexicographic KVPR tie-breaking, and diversified candidate generation ensure feasibility and quality.\n- **Performance**: Combined score 26.24; max_kvpr 25.242; success_rate 1.000; execution_time 0.092s.\n- **Feedback**: The approach reliably produced feasible, low-KVPR placements with fast runtime, passing all validation tests. Parametric search plus local refinements appear to drive the strong min-max KVPR outcome, while fallbacks add robustness without hurting performance.\n**Program Identifier:** Generation 96 - Patch Name midpack_t_retune - Correct Program: True\n\n**Program Name: KV Cache Pressure-Minimizing GPU Model Placement**\n- **Implementation**: Uses a feasibility search over pressure level T with tight lower bounds (individual/global/pair/triplet/k-prefix), exponential+binary search, and a balanced-slack assignment (n + T*m) to place models. It pre-places memory-only items, guards against fragmentation, applies micro-restarts with jitter, quick pre-refinement, regret/memory-pack fallbacks, and a bounded local move/swap improvement.\n- **Performance**: Combined score 26.01; max_kvpr 25.010; success_rate 1.000; execution_time 0.005s.\n- **Feedback**: The algorithm is correct and passes all validation tests, achieving consistently low max KVPR with very fast runtime. Robust handling of edge cases (e.g., slo<=0, fragmentation) and multiple heuristic fallbacks contribute to reliability and solution quality.\n**Program Identifier:** Generation 97 - Patch Name k_slack_microrestart - Correct Program: True\n\n**Program Name: Min-Max KVPR GPU Placement**\n- **Implementation**: Uses a parametric T-based packing with tight lower bounds and binary search, multiple orderings/policies (residual, minmax, hybrid), plus regret-based insertion and memory-pack fallbacks. It applies bounded local search (moves, swaps, targeted 2-opt) and a donation-first refinement, selecting the best placement via a (max, second, avg) KVPR tie-break.\n- **Performance**: Combined score 26.24; max_kvpr 25.238; success_rate 1.000; execution_time 0.045s.\n- **Feedback**: Evaluation indicates robust feasibility and fast runtime, with consistent minimization of peak KVPR across cases. The T-search + hybrid policy and subsequent local refinements likely drive the strong balance between solution quality and speed.\n**Program Identifier:** Generation 98 - Patch Name refine_peak_and_tuned_local - Correct Program: True\n\n**Program Name: Min-Max KVPR Multi-Strategy Placer**\n- **Implementation**: Uses a parametric T-based packing (with tight lower bounds: individual, global, pair, triplet, k-prefix), multiple orderings/policies, regret-based insertion, and memory-oriented heuristics to generate placements. Applies intensive local search (moves, swaps, targeted 2-opt, zero-pressure redistribution) and selects the best by lexicographic KVPR minimization with strong validation and numerical safeguards.\n- **Performance**: Combined score 26.24; max_kvpr 25.242; success_rate 1.000; execution_time 0.046s.\n- **Feedback**: The hybrid global T-search plus local refinements achieved low maximum KVPR with fast runtime and perfect feasibility. Diverse candidates and fallbacks improved robustness, while guards against zero-remaining-memory with load prevented infinite-pressure placements.\n**Program Identifier:** Generation 99 - Patch Name resid_guard_lexitiebreak_ratio_candidate - Correct Program: True",
  "meta_scratch_pad": "## Successful Algorithmic Patterns\n- Slack-equalized packing with K-after minimization around a target T is decisively best. Programs that implement K_g = T\u00b7S \u2212 (\u03a3R_g + T\u00b7used_mem_g) and place items by minimizing nonnegative K_after with weights w = dR + T\u00b7size achieved the top score 95.04 at 0.007s with 1.000 success (\u201cSlack-equalized KVPR GPU Placement,\u201d Gen 90, t_bracket_triplet_bound; \u201cBalanced-Slack KVPR Minimization,\u201d Gen 93, fix_t_bracket_triplet_bound). This matches the current best program\u2019s implementation and explains its dominance.\n- Tight, layered lower bounds plus compact T discovery and bracketing improve quality. Adding pair, lightweight triplet, and k-bin prefix bounds to per-item and global bounds, then using a multiplicative feasibility sweep followed by binary bracketing and a small T-neighborhood probe, lifted the top cluster from the previous 89.76 to 95.04. This pattern is explicit in Gen 90/93 and the current best code (triplet and k-prefix bounds, sweep, bracket, probe).\n- Light diversification and local refinement trim peak KVPR with negligible cost. Multiple orderings (w_desc, intrinsic_desc, size_desc, density_desc), deterministic light randomization, intrinsic-pressure seeding, and a bounded worst-GPU-focused move/swap loop reduced max KVPR further while keeping runtimes at ~0.007s (Gen 90/93 and current best).\n- Robustness without penalty: explicit handling of slo==0 (treat as dR=0 with greedy fallback) and strict memory/KVPR validation sustained 1.000 success across all top performers (Gen 90/93; current best).\n\n## Ineffective Approaches\n- Parametric pipelines without K-after selection plateaued around 26.24 despite heavy heuristics. \u201cMin-Max KVPR GPU Placer\u201d (Gen 94, 26.24, 0.060s), \u201cMin-max KVPR Multi-Strategy Placement\u201d (Gen 96, 26.24, 0.092s), and similar variants (Gen 98/99, 26.24 at 0.045\u20130.046s) relied on regret-based insertion, multi-order policies, and extensive local search but lacked T-feasible K-after decisioning; they failed to approach 95.04.\n- Partial slack equalization without compact T control underdelivered. \u201cHybrid slack-equalized KVPR GPU placement\u201d (Gen 92, 36.90, 0.003s) used slack packing (w = dR + T\u00b7s, K-based assignment) and local refinement but only swept nearby T values; absence of tight bracketing and aggressive T tightening left a large quality gap to the 95.04 cluster.\n- Transformed-weight/dual-driven methods mismatched the evaluation objective. The MWU-based approach (Gen 95, 1.00 combined, 0.184s) with w = n + T\u00b7ms and dual prices reported zero max KVPR yet achieved the worst combined score, indicating a metric mismatch or numerical artifact; regardless, it clearly underperformed relative to K-after slack equalization.\n- Added heuristic complexity without aligning to T-feasible assignment increased runtime without gains. Multi-operator local searches (moves/swaps/2-opt, donation) and lexicographic tie-breaks in the 26.xx cluster raised runtime (0.045\u20130.092s) but did not close the KVPR gap versus K-after-based methods.\n\n## Implementation Insights\n- What makes the current best program effective:\n  - Layered lower bounds (per-item, global, pair over top-200, lightweight triplet over top-by-size, and k-prefix up to k=6) seed a precise T; a multiplicative sweep to the first feasible T, proper bracketing, and neighborhood probing deliver a compact, high-quality T range (Gen 90/93; current best).\n  - K-after selection rule enforces T-feasibility during packing: initialize K_g = T\u00b7S; each placement consumes w = dR + T\u00b7size; choose GPU minimizing nonnegative K_after with tie-breaks by min-KVPR or memory slack. This tight control is absent in the 26.xx cluster and explains the 95.04 vs ~26.24 gap.\n  - Deterministic light randomization and multiple orderings stabilize and diversify packing without cost. The current best mirrors Gen 90/93 with orderings (w_desc, intrinsic_desc, size_desc, density_desc), intrinsic-pressure seeding, and small jitter among near-equal K_after candidates.\n  - Bounded worst-GPU local refinement (move/swap budgets \u224818/8) consistently shaves peak KVPR with trivial overhead, outperforming broader local searches used in the 26.xx cluster that add runtime but not quality.\n- Coding patterns tied to robustness and speed:\n  - Explicit slo==0 handling (dR=0) and a greedy KVPR-minimizing fallback preserve feasibility; strict memory/T checks maintain 1.000 success (current best; Gen 90/93).\n  - Deterministic RNG keyed to problem size and GPU count ensures repeatability while enabling tiny exploratory variation\u2014beneficial for stability across tests at ~0.007s runtime.\n\n## Performance Analysis\n- Clear top performers at 95.04 with ~0.007s runtime and perfect success: \u201cSlack-equalized KVPR GPU Placement\u201d (Gen 90) and \u201cBalanced-Slack KVPR Minimization\u201d (Gen 93), both using K-after slack equalization, layered bounds, compact T search/bracketing, and bounded local refinement. The current best program matches this pattern and these metrics (Combined 95.04; max_kvpr 94.043; 1.000 success; 0.007s).\n- Mid-tier slack variants (Gen 92, 36.90, 0.003s) confirm that slack balancing helps but is insufficient without tight T control; they remain far below the 95.04 cluster despite being extremely fast.\n- The 26.xx cluster (Gen 94/96/98/99 at 26.24, 0.045\u20130.092s; Gen 97 at 26.01, 0.005s) shows that parametric T handling without K-after assignment and with heavier local search yields stable feasibility but poor KVPR reduction relative to the best.\n- The MWU/dual-based method (Gen 95, 1.00, 0.184s) demonstrates that alternative transformed-weight feasibility oracles do not align with the evaluation\u2019s objective, reinforcing that K-after slack equalization around a carefully bracketed T is the reliable path to top scores.",
  "meta_recommendations": "1. Pre-place memory-only (slo==0) models before T-based packing\n   - Split models into M0 (slo==0) and M+ (slo>0). Place M0 largest-first onto GPUs with the most remaining memory (tie-break by fewest models), freeze per-GPU capacities Sg, then recompute lower bounds and run the K-after slack-equalization on M+ with K_g initialized to T\u00b7Sg. This preserves T-feasibility and avoids having zero-rate items distort the K-equalization, matching the robustness pattern observed in the best programs.\n\n2. Residual-aware mid-placement T retuning inside assign_balanced_slack\n   - After about 40% of items are placed, compute a residual lower bound using the remaining items and the current per-GPU free memory (aggregate to S_total_rem and remaining total size). If residual_lb > 1.02\u00b7T, set T' = residual_lb, recompute weights w = dR + T'\u00b7size, resort the remaining items by w, and continue; optionally do a light second retune at ~75% placed (update T in-place without reordering). This keeps the K-after decision rule tightly aligned with feasibility as the instance evolves, mirroring the \u201ccompact T control\u201d that drives the 95.04 cluster.\n\n3. Micro-restarts with tiny K-jitter, deterministic seed tweaks, and lexicographic selection\n   - For the best T candidate, run 3\u20135 micro-restarts that keep the same ordering but initialize K_g = T\u00b7Sg + \u03b5\u00b7g (\u03b5 \u2248 1e-6\u00b7T\u00b7S_total) and slightly vary a deterministic RNG seed; keep the K-after rule and current tie-breaks. Choose the winner by lexicographic KVPR vectors (sorted descending per-GPU), and add a quick pre-refinement: attempt moving the top-2 w items from the worst GPU to the GPU with the largest nonnegative K that fits before the full local search. This light diversification consistently shaved peaks in top performers without runtime spikes.\n\n4. K-aware local refinement focused on slack equalization at T*\n   - Add a short post-pack loop that uses K_g = T*\u00b7S \u2212 (\u03a3R_g + T*\u00b7used_mem_g): repeatedly pick the worst-KVPR GPU, then attempt moving or swapping its highest-w items to GPUs with the largest K such that K_after \u2265 0 and memory fits; run \u226412 moves and \u22646 swaps. Prefer moves that increase the minimum K across GPUs or reduce the variance of K. This targets the same K-equalization principle that made the main packer strong and typically improves on the current KVPR-only refine.\n\n5. Adaptive tie-breaking and seeding for heavy items to stabilize K and memory slack\n   - In the main K-after selection, when multiple GPUs have near-equal K_after, tie-break by minimizing the resulting sum of squared K across GPUs (proxy for K variance), then by larger memory slack; compute this in O(G) per item. In seeding, explicitly spread all models with size > S/2 (or top-H by size) across distinct GPUs first (subject to K and memory), then continue with intrinsic-pressure seeding. These changes better use memory structure and reduce future conflicts, reinforcing the high-success, low-cost diversification seen in the 95.04 cluster.",
  "meta_recommendations_history": [
    "1. Add a short, bounded local search after the final parametric packing to reduce the measured max KVPR. Focus on the most loaded GPU: try single-item moves and one-swap improvements that strictly decrease the global max KVPR while keeping memory \u2264 80 GB; cap to a small budget (e.g., up to 20 candidate moves and 10 swaps). This leverages the near-optimality of the T-based packing while capturing the consistent gains seen from local refinements in strong programs (26.17 tier).\n\n2. Generate and select from a few additional candidate placements around the final T to exploit discrete packing effects. Build placements at T = high, and at slightly perturbed thresholds like high*(1\u00b10.5%) using both current orderings, and also test First-Fit-Decreasing in transformed space alongside Best-Fit-Decreasing. Measure actual max KVPR for all candidates and pick the best; keep the total variants small (e.g., 6\u20138) to preserve ~0.001s runtime.\n\n3. Tighten the initial lower bound on T with inexpensive subset-based bounds to speed and stabilize the search. In addition to per-item and global bounds, compute pair bounds for the top P memory-heavy pairs that cannot co-reside (m_i + m_j > 80): T \u2265 (n_i + n_j) / (160 \u2212 m_i \u2212 m_j); set P \u2248 200 or all pairs if N is small. Add a k-bin prefix bound: for k = 1..min(gpu_num, 4), take items sorted by memory, find the shortest prefix S where sum(m_S) > (k\u22121)*80, and set T \u2265 sum(n_S) / max(k*80 \u2212 sum(m_S), \u03b5); use the max of all bounds as low_T.\n\n4. Use a two-phase hybrid placement to improve balance before BFD consolidation. Seed placement by spreading the top H \u201cintrinsic pressure\u201d models (highest n/(80\u2212m)) with a worst-fit strategy in transformed space (choose GPU with largest residual cap T*80 \u2212 (n_g + T*m_g)), then run the usual transformed Best-Fit-Decreasing for the remaining models. Set H to a small fraction (e.g., min(4, max(1, gpu_num)), or \u224810% of items) to keep runtime negligible while improving denominator balancing.\n\n5. Introduce lightweight stochastic tie-breaking and tiny randomized restarts to reduce ordering sensitivity while keeping speed. When multiple GPUs are within an epsilon residual in transformed space, randomly pick among the top-k (k=2\u20133) candidates; run 2 seeds per T/order variant and select by measured max KVPR. This preserves the dual-ordering parametric core while adding robustness that has correlated with top-tier results via candidate post-selection.",
    "1. Add an in-placement dynamic T update for the remaining items (two-phase packing). After placing the first 30\u201350% of items with T = T_feas, recompute a lower bound from the remaining items and the residual global capacity (using the same per-item/global/pair/k-prefix bounds but on the remainder), set T\u2019 = max(current T, new lower bound), rebuild weights w = dR + T\u2019\u00b7size for the remainder, re-sort, and continue placement. This preserves the slack-equalization core while adapting to discrete effects and has strong evidence from parametric T search that better-aligned thresholds improve balance.\n\n2. Strengthen lower bounds with a small triplet bound and slightly deeper k-prefix. For the top P=120 largest items by size, add a triplet bound: for any triple with s_i + s_j + s_k > 2S, set T \u2265 (r_i + r_j + r_k) / (3S \u2212 (s_i + s_j + s_k)); scan only O(P^2) candidates by fixing i and j and picking the best k among a short list (e.g., top-10 by size) to keep runtime negligible. Also extend k-prefix to k up to min(gpu_num, 6) to tighten early T; tighter bounds have repeatedly improved convergence and quality.\n\n3. Introduce a blended slack-aware selection rule alongside current \u2018tight\u2019 and \u2018min_kvpr\u2019. When choosing a GPU for an item, minimize J = K_after_norm + \u03b1\u00b7kv_new_norm + \u03b2\u00b7mem_imbalance, where K_after_norm = max(0, K_after)/(T\u00b7S), kv_new_norm = kv_new/max(T, 1e-12), and mem_imbalance = |(used_mem_g + size)/S \u2212 avg_mem_frac| with avg_mem_frac = total_used_mem/(gpu_num\u00b7S); start with \u03b1=0.15, \u03b2=0.05 and adapt \u03b1 upward to 0.25 if the K variance across GPUs is small. Evaluate this \u2018hybrid\u2019 rule as an added variant in the candidate set; it directly extends K-equalization with projected KVPR and memory balancing, an approach that has helped in prior high performers.\n\n4. Expand the bounded local refinement with 2-opt across top-2 loaded GPUs and short eject chains. After the current moves/swaps, run up to 12 targeted 2-opt swaps between the two highest-KVPR GPUs, selecting pairs by best delta in max KVPR using precomputed per-bucket sums. If still stuck, try up to 8 length-2 eject chains: move a from Gmax\u2192G2, then move b from G2\u2192some Gk to restore memory feasibility, accepting only chains that strictly reduce global max KVPR; this captures improvements single-step moves can\u2019t reach, with tight caps to keep sub-millisecond runtime.\n\n5. Make candidate selection more robust via lexicographic scoring and tiny ensemble restarts. When comparing candidate placements, break ties on max KVPR by second-worst KVPR, then by average KVPR (or variance), to avoid \u201chidden spikes\u201d on the second-most loaded GPU. For the strongest two variants per T (e.g., w_desc+tight and intrinsic_desc+tight with seeding), run 2 seeds each (different deterministic RNG seeds) and keep the best; diversification plus post-selection has consistently yielded incremental gains at negligible cost.",
    "1. Add a two-phase, in-placement T update inside assign_balanced_slack. After placing the first 40% of items with T = T_feas, recompute a lower bound using only the remaining items and the residual per-GPU capacities, set T\u2019 = max(T, new_lower_bound), rebuild weights w = dR + T\u2019\u00b7size for the remainder, re-sort, and continue. Keep order/choose_rule unchanged to preserve slack-equalization behavior while correcting discrete effects that misalign T mid-pack.\n\n2. Tighten lower bounds with a light triplet bound and deeper k-prefix. For the top P=120 largest items by size, scan O(P^2) triplets by fixing i,j and picking k from a short list (top-8 by size) to enforce T \u2265 (ri+rj+rk)/(3S \u2212 (si+sj+sk)) when si+sj+sk > 2S; also extend the k-prefix bound to k up to min(gpu_num, 6). Early-stop the multiplicative sweep when the growing T falls below any newly raised bound to save iterations and stabilize T_feas.\n\n3. Introduce a hybrid slack-aware selection rule as an additional choose_rule. Minimize J = K_after_norm + \u03b1\u00b7kv_new_norm + \u03b2\u00b7mem_imbalance, with K_after_norm = max(0, K_after)/(T\u00b7S), kv_new_norm = kv_new/max(T, 1e-12), mem_imbalance = |(used_mem_g + size)/S \u2212 avg_mem_frac|, using \u03b1=0.15, \u03b2=0.05 and raising \u03b1\u21920.25 when var(K) across GPUs drops below a small threshold. Evaluate this variant alongside \u2018tight\u2019 and \u2018min_kvpr\u2019 in both the first-feasible search and the T-neighborhood to capture residual KVPR differences without abandoning slack-equalization.\n\n4. Expand the bounded local refinement with targeted 2-opt swaps and short eject chains. After the current move/swap phase, run up to 12 2-opt swaps between the two highest-KVPR GPUs, selecting pairs by best reduction in global max KVPR using cached per-bucket R and mem; if still stuck, try up to 8 length-2 eject chains (Gmax\u2192G2, then G2\u2192Gk) that strictly reduce the max. Keep all caps tight to maintain sub-millisecond runtime and only commit improving transformations.\n\n5. Make candidate selection more robust with a slightly wider T-neighborhood, lexicographic scoring, and tiny ensemble restarts. Try T \u2208 {0.985, 0.99, 1.0, 1.005, 1.01, 1.015}\u00b7T_feas plus midpoint with lower, evaluate each variant with 2 deterministic seeds, and select by (max KVPR, second-worst KVPR, mean KVPR). This preserves the fast sweep while avoiding \u201chidden spikes\u201d on the second-most loaded GPU and harvesting small gains from diversification.",
    "1. Pre-place slo==0 (memory-only) models before slack packing. Distribute all models with slo==0 by largest-size-first to the GPUs with the largest remaining memory (pure memory balancing), freeze them, reduce per-GPU capacity S accordingly, then run the balanced-slack packer on the remaining items. Recompute all lower bounds on the residual instance to avoid rejecting placements due to the current \u201cdR=inf\u201d guard.\n\n2. Add adaptive in-placement T retuning with residual bounds. After placing roughly 40% of items, recompute a residual lower bound using the remaining items and the current per-GPU residual capacities; set T\u2019 = max(T, residual_lb), rebuild weights w = dR + T\u2019\u00b7size, re-sort, and continue. If K-variance across GPUs remains high after 75% of items, do a second, lighter retune (no reordering, just update T and use the existing order) to correct mid-pack discretization.\n\n3. Strengthen and reuse lower bounds during the multiplicative sweep. Implement a light triplet bound on the top P=120 items by size by checking O(P^2) pairs with k from the top-8, and extend the k-prefix bound to k up to min(gpu_num, 6); set T \u2265 (ri+rj+rk)/(3S \u2212 (si+sj+sk)) when applicable. During find_first_feasible_T, early-jump T to the current maximum bound whenever the sweep falls below it, reducing iterations and stabilizing T_feas.\n\n4. Introduce a hybrid slack-aware choose_rule J and evaluate it alongside existing rules. Use J = K_after_norm + \u03b1\u00b7kv_new_norm + \u03b2\u00b7mem_imbalance, where K_after_norm = max(0, K_after)/(T\u00b7S), kv_new_norm = kv_new/max(T, 1e-12), mem_imbalance = |(used_mem_g + size)/S \u2212 avg_mem_frac|, with \u03b1=0.15, \u03b2=0.05 and raise \u03b1\u21920.25 when var(K) drops below a small threshold (e.g., 0.02\u00b7(T\u00b7S)^2). Run this rule in both the feasibility search and T-neighborhood evaluation to harvest residual KVPR gains without abandoning slack equalization",
    "1. Pre-place memory-only (slo==0) models before slack equalization. Implement a first phase that assigns all slo==0 models by largest-size-first to GPUs with the most remaining memory (pure memory balancing), freeze them, reduce each GPU\u2019s residual capacity S_g accordingly, and then run the balanced-slack packer on the remaining models. Recompute all lower bounds on the residual instance (per-item, global, pair, k-prefix) so T isn\u2019t inflated or blocked by the current dR=inf guard.\n\n2. Strengthen bounds and early-jump inside the multiplicative T sweep. Add a light triplet bound over the top P=120 models by size by checking O(P^2) pairs combined with k from the top-8 (only if si+sj+sk > (k-1)\u00b7S to prune), and extend the k-prefix bound to k up to min(gpu_num, 6). During find_first_feasible_T, track max_lb = max(lb1, lb2, lb_pair, lb_k, lb_triplet) and immediately set T = max(T, max_lb) when the sweep falls below it to skip iterations and stabilize T_feas.\n\n3. Add adaptive in-placement T retuning with residual bounds. After placing roughly 40% of items, recompute a residual lower bound using remaining items and current per-GPU residual capacities; set T\u2019 = max(T, residual_lb), rebuild weights w = dR + T\u2019\u00b7size, re-sort, and continue. If K-variance across GPUs remains high after 75% of items, do a second, lighter retune (no reordering\u2014just update T in-place) to correct mid-pack discretization without extra search.\n\n4. Introduce a hybrid choose_rule J and evaluate it alongside the tight K_after rule. Define J = K_after_norm + \u03b1\u00b7kv_new_norm + \u03b2\u00b7mem_imbalance with \u03b1=0.15, \u03b2=0.05; when var(K)/(T\u00b7S)^2 drops below 0.02, raise \u03b1 to 0.25 to emphasize local KVPR control. For each T candidate, try both choose_rule='tight' and choose_rule='J' (small seeds=1\u20132) and pick the better by measured max KVPR; keep the same deterministic RNG to retain reproducibility.\n\n5. Upgrade local refinement with donation-first moves and size-binned swaps. After initial placement, repeatedly: (a) attempt \u201cdonations\u201d from the worst GPU to the top-2 best GPUs by scanning a capped set of its items (e.g., 12 largest and 12 highest dR) and selecting the move that minimizes resulting global max KVPR; (b) if no move helps, try 2-opt swaps using size bins (e.g., 8 bins) to quickly find near-size pairs that fit and reduce the max. Keep tight budgets (e.g., move_budget=24, swap_budget=12), rollback any non-improving step, and add a final \u201cdual-worst interchange\u201d attempt between the two worst GPUs to harvest stubborn improvements.",
    "1. Pre-place memory-only (slo==0) models before slack equalization with per-GPU residual capacities\n   - Split items into M0 = {slo==0} and M+ = {slo>0}. Place M0 by largest-size-first onto GPUs with the most remaining memory (pure memory balancing), update per-GPU capacities Sg and freeze them; then run assign_balanced_slack only on M+ using per-GPU Sg and initialize K_g = T\u00b7Sg. Recompute lower bounds on the residual instance (using S_total = \u03a3Sg and total_size/total_R from M+) to avoid inflating T and eliminate the current dR==inf guard that triggers fallbacks.\n\n2. Strengthen lower bounds and add an early jump within the multiplicative T sweep\n   - Add a light triplet bound over the top P=120 models by size: for each pair (i,j) in the top-P, scan k in top-8-by-size and if si+sj+sk > (k\u22121)\u00b7S, set T \u2265 (ri+rj+rk) / (k\u00b7S \u2212 (si+sj+sk)) when the denominator > 0. Extend the k-prefix bound to k up to min(gpu_num, 6) and tighten the pair bound by restricting to pairs where max(si,sj) \u2265 0.55\u00b7S to keep it cheap. In find_first_feasible_T, maintain max_lb = max(lb1, lb2, lb_pair, lb_k, lb_triplet) and, if the current T < max_lb, jump T = max_lb immediately to skip unproductive iterations.\n\n3. Adaptive T retuning mid-placement with residual bounds and minimal disruption\n   - During assign_balanced_slack, after placing about 40% of items, recompute a residual lower bound using the remaining items and the current per-GPU residual capacities; if residual_lb > T\u00b71.02, set T\u2019 = residual_lb, recompute residual weights w = dR + T\u2019\u00b7size, re-sort the remaining items by w, and continue. If K-variance across GPUs remains high after ~75% of items, do a second, lighter retune: update T in-place (no reordering), recompute w only for decision checks and tie-breaks, and continue. This keeps the decision rule aligned with the evolving feasible region without adding extra outer-loop search.\n\n4. Add a hybrid choose_rule J and evaluate it alongside the tight K-after rule\n   - Define J = K_after_norm + \u03b1\u00b7kv_new_norm + \u03b2\u00b7mem_imbalance, where K_after_norm = K_after/(T\u00b7S), kv_new_norm = kvpr(sum_R+ dR, S\u2212(used+size))/max(T,1e-12) clipped to [0,1.5], and mem_imbalance = (mean_used \u2212 used_dst)/S. Use \u03b1=0.15, \u03b2=0.05 by default; when var(K)/(T\u00b7S)^2 < 0.02, raise \u03b1 to 0.25 to emphasize local KVPR control near convergence. For each T candidate, try both choose_rule='tight' and choose_rule='J' with seeds=1\u20132 and keep the best measured max KVPR; retain the deterministic RNG and the existing near-tie randomization.\n\n5. Upgrade local refinement with donation-first moves and size-binned swaps focused on the worst GPUs\n   - Replace the current uniform move/swap scan with: (a) donation-first moves from the worst GPU to the top-2 best GPUs by KVPR, scanning only the 12 largest and 12 highest-dR items on the worst GPU, committing the single move that minimizes the resulting global max KVPR; (b) if no move helps, do 2-opt swaps via 8 size bins to quickly find near-size pairs that fit and reduce the max; (c) if still stuck, try a final dual-worst interchange between the two worst GPUs. Keep tight budgets (move_budget=24, swap_budget=12), rollback non-improving steps, and stop early after two consecutive non-improving passes. This preserves speed while consistently trimming the peak KVPR beyond the current bounded refinement.",
    "1. Pre-place memory-only (slo==0) models to unlock slack-equalization for the rest\n   - Split models into M0 = {slo==0 or dR==inf} and M+ = others. Place M0 largest-first onto GPUs with the most remaining memory (break ties by least models), freeze per-GPU capacities Sg, recompute lower bounds on M+ using S_total\u2019 = \u03a3Sg and ignore M0\u2019s rates, then run assign_balanced_slack on M+ with K_g initialized as T\u00b7Sg and memory checks against Sg. This avoids falling back to the greedy path in mixed instances and keeps the decision rule aligned with T-feasibility.\n\n2. Tighten T lower bounds and jump early in the multiplicative sweep\n   - Add a triplet bound over the top P=120 items by size: for pairs (i,j) where max(si,sj) \u2265 0.55\u00b7S, scan k in top-8-by-size; when si+sj+sk > (k\u22121)\u00b7S and k\u00b7S\u2212(si+sj+sk) > 0, set T \u2265 (ri+rj+rk)/(k\u00b7S\u2212(si+sj+sk)). Extend the k-prefix bound to k \u2264 min(gpu_num, 6). In find_first_feasible_T, maintain max_lb over {item, global, pair, k-prefix, triplet} and, if T < max_lb, set T = max_lb immediately to skip unproductive iterations.\n\n3. Residual-aware T retuning mid-placement with minimal disruption\n   - After placing ~40% of items, recompute a residual lower bound using remaining items and current per-GPU residual capacities; if residual_lb > 1.02\u00b7T, set T\u2019 = residual_lb, recompute w = dR + T\u2019\u00b7size, re-sort the remaining items by w (keep placed items fixed), and continue. Optionally do a second, lighter retune near 75% placed: update T in-place (no reordering), using T\u2019 only for choose checks and tie-breaks. This keeps placement decisions aligned with the evolving feasible T without adding an outer search loop.\n\n4. Micro-restarts with tiny K-slack noise and adaptive ordering at the best T\n   - For the best T candidate,",
    "1. Pre-place memory-only (slo==0) models before slack-equalization\n   - Split models into M0 = {slo==0} and M+ = others. Place M0 largest-first onto GPUs with the most remaining memory (tie-break by fewest models), freeze per-GPU capacities Sg, then run the existing slack-equalization on M+ with K_g initialized as T\u00b7Sg and memory checks against Sg. Recompute lower bounds for M+ using S_total' = \u03a3Sg and total_R' = \u03a3 dR over M+, so memory-only models no longer force a greedy fallback and the T-feasibility rule remains intact.\n\n2. Strengthen lower bounds and jump immediately to the max bound in the sweep\n   - Add a triplet bound over the top P=120 items by size: for pairs (i,j) with max(si,sj) \u2265 0.55\u00b7S, scan k among the top-8-by-size items; if si+sj+sk > (k\u22121)\u00b7S and k\u00b7S\u2212(si+sj+sk) > 0, set T \u2265 (ri+rj+rk)/(k\u00b7S\u2212(si+sj+sk)). Extend the k-prefix bound to k \u2264 min(gpu_num, 6). In find_first_feasible_T, compute max_lb across {per-item, global, pair, k-prefix, triplet} and start T = max_lb (or jump to it if current T < max_lb) to avoid wasted multiplicative steps.\n\n3. Correct T bracketing and compact polishing around the feasibility threshold\n   - Replace the current hi initialization (which uses best_val) with a true bracket on T: set lo = lower, hi = T_feas found by the sweep, then binary search on feasibility for 6\u20138 iterations (using assign_balanced_slack as the feasibility oracle). Around the tightened T* (the smallest feasible T found), probe a very narrow neighborhood {0.99, 1.0, 1.01}\u00b7T* and keep the best measured KVPR. This aligns the search strictly with T-feasibility and preserves the compact, fast refinement that characterizes the top programs.\n\n4. Residual-aware mid-placement T retuning with minimal disruption\n   - During assign_balanced_slack, after ~40% of items are placed, recompute a residual lower bound using the remaining items and current per-GPU free memory (aggregate to S_total_rem and remaining total size); if residual_lb > 1.02\u00b7T, set T' = residual_lb, recompute w = dR + T'\u00b7size for the remaining items, resort them by w, and continue. Optionally do a light second retune at ~75% placed: update T in-place without reordering and use T' only for choose checks. This keeps the decision rule aligned with evolving feasibility without adding an outer loop.\n\n5. Diversify near-optimal placements: micro-restarts with tiny K-jitter and lexicographic selection\n   - At the best T candidate, run 3\u20135 micro-restarts that keep the same ordering but add tiny, deterministic jitter to per-GPU slack (e.g., K_g = T\u00b7S + \u03b5\u00b7g, with \u03b5 \u2248 1e-6\u00b7T\u00b7S) and slightly different tie-break random seeds; this preserves feasibility but breaks pathological ties. When comparing candidates, switch from scalar max-KVPR to lexicographic KVPR vectors (sorted descending across GPUs) as the final tie-breaker. This combination consistently improved robustness in the top slack-equalization programs without measurable runtime cost.",
    "1. Pre-place memory-only (slo==0) models before T-based packing\n   - Split models into M0 (slo==0) and M+ (slo>0). Place M0 largest-first onto GPUs with the most remaining memory (tie-break by fewest models), freeze per-GPU capacities Sg, then run the K-after slack-equalization on M+ with K_g initialized to T\u00b7Sg and memory checks against Sg. Recompute lower bounds for M+ using S_total' = \u03a3Sg and total_R' over M+ so the T-feasible assignment never falls back to greedy just because of memory-only items.\n\n2. Correct T bracketing and tighten via feasibility-only binary search\n   - In find_first_feasible_T, return the first feasible T (T_feas) and treat lower as the lo bound. Replace the current hi initialization (which incorrectly uses best_val) with hi = T_feas, then perform 6\u20138 iterations of binary search using assign_balanced_slack as a pure feasibility oracle; after obtaining the smallest feasible T*, probe a compact neighborhood {0.99, 1.0, 1.01}\u00b7T* and keep the best measured KVPR. This aligns the search strictly with T-feasibility and matches the top-performing programs\u2019 compact, fast polishing.\n\n3. Strengthen lower bounds and jump directly to max bound\n   - Add a triplet bound over the top P=120 items by size: for pairs (i,j) with max(si, sj) \u2265 0.55\u00b7S, scan k among the top-8-by-size items; if si+sj+sk > (k\u22121)\u00b7S and k\u00b7S\u2212(si+sj+sk) > 0, set T \u2265 (ri+rj+rk)/(k\u00b7S\u2212(si+sj+sk)). Extend the k-prefix bound to k \u2264 min(gpu_num, 6). In the multiplicative sweep, start at T = max(per-item, global, pair, k-prefix, triplet) to avoid wasted growth steps.\n\n4. Residual-aware mid-placement T retuning\n   - During assign_balanced_slack, after ~40% of items are placed, compute a residual lower bound using remaining items and current per-GPU free memory (aggregate to S_total_rem and remaining total size). If residual_lb > 1.02\u00b7T, set T' = residual_lb, recompute w = dR + T'\u00b7size for the remaining items, resort by w, and continue; optionally do a light second retune at ~75% placed (update T in-place without reordering). This keeps the K-after decision rule aligned with evolving feasibility at negligible overhead.\n\n5. Micro-restarts with K-jitter, lexicographic comparison, and a quick K-aware move\n   - At the best T candidate, run 3\u20135 micro-restarts that keep the same ordering but initialize K_g = T\u00b7Sg + \u03b5\u00b7g (\u03b5 \u2248 1e-6\u00b7T\u00b7S_total), and use small, deterministic RNG seed tweaks; maintain the K-after selection with min_kvpr as a tie-breaker. Compare candidates using lexicographic KVPR vectors (sorted descending across GPUs) rather than scalar max only, then apply a cheap pre-refinement: try moving the top-2 w items from the worst GPU to the GPU with the largest nonnegative K that fits before the full move/swap loop. This combination improves robustness and often shaves the peak KVPR without runtime spikes.",
    "1. Pre-place memory-only (slo==0) models before T-based packing\n   - Split models into M0 (slo==0) and M+ (slo>0). Place M0 largest-first onto GPUs with the most remaining memory (tie-break by fewest models), freeze per-GPU capacities Sg, then recompute lower bounds and run the K-after slack-equalization on M+ with K_g initialized to T\u00b7Sg. This preserves T-feasibility and avoids having zero-rate items distort the K-equalization, matching the robustness pattern observed in the best programs.\n\n2. Residual-aware mid-placement T retuning inside assign_balanced_slack\n   - After about 40% of items are placed, compute a residual lower bound using the remaining items and the current per-GPU free memory (aggregate to S_total_rem and remaining total size). If residual_lb > 1.02\u00b7T, set T' = residual_lb, recompute weights w = dR + T'\u00b7size, resort the remaining items by w, and continue; optionally do a light second retune at ~75% placed (update T in-place without reordering). This keeps the K-after decision rule tightly aligned with feasibility as the instance evolves, mirroring the \u201ccompact T control\u201d that drives the 95.04 cluster.\n\n3. Micro-restarts with tiny K-jitter, deterministic seed tweaks, and lexicographic selection\n   - For the best T candidate, run 3\u20135 micro-restarts that keep the same ordering but initialize K_g = T\u00b7Sg + \u03b5\u00b7g (\u03b5 \u2248 1e-6\u00b7T\u00b7S_total) and slightly vary a deterministic RNG seed; keep the K-after rule and current tie-breaks. Choose the winner by lexicographic KVPR vectors (sorted descending per-GPU), and add a quick pre-refinement: attempt moving the top-2 w items from the worst GPU to the GPU with the largest nonnegative K that fits before the full local search. This light diversification consistently shaved peaks in top performers without runtime spikes.\n\n4. K-aware local refinement focused on slack equalization at T*\n   - Add a short post-pack loop that uses K_g = T*\u00b7S \u2212 (\u03a3R_g + T*\u00b7used_mem_g): repeatedly pick the worst-KVPR GPU, then attempt moving or swapping its highest-w items to GPUs with the largest K such that K_after \u2265 0 and memory fits; run \u226412 moves and \u22646 swaps. Prefer moves that increase the minimum K across GPUs or reduce the variance of K. This targets the same K-equalization principle that made the main packer strong and typically improves on the current KVPR-only refine.\n\n5. Adaptive tie-breaking and seeding for heavy items to stabilize K and memory slack\n   - In the main K-after selection, when multiple GPUs have near-equal K_after, tie-break by minimizing the resulting sum of squared K across GPUs (proxy for K variance), then by larger memory slack; compute this in O(G) per item. In seeding, explicitly spread all models with size > S/2 (or top-H by size) across distinct GPUs first (subject to K and memory), then continue with intrinsic-pressure seeding. These changes better use memory structure and reduce future conflicts, reinforcing the high-success, low-cost diversification seen in the 95.04 cluster."
  ],
  "total_programs_meta_processed": 100
}