<NAME>
donation_first_refine_and_resid_guard
</NAME>

<DESCRIPTION>
I add two targeted improvements:
1) A donation-first final refinement pass that moves a small, carefully chosen subset of models from the worst GPU to the two best GPUs (by KVPR) if such a move strictly reduces the global max KVPR. This concentrates computation on the most impactful adjustments with tight budgets and minimally increases runtime while often shaving the peak KVPR further.

2) A guard in the parametric packing’s "resid" policy to avoid placements that exactly saturate a GPU’s memory with positive load, which would cause infinite KVPR. This prevents low-quality candidates and reduces wasted search paths without hurting feasibility across other variants.

Both changes are compact, safe, and aim to improve the combined score by slightly reducing max KVPR with negligible overhead.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                    if policy == "resid":
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    else:
                        new_local = kvpr(n_sum[g] + n, GPU_MEM_SIZE - (m_sum[g] + ms))
                        # new global max KVPR if placed on g
                        new_max = new_local
                        for k in range(gpu_num):
                            if k != g and cur_kvprs[k] > new_max:
                                new_max = cur_kvprs[k]
                        if policy == "minmax":
                            key = (new_max, new_local, resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                        else:
                            # hybrid: balance projected global KVPR, local KVPR, and memory imbalance
                            mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                            mem_imb = abs(mem_frac_after - avg_mem_frac)
                            J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                            key = (J, new_max, new_local, resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
=======
                    if policy == "resid":
                        # Avoid zero remaining memory with positive load (would create infinite KVPR)
                        if GPU_MEM_SIZE - (m_sum[g] + ms) <= 1e-12 and (n_sum[g] + n) > 0:
                            continue
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    else:
                        new_local = kvpr(n_sum[g] + n, GPU_MEM_SIZE - (m_sum[g] + ms))
                        # new global max KVPR if placed on g
                        new_max = new_local
                        for k in range(gpu_num):
                            if k != g and cur_kvprs[k] > new_max:
                                new_max = cur_kvprs[k]
                        if policy == "minmax":
                            key = (new_max, new_local, resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                        else:
                            # hybrid: balance projected global KVPR, local KVPR, and memory imbalance
                            mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                            mem_imb = abs(mem_frac_after - avg_mem_frac)
                            J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                            key = (J, new_max, new_local, resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_plc = None
    best_score = float('inf')
    for plc in improved_candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc

    # Ensure all GPUs are present
    for g in range(gpu_num):
        best_plc.setdefault(g, [])

    return best_plc
=======
    best_plc = None
    best_score = float('inf')
    for plc in improved_candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc

    # Final donation-first refinement: move a few impactful models from the worst GPU
    def refine_peak(plc, passes=2, top_k=12, eps=1e-12):
        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]

        def kvpr_g(g, msum=None, nsum=None):
            msum = mem[g] if msum is None else msum
            nsum = num[g] if nsum is None else nsum
            return kvpr(nsum, GPU_MEM_SIZE - msum)

        for _ in range(passes):
            # Current KVPRs and worst/best GPUs
            vals = [kvpr_g(g) for g in range(gpu_num)]
            worst = max(range(gpu_num), key=lambda g: vals[g])
            # Identify up to two best GPUs (lowest KVPR) excluding worst
            best_targets = [g for g in sorted(range(gpu_num), key=lambda x: vals[x]) if g != worst][:2]
            if not best_targets:
                break

            # Build candidate set from worst: top by demand and by size
            def dn_of(m):
                return float(getattr(m, "req_rate")) / float(getattr(m, "slo"))
            def sz_of(m):
                return float(getattr(m, "model_size"))

            worst_list = list(per_g[worst])
            if not worst_list:
                break
            top_by_dn = sorted(worst_list, key=dn_of, reverse=True)[:max(1, top_k // 2)]
            top_by_sz = sorted(worst_list, key=sz_of, reverse=True)[:max(1, top_k - len(top_by_dn))]
            cand = list({id(m): m for m in (top_by_dn + top_by_sz)}.values())

            improved = False
            best_new_max = max(vals)
            best_action = None

            for mdl in cand:
                ms = sz_of(mdl)
                dn = dn_of(mdl)
                for tgt in best_targets:
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt and vals[g] > new_max:
                            new_max = vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_action = (mdl, worst, tgt, ms, dn)
                        improved = True

            if not improved:
                break

            mdl, src, tgt, ms, dn = best_action
            per_g[src].remove(mdl)
            per_g[tgt].append(mdl)
            mem[src] -= ms
            num[src] -= dn
            mem[tgt] += ms
            num[tgt] += dn

        return {g: per_g.get(g, []) for g in range(gpu_num)}

    best_plc = refine_peak(best_plc, passes=2, top_k=12)

    # Ensure all GPUs are present
    for g in range(gpu_num):
        best_plc.setdefault(g, [])

    return best_plc
>>>>>>> REPLACE

</DIFF>