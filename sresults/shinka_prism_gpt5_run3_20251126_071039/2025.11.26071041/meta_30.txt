# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy KVPR-Minimizing Model Placement**
- **Implementation**: Greedily sorts models by r_j/s_j (req_rate/SLO) descending and assigns each to the GPU with the lowest current weighted_req_rate/remaining_mem among those with enough free memory (80GB per GPU), updating per-GPU totals after placement. It fails fast by raising an error when a model cannot fit, and does not implement a τ-feasibility check or post-placement ratio evaluation.
- **Performance**: Combined score 21.89; max_kvpr 20.892; success_rate 1.000; execution_time 0.000s.
- **Feedback**: The simple ratio-based balancing yields consistently feasible placements with near-zero runtime and strong KVPR results on the evaluator. Potential improvements include choosing GPUs based on the projected ratio after placement, adding τ checks, and avoiding a fixed 80GB assumption to better generalize and further reduce peak KV pressure.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Greedy Min-Max KVPR GPU Placement**
- **Implementation**: Greedy assignment after sorting models by (req_rate/slo)/(80−size), placing each on the GPU that minimizes the resulting global max KVPR with tie-breakers (lower target KVPR, more remaining memory). A bounded local improvement then moves single models from the most-pressured GPU if it strictly reduces the max KVPR; memory fit is enforced and KVPR is R/rem_mem (inf at zero).
- **Performance**: Combined score 23.13; max_kvpr 22.127; success_rate 1.000; execution_time 0.000s.
- **Feedback**: Passed all validations; the sorting heuristic plus lookahead and local hill-climb effectively balances KV cache pressure across GPUs. Infinity handling is minimal when remaining memory hits zero, but this did not affect the provided tests.
**Program Identifier:** Generation 1 - Patch Name balanced_minmax_kvpr - Correct Program: True

**Program Name: Greedy KV Cache Pressure Balancer**
- **Implementation**: Sorts models by (req_rate/slo) per GB and greedily assigns each to the GPU that minimizes the projected maximum KVPR across all GPUs, with tie-breakers on local KVPR, remaining memory, and GPU id. Enforces 80 GB per-GPU memory, avoids overcommit via hard-fit checks, and guards against zero SLO/size with infinities and epsilons.
- **Performance**: Combined score 20.74; max_kvpr 19.743; success_rate 1.000; execution_time ~0.000s.
- **Feedback**: Passes all validation tests; the global-max KVPR lookahead and tie-breakers yield balanced placements without overcommit. Numerical edge-case handling (zero SLO/size) improves stability and consistency across test cases.
**Program Identifier:** Generation 2 - Patch Name minimax_greedy_kvpr - Correct Program: True

**Program Name: Greedy + Local Search KVPR Balancer**
- **Implementation**: Greedy min-max placement guided by multiple model orderings; for each placement step, it picks the GPU that minimizes the resulting global max KVPR with memory-aware tie-breaks. It then applies bounded local improvement (best-improving single moves from the max-pressure GPU and capped pairwise swaps) using per-GPU sum(r/s) and remaining memory tracking, with infeasible fits rejected.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: Correct and passed all validations; multi-ordering plus local refinement consistently produced balanced placements with low peak pressure. The fixed 80 GB per-GPU assumption and capped improvement iterations trade some optimality for speed and robustness.
**Program Identifier:** Generation 3 - Patch Name multi_heuristic_and_swap_improvement - Correct Program: True

**Program Name: Greedy-MinMax KVPR Placement with Parametric Search**
- **Implementation**: Uses multi-ordering greedy min–max assignment with lookahead and tie-breakers, then bounded local improvement (single-move and capped pairwise swaps), assuming 80 GB/GPU. It further runs a binary search over target KVPR using a transformed capacity model and best-fit-decreasing packing (w = dR + T*size; capacity = T*S), adopting the refined placement if it improves the max KVPR.
- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.002s runtime.
- **Feedback**: The diverse orderings, lookahead placement, and capped local search provided robust, fast placements that passed all validation tests. Parametric refinement effectively tightened worst-case KVPR when feasible, while safety checks (infinite-rememory handling and feasibility bounds) prevented invalid placements.
**Program Identifier:** Generation 4 - Patch Name parametric_bsearch_bfd - Correct Program: True

**Program Name: Binary-searched best-fit KVPR placement**
- **Implementation**: Uses a transformed-capacity formulation w_i(T)=n_i+T*m_i with per-GPU cap 80*T, performing exponential search to find a feasible T and binary search to minimize it, then packs via best-fit decreasing under two orderings (transformed weight and intrinsic pressure). Includes strict input validation, global/individual lower bounds, small numerical slack, a quality-based post-selection, and a greedy fallback, returning a complete GPU-id mapping.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.
- **Feedback**: Dual ordering plus post-selection by measured KVPR yields consistently feasible, near-optimal placements with excellent speed. The fixed 80 GB constraint and robust feasibility checks improved stability and prevented invalid allocations, contributing to perfect success across tests.
**Program Identifier:** Generation 5 - Patch Name kvpr_bisect_packing - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placement**
- **Implementation**: Uses a transformed-capacity bin packing with KVPR threshold T (exponential search for feasibility, binary search to tighten), packing via five ordering variants with tie-breakers to minimize global max KVPR, plus candidate scoring, a greedy fallback, and a local hill-climbing improvement pass. Enforces single-GPU fit, safe divisions, and returns a full GPU-indexed placement map.
- **Performance**: Combined score 25.43; max_kvpr 24.426; success_rate 1.000; execution_time 0.009s.
- **Feedback**: The mix of ordering variants and local improvement reliably finds feasible, balanced placements quickly, yielding perfect success and very low runtime. Evaluation indicates the strategy effectively controls worst-case KVPR across GPUs.
**Program Identifier:** Generation 6 - Patch Name kvpr_bisect_pack_local_search - Correct Program: True

**Program Name: Greedy-Refined KVPR Balancer**
- **Implementation**: Uses a greedy min–max assignment with lookahead and tie-breakers across multiple orderings (pressure weight, r/s, size asc/desc, density), followed by capped local move/swap improvements. It then binary-searches a target KVPR and applies Best-Fit-Decreasing with transformed weights w = dR + T*size to further tighten placement, with 80 GB/GPU and safety checks enforced.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: Consistently finds feasible, low-pressure placements and passes all validation tests, indicating correctness and robustness. The layered greedy+local+parametric refinement and thoughtful tie-breakers likely drive both quality and speed.
**Program Identifier:** Generation 7 - Patch Name parametric_refinement_bsearch - Correct Program: True

**Program Name: KVPR-Aware GPU Placement with Local Search**
- **Implementation**: Computes per-model demand (req_rate/slo) and defines KVPR as demand over remaining GPU memory. Builds initial placements via KVPR-focused regret-based insertion and a memory-oriented dual packing (max-free then best-fit), then applies bounded move/swap local search to minimize the global max KVPR and selects the best candidate.
- **Performance**: Achieved combined score 26.01 with max_kvpr 25.012, 100% success rate, and 0.001s execution time.
- **Feedback**: KVPR-aware initialization plus local improvement effectively balances load and keeps pressure low across GPUs, with strict memory feasibility checks. The method is fast and robust across test cases; KVPR-based tie-breaking improves stability in edge placements.
**Program Identifier:** Generation 8 - Patch Name regret_waterfill_swaps - Correct Program: True

**Program Name: KVPR-optimized bin packing with binary search**
- **Implementation**: Uses per-item/global lower bounds and an exponential+binary search on a KVPR threshold T, reducing placement to a transformed bin-packing (cap=T*80, weight=n_i+T*m_i) under memory constraints. Applies best-fit-decreasing with two ordering variants and selects the placement with the lowest measured max KVPR; includes strict input validation and safe division.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.
- **Feedback**: The dual-ordering heuristic plus near-optimal T search consistently found feasible placements with low KVPR while remaining extremely fast. Robust validation (e.g., per-GPU memory, SLO > 0, oversized models) improved stability and ensured all tests passed.
**Program Identifier:** Generation 9 - Patch Name dual_bisect_bfd - Correct Program: True

**Program Name: Minimax KVPR GPU Placement with BFD Refinement**
- **Implementation**: Multi-ordering greedy min-max placement with lookahead and tie-breakers, followed by local improvement via capped single-item moves and pairwise swaps. A final binary search on target KVPR uses BFD over transformed weights (dR + T·size) with validation, adopting improvements.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.021s.
- **Feedback**: Passed all validation tests; the layered heuristics plus parametric BFD tightening produced balanced, feasible placements with very low runtime. Robustness benefited from multiple orderings, careful tie-breaking, and explicit handling of infeasible single-model cases.
**Program Identifier:** Generation 10 - Patch Name kvpr_minimax_param_refine - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placer**
- **Implementation**: Performs binary search on a KVPR threshold T and reduces feasibility to transformed-capacity bin packing (weight n + T*m, capacity T*80) with two-phase seeding and best/first-fit variants. Establishes strong lower bounds (per-item, global, pairwise, k-prefix), generates multiple candidate placements around T, and applies local move/swap search to reduce the max per-GPU KVPR.
- **Performance**: Combined score 24.55; max_kvpr 23.551; success_rate 1.000; execution_time 0.003s.
- **Feedback**: The multi-bound initialization, diversified packing variants, and local search achieved low maximum KVPR with perfect feasibility and very low latency. Potential minor improvements could come from broader candidate diversification or adaptive seeding, but the current implementation already passes all validation tests.
**Program Identifier:** Generation 11 - Patch Name kvpr_parametric_hybrid_ls - Correct Program: True

**Program Name: KVPR-minimizing placement with LB and packing**
- **Implementation**: Computes tight lower bounds (per-item, global, pair, k-bin) on target KVPR T, then performs transformed bin packing with weights w = dR + T*size using BFD/FFD variants, seeding by intrinsic pressure, and deterministic tie-breaking, with a greedy KVPR fallback. Selects among candidate T values by measured max-KVPR and applies bounded local refinement (targeted moves and swaps) plus safety checks.
- **Performance**: Combined score 25.73 (max_kvpr 24.730), success_rate 1.000, execution_time 0.001s.
- **Feedback**: Passed all validations with excellent speed; LB-guided sweeping and local refinement effectively reduce the worst-case KVPR. Additional variant exploration or deeper local search could yield marginal improvements while maintaining low latency.
**Program Identifier:** Generation 12 - Patch Name pairbound_threshold_sweep - Correct Program: True

**Program Name: KVPR-aware GPU placement with binary search and refinement**
- **Implementation**: Computes a lower bound on KVPR threshold T, then performs exponential+binary search with feasibility packing using transformed weights w(T)=n+T*m across multiple item orderings and policies. It generates diverse candidates, selects the lowest measured max-KVPR placement, and applies a local move-based improvement; includes strict memory/SLO checks and fills all GPU keys.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.004s.
- **Feedback**: Multi-variant packing plus local refinement consistently finds near-optimal placements with perfect success and very low runtime. The w(T)-based search with tight lower bounds is stable, and the greedy min-max fallback boosts robustness.
**Program Identifier:** Generation 13 - Patch Name hybrid_tsearch_minmax_local - Correct Program: True

**Program Name: Balanced-slack KVPR Minimization**
- **Implementation**: Computes tight lower bounds for the KVPR threshold T (per-item, global, pairwise, k-bin) and finds a feasible T via a multiplicative sweep while packing with a slack-equalization bin packer (weight w=dR+T*size), seeded ordering, and min-K_after/min-KVPR tie-breaks with slight randomization. Around the first feasible T it explores multiple orderings, applies targeted move/swap local refinement, and uses strict memory/KVPR checks with a deterministic greedy fallback for feasibility.
- **Performance**: Combined score 36.51; success_rate 1.000; execution_time 0.002s; reported max_kvpr metric 35.512.
- **Feedback**: Lower-bound-guided T search plus equalized-slack packing quickly yields balanced placements, with local refinement providing incremental improvements. Robust handling of edge cases (e.g., slo==0), deterministic seeding, and validation checks led to reliable, passing results across all tests.
**Program Identifier:** Generation 14 - Patch Name slack_equalization_t_search - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placement with Slack Equalization**
- **Implementation**: Computes tight lower bounds (per-item, global, pairwise, k-bin) on target KV pressure, then packs via a slack-equalization scheduler with weight w=dR+T*size, exploring multiple orderings, tie-breakers, and deterministic randomness. Feasible T is found by a multiplicative sweep, followed by variant trials and a local refine phase (moves/swaps) plus a greedy fallback and strict safety checks.
- **Performance**: Combined score 25.99 (max_kvpr 24.988; success_rate 1.000; execution_time 0.003s).
- **Feedback**: Lower-bound-guided T selection and K-slack equalization with local refinement effectively balances memory and request rates, yielding low max KVPR and perfect feasibility at very low runtime. The greedy fallback robustly covers slo==0/infeasible cases, and deterministic seeding ensures reproducibility.
**Program Identifier:** Generation 15 - Patch Name kvpr_balanced_param_local - Correct Program: True

**Program Name: KVPR-Minimizing GPU Placement**
- **Implementation**: Lower-bound–guided search on a KVPR threshold combined with transformed bin packing (w_i = n_i + T*m_i, cap = T*80) under strict per-GPU memory constraints, using two ordering heuristics and exponential warm-up followed by binary search. Near-optimal candidates are measured by actual KVPR and refined via local moves and first-improving swaps to reduce the worst GPU pressure.
- **Performance**: Combined score 24.44; max_kvpr 23.442; success_rate 1.000; execution_time 0.001s.
- **Feedback**: Strong bounds (per-item, global, pair, k-prefix) tighten the initial feasible region and speed convergence, while dual orderings and local refinement improve packings around the optimal threshold. The approach is robust (100% success) and extremely fast; remaining improvements would likely come from enhanced local search or additional ordering strategies.
**Program Identifier:** Generation 16 - Patch Name tighter_bounds_and_local_refine - Correct Program: True

**Program Name: Balanced-Slack KVPR Placement**
- **Implementation**: Uses strong lower bounds (per-item, global, pairwise, k-bin) to seed a balanced-slack bin packing that minimizes max KVPR by packing weights w = dR + T*s with multiple orderings, light deterministic randomization, and strict validation. It then applies localized move/swap refinement and selects the best among refined, search-based, and greedy fallback placements (fallback also covers dR=inf cases).
- **Performance**: Combined score 25.99 with max_kvpr 24.988, success_rate 1.000, execution_time 0.003s.
- **Feedback**: Bound-guided search plus local refinement consistently yields low max KVPR while remaining very fast, and the greedy fallback ensures robustness in edge cases (e.g., SLO=0 or tight memory). Final memory checks and candidate selection contribute to reliability without noticeable runtime cost.
**Program Identifier:** Generation 17 - Patch Name tsearch_local_refine_fix - Correct Program: True

**Program Name: Min-Max KV Cache Pressure Placement**
- **Implementation**: Computes tight lower bounds (per-item, global, heavy-pair, k-prefix) on the KVPR threshold T, then performs exponential+binary search with a T-aware best-fit/min-max packer across multiple orderings. Diversifies candidates around near-optimal T, adds a demand-per-GB greedy baseline, and applies single-move and swap local search to reduce the measured max KVPR.
- **Performance**: Combined score 25.70; max_kvpr 24.702; success_rate 1.000; execution_time 0.004s.
- **Feedback**: The program is correct and passes all validation tests. Strong bounds plus candidate diversification and local improvement yield robust, low-pressure placements while remaining extremely fast.
**Program Identifier:** Generation 18 - Patch Name pair_kprefix_t_perturb_and_swaps - Correct Program: True

**Program Name: KVPR-Minimizing GPU Placement via Search and Local Moves**
- **Implementation**: Computes tight lower bounds (individual, global, pair-based, k-bin), then uses exponential+binary search on a KVPR threshold T, packing with transformed weights w(T)=n+T*m under multiple ordering/policy heuristics. It selects the best measured placement, adds a greedy min-max candidate, and performs bounded local improvements via moves and swaps.
- **Performance**: Combined score 25.67 with max_kvpr 24.667, 100% success rate, and 0.004s execution time.
- **Feedback**: The method is correct and robust, consistently finding feasible placements that balance KV cache pressure with very low latency. The mix of diverse heuristics and local refinement likely drives the strong KVPR; exploring more variants or deeper local search could yield marginal gains.
**Program Identifier:** Generation 19 - Patch Name t_perturb_kbin_pairbounds_swap_local - Correct Program: True

**Program Name: Greedy-Search KVPR Balancer for GPU Placement**
- **Implementation**: Greedy min–max assignment with lookahead and tie-breaking (favoring lower resulting max KVPR, lower per-GPU KVPR, then more remaining memory), followed by bounded local improvements (single-model moves and capped pairwise swaps). Seeds with multiple model orderings, picks the best, then runs a parametric binary search on target KVPR using best-fit-decreasing in a transformed space, with optional final refinement and robust feasibility checks.
- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.002s execution time.
- **Feedback**: Ensemble seeding plus the parametric feasibility pass yielded consistent, fast placements that passed all validations. Further gains may come from expanding swap neighborhoods or adaptive iteration budgets, but the current approach is already efficient and robust.
**Program Identifier:** Generation 20 - Patch Name add_parametric_refinement - Correct Program: True

**Program Name: Min-Max KVPR GPU Model Placement**
- **Implementation**: Greedy min-max placement with lookahead and deterministic tie-breaking is followed by local improvement (move/swap) and multiple candidate orderings. It then runs a parametric binary search on T using a transformed capacity model (w = dR + T*size) with a best-fit decreasing assigner, bounded by several lower bounds, and optional refinement.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.003s.
- **Feedback**: The layered approach (heuristics + parametric search) effectively reduces worst-case KVPR while keeping runtime low, and it consistently produced feasible placements. Strong feasibility checks, careful tie-breaking, and capped local search iterations improved stability and robustness across test cases.
**Program Identifier:** Generation 21 - Patch Name hybrid_bfd_and_bounds - Correct Program: True

**Program Name: KVPR-Aware Multi-Stage GPU Placement**
- **Implementation**: Uses a multi-stage heuristic: greedy min-max assignment with KVPR lookahead and deterministic tie-breaking, followed by local improvements (single moves, pairwise swaps, and length-2 eject chains). It explores multiple model orderings, selects the best by (max, second, avg) KVPR, then applies a parametric Best-Fit-Decreasing with binary search on a KVPR target using several lower bounds, and optionally refines the result.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: The multi-start ordering plus targeted local search and parametric refinement effectively reduces peak KVPR while maintaining speed, yielding robust placements and 100% success. Iteration caps, careful tie-breaking, and bound-guided binary search contribute to stability and fast convergence, and the solution passed all validation tests.
**Program Identifier:** Generation 22 - Patch Name bfd_kbounds_ejectchain_tielex - Correct Program: True

**Program Name: Threshold-guided KVPR min-max placement**
- **Implementation**: Computes tight lower bounds (individual/global/pair/triplet/k-prefix) to initialize an exponential+binary search over a KVPR threshold T, then packs using multiple orderings (w(T)=n+T·m, intrinsic KVPR, demand/GB) and policies (residual, minmax, hybrid) under a transformed capacity model. Generates diverse candidates near-optimal T, adds a greedy min-max baseline, selects by measured KVPR, and applies local improvements (moves, swaps, two-opt); enforces 80 GB per-GPU and input validity.
- **Performance**: Combined score 25.76; max_kvpr 24.760; success_rate 1.000; execution_time 0.006s.
- **Feedback**: The program is correct and passes all validation tests. Candidate diversity plus local search consistently achieves low max KVPR with very fast runtime; bounded combinatorics in LB and swap stages maintain efficiency.
**Program Identifier:** Generation 23 - Patch Name triplet_bound_hybrid_policy_2opt_tiebreak - Correct Program: True

**Program Name: KVPR-Aware Multi-Strategy Placement**
- **Implementation**: Combines a parametric T-based bin packing (with lower bounds, exponential/binary search, and two orderings) with KVPR-aware regret insertion and memory heuristics, then applies local move/swap search to minimize the global max KVPR. It generates multiple candidates, evaluates by measured max KVPR, and uses strict validations, tie-breakers, and feasibility fallbacks.
- **Performance**: Combined score 26.19; max_kvpr 25.192; success_rate 1.000; execution_time 0.003s.
- **Feedback**: Delivers consistently feasible, low-KVPR placements at very low runtime; the parametric initialization plus local search notably improves quality. Passed all validation tests, and numerical guards/fallback strategies enhance robustness across diverse cases.
**Program Identifier:** Generation 24 - Patch Name add_parametric_T_candidates - Correct Program: True

**Program Name: Min-Max KVPR GPU Placement**
- **Implementation**: Uses greedy lookahead assignment across multiple model orderings with strict tie-breaking, then applies a capped local improvement phase (move/swap) to reduce the maximum KV cache pressure. It further performs a binary search on a KVPR target using transformed weights and several analytic lower bounds to tighten solutions, while enforcing memory feasibility.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.030s.
- **Feedback**: Multi-heuristic seeding plus limited local search provides robust, fast placements, and the parametric refinement reliably lowers worst-case pressure. The approach balances solution quality and speed well, though the fixed 80 GB GPU memory assumption should be parameterized for broader applicability.
**Program Identifier:** Generation 25 - Patch Name hybrid_bfd_and_tighter_bounds - Correct Program: True

**Program Name: Slack-Equalized KVPR GPU Placement**
- **Implementation**: Uses tight lower bounds (single/global/pair/triplet/k-prefix) and a multiplicative sweep over T to drive a slack-equalization assignment (w = dR + T*size) with seeding, ordering variants, dynamic T updates, and a local move/swap refinement; includes a greedy KVPR-minimizing fallback for infeasible cases.
- **Performance**: Combined score 24.52; max_kvpr 23.518; success_rate 1.000; execution_time 0.004s.
- **Feedback**: The multi-bound initialization and dynamic slack updating quickly find feasible low-KVPR placements, while local refinement reduces peak pressure further. Greedy fallback for slo=0 models safeguards feasibility, contributing to 100% success with very low runtime.
**Program Identifier:** Generation 26 - Patch Name kvpr_two_phase_slack - Correct Program: True

**Program Name: Slack-Equalized KVPR-Minimizing Model Placement**
- **Implementation**: Computes strong lower bounds for T (max KVPR), then performs a multiplicative sweep to a feasible T and packs using KV-slack equalization with weights w=dR+T*s and K_g=T*S−(sumR_g+T*mem_g), trying multiple orderings and tie-breakers. Includes a deterministic greedy fallback for infeasible/infinite-demand cases and a bounded local move/swap refinement to reduce the worst-GPU KVPR.
- **Performance**: Combined score 36.51; max_kvpr 35.512; success_rate 1.000; execution_time 0.002s.
- **Feedback**: The lower-bound-guided search plus local refinement produced consistently feasible, high-quality placements with very low latency and perfect success. Edge cases with zero-SLO/infinite demand are handled via the greedy path, which zeroes their pressure in sums—robust for feasibility but potentially conservative for optimality.
**Program Identifier:** Generation 27 - Patch Name slack_bsearch_hybrid - Correct Program: True

**Program Name: Min-Max KVPR GPU Model Placement**
- **Implementation**: Uses a greedy, lookahead min-max placement with lexicographic KVPR scoring across multiple model orderings, followed by local move/swap improvements. Adds a parametric binary search on target KVPR using transformed best-fit packing with multiple lower bounds, then selects the best candidate and optionally refines it.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.004s.
- **Feedback**: The multi-heuristic pipeline and careful tie-breaking yield low worst-case KVPR with perfect feasibility and very fast runtime. Lower-bound seeding stabilizes the binary search, and clear fallbacks make the solver robust across test cases.
**Program Identifier:** Generation 28 - Patch Name lex_triplet_hybrid - Correct Program: True

**Program Name: Balanced-slack KVPR minimization with local search**
- **Implementation**: Uses lower-bound-guided target-KVPR (T) search with a balanced-slack bin packer (weight = dR + T*size), multiple orderings/tie-breaks, and seeding of high-pressure items. Augments with multi-order greedy placement, bounded move/swap local refinements, a binary search to tighten T, deterministic RNG, and strict memory/KVPR validation with a greedy fallback.
- **Performance**: Combined score 29.35 (max_kvpr 28.347, success_rate 1.000) with 0.003s execution time.
- **Feedback**: The multi-heuristic T-sweep plus local refinement reliably reduces peak KVPR while maintaining feasibility; fallback paths handle edge cases (e.g., infinite dR or tight memory). Passed all validation tests, indicating correctness and robustness.
**Program Identifier:** Generation 29 - Patch Name kvpr_balanced_bsearch - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

## Successful Algorithmic Patterns
- Slack-equalization around a KVPR threshold T is the clear winner. The current best program, Slack-Equalized KVPR-Minimizing Model Placement (Generation 27, slack_bsearch_hybrid), achieved the top combined score 36.51 (success_rate 1.000, 0.002s) by explicitly equalizing per-GPU KV slack K_g = T·S − (ΣR_g + T·mem_g), placing items to minimize nonnegative K_after, and then running a compact T-neighborhood search plus bounded local refinement.
- Strong lower bounds and a fast multiplicative T sweep consistently accelerate convergence and stabilize quality. The best program computes per-item, global, pair (filtered to top 200 by size), and k-prefix bounds to seed the sweep and then explores a small set of Ts around the first feasible T (e.g., {0.99, 1.0, 1.005, 1.02}·T_feas plus midpoint), maintaining ultra-low latency (0.002s) while improving placements.
- Diversified orderings with deterministic tie-breaking and light randomization improve robustness. Generation 27 and other high-performers try multiple orderings (w_desc, intrinsic_desc, density_desc, size_desc) with strict feasibility checks and small top-2 randomized tie-breaks, leading to consistent, fast solutions (e.g., Gens 20–22, 25, 28 all at 26.17 and 0.003–0.030s with similar diversification).
- Bounded local search focused on the worst GPU reliably trims residual peak KVPR. Programs that include capped moves/swaps improve max KVPR at negligible cost (e.g., Gen 27’s move_budget=20, swap_budget=10; Gen 24’s local refinement), contributing to their robust outcomes.

## Ineffective Approaches
- Pure greedy or lookahead-only greedy without T-based feasibility modeling underperformed in prior evaluations (e.g., early baselines at 21.89; Greedy KV Cache Pressure Balancer, Gen 2, 20.74). They fail to align placement decisions with global KVPR thresholds, trailing parametric and slack-equalized methods.
- Over-reliance on transformed-space best-fit (w = dR + T·size) plateaued around the 26.17–26.23 tier. Multiple programs with hybrid BFD and binary search (Gens 20, 21, 22, 25, 28) clustered at 26.17 despite careful tie-breaking and local search, indicating diminishing returns from BFD alone versus direct slack equalization.
- Complexity without direct slack equalization did not break the plateau. Threshold-guided KVPR min-max placement (Gen 23, 25.76) used extensive bounds (including triplet) and multiple policies/orderings but still lagged the 26.17–26.19 tier, suggesting that more candidate diversity in BFD-style pipelines alone doesn’t deliver further gains.
- Slack-equalization variants can regress if not tightly integrated. Slack-Equalized KVPR GPU Placement (Gen 26, 24.52) used multiplicative T sweep and local refinement but underperformed relative to both the 26.17 cluster and the best slack-equalized approach. Feedback points to conservative greedy fallbacks and dynamic updates that safeguard feasibility yet may lose optimality.

## Implementation Insights
- Why the current best works (Gen 27, 36.51):
  -

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

1. Add a two-phase, in-placement T update inside assign_balanced_slack. After placing the first 40% of items with T = T_feas, recompute a lower bound using only the remaining items and the residual per-GPU capacities, set T’ = max(T, new_lower_bound), rebuild weights w = dR + T’·size for the remainder, re-sort, and continue. Keep order/choose_rule unchanged to preserve slack-equalization behavior while correcting discrete effects that misalign T mid-pack.

2. Tighten lower bounds with a light triplet bound and deeper k-prefix. For the top P=120 largest items by size, scan O(P^2) triplets by fixing i,j and picking k from a short list (top-8 by size) to enforce T ≥ (ri+rj+rk)/(3S − (si+sj+sk)) when si+sj+sk > 2S; also extend the k-prefix bound to k up to min(gpu_num, 6). Early-stop the multiplicative sweep when the growing T falls below any newly raised bound to save iterations and stabilize T_feas.

3. Introduce a hybrid slack-aware selection rule as an additional choose_rule. Minimize J = K_after_norm + α·kv_new_norm + β·mem_imbalance, with K_after_norm = max(0, K_after)/(T·S), kv_new_norm = kv_new/max(T, 1e-12), mem_imbalance = |(used_mem_g + size)/S − avg_mem_frac|, using α=0.15, β=0.05 and raising α→0.25 when var(K) across GPUs drops below a small threshold. Evaluate this variant alongside ‘tight’ and ‘min_kvpr’ in both the first-feasible search and the T-neighborhood to capture residual KVPR differences without abandoning slack-equalization.

4. Expand the bounded local refinement with targeted 2-opt swaps and short eject chains. After the current move/swap phase, run up to 12 2-opt swaps between the two highest-KVPR GPUs, selecting pairs by best reduction in global max KVPR using cached per-bucket R and mem; if still stuck, try up to 8 length-2 eject chains (Gmax→G2, then G2→Gk) that strictly reduce the max. Keep all caps tight to maintain sub-millisecond runtime and only commit improving transformations.

5. Make candidate selection more robust with a slightly wider T-neighborhood, lexicographic scoring, and tiny ensemble restarts. Try T ∈ {0.985, 0.99, 1.0, 1.005, 1.01, 1.015}·T_feas plus midpoint with lower, evaluate each variant with 2 deterministic seeds, and select by (max KVPR, second-worst KVPR, mean KVPR). This preserves the fast sweep while avoiding “hidden spikes” on the second-most loaded GPU and harvesting small gains from diversification.