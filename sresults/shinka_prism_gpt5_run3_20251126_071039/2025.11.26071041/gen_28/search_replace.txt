<NAME>
lex_triplet_hybrid
</NAME>

<DESCRIPTION>
I introduce three targeted improvements:
1) Lexicographic scoring when choosing among greedy orderings and final candidates. Instead of minimizing only the maximum KVPR, we compare candidates by (max KVPR, second-worst KVPR, average KVPR). This reduces hidden spikes on the second-most loaded GPU and yields better overall KVPR distributions.
2) Strengthened lower bounds by adding a triplet bound and extending the k-prefix bound to k up to 6. The triplet bound scans a small subset of largest models (top-200, with the third element from top-10) to tighten feasible T early, improving the parametric search effectiveness without noticeable runtime overhead.
3) Enhanced bfd_assign_for_T tie-breaking with a hybrid cost that combines projected global max KVPR with normalized local KVPR, slack (capacity) utilization, and memory imbalance. This selects more balanced placements when projected costs are close, further reducing the final max KVPR.

These changes are minimal, keep the code simple, safe, and fast, while directly targeting the objective of minimizing the maximum KVPR across GPUs.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Helper to compute KVPR for a GPU safely
    def kvpr(R, rem_mem):
        if rem_mem <= 0:
            return float('inf')
        return R / rem_mem
=======
    # Helper to compute KVPR for a GPU safely
    def kvpr(R, rem_mem):
        if rem_mem <= 0:
            return float('inf')
        return R / rem_mem

    # Lexicographic scoring: (max KVPR, second-worst KVPR, average KVPR)
    def lex_score(kvprs):
        if not kvprs:
            return (0.0, 0.0, 0.0)
        kv_sorted = sorted(kvprs, reverse=True)
        maxv = kv_sorted[0]
        second = kv_sorted[1] if len(kv_sorted) > 1 else kv_sorted[0]
        avg = sum(kv_sorted) / float(len(kv_sorted))
        return (maxv, second, avg)

    def is_better_score(a, b, eps=1e-12):
        # Return True if score a is strictly better (smaller lexicographically) than b
        if a[0] + eps < b[0]:
            return True
        if abs(a[0] - b[0]) <= eps:
            if a[1] + eps < b[1]:
                return True
            if abs(a[1] - b[1]) <= eps:
                return a[2] < b[2]
        return False
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_placement = None
    best_max_kvpr = float('inf')

    for make_order in orderings:
        try:
            ordered = make_order(models)
            placement, rem_mem, sum_r_over_s = greedy_assign(ordered)
            # Refine with local improvements
            placement, rem_mem, sum_r_over_s = improve(placement, rem_mem, sum_r_over_s)
            # Evaluate
            kvprs = [kvpr(sum_r_over_s[i], rem_mem[i]) for i in range(gpu_num)]
            cand_max = max(kvprs) if kvprs else 0.0
            if cand_max < best_max_kvpr:
                best_max_kvpr = cand_max
                best_placement = placement
        except ValueError:
            # This ordering couldn't place all models due to per-GPU memory constraints
            continue

    if best_placement is None:
        # Fall back to an error consistent with greedy behavior
        # Try a final simple size-desc heuristic to produce a clearer error state
        ordered = sorted(models, key=lambda m: m.model_size, reverse=True)
        # This will raise ValueError if infeasible
        best_placement, _, _ = greedy_assign(ordered)
=======
    best_placement = None
    best_score = (float('inf'), float('inf'), float('inf'))

    for make_order in orderings:
        try:
            ordered = make_order(models)
            placement, rem_mem, sum_r_over_s = greedy_assign(ordered)
            # Refine with local improvements
            placement, rem_mem, sum_r_over_s = improve(placement, rem_mem, sum_r_over_s)
            # Evaluate via lexicographic scoring
            kvprs = [kvpr(sum_r_over_s[i], rem_mem[i]) for i in range(gpu_num)]
            cand_score = lex_score(kvprs)
            if is_better_score(cand_score, best_score):
                best_score = cand_score
                best_placement = placement
        except ValueError:
            # This ordering couldn't place all models due to per-GPU memory constraints
            continue

    if best_placement is None:
        # Fall back to an error consistent with greedy behavior
        # Try a final simple size-desc heuristic to produce a clearer error state
        ordered = sorted(models, key=lambda m: m.model_size, reverse=True)
        # This will raise ValueError if infeasible
        best_placement, rem_mem, sum_r_over_s = greedy_assign(ordered)
        # Compute score (not strictly needed later but keeps consistency)
        _ = lex_score([kvpr(sum_r_over_s[i], rem_mem[i]) for i in range(gpu_num)])
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def bfd_assign_for_T(T):
        # Hybrid best-fit using transformed weights that also enforces memory
        # and minimizes the projected global max KVPR after each placement.
        capacity = T * S
        if T < 0:
            return None

        # Build items with transformed weights
        items = []
        for m in models:
            dR = (m.req_rate / m.slo)
            w = dR + T * m.model_size
            if w < 0:
                w = 0.0
            items.append((w, dR, m.model_size, m))
        items.sort(key=lambda x: x[0], reverse=True)

        used_w = [0.0] * gpu_num
        bins_R = [0.0] * gpu_num
        bins_used_mem = [0.0] * gpu_num
        assign = {i: [] for i in range(gpu_num)}

        for w, dR, sz, m in items:
            # Compute current top-1 and top-2 KVPRs to evaluate projected global max quickly
            top1_val = -1.0
            top2_val = -1.0
            top1_id = -1
            for gid in range(gpu_num):
                rem = S - bins_used_mem[gid]
                val = kvpr(bins_R[gid], rem)
                if val > top1_val:
                    top2_val = top1_val
                    top1_val = val
                    top1_id = gid
                elif val > top2_val:
                    top2_val = val

            best_gid = None
            best_result = float('inf')
            best_new_k = float('inf')
            best_after_w = float('inf')
            best_rem_after = -1.0

            for gid in range(gpu_num):
                nw = used_w[gid] + w
                mem_after = bins_used_mem[gid] + sz
                if nw <= capacity + 1e-9 and mem_after <= S + 1e-9:
                    rem_after = S - mem_after
                    if rem_after <= 0:
                        continue
                    new_k = (bins_R[gid] + dR) / rem_after
                    max_other = top2_val if gid == top1_id else top1_val
                    projected = new_k if new_k > max_other else max_other

                    if (projected < best_result or
                        (projected == best_result and new_k < best_new_k) or
                        (projected == best_result and new_k == best_new_k and nw < best_after_w) or
                        (projected == best_result and new_k == best_new_k and nw == best_after_w and rem_after > best_rem_after)):
                        best_result = projected
                        best_new_k = new_k
                        best_after_w = nw
                        best_rem_after = rem_after
                        best_gid = gid

            if best_gid is None:
                return None

            used_w[best_gid] += w
            bins_R[best_gid] += dR
            bins_used_mem[best_gid] += sz
            assign[best_gid].append(m)

        # Validate memory and KVPR constraints for this T
        for gid in range(gpu_num):
            if bins_used_mem[gid] - S > 1e-6:
                return None
            rem = S - bins_used_mem[gid]
            if rem <= 0:
                if bins_R[gid] > 1e-12:
                    return None
            else:
                if (bins_R[gid] / rem) - T > 1e-6:
                    return None
        return assign
=======
    def bfd_assign_for_T(T):
        # Hybrid best-fit using transformed weights: enforce memory and minimize
        # projected global max KVPR, with a slack/memory-aware tie-break.
        capacity = T * S
        if T < 0:
            return None

        # Build items with transformed weights
        items = []
        for m in models:
            dR = (m.req_rate / m.slo)
            w = dR + T * m.model_size
            if w < 0:
                w = 0.0
            items.append((w, dR, m.model_size, m))
        items.sort(key=lambda x: x[0], reverse=True)

        used_w = [0.0] * gpu_num
        bins_R = [0.0] * gpu_num
        bins_used_mem = [0.0] * gpu_num
        assign = {i: [] for i in range(gpu_num)}

        total_used_mem = 0.0
        alpha = 0.15
        beta = 0.05
        eps = 1e-12

        for w, dR, sz, m in items:
            # Compute current top-1 and top-2 KVPRs to evaluate projected global max quickly
            top1_val = -1.0
            top2_val = -1.0
            top1_id = -1
            for gid in range(gpu_num):
                rem = S - bins_used_mem[gid]
                val = kvpr(bins_R[gid], rem)
                if val > top1_val:
                    top2_val = top1_val
                    top1_val = val
                    top1_id = gid
                elif val > top2_val:
                    top2_val = val

            # Global average memory fraction after placing this item (independent of gid)
            avg_mem_frac_after = (total_used_mem + sz) / (gpu_num * S) if S > 0 else 0.0

            best_gid = None
            best_proj = float('inf')
            best_hybrid = float('inf')
            best_nw = float('inf')
            best_rem_after = -1.0

            for gid in range(gpu_num):
                nw = used_w[gid] + w
                mem_after = bins_used_mem[gid] + sz
                if nw <= capacity + 1e-9 and mem_after <= S + 1e-9:
                    rem_after = S - mem_after
                    if rem_after <= 0:
                        continue
                    new_k = (bins_R[gid] + dR) / rem_after
                    max_other = top2_val if gid == top1_id else top1_val
                    projected = new_k if new_k > max_other else max_other

                    # Hybrid tie-break cost
                    cap = capacity if capacity > 0 else 1.0
                    k_after_norm = max(0.0, (capacity - nw)) / (cap + eps)
                    kv_new_norm = new_k / max(T, eps) if T > eps else new_k
                    mem_imbalance = abs((mem_after / S) - avg_mem_frac_after) if S > 0 else 0.0
                    hybrid = k_after_norm + alpha * kv_new_norm + beta * mem_imbalance

                    if (projected + 1e-12 < best_proj or
                        (abs(projected - best_proj) <= 1e-12 and (hybrid < best_hybrid or
                                                                 (abs(hybrid - best_hybrid) <= 1e-12 and (nw < best_nw or
                                                                                                         (nw == best_nw and rem_after > best_rem_after)))))):
                        best_proj = projected
                        best_hybrid = hybrid
                        best_nw = nw
                        best_rem_after = rem_after
                        best_gid = gid

            if best_gid is None:
                return None

            used_w[best_gid] += w
            bins_R[best_gid] += dR
            bins_used_mem[best_gid] += sz
            assign[best_gid].append(m)
            total_used_mem += sz

        # Validate memory and KVPR constraints for this T
        for gid in range(gpu_num):
            if bins_used_mem[gid] - S > 1e-6:
                return None
            rem = S - bins_used_mem[gid]
            if rem <= 0:
                if bins_R[gid] > 1e-12:
                    return None
            else:
                if (bins_R[gid] / rem) - T > 1e-6:
                    return None
        return assign
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Lower bound 3: pair bound for pairs that cannot co-reside (si + sj > S)
    lb_pair = 0.0
    if models:
        P = min(len(models), 200)
        by_size = sorted(models, key=lambda m: m.model_size, reverse=True)[:P]
        for i in range(len(by_size)):
            mi = by_size[i]
            si = mi.model_size
            ri = (mi.req_rate / mi.slo)
            for j in range(i + 1, len(by_size)):
                mj = by_size[j]
                sj = mj.model_size
                rj = (mj.req_rate / mj.slo)
                if si + sj > S:
                    denom = 2 * S - (si + sj)
                    if denom > 0:
                        cand = (ri + rj) / denom
                        if cand > lb_pair:
                            lb_pair = cand
=======
    # Lower bound 3: pair bound for pairs that cannot co-reside (si + sj > S)
    lb_pair = 0.0
    if models:
        P = min(len(models), 200)
        by_size = sorted(models, key=lambda m: m.model_size, reverse=True)[:P]
        for i in range(len(by_size)):
            mi = by_size[i]
            si = mi.model_size
            ri = (mi.req_rate / mi.slo)
            for j in range(i + 1, len(by_size)):
                mj = by_size[j]
                sj = mj.model_size
                rj = (mj.req_rate / mj.slo)
                if si + sj > S:
                    denom = 2 * S - (si + sj)
                    if denom > 0:
                        cand = (ri + rj) / denom
                        if cand > lb_pair:
                            lb_pair = cand

        # Lower bound 3b: triplet bound for triples with si + sj + sk > 2S
        lb_triplet = 0.0
        if len(by_size) >= 3:
            KTOP = min(10, len(by_size))
            topK = by_size[:KTOP]
            for i in range(len(by_size)):
                mi = by_size[i]
                si = mi.model_size
                ri = (mi.req_rate / mi.slo)
                for j in range(i + 1, len(by_size)):
                    mj = by_size[j]
                    sj = mj.model_size
                    rj = (mj.req_rate / mj.slo)
                    for mk in topK:
                        if mk is mi or mk is mj:
                            continue
                        sk = mk.model_size
                        rk = (mk.req_rate / mk.slo)
                        ssum = si + sj + sk
                        if ssum > 2 * S:
                            denom = 3 * S - ssum
                            if denom > 0:
                                cand = (ri + rj + rk) / denom
                                if cand > lb_triplet:
                                    lb_triplet = cand
        else:
            lb_triplet = 0.0
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        for k in range(1, min(gpu_num, 5) + 1):
            threshold = (k - 1) * S
            idx = -1
            for t in range(len(prefix_sizes)):
                if prefix_sizes[t] > threshold:
                    idx = t
                    break
            if idx >= 0:
                numer = prefix_rates[idx]
                denom = k * S - prefix_sizes[idx]
                if denom > 0 and numer > 0:
                    cand = numer / denom
                    if cand > lb_k:
                        lb_k = cand
=======
        for k in range(1, min(gpu_num, 6) + 1):
            threshold = (k - 1) * S
            idx = -1
            for t in range(len(prefix_sizes)):
                if prefix_sizes[t] > threshold:
                    idx = t
                    break
            if idx >= 0:
                numer = prefix_rates[idx]
                denom = k * S - prefix_sizes[idx]
                if denom > 0 and numer > 0:
                    cand = numer / denom
                    if cand > lb_k:
                        lb_k = cand
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    lower = max(0.0, lb1, lb2, lb_pair, lb_k)
=======
    lower = max(0.0, lb1, lb2, lb_pair, lb_triplet, lb_k)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_final = best_placement
    best_val = max_kvpr_of(best_final)

    if best_bsearch is not None:
        # Try a short local improvement on the parametric candidate
        rem_mem_b, sum_r_b = summarize(best_bsearch)
        improved_bsearch, rem_mem_b, sum_r_b = improve({i: list(best_bsearch.get(i, [])) for i in range(gpu_num)},
                                                       rem_mem_b, sum_r_b)
        val_b = max_kvpr_of(improved_bsearch)
        if val_b + 1e-12 < best_val:
            best_final = improved_bsearch
            best_val = val_b

    return best_final
=======
    best_final = best_placement
    # Score the current best using lexicographic metrics
    rem_init, sr_init = summarize(best_final)
    kvprs_init = [kvpr(sr_init[i], rem_init[i]) for i in range(gpu_num)]
    best_score_final = lex_score(kvprs_init)

    if best_bsearch is not None:
        # Try a short local improvement on the parametric candidate
        rem_mem_b, sum_r_b = summarize(best_bsearch)
        improved_bsearch, rem_mem_b, sum_r_b = improve({i: list(best_bsearch.get(i, [])) for i in range(gpu_num)},
                                                       rem_mem_b, sum_r_b)
        kvprs_b = [kvpr(sum_r_b[i], rem_mem_b[i]) for i in range(gpu_num)]
        score_b = lex_score(kvprs_b)
        if is_better_score(score_b, best_score_final):
            best_final = improved_bsearch
            best_score_final = score_b

    return best_final
>>>>>>> REPLACE

</DIFF>