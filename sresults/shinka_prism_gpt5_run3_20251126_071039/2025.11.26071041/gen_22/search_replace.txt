<NAME>
bfd_kbounds_ejectchain_tielex
</NAME>

<DESCRIPTION>
This edit makes four targeted improvements to minimize the maximum KVPR while keeping the code simple and fast:

1) Strengthen lower bounds for binary search T by adding a pairwise bound and a k-prefix bound (up to k=min(6, gpu_num)), in addition to existing per-item and global bounds. Tighter lower bounds focus the search and improve feasibility discrimination.

2) Improve Best-Fit-Decreasing assignment under transformed weights (for a given T) by breaking ties using the projected per-GPU KVPR after placement, not just weight closeness. This aligns bin selection with the objective.

3) Enhance the local improvement routine with a bounded length-2 eject chain: if no single move or swap improves the max KVPR, try moving a model off the worst GPU by evicting one model from a destination GPU to a third GPU. This captures improvements single-step moves/swaps may miss, with strict caps to preserve speed.

4) Make candidate ordering selection more robust via lexicographic scoring: when evaluating greedy-then-improve placements across multiple orderings, break ties on max KVPR by second-worst KVPR and then by average KVPR to avoid hidden spikes.

These changes are minimal, self-contained, and consistent with the current structure, improving solution quality without harming runtime or stability.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
            else:
                # Try one pairwise swap between the most pressured GPU and others
                best_swap = None  # (src, dst, a, b, resulting_max)
                src = max_gid
                # Cap the search to keep it fast
                cap_a = max(3, min(10, len(placement[src])))
                for ai, a in enumerate(list(placement[src])[:cap_a]):
                    aR = a.req_rate / a.slo
                    aS = a.model_size
                    for dst in range(gpu_num):
                        if dst == src or not placement[dst]:
                            continue
                        cap_b = max(3, min(10, len(placement[dst])))
                        for bi, b in enumerate(list(placement[dst])[:cap_b]):
                            bR = b.req_rate / b.slo
                            bS = b.model_size

                            # New states after swap
                            src_new_R = sum_r_over_s[src] - aR + bR
                            dst_new_R = sum_r_over_s[dst] - bR + aR
                            src_new_mem = rem_mem[src] + aS - bS
                            dst_new_mem = rem_mem[dst] + bS - aS

                            if src_new_mem < 0 or dst_new_mem < 0:
                                continue

                            src_new_kvpr = kvpr(src_new_R, src_new_mem)
                            dst_new_kvpr = kvpr(dst_new_R, dst_new_mem)

                            # Compute resulting max across all GPUs
                            resulting_max = src_new_kvpr if src_new_kvpr > dst_new_kvpr else dst_new_kvpr
                            for j in range(gpu_num):
                                if j == src or j == dst:
                                    continue
                                if kvprs[j] > resulting_max:
                                    resulting_max = kvprs[j]

                            if resulting_max + eps < current_max:
                                if best_swap is None or resulting_max < best_swap[4]:
                                    best_swap = (src, dst, a, b, resulting_max)

                if best_swap is not None:
                    src, dst, a, b, _ = best_swap
                    # Apply swap
                    placement[src].remove(a)
                    placement[dst].append(a)
                    placement[dst].remove(b)
                    placement[src].append(b)

                    aR = a.req_rate / a.slo
                    bR = b.req_rate / b.slo
                    aS = a.model_size
                    bS = b.model_size

                    sum_r_over_s[src] = sum_r_over_s[src] - aR + bR
                    sum_r_over_s[dst] = sum_r_over_s[dst] - bR + aR
                    rem_mem[src] = rem_mem[src] + aS - bS
                    rem_mem[dst] = rem_mem[dst] + bS - aS
                    improved = True
=======
            else:
                # Try one pairwise swap between the most pressured GPU and others
                best_swap = None  # (src, dst, a, b, resulting_max)
                src = max_gid
                # Cap the search to keep it fast
                cap_a = max(3, min(10, len(placement[src])))
                for ai, a in enumerate(list(placement[src])[:cap_a]):
                    aR = a.req_rate / a.slo
                    aS = a.model_size
                    for dst in range(gpu_num):
                        if dst == src or not placement[dst]:
                            continue
                        cap_b = max(3, min(10, len(placement[dst])))
                        for bi, b in enumerate(list(placement[dst])[:cap_b]):
                            bR = b.req_rate / b.slo
                            bS = b.model_size

                            # New states after swap
                            src_new_R = sum_r_over_s[src] - aR + bR
                            dst_new_R = sum_r_over_s[dst] - bR + aR
                            src_new_mem = rem_mem[src] + aS - bS
                            dst_new_mem = rem_mem[dst] + bS - aS

                            if src_new_mem < 0 or dst_new_mem < 0:
                                continue

                            src_new_kvpr = kvpr(src_new_R, src_new_mem)
                            dst_new_kvpr = kvpr(dst_new_R, dst_new_mem)

                            # Compute resulting max across all GPUs
                            resulting_max = src_new_kvpr if src_new_kvpr > dst_new_kvpr else dst_new_kvpr
                            for j in range(gpu_num):
                                if j == src or j == dst:
                                    continue
                                if kvprs[j] > resulting_max:
                                    resulting_max = kvprs[j]

                            if resulting_max + eps < current_max:
                                if best_swap is None or resulting_max < best_swap[4]:
                                    best_swap = (src, dst, a, b, resulting_max)

                if best_swap is not None:
                    src, dst, a, b, _ = best_swap
                    # Apply swap
                    placement[src].remove(a)
                    placement[dst].append(a)
                    placement[dst].remove(b)
                    placement[src].append(b)

                    aR = a.req_rate / a.slo
                    bR = b.req_rate / b.slo
                    aS = a.model_size
                    bS = b.model_size

                    sum_r_over_s[src] = sum_r_over_s[src] - aR + bR
                    sum_r_over_s[dst] = sum_r_over_s[dst] - bR + aR
                    rem_mem[src] = rem_mem[src] + aS - bS
                    rem_mem[dst] = rem_mem[dst] + bS - aS
                    improved = True
                else:
                    # Length-2 eject chain: src(max)->dst by evicting b from dst to k
                    best_chain = None  # (src, dst, k, a, b, resulting_max)
                    cap_a2 = min(6, len(placement[src]))
                    for a in list(placement[src])[:cap_a2]:
                        aR = a.req_rate / a.slo
                        aS = a.model_size
                        # Consider destination GPUs that currently cannot fit a without eviction
                        for dst in range(gpu_num):
                            if dst == src or not placement[dst]:
                                continue
                            if rem_mem[dst] + 1e-9 >= aS:
                                continue  # regular move would handle this
                            cap_b2 = min(6, len(placement[dst]))
                            for b in list(placement[dst])[:cap_b2]:
                                bR = b.req_rate / b.slo
                                bS = b.model_size
                                # After evicting b from dst, can a fit?
                                if rem_mem[dst] + bS + 1e-9 < aS:
                                    continue
                                # Find a third GPU k to host b
                                for k in range(gpu_num):
                                    if k == dst or k == src:
                                        continue
                                    if rem_mem[k] + 1e-9 < bS:
                                        continue
                                    # Compute new remaining memories
                                    rem_src_new = rem_mem[src] + aS
                                    rem_dst_new = rem_mem[dst] + bS - aS
                                    rem_k_new = rem_mem[k] - bS
                                    if rem_src_new <= 0 or rem_dst_new <= 0 or rem_k_new <= 0:
                                        # If any bucket becomes full with positive load, skip
                                        if (rem_src_new <= 0 and (sum_r_over_s[src] - aR) > 1e-12) or \
                                           (rem_dst_new <= 0 and (sum_r_over_s[dst] - bR + aR) > 1e-12) or \
                                           (rem_k_new <= 0 and (sum_r_over_s[k] + bR) > 1e-12):
                                            continue
                                    # New loads
                                    src_R_new = sum_r_over_s[src] - aR
                                    dst_R_new = sum_r_over_s[dst] - bR + aR
                                    k_R_new = sum_r_over_s[k] + bR

                                    # Compute KVPRs post chain
                                    src_kv = kvpr(src_R_new, rem_src_new)
                                    dst_kv = kvpr(dst_R_new, rem_dst_new)
                                    k_kv = kvpr(k_R_new, rem_k_new)
                                    resulting = src_kv if src_kv > dst_kv else dst_kv
                                    if k_kv > resulting:
                                        resulting = k_kv
                                    for g in range(gpu_num):
                                        if g == src or g == dst or g == k:
                                            continue
                                        if kvprs[g] > resulting:
                                            resulting = kvprs[g]
                                    if resulting + eps < current_max:
                                        if best_chain is None or resulting < best_chain[5]:
                                            best_chain = (src, dst, k, a, b, resulting)
                    if best_chain is not None:
                        src, dst, k, a, b, _ = best_chain
                        # Apply chain: b from dst->k, a from src->dst
                        placement[src].remove(a)
                        placement[dst].append(a)
                        placement[dst].remove(b)
                        placement[k].append(b)

                        aR = a.req_rate / a.slo
                        bR = b.req_rate / b.slo
                        aS = a.model_size
                        bS = b.model_size

                        # Update sums and remaining memory
                        sum_r_over_s[src] -= aR
                        rem_mem[src] += aS

                        sum_r_over_s[dst] = sum_r_over_s[dst] - bR + aR
                        rem_mem[dst] = rem_mem[dst] + bS - aS

                        sum_r_over_s[k] += bR
                        rem_mem[k] -= bS
                        improved = True
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        for w, dR, sz, m in items:
            best_bin = None
            best_after = float('inf')
            for gid in range(gpu_num):
                nw = used_w[gid] + w
                if nw <= capacity + 1e-9:
                    if nw < best_after:
                        best_after = nw
                        best_bin = gid
            if best_bin is None:
                return None
            used_w[best_bin] += w
            bins_R[best_bin] += dR
            bins_used_mem[best_bin] += sz
            assign[best_bin].append(m)
=======
        for w, dR, sz, m in items:
            best_bin = None
            best_key = (float('inf'), float('inf'))
            for gid in range(gpu_num):
                nw = used_w[gid] + w
                if nw <= capacity + 1e-9:
                    rem_after = S - (bins_used_mem[gid] + sz)
                    R_after = bins_R[gid] + dR
                    if rem_after <= 0:
                        kv_after = float('inf') if R_after > 1e-12 else 0.0
                    else:
                        kv_after = R_after / rem_after
                    key = (nw, kv_after)
                    if key < best_key:
                        best_key = key
                        best_bin = gid
            if best_bin is None:
                return None
            used_w[best_bin] += w
            bins_R[best_bin] += dR
            bins_used_mem[best_bin] += sz
            assign[best_bin].append(m)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_placement = None
    best_max_kvpr = float('inf')

    for make_order in orderings:
        try:
            ordered = make_order(models)
            placement, rem_mem, sum_r_over_s = greedy_assign(ordered)
            # Refine with local improvements
            placement, rem_mem, sum_r_over_s = improve(placement, rem_mem, sum_r_over_s)
            # Evaluate
            kvprs = [kvpr(sum_r_over_s[i], rem_mem[i]) for i in range(gpu_num)]
            cand_max = max(kvprs) if kvprs else 0.0
            if cand_max < best_max_kvpr:
                best_max_kvpr = cand_max
                best_placement = placement
        except ValueError:
            # This ordering couldn't place all models due to per-GPU memory constraints
            continue
=======
    best_placement = None
    best_score = (float('inf'), float('inf'), float('inf'))

    for make_order in orderings:
        try:
            ordered = make_order(models)
            placement, rem_mem, sum_r_over_s = greedy_assign(ordered)
            # Refine with local improvements
            placement, rem_mem, sum_r_over_s = improve(placement, rem_mem, sum_r_over_s)
            # Evaluate
            kvprs = [kvpr(sum_r_over_s[i], rem_mem[i]) for i in range(gpu_num)]
            if kvprs:
                sorted_k = sorted(kvprs, reverse=True)
                cand_max = sorted_k[0]
                cand_second = sorted_k[1] if len(sorted_k) > 1 else 0.0
                cand_avg = sum(kvprs) / len(kvprs)
            else:
                cand_max = 0.0
                cand_second = 0.0
                cand_avg = 0.0
            cand_score = (cand_max, cand_second, cand_avg)
            if cand_score < best_score:
                best_score = cand_score
                best_placement = placement
        except ValueError:
            # This ordering couldn't place all models due to per-GPU memory constraints
            continue
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    total_R = sum((m.req_rate / m.slo) for m in models)
    total_size = sum(m.model_size for m in models)

    # Lower bound 1: per-model bound T >= dR / (S - size) for any model
    lb1 = 0.0
    infeasible_single = False
    for m in models:
        dR = (m.req_rate / m.slo)
        denom = S - m.model_size
        if denom <= 0:
            if dR > 0:
                infeasible_single = True
            continue
        if dR > 0:
            cand = dR / denom
            if cand > lb1:
                lb1 = cand

    # Lower bound 2: global bound from totals
    denom2 = gpu_num * S - total_size
    if denom2 <= 0 and total_R > 0:
        # Not enough aggregate free memory to host any KV capacity
        return best_placement
    lb2 = 0.0 if denom2 <= 0 else (total_R / denom2 if total_R > 0 else 0.0)

    if infeasible_single:
        return best_placement

    lower = max(0.0, lb1, lb2)
=======
    total_R = sum((m.req_rate / m.slo) for m in models)
    total_size = sum(m.model_size for m in models)

    # Lower bound 1: per-model bound T >= dR / (S - size) for any model
    lb1 = 0.0
    infeasible_single = False
    for m in models:
        dR = (m.req_rate / m.slo)
        denom = S - m.model_size
        if denom <= 0:
            if dR > 0:
                infeasible_single = True
            continue
        if dR > 0:
            cand = dR / denom
            if cand > lb1:
                lb1 = cand

    # Lower bound 2: global bound from totals
    denom2 = gpu_num * S - total_size
    if denom2 <= 0 and total_R > 0:
        # Not enough aggregate free memory to host any KV capacity
        return best_placement
    lb2 = 0.0 if denom2 <= 0 else (total_R / denom2 if total_R > 0 else 0.0)

    # Lower bound 3: pair bound for items that cannot co-reside on one GPU
    lb_pair = 0.0
    P = min(len(models), 200)
    by_size = sorted(models, key=lambda m: m.model_size, reverse=True)[:P]
    for i in range(len(by_size)):
        mi = by_size[i]; si = mi.model_size; ri = (mi.req_rate / mi.slo)
        for j in range(i + 1, len(by_size)):
            mj = by_size[j]; sj = mj.model_size; rj = (mj.req_rate / mj.slo)
            if si + sj > S:
                denom = 2 * S - (si + sj)
                if denom > 0:
                    cand = (ri + rj) / denom
                    if cand > lb_pair:
                        lb_pair = cand

    # Lower bound 4: k-prefix bound (k up to min(gpu_num, 6))
    lb_k = 0.0
    sized = sorted(((m.model_size, (m.req_rate / m.slo)) for m in models), key=lambda t: t[0], reverse=True)
    prefix_s, prefix_r = [], []
    cs = 0.0; cr = 0.0
    for s_i, r_i in sized:
        cs += s_i; cr += r_i
        prefix_s.append(cs); prefix_r.append(cr)
    for k in range(1, min(gpu_num, 6) + 1):
        threshold = (k - 1) * S
        idx = -1
        for t in range(len(prefix_s)):
            if prefix_s[t] > threshold:
                idx = t
                break
        if idx >= 0:
            numer = prefix_r[idx]
            denom = k * S - prefix_s[idx]
            if denom > 0 and numer > 0:
                cand = numer / denom
                if cand > lb_k:
                    lb_k = cand

    if infeasible_single:
        return best_placement

    lower = max(0.0, lb1, lb2, lb_pair, lb_k)
>>>>>>> REPLACE

</DIFF>