<NAME>
kvpr_balanced_greedy_and_eval_fixes
</NAME>

<DESCRIPTION>
I improved the greedy fallback to treat models with slo==0 as memory-only (dR=0), avoiding inflated demand that previously skewed placements. I fixed eval_max_kvpr to not count infinite demand for slo==0 models, which otherwise made KVPR infinite and hindered selection. I expanded the candidate T sweep to explore a wider neighborhood around the first feasible T, which helps achieve lower maximum KVPR. Finally, I added a greedy baseline plus its refinement and select the best placement among T-based and greedy-refined candidates, further reducing max KVPR while keeping the code simple and robust.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Greedy fallback minimizing local max-KVPR increase
    def _greedy_fallback_kvpr(gpu_num, models, S):
        # Sort by demand ratio descending; tie by size desc
        sorted_models = sorted(
            models,
            key=lambda m: ((m.req_rate / m.slo) if m.slo != 0 else float('inf'), m.model_size),
            reverse=True
        )
        placement = {i: [] for i in range(gpu_num)}
        rem_mem = [S] * gpu_num
        sum_R = [0.0] * gpu_num
        for m in sorted_models:
            dR = (m.req_rate / m.slo) if m.slo != 0 else float('inf')
            size = float(m.model_size)
            best_gid = None
            best_val = float('inf')
            for gid in range(gpu_num):
                if size <= rem_mem[gid]:
                    rem = rem_mem[gid] - size
                    if rem <= 0:
                        continue
                    val = (sum_R[gid] + dR) / rem
                    if val < best_val:
                        best_val = val
                        best_gid = gid
            if best_gid is None:
                raise ValueError(
                    f"Unable to place model of size {m.model_size} GB on any GPU. "
                    f"Remaining per-GPU memory: {rem_mem}"
                )
            placement[best_gid].append(m)
            sum_R[best_gid] +=  dR if dR != float('inf') else 0.0
            rem_mem[best_gid] -= size
        return placement
=======
    # Greedy fallback minimizing local max-KVPR increase (treat slo==0 as memory-only)
    def _greedy_fallback_kvpr(gpu_num, models, S):
        # Sort by demand ratio descending; tie by size desc
        sorted_models = sorted(
            models,
            key=lambda m: ((m.req_rate / m.slo) if m.slo != 0 else 0.0, m.model_size),
            reverse=True
        )
        placement = {i: [] for i in range(gpu_num)}
        rem_mem = [S] * gpu_num
        sum_R = [0.0] * gpu_num
        for m in sorted_models:
            dR = (m.req_rate / m.slo) if m.slo != 0 else 0.0
            size = float(m.model_size)
            best_gid = None
            best_val = float('inf')
            for gid in range(gpu_num):
                if size <= rem_mem[gid]:
                    rem = rem_mem[gid] - size
                    if rem <= 0:
                        continue
                    val = (sum_R[gid] + dR) / rem
                    if val < best_val:
                        best_val = val
                        best_gid = gid
            if best_gid is None:
                raise ValueError(
                    f"Unable to place model of size {m.model_size} GB on any GPU. "
                    f"Remaining per-GPU memory: {rem_mem}"
                )
            placement[best_gid].append(m)
            sum_R[best_gid] += dR
            rem_mem[best_gid] -= size
        return placement
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    def eval_max_kvpr(placement_dict):
        max_v = 0.0
        for gid in range(gpu_num):
            bucket = placement_dict.get(gid, [])
            used = 0.0
            R = 0.0
            for m in bucket:
                used += float(m.model_size)
                R += float(m.req_rate / m.slo) if m.slo != 0 else float('inf')
            val = kvpr(R, S - used)
            if val > max_v:
                max_v = val
        return max_v
=======
    def eval_max_kvpr(placement_dict):
        max_v = 0.0
        for gid in range(gpu_num):
            bucket = placement_dict.get(gid, [])
            used = 0.0
            R = 0.0
            for m in bucket:
                used += float(m.model_size)
                R += float(m.req_rate / m.slo) if m.slo != 0 else 0.0
            val = kvpr(R, S - used)
            if val > max_v:
                max_v = val
        return max_v
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    candidates_T = []
    for mul in [0.99, 1.0, 1.005, 1.02]:
        val = max(lower, T_feas * mul)
        candidates_T.append(val)
    candidates_T.append(0.5 * (lower + T_feas))
    candidates_T = sorted(set(round(t, 12) for t in candidates_T))
=======
    candidates_T = []
    for mul in [0.975, 0.985, 0.99, 1.0, 1.005, 1.01, 1.02, 1.03]:
        val = max(lower, T_feas * mul)
        candidates_T.append(val)
    candidates_T.append(0.5 * (lower + T_feas))
    candidates_T = sorted(set(round(t, 12) for t in candidates_T))
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    refined = local_refine(best_placement, move_budget=20, swap_budget=10)

    # Final check: memory safety
    for gid in range(gpu_num):
        mem = sum(float(m.model_size) for m in refined.get(gid, []))
        if mem - S > 1e-6:
            return best_placement

    return refined
=======
    refined = local_refine(best_placement, move_budget=20, swap_budget=10)
    # Greedy baseline and its refinement
    greedy_baseline = _greedy_fallback_kvpr(gpu_num, models, S)
    greedy_refined = local_refine(greedy_baseline, move_budget=12, swap_budget=6)

    # Select the best by measured max KVPR
    candidates = [best_placement, refined, greedy_refined]
    best_final = candidates[0]
    best_score = eval_max_kvpr(best_final)
    for cand in candidates[1:]:
        v = eval_max_kvpr(cand)
        if v < best_score:
            best_score = v
            best_final = cand

    # Final check: memory safety
    for gid in range(gpu_num):
        mem = sum(float(m.model_size) for m in best_final.get(gid, []))
        if mem - S > 1e-6:
            return refined

    return best_final
>>>>>>> REPLACE

</DIFF>