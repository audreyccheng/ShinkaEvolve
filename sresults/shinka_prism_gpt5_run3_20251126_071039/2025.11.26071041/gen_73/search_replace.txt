<NAME>
tighten_t_search_and_tiebreak
</NAME>

<DESCRIPTION>
I improve the candidate generation and selection in two targeted ways to lower the maximum KVPR:
1) Tighten T feasibility search by checking more packing variants during the binary search (resid with three orderings, and minmax/hybrid with two orderings). This increases the chance to find a feasible placement at a smaller T, which directly reduces the achievable max KVPR.
2) Use a lexicographic tie-breaker (max, second, average KVPR) when selecting the best placement after local improvements, instead of only the maximum KVPR. This yields better-balanced solutions when several candidates share the same max KVPR.
3) Add an additional candidate from memory packing with ratio_desc and best-fit, increasing candidate diversity with minimal overhead.

These changes are small, deterministic, and keep runtime modest while potentially improving the combined score by reducing max KVPR.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # For feasibility checks during search (keep minimal to stay fast)
        def try_any(T, need_plc=False):
            if need_plc:
                feas = []
                ok0, p0 = try_pack(T, 0, "resid", True)
                ok1, p1 = try_pack(T, 1, "resid", True)
                if ok0: feas.append(p0)
                if ok1: feas.append(p1)
                return (len(feas) > 0), feas
            else:
                return try_pack(T, 0, "resid", False) or try_pack(T, 1, "resid", False)
=======
        # For feasibility checks during search (cover more variants to find smaller feasible T)
        def try_any(T, need_plc=False):
            variants = [
                (0, "resid"), (1, "resid"), (2, "resid"),
                (0, "minmax"), (1, "minmax"),
                (0, "hybrid"), (1, "hybrid")
            ]
            if need_plc:
                feas = []
                for ov, pol in variants:
                    ok, p = try_pack(T, ov, pol, True)
                    if ok:
                        feas.append(p)
                return (len(feas) > 0), feas
            else:
                for ov, pol in variants:
                    if try_pack(T, ov, pol, False):
                        return True
                return False
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Candidate B: memory-balanced dual strategy
    plc_dual = memory_pack(order="size_desc", strategy="dual")
    if plc_dual is not None:
        candidates.append(plc_dual)
=======
    # Candidate B: memory-balanced dual strategy
    plc_dual = memory_pack(order="size_desc", strategy="dual")
    if plc_dual is not None:
        candidates.append(plc_dual)

    # Candidate C: ratio-desc best-fit to diversify memory-rate density packing
    plc_ratio = memory_pack(order="ratio_desc", strategy="bestfit")
    if plc_ratio is not None:
        candidates.append(plc_ratio)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_plc = None
    best_score = float('inf')
    for plc in improved_candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc
=======
    # Use lexicographic tie-break: (max KVPR, second-worst KVPR, average KVPR)
    def score_tuple(plc):
        kvprs = []
        for g in range(gpu_num):
            used_mem = sum(getattr(m, "model_size") for m in plc.get(g, []))
            numer = sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in plc.get(g, []))
            kvprs.append(kvpr(numer, GPU_MEM_SIZE - used_mem))
        if not kvprs:
            return (0.0, 0.0, 0.0)
        kvprs_sorted = sorted(kvprs, reverse=True)
        max_k = kvprs_sorted[0]
        second = kvprs_sorted[1] if len(kvprs_sorted) > 1 else kvprs_sorted[0]
        avg = sum(kvprs_sorted) / len(kvprs_sorted)
        return (max_k, second, avg)

    best_plc = None
    best_score = None
    for plc in improved_candidates:
        st = score_tuple(plc)
        if best_score is None or st < best_score:
            best_score = st
            best_plc = plc
>>>>>>> REPLACE

</DIFF>