# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy KVPR-Minimizing Model Placement**
- **Implementation**: Greedily sorts models by r_j/s_j (req_rate/SLO) descending and assigns each to the GPU with the lowest current weighted_req_rate/remaining_mem among those with enough free memory (80GB per GPU), updating per-GPU totals after placement. It fails fast by raising an error when a model cannot fit, and does not implement a τ-feasibility check or post-placement ratio evaluation.
- **Performance**: Combined score 21.89; max_kvpr 20.892; success_rate 1.000; execution_time 0.000s.
- **Feedback**: The simple ratio-based balancing yields consistently feasible placements with near-zero runtime and strong KVPR results on the evaluator. Potential improvements include choosing GPUs based on the projected ratio after placement, adding τ checks, and avoiding a fixed 80GB assumption to better generalize and further reduce peak KV pressure.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Greedy Min-Max KVPR GPU Placement**
- **Implementation**: Greedy assignment after sorting models by (req_rate/slo)/(80−size), placing each on the GPU that minimizes the resulting global max KVPR with tie-breakers (lower target KVPR, more remaining memory). A bounded local improvement then moves single models from the most-pressured GPU if it strictly reduces the max KVPR; memory fit is enforced and KVPR is R/rem_mem (inf at zero).
- **Performance**: Combined score 23.13; max_kvpr 22.127; success_rate 1.000; execution_time 0.000s.
- **Feedback**: Passed all validations; the sorting heuristic plus lookahead and local hill-climb effectively balances KV cache pressure across GPUs. Infinity handling is minimal when remaining memory hits zero, but this did not affect the provided tests.
**Program Identifier:** Generation 1 - Patch Name balanced_minmax_kvpr - Correct Program: True

**Program Name: Greedy KV Cache Pressure Balancer**
- **Implementation**: Sorts models by (req_rate/slo) per GB and greedily assigns each to the GPU that minimizes the projected maximum KVPR across all GPUs, with tie-breakers on local KVPR, remaining memory, and GPU id. Enforces 80 GB per-GPU memory, avoids overcommit via hard-fit checks, and guards against zero SLO/size with infinities and epsilons.
- **Performance**: Combined score 20.74; max_kvpr 19.743; success_rate 1.000; execution_time ~0.000s.
- **Feedback**: Passes all validation tests; the global-max KVPR lookahead and tie-breakers yield balanced placements without overcommit. Numerical edge-case handling (zero SLO/size) improves stability and consistency across test cases.
**Program Identifier:** Generation 2 - Patch Name minimax_greedy_kvpr - Correct Program: True

**Program Name: Greedy + Local Search KVPR Balancer**
- **Implementation**: Greedy min-max placement guided by multiple model orderings; for each placement step, it picks the GPU that minimizes the resulting global max KVPR with memory-aware tie-breaks. It then applies bounded local improvement (best-improving single moves from the max-pressure GPU and capped pairwise swaps) using per-GPU sum(r/s) and remaining memory tracking, with infeasible fits rejected.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: Correct and passed all validations; multi-ordering plus local refinement consistently produced balanced placements with low peak pressure. The fixed 80 GB per-GPU assumption and capped improvement iterations trade some optimality for speed and robustness.
**Program Identifier:** Generation 3 - Patch Name multi_heuristic_and_swap_improvement - Correct Program: True

**Program Name: Greedy-MinMax KVPR Placement with Parametric Search**
- **Implementation**: Uses multi-ordering greedy min–max assignment with lookahead and tie-breakers, then bounded local improvement (single-move and capped pairwise swaps), assuming 80 GB/GPU. It further runs a binary search over target KVPR using a transformed capacity model and best-fit-decreasing packing (w = dR + T*size; capacity = T*S), adopting the refined placement if it improves the max KVPR.
- **Performance**: Achieved combined score 26.17 with max_kvpr 25.168, 100% success rate, and 0.002s runtime.
- **Feedback**: The diverse orderings, lookahead placement, and capped local search provided robust, fast placements that passed all validation tests. Parametric refinement effectively tightened worst-case KVPR when feasible, while safety checks (infinite-rememory handling and feasibility bounds) prevented invalid placements.
**Program Identifier:** Generation 4 - Patch Name parametric_bsearch_bfd - Correct Program: True

**Program Name: Binary-searched best-fit KVPR placement**
- **Implementation**: Uses a transformed-capacity formulation w_i(T)=n_i+T*m_i with per-GPU cap 80*T, performing exponential search to find a feasible T and binary search to minimize it, then packs via best-fit decreasing under two orderings (transformed weight and intrinsic pressure). Includes strict input validation, global/individual lower bounds, small numerical slack, a quality-based post-selection, and a greedy fallback, returning a complete GPU-id mapping.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.
- **Feedback**: Dual ordering plus post-selection by measured KVPR yields consistently feasible, near-optimal placements with excellent speed. The fixed 80 GB constraint and robust feasibility checks improved stability and prevented invalid allocations, contributing to perfect success across tests.
**Program Identifier:** Generation 5 - Patch Name kvpr_bisect_packing - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placement**
- **Implementation**: Uses a transformed-capacity bin packing with KVPR threshold T (exponential search for feasibility, binary search to tighten), packing via five ordering variants with tie-breakers to minimize global max KVPR, plus candidate scoring, a greedy fallback, and a local hill-climbing improvement pass. Enforces single-GPU fit, safe divisions, and returns a full GPU-indexed placement map.
- **Performance**: Combined score 25.43; max_kvpr 24.426; success_rate 1.000; execution_time 0.009s.
- **Feedback**: The mix of ordering variants and local improvement reliably finds feasible, balanced placements quickly, yielding perfect success and very low runtime. Evaluation indicates the strategy effectively controls worst-case KVPR across GPUs.
**Program Identifier:** Generation 6 - Patch Name kvpr_bisect_pack_local_search - Correct Program: True

**Program Name: Greedy-Refined KVPR Balancer**
- **Implementation**: Uses a greedy min–max assignment with lookahead and tie-breakers across multiple orderings (pressure weight, r/s, size asc/desc, density), followed by capped local move/swap improvements. It then binary-searches a target KVPR and applies Best-Fit-Decreasing with transformed weights w = dR + T*size to further tighten placement, with 80 GB/GPU and safety checks enforced.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.002s.
- **Feedback**: Consistently finds feasible, low-pressure placements and passes all validation tests, indicating correctness and robustness. The layered greedy+local+parametric refinement and thoughtful tie-breakers likely drive both quality and speed.
**Program Identifier:** Generation 7 - Patch Name parametric_refinement_bsearch - Correct Program: True

**Program Name: KVPR-Aware GPU Placement with Local Search**
- **Implementation**: Computes per-model demand (req_rate/slo) and defines KVPR as demand over remaining GPU memory. Builds initial placements via KVPR-focused regret-based insertion and a memory-oriented dual packing (max-free then best-fit), then applies bounded move/swap local search to minimize the global max KVPR and selects the best candidate.
- **Performance**: Achieved combined score 26.01 with max_kvpr 25.012, 100% success rate, and 0.001s execution time.
- **Feedback**: KVPR-aware initialization plus local improvement effectively balances load and keeps pressure low across GPUs, with strict memory feasibility checks. The method is fast and robust across test cases; KVPR-based tie-breaking improves stability in edge placements.
**Program Identifier:** Generation 8 - Patch Name regret_waterfill_swaps - Correct Program: True

**Program Name: KVPR-optimized bin packing with binary search**
- **Implementation**: Uses per-item/global lower bounds and an exponential+binary search on a KVPR threshold T, reducing placement to a transformed bin-packing (cap=T*80, weight=n_i+T*m_i) under memory constraints. Applies best-fit-decreasing with two ordering variants and selects the placement with the lowest measured max KVPR; includes strict input validation and safe division.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.001s.
- **Feedback**: The dual-ordering heuristic plus near-optimal T search consistently found feasible placements with low KVPR while remaining extremely fast. Robust validation (e.g., per-GPU memory, SLO > 0, oversized models) improved stability and ensured all tests passed.
**Program Identifier:** Generation 9 - Patch Name dual_bisect_bfd - Correct Program: True

**Program Name: Minimax KVPR GPU Placement with BFD Refinement**
- **Implementation**: Multi-ordering greedy min-max placement with lookahead and tie-breakers, followed by local improvement via capped single-item moves and pairwise swaps. A final binary search on target KVPR uses BFD over transformed weights (dR + T·size) with validation, adopting improvements.
- **Performance**: Combined score 26.17; max_kvpr 25.168; success_rate 1.000; execution_time 0.021s.
- **Feedback**: Passed all validation tests; the layered heuristics plus parametric BFD tightening produced balanced, feasible placements with very low runtime. Robustness benefited from multiple orderings, careful tie-breaking, and explicit handling of infeasible single-model cases.
**Program Identifier:** Generation 10 - Patch Name kvpr_minimax_param_refine - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placer**
- **Implementation**: Performs binary search on a KVPR threshold T and reduces feasibility to transformed-capacity bin packing (weight n + T*m, capacity T*80) with two-phase seeding and best/first-fit variants. Establishes strong lower bounds (per-item, global, pairwise, k-prefix), generates multiple candidate placements around T, and applies local move/swap search to reduce the max per-GPU KVPR.
- **Performance**: Combined score 24.55; max_kvpr 23.551; success_rate 1.000; execution_time 0.003s.
- **Feedback**: The multi-bound initialization, diversified packing variants, and local search achieved low maximum KVPR with perfect feasibility and very low latency. Potential minor improvements could come from broader candidate diversification or adaptive seeding, but the current implementation already passes all validation tests.
**Program Identifier:** Generation 11 - Patch Name kvpr_parametric_hybrid_ls - Correct Program: True

**Program Name: KVPR-minimizing placement with LB and packing**
- **Implementation**: Computes tight lower bounds (per-item, global, pair, k-bin) on target KVPR T, then performs transformed bin packing with weights w = dR + T*size using BFD/FFD variants, seeding by intrinsic pressure, and deterministic tie-breaking, with a greedy KVPR fallback. Selects among candidate T values by measured max-KVPR and applies bounded local refinement (targeted moves and swaps) plus safety checks.
- **Performance**: Combined score 25.73 (max_kvpr 24.730), success_rate 1.000, execution_time 0.001s.
- **Feedback**: Passed all validations with excellent speed; LB-guided sweeping and local refinement effectively reduce the worst-case KVPR. Additional variant exploration or deeper local search could yield marginal improvements while maintaining low latency.
**Program Identifier:** Generation 12 - Patch Name pairbound_threshold_sweep - Correct Program: True

**Program Name: KVPR-aware GPU placement with binary search and refinement**
- **Implementation**: Computes a lower bound on KVPR threshold T, then performs exponential+binary search with feasibility packing using transformed weights w(T)=n+T*m across multiple item orderings and policies. It generates diverse candidates, selects the lowest measured max-KVPR placement, and applies a local move-based improvement; includes strict memory/SLO checks and fills all GPU keys.
- **Performance**: Combined score 26.23; max_kvpr 25.233; success_rate 1.000; execution_time 0.004s.
- **Feedback**: Multi-variant packing plus local refinement consistently finds near-optimal placements with perfect success and very low runtime. The w(T)-based search with tight lower bounds is stable, and the greedy min-max fallback boosts robustness.
**Program Identifier:** Generation 13 - Patch Name hybrid_tsearch_minmax_local - Correct Program: True

**Program Name: Balanced-slack KVPR Minimization**
- **Implementation**: Computes tight lower bounds for the KVPR threshold T (per-item, global, pairwise, k-bin) and finds a feasible T via a multiplicative sweep while packing with a slack-equalization bin packer (weight w=dR+T*size), seeded ordering, and min-K_after/min-KVPR tie-breaks with slight randomization. Around the first feasible T it explores multiple orderings, applies targeted move/swap local refinement, and uses strict memory/KVPR checks with a deterministic greedy fallback for feasibility.
- **Performance**: Combined score 36.51; success_rate 1.000; execution_time 0.002s; reported max_kvpr metric 35.512.
- **Feedback**: Lower-bound-guided T search plus equalized-slack packing quickly yields balanced placements, with local refinement providing incremental improvements. Robust handling of edge cases (e.g., slo==0), deterministic seeding, and validation checks led to reliable, passing results across all tests.
**Program Identifier:** Generation 14 - Patch Name slack_equalization_t_search - Correct Program: True

**Program Name: KVPR-Minimizing GPU Model Placement with Slack Equalization**
- **Implementation**: Computes tight lower bounds (per-item, global, pairwise, k-bin) on target KV pressure, then packs via a slack-equalization scheduler with weight w=dR+T*size, exploring multiple orderings, tie-breakers, and deterministic randomness. Feasible T is found by a multiplicative sweep, followed by variant trials and a local refine phase (moves/swaps) plus a greedy fallback and strict safety checks.
- **Performance**: Combined score 25.99 (max_kvpr 24.988; success_rate 1.000; execution_time 0.003s).
- **Feedback**: Lower-bound-guided T selection and K-slack equalization with local refinement effectively balances memory and request rates, yielding low max KVPR and perfect feasibility at very low runtime. The greedy fallback robustly covers slo==0/infeasible cases, and deterministic seeding ensures reproducibility.
**Program Identifier:** Generation 15 - Patch Name kvpr_balanced_param_local - Correct Program: True

**Program Name: KVPR-Minimizing GPU Placement**
- **Implementation**: Lower-bound–guided search on a KVPR threshold combined with transformed bin packing (w_i = n_i + T*m_i, cap = T*80) under strict per-GPU memory constraints, using two ordering heuristics and exponential warm-up followed by binary search. Near-optimal candidates are measured by actual KVPR and refined via local moves and first-improving swaps to reduce the worst GPU pressure.
- **Performance**: Combined score 24.44; max_kvpr 23.442; success_rate 1.000; execution_time 0.001s.
- **Feedback**: Strong bounds (per-item, global, pair, k-prefix) tighten the initial feasible region and speed convergence, while dual orderings and local refinement improve packings around the optimal threshold. The approach is robust (100% success) and extremely fast; remaining improvements would likely come from enhanced local search or additional ordering strategies.
**Program Identifier:** Generation 16 - Patch Name tighter_bounds_and_local_refine - Correct Program: True

**Program Name: Balanced-Slack KVPR Placement**
- **Implementation**: Uses strong lower bounds (per-item, global, pairwise, k-bin) to seed a balanced-slack bin packing that minimizes max KVPR by packing weights w = dR + T*s with multiple orderings, light deterministic randomization, and strict validation. It then applies localized move/swap refinement and selects the best among refined, search-based, and greedy fallback placements (fallback also covers dR=inf cases).
- **Performance**: Combined score 25.99 with max_kvpr 24.988, success_rate 1.000, execution_time 0.003s.
- **Feedback**: Bound-guided search plus local refinement consistently yields low max KVPR while remaining very fast, and the greedy fallback ensures robustness in edge cases (e.g., SLO=0 or tight memory). Final memory checks and candidate selection contribute to reliability without noticeable runtime cost.
**Program Identifier:** Generation 17 - Patch Name tsearch_local_refine_fix - Correct Program: True

**Program Name: Min-Max KV Cache Pressure Placement**
- **Implementation**: Computes tight lower bounds (per-item, global, heavy-pair, k-prefix) on the KVPR threshold T, then performs exponential+binary search with a T-aware best-fit/min-max packer across multiple orderings. Diversifies candidates around near-optimal T, adds a demand-per-GB greedy baseline, and applies single-move and swap local search to reduce the measured max KVPR.
- **Performance**: Combined score 25.70; max_kvpr 24.702; success_rate 1.000; execution_time 0.004s.
- **Feedback**: The program is correct and passes all validation tests. Strong bounds plus candidate diversification and local improvement yield robust, low-pressure placements while remaining extremely fast.
**Program Identifier:** Generation 18 - Patch Name pair_kprefix_t_perturb_and_swaps - Correct Program: True

**Program Name: KVPR-Minimizing GPU Placement via Search and Local Moves**
- **Implementation**: Computes tight lower bounds (individual, global, pair-based, k-bin), then uses exponential+binary search on a KVPR threshold T, packing with transformed weights w(T)=n+T*m under multiple ordering/policy heuristics. It selects the best measured placement, adds a greedy min-max candidate, and performs bounded local improvements via moves and swaps.
- **Performance**: Combined score 25.67 with max_kvpr 24.667, 100% success rate, and 0.004s execution time.
- **Feedback**: The method is correct and robust, consistently finding feasible placements that balance KV cache pressure with very low latency. The mix of diverse heuristics and local refinement likely drives the strong KVPR; exploring more variants or deeper local search could yield marginal gains.
**Program Identifier:** Generation 19 - Patch Name t_perturb_kbin_pairbounds_swap_local - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

## Successful Algorithmic Patterns
- Slack-equalization packing around a parametric KVPR threshold T delivered the best score. Balanced-slack KVPR Minimization (Generation 14, slack_equalization_t_search) achieved the top combined score 36.51 (success_rate 1.000, 0.002s) by equalizing residual KV slack K_g = T·S − (ΣR_g + T·mem_g) during placement, using transformed weights w = dR + T·size, multiplicative T-sweep, multi-order variants, and bounded local refinement (moves/swaps).
- Parametric T search with transformed-weight feasibility checks remains highly effective and robust. KVPR-aware GPU placement with binary search and refinement (Gen 13, hybrid_tsearch_minmax_local) matched the prior best tier at 26.23 (max_kvpr 25.233, 1.000, 0.004s), confirming that w(T) = n + T·m packing with strong lower bounds and candidate diversification consistently finds near-optimal placements at ultra-low latency.
- Tight lower bounds on T consistently improve convergence and placement quality. Programs across Generations 10–19 compute per-item, global, pairwise, and k-bin/prefix bounds; for example, KVPR-minimizing placement with LB and packing (Gen 12, pairbound_threshold_sweep, 25.73) and KVPR-Minimizing GPU Placement (Gen 16, tighter_bounds_and_local_refine, 24.44) leverage these bounds to shrink the search space and speed feasibility.
- Diversification plus local refinement reduces residual worst-case KVPR. Multiple orderings, slight deterministic randomization, and bounded local search (single-item moves and pair swaps) consistently yield further improvements after packing; e.g., KVPR-Minimizing GPU Model Placer (Gen 11, 24.55) and Min-Max KV Cache Pressure Placement (Gen 18, 25.70).

## Ineffective Approaches
- Pure greedy without global KVPR thresholding or feasibility modeling underperformed. Earlier baselines (e.g., initial_program at 21.89 and Gen 1 at 23.13) sorted by simple ratios and placed to minimize immediate local pressure without transformed-capacity feasibility or tight bounds; they lagged significantly behind parametric T-based packers (≥24.44 to 26.23) and the slack-equalization winner (36.51).
- Lookahead-only greedy without parametric search did not close the gap. The “Greedy KV Cache Pressure Balancer” (Gen 2, 20.74) shows that projecting local max KVPR at each step, absent a T-aware feasibility framework, is insufficient versus transformed packing/BFD or slack-equalization approaches that align directly with the min-max objective.
- Overly narrow reliance on best-fit-decreasing in transformed space plateaued. Dual-ordering BFD approaches previously topped out at 26.23 (e.g., Gen 13 and earlier Gen 5/9 references). The shift to slack-equalization placement improved further to 36.51, indicating that minimizing residual KV slack K_g during assignment can outperform pure best-fit on w(T) in practice.

## Implementation Insights
- What makes the current best program effective (Gen 14, 36.51):
  - It explicitly equalizes per-GPU KV slack K_g = T·S − (ΣR_g + T·mem_g) and assigns each item to minimize nonnegative K_after, directly targeting worst-case KVPR reduction. This differs from pure best-fit in transformed-weight space and led to a clear score jump over the 26.23 tier.
  - It uses robust, tight lower bounds (per-item, global, pairwise with size filter, and k-bin/prefix) to seed a multiplicative T sweep, quickly finding the first feasible T without expensive binary search; this preserves ultra-low runtime (0.002–0.003s).
  - It stabilizes outcomes via multiple orderings (w_desc, intrinsic_desc, density_desc, size_desc), selective seeding of high-intrinsic-pressure items, deterministic light randomization for tie-breaking, strict feasibility validation, and a greedy fallback for edge cases (e.g., slo == 0).
  - It adds bounded local refinement focused on the most loaded GPU (moves then swaps with small caps), yielding incremental but reliable reductions in measured max KVPR at negligible runtime cost.
- Efficient bounds and validation patterns recur across high-performers:
  - Pair bound restricted to large items (e.g., top P=200 by size) and k-prefix bounds over k ∈ [1..min(gpu_num,4)] provide tightness without runtime penalties (seen in Gen 10–19 variants).
  - Strict memory/SLO checks with small numerical slack and final revalidation ensure 100% success across all top programs.
- Candidate diversification around T matters:
  - The best programs test a compact set of T values around the first feasible T (e.g., {0.99, 1.0, 1.005, 1.02}·T_feas plus midpoint) and pick by measured max KVPR; this mirrors prior best practices (Gen 11, 12, 13) and remains crucial in the current best.

## Performance Analysis
- New best result: Balanced-slack KVPR Minimization (Gen 14) sets a new high at 36.51 (success_rate 1.000, 0.002s), surpassing the earlier top tier 26.23 achieved by dual-ordering parametric BFD packers (e.g., Gen 13 at 26.23, 0.004s). This indicates a meaningful gain from slack-equalization over best-fit transformed packing.
- Consistent high-performing cluster: Programs combining tight bounds, parametric T search, multiple orderings, and local refinement score in the 24.44–26.23 range with perfect success and sub-5ms latency (Gen 11: 24.55; Gen 12: 25.73; Gen 16: 24.44; Gen 18: 25.70; Gen 19: 25.67).
- Greedy+local search without T-based feasibility remains close but slightly behind parametric methods. Multi-ordering greedy min-max with refinement peaked at 26.17 (Gen 10 at 26.17), trailing the best parametric packers (26.23) and the slack-equalization winner (36.51), reinforcing the value of aligning packing with the KVPR threshold model.
- Runtime is uniformly ultra-low across all correct programs (0.001–0.004s), and success_rate is 1.000 throughout; differentiation is driven by max_kvpr/combined score. Techniques that align placement with KVPR-transformed capacities and manage residual KV slack (K_g) correlate with the highest scores.

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

1. Add an in-placement dynamic T update for the remaining items (two-phase packing). After placing the first 30–50% of items with T = T_feas, recompute a lower bound from the remaining items and the residual global capacity (using the same per-item/global/pair/k-prefix bounds but on the remainder), set T’ = max(current T, new lower bound), rebuild weights w = dR + T’·size for the remainder, re-sort, and continue placement. This preserves the slack-equalization core while adapting to discrete effects and has strong evidence from parametric T search that better-aligned thresholds improve balance.

2. Strengthen lower bounds with a small triplet bound and slightly deeper k-prefix. For the top P=120 largest items by size, add a triplet bound: for any triple with s_i + s_j + s_k > 2S, set T ≥ (r_i + r_j + r_k) / (3S − (s_i + s_j + s_k)); scan only O(P^2) candidates by fixing i and j and picking the best k among a short list (e.g., top-10 by size) to keep runtime negligible. Also extend k-prefix to k up to min(gpu_num, 6) to tighten early T; tighter bounds have repeatedly improved convergence and quality.

3. Introduce a blended slack-aware selection rule alongside current ‘tight’ and ‘min_kvpr’. When choosing a GPU for an item, minimize J = K_after_norm + α·kv_new_norm + β·mem_imbalance, where K_after_norm = max(0, K_after)/(T·S), kv_new_norm = kv_new/max(T, 1e-12), and mem_imbalance = |(used_mem_g + size)/S − avg_mem_frac| with avg_mem_frac = total_used_mem/(gpu_num·S); start with α=0.15, β=0.05 and adapt α upward to 0.25 if the K variance across GPUs is small. Evaluate this ‘hybrid’ rule as an added variant in the candidate set; it directly extends K-equalization with projected KVPR and memory balancing, an approach that has helped in prior high performers.

4. Expand the bounded local refinement with 2-opt across top-2 loaded GPUs and short eject chains. After the current moves/swaps, run up to 12 targeted 2-opt swaps between the two highest-KVPR GPUs, selecting pairs by best delta in max KVPR using precomputed per-bucket sums. If still stuck, try up to 8 length-2 eject chains: move a from Gmax→G2, then move b from G2→some Gk to restore memory feasibility, accepting only chains that strictly reduce global max KVPR; this captures improvements single-step moves can’t reach, with tight caps to keep sub-millisecond runtime.

5. Make candidate selection more robust via lexicographic scoring and tiny ensemble restarts. When comparing candidate placements, break ties on max KVPR by second-worst KVPR, then by average KVPR (or variance), to avoid “hidden spikes” on the second-most loaded GPU. For the strongest two variants per T (e.g., w_desc+tight and intrinsic_desc+tight with seeding), run 2 seeds each (different deterministic RNG seeds) and keep the best; diversification plus post-selection has consistently yielded incremental gains at negligible cost.