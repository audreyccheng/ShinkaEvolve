<NAME>
resid_guard_lexitiebreak_ratio_candidate
</NAME>

<DESCRIPTION>
I propose three targeted improvements:
1) Add a guard in the resid policy of the parametric packers (both try_pack and the retune variant) to avoid placing a positive-load model on a GPU that would have zero remaining memory, which would create infinite KVPR. This prevents generating poor candidates and tightens T-feasibility.
2) Add a ratio-based dual memory packing candidate to diversify initial placements, which can reduce peak KVPR in some instances.
3) Replace the scalar max-KVPR selection of the best candidate with a lexicographic tie-break on the descending KVPR vector, improving robustness by considering the entire distribution, not just the max.

These changes are minimal, keep the code simple, and aim to reduce the final maximum KVPR without harming feasibility or runtime.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
                    if policy == "resid":
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    elif policy == "minmax":
=======
                    if policy == "resid":
                        # Avoid zero remaining memory with positive load (would create infinite KVPR)
                        if GPU_MEM_SIZE - (m_sum[g] + ms) <= 1e-12 and (n_sum[g] + n) > 0:
                            continue
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    elif policy == "minmax":
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
                    if policy == "resid":
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    elif policy == "minmax":
=======
                    if policy == "resid":
                        # Avoid zero remaining memory with positive load (would create infinite KVPR)
                        if GPU_MEM_SIZE - (m_sum[g] + ms) <= 1e-12 and (n_sum[g] + n) > 0:
                            continue
                        key = (resid, -(GPU_MEM_SIZE - (m_sum[g] + ms)), g)
                    elif policy == "minmax":
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Candidate B: memory-balanced dual strategy
    plc_dual = memory_pack(order="size_desc", strategy="dual")
    if plc_dual is not None:
        candidates.append(plc_dual)
=======
    # Candidate B: memory-balanced dual strategy
    plc_dual = memory_pack(order="size_desc", strategy="dual")
    if plc_dual is not None:
        candidates.append(plc_dual)

    # Candidate C: ratio-based dual strategy to diversify memory pressure patterns
    plc_dual_ratio = memory_pack(order="ratio_desc", strategy="dual")
    if plc_dual_ratio is not None:
        candidates.append(plc_dual_ratio)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_plc = None
    best_score = float('inf')
    for plc in improved_candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc
=======
    best_plc = None
    best_key = (float('inf'), ())
    for plc in improved_candidates:
        # Build KVPR vector (sorted descending) for lexicographic tie-break
        per_vals = []
        for g in range(gpu_num):
            msum = sum(getattr(m, "model_size") for m in plc.get(g, []))
            nsum = sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in plc.get(g, []))
            per_vals.append(kvpr(nsum, GPU_MEM_SIZE - msum))
        max_v = max(per_vals) if per_vals else 0.0
        key = (max_v, tuple(sorted(per_vals, reverse=True)))
        if key < best_key:
            best_key = key
            best_plc = plc
>>>>>>> REPLACE

</DIFF>