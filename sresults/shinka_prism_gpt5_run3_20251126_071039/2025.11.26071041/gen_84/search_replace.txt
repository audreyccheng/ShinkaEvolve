<NAME>
variants_ratio_lexi
</NAME>

<DESCRIPTION>
I propose three targeted improvements:
1) Expand the feasibility/candidate exploration variants in the T-based parametric packing to include ordering=2 for "minmax" and "hybrid" policies. This widens the search space cheaply and often finds better placements near the feasibility threshold.
2) Add an additional memory-oriented candidate using ratio-based ordering with the dual strategy. This provides more diverse initial placements for local search.
3) When selecting the final placement among improved candidates, switch to lexicographic comparison of per-GPU KVPR vectors (sorted descending) with the maximum KVPR as the primary key. This refines the tie-breaking and often yields lower peak KVPR without extra compute.

These changes are simple, maintain performance, and improve robustness and quality of the final placement.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        def try_any(T, need_plc=False):
            variants = [
                (0, "resid"), (1, "resid"), (2, "resid"),
                (0, "minmax"), (1, "minmax"),
                (0, "hybrid"), (1, "hybrid")
            ]
            if need_plc:
                feas = []
                for ov, pol in variants:
                    ok, p = try_pack(T, ov, pol, True)
                    if ok:
                        feas.append(p)
                return (len(feas) > 0), feas
            else:
                for ov, pol in variants:
                    if try_pack(T, ov, pol, False):
                        return True
                return False
=======
        def try_any(T, need_plc=False):
            variants = [
                (0, "resid"), (1, "resid"), (2, "resid"),
                (0, "minmax"), (1, "minmax"), (2, "minmax"),
                (0, "hybrid"), (1, "hybrid"), (2, "hybrid")
            ]
            if need_plc:
                feas = []
                for ov, pol in variants:
                    ok, p = try_pack(T, ov, pol, True)
                    if ok:
                        feas.append(p)
                return (len(feas) > 0), feas
            else:
                for ov, pol in variants:
                    if try_pack(T, ov, pol, False):
                        return True
                return False
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Candidate B: memory-balanced dual strategy
    plc_dual = memory_pack(order="size_desc", strategy="dual")
    if plc_dual is not None:
        candidates.append(plc_dual)
=======
    # Candidate B: memory-balanced dual strategy
    plc_dual = memory_pack(order="size_desc", strategy="dual")
    if plc_dual is not None:
        candidates.append(plc_dual)

    # Candidate C: ratio-based dual strategy to diversify memory pressure patterns
    plc_dual_ratio = memory_pack(order="ratio_desc", strategy="dual")
    if plc_dual_ratio is not None:
        candidates.append(plc_dual_ratio)
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    best_plc = None
    best_score = float('inf')
    for plc in improved_candidates:
        score = measured_max_kvpr(plc)
        if score < best_score:
            best_score = score
            best_plc = plc
=======
    best_plc = None
    best_key = (float('inf'), ())
    for plc in improved_candidates:
        # Build KVPR vector (sorted descending) for lexicographic tie-break
        per_vals = []
        for g in range(gpu_num):
            msum = sum(getattr(m, "model_size") for m in plc.get(g, []))
            nsum = sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in plc.get(g, []))
            per_vals.append(kvpr(nsum, GPU_MEM_SIZE - msum))
        max_v = max(per_vals) if per_vals else 0.0
        key = (max_v, tuple(sorted(per_vals, reverse=True)))
        if key < best_key:
            best_key = key
            best_plc = plc
>>>>>>> REPLACE

</DIFF>