--- a/original.py
+++ b/original.py
@@ -1,249 +1,379 @@
 # EVOLVE-BLOCK-START
 """Model placement algorithm for minimizing maximum KV cache pressure across GPUs"""
 
 GPU_MEM_SIZE = 80  # GB
 
 def compute_model_placement(gpu_num, models):
     """
     Compute a model placement that minimizes the maximum KVPR across all GPUs.
 
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
 
     Returns:
         A placement of models to GPUs
     """
     if gpu_num <= 0:
         raise ValueError("gpu_num must be positive")
 
-    # Extract per-model stats
+    # ---------- Helpers ----------
+    def safe_div(num, den):
+        if den <= 0:
+            return float('inf') if num > 0 else 0.0
+        return num / den
+
+    def kvpr_val(numer, rem_mem):
+        return safe_div(numer, rem_mem)
+
+    # ---------- Extract per-model stats ----------
     items = []
     total_mem = 0.0
     total_n = 0.0
     for idx, m in enumerate(models):
-        ms = float(m.model_size)
+        ms = float(getattr(m, "model_size"))
+        slo = float(getattr(m, "slo"))
+        rr = float(getattr(m, "req_rate"))
         if ms < 0:
             raise ValueError("Model size must be non-negative")
         if ms > GPU_MEM_SIZE + 1e-9:
             raise ValueError(f"Model of size {ms} GB cannot fit into a single GPU of size {GPU_MEM_SIZE} GB")
-        slo = float(m.slo)
         if slo <= 0:
-            # Treat as impossible, consistent with minimization problem (infinite pressure)
             raise ValueError("Model SLO must be positive")
-        n = float(m.req_rate) / slo  # r_j / s_j
+        n = rr / slo  # r_j / s_j
         items.append((idx, m, ms, n))
         total_mem += ms
         total_n += n
 
     if not items:
         return {gpu_id: [] for gpu_id in range(gpu_num)}
 
     total_capacity_mem = gpu_num * GPU_MEM_SIZE
     if total_mem - total_capacity_mem > 1e-9:
-        # Impossible: total memory exceeds available
         raise ValueError("Total model memory exceeds total GPU memory")
 
-    # Lower bound on T from individual models and global aggregation
-    def safe_div(num, den):
-        if den <= 0:
-            return float('inf')
-        return num / den
-
+    # ---------- Lower bound on T ----------
     indiv_lb = max(safe_div(n, GPU_MEM_SIZE - ms) for _, _, ms, n in items)
     global_lb = safe_div(total_n, max(total_capacity_mem - total_mem, 1e-9))
     low_T = max(0.0, indiv_lb, global_lb)
 
-    # Feasibility check using best-fit decreasing on transformed weights: w_i(T) = n_i + T * m_i
-    def try_pack(T, order_variant=0, return_placement=False):
-        cap = GPU_MEM_SIZE * T  # capacity per GPU in transformed space
+    # ---------- Feasibility check and packing at T ----------
+    # order_variant:
+    #   0 -> by transformed weight w(T) = n + T*m
+    #   1 -> by intrinsic-alone KVPR n / (80 - m)
+    #   2 -> by pressure per GB n / m
+    # policy:
+    #   "resid"  -> best-fit on transformed residual
+    #   "minmax" -> choose GPU minimizing new global max KVPR
+    def try_pack(T, order_variant=0, policy="resid", return_placement=False):
+        cap = GPU_MEM_SIZE * T
+        eps = 1e-12
+
         # Build sorted order
         if order_variant == 0:
-            # Primary: sort by decreasing transformed weight; break by higher n, then larger m
             ordered = sorted(items, key=lambda it: (it[3] + T * it[2], it[3], it[2]), reverse=True)
+        elif order_variant == 1:
+            ordered = sorted(items, key=lambda it: (safe_div(it[3], max(GPU_MEM_SIZE - it[2], 1e-9)), it[2]), reverse=True)
         else:
-            # Alternative: sort by "intrinsic KVPR" pressure n/(80-m) and then by memory
-            ordered = sorted(items, key=lambda it: (safe_div(it[3], max(GPU_MEM_SIZE - it[2], 1e-9)), it[2]), reverse=True)
+            ordered = sorted(items, key=lambda it: (safe_div(it[3], max(it[2], 1e-9)), it[3]), reverse=True)
 
         # Per-GPU state
         n_sum = [0.0] * gpu_num
         m_sum = [0.0] * gpu_num
         used_cap = [0.0] * gpu_num  # equals n_sum + T * m_sum
-        place_lists = [[] for _ in range(gpu_num)]
-
-        for it in ordered:
-            idx, mdl, ms, n = it
+        placement = [[] for _ in range(gpu_num)]
+
+        for _, mdl, ms, n in ordered:
             w = n + T * ms
-            best_gpu = None
-            best_residual = float('inf')
+            candidates = []
+            # Precompute current kvprs
+            cur_kvprs = [kvpr_val(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)]
 
             for g in range(gpu_num):
-                # Memory feasibility
-                if m_sum[g] + ms > GPU_MEM_SIZE + 1e-12:
+                if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                     continue
-                # Transformed capacity feasibility
                 residual = cap - (used_cap[g] + w)
-                if residual >= -1e-12:  # allow tiny numerical slack
-                    # Best-fit: minimize residual to tighten packing
-                    if residual < best_residual - 1e-15:
-                        best_residual = residual
-                        best_gpu = g
-
-            if best_gpu is None:
+                if residual < -eps:
+                    continue
+                if policy == "resid":
+                    candidates.append((g, residual, None, None))
+                else:
+                    new_n = n_sum[g] + n
+                    new_m = m_sum[g] + ms
+                    new_local = kvpr_val(new_n, GPU_MEM_SIZE - new_m)
+                    # New global max if placed on g
+                    new_max = new_local
+                    for k in range(gpu_num):
+                        if k != g and cur_kvprs[k] > new_max:
+                            new_max = cur_kvprs[k]
+                    candidates.append((g, residual, new_max, new_local))
+
+            if not candidates:
                 return (False, None) if return_placement else False
 
-            # Place item
-            place_lists[best_gpu].append(mdl)
-            n_sum[best_gpu] += n
-            m_sum[best_gpu] += ms
-            used_cap[best_gpu] += w
+            if policy == "resid":
+                # Best-fit: minimize transformed residual; tie by more remaining mem then gpu id
+                # Remaining mem after placement equals GPU_MEM_SIZE - (m_sum[g]+ms)
+                chosen = min(
+                    candidates,
+                    key=lambda c: (c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
+                )[0]
+            else:
+                # Minimize global new max KVPR; tie-break by local KVPR then residual then more remaining mem then id
+                chosen = min(
+                    candidates,
+                    key=lambda c: (c[2], c[3], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
+                )[0]
+
+            # Place
+            placement[chosen].append(mdl)
+            n_sum[chosen] += n
+            m_sum[chosen] += ms
+            used_cap[chosen] += w
 
         if return_placement:
-            return True, {g: place_lists[g] for g in range(gpu_num)}
+            return True, {g: placement[g] for g in range(gpu_num)}
         return True
 
-    # Find an initial feasible high_T by exponential search (monotonic feasibility in T)
-    # Start from a reasonable T guess
+    # For quick feasibility checks during search
+    def try_pack_any(T, need_placement=False):
+        variants = [(0, "resid"), (1, "resid")]
+        feasibles = []
+        for ov, pol in variants:
+            if need_placement:
+                ok, plc = try_pack(T, ov, pol, True)
+                if ok:
+                    feasibles.append(plc)
+            else:
+                if try_pack(T, ov, pol, False):
+                    return True
+        if need_placement:
+            return (len(feasibles) > 0), feasibles
+        return False
+
+    # ---------- Exponential search for feasible T ----------
     T = max(low_T, 1e-9)
-    feasible = False
-    for _ in range(60):
-        if try_pack(T, 0) or try_pack(T, 1):
-            feasible = True
+    found = False
+    for _ in range(50):
+        if try_pack_any(T, need_placement=False):
+            found = True
             break
         T *= 2.0
 
-    if not feasible:
-        # Even with very large T, packing failed -> truly infeasible
+    if not found:
         raise ValueError("Unable to find a feasible packing for any KVPR threshold")
 
-    high_T = T
-    low = low_T
-    high = high_T
-
-    # Binary search to minimize T
+    # ---------- Binary search to minimize T ----------
+    low, high = low_T, T
     for _ in range(40):
         mid = (low + high) / 2.0
         if mid <= 0:
             high = mid
             continue
-        if try_pack(mid, 0) or try_pack(mid, 1):
+        if try_pack_any(mid, need_placement=False):
             high = mid
         else:
             low = mid
 
-    # Build final placement at near-optimal T using both orderings and pick the better (smaller measured max KVPR)
-    def build_and_score(T):
-        ok0, plc0 = try_pack(T, 0, return_placement=True)
-        ok1, plc1 = try_pack(T, 1, return_placement=True)
-        candidates = []
-        if ok0: candidates.append(plc0)
-        if ok1: candidates.append(plc1)
-
-        # Fallback (shouldn't happen): use the last feasible order we had
-        if not candidates:
-            ok0, plc0 = try_pack(high, 0, return_placement=True)
-            if ok0:
-                candidates.append(plc0)
-
-        def kvpr_of(plc):
-            kvprs = []
+    # ---------- Build diverse candidates at near-optimal T ----------
+    def measured_max_kvpr(plc):
+        vals = []
+        for g in range(gpu_num):
+            used_mem = sum(getattr(m, "model_size") for m in plc.get(g, []))
+            numer = sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in plc.get(g, []))
+            vals.append(kvpr_val(numer, GPU_MEM_SIZE - used_mem))
+        return max(vals) if vals else 0.0
+
+    # Additional greedy min-max candidate (ignores T; memory-feasible)
+    def greedy_minmax_candidate():
+        # Sort by pressure per GB, then by demand
+        def key_m(m):
+            dn = (m.req_rate / m.slo) if m.slo != 0 else float('inf')
+            sz = m.model_size if m.model_size > 0 else 1e-9
+            return (dn / sz, dn)
+        ordered = sorted(models, key=key_m, reverse=True)
+
+        plc = {g: [] for g in range(gpu_num)}
+        rem = [GPU_MEM_SIZE] * gpu_num
+        numer = [0.0] * gpu_num
+
+        for m in ordered:
+            ms = float(m.model_size)
+            dn = float(m.req_rate) / float(m.slo)
+            # Precompute current kvprs
+            cur_k = [kvpr_val(numer[g], rem[g]) for g in range(gpu_num)]
+            best = None
             for g in range(gpu_num):
-                used = sum(getattr(m, 'model_size') for m in plc.get(g, []))
-                numer = sum((getattr(m, 'req_rate') / getattr(m, 'slo')) for m in plc.get(g, []))
-                denom = GPU_MEM_SIZE - used
-                if denom <= 0:
-                    kv = float('inf') if numer > 0 else 0.0
-                else:
-                    kv = numer / denom
-                kvprs.append(kv)
-            return max(kvprs)
-
-        best_plc = None
-        best_score = float('inf')
-        for plc in candidates:
-            score = kvpr_of(plc)
-            if score < best_score:
-                best_score = score
-                best_plc = plc
-        return best_plc
-
-    placement = build_and_score(high)
-    if placement is None:
-        # As a very last resort, place greedily by minimizing current KVPR (should be rare)
-        placement = {g: [] for g in range(gpu_num)}
-        rem_mem = [GPU_MEM_SIZE] * gpu_num
-        numer = [0.0] * gpu_num
-        # Sort by decreasing n and then by size
-        sorted_models = sorted(models, key=lambda m: ((m.req_rate / m.slo), m.model_size), reverse=True)
-        for m in sorted_models:
-            best_g = None
-            best_ratio = float('inf')
-            for g in range(gpu_num):
-                if m.model_size <= rem_mem[g] and rem_mem[g] > 0:
-                    cur = numer[g] / rem_mem[g]
-                    if cur < best_ratio:
-                        best_ratio = cur
-                        best_g = g
-            if best_g is None:
-                raise ValueError("Unable to place models with greedy fallback")
-            placement[best_g].append(m)
-            numer[best_g] += m.req_rate / m.slo
-            rem_mem[best_g] -= m.model_size
+                if ms <= rem[g]:
+                    new_local = kvpr_val(numer[g] + dn, rem[g] - ms)
+                    new_max = new_local
+                    for k in range(gpu_num):
+                        if k != g and cur_k[k] > new_max:
+                            new_max = cur_k[k]
+                    # tie-breaks: min new_max, then min local, then more remaining mem, then gpu id
+                    key = (new_max, new_local, -(rem[g] - ms), g)
+                    if best is None or key < best[0]:
+                        best = (key, g)
+            if best is None:
+                return None
+            g = best[1]
+            plc[g].append(m)
+            rem[g] -= ms
+            numer[g] += dn
+        return plc
+
+    candidates = []
+
+    # Collect candidates with multiple orderings and policies at high
+    combos = [(0, "resid"), (1, "resid"), (2, "resid"), (0, "minmax"), (1, "minmax")]
+    for ov, pol in combos:
+        ok, plc = try_pack(high, ov, pol, True)
+        if ok:
+            candidates.append(plc)
+
+    # Add greedy candidate
+    gu = greedy_minmax_candidate()
+    if gu is not None:
+        candidates.append(gu)
+
+    if not candidates:
+        # Fallback: at least one feasible must exist
+        ok, plc = try_pack(high, 0, "resid", True)
+        if not ok:
+            raise ValueError("Feasible packing unexpectedly unavailable")
+        candidates.append(plc)
+
+    # ---------- Select best candidate by measured max KVPR ----------
+    best_plc = None
+    best_score = float('inf')
+    for plc in candidates:
+        score = measured_max_kvpr(plc)
+        if score < best_score:
+            best_score = score
+            best_plc = plc
+
+    # ---------- Lightweight local improvement ----------
+    def local_improve(plc, max_moves=200, eps=1e-12):
+        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
+        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
+        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]
+
+        def kv_g(g, msum=None, nsum=None):
+            msum = mem[g] if msum is None else msum
+            nsum = num[g] if nsum is None else nsum
+            return kvpr_val(nsum, GPU_MEM_SIZE - msum)
+
+        def global_vals():
+            vals = [kv_g(g) for g in range(gpu_num)]
+            return max(vals), vals
+
+        moves = 0
+        while moves < max_moves:
+            cur_max, vals = global_vals()
+            worst = max(range(gpu_num), key=lambda g: vals[g])
+
+            improved = False
+            best_new_max = cur_max
+            best_move = None
+
+            for mdl in list(per_g[worst]):
+                ms = float(getattr(mdl, "model_size"))
+                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
+                for tgt in range(gpu_num):
+                    if tgt == worst:
+                        continue
+                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
+                        continue
+
+                    src_mem = mem[worst] - ms
+                    src_num = num[worst] - dn
+                    tgt_mem = mem[tgt] + ms
+                    tgt_num = num[tgt] + dn
+
+                    src_k = kvpr_val(src_num, GPU_MEM_SIZE - src_mem)
+                    tgt_k = kvpr_val(tgt_num, GPU_MEM_SIZE - tgt_mem)
+
+                    new_max = max(src_k, tgt_k)
+                    for g in range(gpu_num):
+                        if g != worst and g != tgt:
+                            if vals[g] > new_max:
+                                new_max = vals[g]
+
+                    if new_max + eps < best_new_max:
+                        best_new_max = new_max
+                        best_move = (mdl, worst, tgt, ms, dn)
+                        improved = True
+
+            if not improved:
+                break
+
+            mdl, src, tgt, ms, dn = best_move
+            per_g[src].remove(mdl)
+            per_g[tgt].append(mdl)
+            mem[src] -= ms
+            num[src] -= dn
+            mem[tgt] += ms
+            num[tgt] += dn
+            moves += 1
+
+        return {g: per_g.get(g, []) for g in range(gpu_num)}
+
+    best_plc = local_improve(best_plc, max_moves=100)
 
     # Ensure all GPUs are represented in dict keys
     for g in range(gpu_num):
-        placement.setdefault(g, [])
-
-    return placement
+        best_plc.setdefault(g, [])
+
+    return best_plc
 
 # EVOLVE-BLOCK-END
 
 
 def run_placement(gpu_num, models):
     """
     Main entry point that will be called by the evaluator.
     
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
     
     Returns:
         Dictionary containing GPU placements
     """
     return compute_model_placement(gpu_num, models)
 
 
 if __name__ == "__main__":
     # Test the algorithm
     import os
     import sys
     
     # Add the openevolve_examples directory to the path to import evaluator
     def find_repo_root(start_path):
         """Find the repository root by looking for openevolve_examples directory."""
         current = os.path.abspath(start_path)
         while current != os.path.dirname(current):  # Stop at filesystem root
             if os.path.exists(os.path.join(current, 'openevolve_examples', 'prism')):
                 return current
             current = os.path.dirname(current)
         raise RuntimeError("Could not find openevolve_examples directory")
     
     repo_root = find_repo_root(os.path.dirname(__file__))
     sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'prism'))
     
     from evaluator import generate_test_gpu_models, calculate_kvcache_pressure, safe_float
     import numpy as np
 
     test_cases = generate_test_gpu_models()
     all_kvpr = []
     for i, (gpu_num, gpu_models) in enumerate(test_cases):
         results = compute_model_placement(gpu_num, gpu_models)
         max_kvpr = calculate_kvcache_pressure(results)
         all_kvpr.append(safe_float(max_kvpr))
 
     avg_kvpr = np.mean(all_kvpr)
     if avg_kvpr != 0:
         avg_kvpr = 1.0 / avg_kvpr
 
     print(f"Max KVPR: {avg_kvpr:.3f}")
 
