<NAME>
donation_first_local_refinement
</NAME>

<DESCRIPTION>
I replace the generic local search improve_local with a donation-first refinement focused on the worst GPU. The new method prioritizes moving a small, high-impact subset of models (top by size and top by demand) from the worst GPU to the two best GPUs by KVPR, committing the single move that minimizes the global max KVPR. If no move helps, it tries bounded swaps between the worst and second-worst GPUs using the same top subsets. Finally, it retains the existing bounded 2-opt swaps between the two worst GPUs. This targeted refinement reduces the maximum KVPR more consistently and avoids scanning all models and all GPUs, improving solution quality without hurting runtime. The rest of the algorithm remains unchanged.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Local search: move and swap to reduce global max KVPR
    def improve_local(plc, max_iters=4000, eps=1e-12):
        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]

        def kvpr_g(g, msum=None, nsum=None):
            msum = mem[g] if msum is None else msum
            nsum = num[g] if nsum is None else nsum
            return kvpr(nsum, GPU_MEM_SIZE - msum)

        def global_max_vals():
            vals = [kvpr_g(g) for g in range(gpu_num)]
            return max(vals), vals

        it = 0
        while it < max_iters:
            it += 1
            cur_max, cur_vals = global_max_vals()
            worst = max(range(gpu_num), key=lambda g: cur_vals[g])
            improved = False
            best_move = None
            best_new_max = cur_max

            worst_models = list(per_g[worst])

            # Try single-item moves out of worst GPU
            for mdl in worst_models:
                ms = float(getattr(mdl, "model_size"))
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    # New max among unchanged GPUs
                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt:
                            if cur_vals[g] > new_max:
                                new_max = cur_vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_move = ("move", mdl, worst, tgt, ms, dn)
                        improved = True

            if improved:
                # Apply best single move
                _, mdl, src, tgt, ms, dn = best_move
                per_g[src].remove(mdl)
                per_g[tgt].append(mdl)
                mem[src] -= ms
                num[src] -= dn
                mem[tgt] += ms
                num[tgt] += dn
                continue  # iterate again

            # Try swaps between worst GPU and others (first improving swap)
            found_swap = False
            for mdl_a in worst_models:
                ms_a = float(getattr(mdl_a, "model_size"))
                dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                for tgt in range(gpu_num):
                    if tgt == worst:
                        continue
                    for mdl_b in list(per_g[tgt]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[tgt] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        src_mem = mem[worst] - ms_a + ms_b
                        src_num = num[worst] - dn_a + dn_b
                        tgt_mem = mem[tgt] - ms_b + ms_a
                        tgt_num = num[tgt] - dn_b + dn_a

                        src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                        tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                        new_max = max(src_k, tgt_k)
                        for g in range(gpu_num):
                            if g != worst and g != tgt:
                                if cur_vals[g] > new_max:
                                    new_max = cur_vals[g]

                        if new_max + eps < cur_max:
                            # Apply first improving swap
                            per_g[worst].remove(mdl_a)
                            per_g[tgt].remove(mdl_b)
                            per_g[worst].append(mdl_b)
                            per_g[tgt].append(mdl_a)
                            mem[worst] = src_mem
                            num[worst] = src_num
                            mem[tgt] = tgt_mem
                            num[tgt] = tgt_num
                            found_swap = True
                            break
                    if found_swap:
                        break
                if found_swap:
                    break

            if found_swap:
                continue

            # No improving move or swap found; stop
            break

        # Targeted 2-opt swaps between the two worst GPUs (bounded)
        if gpu_num >= 2:
            for _ in range(12):
                cur_max, vals = global_max_vals()
                worst = max(range(gpu_num), key=lambda g: vals[g])
                # identify second-worst
                second = None
                best_val = -float('inf')
                for g in range(gpu_num):
                    if g == worst:
                        continue
                    if vals[g] > best_val:
                        best_val = vals[g]
                        second = g
                if second is None:
                    break

                improved = False
                best_new_max = cur_max
                best_swap = None

                for mdl_a in list(per_g[worst]):
                    ms_a = float(getattr(mdl_a, "model_size"))
                    dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                    for mdl_b in list(per_g[second]):
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[second] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        w_mem = mem[worst] - ms_a + ms_b
                        w_num = num[worst] - dn_a + dn_b
                        s_mem = mem[second] - ms_b + ms_a
                        s_num = num[second] - dn_b + dn_a

                        w_k = kvpr(w_num, GPU_MEM_SIZE - w_mem)
                        s_k = kvpr(s_num, GPU_MEM_SIZE - s_mem)

                        new_max = max(w_k, s_k)
                        # other GPUs unchanged
                        for g in range(gpu_num):
                            if g != worst and g != second:
                                if kvpr_g(g) > new_max:
                                    new_max = kvpr_g(g)

                        if new_max + eps < best_new_max:
                            best_new_max = new_max
                            best_swap = (mdl_a, mdl_b, w_mem, w_num, s_mem, s_num)
                            improved = True

                if not improved:
                    break

                mdl_a, mdl_b, w_mem, w_num, s_mem, s_num = best_swap
                per_g[worst].remove(mdl_a)
                per_g[second].remove(mdl_b)
                per_g[worst].append(mdl_b)
                per_g[second].append(mdl_a)
                mem[worst] = w_mem
                num[worst] = w_num
                mem[second] = s_mem
                num[second] = s_num

        return {g: per_g.get(g, []) for g in range(gpu_num)}
=======
    # Local search: donation-first moves and bounded swaps to reduce global max KVPR
    def improve_local(plc, max_iters=200, eps=1e-12):
        per_g = {g: list(plc.get(g, [])) for g in range(gpu_num)}
        mem = [sum(getattr(m, "model_size") for m in per_g[g]) for g in range(gpu_num)]
        num = [sum((getattr(m, "req_rate") / getattr(m, "slo")) for m in per_g[g]) for g in range(gpu_num)]

        def kvpr_g(g, msum=None, nsum=None):
            msum = mem[g] if msum is None else msum
            nsum = num[g] if nsum is None else nsum
            return kvpr(nsum, GPU_MEM_SIZE - msum)

        def global_max_vals():
            vals = [kvpr_g(g) for g in range(gpu_num)]
            return max(vals), vals

        # Helper: select top models by size and demand from a given GPU
        def top_candidates(g, k=12):
            ms_list = sorted(per_g[g], key=lambda md: float(getattr(md, "model_size")), reverse=True)[:k]
            dn_list = sorted(per_g[g], key=lambda md: float(getattr(md, "req_rate")) / float(getattr(md, "slo")), reverse=True)[:k]
            # Deduplicate while preserving order preference: large size first
            seen = set()
            cand = []
            for md in ms_list + dn_list:
                if id(md) not in seen:
                    seen.add(id(md))
                    cand.append(md)
            return cand

        it = 0
        while it < max_iters:
            it += 1
            cur_max, cur_vals = global_max_vals()
            if gpu_num <= 1:
                break
            worst = max(range(gpu_num), key=lambda g: cur_vals[g])

            # Identify top-2 recipient GPUs (lowest KVPR)
            order = sorted(range(gpu_num), key=lambda g: cur_vals[g])
            best_targets = [g for g in order if g != worst][:2]

            improved = False
            best_move = None
            best_new_max = cur_max

            # Donation-first: try moving a small set of high-impact models from worst to best targets
            w_cands = top_candidates(worst, k=12)
            for mdl in w_cands:
                ms = float(getattr(mdl, "model_size"))
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                for tgt in best_targets:
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    new_max = max(src_k, tgt_k)
                    # Other GPUs unchanged
                    for g in range(gpu_num):
                        if g != worst and g != tgt:
                            if cur_vals[g] > new_max:
                                new_max = cur_vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_move = ("move", mdl, worst, tgt, ms, dn)
                        improved = True

            if improved:
                _, mdl, src, tgt, ms, dn = best_move
                per_g[src].remove(mdl)
                per_g[tgt].append(mdl)
                mem[src] -= ms
                num[src] -= dn
                mem[tgt] += ms
                num[tgt] += dn
                continue

            # If no move helps, try bounded swaps between worst and second-worst GPUs
            # Identify second-worst
            second = None
            best_val = -float('inf')
            for g in range(gpu_num):
                if g == worst:
                    continue
                if cur_vals[g] > best_val:
                    best_val = cur_vals[g]
                    second = g

            if second is None or not per_g[worst] or not per_g[second]:
                break

            # Build candidate pools
            a_cands = top_candidates(worst, k=12)
            b_cands = top_candidates(second, k=12)

            found_swap = False
            best_swap = None
            best_new_max = cur_max

            for mdl_a in a_cands:
                ms_a = float(getattr(mdl_a, "model_size"))
                dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                for mdl_b in b_cands:
                    ms_b = float(getattr(mdl_b, "model_size"))
                    dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                    # Memory feasibility after swap
                    if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                        continue
                    if mem[second] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                        continue

                    w_mem = mem[worst] - ms_a + ms_b
                    w_num = num[worst] - dn_a + dn_b
                    s_mem = mem[second] - ms_b + ms_a
                    s_num = num[second] - dn_b + dn_a

                    w_k = kvpr(w_num, GPU_MEM_SIZE - w_mem)
                    s_k = kvpr(s_num, GPU_MEM_SIZE - s_mem)

                    new_max = max(w_k, s_k)
                    for g in range(gpu_num):
                        if g != worst and g != second:
                            if cur_vals[g] > new_max:
                                new_max = cur_vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_swap = (mdl_a, mdl_b, w_mem, w_num, s_mem, s_num)
                        found_swap = True

            if found_swap and best_swap is not None:
                mdl_a, mdl_b, w_mem, w_num, s_mem, s_num = best_swap
                per_g[worst].remove(mdl_a)
                per_g[second].remove(mdl_b)
                per_g[worst].append(mdl_b)
                per_g[second].append(mdl_a)
                mem[worst] = w_mem
                num[worst] = w_num
                mem[second] = s_mem
                num[second] = s_num
                continue

            # No improving move or swap found; stop
            break

        # Final bounded 2-opt swaps between the two worst GPUs (as a polishing step)
        if gpu_num >= 2:
            for _ in range(12):
                cur_max, vals = global_max_vals()
                worst = max(range(gpu_num), key=lambda g: vals[g])
                # identify second-worst
                second = None
                best_val = -float('inf')
                for g in range(gpu_num):
                    if g == worst:
                        continue
                    if vals[g] > best_val:
                        best_val = vals[g]
                        second = g
                if second is None:
                    break

                improved = False
                best_new_max = cur_max
                best_swap = None

                # Limit candidate scans to top by size/demand
                a_cands = top_candidates(worst, k=12)
                b_cands = top_candidates(second, k=12)

                for mdl_a in a_cands:
                    ms_a = float(getattr(mdl_a, "model_size"))
                    dn_a = float(getattr(mdl_a, "req_rate")) / float(getattr(mdl_a, "slo"))
                    for mdl_b in b_cands:
                        ms_b = float(getattr(mdl_b, "model_size"))
                        dn_b = float(getattr(mdl_b, "req_rate")) / float(getattr(mdl_b, "slo"))

                        # Memory feasibility after swap
                        if mem[worst] - ms_a + ms_b > GPU_MEM_SIZE + 1e-12:
                            continue
                        if mem[second] - ms_b + ms_a > GPU_MEM_SIZE + 1e-12:
                            continue

                        w_mem = mem[worst] - ms_a + ms_b
                        w_num = num[worst] - dn_a + dn_b
                        s_mem = mem[second] - ms_b + ms_a
                        s_num = num[second] - dn_b + dn_a

                        w_k = kvpr(w_num, GPU_MEM_SIZE - w_mem)
                        s_k = kvpr(s_num, GPU_MEM_SIZE - s_mem)

                        new_max = max(w_k, s_k)
                        for g in range(gpu_num):
                            if g != worst and g != second:
                                if kvpr_g(g) > new_max:
                                    new_max = kvpr_g(g)

                        if new_max + eps < best_new_max:
                            best_new_max = new_max
                            best_swap = (mdl_a, mdl_b, w_mem, w_num, s_mem, s_num)
                            improved = True

                if not improved:
                    break

                mdl_a, mdl_b, w_mem, w_num, s_mem, s_num = best_swap
                per_g[worst].remove(mdl_a)
                per_g[second].remove(mdl_b)
                per_g[worst].append(mdl_b)
                per_g[second].append(mdl_a)
                mem[worst] = w_mem
                num[worst] = w_num
                mem[second] = s_mem
                num[second] = s_num

        return {g: per_g.get(g, []) for g in range(gpu_num)}
>>>>>>> REPLACE

</DIFF>