<NAME>
targeted_moves_and_candidate_pruning
</NAME>

<DESCRIPTION>
I introduce two complementary improvements to reduce max KVPR while significantly speeding up the algorithm:
1) Donation-first targeted local moves: Before the exhaustive single-item move search, the worst GPU donates one of its 12 largest or 12 highest-pressure models to the two best GPUs by current KVPR. This focuses on moves that are most likely to reduce the global maximum KVPR with minimal scanning, often finding strong improvements quickly.
2) Candidate pruning and leaner parametric exploration: I reduce the number of parametric packing combinations and T-neighborhoods explored, and only run local improvement on the top 3 candidates by raw max KVPR. This preserves solution quality while cutting execution time.

Both changes are simple, self-contained, and keep the algorithm deterministic and robust.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
            worst_models = list(per_g[worst])

            # Try single-item moves out of worst GPU
            for mdl in worst_models:
=======
            worst_models = list(per_g[worst])

            # Donation-first: targeted moves from worst GPU to two best GPUs by KVPR
            # Build candidate models: top-12 by size and top-12 by demand (dn)
            size_sorted = sorted(worst_models, key=lambda md: float(getattr(md, "model_size")), reverse=True)[:12]
            dn_sorted = sorted(worst_models, key=lambda md: float(getattr(md, "req_rate")) / float(getattr(md, "slo")), reverse=True)[:12]
            seen_ids = set()
            cand_models = []
            for md in size_sorted + dn_sorted:
                mid = id(md)
                if mid not in seen_ids:
                    seen_ids.add(mid)
                    cand_models.append(md)

            # Choose up to two best target GPUs (lowest KVPR excluding worst)
            target_order = sorted([g for g in range(gpu_num) if g != worst], key=lambda g: cur_vals[g])
            best_targets = target_order[:2]

            # Evaluate targeted donation moves first
            for mdl in cand_models:
                ms = float(getattr(mdl, "model_size"))
                dn = float(getattr(mdl, "req_rate")) / float(getattr(mdl, "slo"))
                for tgt in best_targets:
                    if mem[tgt] + ms > GPU_MEM_SIZE + 1e-12:
                        continue

                    src_mem = mem[worst] - ms
                    src_num = num[worst] - dn
                    tgt_mem = mem[tgt] + ms
                    tgt_num = num[tgt] + dn

                    src_k = kvpr(src_num, GPU_MEM_SIZE - src_mem)
                    tgt_k = kvpr(tgt_num, GPU_MEM_SIZE - tgt_mem)

                    new_max = max(src_k, tgt_k)
                    for g in range(gpu_num):
                        if g != worst and g != tgt and cur_vals[g] > new_max:
                            new_max = cur_vals[g]

                    if new_max + eps < best_new_max:
                        best_new_max = new_max
                        best_move = ("move", mdl, worst, tgt, ms, dn)
                        improved = True

            if improved:
                _, mdl, src, tgt, ms, dn = best_move
                per_g[src].remove(mdl)
                per_g[tgt].append(mdl)
                mem[src] -= ms; num[src] -= dn
                mem[tgt] += ms; num[tgt] += dn
                continue

            # Try single-item moves out of worst GPU
            for mdl in worst_models:
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
        # Build placements at near-optimal T across multiple orderings and a small T-neighborhood
        all_plcs = []
        Ts = [high, high * 0.995, high * 1.005, high * 0.99, high * 1.01]
        combos = [
            (0, "resid"), (1, "resid"), (2, "resid"),
            (0, "minmax"), (1, "minmax"), (2, "minmax"),
            (0, "hybrid"), (1, "hybrid"), (2, "hybrid")
        ]
        for Tv in Ts:
            for ov, pol in combos:
                ok, plc = try_pack(Tv, ov, pol, True)
                if ok:
                    all_plcs.append(plc)

        # A couple of retuned candidates at final T
        ok_hr, plc_hr = try_pack_retune(high, 0, "hybrid", True)
        if ok_hr:
            all_plcs.append(plc_hr)
        ok_mr, plc_mr = try_pack_retune(high, 0, "minmax", True)
        if ok_mr:
            all_plcs.append(plc_mr)

        return all_plcs
=======
        # Build placements at near-optimal T across multiple orderings with a lean T-neighborhood
        all_plcs = []
        Ts = [high, high * 0.99, high * 1.01]
        combos = [
            (0, "resid"), (1, "resid"),
            (0, "minmax"), (1, "minmax"),
            (0, "hybrid")
        ]
        for Tv in Ts:
            for ov, pol in combos:
                ok, plc = try_pack(Tv, ov, pol, True)
                if ok:
                    all_plcs.append(plc)

        # A couple of retuned candidates at final T
        ok_hr, plc_hr = try_pack_retune(high, 0, "hybrid", True)
        if ok_hr:
            all_plcs.append(plc_hr)
        ok_mr, plc_mr = try_pack_retune(high, 0, "minmax", True)
        if ok_mr:
            all_plcs.append(plc_mr)

        return all_plcs
>>>>>>> REPLACE

</DIFF>
<DIFF>
<<<<<<< SEARCH
    # Improve each candidate locally and pick the best by measured max KVPR
    improved_candidates = []
    for plc in candidates:
        improved_candidates.append(improve_local(plc))

    # Tie-break robustly using (max, second-max, average) KVPR tuple
    def score_tuple(plc):
=======
    # Improve only the top few candidates locally (preselect by raw max KVPR)
    scored = [(measured_max_kvpr(plc), plc) for plc in candidates]
    scored.sort(key=lambda x: x[0])
    topk = [plc for _, plc in scored[:min(3, len(scored))]]
    improved_candidates = [improve_local(plc) for plc in topk]

    # Tie-break robustly using (max, second-max, average) KVPR tuple
    def score_tuple(plc):
>>>>>>> REPLACE

</DIFF>