<NAME>
two_phase_t_update
</NAME>

<DESCRIPTION>
Introduce a two-phase dynamic T refinement inside the transformed packing function to better align the placement with residual capacity and remaining items, which helps minimize the maximum KVPR. After placing about 45% of the items, we recompute a tighter lower bound T’ on the remaining items using per-item, global (with residual memory), pair, triplet, and k-prefix bounds on the remainder set. We then update T to max(T, T’) and reorder only the remaining items by the new transformed weights. This adapts the slack equalization to discrete effects and typically reduces the final max KVPR. Additionally, in the hybrid policy we adapt α based on the spread of current GPU KVPRs to balance projected max KVPR and memory imbalance more effectively. The change is localized within try_pack, keeping the rest of the algorithm intact and lightweight.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        for _, mdl, ms, n in ordered:
            w = n + T * ms
            candidates = []
            # Precompute current kvprs
            cur_kvprs = [kvpr_val(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)]

            # Precompute globals for hybrid memory balance
            total_m_after = sum(m_sum) + ms
            avg_mem_frac = total_m_after / (gpu_num * GPU_MEM_SIZE) if gpu_num > 0 else 0.0
            Tnorm = max(T, 1e-12)
            alpha = 0.2
            beta = 0.05

            for g in range(gpu_num):
                if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                    continue
                residual = cap - (used_cap[g] + w)
                if residual < -eps:
                    continue
                if policy == "resid":
                    candidates.append((g, residual, None, None, None))
                else:
                    new_n = n_sum[g] + n
                    new_m = m_sum[g] + ms
                    new_local = kvpr_val(new_n, GPU_MEM_SIZE - new_m)
                    # New global max if placed on g
                    new_max = new_local
                    for k in range(gpu_num):
                        if k != g and cur_kvprs[k] > new_max:
                            new_max = cur_kvprs[k]
                    if policy == "hybrid":
                        mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                        mem_imb = abs(mem_frac_after - avg_mem_frac)
                        J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                        candidates.append((g, residual, new_max, new_local, J))
                    else:
                        candidates.append((g, residual, new_max, new_local, None))

            if not candidates:
                return (False, None) if return_placement else False

            if policy == "resid":
                # Best-fit: minimize transformed residual; tie by more remaining mem then gpu id
                chosen = min(
                    candidates,
                    key=lambda c: (c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            elif policy == "hybrid":
                # Blend projected max KVPR, local KVPR, and memory imbalance
                chosen = min(
                    candidates,
                    key=lambda c: (c[4], c[2], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            else:
                # Minimize global new max KVPR; tie-break by local KVPR then residual then more remaining mem then id
                chosen = min(
                    candidates,
                    key=lambda c: (c[2], c[3], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]

            # Place
            placement[chosen].append(mdl)
            n_sum[chosen] += n
            m_sum[chosen] += ms
            used_cap[chosen] += w
=======
        # Two-phase dynamic T update: after placing ~45% of items, recompute a tighter lower bound
        updated_dynamic = False
        threshold_idx = max(1, int(0.45 * len(ordered)))
        i = 0
        while i < len(ordered):
            _, mdl, ms, n = ordered[i]
            w = n + T * ms
            candidates = []
            # Precompute current kvprs
            cur_kvprs = [kvpr_val(n_sum[g], GPU_MEM_SIZE - m_sum[g]) for g in range(gpu_num)]

            # Precompute globals for hybrid memory balance
            total_m_after = sum(m_sum) + ms
            avg_mem_frac = total_m_after / (gpu_num * GPU_MEM_SIZE) if gpu_num > 0 else 0.0
            Tnorm = max(T, 1e-12)
            spread = (max(cur_kvprs) - min(cur_kvprs)) if cur_kvprs else 0.0
            alpha = 0.25 if spread < 0.15 * Tnorm else 0.15
            beta = 0.05

            for g in range(gpu_num):
                if m_sum[g] + ms > GPU_MEM_SIZE + eps:
                    continue
                residual = cap - (used_cap[g] + w)
                if residual < -eps:
                    continue
                if policy == "resid":
                    candidates.append((g, residual, None, None, None))
                else:
                    new_n = n_sum[g] + n
                    new_m = m_sum[g] + ms
                    new_local = kvpr_val(new_n, GPU_MEM_SIZE - new_m)
                    # New global max if placed on g
                    new_max = new_local
                    for k in range(gpu_num):
                        if k != g and cur_kvprs[k] > new_max:
                            new_max = cur_kvprs[k]
                    if policy == "hybrid":
                        mem_frac_after = (m_sum[g] + ms) / GPU_MEM_SIZE
                        mem_imb = abs(mem_frac_after - avg_mem_frac)
                        J = (new_max / Tnorm) + alpha * (new_local / Tnorm) + beta * mem_imb
                        candidates.append((g, residual, new_max, new_local, J))
                    else:
                        candidates.append((g, residual, new_max, new_local, None))

            if not candidates:
                return (False, None) if return_placement else False

            if policy == "resid":
                # Best-fit: minimize transformed residual; tie by more remaining mem then gpu id
                chosen = min(
                    candidates,
                    key=lambda c: (c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            elif policy == "hybrid":
                # Blend projected max KVPR, local KVPR, and memory imbalance
                chosen = min(
                    candidates,
                    key=lambda c: (c[4], c[2], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]
            else:
                # Minimize global new max KVPR; tie-break by local KVPR then residual then more remaining mem then id
                chosen = min(
                    candidates,
                    key=lambda c: (c[2], c[3], c[1], -(GPU_MEM_SIZE - (m_sum[c[0]] + ms)), c[0])
                )[0]

            # Place
            placement[chosen].append(mdl)
            n_sum[chosen] += n
            m_sum[chosen] += ms
            used_cap[chosen] += w

            i += 1

            # Dynamic T refinement after initial phase
            if (not updated_dynamic) and (i >= threshold_idx) and (i < len(ordered)):
                # Remaining items
                rem = ordered[i:]
                if rem:
                    # Compute residual lower bound on T using remaining items and residual memory
                    rem_ms = [it[2] for it in rem]
                    rem_ns = [it[3] for it in rem]
                    sum_m_rem = sum(rem_ms)
                    sum_n_rem = sum(rem_ns)
                    used_mem_total = sum(m_sum)

                    indiv_rem = max(safe_div(nv, GPU_MEM_SIZE - mv) for mv, nv in zip(rem_ms, rem_ns))
                    global_rem = safe_div(sum_n_rem, max(gpu_num * GPU_MEM_SIZE - used_mem_total - sum_m_rem, 1e-9))

                    # Pair bound on top-by-size remainder (lightweight)
                    pair_rem = 0.0
                    Q = min(len(rem), 120)
                    heavy_rem = sorted(rem, key=lambda it: it[2], reverse=True)[:Q]
                    for a in range(len(heavy_rem)):
                        ma = heavy_rem[a][2]; na = heavy_rem[a][3]
                        for b in range(a + 1, len(heavy_rem)):
                            mb = heavy_rem[b][2]; nb = heavy_rem[b][3]
                            if ma + mb > GPU_MEM_SIZE + 1e-12:
                                denom = 2.0 * GPU_MEM_SIZE - (ma + mb)
                                pair_rem = max(pair_rem, safe_div(na + nb, max(denom, 1e-9)))

                    # Small triplet bound on remainder
                    trip_rem = 0.0
                    L2 = min(len(rem), 40)
                    top_rem = sorted(rem, key=lambda it: it[2], reverse=True)[:L2]
                    for a in range(L2):
                        ma = top_rem[a][2]; na = top_rem[a][3]
                        for b in range(a + 1, min(L2, a + 1 + 8)):
                            mb = top_rem[b][2]; nb = top_rem[b][3]
                            for c in range(b + 1, min(L2, b + 1 + 8)):
                                mc = top_rem[c][2]; nc = top_rem[c][3]
                                tm = ma + mb + mc
                                if tm > 2.0 * GPU_MEM_SIZE + 1e-12:
                                    denom = 3.0 * GPU_MEM_SIZE - tm
                                    trip_rem = max(trip_rem, safe_div(na + nb + nc, max(denom, 1e-9)))

                    # Small k-prefix on remainder
                    kpref_rem = 0.0
                    by_m_rem = sorted(rem, key=lambda it: it[2], reverse=True)
                    for kpf in range(1, min(gpu_num, 4) + 1):
                        sm = 0.0; sn = 0.0
                        for it in by_m_rem:
                            sm += it[2]; sn += it[3]
                            if sm > (kpf - 1) * GPU_MEM_SIZE + 1e-12:
                                break
                        denom = kpf * GPU_MEM_SIZE - sm
                        kpref_rem = max(kpref_rem, safe_div(sn, max(denom, 1e-9)))

                    T_new = max(T, indiv_rem, global_rem, pair_rem, trip_rem, kpref_rem)
                    if T_new > T + 1e-12:
                        # Update T and capacities; reorder remaining by new T
                        T = T_new
                        cap = GPU_MEM_SIZE * T
                        used_cap = [n_sum[g] + T * m_sum[g] for g in range(gpu_num)]
                        if order_variant == 0:
                            rem_sorted = sorted(rem, key=lambda it: (it[3] + T * it[2], it[3], it[2]), reverse=True)
                        elif order_variant == 1:
                            rem_sorted = sorted(rem, key=lambda it: (safe_div(it[3], max(GPU_MEM_SIZE - it[2], 1e-9)), it[2]), reverse=True)
                        else:
                            rem_sorted = sorted(rem, key=lambda it: (safe_div(it[3], max(it[2], 1e-9)), it[3]), reverse=True)
                        ordered[i:] = rem_sorted
                updated_dynamic = True
>>>>>>> REPLACE

</DIFF>