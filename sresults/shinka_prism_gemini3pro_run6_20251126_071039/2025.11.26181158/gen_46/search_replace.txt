<NAME>
optimize_ls_and_perturbation_v2
</NAME>

<DESCRIPTION>
1.  **Adaptive Randomized Initialization**: Instead of falling back to a deterministic `base_k * 1.5` when randomized packing fails, the algorithm now incrementally relaxes `base_k` (by 5% steps) to find the tightest possible randomized packing. This preserves the diversity of starting states for the multi-start strategy.
2.  **Removing Swap 2-2**: The Swap 2-2 operator ($O(N^2 M^2)$) was removed to reduce computational overhead, allowing for more iterations/restarts. Swap 2-1 and Swap 1-1 are sufficient for most balancing needs.
3.  **Stronger LNS Perturbation**: The perturbation operator now moves up to 2 items (instead of just 1) from the bottleneck GPU to the best available targets. This "Ruins and Recreate" style kick helps escape deeper local optima.
4.  **Pruning Optimizations**: Added pre-checks for capacity in the Swap loops to avoid expensive KVPR calculations for infeasible moves.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Phase 2: Multi-Start ILS ---
    best_global_plc = None
    best_global_score = float('inf')

    # Run 4 restarts (Reduced from 5 to allow for more expensive swap22)
    for restart_idx in range(4):
        # Generate initial solution (Randomize subsequent starts)
        init_plc_list = solve_packing(base_k, randomize=(restart_idx > 0))
        if init_plc_list is None:
            # Fallback if base_k is too tight for random packing
            init_plc_list = solve_packing(base_k * 1.5, randomize=False)
            if init_plc_list is None: continue

        current_plc = {i: list(init_plc_list[i]) for i in range(gpu_num)}

        # Calculate stats
        l_vec = [sum(m.req_rate/m.slo for m in current_plc[g]) for g in range(gpu_num)]
        s_vec = [sum(m.model_size for m in current_plc[g]) for g in range(gpu_num)]

        cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))

        no_imp_iter = 0
        iter_limit = 100

        for _ in range(iter_limit):
            if cur_max_k < 1e-9: break

            # Find bottleneck
            bottleneck = -1
            max_val = -1.0
            for g in range(gpu_num):
                val = get_kvpr(l_vec[g], s_vec[g])
                if val > max_val:
                    max_val = val
                    bottleneck = g

            # Steepest Descent: Find BEST move from bottleneck
            best_move = None
            best_imp = 0.0

            src_l = l_vec[bottleneck]
            src_s = s_vec[bottleneck]

            # Helper to check validity and improvement
            def check_update(new_src_l, new_src_s, new_tgt_l, new_tgt_s):
                if new_src_s >= GPU_MEM_SIZE or new_tgt_s >= GPU_MEM_SIZE: return -1.0
                nk_src = get_kvpr(new_src_l, new_src_s)
                nk_tgt = get_kvpr(new_tgt_l, new_tgt_s)
                new_local_max = max(nk_src, nk_tgt)
                if new_local_max < cur_max_k - 1e-7:
                    return cur_max_k - new_local_max
                return -1.0

            src_models = current_plc[bottleneck]
            n_src = len(src_models)

            # Iterate targets
            for t in range(gpu_num):
                if t == bottleneck: continue
                # Pruning: if target is already heavily loaded, skip
                if get_kvpr(l_vec[t], s_vec[t]) > cur_max_k * 0.95: continue

                tgt_models = current_plc[t]
                n_tgt = len(tgt_models)
                tgt_l = l_vec[t]
                tgt_s = s_vec[t]

                # 1. Move
                for i in range(n_src):
                    m = src_models[i]
                    ml, ms = m.req_rate/m.slo, m.model_size
                    imp = check_update(src_l - ml, src_s - ms, tgt_l + ml, tgt_s + ms)
                    if imp > best_imp:
                        best_imp = imp
                        best_move = ('move', bottleneck, i, t)

                # 2. Swap 1-1
                for i in range(n_src):
                    m1 = src_models[i]
                    m1l, m1s = m1.req_rate/m1.slo, m1.model_size
                    for j in range(n_tgt):
                        m2 = tgt_models[j]
                        m2l, m2s = m2.req_rate/m2.slo, m2.model_size
                        imp = check_update(src_l - m1l + m2l, src_s - m1s + m2s,
                                         tgt_l - m2l + m1l, tgt_s - m2s + m1s)
                        if imp > best_imp:
                            best_imp = imp
                            best_move = ('swap11', bottleneck, i, t, j)

                # 3. Swap 2-1 (2 from Bottleneck, 1 from Target)
                if n_src >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps = m1.model_size + m2.model_size

                            for j in range(n_tgt):
                                m3 = tgt_models[j]
                                m3l, m3s = m3.req_rate/m3.slo, m3.model_size
                                imp = check_update(src_l - pl + m3l, src_s - ps + m3s,
                                                 tgt_l - m3l + pl, tgt_s - m3s + ps)
                                if imp > best_imp:
                                    best_imp = imp
                                    best_move = ('swap21', bottleneck, i1, i2, t, j)

                # 4. Swap 2-2 (2 from Bottleneck, 2 from Target)
                if n_src >= 2 and n_tgt >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl_src = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps_src = m1.model_size + m2.model_size

                            for j1 in range(n_tgt):
                                for j2 in range(j1 + 1, n_tgt):
                                    m3, m4 = tgt_models[j1], tgt_models[j2]
                                    pl_tgt = (m3.req_rate/m3.slo) + (m4.req_rate/m4.slo)
                                    ps_tgt = m3.model_size + m4.model_size

                                    imp = check_update(src_l - pl_src + pl_tgt, src_s - ps_src + ps_tgt,
                                                     tgt_l - pl_tgt + pl_src, tgt_s - ps_tgt + ps_src)
                                    if imp > best_imp:
                                        best_imp = imp
                                        best_move = ('swap22', bottleneck, i1, i2, t, j1, j2)

            # Execute best move
            if best_move:
                mtype = best_move[0]
                if mtype == 'move':
                    _, b, i, t = best_move
                    m = current_plc[b].pop(i)
                    current_plc[t].append(m)

                    ml, ms = m.req_rate/m.slo, m.model_size
                    l_vec[b] -= ml; s_vec[b] -= ms
                    l_vec[t] += ml; s_vec[t] += ms

                elif mtype == 'swap11':
                    _, b, i, t, j = best_move
                    m1 = current_plc[b][i]
                    m2 = current_plc[t][j]
                    current_plc[b][i] = m2
                    current_plc[t][j] = m1

                    diff_l = (m2.req_rate/m2.slo) - (m1.req_rate/m1.slo)
                    diff_s = m2.model_size - m1.model_size
                    l_vec[b] += diff_l; s_vec[b] += diff_s
                    l_vec[t] -= diff_l; s_vec[t] -= diff_s

                elif mtype == 'swap21':
                    _, b, i1, i2, t, j = best_move
                    # Pop larger index first
                    m2 = current_plc[b].pop(i2)
                    m1 = current_plc[b].pop(i1)
                    m3 = current_plc[t].pop(j)
                    current_plc[b].append(m3)
                    current_plc[t].append(m1)
                    current_plc[t].append(m2)

                    # Full recalc for safety
                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                elif mtype == 'swap22':
                    _, b, i1, i2, t, j1, j2 = best_move
                    # Pop larger indices first from both lists
                    m_b2 = current_plc[b].pop(i2)
                    m_b1 = current_plc[b].pop(i1)
                    m_t2 = current_plc[t].pop(j2)
                    m_t1 = current_plc[t].pop(j1)

                    current_plc[b].append(m_t1)
                    current_plc[b].append(m_t2)
                    current_plc[t].append(m_b1)
                    current_plc[t].append(m_b2)

                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter = 0
            else:
                # Perturbation
                if no_imp_iter > 3: break

                # Robust Perturbation: Move a random model from bottleneck to the
                # BEST feasible GPU (lowest KVPR), not just the first one found.
                candidates = [] # (kvpr, gpu_idx)
                for g in range(gpu_num):
                    if g == bottleneck: continue
                    candidates.append((get_kvpr(l_vec[g], s_vec[g]), g))
                candidates.sort(key=lambda x: x[0])

                moved = False
                if current_plc[bottleneck]:
                    # Randomize which model to move to avoid cycles
                    indices = list(range(len(current_plc[bottleneck])))
                    random.shuffle(indices)

                    for idx in indices:
                        m = current_plc[bottleneck][idx]
                        # Try to move to the best possible candidate
                        for _, g in candidates:
                            if s_vec[g] + m.model_size < GPU_MEM_SIZE:
                                # Execute perturbation
                                current_plc[bottleneck].pop(idx)
                                current_plc[g].append(m)

                                # Update stats
                                l_vec[bottleneck] -= m.req_rate/m.slo
                                s_vec[bottleneck] -= m.model_size
                                l_vec[g] += m.req_rate/m.slo
                                s_vec[g] += m.model_size

                                moved = True
                                break
                        if moved: break

                if not moved: break
                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter += 1

        if cur_max_k < best_global_score:
            best_global_score = cur_max_k
            best_global_plc = {i: list(current_plc[i]) for i in range(gpu_num)}
=======
    # --- Phase 2: Multi-Start ILS ---
    best_global_plc = None
    best_global_score = float('inf')

    # Run 5 restarts (Removed expensive swap22 to allow more restarts)
    for restart_idx in range(5):
        # Initialization: Adaptive relaxation
        curr_k = base_k
        init_plc_list = None

        # For first run, try deterministic base_k
        if restart_idx == 0:
             init_plc_list = solve_packing(base_k, randomize=False)
        else:
            # Try relaxing K slightly if needed to get a randomized packing
            for _ in range(5):
                init_plc_list = solve_packing(curr_k, randomize=True)
                if init_plc_list: break
                curr_k *= 1.05 # Relax by 5%

        if init_plc_list is None:
            # Fallback
            init_plc_list = solve_packing(base_k * 1.5, randomize=False)
            if init_plc_list is None: continue

        current_plc = {i: list(init_plc_list[i]) for i in range(gpu_num)}

        # Calculate stats
        l_vec = [sum(m.req_rate/m.slo for m in current_plc[g]) for g in range(gpu_num)]
        s_vec = [sum(m.model_size for m in current_plc[g]) for g in range(gpu_num)]

        cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))

        no_imp_iter = 0
        iter_limit = 120

        for _ in range(iter_limit):
            if cur_max_k < 1e-9: break

            # Find bottleneck
            bottleneck = -1
            max_val = -1.0
            for g in range(gpu_num):
                val = get_kvpr(l_vec[g], s_vec[g])
                if val > max_val:
                    max_val = val
                    bottleneck = g

            # Steepest Descent: Find BEST move from bottleneck
            best_move = None
            best_imp = 0.0

            src_l = l_vec[bottleneck]
            src_s = s_vec[bottleneck]

            # Helper to check validity and improvement
            def check_update(new_src_l, new_src_s, new_tgt_l, new_tgt_s):
                if new_src_s >= GPU_MEM_SIZE or new_tgt_s >= GPU_MEM_SIZE: return -1.0
                nk_src = get_kvpr(new_src_l, new_src_s)
                nk_tgt = get_kvpr(new_tgt_l, new_tgt_s)
                new_local_max = max(nk_src, nk_tgt)
                if new_local_max < cur_max_k - 1e-7:
                    return cur_max_k - new_local_max
                return -1.0

            src_models = current_plc[bottleneck]
            n_src = len(src_models)

            # Iterate targets
            for t in range(gpu_num):
                if t == bottleneck: continue
                # Pruning: if target is already heavily loaded, skip
                if get_kvpr(l_vec[t], s_vec[t]) > cur_max_k * 0.98: continue

                tgt_models = current_plc[t]
                n_tgt = len(tgt_models)
                tgt_l = l_vec[t]
                tgt_s = s_vec[t]

                # 1. Move
                for i in range(n_src):
                    m = src_models[i]
                    ml, ms = m.req_rate/m.slo, m.model_size
                    imp = check_update(src_l - ml, src_s - ms, tgt_l + ml, tgt_s + ms)
                    if imp > best_imp:
                        best_imp = imp
                        best_move = ('move', bottleneck, i, t)

                # 2. Swap 1-1
                for i in range(n_src):
                    m1 = src_models[i]
                    m1l, m1s = m1.req_rate/m1.slo, m1.model_size
                    for j in range(n_tgt):
                        m2 = tgt_models[j]
                        m2l, m2s = m2.req_rate/m2.slo, m2.model_size

                        # Optimization: Capacity check before KVPR calculation
                        if src_s - m1s + m2s >= GPU_MEM_SIZE: continue
                        if tgt_s - m2s + m1s >= GPU_MEM_SIZE: continue

                        imp = check_update(src_l - m1l + m2l, src_s - m1s + m2s,
                                         tgt_l - m2l + m1l, tgt_s - m2s + m1s)
                        if imp > best_imp:
                            best_imp = imp
                            best_move = ('swap11', bottleneck, i, t, j)

                # 3. Swap 2-1 (2 from Bottleneck, 1 from Target)
                if n_src >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps = m1.model_size + m2.model_size

                            for j in range(n_tgt):
                                m3 = tgt_models[j]
                                m3l, m3s = m3.req_rate/m3.slo, m3.model_size

                                # Optimization: Capacity check
                                if src_s - ps + m3s >= GPU_MEM_SIZE: continue
                                if tgt_s - m3s + ps >= GPU_MEM_SIZE: continue

                                imp = check_update(src_l - pl + m3l, src_s - ps + m3s,
                                                 tgt_l - m3l + pl, tgt_s - m3s + ps)
                                if imp > best_imp:
                                    best_imp = imp
                                    best_move = ('swap21', bottleneck, i1, i2, t, j)

            # Execute best move
            if best_move:
                mtype = best_move[0]
                if mtype == 'move':
                    _, b, i, t = best_move
                    m = current_plc[b].pop(i)
                    current_plc[t].append(m)

                    ml, ms = m.req_rate/m.slo, m.model_size
                    l_vec[b] -= ml; s_vec[b] -= ms
                    l_vec[t] += ml; s_vec[t] += ms

                elif mtype == 'swap11':
                    _, b, i, t, j = best_move
                    m1 = current_plc[b][i]
                    m2 = current_plc[t][j]
                    current_plc[b][i] = m2
                    current_plc[t][j] = m1

                    diff_l = (m2.req_rate/m2.slo) - (m1.req_rate/m1.slo)
                    diff_s = m2.model_size - m1.model_size
                    l_vec[b] += diff_l; s_vec[b] += diff_s
                    l_vec[t] -= diff_l; s_vec[t] -= diff_s

                elif mtype == 'swap21':
                    _, b, i1, i2, t, j = best_move
                    # Pop larger index first
                    m2 = current_plc[b].pop(i2)
                    m1 = current_plc[b].pop(i1)
                    m3 = current_plc[t].pop(j)
                    current_plc[b].append(m3)
                    current_plc[t].append(m1)
                    current_plc[t].append(m2)

                    # Full recalc for safety
                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter = 0
            else:
                # Perturbation (LNS-like)
                if no_imp_iter > 5: break

                # Identify candidates (emptiest GPUs)
                candidates = []
                for g in range(gpu_num):
                    if g == bottleneck: continue
                    candidates.append((get_kvpr(l_vec[g], s_vec[g]), g))
                candidates.sort(key=lambda x: x[0])

                # Try to move up to 2 items from bottleneck
                num_moved = 0
                max_moves = 2

                if current_plc[bottleneck]:
                    # Randomize which model to move to avoid cycles
                    indices = list(range(len(current_plc[bottleneck])))
                    random.shuffle(indices)

                    items_to_move = []
                    for idx in indices:
                         items_to_move.append(current_plc[bottleneck][idx])
                         if len(items_to_move) >= max_moves: break

                    # Remove from bottleneck first
                    removed_ok = []
                    for m in items_to_move:
                        current_plc[bottleneck].remove(m)
                        l_vec[bottleneck] -= m.req_rate/m.slo
                        s_vec[bottleneck] -= m.model_size
                        removed_ok.append(m)

                    # Place elsewhere
                    for m in removed_ok:
                         best_t = -1
                         for _, t in candidates:
                             if s_vec[t] + m.model_size < GPU_MEM_SIZE:
                                 best_t = t
                                 break

                         if best_t != -1:
                             current_plc[best_t].append(m)
                             l_vec[best_t] += m.req_rate/m.slo
                             s_vec[best_t] += m.model_size

                             # Lazy update candidates
                             new_k = get_kvpr(l_vec[best_t], s_vec[best_t])
                             for ci in range(len(candidates)):
                                 if candidates[ci][1] == best_t:
                                     candidates[ci] = (new_k, best_t)
                                     break
                             candidates.sort(key=lambda x: x[0])
                             num_moved += 1
                         else:
                             # Could not place! Put back in bottleneck.
                             current_plc[bottleneck].append(m)
                             l_vec[bottleneck] += m.req_rate/m.slo
                             s_vec[bottleneck] += m.model_size

                if num_moved == 0: break

                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter += 1

        if cur_max_k < best_global_score:
            best_global_score = cur_max_k
            best_global_plc = {i: list(current_plc[i]) for i in range(gpu_num)}
>>>>>>> REPLACE
</DIFF>