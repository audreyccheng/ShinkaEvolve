--- a/original.py
+++ b/original.py
@@ -1,339 +1,319 @@
 # EVOLVE-BLOCK-START
+import random
 import math
 
 GPU_MEM_SIZE = 80  # GB
-
-import random
 
 def compute_model_placement(gpu_num, models):
     """
     Compute a model placement that minimizes the maximum KVPR across all GPUs.
 
-    Algorithm: Multi-Start Perturbation-Based Iterated Local Search.
-    1. Initialization: Randomized Bin Packing (Best Fit Decreasing) with Binary Search for K.
-    2. Local Search: Steepest Descent on max KVPR using extensive neighborhoods:
-       - Shift (1 -> 0)
-       - Swap (1 <-> 1)
-       - Swap (2 <-> 1)
-       - Swap (2 <-> 2)
-    3. Restarts: Run multiple times with randomized sorting to find better basins.
+    Combines Multi-Strategy Binary Search initialization with Multi-Start 
+    Iterated Local Search using extensive neighborhoods (Shift, Swap11, Swap21, Swap22).
     """
 
-    # Pre-calculate model properties
+    # 1. Data Preparation
     model_data = []
     for i, m in enumerate(models):
         model_data.append({
             'model': m,
             'l': m.req_rate / m.slo,
             's': m.model_size,
             'id': i
         })
 
-    def solve_packing(target_k, randomize=False):
-        capacity = target_k * GPU_MEM_SIZE
-
-        # Base weights: L + K*S
-        items = []
-        for x in model_data:
-            w = x['l'] + target_k * x['s']
-            if randomize:
-                w *= random.uniform(0.95, 1.05)
-            items.append((w, x))
-
-        # Sort descending by weight
-        items.sort(key=lambda x: x[0], reverse=True)
-
-        bins_l = [0.0] * gpu_num
-        bins_s = [0.0] * gpu_num
-        bins_items = [[] for _ in range(gpu_num)]
-
-        for _, item in items:
-            best_bin = -1
-            min_slack = float('inf')
-
-            item_w = item['l'] + target_k * item['s']
-
-            # Randomized start index for tie-breaking if randomize=True
-            indices = list(range(gpu_num))
-            if randomize:
-                random.shuffle(indices)
-
-            for b in indices:
-                if bins_s[b] + item['s'] >= GPU_MEM_SIZE - 1e-6:
-                    continue
-
-                current_bin_w = bins_l[b] + target_k * bins_s[b]
-                if current_bin_w + item_w <= capacity + 1e-9:
-                    slack = capacity - (current_bin_w + item_w)
-                    if slack < min_slack:
-                        min_slack = slack
-                        best_bin = b
-
-            if best_bin != -1:
-                bins_l[best_bin] += item['l']
-                bins_s[best_bin] += item['s']
-                bins_items[best_bin].append(item)
-            else:
-                return None
-
-        return bins_items
-
     def get_kvpr(l, s):
         if s >= GPU_MEM_SIZE - 1e-6: return 1e15
         return l / (GPU_MEM_SIZE - s)
 
-    # --- Phase 1: Determine Baseline K ---
+    # 2. Multi-Strategy Packing for Initialization
+    def pack_models(target_k, sorting_strategy='weighted', randomize=False):
+        capacity = target_k * GPU_MEM_SIZE
+        
+        # Prepare items with sorting key
+        items = []
+        for d in model_data:
+            key = 0.0
+            if sorting_strategy == 'weighted':
+                # Linearized weight: L + K*S
+                key = d['l'] + target_k * d['s']
+            elif sorting_strategy == 'size':
+                key = d['s']
+            elif sorting_strategy == 'load':
+                key = d['l']
+            elif sorting_strategy == 'density':
+                key = d['l'] / d['s'] if d['s'] > 0 else d['l'] * 1e6
+            
+            if randomize:
+                key *= random.uniform(0.95, 1.05)
+            items.append((key, d))
+            
+        # Sort descending by key
+        items.sort(key=lambda x: x[0], reverse=True)
+        
+        gpu_l = [0.0] * gpu_num
+        gpu_s = [0.0] * gpu_num
+        gpu_items = [[] for _ in range(gpu_num)]
+        
+        # Tie-breaking for bins
+        bin_indices = list(range(gpu_num))
+        if randomize:
+            random.shuffle(bin_indices)
+            
+        for _, item in items:
+            best_idx = -1
+            min_rem = float('inf')
+            w_item = item['l'] + target_k * item['s']
+            
+            # Best Fit
+            for i in bin_indices:
+                if gpu_s[i] + item['s'] >= GPU_MEM_SIZE - 1e-6:
+                    continue
+                
+                curr_w = gpu_l[i] + target_k * gpu_s[i]
+                if curr_w + w_item <= capacity + 1e-9:
+                    rem = capacity - (curr_w + w_item)
+                    if rem < min_rem:
+                        min_rem = rem
+                        best_idx = i
+            
+            if best_idx != -1:
+                gpu_l[best_idx] += item['l']
+                gpu_s[best_idx] += item['s']
+                gpu_items[best_idx].append(item)
+            else:
+                return None
+        return gpu_items
+
+    def solve_multistrategy(target_k):
+        # Try multiple strategies to find ANY valid packing at target_k
+        # This increases robustness of the binary search
+        strategies = ['weighted', 'size', 'load']
+        for strat in strategies:
+            res = pack_models(target_k, sorting_strategy=strat, randomize=False)
+            if res is not None:
+                return res
+        return None
+
+    # 3. Binary Search for Baseline K
     low, high = 0.0, 1.0
     for _ in range(20):
-        if solve_packing(high) is not None: break
+        if solve_multistrategy(high) is not None: break
         low = high
         high *= 2.0
-    else: high = 1e9
-
-    for _ in range(20):
+    else:
+        high = 1e9 
+
+    best_init_placement = None
+    for _ in range(25):
         mid = (low + high) / 2
-        if solve_packing(mid) is not None: high = mid
-        else: low = mid
+        res = solve_multistrategy(mid)
+        if res:
+            best_init_placement = res
+            high = mid
+        else:
+            low = mid
+            
     base_k = high
-
+    if best_init_placement is None:
+        best_init_placement = solve_multistrategy(base_k)
+        if best_init_placement is None:
+            # Should generally not happen unless physically impossible
+            raise ValueError("Unable to fit models into GPU memory.")
+
+    # 4. ILS / Local Search Phase
     best_global_plc = None
     best_global_score = float('inf')
-
-    # --- Phase 2: Multi-Start ILS ---
-    # Run 3 restarts
-    for restart in range(3):
-        # Generate initial solution
-        randomize = (restart > 0)
-        init_bins = solve_packing(base_k, randomize=randomize)
-
-        # If random packing fails at base_k, relax slightly or skip
-        if init_bins is None:
-            if restart == 0:
-                # Should not happen given Phase 1, but safety
-                init_bins = solve_packing(high * 1.01)
-                if init_bins is None: continue
-            else:
-                continue
-
-        # Convert to mutable state
+    
+    # Candidate generation
+    # 1. The best result from Binary Search
+    # 2. Randomized results using Weighted sort around base_k
+    candidates = [best_init_placement]
+    
+    for _ in range(2): # Add randomized starts
+        rnd = pack_models(base_k * 1.02, sorting_strategy='weighted', randomize=True)
+        if rnd: candidates.append(rnd)
+            
+    # Run Local Search on candidates
+    for start_sol in candidates:
+        # State construction
         gpu_states = []
         for g in range(gpu_num):
-            items = init_bins[g]
-            g_l = sum(x['l'] for x in items)
-            g_s = sum(x['s'] for x in items)
-            gpu_states.append({'l': g_l, 's': g_s, 'items': list(items)})
-
-        current_max = max(get_kvpr(g['l'], g['s']) for g in gpu_states)
-
+            items = start_sol[g]
+            gpu_states.append({
+                'l': sum(x['l'] for x in items),
+                's': sum(x['s'] for x in items),
+                'items': list(items)
+            })
+            
+        curr_max_k = max(get_kvpr(g['l'], g['s']) for g in gpu_states)
+        
         # Steepest Descent Local Search
-        iter_limit = 150
-        for _ in range(iter_limit):
-            if current_max < 1e-9: break
-
+        for _ in range(150):
+            if curr_max_k < 1e-9: break
+            
             # Find bottleneck
             max_val = -1.0
-            max_gpu = -1
-            gpu_kvprs = []
+            bottleneck = -1
+            g_vals = []
             for g in range(gpu_num):
-                val = get_kvpr(gpu_states[g]['l'], gpu_states[g]['s'])
-                gpu_kvprs.append(val)
-                if val > max_val:
-                    max_val = val
-                    max_gpu = g
-
+                v = get_kvpr(gpu_states[g]['l'], gpu_states[g]['s'])
+                g_vals.append(v)
+                if v > max_val:
+                    max_val = v
+                    bottleneck = g
+                    
             best_move = None
-            best_gain = 0.0
-
-            src = gpu_states[max_gpu]
-            src_n = len(src['items'])
-
-            # Function to eval move
-            def eval_state(s_l, s_s, t_l, t_s):
-                if s_s >= GPU_MEM_SIZE or t_s >= GPU_MEM_SIZE: return -1.0
-                nk_s = get_kvpr(s_l, s_s)
-                nk_t = get_kvpr(t_l, t_s)
-                new_peak = max(nk_s, nk_t)
-                if new_peak < current_max - 1e-7:
-                    return current_max - new_peak
+            best_imp = 0.0
+            
+            src = gpu_states[bottleneck]
+            
+            def check_gain(sl, ss, tl, ts):
+                if ss >= GPU_MEM_SIZE or ts >= GPU_MEM_SIZE: return -1.0
+                n_max = max(get_kvpr(sl, ss), get_kvpr(tl, ts))
+                if n_max < curr_max_k - 1e-7:
+                    return curr_max_k - n_max
                 return -1.0
 
             # Scan targets
             for t in range(gpu_num):
-                if t == max_gpu: continue
-                # Skip if target is already close to max (heuristic pruning)
-                if gpu_kvprs[t] > current_max * 0.95: continue
-
+                if t == bottleneck: continue
+                # Pruning: skip if target is already heavily loaded
+                if g_vals[t] > curr_max_k * 0.98: continue
+                
                 tgt = gpu_states[t]
-                tgt_n = len(tgt['items'])
-
-                # 1. Shift
-                for i in range(src_n):
-                    itm = src['items'][i]
-                    gain = eval_state(src['l']-itm['l'], src['s']-itm['s'],
-                                    tgt['l']+itm['l'], tgt['s']+itm['s'])
-                    if gain > best_gain:
-                        best_gain = gain
+                
+                # Shift
+                for i, m in enumerate(src['items']):
+                    gain = check_gain(src['l']-m['l'], src['s']-m['s'], tgt['l']+m['l'], tgt['s']+m['s'])
+                    if gain > best_imp:
+                        best_imp = gain
                         best_move = ('shift', i, t)
-
-                # 2. Swap 1-1
-                for i in range(src_n):
-                    si = src['items'][i]
-                    for j in range(tgt_n):
-                        tj = tgt['items'][j]
-                        gain = eval_state(
-                            src['l']-si['l']+tj['l'], src['s']-si['s']+tj['s'],
-                            tgt['l']-tj['l']+si['l'], tgt['s']-tj['s']+si['s']
-                        )
-                        if gain > best_gain:
-                            best_gain = gain
+                        
+                # Swap 1-1
+                for i, m1 in enumerate(src['items']):
+                    for j, m2 in enumerate(tgt['items']):
+                        gain = check_gain(src['l']-m1['l']+m2['l'], src['s']-m1['s']+m2['s'],
+                                          tgt['l']-m2['l']+m1['l'], tgt['s']-m2['s']+m1['s'])
+                        if gain > best_imp:
+                            best_imp = gain
                             best_move = ('swap11', i, t, j)
-
-                # 3. Swap 2-1 (2 from src, 1 from tgt)
-                if src_n >= 2:
-                    for i1 in range(src_n):
-                        for i2 in range(i1+1, src_n):
-                            s1, s2 = src['items'][i1], src['items'][i2]
-                            pl, ps = s1['l']+s2['l'], s1['s']+s2['s']
-                            for j in range(tgt_n):
-                                tj = tgt['items'][j]
-                                gain = eval_state(
-                                    src['l']-pl+tj['l'], src['s']-ps+tj['s'],
-                                    tgt['l']-tj['l']+pl, tgt['s']-tj['s']+ps
-                                )
-                                if gain > best_gain:
-                                    best_gain = gain
+                            
+                # Swap 2-1
+                if len(src['items']) >= 2:
+                    for i1 in range(len(src['items'])):
+                        for i2 in range(i1+1, len(src['items'])):
+                            m1, m2 = src['items'][i1], src['items'][i2]
+                            pl, ps = m1['l']+m2['l'], m1['s']+m2['s']
+                            for j, m3 in enumerate(tgt['items']):
+                                gain = check_gain(src['l']-pl+m3['l'], src['s']-ps+m3['s'],
+                                                  tgt['l']-m3['l']+pl, tgt['s']-m3['s']+ps)
+                                if gain > best_imp:
+                                    best_imp = gain
                                     best_move = ('swap21', i1, i2, t, j)
 
-                # 4. Swap 2-2 (2 from src, 2 from tgt)
-                if src_n >= 2 and tgt_n >= 2:
-                     for i1 in range(src_n):
-                        for i2 in range(i1+1, src_n):
-                            s1, s2 = src['items'][i1], src['items'][i2]
-                            sl, ss = s1['l']+s2['l'], s1['s']+s2['s']
-                            for j1 in range(tgt_n):
-                                for j2 in range(j1+1, tgt_n):
-                                    t1, t2 = tgt['items'][j1], tgt['items'][j2]
-                                    tl, ts = t1['l']+t2['l'], t1['s']+t2['s']
-
-                                    gain = eval_state(
-                                        src['l']-sl+tl, src['s']-ss+ts,
-                                        tgt['l']-tl+sl, tgt['s']-ts+ss
-                                    )
-                                    if gain > best_gain:
-                                        best_gain = gain
+                # Swap 2-2
+                if len(src['items']) >= 2 and len(tgt['items']) >= 2:
+                    for i1 in range(len(src['items'])):
+                        for i2 in range(i1+1, len(src['items'])):
+                            m1, m2 = src['items'][i1], src['items'][i2]
+                            sl, ss = m1['l']+m2['l'], m1['s']+m2['s']
+                            for j1 in range(len(tgt['items'])):
+                                for j2 in range(j1+1, len(tgt['items'])):
+                                    m3, m4 = tgt['items'][j1], tgt['items'][j2]
+                                    tl, ts = m3['l']+m4['l'], m3['s']+m4['s']
+                                    gain = check_gain(src['l']-sl+tl, src['s']-ss+ts,
+                                                      tgt['l']-tl+sl, tgt['s']-ts+ss)
+                                    if gain > best_imp:
+                                        best_imp = gain
                                         best_move = ('swap22', i1, i2, t, j1, j2)
 
             if best_move:
                 mtype = best_move[0]
                 if mtype == 'shift':
                     _, i, t = best_move
-                    itm = src['items'].pop(i)
-                    tgt = gpu_states[t]
-                    src['l']-=itm['l']; src['s']-=itm['s']
-                    tgt['items'].append(itm)
-                    tgt['l']+=itm['l']; tgt['s']+=itm['s']
-
+                    m = src['items'].pop(i)
+                    tgt['items'].append(m)
                 elif mtype == 'swap11':
                     _, i, t, j = best_move
-                    tgt = gpu_states[t]
-                    s_itm = src['items'][i]
-                    t_itm = tgt['items'][j]
-                    src['items'][i] = t_itm
-                    tgt['items'][j] = s_itm
-
-                    src['l'] += t_itm['l'] - s_itm['l']; src['s'] += t_itm['s'] - s_itm['s']
-                    tgt['l'] += s_itm['l'] - t_itm['l']; tgt['s'] += s_itm['s'] - t_itm['s']
-
+                    src['items'][i], tgt['items'][j] = tgt['items'][j], src['items'][i]
                 elif mtype == 'swap21':
                     _, i1, i2, t, j = best_move
-                    tgt = gpu_states[t]
-                    # pop max index first
-                    s2 = src['items'].pop(i2)
-                    s1 = src['items'].pop(i1)
-                    t1 = tgt['items'].pop(j)
-
-                    src['items'].append(t1)
-                    tgt['items'].extend([s1, s2])
-
-                    # Full recalc simpler
-                    src['l'] = sum(x['l'] for x in src['items']); src['s'] = sum(x['s'] for x in src['items'])
-                    tgt['l'] = sum(x['l'] for x in tgt['items']); tgt['s'] = sum(x['s'] for x in tgt['items'])
-
+                    # Pop higher index first to preserve lower index
+                    m2 = src['items'].pop(i2)
+                    m1 = src['items'].pop(i1)
+                    m3 = tgt['items'].pop(j)
+                    src['items'].append(m3)
+                    tgt['items'].extend([m1, m2])
                 elif mtype == 'swap22':
                     _, i1, i2, t, j1, j2 = best_move
-                    tgt = gpu_states[t]
-
-                    s2 = src['items'].pop(i2)
-                    s1 = src['items'].pop(i1)
-                    t2 = tgt['items'].pop(j2)
-                    t1 = tgt['items'].pop(j1)
-
-                    src['items'].extend([t1, t2])
-                    tgt['items'].extend([s1, s2])
-
-                    src['l'] = sum(x['l'] for x in src['items']); src['s'] = sum(x['s'] for x in src['items'])
-                    tgt['l'] = sum(x['l'] for x in tgt['items']); tgt['s'] = sum(x['s'] for x in tgt['items'])
-
-                # Recompute current max
-                current_max = max(get_kvpr(g['l'], g['s']) for g in gpu_states)
+                    m_s2 = src['items'].pop(i2)
+                    m_s1 = src['items'].pop(i1)
+                    m_t2 = tgt['items'].pop(j2)
+                    m_t1 = tgt['items'].pop(j1)
+                    src['items'].extend([m_t1, m_t2])
+                    tgt['items'].extend([m_s1, m_s2])
+                
+                # Update cached sums
+                src['l'] = sum(x['l'] for x in src['items']); src['s'] = sum(x['s'] for x in src['items'])
+                tgt['l'] = sum(x['l'] for x in tgt['items']); tgt['s'] = sum(x['s'] for x in tgt['items'])
+                
+                curr_max_k = max(get_kvpr(g['l'], g['s']) for g in gpu_states)
             else:
                 break
-
-        if current_max < best_global_score:
-            best_global_score = current_max
+                
+        if curr_max_k < best_global_score:
+            best_global_score = curr_max_k
             best_global_plc = {g: [x['model'] for x in gpu_states[g]['items']] for g in range(gpu_num)}
-
-    if best_global_plc is None:
-        raise ValueError("Could not find valid placement")
 
     return best_global_plc
 # EVOLVE-BLOCK-END
 
 
 def run_placement(gpu_num, models):
     """
     Main entry point that will be called by the evaluator.
 
     Args:
         gpu_num: Number of GPUs
         models: List of models to place
 
     Returns:
         Dictionary containing GPU placements
     """
     return compute_model_placement(gpu_num, models)
 
 
 if __name__ == "__main__":
     # Test the algorithm
     import os
     import sys
 
     # Add the openevolve_examples directory to the path to import evaluator
     def find_repo_root(start_path):
         """Find the repository root by looking for openevolve_examples directory."""
         current = os.path.abspath(start_path)
         while current != os.path.dirname(current):  # Stop at filesystem root
             if os.path.exists(os.path.join(current, 'openevolve_examples', 'prism')):
                 return current
             current = os.path.dirname(current)
         raise RuntimeError("Could not find openevolve_examples directory")
 
     repo_root = find_repo_root(os.path.dirname(__file__))
     sys.path.insert(0, os.path.join(repo_root, 'openevolve_examples', 'prism'))
 
     from evaluator import generate_test_gpu_models, calculate_kvcache_pressure, safe_float
     import numpy as np
 
     test_cases = generate_test_gpu_models()
     all_kvpr = []
     for i, (gpu_num, gpu_models) in enumerate(test_cases):
         results = compute_model_placement(gpu_num, gpu_models)
         max_kvpr = calculate_kvcache_pressure(results)
         all_kvpr.append(safe_float(max_kvpr))
 
     avg_kvpr = np.mean(all_kvpr)
     if avg_kvpr != 0:
         avg_kvpr = 1.0 / avg_kvpr
 
     print(f"Max KVPR: {avg_kvpr:.3f}")