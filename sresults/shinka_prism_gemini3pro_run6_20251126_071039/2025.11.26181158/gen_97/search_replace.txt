<NAME>
local_search_refinement
</NAME>

<DESCRIPTION>
Implement a post-processing local search refinement step after the binary search. The binary search combined with Best Fit Decreasing finds a feasible placement with a low max KVPR, but the greedy nature of BFD often leaves room for improvement (e.g., uneven load distribution). The refinement step iteratively identifies the bottleneck GPU (highest KVPR) and attempts to move or swap models with other GPUs to reduce the maximum KVPR, thereby fine-tuning the solution and improving the score.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Binary Search
    for _ in range(50):
        mid = (low + high) / 2
        res = can_pack(mid)
        if res is not None:
            best_placement = res
            high = mid
        else:
            low = mid

    # Format the result
    return {i: best_placement[i] for i in range(gpu_num)}
=======
    # Binary Search
    for _ in range(50):
        mid = (low + high) / 2
        res = can_pack(mid)
        if res is not None:
            best_placement = res
            high = mid
        else:
            low = mid

    # Local Search Refinement
    # Greedily move/swap models to reduce the max KVPR
    current_placement = best_placement

    def get_gpu_kvpr(models_on_gpu):
        if not models_on_gpu: return 0.0
        sum_l = sum(m.req_rate / m.slo for m in models_on_gpu)
        sum_s = sum(m.model_size for m in models_on_gpu)
        if sum_s >= GPU_MEM_SIZE - 1e-6:
            return float('inf')
        return sum_l / (GPU_MEM_SIZE - sum_s)

    # Precompute model properties for fast lookup
    mod_to_props = {d['model']: d for d in model_data}

    for _ in range(50):  # Iteration limit
        # Find bottleneck GPU
        kvprs = [get_gpu_kvpr(current_placement[i]) for i in range(gpu_num)]
        max_kvpr = max(kvprs)
        if max_kvpr == 0: break

        src_gpu = kvprs.index(max_kvpr)
        models_src = current_placement[src_gpu]

        # Calculate source stats
        src_l = sum(mod_to_props[m]['l'] for m in models_src)
        src_s = sum(mod_to_props[m]['s'] for m in models_src)

        improved = False

        # Strategy 1: Move a model from src to dst
        for i, m in enumerate(models_src):
            m_props = mod_to_props[m]
            ml, ms = m_props['l'], m_props['s']

            # Theoretical new src KVPR
            new_src_s = src_s - ms
            new_src_l = src_l - ml
            if abs(new_src_s - GPU_MEM_SIZE) < 1e-6:
                 new_src_kvpr = float('inf')
            else:
                 new_src_kvpr = new_src_l / (GPU_MEM_SIZE - new_src_s)

            for dst_gpu in range(gpu_num):
                if dst_gpu == src_gpu: continue

                models_dst = current_placement[dst_gpu]
                dst_l = sum(mod_to_props[mod]['l'] for mod in models_dst)
                dst_s = sum(mod_to_props[mod]['s'] for mod in models_dst)

                if dst_s + ms >= GPU_MEM_SIZE - 1e-6: continue

                new_dst_kvpr = (dst_l + ml) / (GPU_MEM_SIZE - (dst_s + ms))

                if max(new_src_kvpr, new_dst_kvpr) < max_kvpr - 1e-9:
                    models_dst.append(m)
                    models_src.pop(i)
                    improved = True
                    break
            if improved: break

        if improved: continue

        # Strategy 2: Swap a model from src with a model from dst
        for i, m in enumerate(models_src):
            m_props = mod_to_props[m]
            ml, ms = m_props['l'], m_props['s']

            for dst_gpu in range(gpu_num):
                if dst_gpu == src_gpu: continue
                models_dst = current_placement[dst_gpu]

                dst_l_base = sum(mod_to_props[mod]['l'] for mod in models_dst)
                dst_s_base = sum(mod_to_props[mod]['s'] for mod in models_dst)

                for j, n in enumerate(models_dst):
                    n_props = mod_to_props[n]
                    nl, ns = n_props['l'], n_props['s']

                    new_src_s = src_s - ms + ns
                    new_dst_s = dst_s_base - ns + ms

                    if new_src_s >= GPU_MEM_SIZE - 1e-6 or new_dst_s >= GPU_MEM_SIZE - 1e-6:
                        continue

                    new_src_l = src_l - ml + nl
                    new_dst_l = dst_l_base - nl + ml

                    new_src_kvpr = new_src_l / (GPU_MEM_SIZE - new_src_s)
                    new_dst_kvpr = new_dst_l / (GPU_MEM_SIZE - new_dst_s)

                    if max(new_src_kvpr, new_dst_kvpr) < max_kvpr - 1e-9:
                        models_src[i] = n
                        models_dst[j] = m
                        improved = True
                        break
                if improved: break
            if improved: break

        if not improved:
            break

    # Format the result
    return {i: current_placement[i] for i in range(gpu_num)}
>>>>>>> REPLACE
</DIFF>