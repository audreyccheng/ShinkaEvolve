<NAME>
stochastic_initialization_and_ils_overhaul
</NAME>

<DESCRIPTION>
1.  **Stochastic Multi-Start Initialization**: Replaces the single deterministic binary search for the linearization parameter $K$ with a randomized approach. It finds a baseline $K$, then runs multiple iterations with perturbed $K$ and randomized item weights (noise) to explore different packing basins.
2.  **Best Improvement ILS**: Changes the Move and Swap 1-1 operators from "First Improvement" to "Best Improvement". The algorithm now scans all valid moves/swaps involving the top bottleneck GPUs and selects the one that yields the maximum reduction in the lexicographical vector. This helps escape shallow local optima.
3.  **Ruins-and-Recreate Perturbation**: Replaces the weak single-model perturbation with a destructive "Ruins-and-Recreate" operator. When stagnant, it empties the worst bottleneck GPU completely and re-inserts its models using a Best Fit heuristic into other GPUs (or back if necessary), significantly altering the state to jump out of deep local optima.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # A. Binary Search Linearization
    def solve_linearized_bp(target_k):
        bin_cap = target_k * GPU_MEM_SIZE
        items = []
        for m in models:
            w = (m.req_rate / m.slo) + target_k * m.model_size
            items.append((w, m))
        items.sort(key=lambda x: x[0], reverse=True)

        bins = [GPUState(i) for i in range(gpu_num)]
        for w, m in items:
            best_idx = -1
            min_rem = float('inf')
            for i in range(gpu_num):
                if not bins[i].can_fit(m.model_size): continue
                lin_usage = bins[i].load + target_k * bins[i].used_mem
                if lin_usage + w <= bin_cap:
                    rem = bin_cap - (lin_usage + w)
                    if rem < min_rem:
                        min_rem = rem
                        best_idx = i
            if best_idx != -1:
                bins[best_idx].add(m)
            else:
                return None
        return bins

    low, high = 0.0, 1000.0
    if solve_linearized_bp(high) is None: high = 1e8

    bs_res = None
    for _ in range(20):
        mid = (low + high) / 2
        res = solve_linearized_bp(mid)
        if res:
            bs_res = res
            high = mid
        else:
            low = mid
    if bs_res: candidates.append(bs_res)
=======
    # A. Randomized Binary Search Linearization
    def solve_linearized_bp(target_k, noise=0.0):
        bin_cap = target_k * GPU_MEM_SIZE
        items = []
        for m in models:
            base_w = (m.req_rate / m.slo) + target_k * m.model_size
            w = base_w
            if noise > 0:
                w *= random.uniform(1.0 - noise, 1.0 + noise)
            items.append((w, m, base_w))
        items.sort(key=lambda x: x[0], reverse=True)

        bins = [GPUState(i) for i in range(gpu_num)]
        for w, m, base_w in items:
            best_idx = -1
            min_rem = float('inf')
            for i in range(gpu_num):
                if not bins[i].can_fit(m.model_size): continue
                lin_usage = bins[i].load + target_k * bins[i].used_mem
                if lin_usage + base_w <= bin_cap:
                    rem = bin_cap - (lin_usage + base_w)
                    if rem < min_rem:
                        min_rem = rem
                        best_idx = i
            if best_idx != -1:
                bins[best_idx].add(m)
            else:
                return None
        return bins

    low, high = 0.0, 1000.0
    if solve_linearized_bp(high) is None: high = 1e9

    bs_res = None
    best_k = high
    for _ in range(20):
        mid = (low + high) / 2
        res = solve_linearized_bp(mid)
        if res:
            bs_res = res
            best_k = mid
            high = mid
        else:
            low = mid
    if bs_res: candidates.append(bs_res)

    # Randomized refinements around best_k
    for _ in range(15):
        k_noisy = best_k * random.uniform(0.9, 1.1)
        res_noise = solve_linearized_bp(k_noisy, noise=0.05)
        if res_noise: candidates.append(res_noise)
>>>>>>> REPLACE
<<<<<<< SEARCH
    # -------------------------------------------------------------------------
    # 2. Iterated Local Search
    # -------------------------------------------------------------------------
    iter_cnt = 0
    max_iter = 150

    while iter_cnt < max_iter:
        improved_step = False
        iter_cnt += 1

        sorted_gpus = sorted(current_gpus, key=lambda g: g.kvpr(), reverse=True)
        sources = sorted_gpus[:4]

        # --- Move ---
        for source in sources:
            for i, model in enumerate(source.models):
                for dest in current_gpus:
                    if dest.id == source.id: continue
                    if dest.can_fit(model.model_size):
                        source.remove(i)
                        dest.add(model)
                        new_vec = get_vector(current_gpus)
                        if new_vec < current_vector:
                            current_vector = new_vec
                            improved_step = True
                            if current_vector < best_vector:
                                best_vector = current_vector
                                for k in range(gpu_num): best_gpus[k].copy_from(current_gpus[k])
                            break
                        else:
                            dest.remove(len(dest.models)-1)
                            source.restore_model(i, model)
                if improved_step: break
            if improved_step: break
        if improved_step: continue

        # --- Swap 1-1 ---
        for source in sources:
            for i, m_a in enumerate(source.models):
                for dest in current_gpus:
                    if dest.id == source.id: continue
                    if dest.kvpr() >= source.kvpr(): continue
                    for j, m_b in enumerate(dest.models):
                        s_mem = source.used_mem - m_a.model_size + m_b.model_size
                        d_mem = dest.used_mem - m_b.model_size + m_a.model_size
                        if s_mem <= GPU_MEM_SIZE and d_mem <= GPU_MEM_SIZE:
                            source.remove(i)
                            dest.remove(j)
                            source.add(m_b)
                            dest.add(m_a)
                            new_vec = get_vector(current_gpus)
                            if new_vec < current_vector:
                                current_vector = new_vec
                                improved_step = True
                                if current_vector < best_vector:
                                    best_vector = current_vector
                                    for k in range(gpu_num): best_gpus[k].copy_from(current_gpus[k])
                                break
                            else:
                                dest.remove(len(dest.models)-1)
                                source.remove(len(source.models)-1)
                                dest.restore_model(j, m_b)
                                source.restore_model(i, m_a)
                    if improved_step: break
                if improved_step: break
        if improved_step: continue

        # --- Swap 2-1 (New) ---
        for source in sources[:2]:
            if len(source.models) < 2: continue
            for i1 in range(len(source.models)):
                for i2 in range(i1+1, len(source.models)):
                    m_a1 = source.models[i1]
                    m_a2 = source.models[i2]
                    for dest in current_gpus:
                        if dest.id == source.id: continue
                        if dest.kvpr() >= source.kvpr(): continue
                        for j, m_b in enumerate(dest.models):
                            s_mem = source.used_mem - m_a1.model_size - m_a2.model_size + m_b.model_size
                            d_mem = dest.used_mem - m_b.model_size + m_a1.model_size + m_a2.model_size
                            if s_mem <= GPU_MEM_SIZE and d_mem <= GPU_MEM_SIZE:
                                source.remove(i2) # Remove higher index first
                                source.remove(i1)
                                dest.remove(j)
                                source.add(m_b)
                                dest.add(m_a1)
                                dest.add(m_a2)
                                new_vec = get_vector(current_gpus)
                                if new_vec < current_vector:
                                    current_vector = new_vec
                                    improved_step = True
                                    if current_vector < best_vector:
                                        best_vector = current_vector
                                        for k in range(gpu_num): best_gpus[k].copy_from(current_gpus[k])
                                    break
                                else:
                                    dest.remove(len(dest.models)-1)
                                    dest.remove(len(dest.models)-1)
                                    source.remove(len(source.models)-1)
                                    dest.restore_model(j, m_b)
                                    source.restore_model(i1, m_a1)
                                    source.restore_model(i2, m_a2)
                        if improved_step: break
                    if improved_step: break
                if improved_step: break
            if improved_step: break
        if improved_step: continue

        # --- Swap 1-2 ---
        for source in sources[:2]:
            for i, m_a in enumerate(source.models):
                for dest in current_gpus:
                    if dest.id == source.id: continue
                    if dest.kvpr() >= source.kvpr(): continue
                    if len(dest.models) < 2: continue
                    n_d = len(dest.models)
                    pair_found = False
                    for j1 in range(n_d):
                        for j2 in range(j1+1, n_d):
                            m_b1 = dest.models[j1]
                            m_b2 = dest.models[j2]
                            s_mem = source.used_mem - m_a.model_size + m_b1.model_size + m_b2.model_size
                            d_mem = dest.used_mem - m_b1.model_size - m_b2.model_size + m_a.model_size
                            if s_mem <= GPU_MEM_SIZE and d_mem <= GPU_MEM_SIZE:
                                source.remove(i)
                                dest.remove(j2)
                                dest.remove(j1)
                                source.add(m_b1)
                                source.add(m_b2)
                                dest.add(m_a)
                                new_vec = get_vector(current_gpus)
                                if new_vec < current_vector:
                                    current_vector = new_vec
                                    improved_step = True
                                    pair_found = True
                                    if current_vector < best_vector:
                                        best_vector = current_vector
                                        for k in range(gpu_num): best_gpus[k].copy_from(current_gpus[k])
                                    break
                                else:
                                    dest.remove(len(dest.models)-1)
                                    source.remove(len(source.models)-1)
                                    source.remove(len(source.models)-1)
                                    dest.restore_model(j1, m_b1)
                                    dest.restore_model(j2, m_b2)
                        if pair_found: break
                    if pair_found: break
                if improved_step: break
        if improved_step: continue

        # --- Perturbation ---
        if iter_cnt > max_iter - 20: break
        worst_gpu = sorted_gpus[0]
        if not worst_gpu.models: break
        m_idx = random.randint(0, len(worst_gpu.models)-1)
        model_to_move = worst_gpu.models[m_idx]
        feasible_dests = [g for g in current_gpus if g.id != worst_gpu.id and g.can_fit(model_to_move.model_size)]
        if feasible_dests:
            # Guided perturbation: Prefer destination with low pressure
            feasible_dests.sort(key=lambda g: g.kvpr())
            dest = random.choice(feasible_dests[:3])
            worst_gpu.remove(m_idx)
            dest.add(model_to_move)
            current_vector = get_vector(current_gpus)
        else:
            break

    return {g.id: g.models for g in best_gpus}
=======
    # -------------------------------------------------------------------------
    # 2. Iterated Local Search (ILS)
    # -------------------------------------------------------------------------
    iter_cnt = 0
    max_iter = 150

    while iter_cnt < max_iter:
        improved_step = False

        # Sort GPUs: process bottlenecks first
        sorted_gpus = sorted(current_gpus, key=lambda g: g.kvpr(), reverse=True)
        sources = sorted_gpus[:4]
        destinations = sorted_gpus[::-1]

        # --- Operator 1: Move (Best Improvement) ---
        best_move = None
        best_move_gain = current_vector

        for source in sources:
            for i, model in enumerate(source.models):
                for dest in current_gpus:
                    if dest.id == source.id: continue
                    if dest.can_fit(model.model_size):
                        source.remove(i)
                        dest.add(model)

                        new_vec = get_vector(current_gpus)
                        if new_vec < best_move_gain:
                            best_move_gain = new_vec
                            best_move = (source, i, dest, model)

                        dest.remove(len(dest.models)-1)
                        source.restore_model(i, model)

        if best_move:
            src, idx, dst, mdl = best_move
            src.remove(idx)
            dst.add(mdl)
            current_vector = best_move_gain
            improved_step = True

            if current_vector < best_vector:
                best_vector = current_vector
                for k in range(gpu_num): best_gpus[k].copy_from(current_gpus[k])
            iter_cnt += 1
            continue

        # --- Operator 2: Swap 1-1 (Best Improvement) ---
        best_swap = None
        best_swap_gain = current_vector

        for source in sources:
            for i, m_a in enumerate(source.models):
                for dest in destinations:
                    if dest.id == source.id: continue
                    if dest.kvpr() >= source.kvpr(): continue

                    for j, m_b