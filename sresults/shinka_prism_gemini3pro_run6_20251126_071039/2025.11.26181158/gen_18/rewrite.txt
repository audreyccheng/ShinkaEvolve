# EVOLVE-BLOCK-START
import math

GPU_MEM_SIZE = 80  # GB

def compute_model_placement(gpu_num, models):
    """
    Compute a model placement that minimizes the maximum KVPR across all GPUs.
    
    Algorithm:
    1. Binary Search for the optimal Max KVPR 'K'.
       The feasibility check transforms the problem into a Bin Packing Problem
       with linearized item weights: w = l + K * s.
       It uses Best Fit Decreasing with 4 sorting heuristics:
       - Linearized Weight: l + K*s
       - Size: s
       - Load: l
       - Density: l/s
    2. Local Search Refinement.
       After finding a feasible placement, we explicitly minimize the max KVPR
       using three neighborhood operators on the bottleneck GPU:
       - Shift: Move 1 model to another GPU.
       - Swap 1-1: Exchange 1 model with 1 from another GPU.
       - Swap 2-1: Exchange 2 models with 1 from another GPU (helps with fragmentation).
    """
    
    # Precompute model characteristics
    model_data = []
    for i, m in enumerate(models):
        model_data.append({
            'model': m,
            'l': m.req_rate / m.slo,
            's': m.model_size,
            'id': i
        })

    # --- Phase 1: Binary Search Construction ---
    
    def solve_packing(target_k):
        capacity = target_k * GPU_MEM_SIZE
        
        # Sorting strategies for Best Fit Decreasing
        heuristics = [
            # 1. Linearized Weight: balances load and size based on K
            lambda x: x['l'] + target_k * x['s'],
            # 2. Size: prioritizes fitting large items (memory constrained)
            lambda x: x['s'],
            # 3. Load: prioritizes high load items
            lambda x: x['l'],
            # 4. Density: efficient packing
            lambda x: x['l'] / x['s'] if x['s'] > 0 else 0
        ]
        
        for key_func in heuristics:
            # Sort descending
            items = sorted(model_data, key=key_func, reverse=True)
            
            bins_l = [0.0] * gpu_num
            bins_s = [0.0] * gpu_num
            bins_items = [[] for _ in range(gpu_num)]
            
            feasible = True
            for item in items:
                best_bin = -1
                min_slack = float('inf')
                
                # Weight of item in linearized constraint
                item_w = item['l'] + target_k * item['s']
                
                for b in range(gpu_num):
                    # Hard Memory Constraint
                    if bins_s[b] + item['s'] >= GPU_MEM_SIZE - 1e-6:
                        continue
                    
                    # Linearized Constraint: sum(L) + K*sum(S) <= K*M
                    current_bin_w = bins_l[b] + target_k * bins_s[b]
                    
                    if current_bin_w + item_w <= capacity + 1e-9:
                        # Best Fit: minimize slack
                        slack = capacity - (current_bin_w + item_w)
                        if slack < min_slack:
                            min_slack = slack
                            best_bin = b
                            
                if best_bin != -1:
                    bins_l[best_bin] += item['l']
                    bins_s[best_bin] += item['s']
                    bins_items[best_bin].append(item)
                else:
                    feasible = False
                    break
            
            if feasible:
                return bins_items
                
        return None

    # Binary Search
    low = 0.0
    high = 1.0
    
    # Exponential search for upper bound
    for _ in range(20):
        if solve_packing(high) is not None:
            break
        low = high
        high *= 2.0
    else:
        high = 1e9 # Fallback
        
    best_packing = None
    
    # Precision search
    for _ in range(30):
        mid = (low + high) / 2
        res = solve_packing(mid)
        if res is not None:
            best_packing = res
            high = mid
        else:
            low = mid
            
    if best_packing is None:
        best_packing = solve_packing(high)
        if best_packing is None:
            raise ValueError("Unable to place models.")

    # Convert to standard format for Phase 2
    placement = {i: [x['model'] for x in best_packing[i]] for i in range(gpu_num)}

    # --- Phase 2: Local Search Refinement ---
    
    # Initialize state for fast access
    gpu_states = []
    for g in range(gpu_num):
        # We use the dictionaries from model_data to avoid re-creating them
        # We need to map the model objects back to their data dicts
        p_models = placement[g]
        g_items = []
        g_l = 0.0
        g_s = 0.0
        # Map models to data dicts. Optimization: Create a lookup if N is large, 
        # but for small N nested loop is fine.
        for m in p_models:
            for d in model_data:
                if d['model'] is m:
                    g_items.append(d)
                    g_l += d['l']
                    g_s += d['s']
                    break
        gpu_states.append({'l': g_l, 's': g_s, 'items': g_items})

    def get_kvpr(l, s):
        if s >= GPU_MEM_SIZE - 1e-6: return float('inf')
        return l / (GPU_MEM_SIZE - s)

    # Hill Climbing on Global Max KVPR
    for _ in range(200): # Iteration limit
        # 1. Identify Bottleneck
        max_kvpr = -1.0
        max_gpu = -1
        current_kvprs = []
        
        for g in range(gpu_num):
            val = get_kvpr(gpu_states[g]['l'], gpu_states[g]['s'])
            current_kvprs.append(val)
            if val > max_kvpr:
                max_kvpr = val
                max_gpu = g
        
        if max_kvpr < 1e-9: break # Perfect score
        
        # 2. Find Best Move
        best_move = None # (type, gain, args...)
        best_gain = 0.0
        
        src = gpu_states[max_gpu]
        
        # Helper to calculate gain
        def calc_gain(src_l_new, src_s_new, tgt_l_new, tgt_s_new, old_tgt_kvpr):
            ns_k = get_kvpr(src_l_new, src_s_new)
            nt_k = get_kvpr(tgt_l_new, tgt_s_new)
            new_peak = max(ns_k, nt_k)
            # We strictly want to reduce the global max
            if new_peak < max_kvpr - 1e-7:
                return max_kvpr - new_peak
            return -1.0

        # Move Types
        # A. Shift: Move item from src -> tgt
        for i, item in enumerate(src['items']):
            for t in range(gpu_num):
                if t == max_gpu: continue
                # Pruning: Target shouldn't be worse than current max
                if current_kvprs[t] >= max_kvpr: continue
                
                tgt = gpu_states[t]
                if tgt['s'] + item['s'] >= GPU_MEM_SIZE: continue
                
                gain = calc_gain(
                    src['l'] - item['l'], src['s'] - item['s'],
                    tgt['l'] + item['l'], tgt['s'] + item['s'],
                    current_kvprs[t]
                )
                if gain > best_gain:
                    best_gain = gain
                    best_move = ('shift', i, t)

        # B. Swap 1-1: Swap item src <-> item tgt
        for i, s_item in enumerate(src['items']):
            for t in range(gpu_num):
                if t == max_gpu: continue
                if current_kvprs[t] >= max_kvpr: continue
                
                tgt = gpu_states[t]
                for j, t_item in enumerate(tgt['items']):
                    # Check capacity
                    ns_s = src['s'] - s_item['s'] + t_item['s']
                    nt_s = tgt['s'] - t_item['s'] + s_item['s']
                    
                    if ns_s >= GPU_MEM_SIZE or nt_s >= GPU_MEM_SIZE: continue
                    
                    gain = calc_gain(
                        src['l'] - s_item['l'] + t_item['l'], ns_s,
                        tgt['l'] - t_item['l'] + s_item['l'], nt_s,
                        current_kvprs[t]
                    )
                    if gain > best_gain:
                        best_gain = gain
                        best_move = ('swap11', i, t, j)
                        
        # C. Swap 2-1: Swap {item1, item2} src <-> {item3} tgt
        # Useful for defragmentation or load balancing
        if len(src['items']) >= 2:
            n_src = len(src['items'])
            # Limit checks to prevent O(N^3) explosion if N is large
            # But typically N is small per GPU
            for i1 in range(n_src):
                for i2 in range(i1 + 1, n_src):
                    itm1 = src['items'][i1]
                    itm2 = src['items'][i2]
                    pair_l = itm1['l'] + itm2['l']
                    pair_s = itm1['s'] + itm2['s']
                    
                    for t in range(gpu_num):
                        if t == max_gpu: continue
                        if current_kvprs[t] >= max_kvpr: continue
                        
                        tgt = gpu_states[t]
                        for j, t_itm in enumerate(tgt['items']):
                            ns_s = src['s'] - pair_s + t_itm['s']
                            nt_s = tgt['s'] - t_itm['s'] + pair_s
                            
                            if ns_s >= GPU_MEM_SIZE or nt_s >= GPU_MEM_SIZE: continue
                            
                            gain = calc_gain(
                                src['l'] - pair_l + t_itm['l'], ns_s,
                                tgt['l'] - t_itm['l'] + pair_l, nt_s,
                                current_kvprs[t]
                            )
                            if gain > best_gain:
                                best_gain = gain
                                best_move = ('swap21', i1, i2, t, j)

        # Execute Move
        if best_move:
            mtype = best_move[0]
            if mtype == 'shift':
                _, idx, t_id = best_move
                item = src['items'].pop(idx)
                tgt = gpu_states[t_id]
                
                src['l'] -= item['l']; src['s'] -= item['s']
                tgt['items'].append(item)
                tgt['l'] += item['l']; tgt['s'] += item['s']
                
            elif mtype == 'swap11':
                _, s_idx, t_id, t_idx = best_move
                tgt = gpu_states[t_id]
                s_item = src['items'][s_idx]
                t_item = tgt['items'][t_idx]
                
                src['items'][s_idx] = t_item
                tgt['items'][t_idx] = s_item
                
                src['l'] += t_item['l'] - s_item['l']; src['s'] += t_item['s'] - s_item['s']
                tgt['l'] += s_item['l'] - t_item['l']; tgt['s'] += s_item['s'] - t_item['s']
                
            elif mtype == 'swap21':
                _, i1, i2, t_id, t_idx = best_move
                tgt = gpu_states[t_id]
                
                # Pop strictly i2 > i1
                itm2 = src['items'].pop(i2)
                itm1 = src['items'].pop(i1)
                t_itm = tgt['items'].pop(t_idx)
                
                src['items'].append(t_itm)
                tgt['items'].extend([itm1, itm2])
                
                pair_l = itm1['l'] + itm2['l']; pair_s = itm1['s'] + itm2['s']
                src['l'] += t_itm['l'] - pair_l; src['s'] += t_itm['s'] - pair_s
                tgt['l'] += pair_l - t_itm['l']; tgt['s'] += pair_s - t_itm['s']
        else:
            break # No improvement found
            
    return {g: [x['model'] for x in gpu_states[g]['items']] for g in range(gpu_num)}
# EVOLVE-BLOCK-END