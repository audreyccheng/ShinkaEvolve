# INDIVIDUAL PROGRAM SUMMARIES

The following are summaries of individual programs evaluated since the last meta update:

**Program Name: Greedy Load-Density Minimization Placement**
- **Implementation**: The algorithm sorts models by load intensity (request rate/SLO) and places them on the GPU that minimizes the current ratio of accumulated load to remaining memory.
- **Performance**: Achieved a high combined score of 21.89 and a 100% success rate, efficiently minimizing maximum KV cache pressure.
- **Feedback**: The strategy of dynamically balancing accumulated load against available capacity effectively prevents hotspots, resulting in a superior distribution of cache pressure compared to standard packing methods.
**Program Identifier:** Generation 0 - Patch Name initial_program - Correct Program: True

**Program Name: Multi-start Greedy with Lexicographical Local Search**
- **Implementation**: The algorithm generates initial solutions using three sorting heuristics (size, load, density) and refines the best one using a local search that applies moves and swaps to the bottleneck GPU, accepting changes that improve the lexicographical vector of pressures.
- **Performance**: It achieved a high combined score of 25.75 with extremely fast execution (0.004s) and a 100% success rate.
- **Feedback**: The lexicographical comparison enables the local search to optimize the overall load distribution rather than just the maximum peak, while the multi-start approach robustly handles varying model characteristics.
**Program Identifier:** Generation 1 - Patch Name greedy_multistart_localsearch - Correct Program: True

**Program Name: Greedy Resulting-Pressure Minimization with Size-Descent Sort**
- **Implementation**: The algorithm sorts models by size and load (descending) and iteratively assigns them to the GPU that minimizes the resulting KV cache pressure (total load divided by remaining memory).
- **Performance**: Achieved a high combined score of 20.43 with a 100% success rate and very low execution time (0.013s).
- **Feedback**: Sorting by size primarily ensures large models are placed before memory becomes fragmented, while the greedy look-ahead strategy for specific pressure reduction effectively balances the load across resources.
**Program Identifier:** Generation 2 - Patch Name greedy_resulting_kvpr_bfd - Correct Program: True

**Program Name: Multi-start Greedy with Lexicographical Local Search**
- **Implementation**: The solution employs a multi-start greedy strategy initialized by various sorting metrics (size, load, density) and random shuffles, followed by a local search refinement. It optimizes the lexicographically sorted vector of GPU pressures using move and swap operators targeted specifically at the top three bottleneck GPUs.
- **Performance**: Achieved a high combined score of 26.26 with a 100% success rate and fast execution time of 0.103s.
- **Feedback**: The use of lexicographical comparison allows the algorithm to improve secondary bottlenecks when the maximum pressure cannot be immediately reduced, preventing premature convergence. Focusing the local search on high-pressure GPUs ensures the solution remains computationally efficient while effectively balancing the load.
**Program Identifier:** Generation 3 - Patch Name randomized_multi_start_local_search - Correct Program: True

**Program Name: Binary Search KVPR with Linearized Weight Bin Packing**
- **Implementation**: The algorithm minimizes maximum KV cache pressure by binary searching for a target threshold, converting the feasibility check into a bin packing problem using First Fit Decreasing on linearized weights ($req\_rate/slo + threshold \times size$).
- **Performance**: It achieved a high score of 26.23 and a 100% success rate, efficiently balancing load and memory constraints with negligible execution time.
- **Feedback**: The transformation of the fractional objective into a linear bin-packing constraint allows the heuristic to adaptively prioritize heavy or large models based on the current target pressure, resulting in optimal placements.
**Program Identifier:** Generation 4 - Patch Name kvpr_binary_search_packing - Correct Program: True

**Program Name: Linearized Bin Packing with Best Fit and Local Search**
- **Implementation**: The algorithm linearizes the KVPR objective to enable binary search for the optimal target value, utilizing Best Fit bin packing with dual sorting heuristics (linearized weight and model size) to check feasibility. A post-processing local search greedily moves models from the highest-pressure GPU to others to refine the global maximum pressure.
- **Performance**: The solution achieved a combined score of 26.23 with a max KVPR metric of 25.233, maintaining a 100% success rate and negligible execution time (0.001s).
- **Feedback**: Transforming the non-linear KVPR metric into a linear constraint allows for efficient approximation via binary search, solving the core allocation problem effectively. The addition of local search refinement ensures the initial packing is optimized further, correcting any imbalances left by the heuristic packing.
**Program Identifier:** Generation 5 - Patch Name bs_bestfit_localsearch - Correct Program: True

**Program Name: Binary Search with Transformed First-Fit Decreasing Bin Packing**
- **Implementation**: The solution minimizes maximum KV cache pressure by binary searching for an optimal target value, transforming the non-linear ratio constraint into linear item weights and validating feasibility using a First-Fit Decreasing heuristic.
- **Performance**: The approach performed exceptionally well, achieving a combined score of 26.10 with a 100% success rate and negligible execution time (0.001s).
- **Feedback**: Converting the min-max objective into a feasibility problem via binary search allows efficient application of standard bin packing heuristics, effectively balancing computational speed with solution quality.
**Program Identifier:** Generation 6 - Patch Name binary_search_bin_packing - Correct Program: True

**Program Name: Binary Search with Multi-Strategy Best Fit Packing**
- **Implementation**: The algorithm minimizes KV cache pressure using binary search on the pressure ratio, validating feasibility via Best Fit Decreasing with three alternate sorting strategies (linearized weight, model size, and load).
- **Performance**: Achieves a high score of 26.10 with a 100% success rate and negligible execution time (0.001s).
- **Feedback**: The use of multiple sorting heuristics within the packing check allows the solution to adapt dynamically to whether memory or load is the dominant constraint, resulting in highly efficient placements.
**Program Identifier:** Generation 7 - Patch Name improved_packing_heuristics - Correct Program: True

**Program Name: Binary Search Best Fit with Multi-Strategy Sorting**
- **Implementation**: The solution minimizes maximum KVPR by binary searching for the optimal pressure threshold, initializing with a theoretical lower bound derived from fluid packing. The feasibility check uses a Best Fit Decreasing algorithm that attempts three distinct sorting strategies (Linearized Weight, Size, and Load) to robustly fit models into GPUs.
- **Performance**: The algorithm achieved a high combined score of 26.23 and a 100% success rate with extremely fast execution times (0.002s).
- **Feedback**: The use of multiple sorting strategies allows the packer to adapt dynamically to both memory-bound and load-bound scenarios, significantly improving packing density. Additionally, calculating a precise lower bound for the binary search range ensures the algorithm converges quickly on the optimal solution.
**Program Identifier:** Generation 8 - Patch Name adaptive_multi_strategy_packing - Correct Program: True

**Program Name: Binary Search Bin Packing with Local Search Refinement**
- **Implementation**: The algorithm performs a binary search on the target KVPR to solve a linearized bin packing problem using Best Fit with multiple sorting heuristics, followed by a greedy local search that moves or swaps models to relieve the bottleneck GPU.
- **Performance**: It achieves a high score of 26.23 and perfect success rate with negligible execution time (0.001s).
- **Feedback**: The hybrid approach effectively balances global constraints via linearization and local non-linear optimization, providing a robust solution for the rational objective function without heavy computational overhead.
**Program Identifier:** Generation 9 - Patch Name improved_packing_and_local_search - Correct Program: True

# GLOBAL INSIGHTS SCRATCHPAD

The following are global insights about optimization approaches and their effectiveness:

Based on the analysis of the individual program summaries and the code of the current best program (Generation 3), here are the insights:

## Successful Algorithmic Patterns
- **Lexicographical Vector Optimization**: The current best program (Generation 3, Score 26.26) optimizes the lexicographically sorted vector of all GPU pressures, not just the single maximum peak. This allows the algorithm to reduce secondary and tertiary bottlenecks when the primary bottleneck cannot be improved, preventing premature convergence.
- **Randomized Multi-Start Initialization**: While deterministic multi-start (Generation 1, Score 25.75) performed well, adding random shuffles to the initialization phase (Generation 3) improved the score to 26.26. This diversification allows the local search to explore different basins of attraction in the non-linear solution space.
- **Linearization via Binary Search**: Transforming the fractional KVPR objective into a linear bin packing constraint ($req\_rate/slo + threshold \times size \le capacity$) enabled Generations 4-9 to achieve near-optimal scores (~26.23) with negligible execution times (~0.001s), offering a highly efficient alternative to iterative search.
- **Targeted Local Search Scope**: The best program focuses its expensive swap/move operations only on the top 3 bottleneck GPUs. This targeted approach effectively balances computational cost with optimization depth, contributing to the high success rate and reasonable execution time (0.103s).

## Ineffective Approaches
- **Single-Heuristic Greedy Construction**: Approaches relying on a single sorting metric without refinement (e.g., Generation 2, Score 20.43) significantly underperformed compared to multi-start or iterative methods. The complex interaction between model size and request rate requires more than a single "smart" sort to resolve optimally.
- **Purely Deterministic Greedy**: Even with local search, the purely deterministic approach of Generation 1 (Score 25.75) could not reach the global optima found by the randomized approach (Generation 3, Score 26.26) or the mathematical linearization approaches, indicating that deterministic heuristics alone are prone to getting stuck in local optima.

## Implementation Insights
- **Vector-Based Comparison Key**: The best program effectively implements the lexicographical optimization using Python's native tuple comparison on the pressure vector: `current_vector = sorted([g.kvpr() for g in gs], reverse=True)`. This simple implementation detail ensures that any move improving the overall distribution shape is accepted.
- **Dynamic Constraint Adaptation**: In the Binary Search implementations (e.g., Generation 8), checking feasibility using multiple internal sorting strategies (Linearized Weight, Size, Load) allows the packer to adapt dynamically to instances constrained by memory versus those constrained by compute load.
- **State Caching**: The best program uses a `GPUState` class that caches the `_cached_kvpr` calculation. Since the

# META RECOMMENDATIONS

The following are actionable recommendations for the next program generations:

Based on the analysis of the current best program (Generation 3) and the high-performing patterns from other generations (specifically the Binary Search linearization), here are 5 actionable recommendations for future mutations:

1.  **Hybrid Linearization Initialization**: Integrate the "Binary Search with Linearization" pattern (successful in Generations 4-9) to generate the initial solution seed, rather than relying solely on simple greedy sorts. Use the current best program's Lexicographical Local Search to refine this seed. This combines the global approximation power of the linearization method with the fine-grained distribution shaping of the local search.
2.  **Iterated Local Search (ILS) with Perturbation**: Instead of independent random restarts, implement an Iterated Local Search strategy where the best found solution is "perturbed" (e.g., randomly unassigning 20% of models or clearing the bottleneck GPU) and then re-optimized. This allows the search to explore the solution space surrounding high-quality optima, potentially bridging the gap between local and global maximums.
3.  **Compound Neighborhood Moves (2-for-1 Swaps)**: Expand the local search `swap` operator to include "2-for-1" exchanges, where two smaller models from a target GPU are swapped for one large model from a bottleneck GPU. This specifically addresses memory capacity constraints (80GB) where 1-1 swaps often fail because no single model on the target is large enough to free up required space.
4.  **Regret-Based Greedy Construction**: Modify the deterministic construction phase to order models by "regret"â€”the difference in cost between placing a model on its best GPU versus its second-best GPU. Placing high-regret models first ensures that critical decisions are prioritized, preventing scenarios where "difficult" models are forced onto overloaded GPUs at the end of the process.
5.  **Optimized Delta-Vector Evaluation**: Refine the local search acceptance criteria to compare only the modified elements of the pressure vector rather than re-sorting the entire state ($O(N \log N)$) at every step. By checking if the modified GPUs' new pressures are lexicographically better than their old values (relative to the global max), you can significantly reduce computational overhead, allowing for more search iterations or restarts.