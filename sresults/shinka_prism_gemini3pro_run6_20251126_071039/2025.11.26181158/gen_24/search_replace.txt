<NAME>
swap22_and_robust_perturbation
</NAME>

<DESCRIPTION>
Introduces a 2-to-2 Swap operator in the local search to better handle fragmentation and complex balancing scenarios where models of similar size but different loads (or vice versa) need to be exchanged in pairs. Enhances the perturbation mechanism to iterate through models in the bottleneck GPU (in randomized order) and attempts to move them to the least loaded feasible GPU (sorting candidates by KVPR), rather than just trying the first model on the first feasible GPU. Reduces the restart count from 5 to 4 to balance the computational cost of the new swap operator.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # --- Phase 2: Multi-Start ILS ---
    best_global_plc = None
    best_global_score = float('inf')

    # Run 5 restarts (Time permitting, this is very fast)
    for restart_idx in range(5):
        # Generate initial solution (Randomize subsequent starts)
        init_plc_list = solve_packing(base_k, randomize=(restart_idx > 0))
        if init_plc_list is None:
            # Fallback if base_k is too tight for random packing
            init_plc_list = solve_packing(base_k * 1.5, randomize=False)
            if init_plc_list is None: continue

        current_plc = {i: list(init_plc_list[i]) for i in range(gpu_num)}

        # Calculate stats
        l_vec = [sum(m.req_rate/m.slo for m in current_plc[g]) for g in range(gpu_num)]
        s_vec = [sum(m.model_size for m in current_plc[g]) for g in range(gpu_num)]

        cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))

        no_imp_iter = 0
        iter_limit = 100

        for _ in range(iter_limit):
            if cur_max_k < 1e-9: break

            # Find bottleneck
            bottleneck = -1
            max_val = -1.0
            for g in range(gpu_num):
                val = get_kvpr(l_vec[g], s_vec[g])
                if val > max_val:
                    max_val = val
                    bottleneck = g

            # Steepest Descent: Find BEST move from bottleneck
            best_move = None
            best_imp = 0.0

            src_l = l_vec[bottleneck]
            src_s = s_vec[bottleneck]

            # Helper to check validity and improvement
            def check_update(new_src_l, new_src_s, new_tgt_l, new_tgt_s):
                if new_src_s >= GPU_MEM_SIZE or new_tgt_s >= GPU_MEM_SIZE: return -1.0
                nk_src = get_kvpr(new_src_l, new_src_s)
                nk_tgt = get_kvpr(new_tgt_l, new_tgt_s)
                new_local_max = max(nk_src, nk_tgt)
                if new_local_max < cur_max_k - 1e-7:
                    return cur_max_k - new_local_max
                return -1.0

            src_models = current_plc[bottleneck]
            n_src = len(src_models)

            # Iterate targets
            for t in range(gpu_num):
                if t == bottleneck: continue
                # Pruning: if target is already heavily loaded, skip
                if get_kvpr(l_vec[t], s_vec[t]) > cur_max_k * 0.95: continue

                tgt_models = current_plc[t]
                n_tgt = len(tgt_models)
                tgt_l = l_vec[t]
                tgt_s = s_vec[t]

                # 1. Move
                for i in range(n_src):
                    m = src_models[i]
                    ml, ms = m.req_rate/m.slo, m.model_size
                    imp = check_update(src_l - ml, src_s - ms, tgt_l + ml, tgt_s + ms)
                    if imp > best_imp:
                        best_imp = imp
                        best_move = ('move', bottleneck, i, t)

                # 2. Swap 1-1
                for i in range(n_src):
                    m1 = src_models[i]
                    m1l, m1s = m1.req_rate/m1.slo, m1.model_size
                    for j in range(n_tgt):
                        m2 = tgt_models[j]
                        m2l, m2s = m2.req_rate/m2.slo, m2.model_size
                        imp = check_update(src_l - m1l + m2l, src_s - m1s + m2s,
                                         tgt_l - m2l + m1l, tgt_s - m2s + m1s)
                        if imp > best_imp:
                            best_imp = imp
                            best_move = ('swap11', bottleneck, i, t, j)

                # 3. Swap 2-1 (2 from Bottleneck, 1 from Target)
                if n_src >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps = m1.model_size + m2.model_size

                            for j in range(n_tgt):
                                m3 = tgt_models[j]
                                m3l, m3s = m3.req_rate/m3.slo, m3.model_size
                                imp = check_update(src_l - pl + m3l, src_s - ps + m3s,
                                                 tgt_l - m3l + pl, tgt_s - m3s + ps)
                                if imp > best_imp:
                                    best_imp = imp
                                    best_move = ('swap21', bottleneck, i1, i2, t, j)

            # Execute best move
            if best_move:
                mtype = best_move[0]
                if mtype == 'move':
                    _, b, i, t = best_move
                    m = current_plc[b].pop(i)
                    current_plc[t].append(m)

                    ml, ms = m.req_rate/m.slo, m.model_size
                    l_vec[b] -= ml; s_vec[b] -= ms
                    l_vec[t] += ml; s_vec[t] += ms

                elif mtype == 'swap11':
                    _, b, i, t, j = best_move
                    m1 = current_plc[b][i]
                    m2 = current_plc[t][j]
                    current_plc[b][i] = m2
                    current_plc[t][j] = m1

                    diff_l = (m2.req_rate/m2.slo) - (m1.req_rate/m1.slo)
                    diff_s = m2.model_size - m1.model_size
                    l_vec[b] += diff_l; s_vec[b] += diff_s
                    l_vec[t] -= diff_l; s_vec[t] -= diff_s

                elif mtype == 'swap21':
                    _, b, i1, i2, t, j = best_move
                    # Pop carefully: larger index first
                    m2 = current_plc[b].pop(i2)
                    m1 = current_plc[b].pop(i1)
                    m3 = current_plc[t].pop(j)
                    current_plc[b].append(m3)
                    current_plc[t].append(m1)
                    current_plc[t].append(m2)

                    # Full recalc for safety on multi-item moves
                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter = 0
            else:
                # Perturbation
                if no_imp_iter > 3: break

                # Move a model from bottleneck to LEAST LOADED feasible GPU
                min_k = float('inf')
                min_g = -1
                for g in range(gpu_num):
                    if g == bottleneck: continue
                    k_val = get_kvpr(l_vec[g], s_vec[g])
                    if k_val < min_k:
                        min_k = k_val
                        min_g = g

                moved = False
                if min_g != -1 and current_plc[bottleneck]:
                    # Try first model (simple heuristic)
                    m = current_plc[bottleneck][0]
                    if s_vec[min_g] + m.model_size < GPU_MEM_SIZE:
                        current_plc[bottleneck].pop(0)
                        current_plc[min_g].append(m)

                        l_vec[bottleneck] = sum(m.req_rate/m.slo for m in current_plc[bottleneck])
                        s_vec[bottleneck] = sum(m.model_size for m in current_plc[bottleneck])
                        l_vec[min_g] = sum(m.req_rate/m.slo for m in current_plc[min_g])
                        s_vec[min_g] = sum(m.model_size for m in current_plc[min_g])

                        cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                        moved = True

                if not moved: break
                no_imp_iter += 1

        if cur_max_k < best_global_score:
            best_global_score = cur_max_k
            best_global_plc = {i: list(current_plc[i]) for i in range(gpu_num)}

    # Fallback guarantees
    if best_global_plc is None:
        init = solve_packing(base_k)
        if init is None: init = solve_packing(1e9)
        if init is None: raise ValueError("No valid placement found.")
        best_global_plc = {i: init[i] for i in range(gpu_num)}

    return best_global_plc
=======
    # --- Phase 2: Multi-Start ILS ---
    best_global_plc = None
    best_global_score = float('inf')

    # Run 4 restarts (Reduced from 5 to allow for more expensive swap22)
    for restart_idx in range(4):
        # Generate initial solution (Randomize subsequent starts)
        init_plc_list = solve_packing(base_k, randomize=(restart_idx > 0))
        if init_plc_list is None:
            # Fallback if base_k is too tight for random packing
            init_plc_list = solve_packing(base_k * 1.5, randomize=False)
            if init_plc_list is None: continue

        current_plc = {i: list(init_plc_list[i]) for i in range(gpu_num)}

        # Calculate stats
        l_vec = [sum(m.req_rate/m.slo for m in current_plc[g]) for g in range(gpu_num)]
        s_vec = [sum(m.model_size for m in current_plc[g]) for g in range(gpu_num)]

        cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))

        no_imp_iter = 0
        iter_limit = 100

        for _ in range(iter_limit):
            if cur_max_k < 1e-9: break

            # Find bottleneck
            bottleneck = -1
            max_val = -1.0
            for g in range(gpu_num):
                val = get_kvpr(l_vec[g], s_vec[g])
                if val > max_val:
                    max_val = val
                    bottleneck = g

            # Steepest Descent: Find BEST move from bottleneck
            best_move = None
            best_imp = 0.0

            src_l = l_vec[bottleneck]
            src_s = s_vec[bottleneck]

            # Helper to check validity and improvement
            def check_update(new_src_l, new_src_s, new_tgt_l, new_tgt_s):
                if new_src_s >= GPU_MEM_SIZE or new_tgt_s >= GPU_MEM_SIZE: return -1.0
                nk_src = get_kvpr(new_src_l, new_src_s)
                nk_tgt = get_kvpr(new_tgt_l, new_tgt_s)
                new_local_max = max(nk_src, nk_tgt)
                if new_local_max < cur_max_k - 1e-7:
                    return cur_max_k - new_local_max
                return -1.0

            src_models = current_plc[bottleneck]
            n_src = len(src_models)

            # Iterate targets
            for t in range(gpu_num):
                if t == bottleneck: continue
                # Pruning: if target is already heavily loaded, skip
                if get_kvpr(l_vec[t], s_vec[t]) > cur_max_k * 0.95: continue

                tgt_models = current_plc[t]
                n_tgt = len(tgt_models)
                tgt_l = l_vec[t]
                tgt_s = s_vec[t]

                # 1. Move
                for i in range(n_src):
                    m = src_models[i]
                    ml, ms = m.req_rate/m.slo, m.model_size
                    imp = check_update(src_l - ml, src_s - ms, tgt_l + ml, tgt_s + ms)
                    if imp > best_imp:
                        best_imp = imp
                        best_move = ('move', bottleneck, i, t)

                # 2. Swap 1-1
                for i in range(n_src):
                    m1 = src_models[i]
                    m1l, m1s = m1.req_rate/m1.slo, m1.model_size
                    for j in range(n_tgt):
                        m2 = tgt_models[j]
                        m2l, m2s = m2.req_rate/m2.slo, m2.model_size
                        imp = check_update(src_l - m1l + m2l, src_s - m1s + m2s,
                                         tgt_l - m2l + m1l, tgt_s - m2s + m1s)
                        if imp > best_imp:
                            best_imp = imp
                            best_move = ('swap11', bottleneck, i, t, j)

                # 3. Swap 2-1 (2 from Bottleneck, 1 from Target)
                if n_src >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps = m1.model_size + m2.model_size

                            for j in range(n_tgt):
                                m3 = tgt_models[j]
                                m3l, m3s = m3.req_rate/m3.slo, m3.model_size
                                imp = check_update(src_l - pl + m3l, src_s - ps + m3s,
                                                 tgt_l - m3l + pl, tgt_s - m3s + ps)
                                if imp > best_imp:
                                    best_imp = imp
                                    best_move = ('swap21', bottleneck, i1, i2, t, j)

                # 4. Swap 2-2 (2 from Bottleneck, 2 from Target)
                if n_src >= 2 and n_tgt >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl_src = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps_src = m1.model_size + m2.model_size

                            for j1 in range(n_tgt):
                                for j2 in range(j1 + 1, n_tgt):
                                    m3, m4 = tgt_models[j1], tgt_models[j2]
                                    pl_tgt = (m3.req_rate/m3.slo) + (m4.req_rate/m4.slo)
                                    ps_tgt = m3.model_size + m4.model_size

                                    imp = check_update(src_l - pl_src + pl_tgt, src_s - ps_src + ps_tgt,
                                                     tgt_l - pl_tgt + pl_src, tgt_s - ps_tgt + ps_src)
                                    if imp > best_imp:
                                        best_imp = imp
                                        best_move = ('swap22', bottleneck, i1, i2, t, j1, j2)

            # Execute best move
            if best_move:
                mtype = best_move[0]
                if mtype == 'move':
                    _, b, i, t = best_move
                    m = current_plc[b].pop(i)
                    current_plc[t].append(m)

                    ml, ms = m.req_rate/m.slo, m.model_size
                    l_vec[b] -= ml; s_vec[b] -= ms
                    l_vec[t] += ml; s_vec[t] += ms

                elif mtype == 'swap11':
                    _, b, i, t, j = best_move
                    m1 = current_plc[b][i]
                    m2 = current_plc[t][j]
                    current_plc[b][i] = m2
                    current_plc[t][j] = m1

                    diff_l = (m2.req_rate/m2.slo) - (m1.req_rate/m1.slo)
                    diff_s = m2.model_size - m1.model_size
                    l_vec[b] += diff_l; s_vec[b] += diff_s
                    l_vec[t] -= diff_l; s_vec[t] -= diff_s

                elif mtype == 'swap21':
                    _, b, i1, i2, t, j = best_move
                    # Pop larger index first
                    m2 = current_plc[b].pop(i2)
                    m1 = current_plc[b].pop(i1)
                    m3 = current_plc[t].pop(j)
                    current_plc[b].append(m3)
                    current_plc[t].append(m1)
                    current_plc[t].append(m2)

                    # Full recalc for safety
                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                elif mtype == 'swap22':
                    _, b, i1, i2, t, j1, j2 = best_move
                    # Pop larger indices first from both lists
                    m_b2 = current_plc[b].pop(i2)
                    m_b1 = current_plc[b].pop(i1)
                    m_t2 = current_plc[t].pop(j2)
                    m_t1 = current_plc[t].pop(j1)

                    current_plc[b].append(m_t1)
                    current_plc[b].append(m_t2)
                    current_plc[t].append(m_b1)
                    current_plc[t].append(m_b2)

                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter = 0
            else:
                # Perturbation
                if no_imp_iter > 3: break

                # Robust Perturbation: Move a random model from bottleneck to the
                # BEST feasible GPU (lowest KVPR), not just the first one found.
                candidates = [] # (kvpr, gpu_idx)
                for g in range(gpu_num):
                    if g == bottleneck: continue
                    candidates.append((get_kvpr(l_vec[g], s_vec[g]), g))
                candidates.sort(key=lambda x: x[0])

                moved = False
                if current_plc[bottleneck]:
                    # Randomize which model to move to avoid cycles
                    indices = list(range(len(current_plc[bottleneck])))
                    random.shuffle(indices)

                    for idx in indices:
                        m = current_plc[bottleneck][idx]
                        # Try to move to the best possible candidate
                        for _, g in candidates:
                            if s_vec[g] + m.model_size < GPU_MEM_SIZE:
                                # Execute perturbation
                                current_plc[bottleneck].pop(idx)
                                current_plc[g].append(m)

                                # Update stats
                                l_vec[bottleneck] -= m.req_rate/m.slo
                                s_vec[bottleneck] -= m.model_size
                                l_vec[g] += m.req_rate/m.slo
                                s_vec[g] += m.model_size

                                moved = True
                                break
                        if moved: break

                if not moved: break
                cur_max_k = max(get_kvpr(l_vec[g], s_vec[g]) for g in range(gpu_num))
                no_imp_iter += 1

        if cur_max_k < best_global_score:
            best_global_score = cur_max_k
            best_global_plc = {i: list(current_plc[i]) for i in range(gpu_num)}

    # Fallback guarantees
    if best_global_plc is None:
        init = solve_packing(base_k)
        if init is None: init = solve_packing(1e9)
        if init is None: raise ValueError("No valid placement found.")
        best_global_plc = {i: init[i] for i in range(gpu_num)}

    return best_global_plc
>>>>>>> REPLACE
</DIFF>