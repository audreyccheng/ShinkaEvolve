<NAME>
improved_packing_and_swap12
</NAME>

<DESCRIPTION>
1. Enhance Binary Search initialization: Instead of a single linearized sort, try multiple deterministic sorting strategies (Linearized, Size, Load) to find tighter packings. This helps find a better baseline `K` and potentially starts the search in a better basin of attraction.
2. Enhance Local Search: Add 'Swap 1-2' operator (1 model from bottleneck, 2 from target). This complements the existing Move, Swap 1-1, and Swap 2-1/2-2 operators, addressing cases where one large model needs to be exchanged for two smaller ones to balance pressure.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    def solve_packing(target_k, randomize=False):
        """Generates a placement. Randomize=True adds noise to weights for diversity."""
        capacity = target_k * GPU_MEM_SIZE
        items = []
        for d in model_data:
            w = d['l'] + target_k * d['s']
            if randomize:
                w *= random.uniform(0.9, 1.1)
            items.append((w, d))

        items.sort(key=lambda x: x[0], reverse=True)

        gpu_l = [0.0] * gpu_num
        gpu_s = [0.0] * gpu_num
        gpu_models = [[] for _ in range(gpu_num)]

        # Helper indices for random tie-breaking
        indices = list(range(gpu_num))

        for _, item in items:
            best_idx = -1
            min_rem = float('inf')
            w_item = item['l'] + target_k * item['s']

            if randomize: random.shuffle(indices)

            for i in indices:
                if gpu_s[i] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue

                curr_w = gpu_l[i] + target_k * gpu_s[i]
                if curr_w + w_item <= capacity + 1e-9:
                    rem = capacity - (curr_w + w_item)
                    if rem < min_rem:
                        min_rem = rem
                        best_idx = i

            if best_idx != -1:
                gpu_l[best_idx] += item['l']
                gpu_s[best_idx] += item['s']
                gpu_models[best_idx].append(item['model'])
            else:
                return None
        return gpu_models
=======
    def solve_packing(target_k, randomize=False):
        """
        Generates a placement.
        If randomize=False, tries multiple deterministic heuristics.
        If randomize=True, adds noise to the linearized weight heuristic.
        """
        capacity = target_k * GPU_MEM_SIZE

        def get_strategies():
            if randomize:
                # Randomized Linearized
                items = []
                for d in model_data:
                    w = (d['l'] + target_k * d['s']) * random.uniform(0.9, 1.1)
                    items.append((w, d))
                items.sort(key=lambda x: x[0], reverse=True)
                return [[x[1] for x in items]]
            else:
                # Deterministic Heuristics
                strats = []
                # 1. Linearized Descending
                strats.append(sorted(model_data, key=lambda x: x['l'] + target_k * x['s'], reverse=True))
                # 2. Size Descending
                strats.append(sorted(model_data, key=lambda x: x['s'], reverse=True))
                # 3. Load Descending
                strats.append(sorted(model_data, key=lambda x: x['l'], reverse=True))
                return strats

        for items in get_strategies():
            gpu_l = [0.0] * gpu_num
            gpu_s = [0.0] * gpu_num
            gpu_models = [[] for _ in range(gpu_num)]
            indices = list(range(gpu_num))
            feasible = True

            for item in items:
                best_idx = -1
                min_rem = float('inf')
                w_item = item['l'] + target_k * item['s']

                if randomize: random.shuffle(indices)

                for i in indices:
                    if gpu_s[i] + item['s'] >= GPU_MEM_SIZE - 1e-6: continue

                    curr_w = gpu_l[i] + target_k * gpu_s[i]
                    if curr_w + w_item <= capacity + 1e-9:
                        rem = capacity - (curr_w + w_item)
                        if rem < min_rem:
                            min_rem = rem
                            best_idx = i

                if best_idx != -1:
                    gpu_l[best_idx] += item['l']
                    gpu_s[best_idx] += item['s']
                    gpu_models[best_idx].append(item['model'])
                else:
                    feasible = False
                    break

            if feasible:
                return gpu_models
        return None
>>>>>>> REPLACE
<<<<<<< SEARCH
                # 4. Swap 2-2 (2 from Bottleneck, 2 from Target)
                if n_src >= 2 and n_tgt >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl_src = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps_src = m1.model_size + m2.model_size

                            for j1 in range(n_tgt):
                                for j2 in range(j1 + 1, n_tgt):
                                    m3, m4 = tgt_models[j1], tgt_models[j2]
                                    pl_tgt = (m3.req_rate/m3.slo) + (m4.req_rate/m4.slo)
                                    ps_tgt = m3.model_size + m4.model_size

                                    imp = check_update(src_l - pl_src + pl_tgt, src_s - ps_src + ps_tgt,
                                                     tgt_l - pl_tgt + pl_src, tgt_s - ps_tgt + ps_src)
                                    if imp > best_imp:
                                        best_imp = imp
                                        best_move = ('swap22', bottleneck, i1, i2, t, j1, j2)

            # Execute best move
            if best_move:
                mtype = best_move[0]
                if mtype == 'move':
=======
                # 4. Swap 1-2 (1 from Bottleneck, 2 from Target)
                if n_tgt >= 2:
                    for i in range(n_src):
                        m1 = src_models[i]
                        m1l, m1s = m1.req_rate/m1.slo, m1.model_size

                        for j1 in range(n_tgt):
                            for j2 in range(j1 + 1, n_tgt):
                                m2, m3 = tgt_models[j1], tgt_models[j2]
                                pl_tgt = (m2.req_rate/m2.slo) + (m3.req_rate/m3.slo)
                                ps_tgt = m2.model_size + m3.model_size

                                imp = check_update(src_l - m1l + pl_tgt, src_s - m1s + ps_tgt,
                                                 tgt_l - pl_tgt + m1l, tgt_s - ps_tgt + m1s)
                                if imp > best_imp:
                                    best_imp = imp
                                    best_move = ('swap12', bottleneck, i, t, j1, j2)

                # 5. Swap 2-2 (2 from Bottleneck, 2 from Target)
                if n_src >= 2 and n_tgt >= 2:
                    for i1 in range(n_src):
                        for i2 in range(i1 + 1, n_src):
                            m1, m2 = src_models[i1], src_models[i2]
                            pl_src = (m1.req_rate/m1.slo) + (m2.req_rate/m2.slo)
                            ps_src = m1.model_size + m2.model_size

                            for j1 in range(n_tgt):
                                for j2 in range(j1 + 1, n_tgt):
                                    m3, m4 = tgt_models[j1], tgt_models[j2]
                                    pl_tgt = (m3.req_rate/m3.slo) + (m4.req_rate/m4.slo)
                                    ps_tgt = m3.model_size + m4.model_size

                                    imp = check_update(src_l - pl_src + pl_tgt, src_s - ps_src + ps_tgt,
                                                     tgt_l - pl_tgt + pl_src, tgt_s - ps_tgt + ps_src)
                                    if imp > best_imp:
                                        best_imp = imp
                                        best_move = ('swap22', bottleneck, i1, i2, t, j1, j2)

            # Execute best move
            if best_move:
                mtype = best_move[0]
                if mtype == 'move':
>>>>>>> REPLACE
<<<<<<< SEARCH
                elif mtype == 'swap21':
                    _, b, i1, i2, t, j = best_move
                    # Pop larger index first
                    m2 = current_plc[b].pop(i2)
                    m1 = current_plc[b].pop(i1)
                    m3 = current_plc[t].pop(j)
                    current_plc[b].append(m3)
                    current_plc[t].append(m1)
                    current_plc[t].append(m2)

                    # Full recalc for safety
                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                elif mtype == 'swap22':
=======
                elif mtype == 'swap21':
                    _, b, i1, i2, t, j = best_move
                    # Pop larger index first
                    m2 = current_plc[b].pop(i2)
                    m1 = current_plc[b].pop(i1)
                    m3 = current_plc[t].pop(j)
                    current_plc[b].append(m3)
                    current_plc[t].append(m1)
                    current_plc[t].append(m2)

                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                elif mtype == 'swap12':
                    _, b, i, t, j1, j2 = best_move
                    # Pop larger indices first from target
                    m3 = current_plc[t].pop(j2)
                    m2 = current_plc[t].pop(j1)
                    m1 = current_plc[b].pop(i)
                    current_plc[t].append(m1)
                    current_plc[b].append(m2)
                    current_plc[b].append(m3)

                    l_vec[b] = sum(m.req_rate/m.slo for m in current_plc[b])
                    s_vec[b] = sum(m.model_size for m in current_plc[b])
                    l_vec[t] = sum(m.req_rate/m.slo for m in current_plc[t])
                    s_vec[t] = sum(m.model_size for m in current_plc[t])

                elif mtype == 'swap22':
>>>>>>> REPLACE
</DIFF>