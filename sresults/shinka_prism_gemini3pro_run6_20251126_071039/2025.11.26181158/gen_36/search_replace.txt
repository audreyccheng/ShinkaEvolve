<NAME>
linearized_random
</NAME>

<DESCRIPTION>
Introduces randomization into the Linearized Binary Search strategy. After finding the optimal K parameter deterministically, the algorithm runs the bin packing heuristic 10 more times with small random noise (+/- 5%) added to the item weights. This helps explore the "basin of attraction" around the optimal K, potentially finding better initial configurations that deterministic packing misses.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Strategy A: Binary Search Linearization
    def solve_linearized_bp(target_k):
        bin_cap = target_k * GPU_MEM_SIZE
        items = []
        for m in models:
            w = (m.req_rate / m.slo) + target_k * m.model_size
            items.append((w, m))
        items.sort(key=lambda x: x[0], reverse=True)

        bins = [GPUState(i) for i in range(gpu_num)]
        for w, m in items:
            best_idx = -1
            min_rem = float('inf')
            for i in range(gpu_num):
                if not bins[i].can_fit(m.model_size): continue
                lin_usage = bins[i].load + target_k * bins[i].used_mem
                if lin_usage + w <= bin_cap:
                    rem = bin_cap - (lin_usage + w)
                    if rem < min_rem:
                        min_rem = rem
                        best_idx = i
            if best_idx != -1:
                bins[best_idx].add(m)
            else:
                return None
        return bins

    low, high = 0.0, 1000.0
    if solve_linearized_bp(high) is None: high = 1e9

    bs_res = None
    for _ in range(20):
        mid = (low + high) / 2
        res = solve_linearized_bp(mid)
        if res:
            bs_res = res
            high = mid
        else:
            low = mid
    if bs_res: candidates.append(bs_res)
=======
    # Strategy A: Binary Search Linearization (with Randomization)
    def solve_linearized_bp(target_k, noise=0.0):
        bin_cap = target_k * GPU_MEM_SIZE
        items = []
        for m in models:
            base_w = (m.req_rate / m.slo) + target_k * m.model_size
            w = base_w * random.uniform(1.0 - noise, 1.0 + noise)
            items.append((w, m, base_w))
        items.sort(key=lambda x: x[0], reverse=True)

        bins = [GPUState(i) for i in range(gpu_num)]
        for w, m, base_w in items:
            best_idx = -1
            min_rem = float('inf')
            for i in range(gpu_num):
                if not bins[i].can_fit(m.model_size): continue
                lin_usage = bins[i].load + target_k * bins[i].used_mem
                if lin_usage + base_w <= bin_cap:
                    rem = bin_cap - (lin_usage + base_w)
                    if rem < min_rem:
                        min_rem = rem
                        best_idx = i
            if best_idx != -1:
                bins[best_idx].add(m)
            else:
                return None
        return bins

    low, high = 0.0, 1000.0
    if solve_linearized_bp(high) is None: high = 1e9

    bs_res = None
    best_k = high
    for _ in range(20):
        mid = (low + high) / 2
        res = solve_linearized_bp(mid)
        if res:
            bs_res = res
            best_k = mid
            high = mid
        else:
            low = mid
    if bs_res:
        candidates.append(bs_res)
        # Randomized Refinement around best_k
        for _ in range(10):
            res_noise = solve_linearized_bp(best_k, noise=0.05)
            if res_noise: candidates.append(res_noise)
>>>>>>> REPLACE
</DIFF>

<NAME>
randomized_greedy
</NAME>

<DESCRIPTION>
Adds a randomized greedy strategy to the initialization phase. It shuffles the model order 5 times and applies Best Fit Decreasing (KVPR-based). This increases the diversity of candidate solutions and improves the success rate for tight constraints where deterministic sorting might fail.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        if valid: candidates.append(gpus)

    # Fallback
=======
        if valid: candidates.append(gpus)

    # Strategy E: Randomized Greedy (Robustness)
    for _ in range(5):
        gpus = [GPUState(i) for i in range(gpu_num)]
        shuffled_m = list(models)
        random.shuffle(shuffled_m)
        valid = True
        for m in shuffled_m:
            best_idx = -1
            best_val = float('inf')
            for i in range(gpu_num):
                if gpus[i].can_fit(m.model_size):
                    rem = GPU_MEM_SIZE - (gpus[i].used_mem + m.model_size)
                    val = (gpus[i].load + m.req_rate/m.slo) / rem if rem > 1e-7 else float('inf')
                    if val < best_val:
                        best_val = val
                        best_idx = i
            if best_idx != -1:
                gpus[best_idx].add(m)
            else:
                valid = False
                break
        if valid: candidates.append(gpus)

    # Fallback
>>>>>>> REPLACE
</DIFF>

<NAME>
steepest_descent_move
</NAME>

<DESCRIPTION>
Upgrades the "Move" operator from First Improvement to Best Improvement (Steepest Descent). Instead of accepting the first move that reduces KVPR, it scans all possible moves from the bottleneck GPUs to any other GPU and selects the one that results in the lexicographically smallest KVPR vector. This ensures more effective optimization steps, leveraging the available computational budget.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
        # --- Operator 1: Move ---
        for source in sources:
            for i, model in enumerate(source.models):
                for dest in destinations:
                    if dest.id == source.id: continue
                    if dest.can_fit(model.model_size):
                        source.remove(i)
                        dest.add(model)

                        new_vec = get_vector(current_gpus)
                        if new_vec < current_vector:
                            current_vector = new_vec
                            improved_step = True
                            break
                        else:
                            dest.remove(len(dest.models)-1)
                            source.restore_model(i, model)
                if improved_step: break
            if improved_step: break
=======
        # --- Operator 1: Move (Steepest Descent) ---
        best_move = None
        best_move_gain = current_vector

        for source in sources:
            for i, model in enumerate(source.models):
                for dest in current_gpus:
                    if dest.id == source.id: continue
                    if dest.can_fit(model.model_size):
                        source.remove(i)
                        dest.add(model)

                        new_vec = get_vector(current_gpus)
                        if new_vec < best_move_gain:
                            best_move_gain = new_vec
                            best_move = (source, i, dest, model)

                        dest.remove(len(dest.models)-1)
                        source.restore_model(i, model)

        if best_move:
            src, idx, dst, mdl = best_move
            src.remove(idx)
            dst.add(mdl)
            current_vector = best_move_gain
            improved_step = True
>>>>>>> REPLACE
</DIFF>