<NAME>
sweep_init_dual_perturb
</NAME>

<DESCRIPTION>
1.  **Initialization Sweep**: Replaces the single-point randomized refinement around the binary-search-found K with a systematic sweep of K values (from min_feasible to 1.5x). This explores the trade-off between load balancing (low K) and packing efficiency (high K) to find a better starting candidate.
2.  **Dual-Pivot Perturbation**: Modifies the perturbation phase to consistently ruin both the bottleneck GPU (worst) and the least-loaded GPU (sink). This maximizes the available free space, allowing for more effective reshuffling of heavy models from the bottleneck.
3.  **Robust Randomized Fallback**: Enhances the fallback mechanism. If the deterministic size-descending placement fails, it attempts multiple randomized placements (shuffled order) before giving up, reducing the risk of failure on hard instances.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
    # Binary search for min feasible K
    low, high = 0.0, 1000.0
    if solve_linearized_bp(high) is None: high = 1e9

    best_k = high
    for _ in range(16):
        mid = (low + high) / 2
        res = solve_linearized_bp(mid)
        if res:
            best_k = mid
            high = mid
        else:
            low = mid

    # Generate candidates around best_k
    if best_k < 1e8:
        # Base solution
        res = solve_linearized_bp(best_k)
        if res: candidates.append(res)
        # Noisy variations with wider range and more samples
        for _ in range(20):
            k_noisy = best_k * random.uniform(0.85, 1.15)
            res_noise = solve_linearized_bp(k_noisy, noise=0.08)
            if res_noise: candidates.append(res_noise)
=======
    # Binary search for min feasible K
    low, high = 0.0, 1000.0
    if solve_linearized_bp(high) is None: high = 1e9

    min_feasible_k = high
    for _ in range(20):
        mid = (low + high) / 2
        res = solve_linearized_bp(mid)
        if res:
            min_feasible_k = mid
            high = mid
        else:
            low = mid

    # Sweep diverse K values starting from min_feasible_k
    # This explores the trade-off between packing tightness (low K) and load balancing (high K)
    if min_feasible_k < 1e8:
        k_values = [min_feasible_k * (1.0 + 0.05 * i) for i in range(11)]
        for k_val in k_values:
            res = solve_linearized_bp(k_val)
            if res: candidates.append(res)
            # Add noisy versions for robust candidates
            for _ in range(2):
                res_noise = solve_linearized_bp(k_val, noise=0.06)
                if res_noise: candidates.append(res_noise)
>>>>>>> REPLACE
<<<<<<< SEARCH
    # Fallback (Robustness from Current Program)
    if not candidates:
        gpus = [GPUState(i) for i in range(gpu_num)]
        for m in sorted(models, key=lambda x: x.model_size, reverse=True):
            placed = False
            for i in range(gpu_num):
                if gpus[i].can_fit(m.model_size):
                    gpus[i].add(m)
                    placed = True
                    break
            if not placed: raise ValueError("Models do not fit.")
        candidates.append(gpus)
=======
    # Fallback: Retry with randomized orders if deterministic fit fails
    if not candidates:
        # Try deterministic first
        try:
            gpus = [GPUState(i) for i in range(gpu_num)]
            for m in sorted(models, key=lambda x: x.model_size, reverse=True):
                placed = False
                for i in range(gpu_num):
                    if gpus[i].can_fit(m.model_size):
                        gpus[i].add(m)
                        placed = True
                        break
                if not placed: raise ValueError
            candidates.append(gpus)
        except ValueError:
            # Randomized retries
            for _ in range(20):
                gpus = [GPUState(i) for i in range(gpu_num)]
                shuffled = list(models)
                random.shuffle(shuffled)
                valid = True
                for m in shuffled:
                    placed = False
                    for i in range(gpu_num):
                        if gpus[i].can_fit(m.model_size):
                            gpus[i].add(m)
                            placed = True
                            break
                    if not placed:
                        valid = False
                        break
                if valid:
                    candidates.append(gpus)
                    break
            if not candidates:
                raise ValueError("Models do not fit in GPU memory after randomized attempts.")
>>>>>>> REPLACE
<<<<<<< SEARCH
        # Occasionally ruin the lightest GPU to open up space (Probabilistic Dual Ruin)
        if random.random() < 0.25 and len(sorted_gpus) > 1:
            best_gpu = sorted_gpus[-1]
            if best_gpu.id != worst_gpu.id:
                while best_gpu.models: displaced.append(best_gpu.remove(0))
=======
        # Always ruin the lightest GPU (Sink) to create maximum free space for bottleneck items
        if len(sorted_gpus) > 1:
            best_gpu = sorted_gpus[-1]
            if best_gpu.id != worst_gpu.id:
                while best_gpu.models: displaced.append(best_gpu.remove(0))
>>>>>>> REPLACE
</DIFF>